# Data Structures for Density Estimation
**题目:** 密度估计数据结构

**作者:** Anders Aamand, Alexandr Andoni, Justin Y. Chen, Piotr Indyk, Shyam Narayanan, Sandeep Silwal

**Abstract:** We study statistical/computational tradeoffs for the following density estimation problem: given $k$ distributions $v_1, \ldots, v_k$ over a discrete domain of size $n$, and sampling access to a distribution $p$, identify $v_i$ that is "close" to $p$. Our main result is the first data structure that, given a sublinear (in $n$) number of samples from $p$, identifies $v_i$ in time sublinear in $k$. We also give an improved version of the algorithm of Acharya et al. (2018) that reports $v_i$ in time linear in $k$. The experimental evaluation of the latter algorithm shows that it achieves a significant reduction in the number of operations needed to achieve a given accuracy compared to prior work.

**摘要:** 我们研究了下列密度估计问题的统计/计算权衡: 给定 $k$ 分布 $v_1, \ldots, v_k$ 在 $n$ 的离散域上, 和对 $p$ 分布的抽样访问, 识别 $v_i$ 与 $p$ " 接近" 。 我们的主要结果是第一个数据结构, 给定 $p$ 的子线性 (在 $n$ ) 样品数目, 识别 $v_i$ 在 $k$ 的子线性 时间 。 我们还给出了 Acharya et al. (2018) 的改进版本, 报告 $v_i$ 在 $k$ 的 时间 线性 时间 。

**[Paper URL](https://proceedings.mlr.press/v202/aamand23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/aamand23a/aamand23a.pdf)** 

# ClusterFuG: Clustering Fully connected Graphs by Multicut
**题目:** ClusterFuG:由Multicut创建完整的连接图

**作者:** Ahmed Abbas, Paul Swoboda

**Abstract:** We propose a graph clustering formulation based on multicut (a.k.a. weighted correlation clustering) on the complete graph. Our formulation does not need specification of the graph topology as in the original sparse formulation of multicut, making our approach simpler and potentially better performing. In contrast to unweighted correlation clustering we allow for a more expressive weighted cost structure. In dense multicut, the clustering objective is given in a factorized form as inner products of node feature vectors. This allows for an efficient formulation and inference in contrast to multicut/weighted correlation clustering, which has at least quadratic representation and computation complexity when working on the complete graph. We show how to rewrite classical greedy algorithms for multicut in our dense setting and how to modify them for greater efficiency and solution quality. In particular, our algorithms scale to graphs with tens of thousands of nodes. Empirical evidence on instance segmentation on Cityscapes and clustering of ImageNet datasets shows the merits of our approach.

**摘要:** 我们提出了基于多切图(即重度相关聚类)的图集编写公式。我们的编写不需要像多切图的原始稀疏编写那样对图表拓扑的规范,从而使我们的方法更加简单和具有更好的性能。与非重度相关聚类相比,我们允许更具表达性的重度成本结构。在密集的多切图中,聚类目标是作为节点特征向量内部产物的因素化形式给出的。这允许与多切/重度相关聚类相比有效率的编写和推导,这至少在完成图表时具有二次表示和计算复杂性。我们展示了如何在密集的设置中重写经典贪婪算法,以及如何对其进行修改以提高效率和解决质量。对城市景观实例分割和 ImageNet数据集聚类的实证证明表明了我们的方法的优点。

**[Paper URL](https://proceedings.mlr.press/v202/abbas23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/abbas23a/abbas23a.pdf)** 

# Generalization on the Unseen, Logic Reasoning and Degree Curriculum
**题目:** 无形、逻辑推理和学位课程的一般化

**作者:** Emmanuel Abbe, Samy Bengio, Aryo Lotfi, Kevin Rizk

**Abstract:** This paper considers the learning of logical (Boolean) functions with focus on the generalization on the unseen (GOTU) setting, a strong case of out-of-distribution generalization. This is motivated by the fact that the rich combinatorial nature of data in certain reasoning tasks (e.g., arithmetic/logic) makes representative data sampling challenging, and learning successfully under GOTU gives a first vignette of an ’extrapolating’ or ’reasoning’ learner. We then study how different network architectures trained by (S)GD perform under GOTU and provide both theoretical and experimental evidence that for a class of network models including instances of Transformers, random features models, and diagonal linear networks, a min-degree-interpolator is learned on the unseen. We also provide evidence that other instances with larger learning rates or mean-field networks reach leaky min-degree solutions. These findings lead to two implications: (1) we provide an explanation to the length generalization problem (e.g., Anil et al. 2022); (2) we introduce a curriculum learning algorithm called Degree-Curriculum that learns monomials more efficiently by incrementing supports.

**摘要:** 本文对逻辑(Boolean)函数的学习,着重于无形(GOTU)设置的一般化,是非分布式一般化的一个有力案例。这是因为某些推理任务(例如算术/逻辑)中数据的丰富组合性使得代表性数据抽样具有挑战性,并且在GOTU下学习成功,给“推导”或“推理”学习者提供了第一幅画素。然后,我们研究了由(S)GD训练的不同网络架构在GOTU下的表现,并提供了理论和实验证据,即包括变换器、随机特征模型和斜线网络等网络模型的类别,在无形中学习的最小级插值器。这些发现导致了两个影响:(一)我们提供了对长度一般化问题的解释(例如Anil et al. 2022);(二)我们引入了通过增加支持更有效地学习单元课程的学位课程算法。

**[Paper URL](https://proceedings.mlr.press/v202/abbe23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/abbe23a/abbe23a.pdf)** 

# Toward Large Kernel Models
**题目:** 向大型核模型

**作者:** Amirhesam Abedsoltan, Mikhail Belkin, Parthe Pandit

**Abstract:** Recent studies indicate that kernel machines can often perform similarly or better than deep neural networks (DNNs) on small datasets. The interest in kernel machines has been additionally bolstered by the discovery of their equivalence to wide neural networks in certain regimes. However, a key feature of DNNs is their ability to scale the model size and training data size independently, whereas in traditional kernel machines model size is tied to data size. Because of this coupling, scaling kernel machines to large data has been computationally challenging. In this paper, we provide a way forward for constructing large-scale general kernel models, which are a generalization of kernel machines that decouples the model and data, allowing training on large datasets. Specifically, we introduce EigenPro 3.0, an algorithm based on projected dual preconditioned SGD and show scaling to model and data sizes which have not been possible with existing kernel methods. We provide a PyTorch based implementation which can take advantage of multiple GPUs.

**摘要:** 最近的研究表明,内核机器在小数据集上往往能比深度神经网络(DNNs)表现得类似或更好。对内核机器的兴趣,由于在某些情况下发现其与宽神经网络的同等性,进一步增强了。然而,DNNs的一个关键特征是它们能够独立调整模型大小和训练数据大小,而传统的内核机器模型大小与数据大小是联系在一起的。由于这种耦合,将内核机器规模化到大数据具有计算上的挑战性。我们提供一个基于PyTorch的实现,可以利用多个GPU。

**[Paper URL](https://proceedings.mlr.press/v202/abedsoltan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/abedsoltan23a/abedsoltan23a.pdf)** 

# Expertise Trees Resolve Knowledge Limitations in Collective Decision-Making
**题目:** 专家树解决集体决策中的知识限制

**作者:** Axel Abels, Tom Lenaerts, Vito Trianni, Ann Nowe

**Abstract:** Experts advising decision-makers are likely to display expertise which varies as a function of the problem instance. In practice, this may lead to sub-optimal or discriminatory decisions against minority cases. In this work, we model such changes in depth and breadth of knowledge as a partitioning of the problem space into regions of differing expertise. We provide here new algorithms that explicitly consider and adapt to the relationship between problem instances and experts’ knowledge. We first propose and highlight the drawbacks of a naive approach based on nearest neighbor queries. To address these drawbacks we then introduce a novel algorithm — expertise trees — that constructs decision trees enabling the learner to select appropriate models. We provide theoretical insights and empirically validate the improved performance of our novel approach on a range of problems for which existing methods proved to be inadequate.

**摘要:** 在实践中,这可能导致对少数群体案件作出低优或歧视性的决定。在这一工作中,我们将知识深度和宽度的这种变化模式化为问题空间的分割,将问题空间分成不同的专门知识区域。我们提供新的算法,明确考虑和适应问题实例和专家知识之间的关系。我们首先提出和突出基于最近邻近查询的原始方法的缺点。为了解决这些缺点,我们引入了一种新算法——专家树——它构建决策树,让学习者选择合适的模型。我们提供了理论洞察和实验验证了我们新方法在一系列问题上改进的性能,而现有的方法证明不足。

**[Paper URL](https://proceedings.mlr.press/v202/abels23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/abels23a/abels23a.pdf)** 

# Comparison of meta-learners for estimating multi-valued treatment heterogeneous effects
**题目:** 评价多值治疗异质效应的元学习者比较

**作者:** Naoufal Acharki, Ramiro Lugo, Antoine Bertoncello, Josselin Garnier

**Abstract:** Conditional Average Treatment Effects (CATE) estimation is one of the main challenges in causal inference with observational data. In addition to Machine Learning based-models, nonparametric estimators called meta-learners have been developed to estimate the CATE with the main advantage of not restraining the estimation to a specific supervised learning method. This task becomes, however, more complicated when the treatment is not binary as some limitations of the naive extensions emerge. This paper looks into meta-learners for estimating the heterogeneous effects of multi-valued treatments. We consider different meta-learners, and we carry out a theoretical analysis of their error upper bounds as functions of important parameters such as the number of treatment levels, showing that the naive extensions do not always provide satisfactory results. We introduce and discuss meta-learners that perform well as the number of treatments increases. We empirically confirm the strengths and weaknesses of those methods with synthetic and semi-synthetic datasets.

**摘要:** 条件平均治疗效应(CATE)估算是观察数据的因果推导中的主要挑战之一。除了基于机器学习的模型之外,还开发了非参数估算器称Meta-learners来估算CATE,其主要优势在于不限制估算到特定受监督的学习方法。然而,当治疗不是二进制时,这个任务变得更加复杂,因为一些狭义扩展的局限性出现。本文对多值治疗的异质效应估算的Meta-learners进行了研究。我们考虑了不同的Meta-learners,并进行了他们的误差上限的理论分析,作为重要的参数函数,例如治疗水平数目,表明狭义扩展并不总是提供满意的结果。通过合成和半合成数据集,对这些方法的优缺点进行了实证验证。

**[Paper URL](https://proceedings.mlr.press/v202/acharki23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/acharki23a/acharki23a.pdf)** 

# BNN-DP: Robustness Certification of Bayesian Neural Networks via Dynamic Programming
**题目:** BNN-DP:通过动态编程验证贝叶斯神经网络的鲁棒性

**作者:** Steven Adams, Andrea Patane, Morteza Lahijanian, Luca Laurenti

**Abstract:** In this paper, we introduce BNN-DP, an efficient algorithmic framework for analysis of adversarial robustness of Bayesian Neural Networks (BNNs). Given a compact set of input points $T\subset \mathbb{R}^n$, BNN-DP computes lower and upper bounds on the BNN’s predictions for all the points in $T$. The framework is based on an interpretation of BNNs as stochastic dynamical systems, which enables the use of Dynamic Programming (DP) algorithms to bound the prediction range along the layers of the network. Specifically, the method uses bound propagation techniques and convex relaxations to derive a backward recursion procedure to over-approximate the prediction range of the BNN with piecewise affine functions. The algorithm is general and can handle both regression and classification tasks. On a set of experiments on various regression and classification tasks and BNN architectures, we show that BNN-DP outperforms state-of-the-art methods by up to four orders of magnitude in both tightness of the bounds and computational efficiency.

**摘要:** 本文介绍了贝叶斯神经网络(BNN)的敌对鲁棒性分析的高效算法框架BNN-DP。BNN-DP基于BNN作为随机动态系统的一个解释,使动态编程(DP)算法能够在网络的各个层间绑定预测范围。具体而言,该方法使用边界传播技术和凸松弛来推导逆递归过程,使BNN的预测范围与分段微细函数相近。该算法是通用的,可以处理回归和分类任务。通过对不同回归和分类任务以及BNN架构的一系列实验,证明BNN-DP在边界紧缩和计算效率方面比最先进的方法高四等。

**[Paper URL](https://proceedings.mlr.press/v202/adams23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/adams23a/adams23a.pdf)** 

# SAM operates far from home: eigenvalue regularization as a dynamical phenomenon
**题目:** SAM运行离家很远:自值规范化作为动态现象

**作者:** Atish Agarwala, Yann Dauphin

**Abstract:** The Sharpness Aware Minimization (SAM) optimization algorithm has been shown to control large eigenvalues of the loss Hessian and provide generalization benefits in a variety of settings. The original motivation for SAM was a modified loss function which penalized sharp minima; subsequent analyses have also focused on the behavior near minima. However, our work reveals that SAM provides a strong regularization of the eigenvalues throughout the learning trajectory. We show that in a simplified setting, SAM dynamically induces a stabilization related to the edge of stability (EOS) phenomenon observed in large learning rate gradient descent. Our theory predicts the largest eigenvalue as a function of the learning rate and SAM radius parameters. Finally, we show that practical models can also exhibit this EOS stabilization, and that understanding SAM must account for these dynamics far away from any minima.

**摘要:** 研究表明,精细微化优化算法能够控制希西亚损失的较大特征值,并在各种环境下提供广义化利益。该算法的原动力是修正的损失函数,使精细微化受到惩罚;随后的分析也集中在接近微化的行为上。然而,我们的研究表明,精细微化算法在整个学习轨迹中提供了强的特征值 regularization。我们证明,在简化环境下,精细微化算法能动态地诱导与大学习率梯度下降所观察到的稳定性边缘(EOS)现象有关的稳定化。

**[Paper URL](https://proceedings.mlr.press/v202/agarwala23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/agarwala23a/agarwala23a.pdf)** 

# Second-order regression models exhibit progressive sharpening to the edge of stability
**题目:** 第二阶回归模型表现出渐进的锐化到稳定边缘

**作者:** Atish Agarwala, Fabian Pedregosa, Jeffrey Pennington

**Abstract:** Recent studies of gradient descent with large step sizes have shown that there is often a regime with an initial increase in the largest eigenvalue of the loss Hessian (progressive sharpening), followed by a stabilization of the eigenvalue near the maximum value which allows convergence (edge of stability). These phenomena are intrinsically non-linear and do not happen for models in the constant Neural Tangent Kernel (NTK) regime, for which the predictive function is approximately linear in the parameters. As such, we consider the next simplest class of predictive models, namely those that are quadratic in the parameters, which we call second-order regression models. For quadratic objectives in two dimensions, we prove that this second-order regression model exhibits progressive sharpening of the NTK eigenvalue towards a value that differs slightly from the edge of stability, which we explicitly compute. In higher dimensions, the model generically shows similar behavior, even without the specific structure of a neural network, suggesting that progressive sharpening and edge-of-stability behavior aren’t unique features of neural networks, and could be a more general property of discrete learning algorithms in high-dimensional non-linear models.

**摘要:** 大型步骤梯度下降的最近研究表明,损失的最大特征值经常有初始增加的模式( progresive sharpening),其次是 near the maximum value 的特征值的稳定化,允许收敛(稳定边缘)。这些现象是本质上非线性的,并不发生在常数神经 Tangent Kernel (NTK)模式中的模型中,其中预测函数在参数中大约是线性的。因此,我们考虑了下一个最简单的预测模型类别,即参数中是二次的,我们称之为二次回归模型。在更高维度中,模型一般显示类似的行为,即使没有神经网络的特定结构,这表明渐进的锐化和边缘稳定性行为并不是神经网络的独特特征,而且在高维非线性模型中,可作为离散学习算法的更一般的特性。

**[Paper URL](https://proceedings.mlr.press/v202/agarwala23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/agarwala23b/agarwala23b.pdf)** 

# Global optimality of Elman-type RNNs in the mean-field regime
**题目:** 埃尔曼型RNN在平均场模式下的全球最佳性

**作者:** Andrea Agazzi, Jianfeng Lu, Sayan Mukherjee

**Abstract:** We analyze Elman-type recurrent neural networks (RNNs) and their training in the mean-field regime. Specifically, we show convergence of gradient descent training dynamics of the RNN to the corresponding mean-field formulation in the large width limit. We also show that the fixed points of the limiting infinite-width dynamics are globally optimal, under some assumptions on the initialization of the weights. Our results establish optimality for feature-learning with wide RNNs in the mean-field regime.

**摘要:** 分析了埃尔曼型循环神经网络(RNN)及其在平均场模式下的训练,具体表现了RNN梯度下降训练动力学与大宽限的相应平均场公式的收敛性,并表明限制无限宽限动力学的固定点在重量初始化的一些假设下是全球最佳的。

**[Paper URL](https://proceedings.mlr.press/v202/agazzi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/agazzi23a/agazzi23a.pdf)** 

# SemSup-XC: Semantic Supervision for Zero and Few-shot Extreme Classification
**题目:** SemSup-XC:零和少数射击极端分类的语义监督

**作者:** Pranjal Aggarwal, Ameet Deshpande, Karthik R Narasimhan

**Abstract:** Extreme classification (XC) involves predicting over large numbers of classes (thousands to millions), with real-world applications like news article classification and e-commerce product tagging. The zero-shot version of this task requires generalization to novel classes without additional supervision. In this paper, we develop SemSup-XC, a model that achieves state-of-the-art zero-shot and few-shot performance on three XC datasets derived from legal, e-commerce, and Wikipedia data. To develop SemSup-XC, we use automatically collected semantic class descriptions to represent classes and facilitate generalization through a novel hybrid matching module that matches input instances to class descriptions using a combination of semantic and lexical similarity. Trained with contrastive learning, SemSup-XC significantly outperforms baselines and establishes state-of-the-art performance on all three datasets considered, gaining up to 12 precision points on zero-shot and more than 10 precision points on one-shot tests, with similar gains for recall@10. Our ablation studies highlight the relative importance of our hybrid matching module and automatically collected class descriptions.

**摘要:** 极端分类(XC)包括预测大量类别(从数千到数百万)的预测,以及新闻条目分类和电子商务产品标记等实世界应用。该任务的零射击版本不需要额外监督,需要对新类进行一般化。本论文中,我们开发了基于法律、电子商务和维基百科数据的三个XC数据集的最先进的零射击和少数射击性能的SemSup-XC模型。为了开发SemSup-XC,我们使用自动收集的语义类描述来代表类别,并通过一种新的混合匹配模块来促进一般化。SemSup-XC经过对比学习,大大超过了基准,在考虑的三个数据集中建立了最先进的性能,在零射击测试中达到12个精度点,在单射击测试中达到10个精度点,在Recall@10测试中也有类似的提高。

**[Paper URL](https://proceedings.mlr.press/v202/aggarwal23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/aggarwal23a/aggarwal23a.pdf)** 

# Adaptive IMLE for Few-shot Pretraining-free Generative Modelling
**题目:** 低射程预训练无源建模的适应性IMLE

**作者:** Mehran Aghabozorgi, Shichong Peng, Ke Li

**Abstract:** Despite their success on large datasets, GANs have been difficult to apply in the few-shot setting, where only a limited number of training examples are provided. Due to mode collapse, GANs tend to ignore some training examples, causing overfitting to a subset of the training dataset, which is small in the first place. A recent method called Implicit Maximum Likelihood Estimation (IMLE) is an alternative to GAN that tries to address this issue. It uses the same kind of generators as GANs but trains it with a different objective that encourages mode coverage. However, the theoretical guarantees of IMLE hold under a restrictive condition that the optimal likelihood at all data points is the same. In this paper, we present a more generalized formulation of IMLE which includes the original formulation as a special case, and we prove that the theoretical guarantees hold under weaker conditions. Using this generalized formulation, we further derive a new algorithm, which we dub Adaptive IMLE, which can adapt to the varying difficulty of different training examples. We demonstrate on multiple few-shot image synthesis datasets that our method significantly outperforms existing methods. Our code is available at https://github.com/mehranagh20/AdaIMLE.

**摘要:** 尽管在大型数据集中取得了成功,但GAN很难在少数射击设置中应用,只有有限数量的训练实例提供。由于模式崩溃,GAN倾向于忽略一些训练实例,导致训练数据集的一个子集不适,这在一开始就很小。最近一种叫做隐形最大概率估计(IMLE)的方法是GAN的替代方案,它试图解决这个问题。它使用了GAN同类的发电机,但训练它以不同的目标鼓励模式覆盖。然而,IMLE的理论保证在限制条件下保持,在所有数据点的最优概率是相同的。使用这个广义的公式,我们进一步推导了一个新的算法,我们称之为适应性IMLE,它可以适应不同的训练例子的不同难度。我们在多个少数镜头图像合成数据集上证明,我们的方法大大超过现有的方法。我们的代码在 https://github.com/mehranagh20/AdaIMLE上。

**[Paper URL](https://proceedings.mlr.press/v202/aghabozorgi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/aghabozorgi23a/aghabozorgi23a.pdf)** 

# Scaling Laws for Generative Mixed-Modal Language Models
**题目:** 生成混合模态语言模型的尺度法

**作者:** Armen Aghajanyan, Lili Yu, Alexis Conneau, Wei-Ning Hsu, Karen Hambardzumyan, Susan Zhang, Stephen Roller, Naman Goyal, Omer Levy, Luke Zettlemoyer

**Abstract:** Generative language models define distributions over sequences of tokens that can represent essentially any combination of data modalities (e.g., any permutation of image tokens from VQ-VAEs, speech tokens from HuBERT, BPE tokens for language or code, and so on). To better understand the scaling properties of such mixed-modal models, we conducted over 250 experiments using seven different modalities and model sizes ranging from 8 million to 30 billion, trained on 5-100 billion tokens. We report new mixed-modal scaling laws that unify the contributions of individual modalities and the interactions between them. Specifically, we explicitly model the optimal synergy and competition due to data and model size as an additive term to previous uni-modal scaling laws. We also find four empirical phenomena observed during the training, such as emergent coordinate-ascent style training that naturally alternates between modalities, guidelines for selecting critical hyper-parameters, and connections between mixed-modal competition and training stability. Finally, we test our scaling law by training a 30B speech-text model, which significantly outperforms the corresponding unimodal models. Overall, our research provides valuable insights into the design and training of mixed-modal generative models, an important new class of unified models that have unique distributional properties.

**摘要:** 生成语言模型定义了可以代表数据模式的任何组合的符号序列的分布(例如VQ-VAEs的图像符号的变换、HuBERT的语音符号、语言或代码的BPE符号等等)。为了更好地理解这种混合模式模型的 scaling特性,我们进行了超过250次实验,使用7种不同的模式和模型大小,从8亿到30亿,训练5至100亿的符号。我们报告了新的混合模式 scaling laws that unify the contributions of individual modalities and the interactions between them。我们还发现四个在训练中观察到的实证现象,例如一种自然地在模态之间互换的新兴坐标上升式训练,关键超参数选择的指导方针,以及混合模式竞争与训练稳定性之间的联系。最后,我们通过训练一个30B语音文本模型,测试了我们 skaling法,这 significantly outperforms the corresponding unimodal models。

**[Paper URL](https://proceedings.mlr.press/v202/aghajanyan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/aghajanyan23a/aghajanyan23a.pdf)** 

# Hypothesis Transfer Learning with Surrogate Classification Losses: Generalization Bounds through Algorithmic Stability
**题目:** 假定转移学习与替代分类损失:通过算法稳定性的一般化界限

**作者:** Anass Aghbalou, Guillaume Staerman

**Abstract:** Hypothesis transfer learning (HTL) contrasts domain adaptation by allowing for a previous task leverage, named the source, into a new one, the target, without requiring access to the source data. Indeed, HTL relies only on a hypothesis learnt from such source data, relieving the hurdle of expansive data storage and providing great practical benefits. Hence, HTL is highly beneficial for real-world applications relying on big data. The analysis of such a method from a theoretical perspective faces multiple challenges, particularly in classification tasks. This paper deals with this problem by studying the learning theory of HTL through algorithmic stability, an attractive theoretical framework for machine learning algorithms analysis. In particular, we are interested in the statistical behavior of the regularized empirical risk minimizers in the case of binary classification. Our stability analysis provides learning guarantees under mild assumptions. Consequently, we derive several complexity-free generalization bounds for essential statistical quantities like the training error, the excess risk and cross-validation estimates. These refined bounds allow understanding the benefits of transfer learning and comparing the behavior of standard losses in different scenarios, leading to valuable insights for practitioners.

**摘要:** 假设转移学习(HTL)通过允许源代码命名的先前任务杠杆,使域适应为新的目标,而不需要访问源代码。事实上,HTL只依赖于从源代码中学习的假设,缓解了扩展数据存储的障碍,并提供巨大的实际利益。因此,HTL对于依赖于大数据的实世界应用具有很高的效益。从理论角度对这种方法的分析面临着多种挑战,特别是在分类任务中。本论文通过研究HTL的学习理论通过算法稳定性,为机器学习算法分析提供了一个引人注目的理论框架来解决这一问题。因此,我们对基本统计量,如训练误差、风险过多和交叉验证估计,得出一些无复杂性的一般化界限,这些精确的界限允许理解转移学习的好处和在不同场景中比较标准损失的行为,从而为实践者提供宝贵的洞察。

**[Paper URL](https://proceedings.mlr.press/v202/aghbalou23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/aghbalou23a/aghbalou23a.pdf)** 

# Constrained Causal Bayesian Optimization
**题目:** 约束性因果贝叶斯优化

**作者:** Virginia Aglietti, Alan Malek, Ira Ktena, Silvia Chiappa

**Abstract:** We propose constrained causal Bayesian optimization (cCBO), an approach for finding interventions in a known causal graph that optimize a target variable under some constraints. cCBO first reduces the search space by exploiting the graph structure and, if available, an observational dataset; and then solves the restricted optimization problem by modelling target and constraint quantities using Gaussian processes and by sequentially selecting interventions via a constrained expected improvement acquisition function. We propose different surrogate models that enable to integrate observational and interventional data while capturing correlation among effects with increasing levels of sophistication. We evaluate cCBO on artificial and real-world causal graphs showing successful trade off between fast convergence and percentage of feasible interventions.

**摘要:** 我们提出约束性因果贝叶斯优化(cCBO),一种在某些约束下优化目标变量的情况下在已知的因果图中找到干预的方法。 cCBO首先通过利用图结构和,如果可用的话,观察数据集来减少搜索空间;然后通过使用高斯过程模拟目标和约束量并通过通过约束预期改进获取函数连续选择干预来解决限制性优化问题。

**[Paper URL](https://proceedings.mlr.press/v202/aglietti23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/aglietti23a/aglietti23a.pdf)** 

# Explaining the effects of non-convergent MCMC in the training of Energy-Based Models
**题目:** 解释非趋向型MCMC在能源型模型培训中的作用

**作者:** Elisabeth Agoritsas, Giovanni Catania, Aurélien Decelle, Beatriz Seoane

**Abstract:** In this paper, we quantify the impact of using non-convergent Markov chains to train Energy-Based models (EBMs). In particular, we show analytically that EBMs trained with non-persistent short runs to estimate the gradient can perfectly reproduce a set of empirical statistics of the data, not at the level of the equilibrium measure, but through a precise dynamical process. Our results provide a first-principles explanation for the observations of recent works proposing the strategy of using short runs starting from random initial conditions as an efficient way to generate high-quality samples in EBMs, and lay the groundwork for using EBMs as diffusion models. After explaining this effect in generic EBMs, we analyze two solvable models in which the effect of the non-convergent sampling in the trained parameters can be described in detail. Finally, we test these predictions numerically on a ConvNet EBM and a Boltzmann machine.

**摘要:** 本文对使用非收敛马可夫链来训练基于能量的模型的影响进行了定量化,特别是,分析表明用非持久的短跑来估计梯度的EBM能够通过精确的动态过程,而不是在平衡尺度的水平上,完全地复制数据的实证统计。我们的结果为近期研究提出从随机初始条件开始的短跑作为高效的EBM生成高质量样本的方法的策略,并为使用EBM作为扩散模型奠定了基础。分析了一般EBM中这一效应后,分析了两个可解模型,其中非收敛样本在训练参数中的作用可以详细描述。

**[Paper URL](https://proceedings.mlr.press/v202/agoritsas23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/agoritsas23a/agoritsas23a.pdf)** 

# Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies
**题目:** 利用大型语言模型模拟多个人类和复制人类学科研究

**作者:** Gati V Aher, Rosa I. Arriaga, Adam Tauman Kalai

**Abstract:** We introduce a new type of test, called a Turing Experiment (TE), for evaluating to what extent a given language model, such as GPT models, can simulate different aspects of human behavior. A TE can also reveal consistent distortions in a language model’s simulation of a specific human behavior. Unlike the Turing Test, which involves simulating a single arbitrary individual, a TE requires simulating a representative sample of participants in human subject research. We carry out TEs that attempt to replicate well-established findings from prior studies. We design a methodology for simulating TEs and illustrate its use to compare how well different language models are able to reproduce classic economic, psycholinguistic, and social psychology experiments: Ultimatum Game, Garden Path Sentences, Milgram Shock Experiment, and Wisdom of Crowds. In the first three TEs, the existing findings were replicated using recent models, while the last TE reveals a “hyper-accuracy distortion” present in some language models (including ChatGPT and GPT-4), which could affect downstream applications in education and the arts.

**摘要:** 我们引入一种新的测试类型,即图灵实验(TE),以评估某一语言模型,例如GPT模型,能够模拟人类行为的各个方面。TE还能够揭示语言模型对特定人类行为的仿真中的一致扭曲。与图灵实验不同,它涉及模拟单个任意的个体, TE需要模拟人类主体研究的代表样本。我们执行的 TE试图复制先前研究的已建立的发现。我们设计了一个仿真方法,并说明它用来比较不同的语言模型能够再现古典经济、心理语言学和社会心理学实验:Ultimatum Game、花园路径 Sentences、Milgram Shock Experiment和群衆智慧。在最初的三个 TE中,现有的发现被用最近的模型复制,而最后的 TE显示了一些语言模型(包括ChatGPT和GPT-4)存在“高精度扭曲”,这可能影响教育和艺术领域的下游应用。

**[Paper URL](https://proceedings.mlr.press/v202/aher23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/aher23a/aher23a.pdf)** 

# Interventional Causal Representation Learning
**题目:** 干预因果代表学习

**作者:** Kartik Ahuja, Divyat Mahajan, Yixin Wang, Yoshua Bengio

**Abstract:** Causal representation learning seeks to extract high-level latent factors from low-level sensory data. Most existing methods rely on observational data and structural assumptions (e.g., conditional independence) to identify the latent factors. However, interventional data is prevalent across applications. Can interventional data facilitate causal representation learning? We explore this question in this paper. The key observation is that interventional data often carries geometric signatures of the latent factors’ support (i.e. what values each latent can possibly take). For example, when the latent factors are causally connected, interventions can break the dependency between the intervened latents’ support and their ancestors’. Leveraging this fact, we prove that the latent causal factors can be identified up to permutation and scaling given data from perfect do interventions. Moreover, we can achieve block affine identification, namely the estimated latent factors are only entangled with a few other latents if we have access to data from imperfect interventions. These results highlight the unique power of interventional data in causal representation learning; they can enable provable identification of latent factors without any assumptions about their distributions or dependency structure.

**摘要:** 因果表现学习旨在从低层次感官数据中提取高层次的潜在因素。大多数现有方法依靠观察数据和结构假设(例如条件独立)来识别潜在因素。然而,干预数据在应用中普遍存在。干预数据能促进因果表现学习吗?我们在本文中探讨了这个问题。关键的观察是干预数据经常载有潜在因素的支持的几何特征(即每个潜在因素可能采取什么值)。这些结果突出了干预数据在因果关系演示学习中具有独特的能力;它们可以使潜在因素的可证明性识别,而不需要对其分布或依赖结构的任何假设。

**[Paper URL](https://proceedings.mlr.press/v202/ahuja23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ahuja23a/ahuja23a.pdf)** 

# Sequential Underspecified Instrument Selection for Cause-Effect Estimation
**题目:** 因果影响估计的序列未指定仪器选择

**作者:** Elisabeth Ailer, Jason Hartford, Niki Kilbertus

**Abstract:** Instrumental variable (IV) methods are used to estimate causal effects in settings with unobserved confounding, where we cannot directly experiment on the treatment variable. Instruments are variables which only affect the outcome indirectly via the treatment variable(s). Most IV applications focus on low-dimensional treatments and crucially require at least as many instruments as treatments. This assumption is restrictive: in the natural sciences we often seek to infer causal effects of high-dimensional treatments (e.g., the effect of gene expressions or microbiota on health and disease), but can only run few experiments with a limited number of instruments (e.g., drugs or antibiotics). In such under-specified problems, the full treatment effect is not identifiable in a single experiment even in the linear case. We show that one can still reliably recover the projection of the treatment effect onto the instrumented subspace and develop techniques to consistently combine such partial estimates from different sets of instruments. We then leverage our combined estimators in an algorithm that iteratively proposes the most informative instruments at each round of experimentation to maximize the overall information about the full causal effect.

**摘要:** 仪器变量(IV)方法用于在没有观察到的混淆环境下估计因果效应,我们不能直接对治疗变量进行实验。仪器是通过治疗变量(s)间接影响结果的变量。大多数IV应用集中在低次元治疗中,并且最关键的需要至少像治疗一样多的仪器。这一假设是限制性的:在自然科学中,我们经常试图推断高次元治疗的因果效应(例如基因表达或微生物对健康和疾病的影响),但只能用有限的仪器(例如药物或抗生素)进行少数实验。实验结果表明,人们仍可可靠地恢复治疗效果的投影到仪器的子空间,并开发技术,从不同仪器组中连续结合这些局部估计。然后,我们利用我们结合估计器的算法,在每次实验中反复提议最有信息的仪器,以最大化有关全因果效应的总体信息。

**[Paper URL](https://proceedings.mlr.press/v202/ailer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ailer23a/ailer23a.pdf)** 

# Atari-5: Distilling the Arcade Learning Environment down to Five Games
**题目:** Atari-5:将游戏环境分解为五种游戏

**作者:** Matthew Aitchison, Penny Sweetser, Marcus Hutter

**Abstract:** The Arcade Learning Environment (ALE) has become an essential benchmark for assessing the performance of reinforcement learning algorithms. However, the computational cost of generating results on the entire 57-game dataset limits ALE’s use and makes the reproducibility of many results infeasible. We propose a novel solution to this problem in the form of a principled methodology for selecting small but representative subsets of environments within a benchmark suite. We applied our method to identify a subset of five ALE games, we call Atari-5, which produces 57-game median score estimates within 10% of their true values. Extending the subset to 10-games recovers 80% of the variance for log-scores for all games within the 57-game set. We show this level of compression is possible due to a high degree of correlation between many of the games in ALE.

**摘要:** Arcade Learning Environment(ALE)已成为评估增强学习算法性能的一个重要指标。然而,在整个57游戏数据集中生成结果的计算成本限制了ALE的使用,使得许多结果的可重复性无法实现。我们提出了一种基于原则的方法来选择在基准套件内环境的小型但代表性的子集的新解决方案。我们应用了我们的方法来识别五个ALE游戏的子集,我们称之为Atari-5,它在其真实值的10%以内产生57游戏平均分数估算。

**[Paper URL](https://proceedings.mlr.press/v202/aitchison23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/aitchison23a/aitchison23a.pdf)** 

# Towards credible visual model interpretation with path attribution
**题目:** 基于路径归纳的可信的视觉模型解释

**作者:** Naveed Akhtar, Mohammad A. A. K. Jalwana

**Abstract:** With its inspirational roots in game-theory, path attribution framework stands out among the post-hoc model interpretation techniques due to its axiomatic nature. However, recent developments show that despite being axiomatic, path attribution methods can compute counter-intuitive feature attributions. Not only that, for deep visual models, the methods may also not conform to the original game-theoretic intuitions that are the basis of their axiomatic nature. To address these issues, we perform a systematic investigation of the path attribution framework. We first pinpoint the conditions in which the counter-intuitive attributions of deep visual models can be avoided under this framework. Then, we identify a mechanism of integrating the attributions over the paths such that they computationally conform to the original insights of game-theory. These insights are eventually combined into a method, which provides intuitive and reliable feature attributions. We also establish the findings empirically by evaluating the method on multiple datasets, models and evaluation metrics. Extensive experiments show a consistent quantitative and qualitative gain in the results over the baselines.

**摘要:** 路径归因框架在游戏理论中具有启发性根源,其归因性质突出于后时模型解释技术中。然而,最近的发展表明,尽管路径归因方法具有归因性质,但其可计算反直觉特征属性。不仅如此,对于深视觉模型,这些方法也可能不符合其归因性质的基础的原始游戏理论直觉。为了解决这些问题,我们对路径归因框架进行了系统性研究,首先指出了在该框架下可避免深视觉模型的反直觉属性的条件。然后,我们确定了在路径上整合属性的机制,使它们可计算地符合游戏理论的原始洞察。这些洞察最终结合为一种方法提供直觉和可靠特征属性。通过对多种数据集、模型和评价指标的评价,对结果进行了实证的建立,广泛的实验表明,在基线上,结果的定量和质量均有一致的提高。

**[Paper URL](https://proceedings.mlr.press/v202/akhtar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/akhtar23a/akhtar23a.pdf)** 

# Convergence of First-Order Methods for Constrained Nonconvex Optimization with Dependent Data
**题目:** 约束非凸优化初级方法与依赖数据的融合

**作者:** Ahmet Alacaoglu, Hanbaek Lyu

**Abstract:** We focus on analyzing the classical stochastic projected gradient methods under a general dependent data sampling scheme for constrained smooth nonconvex optimization. We show the worst-case rate of convergence $\tilde{O}(t^{-1/4})$ and complexity $\tilde{O}(\varepsilon^{-4})$ for achieving an $\varepsilon$-near stationary point in terms of the norm of the gradient of Moreau envelope and gradient mapping. While classical convergence guarantee requires i.i.d. data sampling from the target distribution, we only require a mild mixing condition of the conditional distribution, which holds for a wide class of Markov chain sampling algorithms. This improves the existing complexity for the constrained smooth nonconvex optimization with dependent data from $\tilde{O}(\varepsilon^{-8})$ to $\tilde{O}(\varepsilon^{-4})$ with a significantly simpler analysis. We illustrate the generality of our approach by deriving convergence results with dependent data for stochastic proximal gradient methods, adaptive stochastic gradient algorithm AdaGrad and stochastic gradient algorithm with heavy ball momentum. As an application, we obtain first online nonnegative matrix factorization algorithms for dependent data based on stochastic projected gradient methods with adaptive step sizes and optimal rate of convergence.

**摘要:** 我们着重分析经典随机投影梯度方法在约束平滑非凸优化的一般依赖数据采样方案下。我们显示了最差的收敛率$\tilde{O}(t^{-1/4})$和复杂度$\tilde{O}(\varepsilon^{-4})$,以达到莫罗包和梯度映射的梯度规范的$\varepsilon$-近静点。经典收敛保证要求从目标分布中采样数据,我们只要求条件分布的轻微混合条件,这为马可夫链采样算法的广泛类别保持。通过对随机近距离梯度方法、适应性随机梯度算法AdaGrad和重球动量随机梯度算法的依赖数据导出收敛结果,说明了该方法的一般性。

**[Paper URL](https://proceedings.mlr.press/v202/alacaoglu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/alacaoglu23a/alacaoglu23a.pdf)** 

# Recasting Self-Attention with Holographic Reduced Representations
**题目:** 用全息缩写表示重现自我关注

**作者:** Mohammad Mahmudul Alam, Edward Raff, Stella Biderman, Tim Oates, James Holt

**Abstract:** In recent years, self-attention has become the dominant paradigm for sequence modeling in a variety of domains. However, in domains with very long sequence lengths the $\mathcal{O}(T^2)$ memory and $\mathcal{O}(T^2 H)$ compute costs can make using transformers infeasible. Motivated by problems in malware detection, where sequence lengths of $T \geq 100,000$ are a roadblock to deep learning, we re-cast self-attention using the neuro-symbolic approach of Holographic Reduced Representations (HRR). In doing so we perform the same high-level strategy of the standard self-attention: a set of queries matching against a set of keys, and returning a weighted response of the values for each key. Implemented as a “Hrrformer” we obtain several benefits including $\mathcal{O}(T H \log H)$ time complexity, $\mathcal{O}(T H)$ space complexity, and convergence in $10\times$ fewer epochs. Nevertheless, the Hrrformer achieves near state-of-the-art accuracy on LRA benchmarks and we are able to learn with just a single layer. Combined, these benefits make our Hrrformer the first viable Transformer for such long malware classification sequences and up to $280\times$ faster to train on the Long Range Arena benchmark.

**摘要:** 近年来,自我关注已成为各种领域中的序列建模的主导范式。然而,在具有非常长的序列长度的领域中, $\mathcal{O}(T^2)$内存和 $\mathcal{O}(T^2 H)$计算成本可以使使用变换器是不可能的。尽管如此,hrrformer在LRA基准上达到了近乎最先进的精度,并且我们能够只使用单层学习。这些好处结合起来,使得我们的hrrformer成为第一个可行的变换器,用于此类长期的恶意软件分类序列,并且在Long Range Arena基准上训练速度更快。

**[Paper URL](https://proceedings.mlr.press/v202/alam23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/alam23a/alam23a.pdf)** 

# The Saddle-Point Method in Differential Privacy
**题目:** 微分隐私中的鞍点方法

**作者:** Wael Alghamdi, Juan Felipe Gomez, Shahab Asoodeh, Flavio Calmon, Oliver Kosut, Lalitha Sankar

**Abstract:** We characterize the differential privacy guarantees of privacy mechanisms in the large-composition regime, i.e., when a privacy mechanism is sequentially applied a large number of times to sensitive data. Via exponentially tilting the privacy loss random variable, we derive a new formula for the privacy curve expressing it as a contour integral over an integration path that runs parallel to the imaginary axis with a free real-axis intercept. Then, using the method of steepest descent from mathematical physics, we demonstrate that the choice of saddle-point as the real-axis intercept yields closed-form accurate approximations of the desired contour integral. This procedure—dubbed the saddle-point accountant (SPA)—yields a constant-time accurate approximation of the privacy curve. Theoretically, our results can be viewed as a refinement of both Gaussian Differential Privacy and the moments accountant method found in Rényi Differential Privacy. In practice, we demonstrate through numerical experiments that the SPA provides a precise approximation of privacy guarantees competitive with purely numerical-based methods (such as FFT-based accountants), while enjoying closed-form mathematical expressions.

**摘要:** 通过指数向倾斜隐私损失随机变量,导出了一种新的隐私曲线公式,表示它为曲线积分,在与自由实轴截断的虚轴平行运行的集成路径上。然后,使用数学物理学最陡 descend方法,证明选择作为实轴截断的鞍点给出了理想的曲线积分的闭式精确近似。这一方法—双重鞍点会计(SPA)—给出了定时精确近似隐私曲线。在实践中,我们通过数值实验证明,SPA提供了一个准确的私隐近似保证与纯粹的数值方法(例如基于FFT的会计)竞争,同时享受闭式数学表达式。

**[Paper URL](https://proceedings.mlr.press/v202/alghamdi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/alghamdi23a/alghamdi23a.pdf)** 

# Nonlinear Advantage: Trained Networks Might Not Be As Complex as You Think
**题目:** 非线性优势:训练网络可能不像你想象的那么复杂

**作者:** Christian H.X. Ali Mehmeti-Göpel, Jan Disselhoff

**Abstract:** We perform an empirical study of the behaviour of deep networks when fully linearizing some of its feature channels through a sparsity prior on the overall number of nonlinear units in the network. In experiments on image classification and machine translation tasks, we investigate how much we can simplify the network function towards linearity before performance collapses. First, we observe a significant performance gap when reducing nonlinearity in the network function early on as opposed to late in training, in-line with recent observations on the time-evolution of the data-dependent NTK. Second, we find that after training, we are able to linearize a significant number of nonlinear units while maintaining a high performance, indicating that much of a network’s expressivity remains unused but helps gradient descent in early stages of training. To characterize the depth of the resulting partially linearized network, we introduce a measure called average path length, representing the average number of active nonlinearities encountered along a path in the network graph. Under sparsity pressure, we find that the remaining nonlinear units organize into distinct structures, forming core-networks of near constant effective depth and width, which in turn depend on task difficulty.

**摘要:** 在图像分类和机器翻译任务的实验中,我们研究了在性能崩溃前如何使网络函数趋于线性化。首先,我们观察到在早期降低网络函数非线性性时,在训练中与训练晚期相比,在数据依赖的NTK的时间演变上存在显著的性能差距。其次,我们发现在训练后,我们能够在保持高性能的同时线性化大量非线性单元,这表明大部分网络的表达性仍未被使用,但在训练的早期阶段有助于梯度下降。为了对结果部分线性化网络的深度进行描述,我们引入了一种叫做平均路径长度的测量方法,它代表了网络图中沿路径遇到的主动非线性点的平均数。在稀疏压力下,我们发现剩余的非线性单元组织成不同的结构,形成近连续有效深度和宽度的核心网络,这些网络 omakorda取决于任务难度。

**[Paper URL](https://proceedings.mlr.press/v202/ali-mehmeti-gopel23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ali-mehmeti-gopel23a/ali-mehmeti-gopel23a.pdf)** 

# A Simple Zero-shot Prompt Weighting Technique to Improve Prompt Ensembling in Text-Image Models
**题目:** 一种简便的零射击快速加权技术,改进文本图像模型的快速模拟

**作者:** James Urquhart Allingham, Jie Ren, Michael W Dusenberry, Xiuye Gu, Yin Cui, Dustin Tran, Jeremiah Zhe Liu, Balaji Lakshminarayanan

**Abstract:** Contrastively trained text-image models have the remarkable ability to perform zero-shot classification, that is, classifying previously unseen images into categories that the model has never been explicitly trained to identify. However, these zero-shot classifiers need prompt engineering to achieve high accuracy. Prompt engineering typically requires hand-crafting a set of prompts for individual downstream tasks. In this work, we aim to automate this prompt engineering and improve zero-shot accuracy through prompt ensembling. In particular, we ask “Given a large pool of prompts, can we automatically score the prompts and ensemble those that are most suitable for a particular downstream dataset, without needing access to labeled validation data?". We demonstrate that this is possible. In doing so, we identify several pathologies in a naive prompt scoring method where the score can be easily overconfident due to biases in pre-training and test data, and we propose a novel prompt scoring method that corrects for the biases. Using our proposed scoring method to create a weighted average prompt ensemble, our method overall outperforms equal average ensemble, as well as hand-crafted prompts, on ImageNet, 4 of its variants, and 11 fine-grained classification benchmarks. while being fully automatic, optimization-free, and not requiring access to labeled validation data.

**摘要:** 对照训练的文本图像模型具有 perform zero-shot分类的显著能力,即将以前未见的图像分类为类别,该模型从未被明确训练来识别。然而,这些 zero-shot分类器需要 prompt engineering来达到高精度。Prompt Engineering通常需要手工制作一套forwards来完成个别下游任务。在这个工作中,我们的目标是通过forward ensembling自动化这个forward engineering并提高forwards精度。在此基础上,我们确定了基于预训练和测试数据的偏差而易于过度自信的原始提示评分方法中的一些病理,并提出了一种新的提示评分方法,该方法能纠正偏差。 使用我们提出的评分方法,创建一个权重平均提示组,我们的方法总体表现优于平均组,以及在ImageNet的4个变量和11个细微分类基准上手工制作的提示。

**[Paper URL](https://proceedings.mlr.press/v202/allingham23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/allingham23a/allingham23a.pdf)** 

# On the Privacy-Robustness-Utility Trilemma in Distributed Learning
**题目:** 分布式学习中的私隐-鲁棒性-实用性三难点

**作者:** Youssef Allouah, Rachid Guerraoui, Nirupam Gupta, Rafael Pinot, John Stephan

**Abstract:** The ubiquity of distributed machine learning (ML) in sensitive public domain applications calls for algorithms that protect data privacy, while being robust to faults and adversarial behaviors. Although privacy and robustness have been extensively studied independently in distributed ML, their synthesis remains poorly understood. We present the first tight analysis of the error incurred by any algorithm ensuring robustness against a fraction of adversarial machines, as well as differential privacy (DP) for honest machines’ data against any other curious entity. Our analysis exhibits a fundamental trade-off between privacy, robustness, and utility. To prove our lower bound, we consider the case of mean estimation, subject to distributed DP and robustness constraints, and devise reductions to centralized estimation of one-way marginals. We prove our matching upper bound by presenting a new distributed ML algorithm using a high-dimensional robust aggregation rule. The latter amortizes the dependence on the dimension in the error (caused by adversarial workers and DP), while being agnostic to the statistical properties of the data.

**摘要:** 在敏感的公共领域应用中,分布式机器学习(ML)的 ubiquity要求算法保护数据隐私,同时对故障和敌对行为具有鲁棒性。虽然分布式ML中隐私和鲁棒性得到了广泛的独立研究,但它们的合成仍未得到充分理解。我们提出了任何算法所造成的错误的第一个紧迫分析,以确保对敌对机器的鲁棒性,以及对诚实机器的数据的微分隐私(DP)。我们的分析显示了隐私、鲁棒性和实用性之间的基本交易。后者在对数据的统计特性持怀疑态度时,将错误(由敌对工人和DP引起的)的维度依赖性减去。

**[Paper URL](https://proceedings.mlr.press/v202/allouah23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/allouah23a/allouah23a.pdf)** 

# Differentially Private Distributed Bayesian Linear Regression with MCMC
**题目:** 微分分布式贝叶斯线性回归与MCMC

**作者:** Baris Alparslan, Sinan Yıldırım, Ilker Birbil

**Abstract:** We propose a novel Bayesian inference framework for distributed differentially private linear regression. We consider a distributed setting where multiple parties hold parts of the data and share certain summary statistics of their portions in privacy-preserving noise. We develop a novel generative statistical model for privately shared statistics, which exploits a useful distributional relation between the summary statistics of linear regression. We propose Bayesian estimation of the regression coefficients, mainly using Markov chain Monte Carlo algorithms, while we also provide a fast version that performs approximate Bayesian estimation in one iteration. The proposed methods have computational advantages over their competitors. We provide numerical results on both real and simulated data, which demonstrate that the proposed algorithms provide well-rounded estimation and prediction.

**摘要:** 提出了一种分布式微分私有线性回归的新贝叶斯推导框架。我们考虑一个分布式设置,其中多个部分持有数据的部分,并共享其部分在隐私保护噪声中的一些摘要统计。我们开发了一种用于私有共享统计的新生成统计模型,它利用了线性回归的摘要统计之间的有用的分布关系。我们提出了贝叶斯估计回归系数的贝叶斯估计,主要使用马可夫链蒙特卡罗算法,同时提供一种快速的版本,在一次迭代中执行近似贝叶斯估计。

**[Paper URL](https://proceedings.mlr.press/v202/alparslan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/alparslan23a/alparslan23a.pdf)** 

# Robust and Scalable Bayesian Online Changepoint Detection
**题目:** 鲁棒和可尺度的贝叶斯在线变化点检测

**作者:** Matias Altamirano, Francois-Xavier Briol, Jeremias Knoblauch

**Abstract:** This paper proposes an online, provably robust, and scalable Bayesian approach for changepoint detection. The resulting algorithm has key advantages over previous work: it provides provable robustness by leveraging the generalised Bayesian perspective, and also addresses the scalability issues of previous attempts. Specifically, the proposed generalised Bayesian formalism leads to conjugate posteriors whose parameters are available in closed form by leveraging diffusion score matching. The resulting algorithm is exact, can be updated through simple algebra, and is more than 10 times faster than its closest competitor.

**摘要:** 本文提出了一种基于网络的、可证明的、可扩展的贝叶斯方法来检测变化点。该算法具有比以往的工作更重要的优点:通过利用广义贝叶斯观点提供可证明的鲁棒性,并解决了以前的尝试的可扩展性问题。

**[Paper URL](https://proceedings.mlr.press/v202/altamirano23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/altamirano23a/altamirano23a.pdf)** 

# Neural Wasserstein Gradient Flows for Discrepancies with Riesz Kernels
**题目:** 神经维多斯泰因梯度流对 Riesz核子的差异

**作者:** Fabian Altekrüger, Johannes Hertrich, Gabriele Steidl

**Abstract:** Wasserstein gradient flows of maximum mean discrepancy (MMD) functionals with non-smooth Riesz kernels show a rich structure as singular measures can become absolutely continuous ones and conversely. In this paper we contribute to the understanding of such flows. We propose to approximate the backward scheme of Jordan, Kinderlehrer and Otto for computing such Wasserstein gradient flows as well as a forward scheme for so-called Wasserstein steepest descent flows by neural networks (NNs). Since we cannot restrict ourselves to absolutely continuous measures, we have to deal with transport plans and velocity plans instead of usual transport maps and velocity fields. Indeed, we approximate the disintegration of both plans by generative NNs which are learned with respect to appropriate loss functions. In order to evaluate the quality of both neural schemes, we benchmark them on the interaction energy. Here we provide analytic formulas for Wasserstein schemes starting at a Dirac measure and show their convergence as the time step size tends to zero. Finally, we illustrate our neural MMD flows by numerical examples.

**摘要:** 与非光滑 Riesz核的最大平均差异函数(MMD)水文梯度流具有丰富的结构,因为单一的措施可以成为完全连续的,反之亦然。本文对这些流的理解作出贡献。我们建议约旦、Kernlehrer和Otto的后向方案来计算这些水文梯度流,以及神经网络(NNs)所谓的水文梯度最陡降流的向前方案。由于我们不能局限于完全连续的措施,我们必须处理运输计划和速度计划,而不是通常的运输图和速度场。事实上,我们通过生成NNs来估计有关损失函数的两项计划的解散。在此,我们为从Dirac测量开始的Waterstein方案提供分析公式,并显示它们在时间步骤大小趋于零时的收敛性。最后,我们通过数值实例说明了我们的神经MMD流动。

**[Paper URL](https://proceedings.mlr.press/v202/altekruger23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/altekruger23a/altekruger23a.pdf)** 

# Distributed Contextual Linear Bandits with Minimax Optimal Communication Cost
**题目:** 分布式上下文线性带子,最小最优通信成本

**作者:** Sanae Amani, Tor Lattimore, András György, Lin Yang

**Abstract:** We study distributed contextual linear bandits with stochastic contexts, where $N$ agents/learners act cooperatively to solve a linear bandit-optimization problem with $d$-dimensional features over the course of $T$ rounds. For this problem, we derive the first ever information-theoretic lower bound $\Omega(dN)$ on the communication cost of any algorithm that performs optimally in a regret minimization setup. We then propose a distributed batch elimination version of the LinUCB algorithm, DisBE-LUCB, where the agents share information among each other through a central server. We prove that the communication cost of DisBE-LUCB, matches our lower bound up to logarithmic factors. In particular, for scenarios with known context distribution, the communication cost of DisBE-LUCB is only $\tilde{\mathcal{O}}(dN)$ and its regret is $\tilde{\mathcal{O}}(\sqrt{dNT})$, which is of the same order as that incurred by an optimal single-agent algorithm for $NT$ rounds. We also provide similar bounds for practical settings where the context distribution can only be estimated. Therefore, our proposed algorithm is nearly minimax optimal in terms of both regret and communication cost. Finally, we propose DecBE-LUCB, a fully decentralized version of DisBE-LUCB, which operates without a central server, where agents share information with their immediate neighbors through a carefully designed consensus procedure.

**摘要:** 我们研究了分布式上下文线性带子与随机上下文,其中$N$代理人/学习者在$T$循环过程中合作解决线性带子优化问题。为此问题,我们导出了第一个信息理论下界$\Omega(dN)$在任何算法的通信成本上,该算法在遗憾最小化设置中执行最优。然后,我们提出了一个分布式批量消除版本的LinuCB算法,DisBE-LUCB,其中代理人通过中央服务器共享信息。我们证明DisBE-LUCB的通信成本符合我们的下界到逻辑因子。因此,我们提出的算法在遗憾和通信成本方面几乎是最优的最小限度。最后,我们提出了DecBE-LUCB,DisBE-LUCB的完全分散式版本,它没有中央服务器,代理人通过精心设计的协商程序与其近邻共享信息。

**[Paper URL](https://proceedings.mlr.press/v202/amani23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/amani23a/amani23a.pdf)** 

# A Kernelized Stein Discrepancy for Biological Sequences
**题目:** 生物序列的核化石异性

**作者:** Alan Nawzad Amin, Eli N Weinstein, Debora Susan Marks

**Abstract:** Generative models of biological sequences are a powerful tool for learning from complex sequence data, predicting the effects of mutations, and designing novel biomolecules with desired properties. To evaluate generative models it is important to accurately measure differences between high-dimensional distributions. In this paper we propose the “KSD-B”, a novel divergence measure for distributions over biological sequences that is based on the kernelized Stein discrepancy (KSD). The KSD-B can be evaluated even when the normalizing constant of the model is unknown; it allows for variable length sequences and can take into account biological notions of sequence distance. Unlike previous KSDs over discrete spaces the KSD-B (a) is theoretically guaranteed to detect convergence and non-convergence of distributions over sequence space and (b) can be efficiently estimated in practice. We demonstrate the advantages of the KSD-B on problems with synthetic and real data, and apply it to measure the fit of state-of-the-art machine learning models. Overall, the KSD-B enables rigorous evaluation of generative biological sequence models, allowing the accuracy of models, sampling procedures, and library designs to be checked reliably.

**摘要:** 生物序列的生成模型是学习复杂序列数据、预测突变的影响和设计具有理想的特性的新生物分子的有力工具。为了评价生成模型,重要的是准确测量高维分布之间的差异。本文提出了一种基于核化施泰因差异(KSD)的生物序列分布的新分离度量“KSD-B”。KSD-B甚至在模型的正常化常数未知的情况下也能进行评估,允许变长序列,并能考虑到序列距离的生物概念。我们展示了KSD-B在合成数据和实数据问题上的优势,并应用它来测量最先进的机器学习模型的适应性。总的来说,KSD-B能够对生成生物序列模型进行严格的评价,使模型、采样程序和图书馆设计的准确性得以可靠地检查。

**[Paper URL](https://proceedings.mlr.press/v202/amin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/amin23a/amin23a.pdf)** 

# The Optimal Approximation Factors in Misspecified Off-Policy Value Function Estimation
**题目:** 误区非政策价值函数估计中最佳近似因素

**作者:** Philip Amortila, Nan Jiang, Csaba Szepesvari

**Abstract:** Theoretical guarantees in reinforcement learning (RL) are known to suffer multiplicative blow-up factors with respect to the misspecification error of function approximation. Yet, the nature of such approximation factors—especially their optimal form in a given learning problem—is poorly understood. In this paper we study this question in linear off-policy value function estimation, where many open questions remain. We study the approximation factor in a broad spectrum of settings, such as presence vs. absence of state aliasing and full vs. partial coverage of the state space. Our core results include instance-dependent upper bounds on the approximation factors with respect to both the weighted $L_2$-norm (where the weighting is the offline state distribution) and the $L_\infty$ norm. We show that these approximation factors are optimal (in an instance-dependent sense) for a number of these settings. In other cases, we show that the instance-dependent parameters which appear in the upper bounds are necessary, and that the finiteness of either alone cannot guarantee a finite approximation factor even in the limit of infinite data.

**摘要:** 在强化学习(RL)中,理论保证是受函数近似误区误区影响的乘法吹爆因素。然而,这种近似因素的性质--尤其是在给定的学习问题中它们的最佳形式--被理解得很差。本论文研究了这一问题在线性非政策值函数估计中,其中许多开放问题仍然存在。我们研究了近似因子在广泛的设置中,如存在与不存在状态异名化和状态空间的完整与部分覆盖等。我们的核心结果包括对近似因子在权重的$L_2$-规范(权重是离线状态分布)和$L_\infty$规范的上下界限。在其他情况下,我们证明在上边上出现的实例依赖参数是必要的,而且单一的有限性不能保证有限的近似因子,即使在无限数据的边界。

**[Paper URL](https://proceedings.mlr.press/v202/amortila23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/amortila23a/amortila23a.pdf)** 

# Meta Optimal Transport
**题目:** 元最佳运输

**作者:** Brandon Amos, Giulia Luise, Samuel Cohen, Ievgen Redko

**Abstract:** We study the use of amortized optimization to predict optimal transport (OT) maps from the input measures, which we call Meta OT. This helps repeatedly solve similar OT problems between different measures by leveraging the knowledge and information present from past problems to rapidly predict and solve new problems. Otherwise, standard methods ignore the knowledge of the past solutions and suboptimally re-solve each problem from scratch. We instantiate Meta OT models in discrete and continuous settings between grayscale images, spherical data, classification labels, and color palettes and use them to improve the computational time of standard OT solvers. Our source code is available at http://github.com/facebookresearch/meta-ot

**摘要:** 我们研究了从输入测量中预测最佳运输(OT)地图的 amortised optimization,我们称之为Meta OT。这通过利用从过去的问题中获取的知识和信息来快速预测和解决新的问题,从而在不同测量之间解决类似的OT问题。否则,标准方法忽略过去的解决方案的知识,并从零点重新解决每个问题。我们将Meta OT模型在灰色图像、球形数据、分类标签和颜色 palettes之间进行离散和连续设置,并利用它们来改善标准 OT 求解器的计算时间。我们的源代码可于 http://github.com/facebookresearch/meta-ot

**[Paper URL](https://proceedings.mlr.press/v202/amos23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/amos23a/amos23a.pdf)** 

# Near-Optimal $Φ$-Regret Learning in Extensive-Form Games
**题目:**  near-optimal $Φ$-在广泛形式游戏中学习

**作者:** Ioannis Anagnostides, Gabriele Farina, Tuomas Sandholm

**Abstract:** In this paper, we establish efficient and uncoupled learning dynamics so that, when employed by all players in multiplayer perfect-recall imperfect-information extensive-form games, the trigger regret of each player grows as $O(\log T)$ after $T$ repetitions of play. This improves exponentially over the prior best known trigger-regret bound of $O(T^{1/4})$, and settles a recent open question by Bai et al. (2022). As an immediate consequence, we guarantee convergence to the set of extensive-form correlated equilibria and coarse correlated equilibria at a near-optimal rate of $\frac{\log T}{T}$. Building on prior work, at the heart of our construction lies a more general result regarding fixed points deriving from rational functions with polynomial degree, a property that we establish for the fixed points of (coarse) trigger deviation functions. Moreover, our construction leverages a refined regret circuit for the convex hull, which—unlike prior guarantees—preserves the RVU property introduced by Syrgkanis et al. (NIPS, 2015); this observation has an independent interest in establishing near-optimal regret under learning dynamics based on a CFR-type decomposition of the regret.

**摘要:** 本文建立了有效的无耦合学习动力学,使得在多人游戏中使用完备回忆不完备信息的广泛形式游戏时,每个玩家的触发遗憾在$T$的重复后增加为$O(\log T)$。这在$O(T^{1/4})$的最早的触发-遗憾界限上指数改善,并解决了拜等人(2022)最近提出的一个公开问题。此外,我们的结构利用凸轮船体的精细 regret 电路,它与以前的保证不同,保留了 Syrgkanis 等人引入的 RVU 特性(NIPS, 2015);这一观察具有独立的兴趣在基于 CFR 类型的 regret 的 learning dynamics 下建立 near-optimal regret 。

**[Paper URL](https://proceedings.mlr.press/v202/anagnostides23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/anagnostides23a/anagnostides23a.pdf)** 

# A Modern Look at the Relationship between Sharpness and Generalization
**题目:** 对 Sharpness 和 Generalization 之间关系的现代视角

**作者:** Maksym Andriushchenko, Francesco Croce, Maximilian Müller, Matthias Hein, Nicolas Flammarion

**Abstract:** Sharpness of minima is a promising quantity that can correlate with generalization in deep networks and, when optimized during training, can improve generalization. However, standard sharpness is not invariant under reparametrizations of neural networks, and, to fix this, reparametrization-invariant sharpness definitions have been proposed, most prominently adaptive sharpness (Kwon et al., 2021). But does it really capture generalization in modern practical settings? We comprehensively explore this question in a detailed study of various definitions of adaptive sharpness in settings ranging from training from scratch on ImageNet and CIFAR-10 to fine-tuning CLIP on ImageNet and BERT on MNLI. We focus mostly on transformers for which little is known in terms of sharpness despite their widespread usage. Overall, we observe that sharpness does not correlate well with generalization but rather with some training parameters like the learning rate that can be positively or negatively correlated with generalization depending on the setup. Interestingly, in multiple cases, we observe a consistent negative correlation of sharpness with OOD generalization implying that sharper minima can generalize better. Finally, we illustrate on a simple model that the right sharpness measure is highly data-dependent, and that we do not understand well this aspect for realistic data distributions.

**摘要:** 最小值的敏度是一个有望的数量,可以与深度网络的广义化相关,并且当在训练过程中优化时,可以改善广义化。然而,标准敏度在神经网络的校正中并不不变,为了解决这一点,已经提出了校正不变敏度定义,最突出的是适应性敏度(Kwon et al., 2021)。总体而言,我们观察到,敏度与一般化并不很好相关,而是与某些训练参数,如学习率,在设置上可以与一般化有积极或消极相关。有趣的是,在多个情况下,我们观察到敏度与OOD一般化有一致的负相关,这意味着更敏度的最小值可以更好地一般化。

**[Paper URL](https://proceedings.mlr.press/v202/andriushchenko23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/andriushchenko23a/andriushchenko23a.pdf)** 

# SGD with Large Step Sizes Learns Sparse Features
**题目:** 大步尺寸的SGD学习备用功能

**作者:** Maksym Andriushchenko, Aditya Vardhan Varre, Loucas Pillaud-Vivien, Nicolas Flammarion

**Abstract:** We showcase important features of the dynamics of the Stochastic Gradient Descent (SGD) in the training of neural networks. We present empirical observations that commonly used large step sizes (i) may lead the iterates to jump from one side of a valley to the other causing loss stabilization, and (ii) this stabilization induces a hidden stochastic dynamics that biases it implicitly toward simple predictors. Furthermore, we show empirically that the longer large step sizes keep SGD high in the loss landscape valleys, the better the implicit regularization can operate and find sparse representations. Notably, no explicit regularization is used: the regularization effect comes solely from the SGD dynamics influenced by the large step sizes schedule. Therefore, these observations unveil how, through the step size schedules, both gradient and noise drive together the SGD dynamics through the loss landscape of neural networks. We justify these findings theoretically through the study of simple neural network models as well as qualitative arguments inspired from stochastic processes. This analysis allows us to shed new light on some common practices and observed phenomena when training deep networks.

**摘要:** 在神经网络训练中,我们展示了随机梯度降落(SGD)动力学的重要特征。我们提出了常用的大阶梯大小(i)可能导致迭代从谷端跳到谷端造成损失稳定化,而(ii)这种稳定化诱导隐藏的随机动力学,使它隐含地偏向简单的预测器。此外,我们通过实验表明,大阶梯大小越长,SGD在损失景观谷端保持高,隐含的调节作用越好,而且表现也越稀疏。通过对简单神经网络模型的研究和随机过程的定性论证,我们从理论上证明了这些发现。通过这种分析,在训练深层网络时,我们能够揭示一些常见的实践和观察到的现象。

**[Paper URL](https://proceedings.mlr.press/v202/andriushchenko23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/andriushchenko23b/andriushchenko23b.pdf)** 

# Neural Continuous-Discrete State Space Models for Irregularly-Sampled Time Series
**题目:** 不规则样本时间序列神经连续散乱状态空间模型

**作者:** Abdul Fatir Ansari, Alvin Heng, Andre Lim, Harold Soh

**Abstract:** Learning accurate predictive models of real-world dynamic phenomena (e.g., climate, biological) remains a challenging task. One key issue is that the data generated by both natural and artificial processes often comprise time series that are irregularly sampled and/or contain missing observations. In this work, we propose the Neural Continuous-Discrete State Space Model (NCDSSM) for continuous-time modeling of time series through discrete-time observations. NCDSSM employs auxiliary variables to disentangle recognition from dynamics, thus requiring amortized inference only for the auxiliary variables. Leveraging techniques from continuous-discrete filtering theory, we demonstrate how to perform accurate Bayesian inference for the dynamic states. We propose three flexible parameterizations of the latent dynamics and an efficient training objective that marginalizes the dynamic states during inference. Empirical results on multiple benchmark datasets across various domains show improved imputation and forecasting performance of NCDSSM over existing models.

**摘要:** 学习真实动态现象(例如气候、生物学)的准确预测模型仍然是一个艰巨的任务。一个关键问题是,由自然过程和人工过程生成的数据往往包含不规则样本和/或包含遗失的观测时间序列。在这个工作中,我们提出了神经连续离散状态空间模型(NCDSSM)用于通过离散时间观测时间序列的连续时间建模。NCDSSM采用辅助变量来从动力学中分角识别,因此只需要对辅助变量进行 amortized inference。对不同领域多个基准数据集的实证结果表明,NCDSSM比现有模型的归纳和预测性能有所提高。

**[Paper URL](https://proceedings.mlr.press/v202/ansari23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ansari23a/ansari23a.pdf)** 

# Paging with Succinct Predictions
**题目:** 用简洁的预言打字

**作者:** Antonios Antoniadis, Joan Boyar, Marek Elias, Lene Monrad Favrholdt, Ruben Hoeksma, Kim S. Larsen, Adam Polak, Bertrand Simon

**Abstract:** Paging is a prototypical problem in the area of online algorithms. It has also played a central role in the development of learning-augmented algorithms. Previous work on learning-augmented paging has investigated predictions on (i) when the current page will be requested again (reoccurrence predictions), (ii) the current state of the cache in an optimal algorithm (state predictions), (iii) all requests until the current page gets requested again, and (iv) the relative order in which pages are requested. We study learning-augmented paging from the new perspective of requiring the least possible amount of predicted information. More specifically, the predictions obtained alongside each page request are limited to one bit only. We develop algorithms satisfy all three desirable properties of learning-augmented algorithms – that is, they are consistent, robust and smooth – despite being limited to a one-bit prediction per request. We also present lower bounds establishing that our algorithms are essentially best possible.

**摘要:** 教程是在线算法领域的一个原型问题。它在学习增强算法的开发中也发挥了中心作用。在学习增强的教程上以前的工作已经对(i)当当前页面再次被请求时的预测进行了研究(reoccurrence predictions),(ii)最佳算法中的缓存状态(state predictions),(iii)所有请求直到当前页面再次被请求,以及(iv)请求页面的相对顺序。我们还给出了较低的界限,证明我们的算法基本上是最好的。

**[Paper URL](https://proceedings.mlr.press/v202/antoniadis23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/antoniadis23a/antoniadis23a.pdf)** 

# Mixing Predictions for Online Metric Algorithms
**题目:** 混合在线量子算法的预测

**作者:** Antonios Antoniadis, Christian Coester, Marek Elias, Adam Polak, Bertrand Simon

**Abstract:** A major technique in learning-augmented online algorithms is combining multiple algorithms or predictors. Since the performance of each predictor may vary over time, it is desirable to use not the single best predictor as a benchmark, but rather a dynamic combination which follows different predictors at different times. We design algorithms that combine predictions and are competitive against such dynamic combinations for a wide class of online problems, namely, metrical task systems. Against the best (in hindsight) unconstrained combination of $\ell$ predictors, we obtain a competitive ratio of $O(\ell^2)$, and show that this is best possible. However, for a benchmark with slightly constrained number of switches between different predictors, we can get a $(1+\epsilon)$-competitive algorithm. Moreover, our algorithms can be adapted to access predictors in a bandit-like fashion, querying only one predictor at a time. An unexpected implication of one of our lower bounds is a new structural insight about covering formulations for the $k$-server problem.

**摘要:** 在学习增强的在线算法中,一个主要技术是结合多个算法或预测器。因为每个预测器的性能可能随时间变化,最好不使用单个最佳预测器作为基准,而是采用动态组合,以不同时间跟踪不同的预测器。我们设计了结合预测的算法,并且对网络问题的广泛类别,即数值任务系统,具有竞争性。一个我们较低的界限的意外影响是关于覆盖$k$-server问题公式的新结构洞察。

**[Paper URL](https://proceedings.mlr.press/v202/antoniadis23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/antoniadis23b/antoniadis23b.pdf)** 

# Exponential Smoothing for Off-Policy Learning
**题目:** 非政治学习的指数缓和

**作者:** Imad Aouali, Victor-Emmanuel Brunel, David Rohde, Anna Korba

**Abstract:** Off-policy learning (OPL) aims at finding improved policies from logged bandit data, often by minimizing the inverse propensity scoring (IPS) estimator of the risk. In this work, we investigate a smooth regularization for IPS, for which we derive a two-sided PAC-Bayes generalization bound. The bound is tractable, scalable, interpretable and provides learning certificates. In particular, it is also valid for standard IPS without making the assumption that the importance weights are bounded. We demonstrate the relevance of our approach and its favorable performance through a set of learning tasks. Since our bound holds for standard IPS, we are able to provide insight into when regularizing IPS is useful. Namely, we identify cases where regularization might not be needed. This goes against the belief that, in practice, clipped IPS often enjoys favorable performance than standard IPS in OPL.

**摘要:** 非策略学习(OPL)旨在从记录的带头数据找到改进的政策,通常通过最小化风险的逆倾向评分(IPS)估算器。在这个工作中,我们研究了IPS的平滑规范化,我们得出两边PAC-Bayes一般化边界。边界是可操作的、可扩展的、可解释的,并提供学习证书。特别是,它也适用于标准IPS,而不假设重要权重是界限的。我们通过一系列学习任务证明了我们的方法及其有利的性能。因为我们的边界为标准IPS持有,我们能够提供理解IPS的合理化是有益的。

**[Paper URL](https://proceedings.mlr.press/v202/aouali23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/aouali23a/aouali23a.pdf)** 

# Polynomial Time and Private Learning of Unbounded Gaussian Mixture Models
**题目:** 无界高斯混合模型的多项式时间与私人学习

**作者:** Jamil Arbas, Hassan Ashtiani, Christopher Liaw

**Abstract:** We study the problem of privately estimating the parameters of $d$-dimensional Gaussian Mixture Models (GMMs) with $k$ components. For this, we develop a technique to reduce the problem to its non-private counterpart. This allows us to privatize existing non-private algorithms in a blackbox manner, while incurring only a small overhead in the sample complexity and running time. As the main application of our framework, we develop an $(\varepsilon, \delta)$-differentially private algorithm to learn GMMs using the non-private algorithm of Moitra and Valiant (2010) as a blackbox. Consequently, this gives the first sample complexity upper bound and first polynomial time algorithm for privately learning GMMs without any boundedness assumptions on the parameters. As part of our analysis, we prove a tight (up to a constant factor) lower bound on the total variation distance of high-dimensional Gaussians which can be of independent interest.

**摘要:** 我们研究了与$k$组件的$d$-维高斯混合模型(GMMs)参数的私下估计问题。为此,我们开发了一个减少问题到非私下对比的技术。这允许我们以黑箱的方式私下现有非私下算法,同时在样品复杂度和运行时间中只涉及少量费用。作为我们框架的主要应用,我们开发了$(\varepsilon, \delta)$-微分私下算法来学习GMMs,使用Moitra和Valiant(2010)的非私下算法作为黑箱。

**[Paper URL](https://proceedings.mlr.press/v202/arbas23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/arbas23a/arbas23a.pdf)** 

# Principled Acceleration of Iterative Numerical Methods Using Machine Learning
**题目:** 利用机器学习的迭代数值方法的原理加速

**作者:** Sohei Arisaka, Qianxiao Li

**Abstract:** Iterative methods are ubiquitous in large-scale scientific computing applications, and a number of approaches based on meta-learning have been recently proposed to accelerate them. However, a systematic study of these approaches and how they differ from meta-learning is lacking. In this paper, we propose a framework to analyze such learning-based acceleration approaches, where one can immediately identify a departure from classical meta-learning. We theoretically show that this departure may lead to arbitrary deterioration of model performance, and at the same time, we identify a methodology to ameliorate it by modifying the loss objective, leading to a novel training method for learning-based acceleration of iterative algorithms. We demonstrate the significant advantage and versatility of the proposed approach through various numerical applications.

**摘要:** 迭代方法在大规模的科学计算应用中普遍存在,并最近提出了基于元学习的方法来加速它们。然而,缺乏对这些方法的系统研究,以及它们与元学习有何不同。本文提出了一种分析基于学习的加速方法的框架,即可以立即识别从经典元学习中逸脱。我们从理论上证明,这种逸脱可能导致模型性能的任意恶化,同时,我们确定了通过修改损失目标来改善这种方法的方法,从而为迭代算法的基于学习的加速提出了一种新的训练方法。

**[Paper URL](https://proceedings.mlr.press/v202/arisaka23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/arisaka23a/arisaka23a.pdf)** 

# Faster Rates of Convergence to Stationary Points in Differentially Private Optimization
**题目:** 差价私营优化中的定点收敛速度提高

**作者:** Raman Arora, Raef Bassily, Tomás González, Cristóbal A Guzmán, Michael Menart, Enayat Ullah

**Abstract:** We study the problem of approximating stationary points of Lipschitz and smooth functions under $(\varepsilon,\delta)$-differential privacy (DP) in both the finite-sum and stochastic settings. A point $\widehat{w}$ is called an $\alpha$-stationary point of a function $F:\mathbb{R}^d\rightarrow\mathbb{R}$ if $\|\nabla F(\widehat{w})\|\leq \alpha$. We give a new construction that improves over the existing rates in the stochastic optimization setting, where the goal is to find approximate stationary points of the population risk given $n$ samples. Our construction finds a $\tilde{O}\big(\frac{1}{n^{1/3}} + \big[\frac{\sqrt{d}}{n\varepsilon}\big]^{1/2}\big)$-stationary point of the population risk in time linear in $n$. We also provide an efficient algorithm that finds an $\tilde{O}\big(\big[\frac{\sqrt{d}}{n\varepsilon}\big]^{2/3}\big)$-stationary point in the finite-sum setting. This improves on the previous best rate of $\tilde{O}\big(\big[\frac{\sqrt{d}}{n\varepsilon}\big]^{1/2}\big)$. Furthermore, under the additional assumption of convexity, we completely characterize the sample complexity of finding stationary points of the population risk (up to polylog factors) and show that the optimal rate on population stationarity is $\tilde \Theta\big(\frac{1}{\sqrt{n}}+\frac{\sqrt{d}}{n\varepsilon}\big)$. Finally, we show that our methods can be used to provide dimension-independent rates of $O\big(\frac{1}{\sqrt{n}}+\min\big(\big[\frac{\sqrt{rank}}{n\varepsilon}\big]^{2/3},\frac{1}{(n\varepsilon)^{2/5}}\big)\big)$ on population stationarity for Generalized Linear Models (GLM), where $rank$ is the rank of the design matrix, which improves upon the previous best known rate.

**摘要:** 我们研究了在有限总和随机设置中$(\varepsilon,\delta)$-微分隐私(DP)下 approximating stationary points of Lipschitz and smooth functions problem. A point $\widehat{w}$ is called a $\alpha$-stationary point of a function $F:\mathbb{R}^d\rightarrow\mathbb{R}$ if $\|\nabla F(\widehat{w})\|\leq \alpha$. 我们给出了一个改进在随机优化设置中的现有率的新构造,目标是找到给定$n$样本的人口风险的 approximate stationary points. 我们的构造找到$\tilde{O}\big(\frac{1}{n^{1/3}} + \big[\frac{\sqrt{d进一步,在增加凸性假设下,我们完全描述了找到人口风险的静点的样品复杂度(至多维因素)并表明,对一般线性模型(GLM)的人口静态率的最优率是$\tilde \Theta\big(\frac{1}{\sqrt{n}}+\frac{\sqrt{d}}{n\varepsilon}\big)$。最后,我们表明,我们的方法可以用于提供$O\big(\frac{1}{\sqrt{n}}+\min\big(\big[\frac{\sqrt{rank}}{n\varepsilon}\big]^{2/3},\frac{1}{(n\varepsilon)^{2/5}}\big)$的维度独立率。

**[Paper URL](https://proceedings.mlr.press/v202/arora23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/arora23a/arora23a.pdf)** 

# Prototype-Sample Relation Distillation: Towards Replay-Free Continual Learning
**题目:** 原型-样品关系蒸馏:面向无重复的持续学习

**作者:** Nader Asadi, Mohammadreza Davari, Sudhir Mudur, Rahaf Aljundi, Eugene Belilovsky

**Abstract:** In Continual learning (CL) balancing effective adaptation while combating catastrophic forgetting is a central challenge. Many of the recent best-performing methods utilize various forms of prior task data, e.g. a replay buffer, to tackle the catastrophic forgetting problem. Having access to previous task data can be restrictive in many real-world scenarios, for example when task data is sensitive or proprietary. To overcome the necessity of using previous tasks’ data, in this work, we start with strong representation learning methods that have been shown to be less prone to forgetting. We propose a holistic approach to jointly learn the representation and class prototypes while maintaining the relevance of old class prototypes and their embedded similarities. Specifically, samples are mapped to an embedding space where the representations are learned using a supervised contrastive loss. Class prototypes are evolved continually in the same latent space, enabling learning and prediction at any point. To continually adapt the prototypes without keeping any prior task data, we propose a novel distillation loss that constrains class prototypes to maintain relative similarities as compared to new task data. This method yields state-of-the-art performance in the task-incremental setting, outperforming methods relying on large amounts of data, and provides strong performance in the class-incremental setting without using any stored data points.

**摘要:** 在持续学习中(CL)平衡有效的适应 while combating catastrophic forgetting is a central challenge. 许多最近最有效的方法利用各种形式的先前任务数据,例如重演缓冲器,来解决灾难性遗忘问题。访问以前任务数据可以在许多现实场景中具有限制性,例如当任务数据敏感或专有时。为了克服使用以前任务数据的必要性,在这项工作中,我们开始使用强的表征学习方法,这些方法被证明不太容易遗忘。我们提议一个整体的方法,共同学习表征和类样本,同时保持旧类样本及其嵌入相似性的相关性。类样本在同一缓存空间中不断演化,在任何时候都能进行学习和预测。为了使样本在没有保留任何任务数据的情况下不断适应,我们提出了一种新的蒸馏损耗,限制类样本在与新的任务数据相比保持相对相似性。该方法在任务增量设置中具有最先进的性能,超越了依赖大量数据的方法,并且在没有使用任何存储数据点的情况下在任务增量设置中提供强大的性能。

**[Paper URL](https://proceedings.mlr.press/v202/asadi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/asadi23a/asadi23a.pdf)** 

# Near-Optimal Algorithms for Private Online Optimization in the Realizable Regime
**题目:** 在可实现模式下实现私人在线优化的近优化算法

**作者:** Hilal Asi, Vitaly Feldman, Tomer Koren, Kunal Talwar

**Abstract:** We consider online learning problems in the realizable setting, where there is a zero-loss solution, and propose new Differentially Private (DP) algorithms that obtain near-optimal regret bounds. For the problem of online prediction from experts, we design new algorithms that obtain near-optimal regret $O \big( \varepsilon^{-1} \mathsf{poly}(\log{d}) \big)$ where $d$ is the number of experts. This significantly improves over the best existing regret bounds for the DP non-realizable setting which are $O \big( \varepsilon^{-1} \min\big\{d, \sqrt{T\log d}\big\} \big)$. We also develop an adaptive algorithm for the small-loss setting with regret $(L^\star+ \varepsilon^{-1}) \cdot O(\mathsf{poly}(\log{d}))$ where $L^\star$ is the total loss of the best expert. Additionally, we consider DP online convex optimization in the realizable setting and propose an algorithm with near-optimal regret $O \big(\varepsilon^{-1} \mathsf{poly}(d) \big)$, as well as an algorithm for the smooth case with regret $O \big( (\sqrt{Td}/\varepsilon)^{2/3} \big)$, both significantly improving over existing bounds in the non-realizable regime.

**摘要:** 我们考虑在可实现环境中在线学习问题,其中存在零损失解决方案,并提出新的差价私有(DP)算法,以获得 near-optimal regret bounds。 对于专家在线预测问题,我们设计了新的算法,以获得 near-optimal regret $O \big( \varepsilon^{-1} \mathsf{poly}(\log{d}) \big)$ 其中 $d$ 是专家的数目。这大大改善了DP非可实现环境中的最好 existing regret bounds,即 $O \big( \varepsilon^{-1} \min\big\{d, \sqrt{T\log d}\big\} \big)$。此外,我们考虑了DP在线凸优化在可实现环境中,并提出了 near-optimal regret $O \big(\varepsilon^{-1} \mathsf{poly}(d) \big)$的算法,以及 regret $O \big( (\sqrt{Td}/\varepsilon)^{2/3} \big)$的平滑案例的算法,两者都大大改善了非可实现环境中的现有边界。

**[Paper URL](https://proceedings.mlr.press/v202/asi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/asi23a/asi23a.pdf)** 

# From Robustness to Privacy and Back
**题目:** 从鲁棒性到隐私和回报

**作者:** Hilal Asi, Jonathan Ullman, Lydia Zakynthinou

**Abstract:** We study the relationship between two desiderata of algorithms in statistical inference and machine learning—differential privacy and robustness to adversarial data corruptions. Their conceptual similarity was first observed by Dwork and Lei (STOC 2009), who observed that private algorithms satisfy robustness, and gave a general method for converting robust algorithms to private ones. However, all general methods for transforming robust algorithms into private ones lead to suboptimal error rates. Our work gives the first black-box transformation that converts any adversarially robust algorithm into one that satisfies pure differential privacy. Moreover, we show that for any low-dimensional estimation task, applying our transformation to an optimal robust estimator results in an optimal private estimator. Thus, we conclude that for any low-dimensional task, the optimal error rate for $\varepsilon$-differentially private estimators is essentially the same as the optimal error rate for estimators that are robust to adversarially corrupting $1/\varepsilon$ training samples. We apply our transformation to obtain new optimal private estimators for several high-dimensional statistical tasks, including Gaussian linear regression and PCA. Finally, we present an extension of our transformation that leads to approximately differentially private algorithms whose error does not depend on the range of the output space, which is impossible under pure differential privacy.

**摘要:** 我们研究了统计推导和机器学习中的两种算法的期望关系——对敌对数据腐败的差异性隐私和鲁棒性。他们的概念相似性首先被Dwork和Lei(STOC 2009)观察,他们观察到私人算法满足鲁棒性,并给出了将鲁棒算法转换为私人算法的一般方法。然而,所有将鲁棒算法转换为私人算法的一般方法都会导致低误差率。因此,我们得出任何低维任务,$\varepsilon$-differentially private estimators的最优误差率基本上与对敌对腐蚀$1/\varepsilon$训练样本的最优误差率相同。我们应用我们的变换,为数个高维统计任务,包括高斯线性回归和PCA,获得新的最优私人估计器。最后,我们提出了一种扩展的变换,导致大约不依赖输出空间的误差的微分私人算法,这在纯微分隐私下是不可能的。

**[Paper URL](https://proceedings.mlr.press/v202/asi23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/asi23b/asi23b.pdf)** 

# SGD with AdaGrad Stepsizes: Full Adaptivity with High Probability to Unknown Parameters, Unbounded Gradients and Affine Variance
**题目:** 基于AdaGrad的SGD步骤大小:高度适应未知参数、无界梯度和影响变量

**作者:** Amit Attia, Tomer Koren

**Abstract:** We study Stochastic Gradient Descent with AdaGrad stepsizes: a popular adaptive (self-tuning) method for first-order stochastic optimization. Despite being well studied, existing analyses of this method suffer from various shortcomings: they either assume some knowledge of the problem parameters, impose strong global Lipschitz conditions, or fail to give bounds that hold with high probability. We provide a comprehensive analysis of this basic method without any of these limitations, in both the convex and non-convex (smooth) cases, that additionally supports a general “affine variance” noise model and provides sharp rates of convergence in both the low-noise and high-noise regimes.

**摘要:** 我们研究了AdaGrad级梯度降落:一种用于第一阶随机优化的流行的自适应(自调)方法。尽管该方法已经得到很好的研究,但其现有的分析存在着各种缺陷:它们要么假设问题参数的某些知识,要么强加强的全球利普希茨条件,要么不能给出与高概率保持的边界。

**[Paper URL](https://proceedings.mlr.press/v202/attia23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/attia23a/attia23a.pdf)** 

# Adversarially Robust PAC Learnability of Real-Valued Functions
**题目:** 实值函数的敌对鲁棒PAC学习性

**作者:** Idan Attias, Steve Hanneke

**Abstract:** We study robustness to test-time adversarial attacks in the regression setting with $\ell_p$ losses and arbitrary perturbation sets. We address the question of which function classes are PAC learnable in this setting. We show that classes of finite fat-shattering dimension are learnable in both the realizable and agnostic settings. Moreover, for convex function classes, they are even properly learnable. In contrast, some non-convex function classes provably require improper learning algorithms. Our main technique is based on a construction of an adversarially robust sample compression scheme of a size determined by the fat-shattering dimension. Along the way, we introduce a novel agnostic sample compression scheme for real-valued functions, which may be of independent interest.

**摘要:** 我们研究了与$ell_p$损失和任意扰动集合的回归设置中测试时间敌对攻击的鲁棒性。我们解决了该设置中哪些函数类是可学习的PAC问题。我们显示有限的脂肪压缩维度的类在可实现和 agnostic设置中都可学习。此外,对于凸函数类,它们甚至可以正确学习。相反,一些非凸函数类可证明需要不恰当的学习算法。我们的主要技术是基于由脂肪压缩维度决定的大小的敌对鲁棒样品压缩方案的构造。

**[Paper URL](https://proceedings.mlr.press/v202/attias23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/attias23a/attias23a.pdf)** 

# Infusing Lattice Symmetry Priors in Attention Mechanisms for Sample-Efficient Abstract Geometric Reasoning
**题目:** 对实例高效抽象几何推理的注意机制中 Lattice Symmetry Priors的引入

**作者:** Mattia Atzeni, Mrinmaya Sachan, Andreas Loukas

**Abstract:** The Abstraction and Reasoning Corpus (ARC) (Chollet, 2019) and its most recent language-complete instantiation (LARC) has been postulated as an important step towards general AI. Yet, even state-of-the-art machine learning models struggle to achieve meaningful performance on these problems, falling behind non-learning based approaches. We argue that solving these tasks requires extreme generalization that can only be achieved by proper accounting for core knowledge priors. As a step towards this goal, we focus on geometry priors and introduce LatFormer, a model that incorporates lattice symmetry priors in attention masks. We show that, for any transformation of the hypercubic lattice, there exists a binary attention mask that implements that group action. Hence, our study motivates a modification to the standard attention mechanism, where attention weights are scaled using soft masks generated by a convolutional network. Experiments on synthetic geometric reasoning show that LatFormer requires 2 orders of magnitude fewer data than standard attention and transformers. Moreover, our results on ARC and LARC tasks that incorporate geometric priors provide preliminary evidence that these complex datasets do not lie out of the reach of deep learning models.

**摘要:** 抽象和推理 Corpus (ARC) (Chollet, 2019)及其最近的语言完整的实证化(LARC)被推测为向一般人工智能迈出的重要一步。然而,即使是最先进的机器学习模型也 struggle to achieve meaningful performance on these problems, falling behind non-learning based approaches. We argue that solving these tasks requires extreme generalization that can only be achieved by proper accounting for core knowledge priors. As a step towards this goal, we focus on geometry priors and introduce LatFormer, a model that incorporates lattice symmetry priors in attention masks. We show that, for any transformation of the hypercubic lattice, there exists a binary attention mask that implements that group action. Hence, our study motivates a modification to the standard attention mechanism, where attention weights are scaled using soft masks generated by a con对合成几何推理的实验表明,LatFormer需要比标准的注意力和变换器少两个数量的数据。此外,我们对包含几何预先的ARC和LARC任务的结果提供了初步证据,表明这些复杂的数据集不属于深度学习模型的范围。

**[Paper URL](https://proceedings.mlr.press/v202/atzeni23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/atzeni23a/atzeni23a.pdf)** 

# Learning to Initiate and Reason in Event-Driven Cascading Processes
**题目:** 如何启动和推理基于事件的缓冲过程

**作者:** Yuval Atzmon, Eli Meirom, Shie Mannor, Gal Chechik

**Abstract:** Training agents to control a dynamic environment is a fundamental task in AI. In many environments, the dynamics can be summarized by a small set of events that capture the semantic behavior of the system. Typically, these events form chains or cascades. We often wish to change the system behavior using a single intervention that propagates through the cascade. For instance, one may trigger a biochemical cascade to switch the state of a cell or, in logistics, reroute a truck to meet an unexpected, urgent delivery. We introduce a new supervised learning setup called Cascade. An agent observes a system with known dynamics evolving from some initial state. The agent is given a structured semantic instruction and needs to make an intervention that triggers a cascade of events, such that the system reaches an alternative (counterfactual) behavior. We provide a test-bed for this problem, consisting of physical objects. We combine semantic tree search with an event-driven forward model and devise an algorithm that learns to efficiently search in exponentially large semantic trees. We demonstrate that our approach learns to follow instructions to intervene in new complex scenes. When provided with an observed cascade of events, it can also reason about alternative outcomes.

**摘要:** 控制动态环境的训练代理是人工智能的一个基本任务。在许多环境中,动态可以通过一系列事件来总结系统语义行为。通常,这些事件形成链路或 cascades。我们经常希望通过单个通过 cascade传播的干预来改变系统行为。例如,一个人可以触发生物化学 cascade来切换细胞的状态,或者在物流中,重新调用卡车来满足意外的、紧急的交付。我们引入新的监管学习设置Cascade。一个代理观察从某些初始状态演变的已知动态系统。代理给予了结构化的语义指令,并需要进行触发事件的 cascade的干预,使得系统达到一种替代(反事实)行为。我们为这一问题提供测试床,由物理对象组成。我们将语义树搜索与事件驱动的前方模型相结合,并设计了一个学习在指数级大的语义树上高效搜索的算法。我们证明,我们的方法学习遵循命令来干预新的复杂场景。

**[Paper URL](https://proceedings.mlr.press/v202/atzmon23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/atzmon23a/atzmon23a.pdf)** 

# On the convergence of the MLE as an estimator of the learning rate in the Exp3 algorithm
**题目:** 关于MLE作为exp3算法学习率的估计器的收敛性

**作者:** Julien Aubert, Luc Lehéricy, Patricia Reynaud-Bouret

**Abstract:** When fitting the learning data of an individual to algorithm-like learning models, the observations are so dependent and non-stationary that one may wonder what the classical Maximum Likelihood Estimator (MLE) could do, even if it is the usual tool applied to experimental cognition. Our objective in this work is to show that the estimation of the learning rate cannot be efficient if the learning rate is constant in the classical Exp3 (Exponential weights for Exploration and Exploitation) algorithm. Secondly, we show that if the learning rate decreases polynomially with the sample size, then the prediction error and in some cases the estimation error of the MLE satisfy bounds in probability that decrease at a polynomial rate.

**摘要:** 在将个人学习数据与类似算法的学习模型相匹配时,观察结果是如此依赖性且非静态的,人们可能想知道经典的最有可能估计器(MLE)能做些什么,即使它是实验认知的常用工具。我们的工作目的是表明,如果学习率在经典的exp3(Exponential weights for Exploration and Exploitation)算法中是不变的,那么学习率的估计是不可能有效的。

**[Paper URL](https://proceedings.mlr.press/v202/aubert23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/aubert23a/aubert23a.pdf)** 

# Dirichlet Diffusion Score Model for Biological Sequence Generation
**题目:** 生物序列生成 Dirichlet扩散分数模型

**作者:** Pavel Avdeyev, Chenlai Shi, Yuhao Tan, Kseniia Dudnyk, Jian Zhou

**Abstract:** Designing biological sequences is an important challenge that requires satisfying complex constraints and thus is a natural problem to address with deep generative modeling. Diffusion generative models have achieved considerable success in many applications. Score-based generative stochastic differential equations (SDE) model is a continuous-time diffusion model framework that enjoys many benefits, but the originally proposed SDEs are not naturally designed for modeling discrete data. To develop generative SDE models for discrete data such as biological sequences, here we introduce a diffusion process defined in the probability simplex space with stationary distribution being the Dirichlet distribution. This makes diffusion in continuous space natural for modeling discrete data. We refer to this approach as Dirchlet diffusion score model. We demonstrate that this technique can generate samples that satisfy hard constraints using a Sudoku generation task. This generative model can also solve Sudoku, including hard puzzles, without additional training. Finally, we applied this approach to develop the first human promoter DNA sequence design model and showed that designed sequences share similar properties with natural promoter sequences.

**摘要:** 生物序列的设计是一个重要的挑战,需要满足复杂的约束,因此是解决深层生成模型的自然问题。扩散生成模型在许多应用中取得了相当大的成功。基于分数的生成随机微分方程(SDE)模型是一个连续时间扩散模型框架,它有许多好处,但最初提出的SDEs并不是自然设计的用于模拟离散数据。最后,我们应用这一方法开发了第一个人类促进剂DNA序列设计模型,表明设计的序列与自然促进剂序列具有相似的特性。

**[Paper URL](https://proceedings.mlr.press/v202/avdeyev23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/avdeyev23a/avdeyev23a.pdf)** 

# Gradient Descent Converges Linearly for Logistic Regression on Separable Data
**题目:** 分离数据逻辑回归的梯度偏移线性收敛

**作者:** Kyriakos Axiotis, Maxim Sviridenko

**Abstract:** We show that running gradient descent with variable learning rate guarantees loss $f(x) ≤ 1.1 \cdot f(x^*)+\epsilon$ for the logistic regression objective, where the error $\epsilon$ decays exponentially with the number of iterations and polynomially with the magnitude of the entries of an arbitrary fixed solution $x$. This is in contrast to the common intuition that the absence of strong convexity precludes linear convergence of first-order methods, and highlights the importance of variable learning rates for gradient descent. We also apply our ideas to sparse logistic regression, where they lead to an exponential improvement of the sparsity-error tradeoff.

**摘要:** 我们证明,运行变量学习率的梯度下降保证了逻辑回归目标的损失 $f(x) ≤ 1.1 \cdot f(x^*)+\epsilon$, 其中错误 $\epsilon$ 随迭代数和任意固定解 $x$ 的输入的大小递减性衰减,这与一般的直觉相反,即缺乏强凸性排除了第一阶方法的线性收敛性,并突出了梯度下降的变量学习率的重要性。

**[Paper URL](https://proceedings.mlr.press/v202/axiotis23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/axiotis23a/axiotis23a.pdf)** 

# Naive imputation implicitly regularizes high-dimensional linear models
**题目:** 直观归纳隐含地规范了高维线性模型

**作者:** Alexis Ayme, Claire Boyer, Aymeric Dieuleveut, Erwan Scornet

**Abstract:** Two different approaches exist to handle missing values for prediction: either imputation, prior to fitting any predictive algorithms, or dedicated methods able to natively incorporate missing values. While imputation is widely (and easily) use, it is unfortunately biased when low-capacity predictors (such as linear models) are applied afterward. However, in practice, naive imputation exhibits good predictive performance. In this paper, we study the impact of imputation in a high-dimensional linear model with MCAR missing data. We prove that zero imputation performs an implicit regularization closely related to the ridge method, often used in high-dimensional problems. Leveraging on this connection, we establish that the imputation bias is controlled by a ridge bias, which vanishes in high dimension. As a predictor, we argue in favor of the averaged SGD strategy, applied to zero-imputed data. We establish an upper bound on its generalization error, highlighting that imputation is benign in the $d \gg \sqrt{n}$ regime. Experiments illustrate our findings.

**摘要:** 在预测中存在两种不同的方法来处理缺失值:即归纳,即在装配任何预测算法之前进行归纳,或专用方法,能够自然地包含缺失值。归纳虽然广泛(而且容易)使用,但由于低容量的预测器(如线性模型)在其后应用时是偏向的。然而,在实践中,单纯的归纳表现出良好的预测性能。本论文研究了归纳在MCAR缺失数据的高维线性模型中的影响。我们建立了它的一般化误差的上限,突出了$d \gg \sqrt{n}$模式中的归因是良性的。实验证明了我们的发现。

**[Paper URL](https://proceedings.mlr.press/v202/ayme23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ayme23a/ayme23a.pdf)** 

# Half-Hop: A graph upsampling approach for slowing down message passing
**题目:** Half-Hop:用于减慢消息传递的图上采样方法

**作者:** Mehdi Azabou, Venkataramana Ganesh, Shantanu Thakoor, Chi-Heng Lin, Lakshmi Sathidevi, Ran Liu, Michal Valko, Petar Veličković, Eva L Dyer

**Abstract:** Message passing neural networks have shown a lot of success on graph-structured data. However, there are many instances where message passing can lead to over-smoothing or fail when neighboring nodes belong to different classes. In this work, we introduce a simple yet general framework for improving learning in message passing neural networks. Our approach essentially upsamples edges in the original graph by adding "slow nodes" at each edge that can mediate communication between a source and a target node. Our method only modifies the input graph, making it plug-and-play and easy to use with existing models. To understand the benefits of slowing down message passing, we provide theoretical and empirical analyses. We report results on several supervised and self-supervised benchmarks, and show improvements across the board, notably in heterophilic conditions where adjacent nodes are more likely to have different labels. Finally, we show how our approach can be used to generate augmentations for self-supervised learning, where slow nodes are randomly introduced into different edges in the graph to generate multi-scale views with variable path lengths.

**摘要:** 信息传递神经网络在图结构数据上取得了很大的成功。然而,在邻接节点属于不同类别时,信息传递可能导致过度缓冲或失败的案例很多。在这一工作中,我们引入了改进信息传递神经网络的学习的简单但通用框架。我们的基本方法是通过在每个边上添加“慢节点”来增加原始图中的边缘,以调介源和目标节点之间的通信。我们的方法只修改输入图,使它能够与现有模型进行插件和游戏,并易于使用。最后,我们展示了如何使用我们的方法来生成自监督学习的增量,即将慢节点随机引入图中的不同边缘,以生成具有可变路径长度的多尺度视图。

**[Paper URL](https://proceedings.mlr.press/v202/azabou23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/azabou23a/azabou23a.pdf)** 

# CLUTR: Curriculum Learning via Unsupervised Task Representation Learning
**题目:** CLUTR:非监督任务表现学习课程学习

**作者:** Abdus Salam Azad, Izzeddin Gur, Jasper Emhoff, Nathaniel Alexis, Aleksandra Faust, Pieter Abbeel, Ion Stoica

**Abstract:** Reinforcement Learning (RL) algorithms are often known for sample inefficiency and difficult generalization. Recently, Unsupervised Environment Design (UED) emerged as a new paradigm for zero-shot generalization by simultaneously learning a task distribution and agent policies on the generated tasks. This is a non-stationary process where the task distribution evolves along with agent policies; creating an instability over time. While past works demonstrated the potential of such approaches, sampling effectively from the task space remains an open challenge, bottlenecking these approaches. To this end, we introduce CLUTR: a novel unsupervised curriculum learning algorithm that decouples task representation and curriculum learning into a two-stage optimization. It first trains a recurrent variational autoencoder on randomly generated tasks to learn a latent task manifold. Next, a teacher agent creates a curriculum by maximizing a minimax REGRET-based objective on a set of latent tasks sampled from this manifold. Using the fixed-pretrained task manifold, we show that CLUTR successfully overcomes the non-stationarity problem and improves stability. Our experimental results show CLUTR outperforms PAIRED, a principled and popular UED method, in the challenging CarRacing and navigation environments: achieving 10.6X and 45% improvement in zero-shot generalization, respectively. CLUTR also performs comparably to the non-UED state-of-the-art for CarRacing, while requiring 500X fewer environment interactions. We open source our code at https://github.com/clutr/clutr.

**摘要:** 强化学习(RL)算法经常以样品效率低和困难的一般化而闻名。最近,无监督环境设计(UED)通过同时学习任务分配和生成任务的代理策略,成为零射程一般化的新范式。这是一个非静态的过程,任务分配与代理策略一起演化;在时间上造成不稳定。虽然过去的工作证明了这种方法的潜力,从任务空间有效采样仍然是一个开放的挑战, bottlenecking这些方法。为此,我们引入CLUTR:一种新颖无监督课程学习算法,将任务表现和课程学习分离为两阶段优化。接下来,一个教师代理创建课程,通过从这个多组中采样的一系列潜在任务上最大化一个基于RegRET的最小目标。使用固定预处理的多组任务,我们显示CLUTR成功地克服了非静态问题,并提高了稳定性。我们的实验结果显示CLUTR在挑战的CarRacing和导航环境中的表现优于PAIRED,一个基本和流行的UED方法:分别达到10.6X和45 %改善零射击一般化。CLUTR也与CarRacing的非UED最新技术相比较,同时需要500X减少环境交互。

**[Paper URL](https://proceedings.mlr.press/v202/azad23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/azad23a/azad23a.pdf)** 

# Personalized Subgraph Federated Learning
**题目:** 个人化分段联邦学习

**作者:** Jinheon Baek, Wonyong Jeong, Jiongdao Jin, Jaehong Yoon, Sung Ju Hwang

**Abstract:** Subgraphs of a larger global graph may be distributed across multiple devices, and only locally accessible due to privacy restrictions, although there may be links between subgraphs. Recently proposed subgraph Federated Learning (FL) methods deal with those missing links across local subgraphs while distributively training Graph Neural Networks (GNNs) on them. However, they have overlooked the inevitable heterogeneity between subgraphs comprising different communities of a global graph, consequently collapsing the incompatible knowledge from local GNN models. To this end, we introduce a new subgraph FL problem, personalized subgraph FL, which focuses on the joint improvement of the interrelated local GNNs rather than learning a single global model, and propose a novel framework, FEDerated Personalized sUBgraph learning (FED-PUB), to tackle it. Since the server cannot access the subgraph in each client, FED-PUB utilizes functional embeddings of the local GNNs using random graphs as inputs to compute similarities between them, and use the similarities to perform weighted averaging for server-side aggregation. Further, it learns a personalized sparse mask at each client to select and update only the subgraph-relevant subset of the aggregated parameters. We validate our FED-PUB for its subgraph FL performance on six datasets, considering both non-overlapping and overlapping subgraphs, on which it significantly outperforms relevant baselines. Our code is available at https://github.com/JinheonBaek/FED-PUB.

**摘要:** 一个较大的全球图形的分段可以分布在多个设备上,并且由于隐私限制,只能在本地访问,尽管分段之间可能有联系。最近提出的分段联邦学习(FL)方法处理在本地分段中缺失的联系,同时分散培训图形神经网络(GNNs)在它们上。然而,他们忽略了包含全球图形不同社区的分段之间不可避免的异质性,因此从本地GNN模型中无法兼容的知识崩溃。为此目的,我们引入了新的分段FL问题,个性化分段FL,它集中于共同改进相互关联的本地GNNs,而不是学习一个单一的全球模型,并提出了一种新的框架, FEDerated Personalized sUBgraph learning(FED-PUB),来解决它。由于服务器不能访问每个客户端的子图, FED-PUB使用局部GNN的函数嵌入式,使用随机图作为输入来计算它们之间的相似性,并使用相似性来执行服务器侧聚合的权重平均值。此外,它在每个客户端学习一个个性化的稀疏面具,以选择和更新aggregated参数的子图相关子集。我们验证了 FED-PUB在六个数据集上的子图FL性能,考虑了非重叠和重叠子图,在其中它显著超过相关基线。

**[Paper URL](https://proceedings.mlr.press/v202/baek23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/baek23a/baek23a.pdf)** 

# Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language
**题目:** 有效的自我监督学习,基于视觉、语音和语言的背景目标表现

**作者:** Alexei Baevski, Arun Babu, Wei-Ning Hsu, Michael Auli

**Abstract:** Current self-supervised learning algorithms are often modality-specific and require large amounts of computational resources. To address these issues, we increase the training efficiency of data2vec, a learning objective that generalizes across several modalities. We do not encode masked tokens, use a fast convolutional decoder and amortize the effort to build teacher representations. data2vec 2.0 benefits from the rich contextualized target representations introduced in data2vec which enable a fast self-supervised learner. Experiments on ImageNet-1K image classification show that data2vec 2.0 matches the accuracy of Masked Autoencoders in 16.4x lower pre-training time, on Librispeech speech recognition it performs as well as wav2vec 2.0 in 10.6x less time, and on GLUE natural language understanding it matches a retrained RoBERTa model in half the time. Trading some speed for accuracy results in ImageNet-1K top-1 accuracy of 86.8% with a ViT-L model trained for 150 epochs.

**摘要:** 当前的自我监督学习算法往往是模态特异的,需要大量的计算资源。为了解决这些问题,我们增加了数据2vec的训练效率,这是一个在多种模态中推广的学习目标。我们不编码掩盖的トークン,使用快速的volutional decoder,并减少建立教师的表述的努力。 data2vec 2.0从数据2vec中引入的丰富上下文化的目标表述中获益,使快速的自我监督学习者能够学习。

**[Paper URL](https://proceedings.mlr.press/v202/baevski23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/baevski23a/baevski23a.pdf)** 

# Efficient preconditioned stochastic gradient descent for estimation in latent variable models
**题目:** 潜在变量模型估计的高效预条件随机梯度下降

**作者:** Charlotte Baey, Maud Delattre, Estelle Kuhn, Jean-Benoist Leger, Sarah Lemler

**Abstract:** Latent variable models are powerful tools for modeling complex phenomena involving in particular partially observed data, unobserved variables or underlying complex unknown structures. Inference is often difficult due to the latent structure of the model. To deal with parameter estimation in the presence of latent variables, well-known efficient methods exist, such as gradient-based and EM-type algorithms, but with practical and theoretical limitations. In this paper, we propose as an alternative for parameter estimation an efficient preconditioned stochastic gradient algorithm. Our method includes a preconditioning step based on a positive definite Fisher information matrix estimate. We prove convergence results for the proposed algorithm under mild assumptions for very general latent variables models. We illustrate through relevant simulations the performance of the proposed methodology in a nonlinear mixed effects model and in a stochastic block model.

**摘要:** 隐形变量模型是建模复杂现象的有力工具,包括部分观测数据、未观察变量或复杂未知结构。隐形变量模型的隐形结构使隐形变量模型的隐形变量结构难以控制。在隐形变量存在时,为了处理隐形变量,已知有效的方法存在,如梯度式和EM型算法,但具有实际和理论上的局限性。本文提出了一种有效的预先条件下的随机梯度算法作为参数估计的替代方案。

**[Paper URL](https://proceedings.mlr.press/v202/baey23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/baey23a/baey23a.pdf)** 

# Feed Two Birds with One Scone: Exploiting Wild Data for Both Out-of-Distribution Generalization and Detection
**题目:** 两只鸟用一杆饲料:利用野生数据进行非分布的一般化和检测

**作者:** Haoyue Bai, Gregory Canal, Xuefeng Du, Jeongyeol Kwon, Robert D Nowak, Yixuan Li

**Abstract:** Modern machine learning models deployed in the wild can encounter both covariate and semantic shifts, giving rise to the problems of out-of-distribution (OOD) generalization and OOD detection respectively. While both problems have received significant research attention lately, they have been pursued independently. This may not be surprising, since the two tasks have seemingly conflicting goals. This paper provides a new unified approach that is capable of simultaneously generalizing to covariate shifts while robustly detecting semantic shifts. We propose a margin-based learning framework that exploits freely available unlabeled data in the wild that captures the environmental test-time OOD distributions under both covariate and semantic shifts. We show both empirically and theoretically that the proposed margin constraint is the key to achieving both OOD generalization and detection. Extensive experiments show the superiority of our framework, outperforming competitive baselines that specialize in either OOD generalization or OOD detection. Code is publicly available at https://github.com/deeplearning-wisc/scone.

**摘要:** 现代机器学习模型在野外应用时,可以遇到两类变异和语义变异,从而产生外分布(OOD)一般化和 OOD检测问题。虽然这两类问题最近得到了大量研究的关注,但它们已经独立进行研究。这可能并不令人惊讶,因为这两个任务有明显的冲突目标。本论文提供了一种能够同时一般化两类变异 while robustly detecting semantic shifts的新统一方法。广泛的实验显示了我们的框架的优越性,超越了在OOD一般化或OOD检测方面的竞争性基线。代码在 https://github.com/deeplearning-wisc/scone上公开。

**[Paper URL](https://proceedings.mlr.press/v202/bai23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bai23a/bai23a.pdf)** 

# Answering Complex Logical Queries on Knowledge Graphs via Query Computation Tree Optimization
**题目:** 通过查询计算树优化来回答知识图的复杂逻辑查询

**作者:** Yushi Bai, Xin Lv, Juanzi Li, Lei Hou

**Abstract:** Answering complex logical queries on incomplete knowledge graphs is a challenging task, and has been widely studied. Embedding-based methods require training on complex queries and may not generalize well to out-of-distribution query structures. Recent work frames this task as an end-to-end optimization problem, and it only requires a pretrained link predictor. However, due to the exponentially large combinatorial search space, the optimal solution can only be approximated, limiting the final accuracy. In this work, we propose QTO (Query Computation Tree Optimization) that can efficiently find the exact optimal solution. QTO finds the optimal solution by a forward-backward propagation on the tree-like computation graph, i.e., query computation tree. In particular, QTO utilizes the independence encoded in the query computation tree to reduce the search space, where only local computations are involved during the optimization procedure. Experiments on 3 datasets show that QTO obtains state-of-the-art performance on complex query answering, outperforming previous best results by an average of 22%. Moreover, QTO can interpret the intermediate solutions for each of the one-hop atoms in the query with over 90% accuracy.

**摘要:** 基于嵌入式方法需要对复杂查询进行培训,并不能对非分布式查询结构进行一般化。最近的工作框架将这一任务视为终点到终点优化问题,并且仅需要预先预定的链路预测器。然而,由于指数级大的组合搜索空间,优化解决方案只能近似,限制最终的准确性。在这个工作中,我们提议QTO(Query Computation Tree Optimization)能有效地找到准确的优化解决方案。3个数据集的实验表明,QTO在复杂查询答复方面取得了最先进的性能,平均达到22 % 。 此外,QTO能够准确地解释查询中每个一个跳原子的中间解决方案。

**[Paper URL](https://proceedings.mlr.press/v202/bai23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bai23b/bai23b.pdf)** 

# Linear optimal partial transport embedding
**题目:** 线性最优部分运输嵌入

**作者:** Yikun Bai, Ivan Vladimir Medri, Rocio Diaz Martin, Rana Shahroz, Soheil Kolouri

**Abstract:** Optimal transport (OT) has gained popularity due to its various applications in fields such as machine learning, statistics, and signal processing. However, the balanced mass requirement limits its performance in practical problems. To address these limitations, variants of the OT problem, including unbalanced OT, Optimal partial transport (OPT), and Hellinger Kantorovich (HK), have been proposed. In this paper, we propose the Linear optimal partial transport (LOPT) embedding, which extends the (local) linearization technique on OT and HK to the OPT problem. The proposed embedding allows for faster computation of OPT distance between pairs of positive measures. Besides our theoretical contributions, we demonstrate the LOPT embedding technique in point-cloud interpolation and PCA analysis. Our code is available at https://github.com/Baio0/LinearOPT.

**摘要:** 优化传输(OT)由于其在机器学习、统计和信号处理等领域中的应用日益广泛,但平衡质量要求限制了其在实际问题中的性能。为了解决这些限制, OT问题的变量,包括不平衡的OT、优化部分传输(OPT)和Hellinger Kantorovich(HK)已经提出。本文提出了线性优化部分传输(LOPT)嵌入法,它将 OT和HK上的(局部)线性化技术扩展到OPT问题。该嵌入法允许在正量对之间更快计算OPT距离。

**[Paper URL](https://proceedings.mlr.press/v202/bai23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bai23c/bai23c.pdf)** 

# Implicit Graph Neural Networks: A Monotone Operator Viewpoint
**题目:** 隐形图神经网络:单调操作者视角

**作者:** Justin Baker, Qingsong Wang, Cory D Hauck, Bao Wang

**Abstract:** Implicit graph neural networks (IGNNs) – that solve a fixed-point equilibrium equation using Picard iteration for representation learning – have shown remarkable performance in learning long-range dependencies (LRD) in the underlying graphs. However, IGNNs suffer from several issues, including 1) their expressivity is limited by their parameterizations for the well-posedness guarantee, 2) IGNNs are unstable in learning LRD, and 3) IGNNs become computationally inefficient when learning LRD. In this paper, we provide a new well-posedness characterization for IGNNs leveraging monotone operator theory, resulting in a much more expressive parameterization than the existing one. We also propose an orthogonal parameterization for IGNN based on Cayley transform to stabilize learning LRD. Furthermore, we leverage Anderson-accelerated operator splitting schemes to efficiently solve for the fixed point of the equilibrium equation of IGNN with monotone or orthogonal parameterization. We verify the computational efficiency and accuracy of the new models over existing IGNNs on various graph learning tasks at both graph and node levels.

**摘要:** 隐形图神经网络(英语:Implicit graph neural networks,缩写为IGNNs) — — 利用Picard迭代求解表示学习的固定点平衡方程 — — 在底层图中显示了学习长距离依赖性(LRD)的显著性能。然而,IGNN有几个问题,包括: 1)它们的表达性受到参数化限制,以保证良好的定位; 2)IGNN在学习LRD中不稳定; 3)IGNN在学习LRD时变得计算效率低。通过对现有IGNN模型的计算效率和准确性进行验证,对各种图形学习任务在图形和节点两级进行了验证。

**[Paper URL](https://proceedings.mlr.press/v202/baker23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/baker23a/baker23a.pdf)** 

# Tensor Decompositions Meet Control Theory: Learning General Mixtures of Linear Dynamical Systems
**题目:** 张力分解与控制理论相符:学习线性动态系统的一般混合物

**作者:** Ainesh Bakshi, Allen Liu, Ankur Moitra, Morris Yau

**Abstract:** Recently Chen and Poor initiated the study of learning mixtures of linear dynamical systems. While linear dynamical systems already have wide-ranging applications in modeling time-series data, using mixture models can lead to a better fit or even a richer understanding of underlying subpopulations represented in the data. In this work we give a new approach to learning mixtures of linear dynamical systems that is based on tensor decompositions. As a result, our algorithm succeeds without strong separation conditions on the components, and can be used to compete with the Bayes optimal clustering of the trajectories. Moreover our algorithm works in the challenging partially-observed setting. Our starting point is the simple but powerful observation that the classic Ho-Kalman algorithm is a relative of modern tensor decomposition methods for learning latent variable models. This gives us a playbook for how to extend it to work with more complicated generative models.

**摘要:** 本文研究了线性动力系统混合物的学习方法。虽然线性动力系统在建模时序数据方面已经具有广泛的应用,但使用混合物模型可导致在数据中表现的下层群体的较好的适应性或更丰富的理解。本文给出了基于变量模型的线性动力系统混合物学习的新方法,结果,我们的算法在组件上没有强的分离条件的情况下成功,并可与贝斯轨道的优化集群竞争。此外,我们的算法在挑战性部分观察环境下工作。

**[Paper URL](https://proceedings.mlr.press/v202/bakshi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bakshi23a/bakshi23a.pdf)** 

# Block Subsampled Randomized Hadamard Transform for Nyström Approximation on Distributed Architectures
**题目:** 分组随机哈达马德变换对分布式建筑的Nyström近似

**作者:** Oleg Balabanov, Matthias Beaupère, Laura Grigori, Victor Lederer

**Abstract:** This article introduces a novel structured random matrix composed blockwise from subsampled randomized Hadamard transforms (SRHTs). The block SRHT is expected to outperform well-known dimension reduction maps, including SRHT and Gaussian matrices on distributed architectures. We prove that a block SRHT with enough rows is an oblivious subspace embedding, i.e., an approximate isometry for an arbitrary low-dimensional subspace with high probability. Our estimate of the required number of rows is similar to that of the standard SRHT. This suggests that the two transforms should provide the same accuracy of approximation in the algorithms. The block SRHT can be readily incorporated into randomized methods for computing a low-rank approximation of a large-scale matrix, such as the Nyström method. For completeness, we revisit this method with a discussion of its implementation on distributed architectures.

**摘要:** 本文介绍了一种由分样随机哈达马德变换(SRHTs)组成的新结构随机矩阵。该块SRHT预计能超过分布式架构中的已知维度减小地图,包括SRHT和高斯矩阵。我们证明,具有足够行的块SRHT是隐形子空间嵌入,即具有较高概率的任意低维子空间的 approximate isometry。我们对所需行数的估计与标准SRHT相似。这表明两个变换应该在算法中提供相同的近似精度。

**[Paper URL](https://proceedings.mlr.press/v202/balabanov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/balabanov23a/balabanov23a.pdf)** 

# Efficient Online Reinforcement Learning with Offline Data
**题目:** 利用网上数据进行有效在线强化学习

**作者:** Philip J. Ball, Laura Smith, Ilya Kostrikov, Sergey Levine

**Abstract:** Sample efficiency and exploration remain major challenges in online reinforcement learning (RL). A powerful approach that can be applied to address these issues is the inclusion of offline data, such as prior trajectories from a human expert or a sub-optimal exploration policy. Previous methods have relied on extensive modifications and additional complexity to ensure the effective use of this data. Instead, we ask: can we simply apply existing off-policy methods to leverage offline data when learning online? In this work, we demonstrate that the answer is yes; however, a set of minimal but important changes to existing off-policy RL algorithms are required to achieve reliable performance. We extensively ablate these design choices, demonstrating the key factors that most affect performance, and arrive at a set of recommendations that practitioners can readily apply, whether their data comprise a small number of expert demonstrations or large volumes of sub-optimal trajectories. We see that correct application of these simple recommendations can provide a $\mathbf{2.5\times}$ improvement over existing approaches across a diverse set of competitive benchmarks, with no additional computational overhead.

**摘要:** 在在线增强学习(RL)中,样本效率和探索仍然是主要的挑战。为了解决这些问题,可以应用强大的方法,包括非网络数据,例如从人类专家或非最佳探索政策的前行路径。以前的方法依赖广泛的修改和额外的复杂性,以确保有效使用这些数据。相反,我们问:在在线学习时,我们能简单地应用现有的非政策方法来利用非网络数据吗?在这个工作中,我们证明答案是是是的;然而,为了实现可靠的性能,需要对现有非政策RL算法进行最小但重要的更改。我们 看到, 正确 地 应用 这些 简单 的 建议 可以 提供 不同 的 竞争 基准 的 现有 方法 比 现有 方法 有所 改善, 没有 额外 的 计算 费用 。

**[Paper URL](https://proceedings.mlr.press/v202/ball23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ball23a/ball23a.pdf)** 

# Mirror Sinkhorn: Fast Online Optimization on Transport Polytopes
**题目:** Mirror Sinkhorn:快速在线优化运输聚合物

**作者:** Marin Ballu, Quentin Berthet

**Abstract:** Optimal transport is an important tool in machine learning, allowing to capture geometric properties of the data through a linear program on transport polytopes. We present a single-loop optimization algorithm for minimizing general convex objectives on these domains, utilizing the principles of Sinkhorn matrix scaling and mirror descent. The proposed algorithm is robust to noise, and can be used in an online setting. We provide theoretical guarantees for convex objectives and experimental results showcasing it effectiveness on both synthetic and real-world data.

**摘要:** 优化传输是机器学习中的一个重要工具,通过传输多极体的线性程序捕捉数据的几何特性。我们提出了一种单环优化算法,以利用辛克宏矩阵尺度和镜下 descend 的原理,在这些领域最小化一般凸目标。该算法对噪声具有鲁棒性,可以在在线设置中使用。

**[Paper URL](https://proceedings.mlr.press/v202/ballu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ballu23a/ballu23a.pdf)** 

# On the Functional Similarity of Robust and Non-Robust Neural Representations
**题目:** 鲁棒神经元和非鲁棒神经元功能相似性

**作者:** András Balogh, Márk Jelasity

**Abstract:** Model stitching—where the internal representations of two neural networks are aligned linearly—helped demonstrate that the representations of different neural networks for the same task are surprisingly similar in a functional sense. At the same time, the representations of adversarially robust networks are considered to be different from non-robust representations. For example, robust image classifiers are invertible, while non-robust networks are not. Here, we investigate the functional similarity of robust and non-robust representations for image classification with the help of model stitching. We find that robust and non-robust networks indeed have different representations. However, these representations are compatible regarding accuracy. From the point of view of robust accuracy, compatibility decreases quickly after the first few layers but the representations become compatible again in the last layers, in the sense that the properties of the front model can be recovered. Moreover, this is true even in the case of cross-task stitching. Our results suggest that stitching in the initial, preprocessing layers and the final, abstract layers test different kinds of compatibilities. In particular, the final layers are easy to match, because their representations depend mostly on the same abstract task specification, in our case, the classification of the input into $n$ classes.

**摘要:** 模型缝合—两个神经网络内部的图形线性地排列—有助于证明,同一任务的不同神经网络的图形在功能上具有惊人的相似性。同时,敌对性强网络的图形被认为是与非强网络的图形不同。例如,强图像分类器是可逆的,而非强网络是不可逆的。在这里,我们利用模型缝合来研究强和非强的图形在图像分类上的功能相似性。我们发现,强和非强网络的确有不同的图形。然而,这些图形在精度方面相容。从强精度的角度来看,相容性在最初几层后迅速下降,但图形在最后几层中再度相容,因为前面图形的特性可以恢复。我们的结果表明,在初始的预处理层和最终的抽象层的缝纫测试不同类型的兼容性,特别是最后的层是容易匹配的,因为它们的表示主要取决于相同的抽象任务规范,在我们的例子中,输入的分类为$n$类。

**[Paper URL](https://proceedings.mlr.press/v202/balogh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/balogh23a/balogh23a.pdf)** 

# Robust Budget Pacing with a Single Sample
**题目:** 单一样本的稳健预算协议

**作者:** Santiago R. Balseiro, Rachitesh Kumar, Vahab Mirrokni, Balasubramanian Sivan, Di Wang

**Abstract:** Major Internet advertising platforms offer budget pacing tools as a standard service for advertisers to manage their ad campaigns. Given the inherent non-stationarity in an advertiser’s value and also competing advertisers’ values over time, a commonly used approach is to learn a target expenditure plan that specifies a target spend as a function of time, and then run a controller that tracks this plan. This raises the question: how many historical samples are required to learn a good expenditure plan? We study this question by considering an advertiser repeatedly participating in $T$ second-price auctions, where the tuple of her value and the highest competing bid is drawn from an unknown time-varying distribution. The advertiser seeks to maximize her total utility subject to her budget constraint. Prior work has shown the sufficiency of $T\log T$ samples per distribution to achieve the optimal $O(\sqrt{T})$-regret. We dramatically improve this state-of-the-art and show that just one sample per distribution is enough to achieve the near-optimal $\tilde O(\sqrt{T})$-regret, while still being robust to noise in the sampling distributions.

**摘要:** 主要的互联网广告平台提供预算配置工具作为广告商管理其广告宣传的标准服务。鉴于广告商的价值的固有非静态性以及广告商在时间上竞争的价值,一个常用的办法是学习一个目标支出计划,指定目标支出作为时间的函数,然后运行一个控制器跟踪这个计划。这引起了问题:要学习一个好的支出计划需要多少历史样本?我们通过考虑一个广告商反复参与$T$第二价拍卖,其中其价值和最高竞争的报价是从未知的时间变价分配中提取的。我们极大地改进了这种最先进的方法,并证明,每种分布中只有一个样品足够达到 near-optimal $\tilde O(\sqrt{T})$-regret,同时在样品分布中仍然对噪声保持鲁棒。

**[Paper URL](https://proceedings.mlr.press/v202/balseiro23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/balseiro23a/balseiro23a.pdf)** 

# Dynamic Constrained Submodular Optimization with Polylogarithmic Update Time
**题目:** 多重整数更新时间的动态约束子模态优化

**作者:** Kiarash Banihashem, Leyla Biabani, Samira Goudarzi, Mohammadtaghi Hajiaghayi, Peyman Jabbarzade, Morteza Monemizadeh

**Abstract:** Maximizing a monotone submodular function under cardinality constraint $k$ is a core problem in machine learning and database with many basic applications, including video and data summarization, recommendation systems, feature extraction, exemplar clustering, and coverage problems. We study this classic problem in the fully dynamic model where a stream of insertions and deletions of elements of an underlying ground set is given and the goal is to maintain an approximate solution using a fast update time. A recent paper at NeurIPS’20 by Lattanzi, Mitrovic, Norouzi-Fard, Tarnawski, Zadimoghaddam claims to obtain a dynamic algorithm for this problem with a $(\frac{1}{2} -\epsilon)$ approximation ratio and a query complexity bounded by $\mathrm{poly}(\log(n),\log(k),\epsilon^{-1})$. However, as we explain in this paper, the analysis has some important gaps. Having a dynamic algorithm for the problem with polylogarithmic update time is even more important in light of a recent result by Chen and Peng at STOC’22 who show a matching lower bound for the problem – any randomized algorithm with a $\frac{1}{2}+\epsilon$ approximation ratio must have an amortized query complexity that is polynomial in $n$. In this paper, we develop a simpler algorithm for the problem that maintains a $(\frac{1}{2}-\epsilon)$-approximate solution for submodular maximization under cardinality constraint $k$ using a polylogarithmic amortized update time.

**摘要:** 在基数约束下最大化单调子模函数$k$是机器学习和数据库中的一个核心问题,包括视频和数据总结、推荐系统、特征提取、范例聚类和覆盖问题。我们研究了这一经典问题在完全动态模型中,其中给出了基本基数集合的元素插入和删除的流,目标是使用快速更新时间保持近似解。最近在NeurIPS’20的拉塔尼、米特罗维奇、诺鲁齐-法尔德、塔尔纳夫斯基、扎迪莫哈达姆的论文声称,该问题具有$(\frac{1}{2} -\epsilon)$近似比和由$\mathrm{poly}(\log(n),\log(k),\epsilon^{-1})$限制的查询复杂性。基于STOC’22中陈和彭的最近研究结果,对具有多项式更新时间问题的动态算法更加重要——任何具有$\frac{1}{2}+\epsilon$近似比率的随机算法必须具有$n$的多项式复数化查询复杂性。本文开发了一种更简单的算法,以使用多项式更新时间来维持在 cardinality约束$k$下的子模态最大化$(\frac{1}{2}-\epsilon)$近似解。

**[Paper URL](https://proceedings.mlr.press/v202/banihashem23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/banihashem23a/banihashem23a.pdf)** 

# One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale
**题目:** 一种变压器适用于大规模多模扩散中的所有分布

**作者:** Fan Bao, Shen Nie, Kaiwen Xue, Chongxuan Li, Shi Pu, Yaole Wang, Gang Yue, Yue Cao, Hang Su, Jun Zhu

**Abstract:** This paper proposes a unified diffusion framework (dubbed UniDiffuser) to fit all distributions relevant to a set of multi-modal data in one model. Our key insight is – learning diffusion models for marginal, conditional, and joint distributions can be unified as predicting the noise in the perturbed data, where the perturbation levels (i.e. timesteps) can be different for different modalities. Inspired by the unified view, UniDiffuser learns all distributions simultaneously with a minimal modification to the original diffusion model – perturbs data in all modalities instead of a single modality, inputs individual timesteps in different modalities, and predicts the noise of all modalities instead of a single modality. UniDiffuser is parameterized by a transformer for diffusion models to handle input types of different modalities. Implemented on large-scale paired image-text data, UniDiffuser is able to perform image, text, text-to-image, image-to-text, and image-text pair generation by setting proper timesteps without additional overhead. In particular, UniDiffuser is able to produce perceptually realistic samples in all tasks and its quantitative results (e.g., the FID and CLIP score) are not only superior to existing general-purpose models but also comparable to the bespoken models (e.g., Stable Diffusion and DALL-E 2) in representative tasks (e.g., text-to-image generation).

**摘要:** 本文提出了一种统一的扩散框架(双重UniDiffuser),以将一个模型中对一组多模数据有关联的所有扩散 fit 。 我们的关键洞察是:学习边缘、条件和联合扩散的扩散模型可以被统一为预测扰动数据中的噪声,在不同的扩散模式中扰动水平(即时间步骤)可以不同。UniDiffuser可以在大规模的图像-文本数据上实现图像、文本、文本-到图像、图像-到文本和图像-文本对生成,通过设置适当的时间步骤,无需额外的额外费用。 特别是,UniDiffuser可以在所有任务中生成感知的现实样本,并且它的定量结果(例如FID和CLIP分数)不仅比现有的一般用途模型高,而且在代表任务(例如文本-到图像生成)中与定制模型(例如Stable Diffusion和DALL-E2)相比较。

**[Paper URL](https://proceedings.mlr.press/v202/bao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bao23a/bao23a.pdf)** 

# Optimizing the Collaboration Structure in Cross-Silo Federated Learning
**题目:** 跨航域联合学习中的协作结构优化

**作者:** Wenxuan Bao, Haohan Wang, Jun Wu, Jingrui He

**Abstract:** In federated learning (FL), multiple clients collaborate to train machine learning models together while keeping their data decentralized. Through utilizing more training data, FL suffers from the potential negative transfer problem: the global FL model may even perform worse than the models trained with local data only. In this paper, we propose FedCollab, a novel FL framework that alleviates negative transfer by clustering clients into non-overlapping coalitions based on their distribution distances and data quantities. As a result, each client only collaborates with the clients having similar data distributions, and tends to collaborate with more clients when it has less data. We evaluate our framework with a variety of datasets, models, and types of non-IIDness. Our results demonstrate that FedCollab effectively mitigates negative transfer across a wide range of FL algorithms and consistently outperforms other clustered FL algorithms.

**摘要:** 在联邦学习(FL)中,多个客户协同训练机器学习模型,同时保持数据分散。通过使用更多的培训数据,FL遭受潜在的负传输问题:全球的FL模型甚至比只使用本地数据训练的模型表现更差。本文提出了一种新的FL框架,它通过将客户聚合成基于分布距离和数据数量的非重叠联盟来缓解负传输。结果,每个客户只与具有相似数据分布的客户合作,并且在有较少数据的情况下倾向于与更多的客户合作。

**[Paper URL](https://proceedings.mlr.press/v202/bao23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bao23b/bao23b.pdf)** 

# MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation
**题目:** 多扩散:融合扩散路径控制图像生成

**作者:** Omer Bar-Tal, Lior Yariv, Yaron Lipman, Tali Dekel

**Abstract:** Recent advances in text-to-image generation with diffusion models present transformative capabilities in image quality. However, user controllability of the generated image, and fast adaptation to new tasks still remains an open challenge, currently mostly addressed by costly and long re-training and fine-tuning or ad-hoc adaptations to specific image generation tasks. In this work, we present MultiDiffusion, a unified framework that enables versatile and controllable image generation, using a pre-trained text-to-image diffusion model, without any further training or finetuning. At the center of our approach is a new generation process, based on an optimization task that binds together multiple diffusion generation processes with a shared set of parameters or constraints. We show that MultiDiffusion can be readily applied to generate high quality and diverse images that adhere to user-provided controls, such as desired aspect ratio (e.g., panorama), and spatial guiding signals, ranging from tight segmentation masks to bounding boxes.

**摘要:** 近年来,基于扩散模型的文本-图像生成提供了图像质量的转变性能力。然而,生成图像的用户可控性和快速适应新任务仍然是一个开放的挑战,目前主要由昂贵而长期的重新培训和微调或对特定图像生成任务的临时调整来解决。我们证明,MultiDiffusion可以轻易地应用,产生高质量和多样的图像,符合用户提供的控件,如期望的视角比(例如,视景)和空间引导信号,从紧致的分段面罩到跳动盒。

**[Paper URL](https://proceedings.mlr.press/v202/bar-tal23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bar-tal23a/bar-tal23a.pdf)** 

# Reinforcement Learning with General Utilities: Simpler Variance Reduction and Large State-Action Space
**题目:** 通用工具强化学习:简化变量减少和大状态行动空间

**作者:** Anas Barakat, Ilyas Fatkhullin, Niao He

**Abstract:** We consider the reinforcement learning (RL) problem with general utilities which consists in maximizing a function of the state-action occupancy measure. Beyond the standard cumulative reward RL setting, this problem includes as particular cases constrained RL, pure exploration and learning from demonstrations among others. For this problem, we propose a simpler single-loop parameter-free normalized policy gradient algorithm. Implementing a recursive momentum variance reduction mechanism, our algorithm achieves $\tilde{\mathcal{O}}(\epsilon^{-3})$ and $\tilde{\mathcal{O}}(\epsilon^{-2})$ sample complexities for $\epsilon$-first-order stationarity and $\epsilon$-global optimality respectively, under adequate assumptions. We further address the setting of large finite state action spaces via linear function approximation of the occupancy measure and show a $\tilde{\mathcal{O}}(\epsilon^{-4})$ sample complexity for a simple policy gradient method with a linear regression subroutine.

**摘要:** 我们考虑了增强学习(RL)问题,它包含在最大化状态行动占用度量函数。除了标准累积奖励RL设置之外,这个问题还包括限制RL的特殊案例、纯探索和学习,包括其他实验。为此问题,我们提出了一种更简单的单环参数自由规范化政策梯度算法。通过实现递归运动变量减少机制,我们的算法实现了$\tilde{\mathcal{O}}(\epsilon^{-3})$和$\tilde{\mathcal{O}}(\epsilon^{-2})$样品复杂度,分别为$\epsilon$-first-order stationarity和$\epsilon$-global optimality,在适当假设下。

**[Paper URL](https://proceedings.mlr.press/v202/barakat23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/barakat23a/barakat23a.pdf)** 

# Interpretable Neural-Symbolic Concept Reasoning
**题目:** 可解释的神经-符号概念推理

**作者:** Pietro Barbiero, Gabriele Ciravegna, Francesco Giannini, Mateo Espinosa Zarlenga, Lucie Charlotte Magister, Alberto Tonda, Pietro Lio, Frederic Precioso, Mateja Jamnik, Giuseppe Marra

**Abstract:** Deep learning methods are highly accurate, yet their opaque decision process prevents them from earning full human trust. Concept-based models aim to address this issue by learning tasks based on a set of human-understandable concepts. However, state-of-the-art concept-based models rely on high-dimensional concept embedding representations which lack a clear semantic meaning, thus questioning the interpretability of their decision process. To overcome this limitation, we propose the Deep Concept Reasoner (DCR), the first interpretable concept-based model that builds upon concept embeddings. In DCR, neural networks do not make task predictions directly, but they build syntactic rule structures using concept embeddings. DCR then executes these rules on meaningful concept truth degrees to provide a final interpretable and semantically-consistent prediction in a differentiable manner. Our experiments show that DCR: (i) improves up to +25% w.r.t. state-of-the-art interpretable concept-based models on challenging benchmarks (ii) discovers meaningful logic rules matching known ground truths even in the absence of concept supervision during training, and (iii), facilitates the generation of counterfactual examples providing the learnt rules as guidance.

**摘要:** 基于概念的模型旨在通过基于一套人类理解的概念的学习任务来解决这一问题。然而,最先进的基于概念的模型依赖于高维的概念嵌入表示,缺乏清晰的语义意义,从而质疑其决策过程的解释性。为了克服这一限制,我们提出了 Deep Concept Reasoner(DCR),第一个基于概念嵌入的可解释的概念模型。基于挑战性指标的最先进的可解释的概念模型(ii)发现具有意义的逻辑规则,即使在训练过程中没有概念监督,也符合已知的事实,并(iii)促进生成反事实实例,提供学到的规则作为指导。

**[Paper URL](https://proceedings.mlr.press/v202/barbiero23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/barbiero23a/barbiero23a.pdf)** 

# Moccasin: Efficient Tensor Rematerialization for Neural Networks
**题目:** 莫卡辛:神经网络的有效张力再材料化

**作者:** Burak Bartan, Haoming Li, Harris Teague, Christopher Lott, Bistra Dilkina

**Abstract:** The deployment and training of neural networks on edge computing devices pose many challenges. The low memory nature of edge devices is often one of the biggest limiting factors encountered in the deployment of large neural network models. Tensor rematerialization or recompute is a way to address high memory requirements for neural network training and inference. In this paper we consider the problem of execution time minimization of compute graphs subject to a memory budget. In particular, we develop a new constraint programming formulation called Moccasin with only $O(n)$ integer variables, where $n$ is the number of nodes in the compute graph. This is a significant improvement over the works in the recent literature that propose formulations with $O(n^2)$ Boolean variables. We present numerical studies that show that our approach is up to an order of magnitude faster than recent work especially for large-scale graphs.

**摘要:** 在边缘计算设备上神经网络的部署和培训提出了许多挑战。边缘设备的低内存性质往往是在部署大型神经网络模型时遇到的最大限制因素之一。网格重构或重新计算是解决神经网络培训和推导的高内存需求的一种方法。本论文考虑了执行时间最小化计算图的 memory budget问题。特别是,我们开发了一个新的约束编程公式,叫做Moccasin,它只包含$O(n)$整数变量,其中$n$是计算图中节点的数目。

**[Paper URL](https://proceedings.mlr.press/v202/bartan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bartan23a/bartan23a.pdf)** 

# User-level Private Stochastic Convex Optimization with Optimal Rates
**题目:** 最优率的用户级私人随机凸优化

**作者:** Raef Bassily, Ziteng Sun

**Abstract:** We study the problem of differentially private (DP) stochastic convex optimization (SCO) under the notion of user-level differential privacy. In this problem, there are $n$ users, each contributing $m>1$ samples to the input dataset of the private SCO algorithm, and the notion of indistinguishability embedded in DP is w.r.t. replacing the entire local dataset of any given user. Under smoothness conditions of the loss, we establish the optimal rates for user-level DP-SCO in both the central and local models of DP. In particular, we show, roughly, that the optimal rate is $\frac{1}{\sqrt{nm}}+\frac{\sqrt{d}}{\varepsilon n \sqrt{m}}$ in the central setting and is $\frac{\sqrt{d}}{\varepsilon \sqrt{nm}}$ in the local setting, where $d$ is the dimensionality of the problem and $\varepsilon$ is the privacy parameter. Our algorithms combine new user-level DP mean estimation techniques with carefully designed first-order stochastic optimization methods. For the central DP setting, our optimal rate improves over the rate attained for the same setting in Levy et al. (2021) by $\sqrt{d}$ factor. One of the main ingredients that enabled such an improvement is a novel application of the generalization properties of DP in the context of multi-pass stochastic gradient methods.

**摘要:** 在用户级微分隐私的概念下,我们研究了微分私有(DP)随机凸优化(SCO)问题。在这个问题中,有$n$用户,每个贡献$m>1$样本到私人SCO算法的输入数据集,而嵌入在DP的不可区分的概念是W.r.t.取代任何给定的用户整个本地数据集。在损失的平滑条件下,我们在DP的中央和局部模型中确定了用户级DP-SCO的最佳率。对于中央的DP设置,我们的最佳速度以$sqrt{d}$因子比勒维等人(英语:Levy et al.)在2021年所取得的相同设置的速度提高。

**[Paper URL](https://proceedings.mlr.press/v202/bassily23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bassily23a/bassily23a.pdf)** 

# A Statistical Perspective on Retrieval-Based Models
**题目:** 基于检索模型的统计视角

**作者:** Soumya Basu, Ankit Singh Rawat, Manzil Zaheer

**Abstract:** Many modern high-performing machine learning models increasingly rely on scaling up models, e.g., transformer networks. Simultaneously, a parallel line of work aims to improve the model performance by augmenting an input instance with other (labeled) instances during inference. Examples of such augmentations include task-specific prompts and similar examples retrieved from the training data by a nonparametric component. Despite a growing literature showcasing the promise of these retrieval-based models, their theoretical underpinnings %for such models remain under-explored. In this paper, we present a formal treatment of retrieval-based models to characterize their performance via a novel statistical perspective. In particular, we study two broad classes of retrieval-based classification approaches: First, we analyze a local learning framework that employs an explicit local empirical risk minimization based on retrieved examples for each input instance. Interestingly, we show that breaking down the underlying learning task into local sub-tasks enables the model to employ a low complexity parametric component to ensure good overall performance. The second class of retrieval-based approaches we explore learns a global model using kernel methods to directly map an input instance and retrieved examples to a prediction, without explicitly solving a local learning task.

**摘要:** 许多现代高性能机器学习模型越来越多地依赖于扩展模型,例如变换器网络。同时,一个平行工作线的目标是通过在推导过程中将输入实例增加到其他(标记)实例来提高模型性能。此类增加的例子包括特定任务的提示和由非参数组件从训练数据中检索的类似实例。尽管越来越多的文献显示了这些基于检索的模型的前景,但这些模型的理论基础仍未得到充分研究。有趣的是,我们证明将基础学习任务分解为局部子任务,使模型能够使用低复杂度参数组件,确保良好的整体性能。我们研究的第二类检索性方法使用内核方法直接绘制一个输入实例,并将检索的实例映射到预测中,而不明确地解决一个局部学习任务。

**[Paper URL](https://proceedings.mlr.press/v202/basu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/basu23a/basu23a.pdf)** 

# Human-Timescale Adaptation in an Open-Ended Task Space
**题目:** 开放任务空间的人类时间尺度适应

**作者:** Jakob Bauer, Kate Baumli, Feryal Behbahani, Avishkar Bhoopchand, Nathalie Bradley-Schmieg, Michael Chang, Natalie Clay, Adrian Collister, Vibhavari Dasagi, Lucy Gonzalez, Karol Gregor, Edward Hughes, Sheleem Kashem, Maria Loks-Thompson, Hannah Openshaw, Jack Parker-Holder, Shreya Pathak, Nicolas Perez-Nieves, Nemanja Rakicevic, Tim Rocktäschel, Yannick Schroecker, Satinder Singh, Jakub Sygnowski, Karl Tuyls, Sarah York, Alexander Zacherl, Lei M Zhang

**Abstract:** Foundation models have shown impressive adaptation and scalability in supervised and self-supervised learning problems, but so far these successes have not fully translated to reinforcement learning (RL). In this work, we demonstrate that training an RL agent at scale leads to a general in-context learning algorithm that can adapt to open-ended novel embodied 3D problems as quickly as humans. In a vast space of held-out environment dynamics, our adaptive agent (AdA) displays on-the-fly hypothesis-driven exploration, efficient exploitation of acquired knowledge, and can successfully be prompted with first-person demonstrations. Adaptation emerges from three ingredients: (1) meta-reinforcement learning across a vast, smooth and diverse task distribution, (2) a policy parameterised as a large-scale attention-based memory architecture, and (3) an effective automated curriculum that prioritises tasks at the frontier of an agent’s capabilities. We demonstrate characteristic scaling laws with respect to network size, memory length, and richness of the training task distribution. We believe our results lay the foundation for increasingly general and adaptive RL agents that perform well across ever-larger open-ended domains.

**摘要:** 基础模型在监督和自我监督的学习问题中显示出令人印象深刻的适应性和可扩展性,但到目前为止这些成功尚未完全转化为强化学习(RL)。在这项工作中,我们证明,在规模上培训一个RL代理人会导致一个通用的上下文学习算法,能够像人类一样迅速适应开放的新型体现的3D问题。在一个广泛的保持环境动力学空间中,我们的适应代理人(AdA)展示着即时假设驱动的探索、有效利用所获得的知识,并能够成功地通过第一人称的演示来推动。我们证明了网络大小、内存长度和训练任务分布的丰富性的特点,我们相信我们的结果为日益通用和适应性的RL代理提供了基础,它们在越来越大的开放域中表现得很好。

**[Paper URL](https://proceedings.mlr.press/v202/bauer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bauer23a/bauer23a.pdf)** 

# A Kernel Stein Test of Goodness of Fit for Sequential Models
**题目:** 对序列模型的适度 Kernel Stein 测试

**作者:** Jerome Baum, Heishiro Kanagawa, Arthur Gretton

**Abstract:** We propose a goodness-of-fit measure for probability densities modeling observations with varying dimensionality, such as text documents of differing lengths or variable-length sequences. The proposed measure is an instance of the kernel Stein discrepancy (KSD), which has been used to construct goodness-of-fit tests for unnormalized densities. The KSD is defined by its Stein operator: current operators used in testing apply to fixed-dimensional spaces. As our main contribution, we extend the KSD to the variable-dimension setting by identifying appropriate Stein operators, and propose a novel KSD goodness-of-fit test. As with the previous variants, the proposed KSD does not require the density to be normalized, allowing the evaluation of a large class of models. Our test is shown to perform well in practice on discrete sequential data benchmarks.

**摘要:** 我们提出了一种用于不同维度的概率密度建模观测的适度度测量方法,例如不同长度的文本文档或变长度序列。该方法是 Kernel Stein discrepancy(KSD)的一个实例,它被用来构造非正常密度的适度测试。KSD由其Stein算子定义:在测试中使用的当前算子适用于固定维空间。作为我们的主要贡献,我们通过识别适当的Stein算子来扩展KSD到变长度设置,并提出一种新颖的KSD适度测试方法。

**[Paper URL](https://proceedings.mlr.press/v202/baum23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/baum23a/baum23a.pdf)** 

# Individually Fair Learning with One-Sided Feedback
**题目:** 基于单边反馈的个人公平学习

**作者:** Yahav Bechavod, Aaron Roth

**Abstract:** We consider an online learning problem with one-sided feedback, in which the learner is able to observe the true label only for positively predicted instances. On each round, $k$ instances arrive and receive classification outcomes according to a randomized policy deployed by the learner, whose goal is to maximize accuracy while deploying individually fair policies. We first present a novel auditing scheme, capable of utilizing feedback from dynamically-selected panels of multiple, possibly inconsistent, auditors regarding fairness violations. In particular, we show how our proposed auditing scheme allows for algorithmically exploring the resulting accuracy-fairness frontier, with no need for additional feedback from auditors. We then present an efficient reduction from our problem of online learning with one-sided feedback and a panel reporting fairness violations to the contextual combinatorial semi-bandit problem (Cesa-Bianchi & Lugosi, 2009; Gyorgy et al., 2007), allowing us to leverage algorithms for contextual combinatorial semi-bandits to establish multi-criteria no regret guarantees in our setting, simultaneously for accuracy and fairness. Our results eliminate two potential sources of bias from prior work: the “hidden outcomes” that are not available to an algorithm operating in the full information setting, and human biases that might be present in any single human auditor, but can be mitigated by selecting a well-chosen panel.

**摘要:** 我们考虑了一个单边反馈的在线学习问题,在其中学习者能够只观察正面预测的实例的真正标签。每轮,$k$实例到达并根据由学习者部署的随机化政策获得分类结果,其目标是在部署个别公平政策的同时最大化准确性。我们首先提出了一种新的审计方案,能够从动态选择的多个、可能不一致的审计员的反馈中利用对公平的违反情况的反馈。然后,我们通过单方面反馈和一个公平性侵犯的小组对上下文组合性半带子问题进行了有效的减少(Cesa-Bianchi & Lugosi, 2009; Gyorgy et al., 2007),使我们能够利用上下文组合性半带子算法在我们的设置中建立多标准,同时确保准确性和公平性。

**[Paper URL](https://proceedings.mlr.press/v202/bechavod23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bechavod23a/bechavod23a.pdf)** 

# Predicting Ordinary Differential Equations with Transformers
**题目:** 预测变换器的普通差分方程

**作者:** Sören Becker, Michal Klein, Alexander Neitz, Giambattista Parascandolo, Niki Kilbertus

**Abstract:** We develop a transformer-based sequence-to-sequence model that recovers scalar ordinary differential equations (ODEs) in symbolic form from irregularly sampled and noisy observations of a single solution trajectory. We demonstrate in extensive empirical evaluations that our model performs better or on par with existing methods in terms of accurate recovery across various settings. Moreover, our method is efficiently scalable: after one-time pretraining on a large set of ODEs, we can infer the governing law of a new observed solution in a few forward passes of the model.

**摘要:** 我们开发了一个基于变换器的序列-到序列模型,从单一解轨迹的不规则样本和噪声观测中以符号形式恢复阶级普通微分方程(ODEs)。我们在广泛的实证评价中证明,我们的模型在不同环境下的精确恢复方面表现得更好或与现有方法相等。此外,我们的方法可有效扩展:在大规模ODEs的一次预训练后,我们可以在模型的几个进路中推导新的观察解的治理法。

**[Paper URL](https://proceedings.mlr.press/v202/becker23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/becker23a/becker23a.pdf)** 

# Explaining Reinforcement Learning with Shapley Values
**题目:** 用沙普利价值解释强化学习

**作者:** Daniel Beechey, Thomas M. S. Smith, Özgür Şimşek

**Abstract:** For reinforcement learning systems to be widely adopted, their users must understand and trust them. We present a theoretical analysis of explaining reinforcement learning using Shapley values, following a principled approach from game theory for identifying the contribution of individual players to the outcome of a cooperative game. We call this general framework Shapley Values for Explaining Reinforcement Learning (SVERL). Our analysis exposes the limitations of earlier uses of Shapley values in reinforcement learning. We then develop an approach that uses Shapley values to explain agent performance. In a variety of domains, SVERL produces meaningful explanations that match and supplement human intuition.

**摘要:** 为了广泛采用强化学习系统,其用户必须理解和信任它们。我们提出了利用Shapley值解释强化学习的理论分析,从游戏理论出发,以确定个体玩家对合作游戏的结果的贡献为原则。我们称之为SVERL(Shapley Values for Explaining Reinforcement Learning)的一般框架。我们的分析揭示了早期在强化学习中使用Shapley值的局限性。然后我们开发了利用Shapley值解释代理性能的方法。在多种领域中,SVERL产生符合人类直觉的有意义的解释。

**[Paper URL](https://proceedings.mlr.press/v202/beechey23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/beechey23a/beechey23a.pdf)** 

# TIDE: Time Derivative Diffusion for Deep Learning on Graphs
**题目:** TIDE:基于图表的深度学习时间导数扩散

**作者:** Maysam Behmanesh, Maximilian Krahn, Maks Ovsjanikov

**Abstract:** A prominent paradigm for graph neural networks is based on the message-passing framework. In this framework, information communication is realized only between neighboring nodes. The challenge of approaches that use this paradigm is to ensure efficient and accurate long-distance communication between nodes, as deep convolutional networks are prone to over smoothing. In this paper, we present a novel method based on time derivative graph diffusion (TIDE) to overcome these structural limitations of the message-passing framework. Our approach allows for optimizing the spatial extent of diffusion across various tasks and network channels, thus enabling medium and long-distance communication efficiently. Furthermore, we show that our architecture design also enables local message-passing and thus inherits from the capabilities of local message-passing approaches. We show that on both widely used graph benchmarks and synthetic mesh and graph datasets, the proposed framework outperforms state-of-the-art methods by a significant margin.

**摘要:** 图神经网络的一个突出的范式是基于消息传递框架,在该框架中,信息通信只实现邻接节点之间。使用该范式的方法的挑战是确保节点间的有效和准确的长距离通信,因为深层卷曲网络容易过滑。本论文提出了基于时间派生图扩散(TIDE)的新方法来克服这些消息传递框架的结构性局限性。我们的方法允许在各种任务和网络渠道中优化扩散的空间范围,从而有效地实现中长距离通信。结果表明,在广泛应用的图标基准和合成网格和图数据集上,该框架的性能远远超过了最先进的方法。

**[Paper URL](https://proceedings.mlr.press/v202/behmanesh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/behmanesh23a/behmanesh23a.pdf)** 

# Fast as CHITA: Neural Network Pruning with Combinatorial Optimization
**题目:** CHITA的速度:神经网络 Pruning与组合优化

**作者:** Riade Benbaki, Wenyu Chen, Xiang Meng, Hussein Hazimeh, Natalia Ponomareva, Zhe Zhao, Rahul Mazumder

**Abstract:** The sheer size of modern neural networks makes model serving a serious computational challenge. A popular class of compression techniques overcomes this challenge by pruning or sparsifying the weights of pretrained networks. While useful, these techniques often face serious tradeoffs between computational requirements and compression quality. In this work, we propose a novel optimization-based pruning framework that considers the combined effect of pruning (and updating) multiple weights subject to a sparsity constraint. Our approach, CHITA, extends the classical Optimal Brain Surgeon framework and results in significant improvements in speed, memory, and performance over existing optimization-based approaches for network pruning. CHITA’s main workhorse performs combinatorial optimization updates on a memory-friendly representation of local quadratic approximation(s) of the loss function. On a standard benchmark of pretrained models and datasets, CHITA leads to superior sparsity-accuracy tradeoffs than competing methods. For example, for MLPNet with only 2% of the weights retained, our approach improves the accuracy by 63% relative to the state of the art. Furthermore, when used in conjunction with fine-tuning SGD steps, our method achieves significant accuracy gains over state-of-the-art approaches. Our code is publicly available at: https://github.com/mazumder-lab/CHITA .

**摘要:** 现代神经网络的纯体大小使得模型提供了一个严重的计算挑战。一种流行的压缩技术通过剪切或稀释预留网络的重量来克服这一挑战。尽管这些技术有用,但它们经常面临计算要求和压缩质量之间的严重折衷。在这个工作中,我们提出了一种基于优化的剪切框架,它考虑到剪切(和更新)多重重量的结合效应受稀释约束。我们的方法,CHITA,扩展了传统的最佳脑外科医生框架,并在现有的基于优化的网络剪切方法中大幅改善速度、记忆和性能。CHITA的主要工作horse执行了对丢失函数的局部二次近似(s)的记忆友好表示的组合优化更新。在预制模型和数据集的标准基准上,CHITA比竞争方法更优越的稀疏精度折衷。例如,对于MLPNet只保留了2%的重量,我们的方法提高了精度的63 %,相对于最新技术。此外,当与精细调制SGD步骤结合时,我们的方法在最先进的方法上取得了显著的精度提升。

**[Paper URL](https://proceedings.mlr.press/v202/benbaki23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/benbaki23a/benbaki23a.pdf)** 

# Continuously Parameterized Mixture Models
**题目:** 连续参数化混合物模型

**作者:** Christopher M Bender, Yifeng Shi, Marc Niethammer, Junier Oliva

**Abstract:** Mixture models are universal approximators of smooth densities but are difficult to utilize in complicated datasets due to restrictions on typically available modes and challenges with initialiations. We show that by continuously parameterizing a mixture of factor analyzers using a learned ordinary differential equation, we can improve the fit of mixture models over direct methods. Once trained, the mixture components can be extracted and the neural ODE can be discarded, leaving us with an effective, but low-resource model. We additionally explore the use of a training curriculum from an easy-to-model latent space extracted from a normalizing flow to the more complex input space and show that the smooth curriculum helps to stabilize and improve results with and without the continuous parameterization. Finally, we introduce a hierarchical version of the model to enable more flexible, robust classification and clustering, and show substantial improvements against traditional parameterizations of GMMs.

**摘要:** 混合模型是平坦密度的通用近似器,但由于通常可用模式和初始化挑战的限制,很难在复杂数据集中使用。我们证明,通过不断参数化因子分析器的混合,通过学习的普通微分方程,我们可以改进混合模型的匹配性,超过直接方法。一旦训练,混合组件可以提取,神经ODE可以丢弃,使我们拥有一个有效的,但低资源的模型。我们还进一步探讨从正常化流向更复杂的输入空间提取的易于模型隐藏空间的训练课程的使用,并表明,平坦课程有助于稳定和改善连续参数化的结果。最后,介绍了该模型的层次化版本,使该模型具有更灵活、更牢固的分类和聚类功能,与传统的GMM参数化相比取得了显著的改进。

**[Paper URL](https://proceedings.mlr.press/v202/bender23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bender23a/bender23a.pdf)** 

# Controllable Neural Symbolic Regression
**题目:** 可控神经符号回归

**作者:** Tommaso Bendinelli, Luca Biggio, Pierre-Alexandre Kamienny

**Abstract:** In symbolic regression, the objective is to find an analytical expression that accurately fits experimental data with the minimal use of mathematical symbols such as operators, variables, and constants. However, the combinatorial space of possible expressions can make it challenging for traditional evolutionary algorithms to find the correct expression in a reasonable amount of time. To address this issue, Neural Symbolic Regression (NSR) algorithms have been developed that can quickly identify patterns in the data and generate analytical expressions. However, these methods, in their current form, lack the capability to incorporate user-defined prior knowledge, which is often required in natural sciences and engineering fields. To overcome this limitation, we propose a novel neural symbolic regression method, named Neural Symbolic Regression with Hypothesis (NSRwH) that enables the explicit incorporation of assumptions about the expected structure of the ground-truth expression into the prediction process. Our experiments demonstrate that the proposed conditioned deep learning model outperforms its unconditioned counterparts in terms of accuracy while also providing control over the predicted expression structure.

**摘要:** 在符号回归中,目标是找到准确地与算符、变量和常数等数学符号的最小使用相适应的实验数据的分析表达式。然而,可能表达式的组合空间使得传统进化算法在合理的时间内找到正确的表达式具有挑战性。为了解决这个问题,已经开发了能快速识别数据中的模式和产生分析表达式的神经符号回归算法。为了克服这一局限性,我们提出了一种新的神经符号回归方法,称为Neural Symbolic Regression with Hypothesis(NSRwH),该方法能够明确地将关于地面真实表达结构的假设纳入预测过程。

**[Paper URL](https://proceedings.mlr.press/v202/bendinelli23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bendinelli23a/bendinelli23a.pdf)** 

# On Second-Order Scoring Rules for Epistemic Uncertainty Quantification
**题目:** 基于二阶分数规则的pistemic不确定性定量

**作者:** Viktor Bengs, Eyke Hüllermeier, Willem Waegeman

**Abstract:** It is well known that accurate probabilistic predictors can be trained through empirical risk minimisation with proper scoring rules as loss functions. While such learners capture so-called aleatoric uncertainty of predictions, various machine learning methods have recently been developed with the goal to let the learner also represent its epistemic uncertainty, i.e., the uncertainty caused by a lack of knowledge and data. An emerging branch of the literature proposes the use of a second-order learner that provides predictions in terms of distributions on probability distributions. However, recent work has revealed serious theoretical shortcomings for second-order predictors based on loss minimisation. In this paper, we generalise these findings and prove a more fundamental result: There seems to be no loss function that provides an incentive for a second-order learner to faithfully represent its epistemic uncertainty in the same manner as proper scoring rules do for standard (first-order) learners. As a main mathematical tool to prove this result, we introduce the generalised notion of second-order scoring rules.

**摘要:** 众所周知,通过经验风险最小化来训练准确的概率预测者,以适当的分数规则作为损失函数。虽然这些学习者捕捉到所谓的预测的随机不确定性,但最近有各种机器学习方法被开发,目的是让学习者代表其pistemic不确定性,即由于缺乏知识和数据所引起的不确定性。在本文中,我们将这些发现归纳为一般化,并证明了一个更基本的结果: 似乎没有一种损失函数,以鼓励第二阶学生忠实地表现其pistemic不确定性,正如标准(第一阶)学生所采用的适当评分规则一样。

**[Paper URL](https://proceedings.mlr.press/v202/bengs23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bengs23a/bengs23a.pdf)** 

# Certified Robust Neural Networks: Generalization and Corruption Resistance
**题目:** 认证鲁棒神经网络:一般化与反腐败

**作者:** Amine Bennouna, Ryan Lucas, Bart Van Parys

**Abstract:** Recent work have demonstrated that robustness (to "corruption") can be at odds with generalization. Adversarial training, for instance, aims to reduce the problematic susceptibility of modern neural networks to small data perturbations. Surprisingly, overfitting is a major concern in adversarial training despite being mostly absent in standard training. We provide here theoretical evidence for this peculiar “robust overfitting” phenomenon. Subsequently, we advance a novel distributionally robust loss function bridging robustness and generalization. We demonstrate both theoretically as well as empirically the loss to enjoy a certified level of robustness against two common types of corruption|data evasion and poisoning attacks|while ensuring guaranteed generalization. We show through careful numerical experiments that our resulting holistic robust (HR) training procedure yields SOTA performance. Finally, we indicate that HR training can be interpreted as a direct extension of adversarial training and comes with a negligible additional computational burden. A ready-to-use python library implementing our algorithm is available at https://github.com/RyanLucas3/HR_Neural_Networks.

**摘要:** 最近的研究表明,鲁棒性(对“腐败”)可能与一般化相抵触。例如,敌对训练旨在减少现代神经网络对小数据干扰的敏感性问题。令人惊奇的是,在敌对训练中,超标是一个主要问题,尽管在标准训练中几乎没有出现。我们在此提供了关于这种特殊的“鲁棒超标”现象的理论证据。最后,我们指出,人力资源培训可以被解释为敌对培训的直接扩展,并伴随一个忽略不计的额外的计算负担。可用的 Python库实现我们的算法可以在 https://github.com/RyanLucas3/HR_Neural_Networks上。

**[Paper URL](https://proceedings.mlr.press/v202/bennouna23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bennouna23a/bennouna23a.pdf)** 

# Gaussian processes at the Helm(holtz): A more fluid model for ocean currents
**题目:** Helm(holtz)的高斯过程:海洋流的更流动模型

**作者:** Renato Berlinghieri, Brian L. Trippe, David R. Burt, Ryan James Giordano, Kaushik Srinivasan, Tamay Özgökmen, Junfei Xia, Tamara Broderick

**Abstract:** Oceanographers are interested in predicting ocean currents and identifying divergences in a current vector field based on sparse observations of buoy velocities. Since we expect current dynamics to be smooth but highly non-linear, Gaussian processes (GPs) offer an attractive model. But we show that applying a GP with a standard stationary kernel directly to buoy data can struggle at both current prediction and divergence identification – due to some physically unrealistic prior assumptions. To better reflect known physical properties of currents, we propose to instead put a standard stationary kernel on the divergence and curl-free components of a vector field obtained through a Helmholtz decomposition. We show that, because this decomposition relates to the original vector field just via mixed partial derivatives, we can still perform inference given the original data with only a small constant multiple of additional computational expense. We illustrate the benefits of our method on synthetic and real oceans data.

**摘要:** 海洋学家对基于稀疏的浮游速度观测的海洋流线场的预测和鉴别偏差感兴趣。由于我们期望流线动力学是平滑的,但高度非线性,高斯过程(GPs)提供了一个引人注目的模型。但我们证明,应用标准静态核直接浮游数据的GP可以对流线的预测和偏差识别作斗争 — — 因为某些物理上不现实的先前假设。为了更好地反映流线的已知物理性质,我们建议将标准静态核置于通过赫尔姆霍兹分解获得的向量场的偏差和无曲线成分上。我们说明了我们对海洋数据的合成和实际数据的方法的优点。

**[Paper URL](https://proceedings.mlr.press/v202/berlinghieri23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/berlinghieri23a/berlinghieri23a.pdf)** 

# Optimal Rates and Efficient Algorithms for Online Bayesian Persuasion
**题目:** 在线贝叶斯 persuasion的优化率和有效算法

**作者:** Martino Bernasconi, Matteo Castiglioni, Andrea Celli, Alberto Marchesi, Francesco Trovò, Nicola Gatti

**Abstract:** Bayesian persuasion studies how an informed sender should influence beliefs of rational receivers that take decisions through Bayesian updating of a common prior. We focus on the online Bayesian persuasion framework, in which the sender repeatedly faces one or more receivers with unknown and adversarially selected types. First, we show how to obtain a tight $\tilde O(T^{1/2})$ regret bound in the case in which the sender faces a single receiver and has bandit feedback, improving over the best previously known bound of $\tilde O(T^{4/5})$. Then, we provide the first no-regret guarantees for the multi-receiver setting under bandit feedback. Finally, we show how to design no-regret algorithms with polynomial per-iteration running time by exploiting type reporting, thereby circumventing known complexity results on online Bayesian persuasion. We provide efficient algorithms guaranteeing a $O(T^{1/2})$ regret upper bound both in the single- and multi-receiver scenario when type reporting is allowed.

**摘要:** 贝叶斯说服研究如何让一个知情的发送者影响合理接收者的信念,通过贝叶斯更新一个共同的预先作出决定。我们着眼于网络贝叶斯说服框架,在该框架中,发送者反复面对一个或多个与未知和敌对选择类型的接收者。首先,我们展示了如何在发送者面对一个单个接收者并有带有带有带有反馈的案例中获得一个紧缩的$\tilde O(T^{1/2})$遗憾约束,改进了带有反馈的$\tilde O(T^{4/5})$的最已知的约束。然后,我们为带有带有反馈的多接收者设置提供了第一个带有约束的保证。最后,我们展示了如何设计带有多项式的带有重复运行时间的带有约束的算法,通过利用类型报告,从而绕过当允许类型报告时,我们提供了有效的算法,保证单个和多个接收者场景中$O(T^{1/2})$ regret上界。

**[Paper URL](https://proceedings.mlr.press/v202/bernasconi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bernasconi23a/bernasconi23a.pdf)** 

# Constrained Phi-Equilibria
**题目:** 限制性非平衡生物

**作者:** Martino Bernasconi, Matteo Castiglioni, Alberto Marchesi, Francesco Trovò, Nicola Gatti

**Abstract:** The computational study of equilibria involving constraints on players’ strategies has been largely neglected. However, in real-world applications, players are usually subject to constraints ruling out the feasibility of some of their strategies, such as, e.g., safety requirements and budget caps. Computational studies on constrained versions of the Nash equilibrium have lead to some results under very stringent assumptions, while finding constrained versions of the correlated equilibrium (CE) is still unexplored. In this paper, we introduce and computationally characterize constrained Phi-equilibria—a more general notion than constrained CEs—in normal-form games. We show that computing such equilibria is in general computationally intractable, and also that the set of the equilibria may not be convex, providing a sharp divide with unconstrained CEs. Nevertheless, we provide a polynomial-time algorithm for computing a constrained (approximate) Phi-equilibrium maximizing a given linear function, when either the number of constraints or that of players’ actions is fixed. Moreover, in the special case in which a player’s constraints do not depend on other players’ strategies, we show that an exact, function-maximizing equilibrium can be computed in polynomial time, while one (approximate) equilibrium can be found with an efficient decentralized no-regret learning algorithm.

**摘要:** 然而,在现实世界中的应用中,玩家通常会受到限制,以排除其某些策略的可行性,例如安全要求和预算上限。对纳什均衡的约束版本的计算研究在非常严格的假设下导致了一些结果,同时发现相关均衡(CE)的约束版本仍然未被探索。尽管如此,我们提供了多项式时间算法来计算一个限制的(近似)最大化给定线性函数的Py平衡,当限制的数量或玩家行动的数量是固定的。 此外,在特殊情况下,一个玩家的限制不依赖于其他玩家的战略,我们证明一个准确的函数最大化平衡可以在多项式时间计算,而一个(近似)平衡可以在高效的分散无悔学习算法中找到。

**[Paper URL](https://proceedings.mlr.press/v202/bernasconi23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bernasconi23b/bernasconi23b.pdf)** 

# Differentiable and Transportable Structure Learning
**题目:** 可辨别和可运输结构学习

**作者:** Jeroen Berrevoets, Nabeel Seedat, Fergus Imrie, Mihaela Van Der Schaar

**Abstract:** Directed acyclic graphs (DAGs) encode a lot of information about a particular distribution in their structure. However, compute required to infer these structures is typically super-exponential in the number of variables, as inference requires a sweep of a combinatorially large space of potential structures. That is, until recent advances made it possible to search this space using a differentiable metric, drastically reducing search time. While this technique— named NOTEARS —is widely considered a seminal work in DAG-discovery, it concedes an important property in favour of differentiability: transportability. To be transportable, the structures discovered on one dataset must apply to another dataset from the same domain. We introduce D-Struct which recovers transportability in the discovered structures through a novel architecture and loss function while remaining fully differentiable. Because D-Struct remains differentiable, our method can be easily adopted in existing differentiable architectures, as was previously done with NOTEARS. In our experiments, we empirically validate D-Struct with respect to edge accuracy and structural Hamming distance in a variety of settings.

**摘要:** 指示环形图(DAGs)编码许多关于其结构中的特定分布的信息。然而,推导这些结构所需的计算通常在变量数量上是超指数的,因为推导需要对潜在结构的组合性大的空间进行扫荡。也就是说,直到最近的进步使得使用可分化度量来搜索这个空间,大大减少搜索时间。由于D-Struct仍然是可微分的,所以我们的方法可以在现有可微分的架构中轻易地采用,如以前的诺塔斯方法。在我们的实验中,我们对D-Struct的边缘精度和结构哈mming距离在各种环境中进行了实证验证。

**[Paper URL](https://proceedings.mlr.press/v202/berrevoets23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/berrevoets23a/berrevoets23a.pdf)** 

# Polyhedral Complex Extraction from ReLU Networks using Edge Subdivision
**题目:** 利用边缘分区从ReLU网络中提取多面复合体

**作者:** Arturs Berzins

**Abstract:** A neural network consisting of piecewise affine building blocks, such as fully-connected layers and ReLU activations, is itself a piecewise affine function supported on a polyhedral complex. This complex has been previously studied to characterize theoretical properties of neural networks, but, in practice, extracting it remains a challenge due to its high combinatorial complexity. A natural idea described in previous works is to subdivide the regions via intersections with hyperplanes induced by each neuron. However, we argue that this view leads to computational redundancy. Instead of regions, we propose to subdivide edges, leading to a novel method for polyhedral complex extraction. A key to this are sign-vectors, which encode the combinatorial structure of the complex. Our approach allows to use standard tensor operations on a GPU, taking seconds for millions of cells on a consumer grade machine. Motivated by the growing interest in neural shape representation, we use the speed and differentiablility of our method to optimize geometric properties of the complex. The code is available at https://github.com/arturs-berzins/relu_edge_subdivision.

**摘要:** 神经网络由单片微细构件组成,如完全连接的层和ReLU活性,本身是一个单片微细函数,支持在多面体复合体上。该复合体以前曾被研究以描述神经网络的理论特性,但在实践中,由于其高组合性,提取它仍然是一个挑战。在以前的工作中描述的自然概念是通过各神经元诱导的超平面的交界分区区域。然而,我们认为这一观点导致计算冗余。由于对神经形状表示的兴趣日益增长,我们利用我们的方法的速度和可变性来优化复合体的几何特性。代码可于 https://github.com/arturs-berzins/relu_edge_subdivision 。

**[Paper URL](https://proceedings.mlr.press/v202/berzins23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/berzins23a/berzins23a.pdf)** 

# Robust One-Class Classification with Signed Distance Function using 1-Lipschitz Neural Networks
**题目:** 基于1-利普希茨神经网络的强性单级分类与符号距离函数

**作者:** Louis Béthune, Paul Novello, Guillaume Coiffier, Thibaut Boissin, Mathieu Serrurier, Quentin Vincenot, Andres Troya-Galvis

**Abstract:** We propose a new method, dubbed One Class Signed Distance Function (OCSDF), to perform One Class Classification (OCC) by provably learning the Signed Distance Function (SDF) to the boundary of the support of any distribution. The distance to the support can be interpreted as a normality score, and its approximation using 1-Lipschitz neural networks provides robustness bounds against $l2$ adversarial attacks, an under-explored weakness of deep learning-based OCC algorithms. As a result, OCSDF comes with a new metric, certified AUROC, that can be computed at the same cost as any classical AUROC. We show that OCSDF is competitive against concurrent methods on tabular and image data while being way more robust to adversarial attacks, illustrating its theoretical properties. Finally, as exploratory research perspectives, we theoretically and empirically show how OCSDF connects OCC with image generation and implicit neural surface parametrization.

**摘要:** 我们提出了一种新的方法,称为一类标记距离函数(OCSDF),以通过证明学习标记距离函数(SDF)对任何分布的支持的边界进行一类分类(OCC)。距离可以解释为正常度分数,并利用1-Lipschitz神经网络的近似提供对$l2$敌对攻击的鲁棒性边界,这是基于深度学习的OCC算法的不足探索的弱点。因此,OCSDF带有新的度量,认证的AUROC,可以同任何经典AUROC一样计算。

**[Paper URL](https://proceedings.mlr.press/v202/bethune23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bethune23a/bethune23a.pdf)** 

# Neural Algorithmic Reasoning with Causal Regularisation
**题目:** 因果调节的神经算法推理

**作者:** Beatrice Bevilacqua, Kyriacos Nikiforou, Borja Ibarz, Ioana Bica, Michela Paganini, Charles Blundell, Jovana Mitrovic, Petar Veličković

**Abstract:** Recent work on neural algorithmic reasoning has investigated the reasoning capabilities of neural networks, effectively demonstrating they can learn to execute classical algorithms on unseen data coming from the train distribution. However, the performance of existing neural reasoners significantly degrades on out-of-distribution (OOD) test data, where inputs have larger sizes. In this work, we make an important observation: there are many different inputs for which an algorithm will perform certain intermediate computations identically. This insight allows us to develop data augmentation procedures that, given an algorithm’s intermediate trajectory, produce inputs for which the target algorithm would have exactly the same next trajectory step. We ensure invariance in the next-step prediction across such inputs, by employing a self-supervised objective derived by our observation, formalised in a causal graph. We prove that the resulting method, which we call Hint-ReLIC, improves the OOD generalisation capabilities of the reasoner. We evaluate our method on the CLRS algorithmic reasoning benchmark, where we show up to 3x improvements on the OOD test data.

**摘要:** 近年来,神经算法推理研究了神经网络的推理能力,有效地证明了它们可以学习执行从列车分布而来的未见数据的经典算法。然而,现有神经推理器的性能在非分布(OOD)测试数据上显著下降,其中输入的大小较大。在这一研究中,我们做了一个重要观察:有多种不同的输入,其中一个算法将同时执行某些中间计算。我们 证明, 我们 称之为 Hint-ReLIC 的 结果 方法 改善 了 推理 器 的 OOD 一般化 能力 。 我们 在 CLRS 算法 推理 基准 上 评价 我们 的 方法, 我们 在 OOD 测试 数据 上 出现 3 倍 的 改进 。

**[Paper URL](https://proceedings.mlr.press/v202/bevilacqua23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bevilacqua23a/bevilacqua23a.pdf)** 

# Optimally-weighted Estimators of the Maximum Mean Discrepancy for Likelihood-Free Inference
**题目:** 最优权重估计量对无概率偏差的最大平均差异

**作者:** Ayush Bharti, Masha Naslidnyk, Oscar Key, Samuel Kaski, Francois-Xavier Briol

**Abstract:** Likelihood-free inference methods typically make use of a distance between simulated and real data. A common example is the maximum mean discrepancy (MMD), which has previously been used for approximate Bayesian computation, minimum distance estimation, generalised Bayesian inference, and within the nonparametric learning framework. The MMD is commonly estimated at a root-$m$ rate, where $m$ is the number of simulated samples. This can lead to significant computational challenges since a large $m$ is required to obtain an accurate estimate, which is crucial for parameter estimation. In this paper, we propose a novel estimator for the MMD with significantly improved sample complexity. The estimator is particularly well suited for computationally expensive smooth simulators with low- to mid-dimensional inputs. This claim is supported through both theoretical results and an extensive simulation study on benchmark simulators.

**摘要:** 无概率推理方法通常使用模拟和实际数据之间的距离。一个常见的例子是最大平均差异(MMD),它以前用于近似贝叶斯计算、最小距离估计、广义贝叶斯推理和非参数学习框架内。MMD通常在根$m$率下估计,$m$是模拟样品的数目。这会导致大量$m$需要获得准确的估计,这对参数估计至关重要。

**[Paper URL](https://proceedings.mlr.press/v202/bharti23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bharti23a/bharti23a.pdf)** 

# Bandit Online Linear Optimization with Hints and Queries
**题目:** 带有提示和查询的网络线性优化

**作者:** Aditya Bhaskara, Ashok Cutkosky, Ravi Kumar, Manish Purohit

**Abstract:** We study variants of the online linear optimization (OLO) problem with bandit feedback, where the algorithm has access to external information about the unknown cost vector. Our motivation is the recent body of work on using such “hints” towards improving regret bounds for OLO problems in the full-information setting. Unlike in the full-information OLO setting, with bandit feedback, we first show that one cannot improve the standard regret bounds of $\tilde{O}(\sqrt{T})$ by using hints, even if they are always well-correlated with the cost vector. In contrast, if the algorithm is empowered to issue queries and if all the responses are correct, then we show $O(\log T)$ regret is achievable. We then show how to make this result more robust—when some of the query responses can be adversarial—by using a little feedback on the quality of the responses.

**摘要:** 我们研究了在线线性优化(OLO)问题与带子反馈的变异,其中算法有访问未知成本向量外部信息的途径。我们的动机是使用这些“提示”来改善OLO问题在全信息设置中的遗憾界限的工作。与完全信息设置的OLO不同,我们首先展示了一个不能通过提示改善$\tilde{O}(\sqrt{T})$的标准遗憾界限,即使它们总是与成本向量有良好的关联。相反,如果算法被授权发布查询,如果所有响应都正确,那么我们显示$O(\log T)$遗憾是可实现的。

**[Paper URL](https://proceedings.mlr.press/v202/bhaskara23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bhaskara23a/bhaskara23a.pdf)** 

# Improved Online Conformal Prediction via Strongly Adaptive Online Learning
**题目:** 通过强适应性在线学习改进在线校准预测

**作者:** Aadyot Bhatnagar, Huan Wang, Caiming Xiong, Yu Bai

**Abstract:** We study the problem of uncertainty quantification via prediction sets, in an online setting where the data distribution may vary arbitrarily over time. Recent work develops online conformal prediction techniques that leverage regret minimization algorithms from the online learning literature to learn prediction sets with approximately valid coverage and small regret. However, standard regret minimization is insufficient for handling changing environments, where performance guarantees may be desired not only over the full time horizon but also in all (sub-)intervals of time. We develop new online conformal prediction methods that minimize the strongly adaptive regret, which measures the worst-case regret over all intervals of a fixed length. We prove that our methods achieve near-optimal strongly adaptive regret for all interval lengths simultaneously, and approximately valid coverage. Experiments show that our methods consistently obtain better coverage and smaller prediction sets than existing methods on real-world tasks such as time series forecasting and image classification under distribution shift.

**摘要:** 我们研究了基于预测集的不确定性定量问题,在在线环境下,数据分布可能随时间变化。最近的研究开发了基于在线学习文献的减少遗憾算法的在线整合预测技术,以学习具有近乎有效的覆盖范围和小遗憾的预测集。然而,标准的减少遗憾对于处理变化的环境来说不够,在整个时间范围上不仅可以要求性能保证,而且在所有(次)时间间隔中也可以要求性能保证。我们开发了新的在线整合预测方法,以减少强烈适应性遗憾,以测量所有固定长度间隔的最坏情况的遗憾。实验表明,我们的方法在分布移下的实物任务,如时间序列预测和图像分类时,比现有方法取得更好的覆盖率和较小的预测集。

**[Paper URL](https://proceedings.mlr.press/v202/bhatnagar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bhatnagar23a/bhatnagar23a.pdf)** 

# Data-Copying in Generative Models: A Formal Framework
**题目:** 生成模型中的数据复制:一个正式框架

**作者:** Robi Bhattacharjee, Sanjoy Dasgupta, Kamalika Chaudhuri

**Abstract:** There has been some recent interest in detecting and addressing memorization of training data by deep neural networks. A formal framework for memorization in generative models, called “data-copying” was proposed by Meehan et. al (2020). We build upon their work to show that their framework may fail to detect certain kinds of blatant memorization. Motivated by this and the theory of non-parametric methods, we provide an alternative definition of data-copying that applies more locally. We provide a method to detect data-copying, and provably show that it works with high probability when enough data is available. We also provide lower bounds that characterize the sample requirement for reliable detection.

**摘要:** 基于Meehan等人(2020年)提出的“数据复制”的生成模型备忘的正式框架,表明它们的框架可能无法检测某些明显的备忘。 基于此和非参数方法的理论,我们提供了一种更局部适用的数据复制的替代定义。我们提供了一种检测数据复制的方法,并证明它在足够数据可用时具有很高的概率。

**[Paper URL](https://proceedings.mlr.press/v202/bhattacharjee23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bhattacharjee23a/bhattacharjee23a.pdf)** 

# Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling
**题目:** Pythia: 跨培训和尺度分析大型语言模型的套件

**作者:** Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley, Kyle O’Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, Usvsn Sai Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, Oskar Van Der Wal

**Abstract:** How do large language models (LLMs) develop and evolve over the course of training? How do these patterns change as models scale? To answer these questions, we introduce Pythia, a suite of 16 LLMs all trained on public data seen in the exact same order and ranging in size from 70M to 12B parameters. We provide public access to 154 checkpoints for each one of the 16 models, alongside tools to download and reconstruct their exact training dataloaders for further study. We intend Pythia to facilitate research in many areas, and we present several case studies including novel results in memorization, term frequency effects on few-shot performance, and reducing gender bias. We demonstrate that this highly controlled setup can be used to yield novel insights toward LLMs and their training dynamics. Trained models, analysis code, training code, and training data can be found at https://github.com/EleutherAI/pythia.

**摘要:** 如何开发和演化大型语言模型(LLM)在训练过程中?这些模式如何变化为模型尺度?为了回答这些问题,我们介绍了Pythia,一个由16个LLM组成的套件,它们都对公共数据进行了训练,并以相同的顺序和从70M到12B参数的大小进行训练。我们为每个16个模型提供154个检查点,并提供下载和再构造其准确的训练数据载体的工具,以便进一步研究。我们打算Pythia在许多领域促进研究,并提出一些案例研究,包括记忆中新的结果, term frequency effects on few-shot performance, and reducing gender bias。

**[Paper URL](https://proceedings.mlr.press/v202/biderman23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/biderman23a/biderman23a.pdf)** 

# StriderNet: A Graph Reinforcement Learning Approach to Optimize Atomic Structures on Rough Energy Landscapes
**题目:** StriderNet:在粗能量景观上优化原子结构的图增强学习方法

**作者:** Vaibhav Bihani, Sahil Manchanda, Srikanth Sastry, Sayan Ranu, N M Anoop Krishnan

**Abstract:** Optimization of atomic structures presents a challenging problem, due to their highly rough and non-convex energy landscape, with wide applications in the fields of drug design, materials discovery, and mechanics. Here, we present a graph reinforcement learning approach, StriderNet, that learns a policy to displace the atoms towards low energy configurations. We evaluate the performance of StriderNet on three complex atomic systems, namely, binary Lennard-Jones particles, calcium silicate hydrates gel, and disordered silicon. We show that StriderNet outperforms all classical optimization algorithms and enables the discovery of a lower energy minimum. In addition, StriderNet exhibits a higher rate of reaching minima with energies, as confirmed by the average over multiple realizations. Finally, we show that StriderNet exhibits inductivity to unseen system sizes that are an order of magnitude different from the training system. All the codes and datasets are available at https://github.com/M3RG-IITD/StriderNET.

**摘要:** 原子结构的优化是一个挑战性问题,因为它具有非常粗糙和非凸的能量景观,在药物设计、材料发现和力学领域有着广泛的应用。这里,我们提出了一种图增强学习方法,StriderNet,它学习了向低能量配置转移原子的政策。我们评估StriderNet在三个复杂的原子系统上的性能,即二进制Lennard-Jones粒子、钙硅酸盐凝胶和混乱硅。所有代码和数据集可以在 https://github.com/M3RG-IITD/StriderNET上找到。

**[Paper URL](https://proceedings.mlr.press/v202/bihani23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bihani23a/bihani23a.pdf)** 

# Modeling Temporal Data as Continuous Functions with Stochastic Process Diffusion
**题目:** 随机过程扩散作为连续函数的临时数据建模

**作者:** Marin Biloš, Kashif Rasul, Anderson Schneider, Yuriy Nevmyvaka, Stephan Günnemann

**Abstract:** Temporal data such as time series can be viewed as discretized measurements of the underlying function. To build a generative model for such data we have to model the stochastic process that governs it. We propose a solution by defining the denoising diffusion model in the function space which also allows us to naturally handle irregularly-sampled observations. The forward process gradually adds noise to functions, preserving their continuity, while the learned reverse process removes the noise and returns functions as new samples. To this end, we define suitable noise sources and introduce novel denoising and score-matching models. We show how our method can be used for multivariate probabilistic forecasting and imputation, and how our model can be interpreted as a neural process.

**摘要:** 对时间序列等临时数据可视作基本函数的离散测量。为建立这种数据的生成模型,我们必须建模其管理的随机过程。我们通过定义函数空间中的噪声扩散模型,提出了一种解决办法,它还允许我们自然处理不规则的采样观察。进程过程逐渐增加噪声,保持其连续性,而学习逆过程则消除噪声并返回函数作为新的采样。为此目的,我们定义了合适的噪声源,引入了新的噪声和分数匹配模型。

**[Paper URL](https://proceedings.mlr.press/v202/bilos23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bilos23a/bilos23a.pdf)** 

# In or Out? Fixing ImageNet Out-of-Distribution Detection Evaluation
**题目:** 内置或外置? ImageNet外置分发检测评估

**作者:** Julian Bitterwolf, Maximilian Müller, Matthias Hein

**Abstract:** Out-of-distribution (OOD) detection is the problem of identifying inputs which are unrelated to the in-distribution task. The OOD detection performance when the in-distribution (ID) is ImageNet-1K is commonly being tested on a small range of test OOD datasets. We find that most of the currently used test OOD datasets, including datasets from the open set recognition (OSR) literature, have severe issues: In some cases more than 50$%$ of the dataset contains objects belonging to one of the ID classes. These erroneous samples heavily distort the evaluation of OOD detectors. As a solution, we introduce with NINCO a novel test OOD dataset, each sample checked to be ID free, which with its fine-grained range of OOD classes allows for a detailed analysis of an OOD detector’s strengths and failure modes, particularly when paired with a number of synthetic “OOD unit-tests”. We provide detailed evaluations across a large set of architectures and OOD detection methods on NINCO and the unit-tests, revealing new insights about model weaknesses and the effects of pretraining on OOD detection performance. We provide code and data at https://github.com/j-cb/NINCO.

**摘要:** Out-of-distribution(OOD)检测是与内部分配任务无关的输入识别问题。当内部分配(ID)是ImageNet-1K时的OOD检测性能通常在测试OOD数据集的小型范围内进行测试。我们发现,目前使用的大部分测试OOD数据集,包括从开放集识别(OSR)文献中的数据集,都有严重问题:在某些情况下,数据集中超过50$%$包含属于ID类的对象。这些错误的样本严重扭曲了OOD检测器的评估。在NINCO和单元测试中,我们提供了大量的架构和OOD检测方法的详细评估,揭示了模型的弱点和预训练对OOD检测性能的影响。我们提供代码和数据 https://github.com/j-cb/NINCO。

**[Paper URL](https://proceedings.mlr.press/v202/bitterwolf23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bitterwolf23a/bitterwolf23a.pdf)** 

# Invariant Slot Attention: Object Discovery with Slot-Centric Reference Frames
**题目:** 不变 Slot Attention:对象发现与 Slot-Centric参考框架

**作者:** Ondrej Biza, Sjoerd Van Steenkiste, Mehdi S. M. Sajjadi, Gamaleldin Fathy Elsayed, Aravindh Mahendran, Thomas Kipf

**Abstract:** Automatically discovering composable abstractions from raw perceptual data is a long-standing challenge in machine learning. Recent slot-based neural networks that learn about objects in a self-supervised manner have made exciting progress in this direction. However, they typically fall short at adequately capturing spatial symmetries present in the visual world, which leads to sample inefficiency, such as when entangling object appearance and pose. In this paper, we present a simple yet highly effective method for incorporating spatial symmetries via slot-centric reference frames. We incorporate equivariance to per-object pose transformations into the attention and generation mechanism of Slot Attention by translating, scaling, and rotating position encodings. These changes result in little computational overhead, are easy to implement, and can result in large gains in terms of data efficiency and overall improvements to object discovery. We evaluate our method on a wide range of synthetic object discovery benchmarks namely CLEVR, Tetrominoes, CLEVRTex, Objects Room and MultiShapeNet, and show promising improvements on the challenging real-world Waymo Open dataset.

**摘要:** 在机器学习中,自动从原始感知数据中发现可编译的抽象是长期存在的挑战。最近在自我监督下学习对象的 Slot-based neural networks 在这一方向取得了令人兴奋的进展。然而,它们通常不能充分捕捉在视觉世界中存在的空间对称,从而导致样品效率低下,例如在纠缠对象的外观和姿态时。我们对包括CLEVR、Tetrominoes、CLEVRTex、Objects Room和MultiShapeNet在内的多种合成对象发现指标的测试方法进行了评估,并展示了 challenging的现实世界Waymo Open数据集的令人期待的改进。

**[Paper URL](https://proceedings.mlr.press/v202/biza23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/biza23a/biza23a.pdf)** 

# Understanding Oversquashing in GNNs through the Lens of Effective Resistance
**题目:** 通过有效抵抗镜来理解GNN中的过度冲突

**作者:** Mitchell Black, Zhengchao Wan, Amir Nayyeri, Yusu Wang

**Abstract:** Message passing graph neural networks (GNNs) are a popular learning architectures for graph-structured data. However, one problem GNNs experience is oversquashing, where a GNN has difficulty sending information between distant nodes. Understanding and mitigating oversquashing has recently received significant attention from the research community. In this paper, we continue this line of work by analyzing oversquashing through the lens of the effective resistance between nodes in the input graph. Effective resistance intuitively captures the “strength” of connection between two nodes by paths in the graph, and has a rich literature spanning many areas of graph theory. We propose to use total effective resistance as a bound of the total amount of oversquashing in a graph and provide theoretical justification for its use. We further develop an algorithm to identify edges to be added to an input graph to minimize the total effective resistance, thereby alleviating oversquashing. We provide empirical evidence of the effectiveness of our total effective resistance based rewiring strategies for improving the performance of GNNs.

**摘要:** 信息传递图神经网络(GNNs)是图结构数据的流行学习架构。然而,GNN经验的一个问题是超标,GNN在远端节点之间发送信息时有困难。超标的理解和缓解最近受到研究界的重视。本文继续通过对输入图中的节点间有效阻抗的透镜分析超标的工作,有效阻力直观地捕捉了两个节点之间通过路径的连接的“强度”,并拥有丰富的文献,涵盖了图理论的许多领域。我们建议使用总有效阻力作为在图中超标的总数量的界限,并为其使用提供理论依据。我们进一步开发了一个算法,以识别输入图中增加的边缘,以减少总有效阻力,从而减轻超标。为提高GNN的性能,我们提供了全面有效的抗电重组策略的实证证据。

**[Paper URL](https://proceedings.mlr.press/v202/black23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/black23a/black23a.pdf)** 

# Unit Scaling: Out-of-the-Box Low-Precision Training
**题目:** 单元尺度:非盒式低精确训练

**作者:** Charlie Blake, Douglas Orr, Carlo Luschi

**Abstract:** We present unit scaling, a paradigm for designing deep learning models that simplifies the use of low-precision number formats. Training in FP16 or the recently proposed FP8 formats offers substantial efficiency gains, but can lack sufficient range for out-of-the-box training. Unit scaling addresses this by introducing a principled approach to model numerics: seeking unit variance of all weights, activations and gradients at initialisation. Unlike alternative methods, this approach neither requires multiple training runs to find a suitable scale nor has significant computational overhead. We demonstrate the efficacy of unit scaling across a range of models and optimisers. We further show that existing models can be adapted to be unit-scaled, training BERT-Large in FP16 and then FP8 with no degradation in accuracy.

**摘要:** 我们 介绍 单元 尺度, 一种 设计 深度 学习 模型 的 范式, 它 简化 了 使用 低精度 数字 格式 。 在 FP 16 或 最近 提出 的 FP 8 格式 中 的 训练 提供 了 相当 的 效率 提高, 但 可能 缺乏 足够 的 范围 来 进行 非 单元 训练 。 单元 尺度 通过 引入 模型 数值 的 原则性 方法 来 解决 这 一 问题 : 在 初始化 时 寻求 所有 重量 、 激活 和 梯度 的 单元 变异 。 与 其他 方法 不同, 这种 方法 既 不 需要 多 次 训练 

**[Paper URL](https://proceedings.mlr.press/v202/blake23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/blake23a/blake23a.pdf)** 

# FLEX: an Adaptive Exploration Algorithm for Nonlinear Systems
**题目:** FLEX:非线性系统适应性探索算法

**作者:** Matthieu Blanke, Marc Lelarge

**Abstract:** Model-based reinforcement learning is a powerful tool, but collecting data to fit an accurate model of the system can be costly. Exploring an unknown environment in a sample-efficient manner is hence of great importance. However, the complexity of dynamics and the computational limitations of real systems make this task challenging. In this work, we introduce FLEX, an exploration algorithm for nonlinear dynamics based on optimal experimental design. Our policy maximizes the information of the next step and results in an adaptive exploration algorithm, compatible with arbitrary parametric learning models, and requiring minimal computing resources. We test our method on a number of nonlinear environments covering different settings, including time-varying dynamics. Keeping in mind that exploration is intended to serve an exploitation objective, we also test our algorithm on downstream model-based classical control tasks and compare it to other state-of-the-art model-based and model-free approaches. The performance achieved by FLEX is competitive and its computational cost is low.

**摘要:** 基于模型的强化学习是一项强大的工具,但收集数据以适应系统准确的模型是昂贵的。因此,以样本效率的方式探索未知环境具有重要意义。然而,动态的复杂性和实际系统计算的局限性使得这项任务具有挑战性。本课题中,我们介绍了基于最佳实验设计的非线性动态探索算法FLEX。考虑到勘探的目的是为了实现开发目标,我们还对基于下游模型的经典控制任务的算法进行了测试,并与其他最先进的基于模型和无模型的方法进行了比较。

**[Paper URL](https://proceedings.mlr.press/v202/blanke23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/blanke23a/blanke23a.pdf)** 

# Not all Strongly Rayleigh Distributions Have Small Probabilistic Generating Circuits
**题目:** 并非所有强雷利分布都有小概率生成电路

**作者:** Markus Bläser

**Abstract:** Probabilistic modeling is a central task in machine learning. Probabilistic models should be tractable, i.e., allowing tractable probabilistic inference, but also efficient, i.e., being able to represent a large set of probability distributions. Zhang et al. (ICML 2021) recently proposed a new model, probabilistic generating circuits. They raised the question whether every strongly Rayleigh distribution can be efficiently represented by such circuits. We prove that this question has a negative answer, there are strongly Rayleigh distributions that cannot be represented by polynomial-sized probabilistic generating circuits, assuming a widely accepted complexity theoretic conjecture.

**摘要:** 概率建模是机器学习中的一个中心任务。概率建模应是可处理的,即允许可处理的概率推理,同时也是有效的,即能够代表一个大的概率分布。张等人(ICML 2021)最近提出了一种新的模型,即概率生成电路。

**[Paper URL](https://proceedings.mlr.press/v202/blaser23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/blaser23a/blaser23a.pdf)** 

# Learning the Dynamics of Sparsely Observed Interacting Systems
**题目:** 学习 sparsely observed交互系统动力学

**作者:** Linus Bleistein, Adeline Fermanian, Anne-Sophie Jannot, Agathe Guilloux

**Abstract:** We address the problem of learning the dynamics of an unknown non-parametric system linking a target and a feature time series. The feature time series is measured on a sparse and irregular grid, while we have access to only a few points of the target time series. Once learned, we can use these dynamics to predict values of the target from the previous values of the feature time series. We frame this task as learning the solution map of a controlled differential equation (CDE). By leveraging the rich theory of signatures, we are able to cast this non-linear problem as a high-dimensional linear regression. We provide an oracle bound on the prediction error which exhibits explicit dependencies on the individual-specific sampling schemes. Our theoretical results are illustrated by simulations which show that our method outperforms existing algorithms for recovering the full time series while being computationally cheap. We conclude by demonstrating its potential on real-world epidemiological data.

**摘要:** 我们解决了与目标和特征时间序列连接的未知非参数系统动态学的问题。特征时间序列在稀疏和不规则的网格上测量,而我们只能访问目标时间序列的少数点。一旦学习,我们可以使用这些动态学来预测目标的值,从特征时间序列的先前值中预测。我们把这个任务定为学习控制微分方程(CDE)的解决方案地图。通过利用丰富的签名理论,我们能够将这个非线性问题铸成高维线性回归。最后,我们通过实物流行病学数据来证明其潜力。

**[Paper URL](https://proceedings.mlr.press/v202/bleistein23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bleistein23a/bleistein23a.pdf)** 

# Subset Selection Based On Multiple Rankings in the Presence of Bias: Effectiveness of Fairness Constraints for Multiwinner Voting Score Functions
**题目:** 基于偏见存在的多个排名的子集选择:多赢投票分数函数公平约束的有效性

**作者:** Niclas Boehmer, L. Elisa Celis, Lingxiao Huang, Anay Mehrotra, Nisheeth K. Vishnoi

**Abstract:** We consider the problem of subset selection where one is given multiple rankings of items and the goal is to select the highest "quality" subset. Score functions from the multiwinner voting literature have been used to aggregate rankings into quality scores for subsets. We study this setting of subset selection problems when, in addition, rankings may contain systemic or unconscious biases toward a group of items. For a general model of input rankings and biases, we show that requiring the selected subset to satisfy group fairness constraints can improve the quality of the selection with respect to unbiased rankings. Importantly, we show that for fairness constraints to be effective, different multiwinner score functions may require a drastically different number of rankings: While for some functions, fairness constraints need an exponential number of rankings to recover a close-to-optimal solution, for others, this dependency is only polynomial. This result relies on a novel notion of "smoothness" of submodular functions in this setting that quantifies how well a function can "correctly" assess the quality of items in the presence of bias. The results in this paper can be used to guide the choice of multiwinner score functions for the subset selection setting considered here; we additionally provide a tool to empirically enable this.

**摘要:** 我们考虑了一个被赋予多个项目排名的子集选择问题,其目标是选择最高“质量”的子集。从多赢家投票文献中取得的分数函数被用来将分组的排名归纳为分组的质量分数。我们研究了该子集选择问题,因为加之,排名可能包含对项目组的系统或无意识偏见。对于输入分组和偏见的一般模型,我们表明要求选定的子集满足群公平约束可以提高对不偏见的分组的选定质量。该结果基于该设置中的子模组函数的“ Smoothness ” 的新概念,该概念量化了一个函数在偏差的情况下“正确”评估项目质量的程度。本论文的结果可用于指导对这里所考虑的子集选择设置的多赢分数函数的选择;我们还提供了一个工具,以实证化实现这一点。

**[Paper URL](https://proceedings.mlr.press/v202/boehmer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/boehmer23a/boehmer23a.pdf)** 

# Properties of the Mallows Model Depending on the Number of Alternatives: A Warning for an Experimentalist
**题目:** 基于选择数的松鼠模型的特性:一个实验者警告

**作者:** Niclas Boehmer, Piotr Faliszewski, Sonja Kraiczy

**Abstract:** The Mallows model is a popular distribution for ranked data. We empirically and theoretically analyze how the properties of rankings sampled from the Mallows model change when increasing the number of alternatives. We find that real-world data behaves differently from the Mallows model, yet is in line with its recent variant proposed by Boehmer et al. [IJCAI ’21]. As part of our study, we issue several warnings about using the classic Mallows model. For instance, we find that one should be extremely careful when using the Mallows model to generate data for experiments with a varying number of alternatives, as observed trends in such experiments might be due to the changing nature of the generated data.

**摘要:** 马洛斯模型是位列数据的一种流行的分布式,我们从经验和理论上分析了从马洛斯模型中提取的位列特性在增加选择数时如何变化。我们发现,现实世界的数据行为与马洛斯模型不同,但与博默等人提出的最近的变异是一致的[IJCAI’21]。作为我们的研究的一部分,我们对使用经典马洛斯模型发出了若干警告。

**[Paper URL](https://proceedings.mlr.press/v202/boehmer23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/boehmer23b/boehmer23b.pdf)** 

# A Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks
**题目:** 反实例指导神经网络修复的鲁棒优化视角

**作者:** David Boetius, Stefan Leue, Tobias Sutter

**Abstract:** Counterexample-guided repair aims at creating neural networks with mathematical safety guarantees, facilitating the application of neural networks in safety-critical domains. However, whether counterexample-guided repair is guaranteed to terminate remains an open question. We approach this question by showing that counterexample-guided repair can be viewed as a robust optimisation algorithm. While termination guarantees for neural network repair itself remain beyond our reach, we prove termination for more restrained machine learning models and disprove termination in a general setting. We empirically study the practical implications of our theoretical results, demonstrating the suitability of common verifiers and falsifiers for repair despite a disadvantageous theoretical result. Additionally, we use our theoretical insights to devise a novel algorithm for repairing linear regression models based on quadratic programming, surpassing existing approaches.

**摘要:** 反实例导修的目的在于创建具有数学安全性保证的神经网络,从而促进神经网络在安全关键领域的应用。然而,反实例导修是否保证终止仍然是一个开放的问题。我们通过证明反实例导修可以被看作一种强有力的优化算法来解决这个问题。

**[Paper URL](https://proceedings.mlr.press/v202/boetius23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/boetius23a/boetius23a.pdf)** 

# Beyond the Universal Law of Robustness: Sharper Laws for Random Features and Neural Tangent Kernels
**题目:** 超越普遍的鲁棒性法则:随机特性和神经 Tangent核的更清晰的法则

**作者:** Simone Bombari, Shayan Kiyani, Marco Mondelli

**Abstract:** Machine learning models are vulnerable to adversarial perturbations, and a thought-provoking paper by Bubeck and Sellke has analyzed this phenomenon through the lens of over-parameterization: interpolating smoothly the data requires significantly more parameters than simply memorizing it. However, this "universal" law provides only a necessary condition for robustness, and it is unable to discriminate between models. In this paper, we address these gaps by focusing on empirical risk minimization in two prototypical settings, namely, random features and the neural tangent kernel (NTK). We prove that, for random features, the model is not robust for any degree of over-parameterization, even when the necessary condition coming from the universal law of robustness is satisfied. In contrast, for even activations, the NTK model meets the universal lower bound, and it is robust as soon as the necessary condition on over-parameterization is fulfilled. This also addresses a conjecture in prior work by Bubeck, Li and Nagaraj. Our analysis decouples the effect of the kernel of the model from an "interaction matrix", which describes the interaction with the test data and captures the effect of the activation. Our theoretical results are corroborated by numerical evidence on both synthetic and standard datasets (MNIST, CIFAR-10).

**摘要:** 机器学习模型易受敌对扰动,布贝克和塞尔克(Bubeck and Sellke)在一篇具有启发思想的论文中通过超参数化透镜分析了这一现象:平滑地对数据进行插值需要比简单地记住数据要多得多的参数。然而,这一“普遍”律只为鲁棒性提供了必要的条件,并不能区分模型。本文通过着重于两个原型设置中的经验风险最小化,即随机特征和神经 Tangent Kernel(NTK)来解决这些缺陷。本文还讨论了布贝克、李和纳加拉杰(Bubeck,Li and Nagaraj)以前的研究假设。我们的分析将模型的核心效应从描述与测试数据相互作用的“相互作用矩阵”中分离出来,并捕捉了激活效应。

**[Paper URL](https://proceedings.mlr.press/v202/bombari23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bombari23a/bombari23a.pdf)** 

# Sliced-Wasserstein on Symmetric Positive Definite Matrices for M/EEG Signals
**题目:** M/EEG信号对称正确定矩阵的 Sliced-Wasserstein

**作者:** Clément Bonet, Benoı̂t Malézieux, Alain Rakotomamonjy, Lucas Drumetz, Thomas Moreau, Matthieu Kowalski, Nicolas Courty

**Abstract:** When dealing with electro or magnetoencephalography records, many supervised prediction tasks are solved by working with covariance matrices to summarize the signals. Learning with these matrices requires the usage of Riemanian geometry to account for their structure. In this paper, we propose a new method to deal with distributions of covariance matrices, and demonstrate its computational efficiency on M/EEG multivariate time series. More specifically, we define a Sliced-Wasserstein distance between measures of symmetric positive definite matrices that comes with strong theoretical guarantees. Then, we take advantage of its properties and kernel methods to apply this discrepancy to brain-age prediction from MEG data, and compare it to state-of-the-art algorithms based on Riemannian geometry. Finally, we show that it is an efficient surrogate to the Wasserstein distance in domain adaptation for Brain Computer Interface applications.

**摘要:** 在处理电磁脑谱记录时,许多监视的预测任务通过使用协变矩阵来总结信号,需要利用黎曼几何学来解释其结构。本文提出了一种处理协变矩阵分布的新方法,并展示其在M/EEG多变数时间序列上的计算效率。具体地说,我们定义了带有强理论保证的对称正确定矩阵的测量间的 Sliced-Wasserstein距离。然后,我们利用其特性和核方法应用这种差异在脑龄预测中,并将其与基于黎曼几何学的最先进的算法进行比较。

**[Paper URL](https://proceedings.mlr.press/v202/bonet23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bonet23a/bonet23a.pdf)** 

# Spherical Fourier Neural Operators: Learning Stable Dynamics on the Sphere
**题目:** 球形傅立叶神经运算器:在球上学习稳定动力学

**作者:** Boris Bonev, Thorsten Kurth, Christian Hundt, Jaideep Pathak, Maximilian Baust, Karthik Kashinath, Anima Anandkumar

**Abstract:** Fourier Neural Operators (FNOs) have proven to be an efficient and effective method for resolution-independent operator learning in a broad variety of application areas across scientific machine learning. A key reason for their success is their ability to accurately model long-range dependencies in spatio-temporal data by learning global convolutions in a computationally efficient manner. To this end, FNOs rely on the discrete Fourier transform (DFT), however, DFTs cause visual and spectral artifacts as well as pronounced dissipation when learning operators in spherical coordinates by incorrectly assuming flat geometry. To overcome this limitation, we generalize FNOs on the sphere, introducing Spherical FNOs (SFNOs) for learning operators on spherical geometries. We apply SFNOs to forecasting atmo- spheric dynamics, and demonstrate stable autoregressive rollouts for a year of simulated time (1,460 steps), while retaining physically plausible dynamics. The SFNO has important implications for machine learning-based simulation of climate dynamics that could eventually help accelerate our response to climate change.

**摘要:** 傅立叶神经运算器(FNOs)在科学机器学习的广泛应用领域中证明是分辨率独立运算器学习的有效和有效的方法。其成功的关键原因在于它们能够准确地建模空间时空数据中的长距离依赖性,并以计算效率的方式学习全球卷曲。为此目的,FNOs依靠离散傅立叶变换(DFT),然而DFTs会造成视觉和光谱的人工物以及在不正确假设平形几何时在球形坐标中学习运算器时显现的消散。为了克服这一局限性,我们将FNOs推广到球面,引入球形运算器学习球形几何的SFNOs。我们应用SFNOs来预测球形动力学,并展示了一年的模拟时间(1,460步)的稳定自回归演变。SFNO对基于机器学习的气候动力学模拟具有重要的影响,最终可以帮助加速我们对气候变化的反应。

**[Paper URL](https://proceedings.mlr.press/v202/bonev23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bonev23a/bonev23a.pdf)** 

# The Regret of Exploration and the Control of Bad Episodes in Reinforcement Learning
**题目:** 强化学习中探索和控制不良事件的遗憾

**作者:** Victor Boone, Bruno Gaujal

**Abstract:** The first contribution of this paper is the introduction of a new performance measure of a RL algorithm that is more discriminating than the regret, that we call the regret of exploration that measures the asymptotic cost of exploration. The second contribution is a new performance test (PT) to end episodes in RL optimistic algorithms. This test is based on the performance of the current policy with respect to the best policy over the current confidence set. This is in contrast with all existing RL algorithms whose episode lengths are only based on the number of visits to the states. This modification does not harm the regret and brings an additional property. We show that while all current episodic RL algorithms have a linear regret of exploration, our method has a $O(\log{T})$ regret of exploration for non-degenerate deterministic MDPs.

**摘要:** 本文的第一个贡献是引入一种比遗憾更具有歧视性的RL算法的新性能指标,我们称之为探索的遗憾,它测量探索的渐近成本。第二个贡献是一个新的性能测试(PT)以结束RL乐观算法中的片段。该测试基于当前政策的性能,以了解当前的最优政策。这与所有现有的RL算法相悖,其片段长度只基于访问状态的数目。此修改不伤害遗憾,并带来了额外属性。我们证明,所有当前的 episodic RL算法都有探索的线性遗憾,我们的方法有非退化确定性MDP探索的$O(\log{T})$遗憾。

**[Paper URL](https://proceedings.mlr.press/v202/boone23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/boone23a/boone23a.pdf)** 

# Model-agnostic Measure of Generalization Difficulty
**题目:** 广义化难度模型误差测量

**作者:** Akhilan Boopathy, Kevin Liu, Jaedong Hwang, Shu Ge, Asaad Mohammedsaleh, Ila R Fiete

**Abstract:** The measure of a machine learning algorithm is the difficulty of the tasks it can perform, and sufficiently difficult tasks are critical drivers of strong machine learning models. However, quantifying the generalization difficulty of machine learning benchmarks has remained challenging. We propose what is to our knowledge the first model-agnostic measure of the inherent generalization difficulty of tasks. Our inductive bias complexity measure quantifies the total information required to generalize well on a task minus the information provided by the data. It does so by measuring the fractional volume occupied by hypotheses that generalize on a task given that they fit the training data. It scales exponentially with the intrinsic dimensionality of the space over which the model must generalize but only polynomially in resolution per dimension, showing that tasks which require generalizing over many dimensions are drastically more difficult than tasks involving more detail in fewer dimensions. Our measure can be applied to compute and compare supervised learning, reinforcement learning and meta-learning generalization difficulties against each other. We show that applied empirically, it formally quantifies intuitively expected trends, e.g. that in terms of required inductive bias, MNIST $<$ CIFAR10 $<$ Imagenet and fully observable Markov decision processes (MDPs) $<$ partially observable MDPs. Further, we show that classification of complex images $<$ few-shot meta-learning with simple images. Our measure provides a quantitative metric to guide the construction of more complex tasks requiring greater inductive bias, and thereby encourages the development of more sophisticated architectures and learning algorithms with more powerful generalization capabilities.

**摘要:** 机器学习算法的测量是其完成任务的难度,而足够困难的任务是强的机器学习模型的关键驱动因素。然而,对机器学习基准的一般化难度的定量仍然是挑战性的。我们提出了对任务的固有一般化难度的第一个模型-认知度量。它以空间的内在维度为指数尺度,在维度上必须将模型广义化,但仅在解像度上具有多项式,表明在多个维度上需要广义化的任务比涉及较少维度的细节的任务更加困难。我们的方法可以用于计算和比较监督学习、增强学习和元学习广义化困难。我们证明,在实验上,它正式量化直观预期趋势,例如在需要的诱导偏差方面,MNIST $<$ CIFAR10 $<$ Imagenet和完全可观测的马可夫决策过程(MDPs) $<$部分可观测的MDPs。我们的测量提供了一个量化度量来指导需要更大的诱导偏见的更复杂的任务的构建,从而鼓励开发具有更强大的一般化能力的更复杂的架构和学习算法。

**[Paper URL](https://proceedings.mlr.press/v202/boopathy23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/boopathy23a/boopathy23a.pdf)** 

# Returning The Favour: When Regression Benefits From Probabilistic Causal Knowledge
**题目:** 归还好处:回归从概率原因知识中获益

**作者:** Shahine Bouabid, Jake Fawkes, Dino Sejdinovic

**Abstract:** A directed acyclic graph (DAG) provides valuable prior knowledge that is often discarded in regression tasks in machine learning. We show that the independences arising from the presence of collider structures in DAGs provide meaningful inductive biases, which constrain the regression hypothesis space and improve predictive performance. We introduce collider regression, a framework to incorporate probabilistic causal knowledge from a collider in a regression problem. When the hypothesis space is a reproducing kernel Hilbert space, we prove a strictly positive generalisation benefit under mild assumptions and provide closed-form estimators of the empirical risk minimiser. Experiments on synthetic and climate model data demonstrate performance gains of the proposed methodology.

**摘要:** 导向环形图(DAG)提供了在机器学习中的回归任务中经常丢弃的宝贵的预先知识。我们证明,在DAG中发生碰撞结构的独立性提供了有意义的诱导偏见,限制了回归假设空间并提高了预测性能。我们引入碰撞回归,一种将碰撞器从回归问题中引入概率性因果知识的框架。当假设空间是复制的希尔伯特核空间时,我们证明在温和假设下具有严格的正统化利益,并提供了经验风险最小化闭式估计器。

**[Paper URL](https://proceedings.mlr.press/v202/bouabid23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bouabid23a/bouabid23a.pdf)** 

# In Search for a Generalizable Method for Source Free Domain Adaptation
**题目:** 寻找源自由域适应的通用方法

**作者:** Malik Boudiaf, Tom Denton, Bart Van Merrienboer, Vincent Dumoulin, Eleni Triantafillou

**Abstract:** Source-free domain adaptation (SFDA) is compelling because it allows adapting an off-the-shelf model to a new domain using only unlabelled data. In this work, we apply existing SFDA techniques to a challenging set of naturally-occurring distribution shifts in bioacoustics, which are very different from the ones commonly studied in computer vision. We find existing methods perform differently relative to each other than observed in vision benchmarks, and sometimes perform worse than no adaptation at all. We propose a new simple method which outperforms the existing methods on our new shifts while exhibiting strong performance on a range of vision datasets. Our findings suggest that existing SFDA methods are not as generalizable as previously thought and that considering diverse modalities can be a useful avenue for designing more robust models.

**摘要:** 无源域适应性(SFDA)是具有吸引力的,因为它允许仅使用未标记的数据来对新域进行外销模型的适应。在这项工作中,我们将现有SFDA技术应用于生物音响学中自然发生分布变化的挑战性集合,这些变化与计算机视觉中经常研究的非常不同。我们发现现有的方法比视觉基准中观察的性能不同,有时甚至比没有适应性更糟糕。

**[Paper URL](https://proceedings.mlr.press/v202/boudiaf23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/boudiaf23a/boudiaf23a.pdf)** 

# Quantum Speedups for Zero-Sum Games via Improved Dynamic Gibbs Sampling
**题目:** 通过改进动态吉布采样量增加零量级游戏的速度

**作者:** Adam Bouland, Yosheb M Getachew, Yujia Jin, Aaron Sidford, Kevin Tian

**Abstract:** We give a quantum algorithm for computing an $\epsilon$-approximate Nash equilibrium of a zero-sum game in a $m \times n$ payoff matrix with bounded entries. Given a standard quantum oracle for accessing the payoff matrix our algorithm runs in time $\widetilde{O}(\sqrt{m + n}\cdot \epsilon^{-2.5} + \epsilon^{-3})$ and outputs a classical representation of the $\epsilon$-approximate Nash equilibrium. This improves upon the best prior quantum runtime of $\widetilde{O}(\sqrt{m + n} \cdot \epsilon^{-3})$ obtained by [van Apeldoorn, Gilyen ’19] and the classical $\widetilde{O}((m + n) \cdot \epsilon^{-2})$ runtime due to [Grigoradis, Khachiyan ’95] whenever $\epsilon = \Omega((m +n)^{-1})$. We obtain this result by designing new quantum data structures for efficiently sampling from a slowly-changing Gibbs distribution.

**摘要:** 我们给出了一个用于计算$m \times n$带有界入的报酬矩阵的零sum游戏$\epsilon$-approximate Nash平衡的量子算法,给出了一个用于访问报酬矩阵的标准量子序列,我们的算法在时间上运行$\widetilde{O}(\sqrt{m + n}\cdot \epsilon^{-2.5} + \epsilon^{-3})$,并输出了$\epsilon$-approximate Nash平衡的经典表现。这改善了[van Apeldoorn, Gilyen ’19]和古典$\widetilde{O}((m + n) \cdot \epsilon^{-2})$运行时间的最好前量子运行时间。

**[Paper URL](https://proceedings.mlr.press/v202/bouland23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bouland23a/bouland23a.pdf)** 

# Diffusion Models as Artists: Are we Closing the Gap between Humans and Machines?
**题目:** 作为艺术家的扩散模型:我们是否要缩小人类和机器之间的差距?

**作者:** Victor Boutin, Thomas Fel, Lakshya Singhal, Rishav Mukherji, Akash Nagaraj, Julien Colin, Thomas Serre

**Abstract:** An important milestone for AI is the development of algorithms that can produce drawings that are indistinguishable from those of humans. Here, we adapt the ”diversity vs. recognizability” scoring framework from Boutin et al (2022) and find that one-shot diffusion models have indeed started to close the gap between humans and machines. However, using a finer-grained measure of the originality of individual samples, we show that strengthening the guidance of diffusion models helps improve the humanness of their drawings, but they still fall short of approximating the originality and recognizability of human drawings. Comparing human category diagnostic features, collected through an online psychophysics experiment, against those derived from diffusion models reveals that humans rely on fewer and more localized features. Overall, our study suggests that diffusion models have significantly helped improve the quality of machine-generated drawings; however, a gap between humans and machines remains – in part explainable by discrepancies in visual strategies.

**摘要:** 人工知能的一个重要里程碑是能够产生与人不同图形的算法的开发。这里,我们采用了布丁等人(2022)的“多样性与可识别性”评分框架,发现单击扩散模型确实开始缩小人与机器之间的差距。然而,使用较精细的个体样本的原型量度,我们表明加强扩散模型的指导有助于提高其图形的人类性,但它们仍然不足以接近人图形的原型和可识别性。总体而言,我们的研究表明,扩散模型大大有助于提高机器生成图画的质量;然而,人类与机器之间的差距仍然存在 — — 部分原因在于视觉策略的差异。

**[Paper URL](https://proceedings.mlr.press/v202/boutin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/boutin23a/boutin23a.pdf)** 

# Settling the Reward Hypothesis
**题目:** 补偿假设的解决

**作者:** Michael Bowling, John D Martin, David Abel, Will Dabney

**Abstract:** The reward hypothesis posits that, "all of what we mean by goals and purposes can be well thought of as maximization of the expected value of the cumulative sum of a received scalar signal (reward)." We aim to fully settle this hypothesis. This will not conclude with a simple affirmation or refutation, but rather specify completely the implicit requirements on goals and purposes under which the hypothesis holds.

**摘要:** 奖赏假设认为,“我们所说的所有目标和目的都可以被当作得到的尺度信号(奖赏)的累积总数的期望值的最大化”。我们的目标是完全解决这一假设。这不会以简单的肯定或反驳来结束,而是完全说明假设所包含的目标和目的的隐含要求。

**[Paper URL](https://proceedings.mlr.press/v202/bowling23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bowling23a/bowling23a.pdf)** 

# ILLUME: Rationalizing Vision-Language Models through Human Interactions
**题目:** ILLUME:基于人际关系的视觉语言模型的合理化

**作者:** Manuel Brack, Patrick Schramowski, Björn Deiseroth, Kristian Kersting

**Abstract:** Bootstrapping from pre-trained language models has been proven to be an efficient approach for building vision-language models (VLM) for tasks such as image captioning or visual question answering. However, outputs of these models rarely align with user’s rationales for specific answers. In order to improve this alignment and reinforce commonsense reasons, we propose a tuning paradigm based on human interactions with machine-generated data. Our ILLUME executes the following loop: Given an image-question-answer prompt, the VLM samples multiple candidate rationales, and a human critic provides feedback via preference selection, used for fine-tuning. This loop increases the training data and gradually carves out the VLM’s rationalization capabilities that are aligned with human intent. Our exhaustive experiments demonstrate that ILLUME is competitive with standard supervised finetuning while using significantly fewer training data and only requiring minimal feedback.

**摘要:** 预先训练语言模型的引导已经证明是建立视觉语言模型(VLM)的有效方法,用于像图像字幕或视觉问题解答等任务。然而,这些模型的输出很少与用户理性为具体的答案进行协调。为了改善这种协调和加强常识原因,我们提出了基于机器生成数据的人类交互的调制范式。我们的ILLUME执行了以下循环: 给出了一个图像问题答复提示,VLM样本提供了多个候选理性,并通过优先选择提供反馈,用于精细调制。

**[Paper URL](https://proceedings.mlr.press/v202/brack23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/brack23a/brack23a.pdf)** 

# Provably Learning Object-Centric Representations
**题目:** 易于学习的对象中心表示

**作者:** Jack Brady, Roland S. Zimmermann, Yash Sharma, Bernhard Schölkopf, Julius Von Kügelgen, Wieland Brendel

**Abstract:** Learning structured representations of the visual world in terms of objects promises to significantly improve the generalization abilities of current machine learning models. While recent efforts to this end have shown promising empirical progress, a theoretical account of when unsupervised object-centric representation learning is possible is still lacking. Consequently, understanding the reasons for the success of existing object-centric methods as well as designing new theoretically grounded methods remains challenging. In the present work, we analyze when object-centric representations can provably be learned without supervision. To this end, we first introduce two assumptions on the generative process for scenes comprised of several objects, which we call compositionality and irreducibility. Under this generative process, we prove that the ground-truth object representations can be identified by an invertible and compositional inference model, even in the presence of dependencies between objects. We empirically validate our results through experiments on synthetic data. Finally, we provide evidence that our theory holds predictive power for existing object-centric models by showing a close correspondence between models’ compositionality and invertibility and their empirical identifiability.

**摘要:** 基于对象的视觉世界结构化表现的研究,有望大大提高当前机器学习模型的一般化能力。虽然最近的研究成果显示了有希望的实证进展,但仍缺乏一个理论的解释,即无监督的对象中心表现学习是可能的。因此,理解现有的对象中心方法的成功原因以及设计新的理论基础的方法仍然是挑战性的。在这一生成过程下,我们证明,即使存在物体间的依赖性,也可以通过可逆和组合推理模型来识别实物的实物表示。我们通过对合成数据的实验验证了我们的结果。最后,我们通过显示模型的组合性和不可逆性以及它们的经验识别性之间的密切相关性,证明了我们理论对现有物体中心模型具有预测性。

**[Paper URL](https://proceedings.mlr.press/v202/brady23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/brady23a/brady23a.pdf)** 

# Quantifying Human Priors over Social and Navigation Networks
**题目:** 社会和导航网络上的人类先驱的定量化

**作者:** Gecia Bravo-Hermsdorff

**Abstract:** Human knowledge is largely implicit and relational — do we have a friend in common? can I walk from here to there? In this work, we leverage the combinatorial structure of graphs to quantify human priors over such relational data. Our experiments focus on two domains that have been continuously relevant over evolutionary timescales: social interaction and spatial navigation. We find that some features of the inferred priors are remarkably consistent, such as the tendency for sparsity as a function of graph size. Other features are domain-specific, such as the propensity for triadic closure in social interactions. More broadly, our work demonstrates how nonclassical statistical analysis of indirect behavioral experiments can be used to efficiently model latent biases in the data.

**摘要:** 人类的知识在很大程度上是隐含的和关联的 — 我们有朋友吗?我可以从这里到那里走吗?在这个研究中,我们利用图形的组合结构来量化人类的优先次序在这些关联数据上。我们的实验集中于两个领域,它们在进化时间尺度上一直具有关联性:社会互动和空间导航。我们发现推测优先次序的一些特征非常一致,如图形大小的一个函数的稀疏性倾向。其他特征是领域特有,如社会互动中三维封闭的倾向。更广泛地,我们的研究表明如何利用非经典统计分析间接行为实验来有效地建模数据中的隐性偏见。

**[Paper URL](https://proceedings.mlr.press/v202/bravo-hermsdorff23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bravo-hermsdorff23a/bravo-hermsdorff23a.pdf)** 

# Critical Points and Convergence Analysis of Generative Deep Linear Networks Trained with Bures-Wasserstein Loss
**题目:** 基于Bures-Wasserstein损失的生成深线性网络的临界点和收敛分析

**作者:** Pierre Bréchet, Katerina Papagiannouli, Jing An, Guido Montufar

**Abstract:** We consider a deep matrix factorization model of covariance matrices trained with the Bures-Wasserstein distance. While recent works have made advances in the study of the optimization problem for overparametrized low-rank matrix approximation, much emphasis has been placed on discriminative settings and the square loss. In contrast, our model considers another type of loss and connects with the generative setting. We characterize the critical points and minimizers of the Bures-Wasserstein distance over the space of rank-bounded matrices. The Hessian of this loss at low-rank matrices can theoretically blow up, which creates challenges to analyze convergence of gradient optimization methods. We establish convergence results for gradient flow using a smooth perturbative version of the loss as well as convergence results for finite step size gradient descent under certain assumptions on the initial weights.

**摘要:** 我们考虑了与伯斯-瓦塞尔斯坦距离训练的共变矩阵深层矩阵因子化模型。虽然最近的工作在研究过参数化低级矩阵近似的优化问题方面取得了进展,但对分离性设置和平方损失的重视却十分突出。相反,我们的模型考虑了另一个类型的损失并与生成性设置相连。我们对伯斯-瓦塞尔斯坦距离的临界点和最小化进行了区分,对低级矩阵的这一损失的赫斯sian理论上可以爆炸,从而为分析梯度优化方法的收敛性提出了挑战。

**[Paper URL](https://proceedings.mlr.press/v202/brechet23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/brechet23a/brechet23a.pdf)** 

# Emergence of Sparse Representations from Noise
**题目:** 噪音引起的节余表现

**作者:** Trenton Bricken, Rylan Schaeffer, Bruno Olshausen, Gabriel Kreiman

**Abstract:** A hallmark of biological neural networks, which distinguishes them from their artificial counterparts, is the high degree of sparsity in their activations. This discrepancy raises three questions our work helps to answer: (i) Why are biological networks so sparse? (ii) What are the benefits of this sparsity? (iii) How can these benefits be utilized by deep learning models? Our answers to all of these questions center around training networks to handle random noise. Surprisingly, we discover that noisy training introduces three implicit loss terms that result in sparsely firing neurons specializing to high variance features of the dataset. When trained to reconstruct noisy-CIFAR10, neurons learn biological receptive fields. More broadly, noisy training presents a new approach to potentially increase model interpretability with additional benefits to robustness and computational efficiency.

**摘要:** 生物神经网络的一个特征,它与其人工的同类不同,是其活动中的稀疏度高。这种不一致性引发了三个问题,我们的工作有助于回答: (i)为什么生物网络如此稀疏? (ii)这种稀疏的好处是什么? (iii)这些好处如何被深度学习模型所利用? 我们对所有这些问题的回答集中在训练网络处理随机噪声的周围。令人惊讶的是,我们发现噪声训练引入了三个隐含的损失条件,结果是稀疏地发射神经元,专门用于数据集的高变异特性。

**[Paper URL](https://proceedings.mlr.press/v202/bricken23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bricken23a/bricken23a.pdf)** 

# Differentially Private Optimization on Large Model at Small Cost
**题目:** 基于小成本的大型模型的微分 Private Optimization

**作者:** Zhiqi Bu, Yu-Xiang Wang, Sheng Zha, George Karypis

**Abstract:** Differentially private (DP) optimization is the standard paradigm to learn large neural networks that are accurate and privacy-preserving. The computational cost for DP deep learning, however, is notoriously heavy due to the per-sample gradient clipping. Existing DP implementations are 2$\sim$1000$\times$ more costly in time and space complexity than the standard (non-private) training. In this work, we develop a novel Book-Keeping (BK) technique that implements existing DP optimizers (thus achieving the same accuracy), with a substantial improvement on the computational cost. Specifically, BK enables DP training on large models and high dimensional data to be roughly as fast and memory-saving as the standard training, whereas previous DP algorithms can be inefficient or incapable of training due to memory error. The computational advantage of BK is supported by the complexity analysis as well as extensive experiments on vision and language tasks. Our implementation achieves state-of-the-art (SOTA) accuracy with very small extra cost: on GPT2 and at almost the same memory cost ($<$1% overhead), BK has 1.03$\times$ the time complexity of the standard training (0.83$\times$ training speed in practice), and 0.61$\times$ the time complexity of the most efficient DP implementation (1.36$\times$ training speed in practice). We open-source the codebase for the BK algorithm at https://github.com/awslabs/fast-differential-privacy.

**摘要:** 不同程度的私人(DP)优化是学习大型神经网络的标准范式,具有准确性和隐私保护性。然而,DP深度学习的计算成本由于每个样本的梯度剪切而十分严重。现有的DP实现比标准(非私人)培训花费2$\sim$1000$\times$的时间和空间复杂度更昂贵。在这个工作中,我们开发了一个新颖的书存(BK)技术,它实现了现有的DP优化器(从而达到相同的精度),大大提高了计算成本。在GPT2和几乎相同的内存成本($<$1%的总成本)上,BK具有标准训练的时间复杂度1.03$\times$(在实践中训练速度0.83$\times$),以及最有效的DP实现的时间复杂度0.61$\times$(在实践中训练速度1.36$\times$)。

**[Paper URL](https://proceedings.mlr.press/v202/bu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bu23a/bu23a.pdf)** 

# Machine Learning Force Fields with Data Cost Aware Training
**题目:** 基于数据成本的机器学习力场训练

**作者:** Alexander Bukharin, Tianyi Liu, Shengjie Wang, Simiao Zuo, Weihao Gao, Wen Yan, Tuo Zhao

**Abstract:** Machine learning force fields (MLFF) have been proposed to accelerate molecular dynamics (MD) simulation, which finds widespread applications in chemistry and biomedical research. Even for the most data-efficient MLFFs, reaching chemical accuracy can require hundreds of frames of force and energy labels generated by expensive quantum mechanical algorithms, which may scale as $O(n^3)$ to $O(n^7)$, with $n$ proportional to the number of basis functions. To address this issue, we propose a multi-stage computational framework – ASTEROID, which lowers the data cost of MLFFs by leveraging a combination of cheap inaccurate data and expensive accurate data. The motivation behind ASTEROID is that inaccurate data, though incurring large bias, can help capture the sophisticated structures of the underlying force field. Therefore, we first train a MLFF model on a large amount of inaccurate training data, employing a bias-aware loss function to prevent the model from overfitting the potential bias of this data. We then fine-tune the obtained model using a small amount of accurate training data, which preserves the knowledge learned from the inaccurate training data while significantly improving the model’s accuracy. Moreover, we propose a variant of ASTEROID based on score matching for the setting where the inaccurate training data are unlabeled. Extensive experiments on MD datasets and downstream tasks validate the efficacy of ASTEROID. Our code and data are available at https://github.com/abukharin3/asteroid.

**摘要:** 机器学习力场(MLFF)被提议加速分子动力学(MD)模拟,它在化学和生物医学研究中得到了广泛的应用。即使是最数据效率高的MLFF,达到化学准确度也需要由昂贵的量子力学算法生成的数百个力框架和能量标签,这些框架可从$O(n^3)$到$O(n^7)$,与$n$相等于基本函数的数目。为了解决这个问题,我们提议一个多阶段计算框架-ASTEROID,它通过利用廉价不准确数据和昂贵的准确数据相结合来降低MLFF的数据成本。因此,我们首先在大量不准确的训练数据上训练MLFF模型,使用偏见意识损伤函数来防止模型超过这一数据的潜在偏见。然后,我们用少量准确的训练数据调制得到的模型,从而保持不准确的训练数据所获得的知识,同时大大提高模型的准确性。此外,我们提出了基于不准确的训练数据未标记的设置的分数匹配的ASTEROID变换。

**[Paper URL](https://proceedings.mlr.press/v202/bukharin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/bukharin23a/bukharin23a.pdf)** 

# Label differential privacy and private training data release
**题目:** 标记差异性隐私和私人培训数据发布

**作者:** Robert Istvan Busa-Fekete, Andres Munoz Medina, Umar Syed, Sergei Vassilvitskii

**Abstract:** We study differentially private mechanisms for sharing training data in machine learning settings. Our goal is to enable learning of an accurate predictive model while protecting the privacy of each user’s label. Previous work established privacy guarantees that assumed the features are public and given exogenously, a setting known as label differential privacy. In some scenarios, this can be a strong assumption that removes the interplay between features and labels from the privacy analysis. We relax this approach and instead assume the features are drawn from a distribution that depends on the private labels. We first show that simply adding noise to the label, as in previous work, can lead to an arbitrarily weak privacy guarantee, and also present methods for estimating this privacy loss from data. We then present a new mechanism that replaces some training examples with synthetically generated data, and show that our mechanism has a much better privacy-utility tradeoff if the synthetic data is ‘realistic’, in a certain quantifiable sense. Finally, we empirically validate our theoretical analysis.

**摘要:** 我们研究了在机器学习设置中共享培训数据的差异性私有机制。我们的目标是在保护每个用户标签的隐私的同时,实现准确的预测模型的学习。以前的工作建立了隐私保证,认为特征是公开的,并且是外来提供的,一个被称为标签差异性隐私的设置。在某些场景中,这可能是消除特征和标签之间的相互作用的强假设,从隐私分析中消除这种相互作用。然后,我们提出了一种新的机制,以合成数据代替一些训练实例,并且表明,如果合成数据在某种可量化意义上是“现实的”,我们的机制具有更好的隐私-实用性交易权。

**[Paper URL](https://proceedings.mlr.press/v202/busa-fekete23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/busa-fekete23a/busa-fekete23a.pdf)** 

# The SSL Interplay: Augmentations, Inductive Bias, and Generalization
**题目:** SSL交互:增强、诱导偏见和一般化

**作者:** Vivien Cabannes, Bobak Kiani, Randall Balestriero, Yann Lecun, Alberto Bietti

**Abstract:** Self-supervised learning (SSL) has emerged as a powerful framework to learn representations from raw data without supervision. Yet in practice, engineers face issues such as instability in tuning optimizers and collapse of representations during training. Such challenges motivate the need for a theory to shed light on the complex interplay between the choice of data augmentation, network architecture, and training algorithm. % on the resulting performance in downstream tasks. We study such an interplay with a precise analysis of generalization performance on both pretraining and downstream tasks in kernel regimes, and highlight several insights for SSL practitioners that arise from our theory.

**摘要:** 自我监督学习(英语:Self-supervised learning,缩写为SSL)是一个强大的框架,可以从无监督的原始数据中学习表现。然而,在实践中,工程师们面临着在调试优化器和训练中表现的崩溃方面的不稳定问题。这样的挑战激励了理论需要在数据增强、网络架构和训练算法的选择之间揭示复杂的相互作用。

**[Paper URL](https://proceedings.mlr.press/v202/cabannes23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cabannes23a/cabannes23a.pdf)** 

# Online Mechanism Design for Information Acquisition
**题目:** 网上信息获取机制设计

**作者:** Federico Cacciamani, Matteo Castiglioni, Nicola Gatti

**Abstract:** We study the problem of designing mechanisms for information acquisition scenarios. This setting models strategic interactions between a uniformed receiver and a set of informed senders. In our model the senders receive information about the underlying state of nature and communicate their observation (either truthfully or not) to the receiver, which, based on this information, selects an action. Our goal is to design mechanisms maximizing the receiver’s utility while incentivizing the senders to report truthfully their information. First, we provide an algorithm that efficiently computes an optimal incentive compatible (IC) mechanism. Then, we focus on the online problem in which the receiver sequentially interacts in an unknown game, with the objective of minimizing the cumulative regret w.r.t. the optimal IC mechanism, and the cumulative violation of the incentive compatibility constraints. We investigate two different online scenarios, i.e., the full and bandit feedback settings. For the full feedback problem, we propose an algorithm that guarantees $\tilde{O}(\sqrt{T})$ regret and violation, while for the bandit feedback setting we present an algorithm that attains $\tilde{O}(T^{\alpha})$ regret and $\tilde{O}(T^{1-\alpha/2})$ violation for any $\alpha \in [1/2, 1]$. Finally, we complement our results providing a tight lower bound.

**摘要:** 我们研究了信息获取场景设计机制的问题。该设置模型为统一接收机和一组知情接收机之间的战略交互模式。在我们的模型中,接收机接收到关于自然的基本状态的信息,并向接收机传达其观察(诚实或不诚实)情况,基于此信息选择行动。我们的目标是设计机制,使接收机的实用性最大化,同时鼓励接收机诚实地报告其信息。首先,我们提供一种高效计算最佳激励兼容(IC)机制的算法。然后,我们着重于接收机在未知游戏中交互的在线问题,目的是减少累积遗憾,即最佳IC机制,以及累积违反激励兼容约束。对于完全反馈问题,我们提出了一种保证$\tilde{O}(\sqrt{T})$遗憾和违反的算法,而对于带式反馈设置,我们提出了一种实现$\tilde{O}(T^{\alpha})$遗憾和$\tilde{O}(T^{1-\alpha/2})$违反任何$\alpha \in [1/2, 1]$的算法。

**[Paper URL](https://proceedings.mlr.press/v202/cacciamani23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cacciamani23a/cacciamani23a.pdf)** 

# MyoDex: A Generalizable Prior for Dexterous Manipulation
**题目:** MyoDex:精巧操作的通用前置

**作者:** Vittorio Caggiano, Sudeep Dasari, Vikash Kumar

**Abstract:** Human dexterity is a hallmark of motor control behaviors. Our hands can rapidly synthesize new behaviors despite the complexity (multi-articular and multi-joints, with 23 joints controlled by more than 40 muscles) of mosculoskeletal control. In this work, we take inspiration from how human dexterity builds on a diversity of prior experiences, instead of being acquired through a single task. Motivated by this observation, we set out to develop agents that can build upon previous experience to quickly acquire new (previously unattainable) behaviors. Specifically, our approach leverages multi-task learning to implicitly capture a task-agnostic behavioral priors (MyoDex) for human-like dexterity, using a physiologically realistic human hand model – MyoHand. We demonstrate MyoDex’s effectiveness in few-shot generalization as well as positive transfer to a large repertoire of unseen dexterous manipulation tasks. MyoDex can solve approximately 3x more tasks and it can accelerate the achievement of solutions by about 4x in comparison to a distillation baseline. While prior work has synthesized single musculoskeletal control behaviors, MyoDex is the first generalizable manipulation prior that catalyzes the learning of dexterous physiological control across a large variety of contact-rich behaviors.

**摘要:** 人类敏捷是运动控制行为的标志。尽管肌肉骨骼控制的复杂性(多关节和多关节,有23个关节由40多个肌肉控制),我们的手能快速合成新的行为。在这个工作中,我们从人类敏捷如何建立在不同经验的基础上,而不是通过单个任务获得的灵感。MyoDex可以解决大约3倍的任务,并且比蒸馏基线快4倍的解决方法。虽然以前的工作已经合成了单个肌肉骨骼控制行为,MyoDex是第一个可推广的前操作,它催化了在大量接触丰富的行为中学习敏捷的生理控制。

**[Paper URL](https://proceedings.mlr.press/v202/caggiano23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/caggiano23a/caggiano23a.pdf)** 

# What Can Be Learnt With Wide Convolutional Neural Networks?
**题目:** 用宽带神经网络学到什么?

**作者:** Francesco Cagnetta, Alessandro Favero, Matthieu Wyart

**Abstract:** Understanding how convolutional neural networks (CNNs) can efficiently learn high-dimensional functions remains a fundamental challenge. A popular belief is that these models harness the local and hierarchical structure of natural data such as images. Yet, we lack a quantitative understanding of how such structure affects performance, e.g., the rate of decay of the generalisation error with the number of training samples. In this paper, we study infinitely-wide deep CNNs in the kernel regime. First, we show that the spectrum of the corresponding kernel inherits the hierarchical structure of the network, and we characterise its asymptotics. Then, we use this result together with generalisation bounds to prove that deep CNNs adapt to the spatial scale of the target function. In particular, we find that if the target function depends on low-dimensional subsets of adjacent input variables, then the decay of the error is controlled by the effective dimensionality of these subsets. Conversely, if the target function depends on the full set of input variables, then the error decay is controlled by the input dimension. We conclude by computing the generalisation error of a deep CNN trained on the output of another deep CNN with randomly-initialised parameters. Interestingly, we find that, despite their hierarchical structure, the functions generated by infinitely-wide deep CNNs are too rich to be efficiently learnable in high dimension.

**摘要:** 理解进化神经网络如何有效学习高维函数仍然是一个基本的挑战。人们普遍认为,这些模型利用自然数据的局部和层次结构,例如图像。然而,我们缺乏对这种结构如何影响性能的定量理解,例如,训练样本的数量与一般化误差的衰减率。相反,如果目标函数依赖输入变量的全部集合,则误差衰变由输入维度控制。我们通过计算基于随机初始参数的另一个深度CNN输出训练的深度CNN的一般化误差,得出结论。有趣的是,我们发现,尽管具有层次结构,无限宽的深度CNN产生的函数过于丰富,无法在高维度中有效学习。

**[Paper URL](https://proceedings.mlr.press/v202/cagnetta23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cagnetta23a/cagnetta23a.pdf)** 

# Causal Discovery with Latent Confounders Based on Higher-Order Cumulants
**题目:** 基于高阶累积物的诱因发现

**作者:** Ruichu Cai, Zhiyi Huang, Wei Chen, Zhifeng Hao, Kun Zhang

**Abstract:** Causal discovery with latent confounders is an important but challenging task in many scientific areas. Despite the success of some overcomplete independent component analysis (OICA) based methods in certain domains, they are computationally expensive and can easily get stuck into local optima. We notice that interestingly, by making use of higher-order cumulants, there exists a closed-form solution to OICA in specific cases, e.g., when the mixing procedure follows the One-Latent-Component structure. In light of the power of the closed-form solution to OICA corresponding to the One-Latent-Component structure, we formulate a way to estimate the mixing matrix using the higher-order cumulants, and further propose the testable One-Latent-Component condition to identify the latent variables and determine causal orders. By iteratively removing the share identified latent components, we successfully extend the results on the One-Latent-Component structure to the Multi-Latent-Component structure and finally provide a practical and asymptotically correct algorithm to learn the causal structure with latent variables. Experimental results illustrate the asymptotic correctness and effectiveness of the proposed method.

**摘要:** 在许多科学领域,与潜在的混淆者进行因果发现是一项重要的,但具有挑战性的任务。尽管在某些领域中某些超完成的独立组件分析(OICA)基于方法取得了成功,但它们是计算上昂贵的,并且很容易陷入局部优化中。我们注意到, interestingly, by making use of higher-order cumulants, there exists a closed-form solution to OICA in specific cases, eg., when the mixing procedure follows the One-Latent-Component structure. In light of the power of the closed-form solution to OICA corresponding to the One-Latent-Component structure, we formulate a way to estimate the mixing matrix using the higher-order cumulants, and further propose the testable One-Latent-Component condition to identify the latent variables and determine causal orders。通过迭代除去已确定的 share latent components,我们成功地将单个 latent-component结构的结果扩展到多个 latent-component结构,并最终提供一种实用和渐近正确算法,以学习 latent变量的因果结构。实验结果说明了该方法的渐近正确性和有效性。

**[Paper URL](https://proceedings.mlr.press/v202/cai23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cai23a/cai23a.pdf)** 

# On the Connection Between MPNN and Graph Transformer
**题目:** MPNN与图形变换器之间的连接

**作者:** Chen Cai, Truong Son Hy, Rose Yu, Yusu Wang

**Abstract:** Graph Transformer (GT) recently has emerged as a new paradigm of graph learning algorithms, outperforming the previously popular Message Passing Neural Network (MPNN) on multiple benchmarks. Previous work shows that with proper position embedding, GT can approximate MPNN arbitrarily well, implying that GT is at least as powerful as MPNN. In this paper, we study the inverse connection and show that MPNN with virtual node (VN), a commonly used heuristic with little theoretical understanding, is powerful enough to arbitrarily approximate the self-attention layer of GT. In particular, we first show that if we consider one type of linear transformer, the so-called Performer/Linear Transformer, then MPNN + VN with only $\mathcal{O}(1)$ depth and $\mathcal{O}(1)$ width can approximate a self-attention layer in Performer/Linear Transformer. Next, via a connection between MPNN + VN and DeepSets, we prove the MPNN + VN with $\mathcal{O}(n^d)$ width and $\mathcal{O}(1)$ depth can approximate the self-attention layer arbitrarily well, where $d$ is the input feature dimension. Lastly, under some assumptions, we provide an explicit construction of MPNN + VN with $\mathcal{O}(1)$ width and $\mathcal{O}(n)$ depth approximating the self-attention layer in GT arbitrarily well. On the empirical side, we demonstrate that 1) MPNN + VN is a surprisingly strong baseline, outperforming GT on the recently proposed Long Range Graph Benchmark (LRGB) dataset, 2) our MPNN + VN improves over early implementation on a wide range of OGB datasets and 3) MPNN + VN outperforms Linear Transformer and MPNN on the climate modeling task.

**摘要:** 图形变换器(GT)最近成为图形学习算法的新范式,在多个基准上超越了以前流行的传递信息神经网络(MPNN)。先前的工作表明,在适当位置嵌入下,GT可以任意地近似MPNN,这意味着GT至少像MPNN一样强大。本论文研究了逆连接,并表明MPNN与虚拟节点(VN),一种常用的理论理解不足的启发式,足以任意近似GT的自注意层。其次,通过MPNN + VN与 DeepSets的连接,我们证明,MPNN + VN具有$\mathcal{O}(n^d)$宽度和$\mathcal{O}(1)$深度可以任意地近似自注意层,其中$d$是输入特征维度。最后,在某些假设下,我们提供了明确的MPNN + VN构造,以$\mathcal{O}(1)$宽度和$\mathcal{O}(n)$深度任意地近似 GT中的自注意层。

**[Paper URL](https://proceedings.mlr.press/v202/cai23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cai23b/cai23b.pdf)** 

# Ske2Grid: Skeleton-to-Grid Representation Learning for Action Recognition
**题目:** Ske2Grid:Skeleton-to-Grid表示学习为行动识别

**作者:** Dongqi Cai, Yangyuxuan Kang, Anbang Yao, Yurong Chen

**Abstract:** This paper presents Ske2Grid, a new representation learning framework for improved skeleton-based action recognition. In Ske2Grid, we define a regular convolution operation upon a novel grid representation of human skeleton, which is a compact image-like grid patch constructed and learned through three novel designs. Specifically, we propose a graph-node index transform (GIT) to construct a regular grid patch through assigning the nodes in the skeleton graph one by one to the desired grid cells. To ensure that GIT is a bijection and enrich the expressiveness of the grid representation, an up-sampling transform (UPT) is learned to interpolate the skeleton graph nodes for filling the grid patch to the full. To resolve the problem when the one-step UPT is aggressive and further exploit the representation capability of the grid patch with increasing spatial size, a progressive learning strategy (PLS) is proposed which decouples the UPT into multiple steps and aligns them to multiple paired GITs through a compact cascaded design learned progressively. We construct networks upon prevailing graph convolution networks and conduct experiments on six mainstream skeleton-based action recognition datasets. Experiments show that our Ske2Grid significantly outperforms existing GCN-based solutions under different benchmark settings, without bells and whistles. Code and models are available at https://github.com/OSVAI/Ske2Grid.

**摘要:** 本文介绍了一种基于骨骼的改进动作识别的新表现学习框架Ske2Grid。在Ske2Grid中,我们定义了一种基于人体骨骼的新网格表现的常规卷曲操作,它是通过三种新设计构建和学习的小型像图网格补丁。具体而言,我们提出了一种图节点索引变换(GIT)来通过将骨架图中的节点分配给希望的网格细胞,构建一个常规网格补丁。为了解决一个步骤UPT的攻击性问题,并进一步利用增加空间大小的网格补丁的表示能力,提出了一种渐进学习策略(PLS),将UPT分离为多个步骤,并将其整合到多个配对的GIT,通过紧凑的 cascaded设计逐步学习。我们建立在现有的图形卷曲网络上网络,并进行6个主流骨骼基于行动识别数据集的实验。实验表明,我们的Ske2Grid在不同的基准设置下明显优于现有GCN-based解决方案,没有铃声和哨声。

**[Paper URL](https://proceedings.mlr.press/v202/cai23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cai23c/cai23c.pdf)** 

# Extrapolated Random Tree for Regression
**题目:** 推导回归的随机树

**作者:** Yuchao Cai, Yuheng Ma, Yiwei Dong, Hanfang Yang

**Abstract:** In this paper, we propose a novel tree-based algorithm named Extrapolated Random Tree for Regression (ERTR) that adapts to arbitrary smoothness of the regression function while maintaining the interpretability of the tree. We first put forward the homothetic random tree for regression (HRTR) that converges to the target function as the homothetic ratio approaches zero. Then ERTR uses a linear regression model to extrapolate HRTR estimations with different ratios to the ratio zero. From the theoretical perspective, we for the first time establish the optimal convergence rates for ERTR when the target function resides in the general Hölder space $C^{k,\alpha}$ for $k\in \mathbb{N}$, whereas the lower bound of the convergence rate of the random tree for regression (RTR) is strictly slower than ERTR in the space $C^{k,\alpha}$ for $k\geq 1$. This shows that ERTR outperforms RTR for the target function with high-order smoothness due to the extrapolation. In the experiments, we compare ERTR with state-of-the-art tree algorithms on real datasets to show the superior performance of our model. Moreover, promising improvements are brought by using the extrapolated trees as base learners in the extension of ERTR to ensemble methods.

**摘要:** 本文提出了一种基于树的求解算法,其名称为求解树随机树回归(英语:Extracted Random Tree for Regression)(ERTR),该算法在保持树的解释性的同时,适应了求解函数的任意平滑度。我们首先提出了求解树随机树的同构随机树(英语:Homothetic random tree for regression)(HRTR),当同构比率接近零时,求解树会向目标函数收敛。在实验中,我们将ERTR与实数据集的最先进的树算法进行了比较,以显示该模型的优越性能。

**[Paper URL](https://proceedings.mlr.press/v202/cai23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cai23d/cai23d.pdf)** 

# Cyclic Block Coordinate Descent With Variance Reduction for Composite Nonconvex Optimization
**题目:** 复合非凸优化的循环块坐标下降与变量减少

**作者:** Xufeng Cai, Chaobing Song, Stephen Wright, Jelena Diakonikolas

**Abstract:** Nonconvex optimization is central in solving many machine learning problems, in which block-wise structure is commonly encountered. In this work, we propose cyclic block coordinate methods for nonconvex optimization problems with non-asymptotic gradient norm guarantees. Our convergence analysis is based on a gradient Lipschitz condition with respect to a Mahalanobis norm, inspired by a recent progress on cyclic block coordinate methods. In deterministic settings, our convergence guarantee matches the guarantee of (full-gradient) gradient descent, but with the gradient Lipschitz constant being defined w.r.t. a Mahalanobis norm. In stochastic settings, we use recursive variance reduction to decrease the per-iteration cost and match the arithmetic operation complexity of current optimal stochastic full-gradient methods, with a unified analysis for both finite-sum and infinite-sum cases. We prove a faster linear convergence result when a Polyak-Łojasiewicz (PŁ) condition holds. To our knowledge, this work is the first to provide non-asymptotic convergence guarantees — variance-reduced or not — for a cyclic block coordinate method in general composite (smooth + nonsmooth) nonconvex settings. Our experimental results demonstrate the efficacy of the proposed cyclic scheme in training deep neural nets.

**摘要:** 非凸优化是解决许多机器学习问题的核心,在该问题中经常遇到分块结构。本研究中,我们提出了非渐近梯度规范保证的非凸优化问题循环分块坐标方法。我们的收敛分析基于关于马哈拉诺比斯规范的利普茨梯度条件,以最近的循环分块坐标方法的进步为灵感。在确定性设置中,我们的收敛保证与(全梯度)梯度下降的保证相符,但利普茨梯度常数被定义为马哈拉诺比斯规范。在随机设置中,我们使用递归变量减少来降低每迭代成本,并与当前最佳随机全梯度方法的算术复杂性相符,同时对有限和无限数的案例进行统一分析。根据我们所知,这项研究是第一个在一般复合( Smooth + Nonsmooth ) 非凸设置中为环块坐标方法提供非渐近收敛性保证 — — 无论 variance-reduced 还是 not — — 。

**[Paper URL](https://proceedings.mlr.press/v202/cai23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cai23e/cai23e.pdf)** 

# Robust Weight Signatures: Gaining Robustness as Easy as Patching Weights?
**题目:** 坚固的重量签名: 获得坚固性与贴身重量一样容易 吗?

**作者:** Ruisi Cai, Zhenyu Zhang, Zhangyang Wang

**Abstract:** Given a robust model trained to be resilient to one or multiple types of distribution shifts (e.g., natural image corruptions), how is that "robustness" encoded in the model weights, and how easily can it be disentangled and/or "zero-shot" transferred to some other models? This paper empirically suggests a surprisingly simple answer: linearly - by straightforward model weight arithmetic! We start by drawing several key observations: (i) assuming that we train the same model architecture on both a clean dataset and its corrupted version, a comparison between the two resultant models shows their weights to mostly differ in shallow layers; (ii) the weight difference after projection, which we call "Robust Weight Signature" (RWS), appears to be discriminative and indicative of different corruption types; (iii) perhaps most strikingly, for the same corruption type, the RWSs obtained by one model architecture are highly consistent and transferable across different datasets. Based on those RWS observations, we propose a minimalistic model robustness "patching" framework that carries a model trained on clean data together with its pre-extracted RWSs. In this way, injecting certain robustness to the model is reduced to directly adding the corresponding RWS to its weight. We experimentally verify our proposed framework to be remarkably (1) lightweight. since RWSs concentrate on the shallowest few layers and we further show they can be painlessly quantized, storing an RWS is up to 13 x more compact than storing the full weight copy; (2) in-situ adjustable. RWSs can be appended as needed and later taken off to restore the intact clean model. We further demonstrate one can linearly re-scale the RWS to control the patched robustness strength; (3) composable. Multiple RWSs can be added simultaneously to patch more comprehensive robustness at once; and (4) transferable. Even when the clean model backbone is continually adapted or updated, RWSs remain as effective patches due to their outstanding cross-dataset transferability.

**摘要:** 鉴于一个训练以适应一个或多个类型的分布变换(例如自然图像损坏)的鲁棒模型,那么该“鲁棒性”如何被编码在模型重数中,并且它如何容易被切断和/或将“零射击”转移到其他模型? 本文从经验上提出一个令人惊讶的简单的答案:线性 - 通过直接的模型重数算术! 我们首先通过绘制几个关键的观察: (i)假设我们训练相同的模型架构在清洁的数据集和它的损坏版本上,两个结果模型之间的比较显示它们的重数大多在浅层中不同; (ii)投影后的重差,我们称之为“鲁布斯特重量签名”(RWS),似乎是歧视性的和指示不同类型的腐败; (iii)也许最引人注目的是,对于同一类型的腐败,由一个模型架构获得的RWS是非常一致的,并且基于这些RWS观察,我们提出了一种 minimalistic model robustness "patching" framework,它将带走一个由清洁数据训练的模型和其预提取的RWS一起。这样,将某些 robustness注入到模型将直接增加相应的RWS到其重量。我们实验验证了我们提议的框架具有显著的(一)轻量。因为RWS集中于最浅层,我们进一步表明它们可以无痛量化,储存的RWS比储存的全重量拷贝更小13倍;(二)在现场可调整。即使清洁模型的骨干不断调整或更新,RWS仍然是有效的补丁,因为它们具有卓越的跨数据集传输能力。

**[Paper URL](https://proceedings.mlr.press/v202/cai23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cai23f/cai23f.pdf)** 

# Doubly Optimal No-Regret Learning in Monotone Games
**题目:** 双倍最佳的单调游戏无记念学习

**作者:** Yang Cai, Weiqiang Zheng

**Abstract:** We consider online learning in multi-player smooth monotone games. Existing algorithms have limitations such as (1) being only applicable to strongly monotone games; (2) lacking the no-regret guarantee; (3) having only asymptotic or slow $\mathcal{O}(\frac{1}{\sqrt{T}})$ last-iterate convergence rate to a Nash equilibrium. While the $\mathcal{O}(\frac{1}{\sqrt{T}})$ rate is tight for a large class of algorithms including the well-studied extragradient algorithm and optimistic gradient algorithm, it is not optimal for all gradient-based algorithms. We propose the accelerated optimistic gradient (AOG) algorithm, the first doubly optimal no-regret learning algorithm for smooth monotone games. Namely, our algorithm achieves both (i) the optimal $\mathcal{O}(\sqrt{T})$ regret in the adversarial setting under smooth and convex loss functions and (ii) the optimal $\mathcal{O}(\frac{1}{T})$ last-iterate convergence rate to a Nash equilibrium in multi-player smooth monotone games. As a byproduct of the accelerated last-iterate convergence rate, we further show that each player suffers only an $\mathcal{O}(\log T)$ individual worst-case dynamic regret, providing an exponential improvement over the previous state-of-the-art $\mathcal{O}(\sqrt{T})$ bound.

**摘要:** 我们考虑在多人单调游戏中在线学习。现有的算法有局限性,例如(1)只适用于强单调游戏;(2)缺乏无悔保证;(3)只具有渐近或慢的$\mathcal{O}(\frac{1}{\sqrt{T}})$最后定量收敛率到纳什均衡。虽然$\mathcal{O}(\frac{1}{\sqrt{T}})$收敛率为包括经过研究的超梯度算法和乐观梯度算法在内的大型类算法非常紧,但并不是所有基于梯度的算法的最佳收敛率。我们提出了加速的乐观梯度(AOG)算法,第一个双倍最佳的无悔学习算法,即,我们的算法实现了(i)在平滑和凸损失函数下敌对设置中的$\mathcal{O}(\sqrt{T})$遗憾作为加速最后位数收敛率的副产物,我们进一步表明,每个玩家只遭受一个$\mathcal{O}(\log T)$最坏情况下的动态遗憾,提供了比以前最先进的$\mathcal{O}(\sqrt{T})$约束的指数改善。

**[Paper URL](https://proceedings.mlr.press/v202/cai23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cai23g/cai23g.pdf)** 

# Multi-Agent Learning from Learners
**题目:** 多代理人从学习者学习

**作者:** Mine Melodi Caliskan, Francesco Chini, Setareh Maghsudi

**Abstract:** A large body of the "Inverse Reinforcement Learning" (IRL) literature focuses on recovering the reward function from a set of demonstrations of an expert agent who acts optimally or noisily optimally. Nevertheless, some recent works move away from the optimality assumption to study the "Learning from a Learner (LfL)" problem, where the challenge is inferring the reward function of a learning agent from a sequence of demonstrations produced by progressively improving policies. In this work, we take one of the initial steps in addressing the multi-agent version of this problem and propose a new algorithm, MA-LfL (Multiagent Learning from a Learner). Unlike the state-of-the-art literature, which recovers the reward functions from trajectories produced by agents in some equilibrium, we study the problem of inferring the reward functions of interacting agents in a general sum stochastic game without assuming any equilibrium state. The MA-LfL algorithm is rigorously built on a theoretical result that ensures its validity in the case of agents learning according to a multi-agent soft policy iteration scheme. We empirically test MA-LfL and we observe high positive correlation between the recovered reward functions and the ground truth.

**摘要:** 反向强化学习(英语:Inverse Reinforcement Learning,IRL)研究主要集中在从一个专家代理人(英语:Expert agent)的一系列演示中获取奖励函数,其行为是最佳的或噪声最佳的。然而,一些最近的研究从最佳性假设出发,研究了“学习者(英语:Learning from a Learner,LfL)”问题,其中挑战是通过逐步改进政策生成的演示序列推导学习代理人(英语:Learning agent)的奖励函数。在这个研究中,我们采取了解决这一问题的多代理版本的初步步骤之一,提出了一种新的算法,即MA-LfL(Multiagent Learning from a Learner)。MA-LfL算法是严格建立在基于多代理软策略迭代方案的代理学习的理论结果之上,以确保其有效性。我们以实证测试MA-LfL,并观察到恢复的奖励函数与地面真理之间存在较高的正相关性。

**[Paper URL](https://proceedings.mlr.press/v202/caliskan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/caliskan23a/caliskan23a.pdf)** 

# Efficient Learning of Mesh-Based Physical Simulation with Bi-Stride Multi-Scale Graph Neural Network
**题目:** 双线性多尺度图形神经网络基于网格物理仿真的有效学习

**作者:** Yadi Cao, Menglei Chai, Minchen Li, Chenfanfu Jiang

**Abstract:** Learning the long-range interactions on large-scale mesh-based physical systems with flat Graph Neural Networks (GNNs) and stacking Message Passings (MPs) is challenging due to the scaling complexity w.r.t. the number of nodes and over-smoothing. Therefore, there has been growing interest in the community to introduce multi-scale structures to GNNs for physics simulation. However, current state-of-the-art methods are limited by their reliance on the labor-heavy drawing of coarser meshes or building coarser levels based on spatial proximity, which can introduce wrong edges across geometry boundaries. Inspired by the bipartite graph determination, we propose a novel pooling strategy, bi-stride to tackle the aforementioned limitations. Bi-stride pools nodes on every other frontier of the Breadth-First-Search (BFS), without the need for the manual drawing of coarser meshes and, avoid wrong edges introduced by spatial proximity. Additionally, it enables a reduced number of MP times on each level and the non-parametrized pooling and unpooling by interpolations, similar to convolutional Neural Networks (CNNs), which significantly reduces computational requirements. Experiments show that the proposed framework, BSMS-GNN, significantly outperforms existing methods in terms of both accuracy and computational efficiency in representative physics-based simulation scenarios.

**摘要:** 利用平面图神经网络(GNN)和堆叠消息传递(MPs)来学习大规模网格基础物理系统中的长距离相互作用,是由于节点数和超缓冲的规模复杂性而引起的挑战。因此,人们对GNN的物理仿真引入多维结构的兴趣日益增加。然而,目前的最先进的方法是依靠劳力密集的粗网格图画或基于空间近距离的粗网格图画来限制,这可以引入几何边界上的错误边缘。此外,它可以使每个级别的MP次数减少,并通过插值进行非参数化聚合和分离,类似于卷积神经网络(CNN),这大大降低了计算要求。实验表明,提出的框架BSMS-GNN在代表物理模拟场景中,在精度和计算效率方面大大超过现有的方法。

**[Paper URL](https://proceedings.mlr.press/v202/cao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cao23a/cao23a.pdf)** 

# Variational Sparse Inverse Cholesky Approximation for Latent Gaussian Processes via Double Kullback-Leibler Minimization
**题目:** 双库尔巴克-莱布勒微化法对隐形高斯过程的变节逆肖尔斯基近似

**作者:** Jian Cao, Myeongjong Kang, Felix Jimenez, Huiyan Sang, Florian Tobias Schaefer, Matthias Katzfuss

**Abstract:** To achieve scalable and accurate inference for latent Gaussian processes, we propose a variational approximation based on a family of Gaussian distributions whose covariance matrices have sparse inverse Cholesky (SIC) factors. We combine this variational approximation of the posterior with a similar and efficient SIC-restricted Kullback-Leibler-optimal approximation of the prior. We then focus on a particular SIC ordering and nearest-neighbor-based sparsity pattern resulting in highly accurate prior and posterior approximations. For this setting, our variational approximation can be computed via stochastic gradient descent in polylogarithmic time per iteration. We provide numerical comparisons showing that the proposed double-Kullback-Leibler-optimal Gaussian-process approximation (DKLGP) can sometimes be vastly more accurate for stationary kernels than alternative approaches such as inducing-point and mean-field approximations at similar computational complexity.

**摘要:** 为了实现隐形高斯过程的可 skalable and accurate inference,我们提出了一种基于高斯分布的变量近似,其共变矩阵具有稀有逆 Cholesky (SIC) 因素的变量近似。我们将后方的变量近似与前方的相似和有效的 SIC 限制的Kullback-Leibler-optimal近似结合起来。然后,我们着重于特定 SIC 顺序和最接近邻近的稀疏模式,从而产生高度准确的前方和后方近似。为此设置,我们的变量近似可以用随机梯度下降在每迭代的多项式时间来计算。

**[Paper URL](https://proceedings.mlr.press/v202/cao23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cao23b/cao23b.pdf)** 

# Learning Lightweight Object Detectors via Multi-Teacher Progressive Distillation
**题目:** 通过多教师进化蒸馏学习轻量物体检测器

**作者:** Shengcao Cao, Mengtian Li, James Hays, Deva Ramanan, Yu-Xiong Wang, Liangyan Gui

**Abstract:** Resource-constrained perception systems such as edge computing and vision-for-robotics require vision models to be both accurate and lightweight in computation and memory usage. While knowledge distillation is a proven strategy to enhance the performance of lightweight classification models, its application to structured outputs like object detection and instance segmentation remains a complicated task, due to the variability in outputs and complex internal network modules involved in the distillation process. In this paper, we propose a simple yet surprisingly effective sequential approach to knowledge distillation that progressively transfers the knowledge of a set of teacher detectors to a given lightweight student. To distill knowledge from a highly accurate but complex teacher model, we construct a sequence of teachers to help the student gradually adapt. Our progressive strategy can be easily combined with existing detection distillation mechanisms to consistently maximize student performance in various settings. To the best of our knowledge, we are the first to successfully distill knowledge from Transformer-based teacher detectors to convolution-based students, and unprecedentedly boost the performance of ResNet-50 based RetinaNet from 36.5% to 42.0% AP and Mask R-CNN from 38.2% to 42.5% AP on the MS COCO benchmark. Code available at https://github.com/Shengcao-Cao/MTPD.

**摘要:** 基于资源约束的视觉系统,如边缘计算和机器人视觉,需要视觉模型在计算和记忆使用中具有准确性和轻量性。虽然知识蒸馏是提高轻量分类模型性能的已证明的策略,但其对结构化输出,如对象检测和实例分割仍然是一个复杂的任务,因为输出的变异性和蒸馏过程中涉及的复杂内部网络模块。我们的进步策略可以轻易地结合现有检测蒸馏机制,以持续最大化学生在各种环境中的表现。为了获得最好的知识,我们是第一个成功地从变形器基础的教师检测器中蒸馏知识,并从36.5%到42.0%的RetinaNet基础的ResNet-50和从38.2%到42.5%的 Mask R-CNN在MSCOCO基准上提高性能。代码可于 https://github.com/Shengcao-Cao/MTPD。

**[Paper URL](https://proceedings.mlr.press/v202/cao23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cao23c/cao23c.pdf)** 

# One-sided Matrix Completion from Two Observations Per Row
**题目:** 单边矩阵从每行两项观察中完成

**作者:** Steven Cao, Percy Liang, Gregory Valiant

**Abstract:** Given only a few observed entries from a low-rank matrix $X$, matrix completion is the problem of imputing the missing entries, and it formalizes a wide range of real-world settings that involve estimating missing data. However, when there are too few observed entries to complete the matrix, what other aspects of the underlying matrix can be reliably recovered? We study one such problem setting, that of “one-sided” matrix completion, where our goal is to recover the right singular vectors of $X$, even in the regime where recovering the left singular vectors is impossible, which arises when there are more rows than columns and very few observations. We propose a natural algorithm that involves imputing the missing values of the matrix $X^TX$ and show that even with only two observations per row in $X$, we can provably recover $X^TX$ as long as we have at least $\Omega(r^2 d \log d)$ rows, where $r$ is the rank and $d$ is the number of columns. We evaluate our algorithm on one-sided recovery of synthetic data and low-coverage genome sequencing. In these settings, our algorithm substantially outperforms standard matrix completion and a variety of direct factorization methods.

**摘要:** 由于只有少数从低级矩阵$X$中观察到的输入,矩阵完成是计算丢失的输入的难题,它形式化了涉及估计丢失的数据的广泛的现实环境设置。然而,当有太多观察到的输入完成矩阵时,底层矩阵的其他方面可以可靠地恢复吗?我们研究了一个这样的问题设置,即“单边”矩阵完成,我们的目标是恢复$X$的右单元向量,即使在无法恢复左单元向量的模式下,这种模式在有超过列数和极少数观察时出现。我们提出了一种自然算法,它涉及计算矩阵$X^TX$的丢失值,并表明即使在$X$中的每行只有两个观察,我们也可以证明$X^TX$的恢复,只要我们至少有$\Omega(r^2 d \log d)$行,其中$我们对合成数据的单边恢复和低覆盖率基因组序列的算法进行了评价,在这些条件下,我们的算法大大超过了标准矩阵完成和各种直接加权方法。

**[Paper URL](https://proceedings.mlr.press/v202/cao23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cao23d/cao23d.pdf)** 

# State and parameter learning with PARIS particle Gibbs
**题目:** PARIS粒子吉布斯的状态与参数学习

**作者:** Gabriel Cardoso, Yazid Janati El Idrissi, Sylvain Le Corff, Eric Moulines, Jimmy Olsson

**Abstract:** Non-linear state-space models, also known as general hidden Markov models (HMM), are ubiquitous in statistical machine learning, being the most classical generative models for serial data and sequences. Learning in HMM, either via Maximum Likelihood Estimation (MLE) or Markov Score Climbing (MSC) requires the estimation of the- smoothing expectation of some additive functionals. Controlling the bias and the variance of this estimation is crucial to establish the convergence of learning algorithms. Our first contribution is to design a novel additive smoothing algorithm, the Parisian particle Gibbs (PPG) sampler, which can be viewed as a PaRIS (Olsson, Westerborn 2017) algorithm driven by conditional SMC moves, resulting in bias-reduced estimates of the targeted quantities. We substantiate the PPG algorithm with theoretical results, including new bounds on bias and variance as well as deviation inequalities. We then establish, in the learning context, and under standard assumptions, non-asymptotic bounds highlighting the value of bias reduction and the implicit Rao–Blackwellization of PPG. These are the first non-asymptotic results of this kind in this setting. We illustrate our theoretical results with numerical experiments supporting our claims.

**摘要:** 非线性状态空间模型(英语:Non-linear state-space models),也称为一般隐形马可夫模型(英语:General hidden Markov models)(HMM),在统计机器学习中普遍存在,是序列数据和序列最经典的生成模型。在HMM学习中,通过最大概率估计(MLE)或马可夫分数 climbing(MSC)需要对某些添加函数的加滑预期的估计。控制这种估计的偏差和变量对于建立学习算法的收敛性至关重要。然后,在学习环境下,在标准假设下,确定了非渐近的界限,突出了偏见减小的价值和PPG的拉奥-布莱克韦尔隐含性。这是这种环境中第一个非渐近的结果。

**[Paper URL](https://proceedings.mlr.press/v202/cardoso23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cardoso23a/cardoso23a.pdf)** 

# Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning
**题目:** 基于网络增强学习在互动环境中建立大型语言模型

**作者:** Thomas Carta, Clément Romac, Thomas Wolf, Sylvain Lamprier, Olivier Sigaud, Pierre-Yves Oudeyer

**Abstract:** Recent works successfully leveraged Large Language Models’ (LLM) abilities to capture abstract knowledge about world’s physics to solve decision-making problems. Yet, the alignment between LLMs’ knowledge and the environment can be wrong and limit functional competence due to lack of grounding. In this paper, we study an approach (named GLAM) to achieve this alignment through functional grounding: we consider an agent using an LLM as a policy that is progressively updated as the agent interacts with the environment, leveraging online Reinforcement Learning to improve its performance to solve goals. Using an interactive textual environment designed to study higher-level forms of functional grounding, and a set of spatial and navigation tasks, we study several scientific questions: 1) Can LLMs boost sample efficiency for online learning of various RL tasks? 2) How can it boost different forms of generalization? 3) What is the impact of online learning? We study these questions by functionally grounding several variants (size, architecture) of FLAN-T5.

**摘要:** 最近的工作成功地利用了大型语言模型(LLM)的能力,以获取关于世界物理学的抽象知识来解决决策问题。然而,LLM的知识与环境的一致性可能是错误的,并且由于缺乏基础,限制了功能能力。利用设计为研究功能基准的更高层次形式的交互文本环境,以及一系列空间和导航任务,我们研究了几个科学问题: 1)LLM能提高不同RL任务的在线学习样本效率吗? 2)它如何提高不同形式的一般化? 3)在线学习的影响是什么? 我们通过功能基准FLAN-T5的几个变量(大小、架构)来研究这些问题。

**[Paper URL](https://proceedings.mlr.press/v202/carta23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/carta23a/carta23a.pdf)** 

# Stein Variational Goal Generation for adaptive Exploration in Multi-Goal Reinforcement Learning
**题目:** 施泰因变目标生成在多目标强化学习中适应性探索

**作者:** Nicolas Castanet, Olivier Sigaud, Sylvain Lamprier

**Abstract:** In multi-goal Reinforcement Learning, an agent can share experience between related training tasks, resulting in better generalization for new tasks at test time. However, when the goal space has discontinuities and the reward is sparse, a majority of goals are difficult to reach. In this context, a curriculum over goals helps agents learn by adapting training tasks to their current capabilities. In this work, we propose Stein Variational Goal Generation (SVGG), which samples goals of intermediate difficulty for the agent, by leveraging a learned predictive model of its goal reaching capabilities. The distribution of goals is modeled with particles that are attracted in areas of appropriate difficulty using Stein Variational Gradient Descent. We show that SVGG outperforms state-of-the-art multi-goal Reinforcement Learning methods in terms of success coverage in hard exploration problems, and demonstrate that it is endowed with a useful recovery property when the environment changes.

**摘要:** 在多目标强化学习中,一个代理人可以分享相关训练任务的经验,从而在测试时对新任务进行更好的一般化。然而,目标空间有不连续性和奖励稀少时,目标的大部分很难达到。在这方面,目标的课程帮助代理人通过适应训练任务到当前的能力学习。在这个工作中,我们提出了施泰因变量目标生成(SVGG),通过利用其目标达到能力的学习预测模型,对代理人的中间困难目标进行抽样。目标的分布是利用施泰因变量梯度下降来吸引在适当困难区域的粒子进行建模。

**[Paper URL](https://proceedings.mlr.press/v202/castanet23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/castanet23a/castanet23a.pdf)** 

# Scalable Safe Policy Improvement via Monte Carlo Tree Search
**题目:** 通过蒙特卡罗树搜索可扩展的安全政策改进

**作者:** Alberto Castellini, Federico Bianchi, Edoardo Zorzi, Thiago D. Simão, Alessandro Farinelli, Matthijs T. J. Spaan

**Abstract:** Algorithms for safely improving policies are important to deploy reinforcement learning approaches in real-world scenarios. In this work, we propose an algorithm, called MCTS-SPIBB, that computes safe policy improvement online using a Monte Carlo Tree Search based strategy. We theoretically prove that the policy generated by MCTS-SPIBB converges, as the number of simulations grows, to the optimal safely improved policy generated by Safe Policy Improvement with Baseline Bootstrapping (SPIBB), a popular algorithm based on policy iteration. Moreover, our empirical analysis performed on three standard benchmark domains shows that MCTS-SPIBB scales to significantly larger problems than SPIBB because it computes the policy online and locally, i.e., only in the states actually visited by the agent.

**摘要:** 基于蒙特卡罗树搜索的策略,我们提出了一种基于网络安全政策改进的算法,即MCTS-SPIBB。我们理论上证明,随着仿真数目增加,由基于网络安全政策改进(SPIBB)生成的最优安全改进政策,即基于网络安全政策改进(Secure Policy Improvement with Baseline Bootstrapping)(SPIBB)的流行算法。此外,我们对三种标准基准域进行的实证分析显示,MCTS-SPIBB比SPIBB更严重的问题,因为它在网络和本地计算政策,即仅在代理人实际访问的国家。

**[Paper URL](https://proceedings.mlr.press/v202/castellini23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/castellini23a/castellini23a.pdf)** 

# LESS-VFL: Communication-Efficient Feature Selection for Vertical Federated Learning
**题目:** LESS-VFL:垂直联合学习的通信效率特征选择

**作者:** Timothy Castiglia, Yi Zhou, Shiqiang Wang, Swanand Kadhe, Nathalie Baracaldo, Stacy Patterson

**Abstract:** We propose LESS-VFL, a communication-efficient feature selection method for distributed systems with vertically partitioned data. We consider a system of a server and several parties with local datasets that share a sample ID space but have different feature sets. The parties wish to collaboratively train a model for a prediction task. As part of the training, the parties wish to remove unimportant features in the system to improve generalization, efficiency, and explainability. In LESS-VFL, after a short pre-training period, the server optimizes its part of the global model to determine the relevant outputs from party models. This information is shared with the parties to then allow local feature selection without communication. We analytically prove that LESS-VFL removes spurious features from model training. We provide extensive empirical evidence that LESS-VFL can achieve high accuracy and remove spurious features at a fraction of the communication cost of other feature selection approaches.

**摘要:** 我们提出了一种具有垂直分区数据的分布式系统通信效率的特征选择方法,即LESS-VFL。我们考虑一个服务器和几个与局部数据集的系统,它们共享一个样品ID空间,但有不同的特征集。当事方希望共同训练一个预测任务的模型。作为培训的一部分,当事方希望在系统中消除不重要的特征,以改善一般化、效率和解释性。在LESS-VFL中,在短的预培训期间,服务器优化了其全球模型的一部分,以确定来自党模型的相关输出。我们提供了广泛的实证证据,表明 LESS-VFL能够达到较高的精度,并以其他特征选择方法的通信成本的一小部分消除伪造特征。

**[Paper URL](https://proceedings.mlr.press/v202/castiglia23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/castiglia23a/castiglia23a.pdf)** 

# On the Robustness of Text Vectorizers
**题目:** 关于文本向量器的鲁棒性

**作者:** Rémi Catellier, Samuel Vaiter, Damien Garreau

**Abstract:** A fundamental issue in machine learning is the robustness of the model with respect to changes in the input. In natural language processing, models typically contain a first embedding layer, transforming a sequence of tokens into vector representations. While the robustness with respect to changes of continuous inputs is well-understood, the situation is less clear when considering discrete changes, for instance replacing a word by another in an input sentence. Our work formally proves that popular embedding schemes, such as concatenation, TF-IDF, and Paragraph Vector (a.k.a. doc2vec), exhibit robustness in the Hölder or Lipschitz sense with respect to the Hamming distance. We provide quantitative bounds for these schemes and demonstrate how the constants involved are affected by the length of the document. These findings are exemplified through a series of numerical examples.

**摘要:** 在机器学习中,一个基本问题是对输入的变化模型的鲁棒性。在自然语言处理中,模型通常包含第一个嵌入层,将符号的序列转换为向量表示。对连续输入的变化的鲁棒性是十分了解的,但考虑离散变化时的情况并不那么清楚,例如在输入句子中用另一个词代替一个词。我们的工作正式证明了流行的嵌入方案,如合并、TF-IDF和段向量(英语:Paragraph Vector (a.k.a. doc2vec)),对海尔德或莱普茨的距离表现出鲁棒性。我们为这些方案提供定量界限,并证明有关的常数如何受到文件长度的影响。这些发现通过一系列的数值实例证明。

**[Paper URL](https://proceedings.mlr.press/v202/catellier23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/catellier23a/catellier23a.pdf)** 

# Learning Globally Smooth Functions on Manifolds
**题目:** 学习多姿态的全球滑动函数

**作者:** Juan Cervino, Luiz F. O. Chamon, Benjamin David Haeffele, Rene Vidal, Alejandro Ribeiro

**Abstract:** Smoothness and low dimensional structures play central roles in improving generalization and stability in learning and statistics. This work combines techniques from semi-infinite constrained learning and manifold regularization to learn representations that are globally smooth on a manifold. To do so, it shows that under typical conditions the problem of learning a Lipschitz continuous function on a manifold is equivalent to a dynamically weighted manifold regularization problem. This observation leads to a practical algorithm based on a weighted Laplacian penalty whose weights are adapted using stochastic gradient techniques. It is shown that under mild conditions, this method estimates the Lipschitz constant of the solution, learning a globally smooth solution as a byproduct. Experiments on real world data illustrate the advantages of the proposed method relative to existing alternatives. Our code is available at https://github.com/JuanCervino/smoothbench.

**摘要:** 滑度和低维结构在学习和统计中提高广义化和稳定性方面起着中心作用。该工作结合半无限约束学习和多维规则化技术,以学习在多维上全球平滑的表示。为此,它显示在典型的条件下,学习多维上的利普希茨连续函数的问题与动态权重的多维规则化问题相等。这一观察导致基于权重的拉普拉西亚刑罚的实用算法,其权重采用随机梯度技术来调整。

**[Paper URL](https://proceedings.mlr.press/v202/cervino23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cervino23a/cervino23a.pdf)** 

# Tighter Lower Bounds for Shuffling SGD: Random Permutations and Beyond
**题目:** 缓冲SGD的更严格的下限:随机变换及 beyond

**作者:** Jaeyoung Cha, Jaewook Lee, Chulhee Yun

**Abstract:** We study convergence lower bounds of without-replacement stochastic gradient descent (SGD) for solving smooth (strongly-)convex finite-sum minimization problems. Unlike most existing results focusing on final iterate lower bounds in terms of the number of components $n$ and the number of epochs $K$, we seek bounds for arbitrary weighted average iterates that are tight in all factors including the condition number $\kappa$. For SGD with Random Reshuffling, we present lower bounds that have tighter $\kappa$ dependencies than existing bounds. Our results are the first to perfectly close the gap between lower and upper bounds for weighted average iterates in both strongly-convex and convex cases. We also prove weighted average iterate lower bounds for arbitrary permutation-based SGD, which apply to all variants that carefully choose the best permutation. Our bounds improve the existing bounds in factors of $n$ and $\kappa$ and thereby match the upper bounds shown for a recently proposed algorithm called GraB.

**摘要:** 我们研究了无置换随机梯度下降(SGD)的收敛较低边界,以解决平滑(粗糙)凸有限总的最小化问题。与大多数现有的结果不同,我们以有限元数 $n$ 和时代数 $K$ 为准,寻找任意权重平均迭代的边界,包括条件数 $\kappa$ 。 对于随机重叠的SGD,我们给出了更紧的 $\kappa$ 依存关系的较低边界。我们的结果是第一个在强凸和凸情况下完全关闭下边界和上边界之间权重平均迭代的差距。我们还证明了任意变换基于SGD的权重平均迭代的较低边界,适用于所有选择最佳变换的变量。我们的边界改进了$n$和$\kappa$的现有边界,从而与最近提出的 GraB算法上边界匹配。

**[Paper URL](https://proceedings.mlr.press/v202/cha23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cha23a/cha23a.pdf)** 

# Orthogonality-Enforced Latent Space in Autoencoders: An Approach to Learning Disentangled Representations
**题目:** 自动编码器中的正交强制拉特空间:学习分散表示的方法

**作者:** Jaehoon Cha, Jeyan Thiyagalingam

**Abstract:** Noting the importance of factorizing (or disentangling) the latent space, we propose a novel, non-probabilistic disentangling framework for autoencoders, based on the principles of symmetry transformations that are independent of one another. To the best of our knowledge, this is the first deterministic model that is aiming to achieve disentanglement based on autoencoders using only a reconstruction loss without pairs of images or labels, by explicitly introducing inductive biases into a model architecture through Euler encoding. The proposed model is then compared with a number of state-of-the-art models, relevant to disentanglement, including symmetry-based models and generative models. Our evaluation using six different disentanglement metrics, including the unsupervised disentanglement metric we propose here in this paper, shows that the proposed model can offer better disentanglement, especially when variances of the features are different, where other methods may struggle. We believe that this model opens several opportunities for linear disentangled representation learning based on deterministic autoencoders.

**摘要:** 本文提出了一种基于互称变换原理的非可信的自动编码器分离框架,以考虑分离空间的因素(或分离)的重要性。本模型旨在实现基于自动编码器的分离,仅通过欧勒编码 explicitly introducing inductive biases into a model architecture。该模型然后与一些有关分离的最先进的模型进行了比较,包括基于互称的模型和生成模型。我们利用六种分离度量,包括无监督分离度量的方法进行评估,表明该模型能够提供更好的分离,特别是在特征的差异不同的情况下,其他方法可能有困难。我们认为,该模型为基于确定式自动编码器的线性无界表示学习提供了多种机会。

**[Paper URL](https://proceedings.mlr.press/v202/cha23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cha23b/cha23b.pdf)** 

# STEERING : Stein Information Directed Exploration for Model-Based Reinforcement Learning
**题目:** 指导:施泰因信息导向的基于模型强化学习研究

**作者:** Souradip Chakraborty, Amrit Bedi, Alec Koppel, Mengdi Wang, Furong Huang, Dinesh Manocha

**Abstract:** Directed Exploration is a crucial challenge in reinforcement learning (RL), especially when rewards are sparse. Information-directed sampling (IDS), which optimizes the information ratio, seeks to do so by augmenting regret with information gain. However, estimating information gain is computationally intractable or relies on restrictive assumptions which prohibit its use in many practical instances. In this work, we posit an alternative exploration incentive in terms of the integral probability metric (IPM) between a current estimate of the transition model and the unknown optimal, which under suitable conditions, can be computed in closed form with the kernelized Stein discrepancy (KSD). Based on KSD, we develop a novel algorithm STEERING: STEin information dirEcted exploration for model-based Reinforcement LearnING. To enable its derivation, we develop fundamentally new variants of KSD for discrete conditional distributions. We further establish that STEERING archives sublinear Bayesian regret, improving upon prior learning rates of information-augmented MBRL, IDS included. Experimentally, we show that the proposed algorithm is computationally affordable and outperforms several prior approaches.

**摘要:** 直接探索是增强学习(RL)中的一个关键性挑战,特别是 rewards 较少时。 信息导向抽样(IDS)是优化信息比的手段,它通过增加信息收益的遗憾来实现这一点。 然而,估计信息收益是计算上难以解决的,或依赖于限制性假设,禁止在许多实际情况下使用它。 在这个工作中,我们提出了一种替代的探索激励,以积分概率计量(IPM)的形式,在当前的转换模型估计和未知最佳模型之间,在适当条件下,可以与核化施泰因差异(KSD)的封闭形式计算。进一步证明,STEERING Archaealogs是基于改进信息增强的MBRL(包括IDS)预先学习率的次线性贝叶斯式遗憾 Archaealogs是基于改进信息增强 MBRL(包括IDS)预先学习率的次线性贝叶斯式遗憾 Archaealogs是基于改进信息增强 MBRL(包括IDS)预先学习率的次线性贝叶斯式遗憾 Archaealogs是基于改进信息增强 MBRL(包括IDS)预先学习率的次线性贝叶斯式遗憾 Archaealogs是基于改进信息增强 MBRL(包括IDS)预先学习率的次线性贝叶斯式遗憾 Archaealogs是基于改进信息增强 MBRL(包括IDS)预先学习率的次线性贝叶斯式遗憾 Archaea

**[Paper URL](https://proceedings.mlr.press/v202/chakraborty23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chakraborty23a/chakraborty23a.pdf)** 

# Thompson Sampling for High-Dimensional Sparse Linear Contextual Bandits
**题目:** 汤普森对高尺寸节骨线性构造带的采样

**作者:** Sunrit Chakraborty, Saptarshi Roy, Ambuj Tewari

**Abstract:** We consider the stochastic linear contextual bandit problem with high-dimensional features. We analyze the Thompson sampling algorithm using special classes of sparsity-inducing priors (e.g., spike-and-slab) to model the unknown parameter and provide a nearly optimal upper bound on the expected cumulative regret. To the best of our knowledge, this is the first work that provides theoretical guarantees of Thompson sampling in high-dimensional and sparse contextual bandits. For faster computation, we use variational inference instead of Markov Chain Monte Carlo (MCMC) to approximate the posterior distribution. Extensive simulations demonstrate the improved performance of our proposed algorithm over existing ones.

**摘要:** 我们考虑了具有高维特征的随机线性上下文带子问题。我们分析了汤普森采样算法,利用稀疏诱导前序的特殊类别(例如 spike-and-slab)模拟未知参数,并提供 near optimal upper bound on the expected cumulative regret。根据我们的知识,这是第一个在高维和稀疏上下文带子中提供汤普森采样的理论保证的工作。

**[Paper URL](https://proceedings.mlr.press/v202/chakraborty23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chakraborty23b/chakraborty23b.pdf)** 

# Representations and Exploration for Deep Reinforcement Learning using Singular Value Decomposition
**题目:** 基于单值分解的深度增强学习表现与探索

**作者:** Yash Chandak, Shantanu Thakoor, Zhaohan Daniel Guo, Yunhao Tang, Remi Munos, Will Dabney, Diana L Borsa

**Abstract:** Representation learning and exploration are among the key challenges for any deep reinforcement learning agent. In this work, we provide a singular value decomposition based method that can be used to obtain representations that preserve the underlying transition structure in the domain. Perhaps interestingly, we show that these representations also capture the relative frequency of state visitations, thereby providing an estimate for pseudo-counts for free. To scale this decomposition method to large-scale domains, we provide an algorithm that never requires building the transition matrix, can make use of deep networks, and also permits mini-batch training. Further, we draw inspiration from predictive state representations and extend our decomposition method to partially observable environments. With experiments on multi-task settings with partially observable domains, we show that the proposed method can not only learn useful representation on DM-Lab-30 environments (that have inputs involving language instructions, pixel images, rewards, among others) but it can also be effective at hard exploration tasks in DM-Hard-8 environments.

**摘要:** 描述学习和探索是任何深度增强学习机构的关键挑战之一。在这项工作中,我们提供一种基于单一值的分解方法,可用于获取在域内保持基本的转换结构的表示。也许有趣的是,我们显示这些表示也捕捉到州访问的相对频率,从而为伪数提供免费的估计。为了将这个分解方法扩展到大规模域,我们提供了一种不需要建立过渡矩阵的算法,可以利用深度网络,并且允许小批量训练。通过对部分可观测域的多任务设置的实验,我们表明,该方法不仅可以在DM-Lab-30环境中学习有用的表示(包括语言指令、像素图像、奖励等输入)而且在DM-Hard-8环境中也能有效执行难的探索任务。

**[Paper URL](https://proceedings.mlr.press/v202/chandak23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chandak23a/chandak23a.pdf)** 

# Memory-Based Dual Gaussian Processes for Sequential Learning
**题目:** 基于记忆的双重高斯过程用于序列学习

**作者:** Paul Edmund Chang, Prakhar Verma, S. T. John, Arno Solin, Mohammad Emtiyaz Khan

**Abstract:** Sequential learning with Gaussian processes (GPs) is challenging when access to past data is limited, for example, in continual and active learning. In such cases, errors can accumulate over time due to inaccuracies in the posterior, hyperparameters, and inducing points, making accurate learning challenging. Here, we present a method to keep all such errors in check using the recently proposed dual sparse variational GP. Our method enables accurate inference for generic likelihoods and improves learning by actively building and updating a memory of past data. We demonstrate its effectiveness in several applications involving Bayesian optimization, active learning, and continual learning.

**摘要:** 高斯过程的序列学习(英语:Sequential learning with Gaussian processes)(GPs)是当访问过去的数据受到限制时的挑战,例如在持续学习和主动学习中。在这种情况下,由于后部、超参数和诱导点的误差,误差会随着时间的推移积累,从而使准确学习变得困难。

**[Paper URL](https://proceedings.mlr.press/v202/chang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chang23a/chang23a.pdf)** 

# Muse: Text-To-Image Generation via Masked Generative Transformers
**题目:** Muse:通过 Masked Generative Transformers生成文本到图像

**作者:** Huiwen Chang, Han Zhang, Jarred Barber, Aaron Maschinot, Jose Lezama, Lu Jiang, Ming-Hsuan Yang, Kevin Patrick Murphy, William T. Freeman, Michael Rubinstein, Yuanzhen Li, Dilip Krishnan

**Abstract:** We present Muse, a text-to-image Transformermodel that achieves state-of-the-art image genera-tion performance while being significantly moreefficient than diffusion or autoregressive models.Muse is trained on a masked modeling task indiscrete token space: given the text embeddingextracted from a pre-trained large language model(LLM), Muse learns to predict randomly maskedimage tokens. Compared to pixel-space diffusionmodels, such as Imagen and DALL-E 2, Muse issignificantly more efficient due to the use of dis-crete tokens and requires fewer sampling itera-tions; compared to autoregressive models such asParti, Muse is more efficient due to the use of par-allel decoding. The use of a pre-trained LLM en-ables fine-grained language understanding, whichtranslates to high-fidelity image generation andthe understanding of visual concepts such as ob-jects, their spatial relationships, pose, cardinalityetc. Our 900M parameter model achieves a newSOTA on CC3M, with an FID score of 6.06. TheMuse 3B parameter model achieves an FID of7.88 on zero-shot COCO evaluation, along with aCLIP score of 0.32. Muse also directly enables anumber of image editing applications without theneed to fine-tune or invert the model: inpainting,outpainting, and mask-free editing. More resultsand videos demonstrating editing are available at https://muse-icml.github.io/

**摘要:** 本文介绍了一种从文本到图像的变换模型,该模型实现了最先进的图像生成性能,同时比扩散或自回归模型更高效。 该模型是基于隐形建模任务的隐形符号空间进行训练的:由于从预训练的大型语言模型(LLM)中提取的文本嵌入,该模型学习预测随机隐形图像符号。 与像素空间扩散模型,如Imagen和DALL-E2相比,该模型由于使用非隐形符号而具有显著的效率,需要少量采样迭代;与Parti等自回归模型相比,该模型由于使用par-allel解码而具有更大的效率。Muse3B参数模型在零射击COCOCO评定中达到了7.88的FID,以及0.32的CLIP评分。Muse还直接允许无须调整或逆转模型的图像编辑应用程序:内油漆、外油漆和无面具的编辑。 More resultsand videos demonstrating editing are available at https://muse-icml.github.io/

**[Paper URL](https://proceedings.mlr.press/v202/chang23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chang23b/chang23b.pdf)** 

# On Investigating the Conservative Property of Score-Based Generative Models
**题目:** 基于分数生成模型的保守特性研究

**作者:** Chen-Hao Chao, Wei-Fang Sun, Bo-Wun Cheng, Chun-Yi Lee

**Abstract:** Existing Score-Based Models (SBMs) can be categorized into constrained SBMs (CSBMs) or unconstrained SBMs (USBMs) according to their parameterization approaches. CSBMs model probability density functions as Boltzmann distributions, and assign their predictions as the negative gradients of some scalar-valued energy functions. On the other hand, USBMs employ flexible architectures capable of directly estimating scores without the need to explicitly model energy functions. In this paper, we demonstrate that the architectural constraints of CSBMs may limit their modeling ability. In addition, we show that USBMs’ inability to preserve the property of conservativeness may lead to degraded performance in practice. To address the above issues, we propose Quasi-Conservative Score-Based Models (QCSBMs) for keeping the advantages of both CSBMs and USBMs. Our theoretical derivations demonstrate that the training objective of QCSBMs can be efficiently integrated into the training processes by leveraging the Hutchinson’s trace estimator. In addition, our experimental results on the CIFAR-10, CIFAR-100, ImageNet, and SVHN datasets validate the effectiveness of QCSBMs. Finally, we justify the advantage of QCSBMs using an example of a one-layered autoencoder.

**摘要:** 现有基于分数模型可以根据其参数化方法分类为约束性分数模型(CSBMs)或无约束性分数模型(USBMs)。CSBMs作为玻尔茨曼分布的概率密度函数模型,并将它们的预测归类为某些标尺值能量函数的负梯度。另一方面,USBMs采用灵活的架构,可以直接估计分数,而不需要明确建模能量函数。我们的理论推导表明,通过利用哈钦森的跟踪估计器,可以有效地整合QCSBM的训练目标。此外,我们对CIFAR-10、CIFAR-100、ImageNet和SVHN数据集的实验结果验证了QCSBM的有效性。最后,我们利用一个单层自动编码器的例子证明了QCSBM的优点。

**[Paper URL](https://proceedings.mlr.press/v202/chao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chao23a/chao23a.pdf)** 

# Robust and private stochastic linear bandits
**题目:** 鲁棒和私人随机线性强盗

**作者:** Vasileios Charisopoulos, Hossein Esfandiari, Vahab Mirrokni

**Abstract:** In this paper, we study the stochastic linear bandit problem under the additional requirements of differential privacy, robustness and batched observations. In particular, we assume an adversary randomly chooses a constant fraction of the observed rewards in each batch, replacing them with arbitrary numbers. We present differentially private and robust variants of the arm elimination algorithm using logarithmic batch queries under two privacy models and provide regret bounds in both settings. In the first model, every reward in each round is reported by a potentially different client, which reduces to standard local differential privacy (LDP). In the second model, every action is "owned" by a different client, who may aggregate the rewards over multiple queries and privatize the aggregate response instead. To the best of our knowledge, our algorithms are the first simultaneously providing differential privacy and adversarial robustness in the stochastic linear bandits problem.

**摘要:** 本文对随机线性盗窃问题进行了研究,并针对随机线性盗窃问题提出了随机线性盗窃算法的额外要求,包括随机盗窃、随机盗窃、随机盗窃、随机盗窃、随机盗窃、随机盗窃、随机盗窃、随机盗窃、随机盗窃、随机盗窃、随机盗窃等。

**[Paper URL](https://proceedings.mlr.press/v202/charisopoulos23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/charisopoulos23a/charisopoulos23a.pdf)** 

# Streaming Submodular Maximization with Differential Privacy
**题目:** 微分隐私的 Streaming 子模块化最大化

**作者:** Anamay Chaturvedi, Huy Nguyen, Thy Dinh Nguyen

**Abstract:** In this work, we study the problem of privately maximizing a submodular function in the streaming setting. Extensive work has been done on privately maximizing submodular functions in the general case when the function depends upon the private data of individuals. However, when the size of the data stream drawn from the domain of the objective function is large or arrives very fast, one must privately optimize the objective within the constraints of the streaming setting. We establish fundamental differentially private baselines for this problem and then derive better trade-offs between privacy and utility for the special case of decomposable submodular functions. A submodular function is decomposable when it can be written as a sum of submodular functions; this structure arises naturally when each summand function models the utility of an individual and the goal is to study the total utility of the whole population as in the well-known Combinatorial Public Projects Problem. Finally, we complement our theoretical analysis with experimental corroboration.

**摘要:** 在这一工作中,我们研究了在流域设置中私下最大化子模函数的问题。在一般情况下,当函数依赖于个人的私人数据时,对私下最大化子模函数进行了广泛的研究。然而,当从目标函数的域中提取的数据流的大小大或到达非常快时,必须私下优化流域设置的约束中的目标。我们为这一问题建立基本的微分私下基线,然后为分解子模函数的特殊情况得出更好的交易权衡。最后, 通过实验证明, 对理论分析进行了补充.

**[Paper URL](https://proceedings.mlr.press/v202/chaturvedi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chaturvedi23a/chaturvedi23a.pdf)** 

# Why does Throwing Away Data Improve Worst-Group Error?
**题目:** 为什么丢失数据会改善最坏组错误?

**作者:** Kamalika Chaudhuri, Kartik Ahuja, Martin Arjovsky, David Lopez-Paz

**Abstract:** When facing data with imbalanced classes or groups, practitioners follow an intriguing strategy to achieve best results. They throw away examples until the classes or groups are balanced in size, and then perform empirical risk minimization on the reduced training set. This opposes common wisdom in learning theory, where the expected error is supposed to decrease as the dataset grows in size. In this work, we leverage extreme value theory to address this apparent contradiction. Our results show that the tails of the data distribution play an important role in determining the worst-group-accuracy of linear classifiers. When learning on data with heavy tails, throwing away data restores the geometric symmetry of the resulting classifier, and therefore improves its worst-group generalization.

**摘要:** 当面对与不平衡的类别或群组的数据时,实践者遵循一个引人注目的策略,以取得最佳结果。他们将这些类别或群组在大小平衡之前抛出实例,然后在减少的训练集合上进行经验风险最小化。这与学习理论中的普遍智慧相反,因为预期的误差应该随着数据集的大小增长而减少。

**[Paper URL](https://proceedings.mlr.press/v202/chaudhuri23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chaudhuri23a/chaudhuri23a.pdf)** 

# Collaborative Multi-Agent Heterogeneous Multi-Armed Bandits
**题目:** 合作多干事异种多武装强盗

**作者:** Ronshee Chawla, Daniel Vial, Sanjay Shakkottai, R. Srikant

**Abstract:** The study of collaborative multi-agent bandits has attracted significant attention recently. In light of this, we initiate the study of a new collaborative setting, consisting of $N$ agents such that each agent is learning one of $M$ stochastic multi-armed bandits to minimize their group cumulative regret. We develop decentralized algorithms which facilitate collaboration between the agents under two scenarios. We characterize the performance of these algorithms by deriving the per agent cumulative regret and group regret upper bounds. We also prove lower bounds for the group regret in this setting, which demonstrates the near-optimal behavior of the proposed algorithms.

**摘要:** 基于此,我们开始研究一种新的协作环境,由$N$代理人组成,使得每个代理人学习一个$M$随机多武器的带子以减少其群体累积的遗憾。我们开发了分散式算法,在两个场景下促进代理人之间的协作。我们通过推导每个代理人累积的遗憾和群体累积的遗憾的上限来区分这些算法的性能。

**[Paper URL](https://proceedings.mlr.press/v202/chawla23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chawla23a/chawla23a.pdf)** 

# Correcting discount-factor mismatch in on-policy policy gradient methods
**题目:** 在政策梯度方法中纠正折扣因子不匹配

**作者:** Fengdi Che, Gautham Vasan, A. Rupam Mahmood

**Abstract:** The policy gradient theorem gives a convenient form of the policy gradient in terms of three factors: an action value, a gradient of the action likelihood, and a state distribution involving discounting called the discounted stationary distribution. But commonly used on-policy methods based on the policy gradient theorem ignores the discount factor in the state distribution, which is technically incorrect and may even cause degenerate learning behavior in some environments. An existing solution corrects this discrepancy by using $\gamma^t$ as a factor in the gradient estimate. However, this solution is not widely adopted and does not work well in tasks where the later states are similar to earlier states. We introduce a novel distribution correction to account for the discounted stationary distribution that can be plugged into many existing gradient estimators. Our correction circumvents the performance degradation associated with the $\gamma^t$ correction with a lower variance. Importantly, compared to the uncorrected estimators, our algorithm provides improved state emphasis to evade suboptimal policies in certain environments and consistently matches or exceeds the original performance on several OpenAI gym and DeepMind suite benchmarks.

**摘要:** 政策梯度定理给出了政策梯度的便利形式,包括三个因素:行动值、行动可能的梯度和包含降价的状态分布,称为降价静态分布。但基于政策梯度定理的常用策略方法忽略了国家分布中的降价因子,这是技术上错误的,甚至在某些环境中可能导致学习行为退化。一个现有的解决方案通过使用降价估计中的因素来纠正这种不一致性。然而,这个解决方案并不被广泛采用,并且在较晚状态与较早状态相似的任务中并不有效。我们引入了一种新的分布纠正,以计算降价静态分布,可以插到许多现有的梯度估计器中。我们的纠正绕过与降价估计相关的性能劣化。重要的是,与未修正的估计器相比,我们的算法提供了更好的状态重点,以避免在某些环境下不理想的政策,并一致或超过了OpenAI健身房和DeepMind套件的标准。

**[Paper URL](https://proceedings.mlr.press/v202/che23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/che23a/che23a.pdf)** 

# Fast Federated Machine Unlearning with Nonlinear Functional Theory
**题目:** 非线性函数理论的快速联邦化机器非学习

**作者:** Tianshi Che, Yang Zhou, Zijie Zhang, Lingjuan Lyu, Ji Liu, Da Yan, Dejing Dou, Jun Huan

**Abstract:** Federated machine unlearning (FMU) aims to remove the influence of a specified subset of training data upon request from a trained federated learning model. Despite achieving remarkable performance, existing FMU techniques suffer from inefficiency due to two sequential operations of training and retraining/unlearning on large-scale datasets. Our prior study, PCMU, was proposed to improve the efficiency of centralized machine unlearning (CMU) with certified guarantees, by simultaneously executing the training and unlearning operations. This paper proposes a fast FMU algorithm, FFMU, for improving the FMU efficiency while maintaining the unlearning quality. The PCMU method is leveraged to train a local machine learning (MU) model on each edge device. We propose to employ nonlinear functional analysis techniques to refine the local MU models as output functions of a Nemytskii operator. We conduct theoretical analysis to derive that the Nemytskii operator has a global Lipschitz constant, which allows us to bound the difference between two MU models regarding the distance between their gradients. Based on the Nemytskii operator and average smooth local gradients, the global MU model on the server is guaranteed to achieve close performance to each local MU model with the certified guarantees.

**摘要:** 联邦机器非学习(FMU)旨在消除由训练的联邦学习模型请求的特定训练数据子集的影响。尽管取得了显著的性能,现有的FMU技术由于在大规模数据集上进行训练和再训练/非学习的两个连续操作而造成效率低下。我们先前的研究,PCMU,提出了通过同时执行训练和非学习操作,以认证保证提高集中机器非学习(CMU)的效率。我们进行了理论分析,得出Nemitskii操作器具有全球利普茨常数,使我们能够结合两个MU模型之间的梯度之间的距离的差异。基于Nemitskii操作器和平均平滑的局部梯度,服务器上的全球MU模型保证与每个局部MU模型的性能接近,并得到认证的保证。

**[Paper URL](https://proceedings.mlr.press/v202/che23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/che23b/che23b.pdf)** 

# On the Statistical Benefits of Temporal Difference Learning
**题目:** 关于临时差异学习的统计效益

**作者:** David Cheikhi, Daniel Russo

**Abstract:** Given a dataset on actions and resulting long-term rewards, a direct estimation approach fits value functions that minimize prediction error on the training data. Temporal difference learning (TD) methods instead fit value functions by minimizing the degree of temporal inconsistency between estimates made at successive time-steps. Focusing on finite state Markov chains, we provide a crisp asymptotic theory of the statistical advantages of this approach. First, we show that an intuitive inverse trajectory pooling coefficient completely characterizes the percent reduction in mean-squared error of value estimates. Depending on problem structure, the reduction could be enormous or nonexistent. Next, we prove that there can be dramatic improvements in estimates of the difference in value-to-go for two states: TD’s errors are bounded in terms of a novel measure – the problem’s trajectory crossing time – which can be much smaller than the problem’s time horizon.

**摘要:** 基于对行为和结果的长期回报的数据集,直接估计方法满足了在训练数据上最小预测误差的值函数。临时差 learning(TD)方法则通过在连续时间步骤中进行的估计之间的时间不一致程度的最小化来满足值函数。我们着重于有限状态马可夫链,提供了这一方法的统计优势的清晰的渐近理论。

**[Paper URL](https://proceedings.mlr.press/v202/cheikhi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cheikhi23a/cheikhi23a.pdf)** 

# Multi-Layer Neural Networks as Trainable Ladders of Hilbert Spaces
**题目:** 多层神经网络作为希尔伯特空间的可训练的梯子

**作者:** Zhengdao Chen

**Abstract:** To characterize the functions spaces explored by multi-layer neural networks (NNs), we introduce Neural Hilbert Ladders (NHLs), a collection of reproducing kernel Hilbert spaces (RKHSes) that are defined iteratively and adaptive to training. First, we prove a correspondence between functions expressed by L-layer NNs and those belonging to L-level NHLs. Second, we prove generalization guarantees for learning the NHL based on a new complexity measure. Third, corresponding to the training of multi-layer NNs in the infinite-width mean-field limit, we derive an evolution of the NHL characterized by the dynamics of multiple random fields. Finally, we examine linear and shallow NNs from the new perspective and complement the theory with numerical results.

**摘要:** 为了对多层神经网络(NN)所探索的函数空间进行描述,我们介绍了神经希尔伯特梯子(NHLs),一种被迭代定义和适应训练的复制核希尔伯特空间(RKHSes)的集合。首先,我们证明了由L层NN和L级NHL所表达的函数之间的对应性。其次,我们证明了基于新的复杂度指标的一般化学习NHL的保证。第三,针对无限宽度平均场限的多层NN的训练,我们得出由多个随机场动态特征的NHL的演化。

**[Paper URL](https://proceedings.mlr.press/v202/chen23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23a/chen23a.pdf)** 

# Beyond the Edge of Stability via Two-step Gradient Updates
**题目:** 通过两步梯度更新超越稳定边缘

**作者:** Lei Chen, Joan Bruna

**Abstract:** Gradient Descent (GD) is a powerful workhorse of modern machine learning thanks to its scalability and efficiency in high-dimensional spaces. Its ability to find local minimisers is only guaranteed for losses with Lipschitz gradients, where it can be seen as a ’bona-fide’ discretisation of an underlying gradient flow. Yet, many ML setups involving overparametrised models do not fall into this problem class, which has motivated research beyond the so-called ”Edge of Stability” (EoS), where the step-size crosses the admissibility threshold inversely proportional to the Lipschitz constant above. Perhaps surprisingly, GD has been empirically observed to still converge regardless of local instability and oscillatory behavior. The incipient theoretical analysis of this phenomena has mainly focused in the overparametrised regime, where the effect of choosing a large learning rate may be associated to a ‘Sharpness-Minimisation’ implicit regularisation within the manifold of minimisers, under appropriate asymptotic limits. In contrast, in this work we directly examine the conditions for such unstable convergence, focusing on simple, yet representative, learning problems, via analysis of two-step gradient updates. Specifically, we characterize a local condition involving third-order derivatives that guarantees existence and convergence to fixed points of the two-step updates, and leverage such property in a teacher-student setting, under population loss. Finally, starting from Matrix Factorization, we provide observations of period-2 orbit of GD in high-dimensional settings with intuition of its dynamics, along with exploration into more general settings.

**摘要:** 梯度降落(Gradient Descent,GD)是现代机器学习的一个强大的工作horse,其在高维空间的可扩展性和效率使得它能够找到局部最小化器。它只能保证在利普茨梯度下损失,在那里它可以被看作是基底梯度流的“bona-fide”离散化。然而,许多涉及过参数化模型的ML设置不属于这一问题类,这使得研究超越所谓的“稳定边缘”(Edge of Stability,EoS),其中步量大小与上面的利普茨常数反比例地跨越可接受度阈值。该现象的初始理论分析主要集中在超参数化模式中,在适当的渐近限度下,选择高学习率的效应可能与“粗糙度-微化”在微化器的多变量范围内的隐性定律化有关。与此相反,本文直接研究了这种不稳定的收敛条件,着重于简单的,但代表性的学习问题,通过分析两步梯度更新的分析。具体地,我们描述了一个涉及三阶衍生物的局部条件,保证两步更新的固定点的存在和收敛,并利用这种属性在教师-学生环境下,在人口损失下。最后,从矩阵因子化开始,我们提供了高维环境中GD周期-2轨道的观察,并对其动力学的直觉,以及更一般环境的探索。

**[Paper URL](https://proceedings.mlr.press/v202/chen23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23b/chen23b.pdf)** 

# Trompt: Towards a Better Deep Neural Network for Tabular Data
**题目:** Trompt:为 Tabular数据提供更好的深度神经网络

**作者:** Kuan-Yu Chen, Ping-Han Chiang, Hsin-Rung Chou, Ting-Wei Chen, Tien-Hao Chang

**Abstract:** Tabular data is arguably one of the most commonly used data structures in various practical domains, including finance, healthcare and e-commerce. The inherent heterogeneity allows tabular data to store rich information. However, based on a recently published tabular benchmark, we can see deep neural networks still fall behind tree-based models on tabular datasets. In this paper, we propose Trompt–which stands for Tabular Prompt–a novel architecture inspired by prompt learning of language models. The essence of prompt learning is to adjust a large pre-trained model through a set of prompts outside the model without directly modifying the model. Based on this idea, Trompt separates the learning strategy of tabular data into two parts. The first part, analogous to pre-trained models, focus on learning the intrinsic information of a table. The second part, analogous to prompts, focus on learning the variations among samples. Trompt is evaluated with the benchmark mentioned above. The experimental results demonstrate that Trompt outperforms state-of-the-art deep neural networks and is comparable to tree-based models.

**摘要:** 图表数据是包括金融、医疗和电子商务在内的各个实际领域最常用的数据结构之一,其内在异质性允许图表数据储存丰富的信息。然而,基于最近发布的图表基准,我们可以看到深层神经网络仍然落在图表数据集的树型模型后面。在这个论文中,我们提议Trompt-它代表 Tabular Prompt-一种由语言模型的快速学习所启发的新架构。实验结果表明,特伦普特具有较先进的深度神经网络性能,与基于树的模型相比。

**[Paper URL](https://proceedings.mlr.press/v202/chen23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23c/chen23c.pdf)** 

# Differentially Private Stochastic Convex Optimization under a Quantile Loss Function
**题目:** 量子损失函数下的微观随机凸优化

**作者:** Du Chen, Geoffrey A. Chua

**Abstract:** We study $(\varepsilon,\delta)$-differentially private (DP) stochastic convex optimization under an $r$-th quantile loss function taking the form $c(u) = ru^+ + (1-r)(-u)^+$. The function is non-smooth, and we propose to approximate it with a smooth function obtained by convolution smoothing, which enjoys both structure and bandwidth flexibility and can address outliers. This leads to a better approximation than those obtained from existing methods such as Moreau Envelope. We then design private algorithms based on DP stochastic gradient descent and objective perturbation, and show that both algorithms achieve (near) optimal excess generalization risk $O(\max\{\frac{1}{\sqrt{n}}, \frac{\sqrt{d\ln(1/\delta)}}{n\varepsilon}\})$. Through objective perturbation, we further derive an upper bound $O(\max\{\sqrt{\frac{d}{n}}, \sqrt{\frac{d\ln(1/\delta)}{n\varepsilon}}\})$ on the parameter estimation error under mild assumptions on data generating processes. Some applications in private quantile regression and private inventory control will be discussed.

**摘要:** 我们研究了$(\varepsilon,\delta)$-在$r$-第量子损失函数下,以$c(u) = ru^+ + (1-r)(-u)^+$的形式进行定量凸优化,该函数是非平滑的,并提出通过卷曲平滑得到的平滑函数的近似,该函数既具有结构和带宽灵活性,而且可以解决异常问题。讨论了私人量子回归和私人库存控制的一些应用.

**[Paper URL](https://proceedings.mlr.press/v202/chen23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23d/chen23d.pdf)** 

# Restoration-Degradation Beyond Linear Diffusions: A Non-Asymptotic Analysis For DDIM-type Samplers
**题目:** 线性差异以外的恢复降解:DDIM型样品的非渐近分析

**作者:** Sitan Chen, Giannis Daras, Alex Dimakis

**Abstract:** We develop a framework for non-asymptotic analysis of deterministic samplers used for diffusion generative modeling. Several recent works have analyzed stochastic samplers using tools like Girsanov’s theorem and a chain rule variant of the interpolation argument. Unfortunately, these techniques give vacuous bounds when applied to deterministic samplers. We give a new operational interpretation for deterministic sampling by showing that one step along the probability flow ODE can be expressed as two steps: 1) a restoration step that runs gradient ascent on the conditional log-likelihood at some infinitesimally previous time, and 2) a degradation step that runs the forward process using noise pointing back towards the current iterate. This perspective allows us to extend denoising diffusion implicit models to general, non-linear forward processes. We then develop the first polynomial convergence bounds for these samplers under mild conditions on the data distribution.

**摘要:** 我们开发了用于扩散生成建模的非渐近分析框架。最近的几项工作分析了使用诸如吉尔萨诺夫定理和插值参数的链式规则变异工具的随机样本器。不幸的是,这些技术在应用于扩散样本器时给定量样本器空界。我们给出了新的定量样本的操作解释,表明一个步骤沿 probability flow ODE可以表示为两个步骤: 1) 恢复步骤运行在某些无限期以前时的条件逻辑概率上的梯度上升,和 2) 降级步骤运行在噪声指向当前迭代的过程。这一视角允许我们扩展扩散隐含模型到一般非线性进程过程。

**[Paper URL](https://proceedings.mlr.press/v202/chen23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23e/chen23e.pdf)** 

# Provably Convergent Schrödinger Bridge with Applications to Probabilistic Time Series Imputation
**题目:** 基于概率时间序列归纳的证明收敛 Schrödinger桥

**作者:** Yu Chen, Wei Deng, Shikai Fang, Fengpei Li, Nicole Tianjiao Yang, Yikai Zhang, Kashif Rasul, Shandian Zhe, Anderson Schneider, Yuriy Nevmyvaka

**Abstract:** The Schrödinger bridge problem (SBP) is gaining increasing attention in generative modeling and showing promising potential even in comparison with the score-based generative models (SGMs). SBP can be interpreted as an entropy-regularized optimal transport problem, which conducts projections onto every other marginal alternatingly. However, in practice, only approximated projections are accessible and their convergence is not well understood. To fill this gap, we present a first convergence analysis of the Schrödinger bridge algorithm based on approximated projections. As for its practical applications, we apply SBP to probabilistic time series imputation by generating missing values conditioned on observed data. We show that optimizing the transport cost improves the performance and the proposed algorithm achieves the state-of-the-art result in healthcare and environmental data while exhibiting the advantage of exploring both temporal and feature patterns in probabilistic time series imputation.

**摘要:**  Schrödinger桥问题(SBP)在生成模型中日益受到关注,甚至与基于分数的生成模型(SGMs)相比,也显示出有潜力的潜力。SBP可以被解释为熵调节的最优传输问题,它对其他边缘进行投影。然而,在实践中,只有近似投影是可访问的,而且它们的收敛性并不十分清楚。为了填补这一空白,我们提出了基于近似投影的 Schrödinger桥算法的第一次收敛分析。结果表明,优化运输成本提高了性能,该算法在医疗和环境数据中实现了最先进的结果,同时显示了探索概率时间序列归纳中时态模式和特征模式的优点。

**[Paper URL](https://proceedings.mlr.press/v202/chen23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23f/chen23f.pdf)** 

# ED-Batch: Efficient Automatic Batching of Dynamic Neural Networks via Learned Finite State Machines
**题目:** ED-Batch:通过学习完备状态机实现动态神经网络的高效自动批量

**作者:** Siyuan Chen, Pratik Pramod Fegade, Tianqi Chen, Phillip Gibbons, Todd Mowry

**Abstract:** Batching has a fundamental influence on the efficiency of deep neural network (DNN) execution. However, for dynamic DNNs, efficient batching is particularly challenging as the dataflow graph varies per input instance. As a result, state-of-the-art frameworks use heuristics that result in suboptimal batching decisions. Further, batching puts strict restrictions on memory adjacency and can lead to high data movement costs. In this paper, we provide an approach for batching dynamic DNNs based on finite state machines, which enables the automatic discovery of batching policies specialized for each DNN via reinforcement learning. Moreover, we find that memory planning that is aware of the batching policy can save significant data movement overheads, which is automated by a PQ tree-based algorithm we introduce. Experimental results show that our framework speeds up state-of-the-art frameworks by on average 1.15x, 1.39x, and 2.45x for chain-based, tree-based, and lattice-based DNNs across CPU and GPU. The framework is open-sourced at https://github.com/gulang2019/ED-Batch.git.

**摘要:** 批量对深度神经网络(DNN)执行效率有根本影响,但对于动态DNN而言,有效的批量是特别具有挑战性的,因为数据流图在输入实例中有所不同。因此,最先进的框架使用启发式,导致下游的批量决策。此外,批量对内存邻近性提出了严格的限制,并可能导致数据移动成本高昂。实验结果表明,我们的框架平均为CPU和GPU的链式、树式和网格式DNN提供1.15x、1.39x和2.45x的最先进的框架速度。该框架在 https://github.com/gulang2019/ED-Batch.git上开放。

**[Paper URL](https://proceedings.mlr.press/v202/chen23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23g/chen23g.pdf)** 

# Is Learning Summary Statistics Necessary for Likelihood-free Inference?
**题目:** 学习摘要统计对无概率的反叛是必要的 吗?

**作者:** Yanzhi Chen, Michael U. Gutmann, Adrian Weller

**Abstract:** Likelihood-free inference (LFI) is a set of techniques for inference in implicit statistical models. A longstanding question in LFI has been how to design or learn good summary statistics of data, but this might now seem unnecessary due to the advent of recent end-to-end (i.e. neural network-based) LFI methods. In this work, we rethink this question with a new method for learning summary statistics. We show that learning sufficient statistics may be easier than direct posterior inference, as the former problem can be reduced to a set of low-dimensional, easy-to-solve learning problems. This suggests us to explicitly decouple summary statistics learning from posterior inference in LFI. Experiments on diverse inference tasks with different data types validate our hypothesis.

**摘要:** 无概率推理(英语:likelihood-free inference,缩写为LFI)是隐性统计模型中推理的一系列技术。LFI是一个长期的问题,是如何设计或学习数据的良好总结统计学,但由于最近的end-to-end(即神经网络基础的)LFI方法的出现,现在可能显得不必要。在这项工作中,我们重新思考这一问题,以学习总结统计学的新方法。我们证明,学习足够的统计学可能比直接后推理更容易,因为前的问题可以减少到一套低维、易于解决的学习问题。

**[Paper URL](https://proceedings.mlr.press/v202/chen23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23h/chen23h.pdf)** 

# Subequivariant Graph Reinforcement Learning in 3D Environments
**题目:** 3D环境下的次等价图增强学习

**作者:** Runfa Chen, Jiaqi Han, Fuchun Sun, Wenbing Huang

**Abstract:** Learning a shared policy that guides the locomotion of different agents is of core interest in Reinforcement Learning (RL), which leads to the study of morphology-agnostic RL. However, existing benchmarks are highly restrictive in the choice of starting point and target point, constraining the movement of the agents within 2D space. In this work, we propose a novel setup for morphology-agnostic RL, dubbed Subequivariant Graph RL in 3D environments (3D-SGRL). Specifically, we first introduce a new set of more practical yet challenging benchmarks in 3D space that allows the agent to have full Degree-of-Freedoms to explore in arbitrary directions starting from arbitrary configurations. Moreover, to optimize the policy over the enlarged state-action space, we propose to inject geometric symmetry, i.e., subequivariance, into the modeling of the policy and Q-function such that the policy can generalize to all directions, improving exploration efficiency. This goal is achieved by a novel SubEquivariant Transformer (SET) that permits expressive message exchange. Finally, we evaluate the proposed method on the proposed benchmarks, where our method consistently and significantly outperforms existing approaches on single-task, multi-task, and zero-shot generalization scenarios. Extensive ablations are also conducted to verify our design.

**摘要:** 在增强学习中,学习指导不同代理人的运动的共享策略具有核心意义,这导致了对形态学 agnostic RL的研究。然而,现有的基准在启动点和目标点的选择上是非常限制性的,限制了在2D空间中的代理人的运动。在这个工作中,我们提出了一种新的形态学 agnostic RL的设置,称为3D环境中的Subequivariant Graph RL(3D-SGRL)。具体地说,我们首先引入了从任意配置开始的任意方向进行探索的代理人具有完全自由度的3D空间中的更实用但挑战性的新基准。本文采用一种新的双变换变换器(SET)实现这一目标,它允许表达式消息交换。最后,我们对拟议的标准方法进行了评估,该方法在单任务、多任务和零射击一般化场景中具有较强的一致性和显著的优越性。

**[Paper URL](https://proceedings.mlr.press/v202/chen23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23i/chen23i.pdf)** 

# GuardHFL: Privacy Guardian for Heterogeneous Federated Learning
**题目:** GuardHFL:异性联合学习的隐私保护者

**作者:** Hanxiao Chen, Meng Hao, Hongwei Li, Kangjie Chen, Guowen Xu, Tianwei Zhang, Xilin Zhang

**Abstract:** Heterogeneous federated learning (HFL) enables clients with different computation and communication capabilities to collaboratively train their own customized models via a query-response paradigm on auxiliary datasets. However, such a paradigm raises serious privacy concerns due to the leakage of highly sensitive query samples and response predictions. We put forth GuardHFL, the first-of-its-kind efficient and privacy-preserving HFL framework. GuardHFL is equipped with a novel HFL-friendly secure querying scheme built on lightweight secret sharing and symmetric-key techniques. The core of GuardHFL is two customized multiplication and comparison protocols, which substantially boost the execution efficiency. Extensive evaluations demonstrate that GuardHFL significantly outperforms the alternative instantiations based on existing state-of-the-art techniques in both runtime and communication cost.

**摘要:** 异性联合学习(英语:Heterogeneous federated learning,缩写为HFL)使具有不同计算和通信能力的客户能够通过辅助数据集的查询响应范式共同训练自己的定制模型。然而,这种范式由于高度敏感查询样本和响应预测的泄漏而引起严重的隐私问题。我们提出了HFL框架,它是第一类高效的、保护隐私的HFL框架。

**[Paper URL](https://proceedings.mlr.press/v202/chen23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23j/chen23j.pdf)** 

# Efficient and Degree-Guided Graph Generation via Discrete Diffusion Modeling
**题目:** 基于离散扩散模型的高效度导图生成

**作者:** Xiaohui Chen, Jiaxing He, Xu Han, Liping Liu

**Abstract:** Diffusion-based generative graph models have been proven effective in generating high-quality small graphs. However, they need to be more scalable for generating large graphs containing thousands of nodes desiring graph statistics. In this work, we propose EDGE, a new diffusion-based generative graph model that addresses generative tasks with large graphs. To improve computation efficiency, we encourage graph sparsity by using a discrete diffusion process that randomly removes edges at each time step and finally obtains an empty graph. EDGE only focuses on a portion of nodes in the graph at each denoising step. It makes much fewer edge predictions than previous diffusion-based models. Moreover, EDGE admits explicitly modeling the node degrees of the graphs, further improving the model performance. The empirical study shows that EDGE is much more efficient than competing methods and can generate large graphs with thousands of nodes. It also outperforms baseline models in generation quality: graphs generated by our approach have more similar graph statistics to those of the training graphs.

**摘要:** 基于扩散的生成图模型已经证明在生成高质量小图中具有有效性。然而,它们需要为生成包含数千节点的大型图提供更多的可扩展性。在这项工作中,我们提出了一种新的基于扩散的生成图模型,以处理与大型图的生成任务。为了提高计算效率,我们鼓励使用随机移除各步骤边缘的离散扩散过程来提高图的稀疏性,最终获得一个空图。它在生成质量方面也超过了基准模型:通过我们的方法生成的图形具有与训练图形比较相似的图形统计。

**[Paper URL](https://proceedings.mlr.press/v202/chen23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23k/chen23k.pdf)** 

# Evolving Semantic Prototype Improves Generative Zero-Shot Learning
**题目:** 演变语义原型改进生成零射击学习

**作者:** Shiming Chen, Wenjin Hou, Ziming Hong, Xiaohan Ding, Yibing Song, Xinge You, Tongliang Liu, Kun Zhang

**Abstract:** In zero-shot learning (ZSL), generative methods synthesize class-related sample features based on predefined semantic prototypes. They advance the ZSL performance by synthesizing unseen class sample features for better training the classifier. We observe that each class’s predefined semantic prototype (also referred to as semantic embedding or condition) does not accurately match its real semantic prototype. So the synthesized visual sample features do not faithfully represent the real sample features, limiting the classifier training and existing ZSL performance. In this paper, we formulate this mismatch phenomenon as the visual-semantic domain shift problem. We propose a dynamic semantic prototype evolving (DSP) method to align the empirically predefined semantic prototypes and the real prototypes for class-related feature synthesis. The alignment is learned by refining sample features and semantic prototypes in a unified framework and making the synthesized visual sample features approach real sample features. After alignment, synthesized sample features from unseen classes are closer to the real sample features and benefit DSP to improve existing generative ZSL methods by 8.5%, 8.0%, and 9.7% on the standard CUB, SUN AWA2 datasets, the significant performance improvement indicates that evolving semantic prototype explores a virgin field in ZSL.

**摘要:** 在零射击学习(ZSL)中,生成方法将基于预定义的语义样本的类相关样本特征合成。它们通过合成未见类样本特征来提高分类器的训练性能。我们观察到每个类的预定义语义样本(也称为语义嵌入或条件)并不准确地匹配其真正的语义样本。因此,合成的视觉样本特征并不忠实地代表真正的样本特征,限制了分类器的训练和现有 ZSL性能。通过在统一的框架中精细样品特征和语义样品,使合成视觉样品特征接近实际样品特征,使样品特征从未见类的合成样品特征更接近实际样品特征,并使DSP在标准CUB、SUNAWA2数据集中以8.5%,8.0%和9.7%改善现有的生成 ZSL方法,显著的性能改进表明,演变语义样品在ZSL中探索了一个纯净的领域。

**[Paper URL](https://proceedings.mlr.press/v202/chen23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23l/chen23l.pdf)** 

# Explore and Exploit the Diverse Knowledge in Model Zoo for Domain Generalization
**题目:** 探索和探索模式动物园的多样性知识以推广领域

**作者:** Yimeng Chen, Tianyang Hu, Fengwei Zhou, Zhenguo Li, Zhi-Ming Ma

**Abstract:** The proliferation of pretrained models, as a result of advancements in pretraining techniques, has led to the emergence of a vast zoo of publicly available models. Effectively utilizing these resources to obtain models with robust out-of-distribution generalization capabilities for downstream tasks has become a crucial area of research. Previous research has primarily focused on identifying the most powerful models within the model zoo, neglecting to fully leverage the diverse inductive biases contained within. This paper argues that the knowledge contained in weaker models is valuable and presents a method for leveraging the diversity within the model zoo to improve out-of-distribution generalization capabilities. Specifically, we investigate the behaviors of various pretrained models across different domains of downstream tasks by characterizing the variations in their encoded representations in terms of two dimensions: diversity shift and correlation shift. This characterization enables us to propose a new algorithm for integrating diverse pretrained models, not limited to the strongest models, in order to achieve enhanced out-of-distribution generalization performance. Our proposed method demonstrates state-of-the-art empirical results on a variety of datasets, thus validating the benefits of utilizing diverse knowledge.

**摘要:** 预制模型的扩散,是预训练技术进步的结果,导致了大量公开模式动物园的出现。有效地利用这些资源,获得具有较强的非分布一般化能力的模式动物园下游任务,已成为研究的一个关键领域。以往的研究主要集中在模式动物园内最强大的模式动物园内模式动物园内模式动物园内模式动物园内各种诱导性偏见的识别上,忽略了充分利用模式动物园内多样性来提高非分布一般化能力的方法。具体而言,我们研究了不同预制模式动物园下游任务的不同领域内的各种模式动物园内模式动物园内模式动物园内模式动物园内模式动物园内模式动物园内模式动物园内模式动物园内模式动物园内模式动物园内模式动物园内模式动物园内模式动物园内模式动物园内模式动物园内模式动物园内模式动物园内模式通过这种特性,我们能够提出一种综合多种预处理模型的新算法,不仅限于最强的模型,以提高非散发一般化性能。我们提出的方法显示了各种数据集的最先进的实证结果,从而验证了利用多种知识的好处。

**[Paper URL](https://proceedings.mlr.press/v202/chen23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23m/chen23m.pdf)** 

# Decentralized Stochastic Bilevel Optimization with Improved per-Iteration Complexity
**题目:** 分散随机双层优化与改进每次迭代复杂性

**作者:** Xuxing Chen, Minhui Huang, Shiqian Ma, Krishna Balasubramanian

**Abstract:** Bilevel optimization recently has received tremendous attention due to its great success in solving important machine learning problems like meta learning, reinforcement learning, and hyperparameter optimization. Extending single-agent training on bilevel problems to the decentralized setting is a natural generalization, and there has been a flurry of work studying decentralized bilevel optimization algorithms. However, it remains unknown how to design the distributed algorithm with sample complexity and convergence rate comparable to SGD for stochastic optimization, and at the same time without directly computing the exact Hessian or Jacobian matrices. In this paper we propose such an algorithm. More specifically, we propose a novel decentralized stochastic bilevel optimization (DSBO) algorithm that only requires first order stochastic oracle, Hessian-vector product and Jacobian-vector product oracle. The sample complexity of our algorithm matches the currently best known results for DSBO, while our algorithm does not require estimating the full Hessian and Jacobian matrices, thereby possessing to improved per-iteration complexity.

**摘要:** 双层优化最近由于在解决诸如元学习、增强学习和超参数优化等重要机器学习问题方面取得了巨大的成功,因此得到了极大的关注。将单元代理训练在双层问题上扩展到分散环境是自然的一般化,并且研究分散双层优化算法的大量工作。然而,仍不清楚如何设计与SGD相似的样品复杂度和收敛率的分布式算法,同时不直接计算精确的希西亚或雅各比矩阵。我们的算法的样本复杂性与目前最著名的DSBO结果相匹配,而我们的算法不需要估计全赫斯和雅各布矩阵,从而具有改进的迭代复杂性。

**[Paper URL](https://proceedings.mlr.press/v202/chen23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23n/chen23n.pdf)** 

# Score Approximation, Estimation and Distribution Recovery of Diffusion Models on Low-Dimensional Data
**题目:** 低尺度数据扩散模型的评分近似、估计和分布恢复

**作者:** Minshuo Chen, Kaixuan Huang, Tuo Zhao, Mengdi Wang

**Abstract:** Diffusion models achieve state-of-the-art performance in various generation tasks. However, their theoretical foundations fall far behind. This paper studies score approximation, estimation, and distribution recovery of diffusion models, when data are supported on an unknown low-dimensional linear subspace. Our result provides sample complexity bounds for distribution estimation using diffusion models. We show that with a properly chosen neural network architecture, the score function can be both accurately approximated and efficiently estimated. Further, the generated distribution based on the estimated score function captures the data geometric structures and converges to a close vicinity of the data distribution. The convergence rate depends on subspace dimension, implying that diffusion models can circumvent the curse of data ambient dimensionality.

**摘要:** 扩散模型在不同生成任务中达到最先进的性能,但其理论基础远远落后。本文研究了在未知的低维线性子空间上支持数据时扩散模型的分数近似、估计和分布恢复。我们的结果为利用扩散模型进行扩散估计提供了样品复杂度边界。我们证明,在适当选择的神经网络架构下,分数函数可以准确地近似和有效估计。此外,基于估计分数函数生成的分布捕获数据几何结构并趋于数据分布的近距离。

**[Paper URL](https://proceedings.mlr.press/v202/chen23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23o/chen23o.pdf)** 

# Sample Complexity of Probability Divergences under Group Symmetry
**题目:** 群对称下概率差异的样本复杂性

**作者:** Ziyu Chen, Markos Katsoulakis, Luc Rey-Bellet, Wei Zhu

**Abstract:** We rigorously quantify the improvement in the sample complexity of variational divergence estimations for group-invariant distributions. In the cases of the Wasserstein-1 metric and the Lipschitz-regularized $\alpha$-divergences, the reduction of sample complexity is proportional to an ambient-dimension-dependent power of the group size. For the maximum mean discrepancy (MMD), the improvement of sample complexity is more nuanced, as it depends on not only the group size but also the choice of kernel. Numerical simulations verify our theories.

**摘要:** 我们严格定量了群不变分布变异偏差估计的样品复杂度的改善。在水星-1度量和利普茨-调节的$\alpha$-偏差的例子中,样品复杂度的降低与群大小的环境维度依赖力相等。 对于最大平均差异(MMD),样品复杂度的改进更加微观,因为它不仅取决于群大小,而且取决于核的选择。

**[Paper URL](https://proceedings.mlr.press/v202/chen23p.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23p/chen23p.pdf)** 

# Improved Analysis of Score-based Generative Modeling: User-Friendly Bounds under Minimal Smoothness Assumptions
**题目:** 基于分数生成模型的改进分析:基于最小 Smoothness假设的用户友好界限

**作者:** Hongrui Chen, Holden Lee, Jianfeng Lu

**Abstract:** We give an improved theoretical analysis of score-based generative modeling. Under a score estimate with small $L^2$ error (averaged across timesteps), we provide efficient convergence guarantees for any data distribution with second-order moment, by either employing early stopping or assuming smoothness condition on the score function of the data distribution. Our result does not rely on any log-concavity or functional inequality assumption and has a logarithmic dependence on the smoothness. In particular, we show that under only a finite second moment condition, approximating the following in reverse KL divergence in $\epsilon$-accuracy can be done in $\tilde O\left(\frac{d \log (1/\delta)}{\epsilon}\right)$ steps: 1) the variance-$\delta$ Gaussian perturbation of any data distribution; 2) data distributions with $1/\delta$-smooth score functions. Our analysis also provides a quantitative comparison between different discrete approximations and may guide the choice of discretization points in practice.

**摘要:** 我们给出了基于分数的生成模型的改进理论分析。在基于小$L^2$误差的分数估计下,我们通过采用早期停止或假设数据分布的分数函数的滑度条件,为任意数据分布提供有效的收敛保证。我们的结果不依赖任何逻辑凹凸或功能不平等假设,并且具有对滑度的逻辑依赖。我们 的 分析 还 提供 了 不同 的 离散 近似 的 数量 比较, 并 可以 在 实践 中 指导 选择 离散 点 。

**[Paper URL](https://proceedings.mlr.press/v202/chen23q.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23q/chen23q.pdf)** 

# Bidirectional Looking with A Novel Double Exponential Moving Average to Adaptive and Non-adaptive Momentum Optimizers
**题目:** 双向视角与一种新型双指数移动平均与适应性和非适应性动量优化器

**作者:** Yineng Chen, Zuchao Li, Lefei Zhang, Bo Du, Hai Zhao

**Abstract:** Optimizer is an essential component for the success of deep learning, which guides the neural network to update the parameters according to the loss on the training set. SGD and Adam are two classical and effective optimizers on which researchers have proposed many variants, such as SGDM and RAdam. In this paper, we innovatively combine the backward-looking and forward-looking aspects of the optimizer algorithm and propose a novel Admeta (A Double exponential Moving averagE To Adaptive and non-adaptive momentum) optimizer framework. For backward-looking part, we propose a DEMA variant scheme, which is motivated by a metric in the stock market, to replace the common exponential moving average scheme. While in the forward-looking part, we present a dynamic lookahead strategy which asymptotically approaches a set value, maintaining its speed at early stage and high convergence performance at final stage. Based on this idea, we provide two optimizer implementations, AdmetaR and AdmetaS, the former based on RAdam and the latter based on SGDM. Through extensive experiments on diverse tasks, we find that the proposed Admeta optimizer outperforms our base optimizers and shows advantages over recently proposed competitive optimizers. We also provide theoretical proof of these two algorithms, which verifies the convergence of our proposed Admeta.

**摘要:** 优化器是深度学习的成功的关键组成部分,它指导神经网络根据训练集合的损失更新参数。SGD和Adam是两个经典有效的优化器,研究者提出了许多变量,例如SGDM和RAdam。本文,我们创新地结合了优化器算法的后向和前向方面,提出了一种新的Admeta(A Double exponential Moving averagE To Adaptive and Non-adaptive momentum)优化器框架。基于这个想法,我们提供了两个优化器实现,AdmetaR和AdmetaS,前者基于RAdam,后者基于SGDM。通过对各种任务的广泛实验,我们发现,提议的Admeta优化器比我们的基本优化器高,显示了最近提议的竞争优化器的优势。我们还提供了这两个算法的理论证明,验证了我们提议的Admeta的收敛性。

**[Paper URL](https://proceedings.mlr.press/v202/chen23r.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23r/chen23r.pdf)** 

# HarsanyiNet: Computing Accurate Shapley Values in a Single Forward Propagation
**题目:** HarsanyiNet:计算单向扩散中的精确形状值

**作者:** Lu Chen, Siyu Lou, Keyan Zhang, Jin Huang, Quanshi Zhang

**Abstract:** The Shapley value is widely regarded as a trustworthy attribution metric. However, when people use Shapley values to explain the attribution of input variables of a deep neural network (DNN), it usually requires a very high computational cost to approximate relatively accurate Shapley values in real-world applications. Therefore, we propose a novel network architecture, the HarsanyiNet, which makes inferences on the input sample and simultaneously computes the exact Shapley values of the input variables in a single forward propagation. The HarsanyiNet is designed on the theoretical foundation that the Shapley value can be reformulated as the redistribution of Harsanyi interactions encoded by the network.

**摘要:** 然而,当人们使用Shapley值来解释深度神经网络(DNN)输入变量的属性时,通常需要很高的计算成本来在现实应用中近似相对准确的Shapley值。因此,我们提出了一种新颖的网络架构,HarsanyiNet,它在输入样本上作出推断,并同时在单个向前传播中计算输入变量的准确的Shapley值。

**[Paper URL](https://proceedings.mlr.press/v202/chen23s.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23s/chen23s.pdf)** 

# Generalized Implicit Follow-The-Regularized-Leader
**题目:** 一般化隐含追随-规范化领导者

**作者:** Keyi Chen, Francesco Orabona

**Abstract:** We propose a new class of online learning algorithms, generalized implicit Follow-The-Regularized-Leader (FTRL), that expands the scope of FTRL framework. Generalized implicit FTRL can recover known algorithms, such as FTRL with linearized losses and implicit FTRL, and it allows the design of new update rules, as extensions of aProx and Mirror-Prox to FTRL. Our theory is constructive in the sense that it provides a simple unifying framework to design updates that directly improve the worst-case upper bound on the regret. The key idea is substituting the linearization of the losses with a Fenchel-Young inequality. We show the flexibility of the framework by proving that some known algorithms, like the Mirror-Prox updates, are instantiations of the generalized implicit FTRL. Finally, the new framework allows us to recover the temporal variation bound of implicit OMD, with the same computational complexity.

**摘要:** 我们提出了一种新的在线学习算法,广义隐式追随-规格化-领导(FTRL),扩大了FTRL框架的范围。广义隐式FTRL可以恢复已知的算法,如FTRL与线性化损失和隐式FTRL,并允许设计新的更新规则,如aProx和Mirror-Prox的扩展到FTRL。我们的理论具有建设性意义,它提供了一个简单的统一框架来设计更新,直接改善遗憾上最坏的上限。关键思想是用Fenchel-Young不平等代替损失的线性化。

**[Paper URL](https://proceedings.mlr.press/v202/chen23t.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23t/chen23t.pdf)** 

# Fisher Information Embedding for Node and Graph Learning
**题目:** 节点和图形学习的鱼类信息嵌入

**作者:** Dexiong Chen, Paolo Pellizzoni, Karsten Borgwardt

**Abstract:** Attention-based graph neural networks (GNNs), such as graph attention networks (GATs), have become popular neural architectures for processing graph-structured data and learning node embeddings. Despite their empirical success, these models rely on labeled data and the theoretical properties of these models have yet to be fully understood. In this work, we propose a novel attention-based node embedding framework for graphs. Our framework builds upon a hierarchical kernel for multisets of subgraphs around nodes (e.g. neighborhoods) and each kernel leverages the geometry of a smooth statistical manifold to compare pairs of multisets, by “projecting” the multisets onto the manifold. By explicitly computing node embeddings with a manifold of Gaussian mixtures, our method leads to a new attention mechanism for neighborhood aggregation. We provide theoretical insights into generalizability and expressivity of our embeddings, contributing to a deeper understanding of attention-based GNNs. We propose both efficient unsupervised and supervised methods for learning the embeddings. Through experiments on several node classification benchmarks, we demonstrate that our proposed method outperforms existing attention-based graph models like GATs. Our code is available at https://github.com/BorgwardtLab/fisher_information_embedding.

**摘要:** 基于注意力的图形神经网络(GNNs),如图形注意力网络(GATs),已成为处理图形结构数据和学习节点嵌入的流行神经架构。尽管它们具有经验性成功,这些模型仍依赖标签的数据,这些模型的理论特性尚未完全理解。在这个工作中,我们提出了一种新的基于注意力的节点嵌入框架,用于图形。我们的框架建立在节点(例如邻域)周围的多组子图形的层次结构内核上,每个内核利用一个平滑统计多组的几何来比较多组的对,通过“投影”多组到多组上。通过对多个节点分类基准的实验,我们证明,我们提出的方法比现有基于注意力的图形模型如GATs高。我们的代码可于 https://github.com/BorgwardtLab/fisher_information_embedding。

**[Paper URL](https://proceedings.mlr.press/v202/chen23u.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23u/chen23u.pdf)** 

# Rethinking Visual Reconstruction: Experience-Based Content Completion Guided by Visual Cues
**题目:** 重新思考视觉重建:基于经验的内容完成以视觉提示为指导

**作者:** Jiaxuan Chen, Yu Qi, Gang Pan

**Abstract:** Decoding seen images from brain activities has been an absorbing field. However, the reconstructed images still suffer from low quality with existing studies. This can be because our visual system is not like a camera that ”remembers” every pixel. Instead, only part of the information can be perceived with our selective attention, and the brain ”guesses” the rest to form what we think we see. Most existing approaches ignored the brain completion mechanism. In this work, we propose to reconstruct seen images with both the visual perception and the brain completion process, and design a simple, yet effective visual decoding framework to achieve this goal. Specifically, we first construct a shared discrete representation space for both brain signals and images. Then, a novel self-supervised token-to-token inpainting network is designed to implement visual content completion by building context and prior knowledge about the visual objects from the discrete latent space. Our approach improved the quality of visual reconstruction significantly and achieved state-of-the-art.

**摘要:** 大脑活动中的视觉图像的解码是一项吸收领域。然而,重建的图像仍受现有研究的低质量影响。这可能是因为我们的视觉系统不像一个像相机那样“记住”每一个像素。相反,只有一部分信息可以被我们选择的注意力所感知,而大脑“推测”其余部分以形成我们认为我们看到的。大多数现有的方法忽视了大脑完成机制。我们的方法大大提高了视觉重建的质量,并实现了最先进的技术。

**[Paper URL](https://proceedings.mlr.press/v202/chen23v.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23v/chen23v.pdf)** 

# Stratified Adversarial Robustness with Rejection
**题目:** 坚固的敌对力量与拒绝

**作者:** Jiefeng Chen, Jayaram Raghuram, Jihye Choi, Xi Wu, Yingyu Liang, Somesh Jha

**Abstract:** Recently, there is an emerging interest in adversarially training a classifier with a rejection option (also known as a selective classifier) for boosting adversarial robustness. While rejection can incur a cost in many applications, existing studies typically associate zero cost with rejecting perturbed inputs, which can result in the rejection of numerous slightly-perturbed inputs that could be correctly classified. In this work, we study adversarially-robust classification with rejection in the stratified rejection setting, where the rejection cost is modeled by rejection loss functions monotonically non-increasing in the perturbation magnitude. We theoretically analyze the stratified rejection setting and propose a novel defense method – Adversarial Training with Consistent Prediction-based Rejection (CPR) – for building a robust selective classifier. Experiments on image datasets demonstrate that the proposed method significantly outperforms existing methods under strong adaptive attacks. For instance, on CIFAR-10, CPR reduces the total robust loss (for different rejection losses) by at least 7.3% under both seen and unseen attacks.

**摘要:** 近年来,针对增强敌对鲁棒性的拒绝选项(也称为选择性分类器)的敌对训练产生了兴趣,拒拒绝在许多应用中可能造成成本,现有的研究通常将零成本与拒绝扰动输入联系起来,这可能导致许多可以正确分类的轻微扰动输入的拒绝。基于图像数据集的实验表明,该方法在强适应性攻击下明显优于现有方法。例如,在CIFAR-10中,CPR降低了在可见和无可见攻击下(对不同的拒绝损失)的总 robust 损失至少为7.3%。

**[Paper URL](https://proceedings.mlr.press/v202/chen23w.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23w/chen23w.pdf)** 

# Multi-task Hierarchical Adversarial Inverse Reinforcement Learning
**题目:** 多任务层次敌对反向强化学习

**作者:** Jiayu Chen, Dipesh Tamboli, Tian Lan, Vaneet Aggarwal

**Abstract:** Multi-task Imitation Learning (MIL) aims to train a policy capable of performing a distribution of tasks based on multi-task expert demonstrations, which is essential for general-purpose robots. Existing MIL algorithms suffer from low data efficiency and poor performance on complex long-horizontal tasks. We develop Multi-task Hierarchical Adversarial Inverse Reinforcement Learning (MH-AIRL) to learn hierarchically-structured multi-task policies, which is more beneficial for compositional tasks with long horizons and has higher expert data efficiency through identifying and transferring reusable basic skills across tasks. To realize this, MH-AIRL effectively synthesizes context-based multi-task learning, AIRL (an IL approach), and hierarchical policy learning. Further, MH-AIRL can be adopted to demonstrations without the task or skill annotations (i.e., state-action pairs only) which are more accessible in practice. Theoretical justifications are provided for each module of MH-AIRL, and evaluations on challenging multi-task settings demonstrate superior performance and transferability of the multi-task policies learned with MH-AIRL as compared to SOTA MIL baselines.

**摘要:** 多任务仿真学习(Multi-task Imitation Learning,MIL)旨在训练具有基于多任务专家演示的任务分配能力的政策,对于通用机器人来说是必不可少的。现有的MIL算法在复杂多目标任务中 suffer from low data efficiency and poor performance. We develop Multi-task Hierarchical Adversarial Inverse Reinforcement Learning (MH-AIRL) to learn hierarchically-structured multi-task policies, which is more beneficial for compositional tasks with long horizons and has higher expert data efficiency through identifying and transferring reusable basic skills across tasks. To realize this, MH-AIRL effectively synthesizes context-based multi-task learning, AIRL (an IL approach), and hierarchical policy learning. Further, MH-AIRL can be adopted to demonstrations without the task or skill annotations (i.e.,为MH-AIRL的每个模块提供了理论依据,对挑战性多任务设置的评价显示了与SOTA MIL基本线相比,MH-AIRL学习的多任务政策的优越性能和可转让性。

**[Paper URL](https://proceedings.mlr.press/v202/chen23x.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23x/chen23x.pdf)** 

# Model Transferability with Responsive Decision Subjects
**题目:** 负责决策主体的模式转移性

**作者:** Yatong Chen, Zeyu Tang, Kun Zhang, Yang Liu

**Abstract:** Given an algorithmic predictor that is accurate on some source population consisting of strategic human decision subjects, will it remain accurate if the population respond to it? In our setting, an agent or a user corresponds to a sample $(X,Y)$ drawn from a distribution $\cal{D}$ and will face a model $h$ and its classification result $h(X)$. Agents can modify $X$ to adapt to $h$, which will incur a distribution shift on $(X,Y)$. Our formulation is motivated by applications where the deployed machine learning models are subjected to human agents, and will ultimately face responsive and interactive data distributions. We formalize the discussions of the transferability of a model by studying how the performance of the model trained on the available source distribution (data) would translate to the performance on its induced domain. We provide both upper bounds for the performance gap due to the induced domain shift, as well as lower bounds for the trade-offs that a classifier has to suffer on either the source training distribution or the induced target distribution. We provide further instantiated analysis for two popular domain adaptation settings, including covariate shift and target shift.

**摘要:** 鉴于一种基于战略人类决策主体的算法预测器对某些源群的准确性,如果该群响应,它是否会保持准确性? 在我们的设置中,一个代理或用户会与从分布 $\cal{D}$提取的样品 $(X,Y)$ 相符,并会面对模型 $h$及其分类结果 $h(X)$ 。代理可以修改 $X$ 以适应 $h$, 这将导致 $(X,Y)$ 上的分布变换。我们提供了基于诱导域移的性能差距的上限,以及一个分类器在源训练分布或诱导目标分布上所遭受的交易权限的下限。我们提供了两个流行域适应设置的进一步实时分析,包括可变域移和目标移。

**[Paper URL](https://proceedings.mlr.press/v202/chen23y.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23y/chen23y.pdf)** 

# Layered State Discovery for Incremental Autonomous Exploration
**题目:** 逐步自主勘探层状状态发现

**作者:** Liyu Chen, Andrea Tirinzoni, Alessandro Lazaric, Matteo Pirotta

**Abstract:** We study the autonomous exploration (AX) problem proposed by Lim & Auer (2012). In this setting, the objective is to discover a set of $\epsilon$-optimal policies reaching a set $\mathcal{S}_L^{\rightarrow}$ of incrementally $L$-controllable states. We introduce a novel layered decomposition of the set of incrementally $L$-controllable states that is based on the iterative application of a state-expansion operator. We leverage these results to design Layered Autonomous Exploration (LAE), a novel algorithm for AX that attains a sample complexity of $\tilde{\mathcal{O}}(LS^{\rightarrow}_{L(1+\epsilon)}\Gamma_{L(1+\epsilon)} A \ln^{12}(S^{\rightarrow}_{L(1+\epsilon)})/\epsilon^2)$, where $S^{\rightarrow}_{L(1+\epsilon)}$ is the number of states that are incrementally $L(1+\epsilon)$-controllable, $A$ is the number of actions, and $\Gamma_{L(1+\epsilon)}$ is the branching factor of the transitions over such states. LAE improves over the algorithm of Tarbouriech et al. (2020a) by a factor of $L^2$ and it is the first algorithm for AX that works in a countably-infinite state space. Moreover, we show that, under a certain identifiability assumption, LAE achieves minimax-optimal sample complexity of $\tilde{\mathcal{O}}(LS^{\rightarrow}_{L}A\ln^{12}(S^{\rightarrow}_{L})/\epsilon^2)$, outperforming existing algorithms and matching for the first time the lower bound proved by Cai et al. (2022) up to logarithmic factors.

**摘要:** 我们研究 Lim & Auer (2012) 提出 的 自主探索 (AX ) 问题 。 在 这个 设置 中, 目标 是 发现 一 套 $\epsilon$ - 最佳 政策, 达到 一 套 $\mathcal{S}_L^{\rightarrow}$ 的 渐进 $ L $ - 可 控制 状态 。 我们 介绍 一 种 基于 状态 - 扩展 算子 迭代 应用 的 渐进 $ L $ - 可 控制 状态 集合 的 新层级 分解 。 我们 利用 这些 结果 设计 层级 自主探索 ( LAE ), 是 AX 的 新算法, 达到 $\tilde{\mathcal{O}} (LS^{\rightarrow}_{L(1+\epsi(2020a)以$L^2$的因子,它是AX的第一个在可计数无穷状态空间中运行的算法。此外,我们证明,在特定可识别假设下,LAE达到$\tilde{\mathcal{O}}(LS^{\rightarrow}_{L}A\ln^{12}(S^{\rightarrow}_{L})/\epsilon^2)$的最小最优样品复杂度,超越现有算法,首次匹配蔡等人(2022)证明的最小限度至数值因子。

**[Paper URL](https://proceedings.mlr.press/v202/chen23z.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23z/chen23z.pdf)** 

# Optimistic Online Mirror Descent for Bridging Stochastic and Adversarial Online Convex Optimization
**题目:** 基于策略和敌对网络凸优化的优化在线镜像降落

**作者:** Sijia Chen, Wei-Wei Tu, Peng Zhao, Lijun Zhang

**Abstract:** Stochastically Extended Adversarial (SEA) model is introduced by Sachs et al. (2022) as an interpolation between stochastic and adversarial online convex optimization. Under the smoothness condition, they demonstrate that the expected regret of optimistic follow-the-regularized-leader (FTRL) depends on the cumulative stochastic variance $\sigma_{1:T}^2$ and the cumulative adversarial variation $\Sigma_{1:T}^2$ for convex functions. They also provide a slightly weaker bound based on the maximal stochastic variance $\sigma_{\max}^2$ and the maximal adversarial variation $\Sigma_{\max}^2$ for strongly convex functions. Inspired by their work, we investigate the theoretical guarantees of optimistic online mirror descent (OMD) for the SEA model. For convex and smooth functions, we obtain the same $\mathcal{O}(\sqrt{\sigma_{1:T}^2}+\sqrt{\Sigma_{1:T}^2})$ regret bound, without the convexity requirement of individual functions. For strongly convex and smooth functions, we establish an $\mathcal{O}(\min\{\log (\sigma_{1:T}^2+\Sigma_{1:T}^2), (\sigma_{\max}^2 + \Sigma_{\max}^2) \log T\})$ bound, better than their $\mathcal{O}((\sigma_{\max}^2 + \Sigma_{\max}^2) \log T)$ result. For exp-concave and smooth functions, we achieve a new $\mathcal{O}(d\log(\sigma_{1:T}^2+\Sigma_{1:T}^2))$ bound. Owing to the OMD framework, we further establish dynamic regret for convex and smooth functions, which is more favorable in non-stationary online scenarios.

**摘要:** 随机扩展逆向(SEA)模型由萨克斯等人(英语:Sachs et al.)引入,作为随机和逆向在线凸优化的插值。在滑度条件下,他们证明,乐观追随调节领导(FTRL)的预期遗憾取决于凸函数的累积随机变量$\sigma_{1:T}^2$和累积逆向变量$\Sigma_{1:T}^2$。他们还提供了基于最大随机变量$\sigma_{\max}^2$和强凸函数的最大逆向变量$\Sigma_{\max}^2$的稍弱的约束。对于强凸和平滑函数,我们建立了$\mathcal{O}(\min\{\log (\sigma_{1:T}^2+\Sigma_{1:T}^2),(\sigma_{\max}^2 + \Sigma_{\max}^2) \log T\})$约束,比其$\mathcal{O}(((\sigma_{\max}^2 + \Sigma_{\max}^2) \log T)$结果更好。 对于exp-凸和平滑函数,我们实现了新的$\mathcal{O}(d\log(\sigma_{1:T}^2+\Sigma_{1:T}^2))$约束。

**[Paper URL](https://proceedings.mlr.press/v202/chen23aa.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23aa/chen23aa.pdf)** 

# Learning to Optimize Differentiable Games
**题目:** 学习优化可变游戏

**作者:** Xuxi Chen, Nelson Vadori, Tianlong Chen, Zhangyang Wang

**Abstract:** Many machine learning problems can be abstracted in solving game theory formulations and boil down to optimizing nested objectives, such as generative adversarial networks (GANs) and multi-agent reinforcement learning. Solving these games requires finding their stable fixed points or Nash equilibrium. However, existing algorithms for solving games suffer from empirical instability, hence demanding heavy ad-hoc tuning in practice. To tackle these challenges, we resort to the emerging scheme of Learning to Optimize (L2O), which discovers problem-specific efficient optimization algorithms through data-driven training. Our customized L2O framework for differentiable game theory problems, dubbed “Learning to Play Games" (L2PG), seeks a stable fixed point solution, by predicting the fast update direction from the past trajectory, with a novel gradient stability-aware, sign-based loss function. We further incorporate curriculum learning and self-learning to strengthen the empirical training stability and generalization of L2PG. On test problems including quadratic games and GANs, L2PG can substantially accelerate the convergence, and demonstrates a remarkably more stable trajectory. Codes are available at https://github.com/VITA-Group/L2PG.

**摘要:** 许多机器学习问题在解决游戏理论公式时可以抽象化,并归纳为优化嵌入目标,例如生成敌对网络(GANs)和多代理增强学习。解决这些游戏需要找到它们的稳定固定点或纳什平衡。然而,现有的解决游戏算法 suffer from empirical instability, hence demanding heavy ad-hoc tuning in practice。我们进一步整合课程学习和自我学习,以加强L2PG的实证训练稳定性和推广。在包括二次游戏和GAN的测试问题上,L2PG可以大幅加速收敛,并显示出更稳定的轨迹。

**[Paper URL](https://proceedings.mlr.press/v202/chen23ab.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23ab/chen23ab.pdf)** 

# Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets
**题目:** 配合预算的重复二价拍卖协调动态投标

**作者:** Yurong Chen, Qian Wang, Zhijian Duan, Haoran Sun, Zhaohua Chen, Xiang Yan, Xiaotie Deng

**Abstract:** In online ad markets, a rising number of advertisers are employing bidding agencies to participate in ad auctions. These agencies are specialized in designing online algorithms and bidding on behalf of their clients. Typically, an agency usually has information on multiple advertisers, so she can potentially coordinate bids to help her clients achieve higher utilities than those under independent bidding. In this paper, we study coordinated online bidding algorithms in repeated second-price auctions with budgets. We propose algorithms that guarantee every client a higher utility than the best she can get under independent bidding. We show that these algorithms achieve maximal social welfare and discuss bidders’ incentives to misreport their budgets, in symmetric cases. Our proofs combine the techniques of online learning and equilibrium analysis, overcoming the difficulty of competing with a multi-dimensional benchmark. The performance of our algorithms is further evaluated by experiments on both synthetic and real data. To the best of our knowledge, we are the first to consider bidder coordination in online repeated auctions with constraints.

**摘要:** 在在线广告市场上,越来越多的广告商正在聘用竞标机构参与竞标。这些机构专门设计在线算法和为客户竞标。通常,一个机构通常有多个广告商的信息,因此它可以潜在地协调竞标,帮助客户获得比在独立竞标中获得的更高效用。本论文研究了在重复的二价竞标中与预算的协调在线竞标算法。我们提出了保证每个客户比在独立竞标中获得的最高效用的算法。通过对合成数据和实际数据的实验,进一步评价了我们的算法的性能。根据我们所知,我们是第一个考虑在限制的在线重复拍卖中投标协调的机构。

**[Paper URL](https://proceedings.mlr.press/v202/chen23ac.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23ac/chen23ac.pdf)** 

# Semi-Offline Reinforcement Learning for Optimized Text Generation
**题目:** 优化文本生成的半线增强学习

**作者:** Changyu Chen, Xiting Wang, Yiqiao Jin, Victor Ye Dong, Li Dong, Jie Cao, Yi Liu, Rui Yan

**Abstract:** Existing reinforcement learning (RL) mainly utilize online or offline settings. The online methods explore the environment with expensive time cost, and the offline methods efficiently obtain reward signals by sacrificing the exploration capability. We propose semi-offline RL, a novel paradigm that can smoothly transit from the offline setting to the online setting, balances the exploration capability and training cost, and provides a theoretical foundation for comparing different RL settings. Based on the semi-offline MDP formulation, we present the RL setting that is optimal in terms of optimization cost, asymptotic error, and overfitting error bound. Extensive experiments show that our semi-offline RL approach is effective in various text generation tasks and datasets, and yields comparable or usually better performance compared with the state-of-the-art methods.

**摘要:** 现有强化学习(RL)主要利用在线或非在线设置。在线方法利用昂贵的时间成本探索环境,非在线方法通过牺牲勘探能力有效地获取奖励信号。我们提出了半 offline RL, 一种新颖的范式,可以从非在线设置顺利过境到在线设置,平衡勘探能力和培训成本,并为比较不同RL设置提供理论基础。

**[Paper URL](https://proceedings.mlr.press/v202/chen23ad.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23ad/chen23ad.pdf)** 

# Lower Bounds for Learning in Revealing POMDPs
**题目:** 在揭示强积金计划方面学习的最低限度

**作者:** Fan Chen, Huan Wang, Caiming Xiong, Song Mei, Yu Bai

**Abstract:** This paper studies the fundamental limits of reinforcement learning (RL) in the challenging partially observable setting. While it is well-established that learning in Partially Observable Markov Decision Processes (POMDPs) requires exponentially many samples in the worst case, a surge of recent work shows that polynomial sample complexities are achievable under the revealing condition—A natural condition that requires the observables to reveal some information about the unobserved latent states. However, the fundamental limits for learning in revealing POMDPs are much less understood, with existing lower bounds being rather preliminary and having substantial gaps from the current best upper bounds. We establish strong PAC and regret lower bounds for learning in revealing POMDPs. Our lower bounds scale polynomially in all relevant problem parameters in a multiplicative fashion, and achieve significantly smaller gaps against the current best upper bounds, providing a solid starting point for future studies. In particular, for multi-step revealing POMDPs, we show that (1) the latent state-space dependence is at least $\Omega(S^{1.5})$ in the PAC sample complexity, which is notably harder than the $\widetilde{\Theta}(S)$ scaling for fully-observable MDPs; (2) Any polynomial sublinear regret is at least $\Omega(T^{2/3})$, suggesting its fundamental difference from the single-step case where $\widetilde{\mathcal{O}}(\sqrt{T})$ regret is achievable. Technically, our hard instance construction adapts techniques in distribution testing, which is new to the RL literature and may be of independent interest. We also complement our results with new sharp regret upper bounds for strongly B-stable PSRs, which include single-step revealing POMDPs as a special case.

**摘要:** 本文研究了部分可观察环境中强化学习的基本局限性。虽然在最坏情况下,部分可观察马可夫决策过程(POMDPs)中学习需要指数多数样品,但最近的大量研究表明,在揭示条件下可实现多项式样品复杂性 — — 自然条件要求可观察者揭示一些关于未观察的潜伏状态的信息。然而,揭示POMDPs的基本局限性较少被理解,现有的下限则较初始,与当前最好的上限有相当大的差距。我们建立了强的PAC和遗憾揭示POMDPs的下限。我们的下边尺度在所有相关问题参数中以乘法方式进行多项式尺度,与当前最好的上边尺度相比达到显著较小的差距,为今后研究提供了一个坚实的起点。特别是,对于多步显示POMDP,我们证明 (1) 潜在状态空间依赖性至少在PAC样品复杂性$\Omega(S^{1.5})$,这比完全可观察的MDP的$\widetilde{\Theta}(S)$尺度明显困难; (2) 任何多项式次线性遗憾至少是$\Omega(T^{2/3})$,这表明与$\widetilde{\mathcal{O}}(\sqrt{T})$遗憾是可实现的单步案例的根本区别。

**[Paper URL](https://proceedings.mlr.press/v202/chen23ae.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23ae/chen23ae.pdf)** 

# Implicit Neural Spatial Representations for Time-dependent PDEs
**题目:** 时间依赖型PDEs的隐性神经空间表现

**作者:** Honglin Chen, Rundi Wu, Eitan Grinspun, Changxi Zheng, Peter Yichen Chen

**Abstract:** Implicit Neural Spatial Representation (INSR) has emerged as an effective representation of spatially-dependent vector fields. This work explores solving time-dependent PDEs with INSR. Classical PDE solvers introduce both temporal and spatial discretizations. Common spatial discretizations include meshes and meshless point clouds, where each degree-of-freedom corresponds to a location in space. While these explicit spatial correspondences are intuitive to model and understand, these representations are not necessarily optimal for accuracy, memory usage, or adaptivity. Keeping the classical temporal discretization unchanged (e.g., explicit/implicit Euler), we explore INSR as an alternative spatial discretization, where spatial information is implicitly stored in the neural network weights. The network weights then evolve over time via time integration. Our approach does not require any training data generated by existing solvers because our approach is the solver itself. We validate our approach on various PDEs with examples involving large elastic deformations, turbulent fluids, and multi-scale phenomena. While slower to compute than traditional representations, our approach exhibits higher accuracy and lower memory consumption. Whereas classical solvers can dynamically adapt their spatial representation only by resorting to complex remeshing algorithms, our INSR approach is intrinsically adaptive. By tapping into the rich literature of classic time integrators, e.g., operator-splitting schemes, our method enables challenging simulations in contact mechanics and turbulent flows where previous neural-physics approaches struggle. Videos and codes are available on the project page: http://www.cs.columbia.edu/cg/INSR-PDE/

**摘要:** 隐性神经空间表示(英语:Implicit Neural Spatial Representation,INSR)是空间依赖向量场的有效表示。该文研究用INSR解决时间依赖的PDEs。经典PDE求解器引入时间和空间区分。常见的空间区分包括网格和无网格点云,其中每个自由度与空间中的某个位置相符。虽然这些隐性空间区分对于建模和理解是直观的,但这些表示并不一定对精度、记忆使用或适应性是最佳的。保持经典时间区分不变(例如隐性/隐性欧勒),我们探索INSR作为替代空间区分,其中空间信息隐性存储在神经网络权重中。网络权重则通过时间整合演变。我们的方法不需要现有求解器生成的任何训练数据,因为我们的方法是求解器本身。我们对各种PDEs的方法进行了验证,并给出了大量弹性变形、湍流和多尺度现象的例子。虽然计算速度比传统的模型慢,但我们的方法具有较高的精度和较低的存储量。而经典的求解者只能依靠复杂的纠正算法动态调整其空间表示,而我们的INSR方法则具有内在的适应性。通过利用经典时间积分器的丰富文献,例如操作器分割方案,我们的方法使接触力学和湍流模拟具有挑战性,而此前的神经物理方法则面临着挑战。

**[Paper URL](https://proceedings.mlr.press/v202/chen23af.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23af/chen23af.pdf)** 

# BEATs: Audio Pre-Training with Acoustic Tokenizers
**题目:** BEATs:音频预训练与音频标记器

**作者:** Sanyuan Chen, Yu Wu, Chengyi Wang, Shujie Liu, Daniel Tompkins, Zhuo Chen, Wanxiang Che, Xiangzhan Yu, Furu Wei

**Abstract:** We introduce a self-supervised learning (SSL) framework BEATs for general audio representation pre-training, where we optimize an acoustic tokenizer and an audio SSL model by iterations. Unlike the previous audio SSL models that employ reconstruction loss for pre-training, our audio SSL model is trained with the discrete label prediction task, where the labels are generated by a semantic-rich acoustic tokenizer. We propose an iterative pipeline to jointly optimize the tokenizer and the pre-trained model, aiming to abstract high-level semantics and discard the redundant details for audio. The experimental results demonstrate our acoustic tokenizers can generate discrete labels with rich audio semantics and our audio SSL models achieve state-of-the-art (SOTA) results across various audio classification benchmarks, even outperforming previous models that use more training data and model parameters significantly. Specifically, we set a new SOTA mAP 50.6% on AudioSet-2M without using any external data, and 98.1% accuracy on ESC-50. The code and pre-trained models are available at https://aka.ms/beats.

**摘要:** 我们引入了自我监督学习(SSL)框架BEATs,用于一般音频表现预训练,其中我们通过迭代优化一个音频标识符和一个音频SSL模型。与以前使用重建损失的音频SSL模型不同,我们的音频SSL模型由离散标签预测任务训练,其中标签由语义丰富的音频标识符生成。我们提出了联合优化标识符和预训练模型的迭代管道,旨在抽象高层次语义并抛弃音频的冗余细节。实验结果表明,我们的音频标识符能够产生带有丰富的音频语义的离散标签,我们的音频SSL模型在各种音频分类基准中取得最先进的结果,甚至超过了使用更多训练数据和模型参数的先前模型。具体而言,我们没有使用任何外部数据,在AudioSet-2M设置了新的SOTA mAP50.6%,在ESC-50设置了98.1%的精度。

**[Paper URL](https://proceedings.mlr.press/v202/chen23ag.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23ag/chen23ag.pdf)** 

# Learning to Incentivize Information Acquisition: Proper Scoring Rules Meet Principal-Agent Model
**题目:** 如何鼓励获取信息:正确评分规则符合首席代理模式

**作者:** Siyu Chen, Jibang Wu, Yifan Wu, Zhuoran Yang

**Abstract:** We study the incentivized information acquisition problem, where a principal hires an agent to gather information on her behalf. Such a problem is modeled as a Stackelberg game between the principal and the agent, where the principal announces a scoring rule that specifies the payment, and then the agent then chooses an effort level that maximizes her own profit and reports the information. We study the online setting of such a problem from the principal’s perspective, i.e., designing the optimal scoring rule by repeatedly interacting with the strategic agent. We design a provably sample efficient algorithm that tailors the UCB algorithm (Auer et al., 2002) to our model, which achieves a $\mathcal{O} (K^2\cdot T^{2/3})$ regret after $T$ iterations, where $K$ is the number of effort levels of the agent. Our algorithm features a delicate estimation procedure for the optimal profit of the principal, and a conservative correction scheme that ensures the desired agent’s actions are incentivized. Furthermore, a key feature of our regret bound is that it is independent of the number of states of the environment.

**摘要:** 我们研究了激励信息获取问题,即委托人雇佣代理人为代理人收集信息。这种问题被建模为委托人与代理人之间的Stackelberg游戏,委托人宣布一个分数规则,指定支付,然后代理人选择一个努力水平,以最大化自己的利润,并报告信息。我们从委托人的角度研究这种问题的在线设置,即通过反复与战略代理人交互设计最佳分数规则。我们的算法具有一种精细的估算程序,以求获得最优的利润,并且有一个保守的纠正方案,以确保所希望的代理人的行为得到激励。此外,我们所束缚的遗憾的一个关键特征是它独立于环境的数量。

**[Paper URL](https://proceedings.mlr.press/v202/chen23ah.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23ah/chen23ah.pdf)** 

# Faster Gradient-Free Algorithms for Nonsmooth Nonconvex Stochastic Optimization
**题目:** 非滑非凸随机优化的快速梯度自由算法

**作者:** Lesi Chen, Jing Xu, Luo Luo

**Abstract:** We consider the optimization problem of the form $\min_{x \in \mathbb{R}^d} f(x) \triangleq \mathbb{E}[F(x;\xi)]$ , where the component $F(x;\xi)$ is $L$-mean-squared Lipschitz but possibly nonconvex and nonsmooth.The recently proposed gradient-free method requires at most $\mathcal{O}( L^4 d^{3/2} \epsilon^{-4} + \Delta L^3 d^{3/2} \delta^{-1} \epsilon^{-4})$ stochastic zeroth-order oracle complexity to find a $(\delta,\epsilon)$-Goldstein stationary point of objective function, where $\Delta = f(x_0) - \inf_{x \in \mathbb{R}^d} f(x)$ and $x_0$ is the initial point of the algorithm. This paper proposes a more efficient algorithm using stochastic recursive gradient estimators, which improves the complexity to $\mathcal{O}(L^3 d^{3/2} \epsilon^{-3}+ \Delta L^2 d^{3/2} \delta^{-1} \epsilon^{-3})$.

**摘要:** 我们考虑了形式 $\min_{x \in \mathbb{R}^d} f(x) \triangleq \mathbb{E}[F(x;\xi)]$ 的优化问题,其中组件 $F(x;\xi)$ 是 $L$-平均平方的利普希茨,但可能不是凸的和不滑的。 最近提出的梯度自由方法最需要 $\mathcal{O}( L^4 d^{3/2} \epsilon^{-4} + \Delta L^3 d^{3/2} \delta^{-1} \epsilon^{-4})$ 的随机零阶词汇复杂性,以找到 $(\delta,\epsilon)$-目标函数的Goldstein静点,其中 $\Delta =

**[Paper URL](https://proceedings.mlr.press/v202/chen23ai.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23ai/chen23ai.pdf)** 

# Efficient Personalized Federated Learning via Sparse Model-Adaptation
**题目:** 基于节余模型适应的高效个人化联邦学习

**作者:** Daoyuan Chen, Liuyi Yao, Dawei Gao, Bolin Ding, Yaliang Li

**Abstract:** Federated Learning (FL) aims to train machine learning models for multiple clients without sharing their own private data. Due to the heterogeneity of clients’ local data distribution, recent studies explore the personalized FL that learns and deploys distinct local models with the help of auxiliary global models. However, the clients can be heterogeneous in terms of not only local data distribution, but also their computation and communication resources. The capacity and efficiency of personalized models are restricted by the lowest-resource clients, leading to sub-optimal performance and limited practicality of personalized FL. To overcome these challenges, we propose a novel approach named pFedGate for efficient personalized FL by adaptively and efficiently learning sparse local models. With a lightweight trainable gating layer, pFedGate enables clients to reach their full potential in model capacity by generating different sparse models accounting for both the heterogeneous data distributions and resource constraints. Meanwhile, the computation and communication efficiency are both improved thanks to the adaptability between the model sparsity and clients’ resources. Further, we theoretically show that the proposed pFedGate has superior complexity with guaranteed convergence and generalization error. Extensive experiments show that pFedGate achieves superior global accuracy, individual accuracy and efficiency simultaneously over state-of-the-art methods. We also demonstrate that pFedGate performs better than competitors in the novel clients participation and partial clients participation scenarios, and can learn meaningful sparse local models adapted to different data distributions.

**摘要:** 联邦学习(FL)旨在为多个客户培训机器学习模型,而不共享他们自己的私人数据。由于客户本地数据分布的异质性,最近的研究探讨了利用辅助全球模型学习和部署不同的本地模型的个性化 FL。然而,客户不仅在本地数据分布方面异质,而且在计算和通信资源方面也异质。同时,由于模型稀疏性和客户资源之间的适应性,计算和通信效率都得到了改善。此外,我们从理论上证明,拟议的pFedGate具有具有较高的复杂性,具有保证的收敛性和推广误差。广泛的实验表明,pFedGate在最先进的方法上同时实现了全球精度、个人精度和效率的优越。

**[Paper URL](https://proceedings.mlr.press/v202/chen23aj.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23aj/chen23aj.pdf)** 

# A Gromov-Wasserstein Geometric View of Spectrum-Preserving Graph Coarsening
**题目:** Gromov-Wasserstein光谱保护图形粗糙度的几何视角

**作者:** Yifan Chen, Rentian Yao, Yun Yang, Jie Chen

**Abstract:** Graph coarsening is a technique for solving large-scale graph problems by working on a smaller version of the original graph, and possibly interpolating the results back to the original graph. It has a long history in scientific computing and has recently gained popularity in machine learning, particularly in methods that preserve the graph spectrum. This work studies graph coarsening from a different perspective, developing a theory for preserving graph distances and proposing a method to achieve this. The geometric approach is useful when working with a collection of graphs, such as in graph classification and regression. In this study, we consider a graph as an element on a metric space equipped with the Gromov–Wasserstein (GW) distance, and bound the difference between the distance of two graphs and their coarsened versions. Minimizing this difference can be done using the popular weighted kernel $K$-means method, which improves existing spectrum-preserving methods with the proper choice of the kernel. The study includes a set of experiments to support the theory and method, including approximating the GW distance, preserving the graph spectrum, classifying graphs using spectral information, and performing regression using graph convolutional networks. Code is available at https://github.com/ychen-stat-ml/GW-Graph-Coarsening.

**摘要:** 图形粗糙度是通过对原始图形的较小版本进行工作,并可能将结果重新插值到原始图形解决大规模图形问题的一种技术。它在科学计算中具有悠久的历史,并最近在机器学习中得到了广泛应用,特别是在保存图形谱的方法中。本研究从不同角度研究图形粗糙度,发展了保存图形距离的理论,并提出了实现此目的方法。该研究包括支持理论和方法的一系列实验,包括近似GW距离、保存图谱、使用光谱信息分类图和使用图卷网络进行回归。代码可于 https://github.com/ychen-stat-ml/GW-Graph-Coarsening。

**[Paper URL](https://proceedings.mlr.press/v202/chen23ak.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23ak/chen23ak.pdf)** 

# How to address monotonicity for model risk management?
**题目:** 如何解决模型风险管理的单调性?

**作者:** Dangxing Chen, Weicheng Ye

**Abstract:** In this paper, we study the problem of establishing the accountability and fairness of transparent machine learning models through monotonicity. Although there have been numerous studies on individual monotonicity, pairwise monotonicity is often overlooked in the existing literature. This paper studies transparent neural networks in the presence of three types of monotonicity: individual monotonicity, weak pairwise monotonicity, and strong pairwise monotonicity. As a means of achieving monotonicity while maintaining transparency, we propose the monotonic groves of neural additive models. As a result of empirical examples, we demonstrate that monotonicity is often violated in practice and that monotonic groves of neural additive models are transparent, accountable, and fair.

**摘要:** 本文研究了通过单调性建立透明机器学习模型的问责和公平问题,虽然对单调性进行了大量的研究,但单调性在现有文献中经常被忽视。本文研究了在单调性存在三个类型的透明神经网络:单调性个体,单调性弱双向,单调性强双向。作为实现单调性 while maintaining transparency的一种手段,我们提出了神经添加模型的单调树林。

**[Paper URL](https://proceedings.mlr.press/v202/chen23al.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23al/chen23al.pdf)** 

# Sketched Ridgeless Linear Regression: The Role of Downsampling
**题目:**  sketched Ridgeless Linear Regression: Downsampling的作用

**作者:** Xin Chen, Yicheng Zeng, Siyue Yang, Qiang Sun

**Abstract:** Overparametrization often helps improve the generalization performance. This paper presents a dual view of overparametrization suggesting that downsampling may also help generalize. Focusing on the proportional regime $m\asymp n \asymp p$, where $m$ represents the sketching size, $n$ is the sample size, and $p$ is the feature dimensionality, we investigate two out-of-sample prediction risks of the sketched ridgeless least square estimator. Our findings challenge conventional beliefs by showing that downsampling does not always harm generalization but can actually improve it in certain cases. We identify the optimal sketching size that minimizes out-of-sample prediction risks and demonstrate that the optimally sketched estimator exhibits stabler risk curves, eliminating the peaks of those for the full-sample estimator. To facilitate practical implementation, we propose an empirical procedure to determine the optimal sketching size. Finally, we extend our analysis to cover central limit theorems and misspecified models. Numerical studies strongly support our theory.

**摘要:** 超参数化常常有助于提高一般化性能。本文提出了超参数化的双重观点,认为下采样也有助于一般化。我们着重于比例模式$m\asymp n \asymp p$,其中$m$代表了下采样大小,$n$是样品大小,$p$是特征维度,我们对下采样无脊 least square 估计器的两个外采样预测风险进行了研究。我们发现下采样并不总是危害一般化,但确实可以在某些情况下改善它。我们确定了最优的下采样大小,以最小化外采样预测风险,并证明了最优的下采样估计器表现出更稳定的风险曲线,消除了全采样估计器的峰值。最后,我们对中心限度定理和误区模型进行了分析,数值研究有力地支持了本文的理论。

**[Paper URL](https://proceedings.mlr.press/v202/chen23am.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23am/chen23am.pdf)** 

# Context-Aware Bayesian Network Actor-Critic Methods for Cooperative Multi-Agent Reinforcement Learning
**题目:**  Bayesian Network Actor-Critic Methods for Cooperative Multi-Agent Reinforcement Learning 的背景意识

**作者:** Dingyang Chen, Qi Zhang

**Abstract:** Executing actions in a correlated manner is a common strategy for human coordination that often leads to better cooperation, which is also potentially beneficial for cooperative multi-agent reinforcement learning (MARL). However, the recent success of MARL relies heavily on the convenient paradigm of purely decentralized execution, where there is no action correlation among agents for scalability considerations. In this work, we introduce a Bayesian network to inaugurate correlations between agents’ action selections in their joint policy. Theoretically, we establish a theoretical justification for why action dependencies are beneficial by deriving the multi-agent policy gradient formula under such a Bayesian network joint policy and proving its global convergence to Nash equilibria under tabular softmax policy parameterization in cooperative Markov games. Further, by equipping existing MARL algorithms with a recent method of differentiable directed acyclic graphs (DAGs), we develop practical algorithms to learn the context-aware Bayesian network policies in scenarios with partial observability and various difficulty. We also dynamically decrease the sparsity of the learned DAG throughout the training process, which leads to weakly or even purely independent policies for decentralized execution. Empirical results on a range of MARL benchmarks show the benefits of our approach.

**摘要:** 协同执行行为是人类协调的共同策略,经常导致更好的合作,也是协同多代理强化学习(MARL)的潜在优势。然而,MARL最近的成功很大程度上依赖于纯粹分散执行的便于范式,在这种范式下,在可扩展性考虑下,代理之间没有行动相关性。本研究中,我们引入了贝叶斯网络,以揭示代理在共同政策中行动选择之间的相关性。同时,通过对现有的MARL算法提供可微分导环形图(DAG)的最新方法,我们开发了具有部分可观察性和各种困难的场景中具有上下文意识的贝叶斯网络策略的实用算法,并通过训练过程动态降低学习的DAG的稀疏性,从而导致分散执行的策略弱甚至完全独立。

**[Paper URL](https://proceedings.mlr.press/v202/chen23an.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23an/chen23an.pdf)** 

# Bidirectional Learning for Offline Model-based Biological Sequence Design
**题目:** 基于非线性模型的生物序列设计的双向学习

**作者:** Can Chen, Yingxue Zhang, Xue Liu, Mark Coates

**Abstract:** Offline model-based optimization aims to maximize a black-box objective function with a static dataset of designs and their scores. In this paper, we focus on biological sequence design to maximize some sequence score. A recent approach employs bidirectional learning, combining a forward mapping for exploitation and a backward mapping for constraint, and it relies on the neural tangent kernel (NTK) of an infinitely wide network to build a proxy model. Though effective, the NTK cannot learn features because of its parametrization, and its use prevents the incorporation of powerful pre-trained Language Models (LMs) that can capture the rich biophysical information in millions of biological sequences. We adopt an alternative proxy model, adding a linear head to a pre-trained LM, and propose a linearization scheme. This yields a closed-form loss and also takes into account the biophysical information in the pre-trained LM. In addition, the forward mapping and the backward mapping play different roles and thus deserve different weights during sequence optimization. To achieve this, we train an auxiliary model and leverage its weak supervision signal via a bi-level optimization framework to effectively learn how to balance the two mappings. Further, by extending the framework, we develop the first learning rate adaptation module Adaptive-$\eta$, which is compatible with all gradient-based algorithms for offline model-based optimization. Experimental results on DNA/protein sequence design tasks verify the effectiveness of our algorithm. Our code is available at https://github.com/GGchen1997/BIB-ICML2023-Submission.

**摘要:** 基于非线性模型的优化目标是利用静态数据集设计及其分数来最大化黑箱目标函数。本论文着重于生物序列设计,以最大化某些序列分数。最近一种方法采用双向学习,结合前向映射用于开发和后向映射用于约束,并依赖无穷宽的网络的神经 Tangent Kernel(NTK)来构建代理模型。虽然有效,NTK不能因参数化而学习特性,其使用阻止了包含在数百万生物序列中丰富的生物物理信息的强大的预训练语言模型(LMs)。此外,前向映射和后向映射扮演不同的角色,因此在序列优化过程中应有不同的权重。为了实现这一点,我们训练了一个辅助模型,并利用其弱的监控信号通过双级优化框架有效学习如何平衡两个映射。此外,通过扩展框架,我们开发了第一个学习速率适应模块Adaptive-$\eta$,它与所有基于梯度的算法兼容,用于基于offline模型的优化。

**[Paper URL](https://proceedings.mlr.press/v202/chen23ao.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23ao/chen23ao.pdf)** 

# Learning to Jump: Thinning and Thickening Latent Counts for Generative Modeling
**题目:** 跳跃学习:生成模型的减小和增大潜在数目

**作者:** Tianqi Chen, Mingyuan Zhou

**Abstract:** Learning to denoise has emerged as a prominent paradigm to design state-of-the-art deep generative models for natural images. How to use it to model the distributions of both continuous real-valued data and categorical data has been well studied in recently proposed diffusion models. However, it is found in this paper to have limited ability in modeling some other types of data, such as count and non-negative continuous data, that are often highly sparse, skewed, heavy-tailed, and/or overdispersed. To this end, we propose learning to jump as a general recipe for generative modeling of various types of data. Using a forward count thinning process to construct learning objectives to train a deep neural network, it employs a reverse count thickening process to iteratively refine its generation through that network. We demonstrate when learning to jump is expected to perform comparably to learning to denoise, and when it is expected to perform better. For example, learning to jump is recommended when the training data is non-negative and exhibits strong sparsity, skewness, heavy-tailedness, and/or heterogeneity.

**摘要:** 如何利用它来建模连续的实值数据和分类数据的分布,在最近提出的扩散模型中得到了很好的研究。然而,本文发现在建模某些其他类型的数据,如数和非负连续数据,往往非常稀疏、偏差、重尾和/或过分散,具有有限的能力。为此,我们建议学习跳跃作为各种类型数据的生成建模的一般方法。例如,如果训练数据不是负的,并且表现出强的稀疏性、斜率、重尾形和/或异质性,则建议学习跳跃。

**[Paper URL](https://proceedings.mlr.press/v202/chen23ap.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23ap/chen23ap.pdf)** 

# Lifelong Language Pretraining with Distribution-Specialized Experts
**题目:** 终身语言预习与分布专业专家

**作者:** Wuyang Chen, Yanqi Zhou, Nan Du, Yanping Huang, James Laudon, Zhifeng Chen, Claire Cui

**Abstract:** Pretraining on a large-scale corpus has become a standard method to build general language models (LMs). Adapting a model to new data distributions targeting different downstream tasks poses significant challenges. Naive fine-tuning may incur catastrophic forgetting when the over-parameterized LMs overfit the new data but fail to preserve the pretrained features. Lifelong learning (LLL) aims to enable information systems to learn from a continuous data stream across time. However, most prior work modifies the training recipe assuming a static fixed network architecture. We find that additional model capacity and proper regularization are key elements to achieving strong LLL performance. Thus, we propose Lifelong-MoE, an extensible MoE (Mixture-of-Experts) architecture that dynamically adds model capacity via adding experts with regularized pretaining. Our results show that by only introducing a limited number of extra experts while keeping the computation cost constant, our model can steadily adapt to data distribution shifts while preserving the previous knowledge. Compared to existing lifelong learning approaches, Lifelong-MoE achieves better few-shot performance on NLP tasks. More impressively, Lifelong-MoE surpasses multi-task learning on 19 downstream NLU tasks.

**摘要:** 在大规模的文体上预备训练已成为建立通用语言模型(LMs)的标准方法。针对不同下游任务的新的数据分布,调整模型会带来重大挑战。不自明的微调可能导致过分参数化LMs超过新数据,但无法保留预备的功能。终身学习(LLL)的目标是使信息系统从连续的数据流中学习。然而,大部分以前的工作修改训练配方,假设是静态固定网络架构。我们发现额外的模型能力和适当的规范化是实现强LLL性能的关键要素。我们的结果表明,只要引入有限的额外专家,同时保持计算成本不变,我们的模型能够稳步地适应数据分布变化,同时保持先前的知识。与现有的终身学习方法相比,Lifelong-MoE在NLP任务中取得较好的少数射击性能。

**[Paper URL](https://proceedings.mlr.press/v202/chen23aq.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23aq/chen23aq.pdf)** 

# Generalized-Smooth Nonconvex Optimization is As Efficient As Smooth Nonconvex Optimization
**题目:** 一般化滑非凸优化比滑非凸优化更有效

**作者:** Ziyi Chen, Yi Zhou, Yingbin Liang, Zhaosong Lu

**Abstract:** Various optimal gradient-based algorithms have been developed for smooth nonconvex optimization. However, many nonconvex machine learning problems do not belong to the class of smooth functions and therefore the existing algorithms are sub-optimal. Instead, these problems have been shown to satisfy certain generalized-smooth conditions, which have not been well understood in the existing literature. In this paper, we propose a notion of $\alpha$-symmetric generalized-smoothness that substantially extends the existing notions and covers many important functions such as high-order polynomials and exponential functions. We study the fundamental properties and establish descent lemmas for the functions in this class. Then, to solve such a large class of nonconvex problems, we design a special deterministic normalized gradient descent algorithm that achieves the optimal iteration complexity $\mathcal{O}(\epsilon^{-2})$, and also prove that the popular SPIDER variance reduction algorithm achieves the optimal sample complexity $\mathcal{O}(\epsilon^{-3})$. Our results show that solving generalized-smooth nonconvex problems is as efficient as solving smooth nonconvex problems.

**摘要:** 为了实现平滑非凸优化,开发了各种基于梯度的优化算法,但许多非凸机学习问题不属于平滑函数类,因此现有的算法是次优的。相反,这些问题已证明满足某些一般化平滑条件,这些条件在现有文献中没有得到很好的理解。然后,为了解决如此大的非凸类问题,我们设计了一种特殊的确定性标准化梯度降落算法,实现了最佳迭代复杂度$\mathcal{O}(\epsilon^{-2})$,并证明了流行的SPIDER变量减少算法实现了最佳样品复杂度$\mathcal{O}(\epsilon^{-3})$。

**[Paper URL](https://proceedings.mlr.press/v202/chen23ar.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chen23ar/chen23ar.pdf)** 

# Weakly Supervised Regression with Interval Targets
**题目:** 弱监管的回归与间隔目标

**作者:** Xin Cheng, Yuzhou Cao, Ximing Li, Bo An, Lei Feng

**Abstract:** This paper investigates an interesting weakly supervised regression setting called regression with interval targets (RIT). Although some of the previous methods on relevant regression settings can be adapted to RIT, they are not statistically consistent, and thus their empirical performance is not guaranteed. In this paper, we provide a thorough study on RIT. First, we proposed a novel statistical model to describe the data generation process for RIT and demonstrate its validity. Second, we analyze a simple selecting method for RIT, which selects a particular value in the interval as the target value to train the model. Third, we propose a statistically consistent limiting method for RIT to train the model by limiting the predictions to the interval. We further derive an estimation error bound for our limiting method. Finally, extensive experiments on various datasets demonstrate the effectiveness of our proposed method.

**摘要:** 本文研究了一种具有弱点监督的回归设置,即与间隔目标的回归(英语:Interval Targets Regression (RIT)) 。虽然有关的回归设置的某些方法可以适应到RIT,但它们的统计性并不一致,因此它们的实证性能没有保证。本文对RIT进行了深入研究。首先,我们提出了一种新的统计模型来描述RIT的数据生成过程,并证明其有效性。其次,我们分析了一种简单的选择方法,该方法在间隔中选择一个特定值,作为训练模型的目标值。第三,我们提出了一种统计性一致的限制方法,以限制到间隔的预测来训练模型。

**[Paper URL](https://proceedings.mlr.press/v202/cheng23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cheng23a/cheng23a.pdf)** 

# PLay: Parametrically Conditioned Layout Generation using Latent Diffusion
**题目:** PLay:使用拉特特扩散的参数配置布局生成

**作者:** Chin-Yi Cheng, Forrest Huang, Gang Li, Yang Li

**Abstract:** Layout design is an important task in various design fields, including user interfaces, document, and graphic design. As this task requires tedious manual effort by designers, prior works have attempted to automate this process using generative models, but commonly fell short of providing intuitive user controls and achieving design objectives. In this paper, we build a conditional latent diffusion model, PLay, that generates parametrically conditioned layouts in vector graphic space from user-specified guidelines, which are commonly used by designers for representing their design intents in current practices. Our method outperforms prior works across three datasets on metrics including FID and FD-VG, and in user test. Moreover, it brings a novel and interactive experience to professional layout design processes.

**摘要:** 布局设计是包括用户界面、文档和图形设计在内的各个设计领域的重要任务。由于这项任务需要设计人员费时的手动努力,以前的工作曾试图通过生成模型实现这种过程的自动化,但通常没有提供直观的用户控制和实现设计目标。本论文中,我们构建了一个条件延迟扩散模型,PLay,它从用户指定的指导方针生成向量图形空间中的参数化条件的布局,通常被设计人员用于在当前实践中代表他们的设计意图。

**[Paper URL](https://proceedings.mlr.press/v202/cheng23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cheng23b/cheng23b.pdf)** 

# Identification of the Adversary from a Single Adversarial Example
**题目:** 从单个敌方例子中辨识敌方

**作者:** Minhao Cheng, Rui Min, Haochen Sun, Pin-Yu Chen

**Abstract:** Deep neural networks have been shown vulnerable to adversarial examples. Even though many defense methods have been proposed to enhance the robustness, it is still a long way toward providing an attack-free method to build a trustworthy machine learning system. In this paper, instead of enhancing the robustness, we take the investigator’s perspective and propose a new framework to trace the first compromised model copy in a forensic investigation manner. Specifically, we focus on the following setting: the machine learning service provider provides model copies for a set of customers. However, one of the customers conducted adversarial attacks to fool the system. Therefore, the investigator’s objective is to identify the first compromised copy by collecting and analyzing evidence from only available adversarial examples. To make the tracing viable, we design a random mask watermarking mechanism to differentiate adversarial examples from different copies. First, we propose a tracing approach in the data-limited case where the original example is also available. Then, we design a data-free approach to identify the adversary without accessing the original example. Finally, the effectiveness of our proposed framework is evaluated by extensive experiments with different model architectures, adversarial attacks, and datasets.

**摘要:** 研究表明,深层神经网络易受敌对实例的攻击。虽然为增强鲁棒性提出了许多防护方法,但为建立可靠的机器学习系统提供无攻击方法仍是一个很长的路途。本文,我们以调查员的视角代替强化鲁棒性,并提出一种新的框架以以法学调查方式追踪第一个妥协的模型副本。具体,我们着重于以下设置:机器学习服务提供模型副本给一组客户。然而,其中一个客户为欺骗系统进行敌对攻击。因此,调查员的目标是通过收集和分析只有可用的敌对实例的证据来识别第一个妥协的副本。首先,在数据有限的例子中,我们提出了一种跟踪方法,然后设计了一个无数据的方法,以不访问原始的例子来识别敌方。最后,通过对不同模型架构、敌方攻击和数据集进行广泛的实验,评估了我们提出的框架的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/cheng23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cheng23c/cheng23c.pdf)** 

# Parallel Online Clustering of Bandits via Hedonic Game
**题目:** 平行网络集结黑人通过黑人游戏

**作者:** Xiaotong Cheng, Cheng Pan, Setareh Maghsudi

**Abstract:** Contextual bandit algorithms appear in several applications, such as online advertisement and recommendation systems like personalized education or personalized medicine. Individually-tailored recommendations boost the performance of the underlying application; nevertheless, providing individual suggestions becomes costly and even implausible as the number of users grows. As such, to efficiently serve the demands of several users in modern applications, it is imperative to identify the underlying users’ clusters, i.e., the groups of users for which a single recommendation might be (near-)optimal. We propose CLUB-HG, a novel algorithm that integrates a game-theoretic approach into clustering inference. Our algorithm achieves Nash equilibrium at each inference step and discovers the underlying clusters. We also provide regret analysis within a standard linear stochastic noise setting. Finally, experiments on synthetic and real-world datasets show the superior performance of our proposed algorithm compared to the state-of-the-art algorithms.

**摘要:** 网络广告和推荐系统,如个性化教育或个性化医疗等,在多个应用中出现的背景盗窃算法。个人定制的建议提升了潜在应用的性能;然而,提供个人建议随着用户数量的增加而变得昂贵甚至难以置信。因此,为了在现代应用中有效地满足多个用户的需求,必须识别潜在用户群,即一个建议可能(接近)最优的用户群。我们提出了一种新颖的算法 CLUB-HG,它将游戏理论方法集成到集群推理中。我们的算法在每个推理步骤中达到纳什均衡,并发现潜在的集群。最后,对合成和实世界数据集的实验表明,我们提出的算法的性能优于最先进的算法。

**[Paper URL](https://proceedings.mlr.press/v202/cheng23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cheng23d/cheng23d.pdf)** 

# Mu$^2$SLAM: Multitask, Multilingual Speech and Language Models
**题目:** Mu$^2$SLAM:多任务、多语言语言和语言模型

**作者:** Yong Cheng, Yu Zhang, Melvin Johnson, Wolfgang Macherey, Ankur Bapna

**Abstract:** We present Mu$^2$SLAM, a multilingual sequence-to-sequence model pre-trained jointly on unlabeled speech, unlabeled text and supervised data spanning Automatic Speech Recognition (ASR), Automatic Speech Translation (AST) and Machine Translation (MT), in over 100 languages. By leveraging a quantized representation of speech as a target, Mu$^2$SLAM trains the speech-text models with a sequence-to-sequence masked denoising objective similar to T5 on the decoder and a masked language modeling objective (MLM) on the encoder, for both unlabeled speech and text, while utilizing the supervised tasks to improve cross-lingual and cross-modal representation alignment within the model. On CoVoST AST, Mu$^2$SLAM establishes a new state-of-the-art for models trained on public datasets, improving on xx-en translation over the previous best by 1.9 BLEU points and on en-xx translation by 1.1 BLEU points. On Voxpopuli ASR, our model matches the performance of an mSLAM model fine-tuned with an RNN-T decoder, despite using a relatively weaker Transformer decoder. On text understanding tasks, our model improves by more than 6% over mSLAM on XNLI, getting closer to the performance of mT5 models of comparable capacity on XNLI and TydiQA, paving the way towards a single model for all speech and text understanding tasks.

**摘要:** 我们 介绍 Mu$^2$SLAM, 一种 在 非 标记 的 话语 、 非 标记 的 文本 和 在 超过 100 个 语言 的 自动 语音 识别 ( ASR ) 、 自动 语音 翻译 ( AST ) 和 机器 翻译 ( MT ) 之间 共同 预先 训练 的 多语言 序列 到 序列 模型 。 通过 利用 语言 的 量化 表示 作为 目标, Mu$^2$SLAM 训练 了 非 标记 话语 和 文本 的 非标记 话语 和 机器 翻译 目标 的 非标记 话语 和 文本 的 非标记 话语 和 机器 翻译 目标, 在Voxpopuli ASR上,我们的模型与使用相对较弱的Transformer解码器的rNN-T解码器调谐的mSLAM模型的性能相匹配。在文本理解任务上,我们的模型比mSLAM在XNLI提高了6%以上,接近在XNLI和TidiQA的mT5模型的性能,为所有语音和文本理解任务铺平了道路。

**[Paper URL](https://proceedings.mlr.press/v202/cheng23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cheng23e/cheng23e.pdf)** 

# Understanding the Role of Feedback in Online Learning with Switching Costs
**题目:** 基于交换成本的在线学习反馈的作用

**作者:** Duo Cheng, Xingyu Zhou, Bo Ji

**Abstract:** In this paper, we study the role of feedback in online learning with switching costs. It has been shown that the minimax regret is $\widetilde{\Theta}(T^{2/3})$ under bandit feedback and improves to $\widetilde{\Theta}(\sqrt{T})$ under full-information feedback, where $T$ is the length of the time horizon. However, it remains largely unknown how the amount and type of feedback generally impact regret. To this end, we first consider the setting of bandit learning with extra observations; that is, in addition to the typical bandit feedback, the learner can freely make a total of $B_{\mathrm{ex}}$ extra observations. We fully characterize the minimax regret in this setting, which exhibits an interesting phase-transition phenomenon: when $B_{\mathrm{ex}} = O(T^{2/3})$, the regret remains $\widetilde{\Theta}(T^{2/3})$, but when $B_{\mathrm{ex}} = \Omega(T^{2/3})$, it becomes $\widetilde{\Theta}(T/\sqrt{B_{\mathrm{ex}}})$, which improves as the budget $B_{\mathrm{ex}}$ increases. To design algorithms that can achieve the minimax regret, it is instructive to consider a more general setting where the learner has a budget of $B$ total observations. We fully characterize the minimax regret in this setting as well and show that it is $\widetilde{\Theta}(T/\sqrt{B})$, which scales smoothly with the total budget $B$. Furthermore, we propose a generic algorithmic framework, which enables us to design different learning algorithms that can achieve matching upper bounds for both settings based on the amount and type of feedback. One interesting finding is that while bandit feedback can still guarantee optimal regret when the budget is relatively limited, it no longer suffices to achieve optimal regret when the budget is relatively large.

**摘要:** 本文研究了基于交换成本的在线学习中反馈的作用。已经证明,最小反馈是$\widetilde{\Theta}(T^{2/3})$在带式反馈下,并且在全信息反馈下改善到$\widetilde{\Theta}(\sqrt{T})$,其中$T$是时间视角的长度。然而,目前仍不清楚反馈的数量和类型如何影响遗憾。为此,我们首先考虑了带式学习的设置,即除了典型的带式反馈之外,学习者可以自由地进行$B_{\mathrm{ex}}$额外的观察。为了设计能够实现微分遗憾的算法,我们需要考虑一个较一般的设置,即学习者具有$B$总观测的预算。我们充分描述了这个设置中的微分遗憾,并表明它是$\widetilde{\Theta}(T/\sqrt{B})$,它与总预算$B$平滑的尺度。此外,我们提出了一种通用的算法框架,它使我们能够设计不同的学习算法,可以根据反馈量和类型为两个设置实现匹配的上限。

**[Paper URL](https://proceedings.mlr.press/v202/cheng23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cheng23f/cheng23f.pdf)** 

# Tighter Bounds on the Expressivity of Transformer Encoders
**题目:** 变换编码器表达能力的更严格限制

**作者:** David Chiang, Peter Cholak, Anand Pillay

**Abstract:** Characterizing neural networks in terms of better-understood formal systems has the potential to yield new insights into the power and limitations of these networks. Doing so for transformers remains an active area of research. Bhattamishra and others have shown that transformer encoders are at least as expressive as a certain kind of counter machine, while Merrill and Sabharwal have shown that fixed-precision transformer encoders recognize only languages in uniform $TC^0$. We connect and strengthen these results by identifying a variant of first-order logic with counting quantifiers that is simultaneously an upper bound for fixed-precision transformer encoders and a lower bound for transformer encoders. This brings us much closer than before to an exact characterization of the languages that transformer encoders recognize.

**摘要:** 将神经网络定义为一种更清晰的正式系统具有产生对这些网络的力量和局限性的新洞察的潜力。对于变换器来说,这样做仍然是研究的一个活跃领域。 Bhattamishra和其他人证明了变换器编码器至少具有某种类型的计数机的表达性,而Merrill和Sabharwal则证明了固定精度变换器编码器只识别统一$TC^0$的语言。我们通过识别一个由数量化器计算的初级逻辑变换来连接和加强这些结果,同时是固定精度变换器编码器的上界和变换器编码器的下界。

**[Paper URL](https://proceedings.mlr.press/v202/chiang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chiang23a/chiang23a.pdf)** 

# Provably Learning Diverse Features in Multi-View Data with Midpoint Mixup
**题目:** 使用Midpoint Mixup学习多视数据中的多种功能

**作者:** Muthu Chidambaram, Xiang Wang, Chenwei Wu, Rong Ge

**Abstract:** Mixup is a data augmentation technique that relies on training using random convex combinations of data points and their labels. In recent years, Mixup has become a standard primitive used in the training of state-of-the-art image classification models due to its demonstrated benefits over empirical risk minimization with regards to generalization and robustness. In this work, we try to explain some of this success from a feature learning perspective. We focus our attention on classification problems in which each class may have multiple associated features (or $\textit{views}$) that can be used to predict the class correctly. Our main theoretical results demonstrate that, for a non-trivial class of data distributions with two features per class, training a 2-layer convolutional network using empirical risk minimization can lead to learning only one feature for almost all classes while training with a specific instantiation of Mixup succeeds in learning both features for every class. We also show empirically that these theoretical insights extend to the practical settings of image benchmarks modified to have multiple features.

**摘要:** Mixup是一个数据增强技术,它依赖于使用数据点及其标签的随机凸组合的训练。近年来,Mixup已成为最先进的图像分类模型的训练中的一个标准原始技术,因为它在经验风险最小化方面的优点被证明,对于推广和鲁棒性而言。在这个工作中,我们试图从特征学习视角解释这一成功。我们集中注意力于分类问题,其中每个类可能有多个相关的特征(或$\textit{views}$),可以用于正确预测该类。我们的主要理论结果表明,对于一个具有两个特征的非平凡数据分布类,使用经验风险最小化训练的2层卷积网络可以导致几乎所有类只学习一个特征,而使用Mixup的特定实例训练则成功地学习每个类的两个特征。我们还通过实验证明,这些理论洞察扩展到修改为具有多种特征的图像基准的实际设置。

**[Paper URL](https://proceedings.mlr.press/v202/chidambaram23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chidambaram23a/chidambaram23a.pdf)** 

# Hiding Data Helps: On the Benefits of Masking for Sparse Coding
**题目:** 隐藏数据的帮助:对备份编码的掩护效果

**作者:** Muthu Chidambaram, Chenwei Wu, Yu Cheng, Rong Ge

**Abstract:** Sparse coding, which refers to modeling a signal as sparse linear combinations of the elements of a learned dictionary, has proven to be a successful (and interpretable) approach in applications such as signal processing, computer vision, and medical imaging. While this success has spurred much work on provable guarantees for dictionary recovery when the learned dictionary is the same size as the ground-truth dictionary, work on the setting where the learned dictionary is larger (or $\textit{over-realized}$) with respect to the ground truth is comparatively nascent. Existing theoretical results in this setting have been constrained to the case of noise-less data. We show in this work that, in the presence of noise, minimizing the standard dictionary learning objective can fail to recover the elements of the ground-truth dictionary in the over-realized regime, regardless of the magnitude of the signal in the data-generating process. Furthermore, drawing from the growing body of work on self-supervised learning, we propose a novel masking objective for which recovering the ground-truth dictionary is in fact optimal as the signal increases for a large class of data-generating processes. We corroborate our theoretical results with experiments across several parameter regimes showing that our proposed objective also enjoys better empirical performance than the standard reconstruction objective.

**摘要:** 稀疏编码(英语:Sparse coding)是指将信号建模成一个学习字典的元素稀疏线性组合,在信号处理、计算机视觉和医学影像等应用中证明是成功的(和可解释的)方法。当学习字典与地面真理字典的大小相同时,在学习字典较大(或$\textit{over-realized}$)的条件下,对地面真理字典相对较新出现的条件下,虽然这一条件下现有的理论结果被限制在无噪数据的条件下。我们在此工作中表明,在噪声的情况下,最小化标准字典学习目标可能无法在过度实现的条件下恢复地面真理字典的元素,不顾数据生成过程中的信号的大小。此外,我们从不断增长的自我监督学习领域中提议一种新的隐蔽目标,因为在大量数据生成过程中信号增加的情况下,复原原基本事实字典实际上是最佳的。我们通过对多个参数模式的实验证实了我们的理论结果,表明我们提议的目标也比标准的重建目标具有更好的经验性能。

**[Paper URL](https://proceedings.mlr.press/v202/chidambaram23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chidambaram23b/chidambaram23b.pdf)** 

# PINA: Leveraging Side Information in eXtreme Multi-label Classification via Predicted Instance Neighborhood Aggregation
**题目:** PINA:利用预见环境邻域集法在eXtreme多标签分类中利用侧信息

**作者:** Eli Chien, Jiong Zhang, Cho-Jui Hsieh, Jyun-Yu Jiang, Wei-Cheng Chang, Olgica Milenkovic, Hsiang-Fu Yu

**Abstract:** The eXtreme Multi-label Classification (XMC) problem seeks to find relevant labels from an exceptionally large label space. Most of the existing XMC learners focus on the extraction of semantic features from input query text. However, conventional XMC studies usually neglect the side information of instances and labels, which can be of use in many real-world applications such as recommendation systems and e-commerce product search. We propose Predicted Instance Neighborhood Aggregation (PINA), a data augmentation method for the general XMC problem that leverages beneficial side information. Unlike most existing XMC frameworks that treat labels and input instances as featureless indicators and independent entries, PINA extracts information from the label metadata and the correlations among training instances. Extensive experimental results demonstrate the consistent gain of PINA on various XMC tasks compared to the state-of-the-art methods: PINA offers a gain in accuracy compared to standard XR-Transformers on five public benchmark datasets. Moreover, PINA achieves a $\sim 5$% gain in accuracy on the largest dataset LF-AmazonTitles-1.3M.

**摘要:** eXtreme多标签分类(XMC)问题旨在从异常大的标签空间中找到相关的标签。大多数现有XMC学习者集中于从输入查询文本中提取语义特征。然而,传统的XMC研究通常忽略实例和标签的侧信息,这些信息可以用于许多现实应用,如推荐系统和电子商务产品搜索。我们提出了 Predicted Instance Neighborhood Aggregation(PINA),一种用于一般XMC问题的数据增加方法,它利用有益的侧信息。广泛的实验结果表明,PINA在不同XMC任务中与最先进的方法相比取得了一致的提高:PINA在5个公共基准数据集中,与标准XR变换器相比,提高了精度。此外,PINA在最大数据集LF-AmazonTitles-1.3M上取得了5$%的精度提高。

**[Paper URL](https://proceedings.mlr.press/v202/chien23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chien23a/chien23a.pdf)** 

# Tight Certification of Adversarially Trained Neural Networks via Nonconvex Low-Rank Semidefinite Relaxations
**题目:** 通过非凸低位半定义松弛的敌对训练神经网络的严格认证

**作者:** Hong-Ming Chiu, Richard Y. Zhang

**Abstract:** Adversarial training is well-known to produce high-quality neural network models that are empirically robust against adversarial perturbations. Nevertheless, once a model has been adversarially trained, one often desires a certification that the model is truly robust against all future attacks. Unfortunately, when faced with adversarially trained models, all existing approaches have significant trouble making certifications that are strong enough to be practically useful. Linear programming (LP) techniques in particular face a “convex relaxation barrier” that prevent them from making high-quality certifications, even after refinement with mixed-integer linear programming (MILP) and branch-and-bound (BnB) techniques. In this paper, we propose a nonconvex certification technique, based on a low-rank restriction of a semidefinite programming (SDP) relaxation. The nonconvex relaxation makes strong certifications comparable to much more expensive SDP methods, while optimizing over dramatically fewer variables comparable to much weaker LP methods. Despite nonconvexity, we show how off-the-shelf local optimization algorithms can be used to achieve and to certify global optimality in polynomial time. Our experiments find that the nonconvex relaxation almost completely closes the gap towards exact certification of adversarially trained models.

**摘要:** 敌对训练是制造高质量的神经网络模型而具有实证性强于敌对扰动的能力。然而,一旦一个模型被敌对训练,人们往往希望得到一个证明,证明该模型对所有未来的攻击是真正强的。不幸的是,当面对敌对训练的模型时,所有现有的方法都有重大的困难制造证明,这些证明足够强,以供实际使用。非凸性松弛使得强的认证与昂贵的 SDP 方法相比较,同时对较弱的 LP 方法相比较的变量大幅减少的优化。 尽管非凸性,我们展示了在多项式时间中实现和验证全球优化的可选的局部优化算法。

**[Paper URL](https://proceedings.mlr.press/v202/chiu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chiu23a/chiu23a.pdf)** 

# Neural Latent Aligner: Cross-trial Alignment for Learning Representations of Complex, Naturalistic Neural Data
**题目:** 神经突变异构:复合神经数据学习表现的跨试验拟合

**作者:** Cheol Jun Cho, Edward Chang, Gopala Anumanchipalli

**Abstract:** Understanding the neural implementation of complex human behaviors is one of the major goals in neuroscience. To this end, it is crucial to find a true representation of the neural data, which is challenging due to the high complexity of behaviors and the low signal-to-ratio (SNR) of the signals. Here, we propose a novel unsupervised learning framework, Neural Latent Aligner (NLA), to find well-constrained, behaviorally relevant neural representations of complex behaviors. The key idea is to align representations across repeated trials to learn cross-trial consistent information. Furthermore, we propose a novel, fully differentiable time warping model (TWM) to resolve the temporal misalignment of trials. When applied to intracranial electrocorticography (ECoG) of natural speaking, our model learns better representations for decoding behaviors than the baseline models, especially in lower dimensional space. The TWM is empirically validated by measuring behavioral coherence between aligned trials. The proposed framework learns more cross-trial consistent representations than the baselines, and when visualized, the manifold reveals shared neural trajectories across trials.

**摘要:** 理解复杂人类行为的神经实现是神经科学的主要目标之一。为此目的,寻找神经数据的真正表现是至关重要的,因为神经行为的复杂性和信号的低信号--比例(SNR)是挑战性的。TWM通过测量整齐试验之间的行为一致性,以实证验证其有效性。提议的框架比基线更了解交叉试验的一致性,并且当可视化时,多变形显示了实验中共享的神经轨迹。

**[Paper URL](https://proceedings.mlr.press/v202/cho23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cho23a/cho23a.pdf)** 

# On the Convergence of Federated Averaging with Cyclic Client Participation
**题目:** 联邦平均与周期客户参与的融合

**作者:** Yae Jee Cho, Pranay Sharma, Gauri Joshi, Zheng Xu, Satyen Kale, Tong Zhang

**Abstract:** Federated Averaging (FedAvg) and its variants are the most popular optimization algorithms in federated learning (FL). Previous convergence analyses of FedAvg either assume full client participation or partial client participation where the clients can be uniformly sampled. However, in practical cross-device FL systems, only a subset of clients that satisfy local criteria such as battery status, network connectivity, and maximum participation frequency requirements (to ensure privacy) are available for training at a given time. As a result, client availability follows a natural cyclic pattern. We provide (to our knowledge) the first theoretical framework to analyze the convergence of FedAvg with cyclic client participation with several different client optimizers such as GD, SGD, and shuffled SGD. Our analysis discovers that cyclic client participation can achieve a faster asymptotic convergence rate than vanilla FedAvg with uniform client participation under suitable conditions, providing valuable insights into the design of client sampling protocols.

**摘要:** 联邦平均(FedAvg)及其变量是联邦学习(FL)中最受欢迎的优化算法。FedAvg的以前的收敛分析要么假设完全的客户参与,要么部分的客户参与,客户可以统一样本。然而,在实际的跨设备 FL系统中,只有满足本地标准的客户部分,例如电池状态、网络连接和最大参与频率要求(确保隐私)在指定的时间为培训提供。结果,客户可用性遵循自然循环模式。我们的分析发现,循环的客户参与能够在适当条件下实现比花蜜的FedAvg更快的渐近收敛率,提供宝贵的洞察 client sampling 协议的设计。

**[Paper URL](https://proceedings.mlr.press/v202/cho23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cho23b/cho23b.pdf)** 

# GREAD: Graph Neural Reaction-Diffusion Networks
**题目:** GREAD:图神经反应-扩散网络

**作者:** Jeongwhan Choi, Seoyoung Hong, Noseong Park, Sung-Bae Cho

**Abstract:** Graph neural networks (GNNs) are one of the most popular research topics for deep learning. GNN methods typically have been designed on top of the graph signal processing theory. In particular, diffusion equations have been widely used for designing the core processing layer of GNNs, and therefore they are inevitably vulnerable to the notorious oversmoothing problem. Recently, a couple of papers paid attention to reaction equations in conjunctions with diffusion equations. However, they all consider limited forms of reaction equations. To this end, we present a reaction-diffusion equation-based GNN method that considers all popular types of reaction equations in addition to one special reaction equation designed by us. To our knowledge, our paper is one of the most comprehensive studies on reaction-diffusion equation-based GNNs. In our experiments with 9 datasets and 28 baselines, our method, called GREAD, outperforms them in a majority of cases. Further synthetic data experiments show that it mitigates the oversmoothing problem and works well for various homophily rates.

**摘要:** 图神经网络(GNNs)是深层学习最流行的研究课题之一。GNN方法通常是图信号处理理论的顶部设计。特别是,扩散方程广泛用于设计GNN的核心处理层,因此它们不可避免地易于恶名昭著的过度扩散问题。最近,一些论文对扩散方程结合的反应方程给予了关注。然而,它们都考虑了反应方程的有限形式。为此目的,我们提出了一种基于反应扩散方程的GNN方法,它除了我们设计的特殊反应方程之外,考虑了所有流行的反应方程类型。进一步的合成数据实验表明,它减轻了过度吸烟问题,并对各种同性恋率有很好的效果。

**[Paper URL](https://proceedings.mlr.press/v202/choi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/choi23a/choi23a.pdf)** 

# Is Overfitting Necessary for Implicit Video Representation?
**题目:** 对隐形视频表示是否需要超标?

**作者:** Hee Min Choi, Hyoa Kang, Dokwan Oh

**Abstract:** Compact representation of multimedia signals using implicit neural representations (INRs) has advanced significantly over the past few years, and recent works address their applications to video. Existing studies on video INR have focused on network architecture design as all video information is contained within network parameters. Here, we propose a new paradigm in efficient INR for videos based on the idea of strong lottery ticket (SLT) hypothesis (Zhou et al., 2019), which demonstrates the possibility of finding an accurate subnetwork mask, called supermask, for a randomly initialized classification network without weight training. Specifically, we train multiple supermasks with a hierarchical structure for a randomly initialized image-wise video representation model without weight updates. Different from a previous approach employing hierarchical supermasks (Okoshi et al., 2022), a trainable scale parameter for each mask is used instead of multiplying by the same fixed scale for all levels. This simple modification widens the parameter search space to sufficiently explore various sparsity patterns, leading the proposed algorithm to find stronger subnetworks. Moreover, extensive experiments on popular UVG benchmark show that random subnetworks obtained from our framework achieve higher reconstruction and visual quality than fully trained models with similar encoding sizes. Our study is the first to demonstrate the existence of SLTs in video INR models and propose an efficient method for finding them.

**摘要:** 使用隐性神经表示(INR)的多媒体信号的小型表示在过去几年中取得了显著的进步,最近的研究都针对其应用于视频。目前的视频INR研究集中在网络架构设计上,因为所有视频信息都包含在网络参数中。不同于以往采用层次级超模(Okoshi et al., 2022),每个模采用可训练的尺度参数,而不是用相同的固定尺度对所有级别的乘法。这一简单的修改扩大了参数搜索空间,充分探索各种稀疏模式,导致提议的算法找到较强的子网络。此外,广泛的实验表明,从我们的框架中获得的随机子网络比具有相似编码大小的完全训练模型具有更高的重建和视觉质量。

**[Paper URL](https://proceedings.mlr.press/v202/choi23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/choi23b/choi23b.pdf)** 

# Semi-Parametric Contextual Pricing Algorithm using Cox Proportional Hazards Model
**题目:** 基于Cox比例风险模型的半参数背景定价算法

**作者:** Young-Geun Choi, Gi-Soo Kim, Yunseo Choi, Wooseong Cho, Myunghee Cho Paik, Min-Hwan Oh

**Abstract:** Contextual dynamic pricing is a problem of setting prices based on current contextual information and previous sales history to maximize revenue. A popular approach is to postulate a distribution of customer valuation as a function of contextual information and the baseline valuation. A semi-parametric setting, where the context effect is parametric and the baseline is nonparametric, is of growing interest due to its flexibility. A challenge is that customer valuation is almost never observable in practice and is instead type-I interval censored by the offered price. To address this challenge, we propose a novel semi-parametric contextual pricing algorithm for stochastic contexts, called the epoch-based Cox proportional hazards Contextual Pricing (CoxCP) algorithm. To our best knowledge, our work is the first to employ the Cox model for customer valuation. The CoxCP algorithm has a high-probability regret upper bound of $\tilde{O}( T^{\frac{2}{3}}d )$, where $T$ is the length of horizon and $d$ is the dimension of context. In addition, if the baseline is known, the regret bound can improve to $O( d \log T )$ under certain assumptions. We demonstrate empirically the proposed algorithm performs better than existing semi-parametric contextual pricing algorithms when the model assumptions of all algorithms are correct.

**摘要:** 语境动态定价是一个基于当前语境信息和以前销售历史的定价问题,以最大化收入。一个流行的方法是假设语境信息和基线定价的分布。一个半参数设置,其中语境效应是参数的,基线是非参数的,是由于其灵活性而日益引起的兴趣。一个挑战是,客户定价几乎从不在实践中观察到,而是由提供的价格censored type-I interval。CoxCP算法具有$\tilde{O}(T^{\frac{2}{3}}d )$的高概率遗憾上限,其中$T$是地平线的长度,$d$是上下文的维度。此外,如果基线是知道的,遗憾上限可以在某些假设下提高到$O(d \log T )$。

**[Paper URL](https://proceedings.mlr.press/v202/choi23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/choi23c/choi23c.pdf)** 

# Restoration based Generative Models
**题目:** 基于恢复的生成模型

**作者:** Jaemoo Choi, Yesom Park, Myungjoo Kang

**Abstract:** Denoising diffusion models (DDMs) have recently attracted increasing attention by showing impressive synthesis quality. DDMs are built on a diffusion process that pushes data to the noise distribution and the models learn to denoise. In this paper, we establish the interpretation of DDMs in terms of image restoration (IR). Integrating IR literature allows us to use an alternative objective and diverse forward processes, not confining to the diffusion process. By imposing prior knowledge on the loss function grounded on MAP-based estimation, we eliminate the need for the expensive sampling of DDMs. Also, we propose a multi-scale training, which improves the performance compared to the diffusion process, by taking advantage of the flexibility of the forward process. Experimental results demonstrate that our model improves the quality and efficiency of both training and inference. Furthermore, we show the applicability of our model to inverse problems. We believe that our framework paves the way for designing a new type of flexible general generative model.

**摘要:** DDM是基于数据推向噪声分布的扩散过程而建起来的,模型学习扩散。本文建立DDM在图像恢复(IR)方面的解释。集成IR文獻允许我们使用替代目标和多样的扩散过程,而不局限于扩散过程。通过基于MAP估计的损失函数的预先知识,我们消除了扩散过程昂贵的采样的必要性。此外,我们提出了多尺度的培训,以利用扩散过程的灵活性提高扩散过程的性能。实验结果表明,我们的模型提高了训练和推导的质量和效率。我们认为,我们的框架为设计一种新型灵活的通用生成模型铺平了道路。

**[Paper URL](https://proceedings.mlr.press/v202/choi23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/choi23d/choi23d.pdf)** 

# Concept-based Explanations for Out-of-Distribution Detectors
**题目:** 基于概念的非分布检测器解释

**作者:** Jihye Choi, Jayaram Raghuram, Ryan Feng, Jiefeng Chen, Somesh Jha, Atul Prakash

**Abstract:** Out-of-distribution (OOD) detection plays a crucial role in ensuring the safe deployment of deep neural network (DNN) classifiers. While a myriad of methods have focused on improving the performance of OOD detectors, a critical gap remains in interpreting their decisions. We help bridge this gap by providing explanations for OOD detectors based on learned high-level concepts. We first propose two new metrics for assessing the effectiveness of a particular set of concepts for explaining OOD detectors: 1) detection completeness, which quantifies the sufficiency of concepts for explaining an OOD-detector’s decisions, and 2) concept separability, which captures the distributional separation between in-distribution and OOD data in the concept space. Based on these metrics, we propose an unsupervised framework for learning a set of concepts that satisfy the desired properties of high detection completeness and concept separability, and demonstrate its effectiveness in providing concept-based explanations for diverse off-the-shelf OOD detectors. We also show how to identify prominent concepts contributing to the detection results, and provide further reasoning about their decisions.

**摘要:** 在确保安全部署深度神经网络(DNN)分类器方面,非分布式检测发挥着关键作用。虽然无数方法集中于提高OOD检测器的性能,但在解释其决策方面仍存在一个关键的缺口。我们通过基于高层次概念的基于OOD检测器的解释来帮助填补这一缺口。首先,我们提出了两个新的指标来评估用于解释OOD检测器的特定概念的有效性:(一)检测完全性,量化了用于解释OOD检测器决策的概念的足够性;(二)概念分离性,它捕捉了在概念空间中内分布和OOD数据的分布分离。基于这些指标,我们提出了一种不受监督的框架,以学习一套符合高检测完整性和概念分离性的要求的概念,并证明其在提供各种现货的OOD检测器的基于概念解释方面的有效性。我们还展示了如何识别有助于检测结果的突出概念,并提供有关其决策的进一步推理。

**[Paper URL](https://proceedings.mlr.press/v202/choi23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/choi23e/choi23e.pdf)** 

# Active causal structure learning with advice
**题目:** 主动因果结构学习与建议

**作者:** Davin Choo, Themistoklis Gouleakis, Arnab Bhattacharyya

**Abstract:** We introduce the problem of active causal structure learning with advice. In the typical well-studied setting, the learning algorithm is given the essential graph for the observational distribution and is asked to recover the underlying causal directed acyclic graph (DAG) $G^*$ while minimizing the number of interventions made. In our setting, we are additionally given side information about $G^*$ as advice, e.g. a DAG $G$ purported to be $G^*$. We ask whether the learning algorithm can benefit from the advice when it is close to being correct, while still having worst-case guarantees even when the advice is arbitrarily bad. Our work is in the same space as the growing body of research on algorithms with predictions. When the advice is a DAG $G$, we design an adaptive search algorithm to recover $G^*$ whose intervention cost is at most $\mathcal{O}(\max\{1, \log \psi\})$ times the cost for verifying $G^*$; here, $\psi$ is a distance measure between $G$ and $G^*$ that is upper bounded by the number of variables $n$, and is exactly 0 when $G=G^*$. Our approximation factor matches the state-of-the-art for the advice-less setting.

**摘要:** 我们引入了主动因果结构学习与建议的问题。在典型研究的设置中,学习算法给出了观察分布的基本图,并要求在最小化所作的干预数时恢复根源因果导向环形图(DAG)$G^*$。在我们的设置中,我们还给出了关于$G^*$作为建议的侧信息,例如一个DAG$G$被认为是$G^*$。当建议是DAG $G$时,我们设计了一个自适应搜索算法来恢复$G^*$,其干预成本最多是$\mathcal{O}(\max\{1, \log \psi\})$ times对验证$G^*$的成本;这里,$\psi$是$G$和$G^*$之间的距离尺度,由变量$n$的数量限制,在$G=G^*$时是0。

**[Paper URL](https://proceedings.mlr.press/v202/choo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/choo23a/choo23a.pdf)** 

# New metrics and search algorithms for weighted causal DAGs
**题目:**  weighted causal DAGs的新计量和搜索算法

**作者:** Davin Choo, Kirankumar Shiragur

**Abstract:** Recovering causal relationships from data is an important problem. Using observational data, one can typically only recover causal graphs up to a Markov equivalence class and additional assumptions or interventional data are needed for complete recovery. In this work, under some standard assumptions, we study causal graph discovery via adaptive interventions with node-dependent interventional costs. For this setting, we show that no algorithm can achieve an approximation guarantee that is asymptotically better than linear in the number of vertices with respect to the verification number; a well-established benchmark for adaptive search algorithms. Motivated by this negative result, we define a new benchmark that captures the worst-case interventional cost for any search algorithm. Furthermore, with respect to this new benchmark, we provide adaptive search algorithms that achieve logarithmic approximations under various settings: atomic, bounded size interventions and generalized cost objectives.

**摘要:** 从数据中恢复因果关系是一个重要的问题。使用观察数据,人们通常只能恢复到马可夫等价类的因果图,并且需要额外的假设或干预数据来完成恢复。在这个工作中,根据一些标准假设,我们通过节点依赖干预成本的适应干预来研究因果图的发现。此外,针对这一新的基准,我们提供适应性搜索算法,在不同的环境下实现数值近似:原子、边界尺寸干预和一般化成本目标。

**[Paper URL](https://proceedings.mlr.press/v202/choo23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/choo23b/choo23b.pdf)** 

# Computational Doob h-transforms for Online Filtering of Discretely Observed Diffusions
**题目:** 随机观察差异的在线滤波的计算doobh变换

**作者:** Nicolas Chopin, Andras Fulop, Jeremy Heng, Alexandre H. Thiery

**Abstract:** This paper is concerned with online filtering of discretely observed nonlinear diffusion processes. Our approach is based on the fully adapted auxiliary particle filter, which involves Doob’s $h$-transforms that are typically intractable. We propose a computational framework to approximate these $h$-transforms by solving the underlying backward Kolmogorov equations using nonlinear Feynman-Kac formulas and neural networks. The methodology allows one to train a locally optimal particle filter prior to the data-assimilation procedure. Numerical experiments illustrate that the proposed approach can be orders of magnitude more efficient than state-of-the-art particle filters in the regime of highly informative observations, when the observations are extreme under the model, and if the state dimension is large.

**摘要:** 本文讨论了离散观察的非线性扩散过程的在线滤波。我们的方法是基于完全适应的辅助粒子滤波器,它涉及多布的$h$-变换,这些变换通常是不可解决的。我们提出了一种计算框架来通过解决非线性费恩曼-卡克公式和神经网络解决这些$h$-变换,以便在数据同化过程之前训练一个局部最佳粒子滤波器。

**[Paper URL](https://proceedings.mlr.press/v202/chopin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chopin23a/chopin23a.pdf)** 

# Multi-Epoch Matrix Factorization Mechanisms for Private Machine Learning
**题目:** 私人机器学习的多阶段矩阵因子化机制

**作者:** Christopher A. Choquette-Choo, Hugh Brendan Mcmahan, J Keith Rush, Abhradeep Guha Thakurta

**Abstract:** We introduce new differentially private (DP) mechanisms for gradient-based machine learning (ML) with multiple passes (epochs) over a dataset, substantially improving the achievable privacy-utility-computation tradeoffs. We formalize the problem of DP mechanisms for adaptive streams with multiple participations and introduce a non-trivial extension of online matrix factorization DP mechanisms to our setting. This includes establishing the necessary theory for sensitivity calculations and efficient computation of optimal matrices. For some applications like $>\!\! 10,000$ SGD steps, applying these optimal techniques becomes computationally expensive. We thus design an efficient Fourier-transform-based mechanism with only a minor utility loss. Extensive empirical evaluation on both example-level DP for image classification and user-level DP for language modeling demonstrate substantial improvements over all previous methods, including the widely-used DP-SGD. Though our primary application is to ML, our main DP results are applicable to arbitrary linear queries and hence may have much broader applicability.

**摘要:** 我们为基于梯度的机器学习(ML)引入新的微分私有(DP)机制,在数据集上具有多个通道(epochs),大大提高了可实现的私有-实用-计算权衡。我们为多参与的自适应流的DP机制问题进行了形式化,并引入了在线矩阵因子化DP机制的非平凡扩展到我们的设置中。这包括建立敏感性计算和优化矩阵的有效计算所需的理论。对于一些应用,如$>\!\!$10,000的SGD步骤,应用这些最佳技术会使计算成本昂贵。因此,我们设计了一个具有效率的傅立叶变换-基础的机制,只有一个小实用损失。虽然我们的主要应用是ML,但我们的主要DP结果适用于任意线性查询,因此可能具有更广泛的适用性。

**[Paper URL](https://proceedings.mlr.press/v202/choquette-choo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/choquette-choo23a/choquette-choo23a.pdf)** 

# Taming graph kernels with random features
**题目:** 利用随机特性来驯服图形核

**作者:** Krzysztof Marcin Choromanski

**Abstract:** We introduce in this paper the mechanism of graph random features (GRFs). GRFs can be used to construct unbiased randomized estimators of several important kernels defined on graphs’ nodes, in particular the regularized Laplacian kernel. As regular RFs for non-graph kernels, they provide means to scale up kernel methods defined on graphs to larger networks. Importantly, they give substantial computational gains also for smaller graphs, while applied in downstream applications. Consequently, GRFs address the notoriously difficult problem of cubic (in the number of the nodes of the graph) time complexity of graph kernels algorithms. We provide a detailed theoretical analysis of GRFs and an extensive empirical evaluation: from speed tests, through Frobenius relative error analysis to kmeans graph-clustering with graph kernels. We show that the computation of GRFs admits an embarrassingly simple distributed algorithm that can be applied if the graph under consideration needs to be split across several machines. We also introduce a (still unbiased) quasi Monte Carlo variant of GRFs, q-GRFs, relying on the so-called reinforced random walks that might be used to optimize the variance of GRFs. As a byproduct, we obtain a novel approach to solve certain classes of linear equations with positive and symmetric matrices.

**摘要:** 本文介绍了图随机特征(GRF)的机理。GRF可以用于构造在图节点上定义的几个重要核子的偏向随机估计器,特别是拉普拉西亚核的正则化估计器。作为非图节点的正则RF,它们提供了将图节点定义的核方法扩展到较大的网络的手段。我们证明,GRF的计算承认一个令人尴尬的简单分布式算法,如果考虑的图需要在几个机器之间分开,它可以被应用。我们还引入了一种(仍不偏见的)GRF的蒙特卡罗变量,q-GRF,它依靠所谓的增强随机行走,可以用于优化GRF的变量。作为副产品,我们获得了一种新的方法来解决某些类的线性方程,用正交和对称矩阵。

**[Paper URL](https://proceedings.mlr.press/v202/choromanski23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/choromanski23a/choromanski23a.pdf)** 

# Efficient Graph Field Integrators Meet Point Clouds
**题目:** 高效的图形场集成器满足点云

**作者:** Krzysztof Marcin Choromanski, Arijit Sehanobish, Han Lin, Yunfan Zhao, Eli Berger, Tetiana Parshakova, Alvin Pan, David Watkins, Tianyi Zhang, Valerii Likhosherstov, Somnath Basu Roy Chowdhury, Kumar Avinava Dubey, Deepali Jain, Tamas Sarlos, Snigdha Chaturvedi, Adrian Weller

**Abstract:** We present two new classes of algorithms for efficient field integration on graphs encoding point cloud data. The first class, $\mathrm{SeparatorFactorization}$ (SF), leverages the bounded genus of point cloud mesh graphs, while the second class, $\mathrm{RFDiffusion}$ (RFD), uses popular $\epsilon$-nearest-neighbor graph representations for point clouds. Both can be viewed as providing the functionality of Fast Multipole Methods (FMMs), which have had a tremendous impact on efficient integration, but for non-Euclidean spaces. We focus on geometries induced by distributions of walk lengths between points (e.g. shortest-path distance). We provide an extensive theoretical analysis of our algorithms, obtaining new results in structural graph theory as a byproduct. We also perform exhaustive empirical evaluation, including on-surface interpolation for rigid and deformable objects (in particular for mesh-dynamics modeling) as well as Wasserstein distance computations for point clouds, including the Gromov-Wasserstein variant.

**摘要:** 我们提出了两个新的基于点云数据编码图的有效场域集成算法。第一类,$\mathrm{SeparatorFactorization}$ (SF),利用点云网格的界限类别,而第二类,$\mathrm{RFDiffusion}$ (RFD),则使用流行的$\epsilon$-nearest-neighbor graph representations for point clouds。这两个类都可以视为提供快速多极方法(FMM)的功能,它们对有效集成产生了巨大的影响,但对于非欧氏空间。同时,我们还进行了深入的实证评价,包括对固体和变形物体(特别是网格动力学模型)的表面插值,以及对点云的Waterstein距离计算,包括Gromov-Wasserstein变量。

**[Paper URL](https://proceedings.mlr.press/v202/choromanski23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/choromanski23b/choromanski23b.pdf)** 

# ContraBAR: Contrastive Bayes-Adaptive Deep RL
**题目:**  KontraBAR: Kontrastive Bayes-Adaptive Deep RL

**作者:** Era Choshen, Aviv Tamar

**Abstract:** In meta reinforcement learning (meta RL), an agent seeks a Bayes-optimal policy – the optimal policy when facing an unknown task that is sampled from some known task distribution. Previous approaches tackled this problem by inferring a $\textit{belief}$ over task parameters, using variational inference methods. Motivated by recent successes of contrastive learning approaches in RL, such as contrastive predictive coding (CPC), we investigate whether contrastive methods can be used for learning Bayes-optimal behavior. We begin by proving that representations learned by CPC are indeed sufficient for Bayes optimality. Based on this observation, we propose a simple meta RL algorithm that uses CPC in lieu of variational belief inference. Our method, $\textit{ContraBAR}$, achieves comparable performance to state-of-the-art in domains with state-based observation and circumvents the computational toll of future observation reconstruction, enabling learning in domains with image-based observations. It can also be combined with image augmentations for domain randomization and used seamlessly in both online and offline meta RL settings.

**摘要:** 在元增强学习(meta RL)中,一个代理人寻求贝伊斯-最佳策略 — — 在面对一个未知任务时最佳策略,该策略是从某些已知任务分布中采样的。以前的方法通过推导$\textit{belief}$在任务参数上,使用变量推导方法解决了这个问题。我们的方法,$\textit{ContraBAR}$,在基于状态观测的领域实现与最新技术相比的性能,并避免了未来观测重建的计算成本,使基于图像观测的领域能够进行学习。它也可以与领域随机化图像增强相结合,并在在线和非在线的元RL设置中使用。

**[Paper URL](https://proceedings.mlr.press/v202/choshen23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/choshen23a/choshen23a.pdf)** 

# Forget Unlearning: Towards True Data-Deletion in Machine Learning
**题目:** 忘记学习:机器学习中的真数据删除

**作者:** Rishav Chourasia, Neil Shah

**Abstract:** Unlearning algorithms aim to remove deleted data’s influence from trained models at a cost lower than full retraining. However, prior guarantees of unlearning in literature are flawed and don’t protect the privacy of deleted records. We show that when people delete their data as a function of published models, records in a database become interdependent. So, even retraining a fresh model after deletion of a record doesn’t ensure its privacy. Secondly, unlearning algorithms that cache partial computations to speed up the processing can leak deleted information over a series of releases, violating the privacy of deleted records in the long run. To address these, we propose a sound deletion guarantee and show that ensuring the privacy of existing records is necessary for the privacy of deleted records. Under this notion, we propose an optimal, computationally efficient, and sound machine unlearning algorithm based on noisy gradient descent.

**摘要:** 非学习算法的目的在于从训练模型中除去删除的数据的影响,以比完全重新训练更低的成本。然而,在文献中未学习的事先保证有缺陷,并不能保护删除记录的隐私。我们显示,当人们删除其数据作为出版模型的函数时,数据库中的记录会相互依存。因此,即使重新训练一个记录的删除后的新模型也无法确保其隐私。

**[Paper URL](https://proceedings.mlr.press/v202/chourasia23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chourasia23a/chourasia23a.pdf)** 

# Patch-level Routing in Mixture-of-Experts is Provably Sample-efficient for Convolutional Neural Networks
**题目:** 混合专家的 Patch-level路由是可信的变形神经网络的实例效率

**作者:** Mohammed Nowaz Rabbani Chowdhury, Shuai Zhang, Meng Wang, Sijia Liu, Pin-Yu Chen

**Abstract:** In deep learning, mixture-of-experts (MoE) activates one or few experts (sub-networks) on a per-sample or per-token basis, resulting in significant computation reduction. The recently proposed patch-level routing in MoE (pMoE) divides each input into $n$ patches (or tokens) and sends $l$ patches ($l\ll n$) to each expert through prioritized routing. pMoE has demonstrated great empirical success in reducing training and inference costs while maintaining test accuracy. However, the theoretical explanation of pMoE and the general MoE remains elusive. Focusing on a supervised classification task using a mixture of two-layer convolutional neural networks (CNNs), we show for the first time that pMoE provably reduces the required number of training samples to achieve desirable generalization (referred to as the sample complexity) by a factor in the polynomial order of $n/l$, and outperforms its single-expert counterpart of the same or even larger capacity. The advantage results from the discriminative routing property, which is justified in both theory and practice that pMoE routers can filter label-irrelevant patches and route similar class-discriminative patches to the same expert. Our experimental results on MNIST, CIFAR-10, and CelebA support our theoretical findings on pMoE’s generalization and show that pMoE can avoid learning spurious correlations.

**摘要:** 在深层学习中,混合专家(MoE)在每个样本或每个token的基础上激活一个或少数专家(子网络),从而大大减少计算量。最近在MoE中提议的 Patch-level routing(pMoE)将每个输入分成$n$ Patches(或token)和通过优先 routing发送$l$ Patches($l\ll n$)给每个专家。 pMoE在降低训练和推理成本的同时保持测试准确性方面表现出了巨大的经验成功。在理论上和实践上,pMoE路由器可以筛选标签不相关的补丁,并向同一专家发送类似类别歧视性补丁。我们对MNIST、CIFAR-10和CelebA的实验结果支持了pMoE的一般化理论发现,表明pMoE可以避免学习伪相关性。

**[Paper URL](https://proceedings.mlr.press/v202/chowdhury23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chowdhury23a/chowdhury23a.pdf)** 

# What do CNNs Learn in the First Layer and Why? A Linear Systems Perspective
**题目:** 第一层CNN学习的是什么,为什么?一个线性系统视角

**作者:** Rhea Chowers, Yair Weiss

**Abstract:** It has previously been reported that the representation that is learned in the first layer of deep Convolutional Neural Networks (CNNs) is highly consistent across initializations and architectures. In this work, we quantify this consistency by considering the first layer as a filter bank and measuring its energy distribution. We find that the energy distribution is very different from that of the initial weights and is remarkably consistent across random initializations, datasets, architectures and even when the CNNs are trained with random labels. In order to explain this consistency, we derive an analytical formula for the energy profile of linear CNNs and show that this profile is mostly dictated by the second order statistics of image patches in the training set and it will approach a whitening transformation when the number of iterations goes to infinity. Finally, we show that this formula for linear CNNs also gives an excellent fit for the energy profiles learned by commonly used nonlinear CNNs such as ResNet and VGG, and that the first layer of these CNNs indeed performs approximate whitening of their inputs.

**摘要:** 先前曾报道,在深度进化神经网络(CNNs)的第一个层中所学习的表示具有高度一致性,在初始化和架构中,我们通过考虑第一层为滤波器和测量其能量分布来量化这一一致性。我们发现,能量分布与初始权重非常不同,并且在随机初始化、数据集、架构中非常一致,甚至在CNN被随机标签训练时也是如此。为了解释这一一致性,我们导出了线性CNN的能量 профил的分析公式,并显示该 профил主要由训练集中的图像补丁的第二阶统计量决定,并且当迭代数达到无限时,它将接近白化变换。最后,我们证明了线性CNN的这个公式对于通常使用的非线性CNN,如ResNet和VGG所学习的能量特性也有很好的适应性,并且这些CNN的第一个层实际上对它们的输入进行了近似的白化。

**[Paper URL](https://proceedings.mlr.press/v202/chowers23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chowers23a/chowers23a.pdf)** 

# Unifying Molecular and Textual Representations via Multi-task Language Modelling
**题目:** 通过多任务语言建模统一分子和文本表示

**作者:** Dimitrios Christofidellis, Giorgio Giannone, Jannis Born, Ole Winther, Teodoro Laino, Matteo Manica

**Abstract:** The recent advances in neural language models have also been successfully applied to the field of chemistry, offering generative solutions for classical problems in molecular design and synthesis planning. These new methods have the potential to fuel a new era of data-driven automation in scientific discovery. However, specialized models are still typically required for each task, leading to the need for problem-specific fine-tuning and neglecting task interrelations. The main obstacle in this field is the lack of a unified representation between natural language and chemical representations, complicating and limiting human-machine interaction. Here, we propose the first multi-domain, multi-task language model that can solve a wide range of tasks in both the chemical and natural language domains. Our model can handle chemical and natural language concurrently, without requiring expensive pre-training on single domains or task-specific models. Interestingly, sharing weights across domains remarkably improves our model when benchmarked against state-of-the-art baselines on single-domain and cross-domain tasks. In particular, sharing information across domains and tasks gives rise to large improvements in cross-domain tasks, the magnitude of which increase with scale, as measured by more than a dozen of relevant metrics. Our work suggests that such models can robustly and efficiently accelerate discovery in physical sciences by superseding problem-specific fine-tuning and enhancing human-model interactions.

**摘要:** 神经语言模型的近期发展也成功地应用于化学领域,为分子设计和合成规划中的经典问题提供生成性解决方案。这些新方法有潜力为科学发现中的数据驱动自动化的新时代提供动力。然而,对于每个任务仍然需要专门的模型,导致问题特有的微调和忽略任务相互关系的需要。在这个领域的主要障碍是自然语言和化学语言之间缺乏统一的表示,使人机交互复杂化和限制。有趣的是,在对单域和跨域任务的最先进的基线进行比较时,分担权重显著改善了我们的模型。 特别是,分担跨域和任务的信息导致跨域任务的巨大改进,其规模随着规模的增加,这由超过十多个相关指标衡量。

**[Paper URL](https://proceedings.mlr.press/v202/christofidellis23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/christofidellis23a/christofidellis23a.pdf)** 

# Wasserstein Barycenter Matching for Graph Size Generalization of Message Passing Neural Networks
**题目:** WassersteinBarycenter图形大小匹配信息传递神经网络的一般化

**作者:** Xu Chu, Yujie Jin, Xin Wang, Shanghang Zhang, Yasha Wang, Wenwu Zhu, Hong Mei

**Abstract:** Graph size generalization is hard for Message passing neural networks (MPNNs). The graph-level classification performance of MPNNs degrades across various graph sizes. Recently, theoretical studies reveal that a slow uncontrollable convergence rate w.r.t. graph size could adversely affect the size generalization. To address the uncontrollable convergence rate caused by correlations across nodes in the underlying dimensional signal-generating space, we propose to use Wasserstein barycenters as graph-level consensus to combat node-level correlations. Methodologically, we propose a Wasserstein barycenter matching (WBM) layer that represents an input graph by Wasserstein distances between its MPNN-filtered node embeddings versus some learned class-wise barycenters. Theoretically, we show that the convergence rate of an MPNN with a WBM layer is controllable and independent to the dimensionality of the signal-generating space. Thus MPNNs with WBM layers are less susceptible to slow uncontrollable convergence rate and size variations. Empirically, the WBM layer improves the size generalization over vanilla MPNNs with different backbones (e.g., GCN, GIN, and PNA) significantly on real-world graph datasets.

**摘要:** 图形大小的一般化对于传递信息的神经网络(MPNN)是困难的,MPNN的图形级别分类性能在不同图形大小上有所下降。最近的理论研究表明,图形大小的缓慢无法控制的收敛率会对大小的一般化产生不利影响。为了解决基于维度的信号生成空间中各节点之间的相关性所引起的无法控制的收敛率,我们建议使用水德斯泰因的巴里中心作为图形级别共识来对抗节点级相关性。因此,带WBM层的MPNN比无法控制的收敛速度和大小变化更小,因此,WBM层对不同骨干(例如GCN、GIN和PNA)的瓦尼拉MPNN比实际图形数据集的大小一般化有显著的改善。

**[Paper URL](https://proceedings.mlr.press/v202/chu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chu23a/chu23a.pdf)** 

# Shape-Guided Dual-Memory Learning for 3D Anomaly Detection
**题目:** 3D异常检测的形状指导双记忆学习

**作者:** Yu-Min Chu, Chieh Liu, Ting-I Hsieh, Hwann-Tzong Chen, Tyng-Luh Liu

**Abstract:** We present a shape-guided expert-learning framework to tackle the problem of unsupervised 3D anomaly detection. Our method is established on the effectiveness of two specialized expert models and their synergy to localize anomalous regions from color and shape modalities. The first expert utilizes geometric information to probe 3D structural anomalies by modeling the implicit distance fields around local shapes. The second expert considers the 2D RGB features associated with the first expert to identify color appearance irregularities on the local shapes. We use the two experts to build the dual memory banks from the anomaly-free training samples and perform shape-guided inference to pinpoint the defects in the testing samples. Owing to the per-point 3D representation and the effective fusion scheme of complementary modalities, our method efficiently achieves state-of-the-art performance on the MVTec 3D-AD dataset with better recall and lower false positive rates, as preferred in real applications.

**摘要:** 我们提出了一种以形状为指导的专家学习框架,以解决无监督的3D异常检测问题。我们的方法建立在两个专门专家模型的有效性及其协同作用上,以定位颜色和形状模式下的异常区域。第一专家利用几何信息,通过对局部形状周围隐形距离场的建模,对3D结构异常进行研究。第二专家考虑与第一专家相关的2D RGB特征,以确定局部形状的颜色外形不规则。我们利用这两个专家从无异常训练样本构建双 memory banks,并以形状为指导的推断来确定测试样本中的缺陷。由于每个点的3D表示和互补模态的有效融合方案,我们的方法有效地实现了MVTec3D-AD数据集的最先进的性能,具有更好的回ruf和较低的假正率,如在实际应用中所偏好。

**[Paper URL](https://proceedings.mlr.press/v202/chu23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chu23b/chu23b.pdf)** 

# Multiply Robust Off-policy Evaluation and Learning under Truncation by Death
**题目:** 以死亡为限的稳固非政策评估和学习

**作者:** Jianing Chu, Shu Yang, Wenbin Lu

**Abstract:** Typical off-policy evaluation (OPE) and off-policy learning (OPL) are not well-defined problems under "truncation by death", where the outcome of interest is not defined after some events, such as death. The standard OPE no longer yields consistent estimators, and the standard OPL results in suboptimal policies. In this paper, we formulate OPE and OPL using principal stratification under "truncation by death". We propose a survivor value function for a subpopulation whose outcomes are always defined regardless of treatment conditions. We establish a novel identification strategy under principal ignorability, and derive the semiparametric efficiency bound of an OPE estimator. Then, we propose multiply robust estimators for OPE and OPL. We show that the proposed estimators are consistent and asymptotically normal even with flexible semi/nonparametric models for nuisance functions approximation. Moreover, under mild rate conditions of nuisance functions approximation, the estimators achieve the semiparametric efficiency bound. Finally, we conduct experiments to demonstrate the empirical performance of the proposed estimators.

**摘要:** 典型的非政策评价(OPE)和非政策学习(OPL)在“死亡突击”下并不明确问题,在某些事件之后,例如死亡,利益的结果没有定义。标准OPE不再产生一致的估计数,标准OPL在亚最佳政策中产生结果。在本文中,我们用“死亡突击”下的主要分层化来拟定OPE和OPL。我们提出了一个关于处理条件的 survival value function,并根据主要忽略性建立新的识别策略,并导出一个OPE估计数的半参数效率界限。然后,我们提出了对OPE和OPL的强有力估计数的乘法。此外,在噪声函数近似的温速条件下,估计器实现了半参数效率约束。最后,我们进行了实验,证明了拟议的估计器的实证性能。

**[Paper URL](https://proceedings.mlr.press/v202/chu23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chu23c/chu23c.pdf)** 

# InfoOT: Information Maximizing Optimal Transport
**题目:** InfoOT:信息最大化最佳运输

**作者:** Ching-Yao Chuang, Stefanie Jegelka, David Alvarez-Melis

**Abstract:** Optimal transport aligns samples across distributions by minimizing the transportation cost between them, e.g., the geometric distances. Yet, it ignores coherence structure in the data such as clusters, does not handle outliers well, and cannot integrate new data points. To address these drawbacks, we propose InfoOT, an information-theoretic extension of optimal transport that maximizes the mutual information between domains while minimizing geometric distances. The resulting objective can still be formulated as a (generalized) optimal transport problem, and can be efficiently solved by projected gradient descent. This formulation yields a new projection method that is robust to outliers and generalizes to unseen samples. Empirically, InfoOT improves the quality of alignments across benchmarks in domain adaptation, cross-domain retrieval, and single-cell alignment.

**摘要:** 优化运输通过最小化它们之间的运输成本,例如几何距离,将分布中的样品排列为最优。然而,它忽略数据中的连贯结构,例如集群,不能很好地处理异常,并不能集成新的数据点。为了解决这些缺点,我们提出了InfoOT,一种优化运输信息理论扩展,它在最小化几何距离的同时,最大化域间的相互信息。

**[Paper URL](https://proceedings.mlr.press/v202/chuang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chuang23a/chuang23a.pdf)** 

# A Toy Model of Universality: Reverse Engineering how Networks Learn Group Operations
**题目:** 通用性的玩具模型:反向工程,网络如何学习群体操作

**作者:** Bilal Chughtai, Lawrence Chan, Neel Nanda

**Abstract:** Universality is a key hypothesis in mechanistic interpretability – that different models learn similar features and circuits when trained on similar tasks. In this work, we study the universality hypothesis by examining how small networks learn to implement group compositions. We present a novel algorithm by which neural networks may implement composition for any finite group via mathematical representation theory. We then show that these networks consistently learn this algorithm by reverse engineering model logits and weights, and confirm our understanding using ablations. By studying networks trained on various groups and architectures, we find mixed evidence for universality: using our algorithm, we can completely characterize the family of circuits and features that networks learn on this task, but for a given network the precise circuits learned – as well as the order they develop – are arbitrary.

**摘要:** 通用性是机械解释能力的一个关键假设,即不同模型在相似任务中学习相似特征和电路。本文研究了小网络如何实现群组结构的通用性假设。我们提出了一种新的算法,通过数学表示理论,神经网络可以实现任意有限群组结构的构造。

**[Paper URL](https://proceedings.mlr.press/v202/chughtai23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/chughtai23a/chughtai23a.pdf)** 

# Distribution Free Prediction Sets for Node Classification
**题目:** 节点分类的分布式自由预测集

**作者:** Jase Clarkson

**Abstract:** Graph Neural Networks (GNNs) are able to achieve high classification accuracy on many important real world datasets, but provide no rigorous notion of predictive uncertainty. Quantifying the confidence of GNN models is difficult due to the dependence between datapoints induced by the graph structure. We leverage recent advances in conformal prediction to construct prediction sets for node classification in inductive learning scenarios. We do this by taking an existing approach for conformal classification that relies on exchangeable data and modifying it by appropriately weighting the conformal scores to reflect the network structure. We show through experiments on standard benchmark datasets using popular GNN models that our approach provides tighter and better calibrated prediction sets than a naive application of conformal prediction.

**摘要:** 图神经网络(GNN)能够在许多重要的现实世界数据集中实现高分类精度,但不能提供预测不确定性的严格概念。GNN模型的定量化是由于图结构所诱导的数据点之间的依赖性而困难的。我们利用近来对应预测的进步来构建对应学习场景中的节点分类的预测集。我们通过采取一种基于可交换数据的对应分类的现有方法,并通过适当权重对应分数来修改它,以反映网络结构。

**[Paper URL](https://proceedings.mlr.press/v202/clarkson23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/clarkson23a/clarkson23a.pdf)** 

# Sequential Strategic Screening
**题目:** 连续战略筛选

**作者:** Lee Cohen, Saeed Sharifi -Malvajerdi, Kevin Stangl, Ali Vakilian, Juba Ziani

**Abstract:** We initiate the study of strategic behavior in screening processes with multiple classifiers. We focus on two contrasting settings: a "conjunctive” setting in which an individual must satisfy all classifiers simultaneously, and a sequential setting in which an individual to succeed must satisfy classifiers one at a time. In other words, we introduce the combination of strategic classificationwith screening processes. We show that sequential screening pipelines exhibit new and surprising behavior where individuals can exploit the sequential ordering of the tests to "zig-zag” between classifiers without having to simultaneously satisfy all of them. We demonstrate an individual can obtain a positive outcome using a limited manipulation budget even when far from the intersection of the positive regions of every classifier. Finally, we consider a learner whose goal is to design a sequential screening process that is robust to such manipulations, and provide a construction for the learner that optimizes a natural objective.

**摘要:** 本文着手对多个分类器的筛选过程中战略行为进行研究,重点研究两个不同的设置:一个“合并”设置,即一个个体必须同时满足所有分类器,一个连续设置,即一个成功者必须一次满足分类器。换句话说,我们引入了战略分类与筛选过程的结合。最后,我们考虑了一个学习者,其目标是设计一个对此类操作具有鲁棒性的连续筛选过程,并为学习者提供一种优化自然目标的结构。

**[Paper URL](https://proceedings.mlr.press/v202/cohen23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cohen23a/cohen23a.pdf)** 

# Few-Sample Feature Selection via Feature Manifold Learning
**题目:** 通过特征模式学习的少数样品特征选择

**作者:** David Cohen, Tal Shnitzer, Yuval Kluger, Ronen Talmon

**Abstract:** In this paper, we present a new method for few-sample supervised feature selection (FS). Our method first learns the manifold of the feature space of each class using kernels capturing multi-feature associations. Then, based on Riemannian geometry, a composite kernel is computed, extracting the differences between the learned feature associations. Finally, a FS score based on spectral analysis is proposed. Considering multi-feature associations makes our method multivariate by design. This in turn allows for the extraction of the hidden manifold underlying the features and avoids overfitting, facilitating few-sample FS. We showcase the efficacy of our method on illustrative examples and several benchmarks, where our method demonstrates higher accuracy in selecting the informative features compared to competing methods. In addition, we show that our FS leads to improved classification and better generalization when applied to test data.

**摘要:** 本文提出了一种基于黎曼几何学的复合核,提取学习特征关联之间的差异。最后,提出了基于光谱分析的FS分数。考虑到多特征关联,我们的方法通过设计进行多变形,从而能够提取特征的基本隐藏的多变形,避免过滤,便利了少数样本FS。我们展示了该方法在示例和几个基准上的应用效果,表明该方法在选择信息特征时比竞争方法更准确。此外,我们证明该方法在应用于测试数据时能提高分类和推广。

**[Paper URL](https://proceedings.mlr.press/v202/cohen23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cohen23b/cohen23b.pdf)** 

# Spatial Implicit Neural Representations for Global-Scale Species Mapping
**题目:** 全球范围物种映射空间隐性神经表现

**作者:** Elijah Cole, Grant Van Horn, Christian Lange, Alexander Shepard, Patrick Leary, Pietro Perona, Scott Loarie, Oisin Mac Aodha

**Abstract:** Estimating the geographical range of a species from sparse observations is a challenging and important geospatial prediction problem. Given a set of locations where a species has been observed, the goal is to build a model to predict whether the species is present or absent at any location. This problem has a long history in ecology, but traditional methods struggle to take advantage of emerging large-scale crowdsourced datasets which can include tens of millions of records for hundreds of thousands of species. In this work, we use Spatial Implicit Neural Representations (SINRs) to jointly estimate the geographical range of 47k species simultaneously. We find that our approach scales gracefully, making increasingly better predictions as we increase the number of species and the amount of data per species when training. To make this problem accessible to machine learning researchers, we provide four new benchmarks that measure different aspects of species range estimation and spatial representation learning. Using these benchmarks, we demonstrate that noisy and biased crowdsourced data can be combined with implicit neural representations to approximate expert-developed range maps for many species.

**摘要:** 从稀疏的观测中估算物种的地理范围是一项具有挑战性和重要的地理空间预测问题。鉴于物种被观察到的地点,目标是建立一种预测物种在任何地点是否存在或不在的模型。这一问题在生态学中有着悠久的历史,但传统的方法难以利用新兴大规模的 crowdsourced数据集,这些数据集可以包含数以万计的记录,包括数以万计的数以万计的物种。在这项工作中,我们使用空间隐形神经表现(SINRs)共同估算47k物种的地理范围。为了使机器学习研究者能够利用这一问题,我们提供了四个新的指标,以衡量物种范围估计和空间表示学习的各个方面。使用这些指标,我们证明了有噪音和偏见的 crowdsourced数据可以与隐性神经表示相结合,以近似许多物种专家开发的范围地图。

**[Paper URL](https://proceedings.mlr.press/v202/cole23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cole23a/cole23a.pdf)** 

# K-SHAP: Policy Clustering Algorithm for Anonymous Multi-Agent State-Action Pairs
**题目:** K-SHAP:匿名多代理国家行动对策聚类算法

**作者:** Andrea Coletta, Svitlana Vyetrenko, Tucker Balch

**Abstract:** Learning agent behaviors from observational data has shown to improve our understanding of their decision-making processes, advancing our ability to explain their interactions with the environment and other agents. While multiple learning techniques have been proposed in the literature, there is one particular setting that has not been explored yet: multi agent systems where agent identities remain anonymous. For instance, in financial markets labeled data that identifies market participant strategies is typically proprietary, and only the anonymous state-action pairs that result from the interaction of multiple market participants are publicly available. As a result, sequences of agent actions are not observable, restricting the applicability of existing work. In this paper, we propose a Policy Clustering algorithm, called K-SHAP, that learns to group anonymous state-action pairs according to the agent policies. We frame the problem as an Imitation Learning (IL) task, and we learn a world-policy able to mimic all the agent behaviors upon different environmental states. We leverage the world-policy to explain each anonymous observation through an additive feature attribution method called SHAP (SHapley Additive exPlanations). Finally, by clustering the explanations we show that we are able to identify different agent policies and group observations accordingly. We evaluate our approach on simulated synthetic market data and a real-world financial dataset. We show that our proposal significantly and consistently outperforms the existing methods, identifying different agent strategies.

**摘要:** 通过观察数据,学习代理行为有助于提高我们对他们决策过程的理解,从而提高我们对环境和其他代理行为的解释能力。虽然在文献中提出了多种学习技术,但仍有一个具体设置尚未研究:多代理系统,其中代理身份保持匿名。例如,在金融市场中,标记数据识别市场参与者策略通常是专属的,只有来自多个市场参与者相互作用的结果的匿名状态行为对是公开的。因此,代理行为的序列不能被观察,限制了现有的工作适用性。我们把问题定义为仿真学习(IL)任务,并学习一个能够模仿不同环境状态的所有代理行为的世界政策。我们利用世界政策来解释每个匿名观察,通过添加特征归纳方法,称为SHAP(SHapley Additive exPlanations)。最后,通过聚类解释,我们证明我们能够根据不同代理政策和群体观察来识别不同的代理行为。

**[Paper URL](https://proceedings.mlr.press/v202/coletta23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/coletta23a/coletta23a.pdf)** 

# Inferring Relational Potentials in Interacting Systems
**题目:** 影响交互系统关系潜力

**作者:** Armand Comas, Yilun Du, Christian Fernandez Lopez, Sandesh Ghimire, Mario Sznaier, Joshua B. Tenenbaum, Octavia Camps

**Abstract:** Systems consisting of interacting agents are prevalent in the world, ranging from dynamical systems in physics to complex biological networks. To build systems which can interact robustly in the real world, it is thus important to be able to infer the precise interactions governing such systems. Existing approaches typically discover such interactions by explicitly modeling the feed-forward dynamics of the trajectories. In this work, we propose Neural Interaction Inference with Potentials (NIIP) as an alternative approach to discover such interactions that enables greater flexibility in trajectory modeling: it discovers a set of relational potentials, represented as energy functions, which when minimized reconstruct the original trajectory. NIIP assigns low energy to the subset of trajectories which respect the relational constraints observed. We illustrate that with these representations NIIP displays unique capabilities in test-time. First, it allows trajectory manipulation, such as interchanging interaction types across separately trained models, as well as trajectory forecasting. Additionally, it allows adding external hand-crafted potentials at test-time. Finally, NIIP enables the detection of out-of-distribution samples and anomalies without explicit training.

**摘要:** 从物理学中的动态系统到复杂的生物网络,相互作用主体构成的系统在世界上普遍存在。为了构建能够在现实世界中相互作用的系统,必须能够推断控制这些系统的具体相互作用。现有的方法通常通过明确的建模轨迹的反馈向后动力学来发现这种相互作用。首先,它允许 trajectory manipulation, 例如在单独训练的模型之间交换相互作用类型,以及 trajectory forecasting 。 此外,它允许在测试时添加外部手工制造的潜力。

**[Paper URL](https://proceedings.mlr.press/v202/comas23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/comas23a/comas23a.pdf)** 

# Task-specific experimental design for treatment effect estimation
**题目:** 特定任务的治疗效果估计实验设计

**作者:** Bethany Connolly, Kim Moore, Tobias Schwedes, Alexander Adam, Gary Willis, Ilya Feige, Christopher Frye

**Abstract:** Understanding causality should be a core requirement of any attempt to build real impact through AI. Due to the inherent unobservability of counterfactuals, large randomised trials (RCTs) are the standard for causal inference. But large experiments are generically expensive, and randomisation carries its own costs, e.g. when suboptimal decisions are trialed. Recent work has proposed more sample-efficient alternatives to RCTs, but these are not adaptable to the downstream application for which the causal effect is sought. In this work, we develop a task-specific approach to experimental design and derive sampling strategies customised to particular downstream applications. Across a range of important tasks, real-world datasets, and sample sizes, our method outperforms other benchmarks, e.g. requiring an order-of-magnitude less data to match RCT performance on targeted marketing tasks.

**摘要:** 由于反事实的不可观察性,大随机试验(RCTs)是因果推理的标准。但大实验是 generically expensive, and randomisation carries its own costs, e.g. when suboptimal decisions are trialed. 最近的工作提出了比RCTs更高效的样本替代方案,但这些方案不能适应下游应用的因果效果。在这个工作中,我们开发了针对特定下游应用定制的实验设计和抽样策略的任务特有方法。在一系列重要的任务、真实世界数据集和样本尺寸方面,我们的方法超过了其他标准,例如需要少量数据以配合目标营销任务的RCT性能。

**[Paper URL](https://proceedings.mlr.press/v202/connolly23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/connolly23a/connolly23a.pdf)** 

# A Mathematical Model for Curriculum Learning for Parities
**题目:** 分数课程学习的数学模型

**作者:** Elisabetta Cornacchia, Elchanan Mossel

**Abstract:** Curriculum learning (CL)- training using samples that are generated and presented in a meaningful order - was introduced in the machine learning context around a decade ago. While CL has been extensively used and analysed empirically, there has been very little mathematical justification for its advantages. We introduce a CL model for learning the class of k-parities on d bits of a binary string with a neural network trained by stochastic gradient descent (SGD). We show that a wise choice of training examples, involving two or more product distributions, allows to reduce significantly the computational cost of learning this class of functions, compared to learning under the uniform distribution. We conduct experiments to support our analysis. Furthermore, we show that for another class of functions - namely the ‘Hamming mixtures’ - CL strategies involving a bounded number of product distributions are not beneficial.

**摘要:** 课程学习(CL)-使用生成和呈现有意义的样本的培训-大约十年前被引入了机器学习环境中。虽然CL被广泛应用和实证分析,但其优点的数学合理性很少。我们介绍了一个CL模型,用于学习二进制字符串的k比特类,由随机梯度下降(SGD)训练的神经网络组成的二进制字符串的d比特类。我们表明,涉及两个或多个产品分布的明智选择可以大大降低学习该类函数的计算成本,与在统一分布下学习相比。我们进行实验以支持我们的分析。此外,我们证明,对于另一个类函数--即“哈mming混合物”--涉及有限数量的产品分布的CL策略并不有益。

**[Paper URL](https://proceedings.mlr.press/v202/cornacchia23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cornacchia23a/cornacchia23a.pdf)** 

# Learning to Maximize Mutual Information for Dynamic Feature Selection
**题目:** 学习最大化动态特征选择的相互信息

**作者:** Ian Connick Covert, Wei Qiu, Mingyu Lu, Na Yoon Kim, Nathan J White, Su-In Lee

**Abstract:** Feature selection helps reduce data acquisition costs in ML, but the standard approach is to train models with static feature subsets. Here, we consider the dynamic feature selection (DFS) problem where a model sequentially queries features based on the presently available information. DFS is often addressed with reinforcement learning, but we explore a simpler approach of greedily selecting features based on their conditional mutual information. This method is theoretically appealing but requires oracle access to the data distribution, so we develop a learning approach based on amortized optimization. The proposed method is shown to recover the greedy policy when trained to optimality, and it outperforms numerous existing feature selection methods in our experiments, thus validating it as a simple but powerful approach for this problem.

**摘要:** 特征选择在ML中有助于降低数据采集成本,但标准方法是训练模型以静态特征子集。这里,我们考虑动态特征选择(DFS)问题,其中模型顺序查询基于当前可用的信息的特征。DFS经常与强化学习有关,但我们探索基于条件相互信息的贪婪选择特征的更简单的方法。

**[Paper URL](https://proceedings.mlr.press/v202/covert23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/covert23a/covert23a.pdf)** 

# Rethinking Weak Supervision in Helping Contrastive Learning
**题目:** 重新思考弱点监督在帮助反向学习方面

**作者:** Jingyi Cui, Weiran Huang, Yifei Wang, Yisen Wang

**Abstract:** Contrastive learning has shown outstanding performances in both supervised and unsupervised learning, and has recently been introduced to solve weakly supervised learning problems such as semi-supervised learning and noisy label learning. Despite the empirical evidence showing that semi-supervised labels improve the representations of contrastive learning, it remains unknown if noisy supervised information can be directly used in training instead of after manual denoising. Therefore, to explore the mechanical differences between semi-supervised and noisy-labeled information in helping contrastive learning, we establish a unified theoretical framework of contrastive learning under weak supervision. Specifically, we investigate the most intuitive paradigm of jointly training supervised and unsupervised contrastive losses. By translating the weakly supervised information into a similarity graph under the framework of spectral clustering based on the posterior probability of weak labels, we establish the downstream classification error bound. We prove that semi-supervised labels improve the downstream error bound whereas noisy labels have limited effects under such a paradigm. Our theoretical findings here provide new insights for the community to rethink the role of weak supervision in helping contrastive learning.

**摘要:** 对照学习在监督和非监督的学习中表现出突出表现,并最近被引入解决弱监督学习问题,例如半监督学习和噪声标签学习。尽管有经验证据表明半监督标签改善对照学习的表现,但仍不清楚是否可以直接使用噪声标签信息在训练中,而不是在手动描述后。因此,为了探讨半监督和噪声标签信息在帮助对照学习中的作用的机械性差异,我们建立了在弱监督下对照学习的统一理论框架。通过基于弱标记后概率的光谱聚类框架,将弱标记信息转化为相似图,建立了下游分类误差约束。我们证明,半监督标记改善下游误差约束,而噪音标记在这样的范式下具有有限的影响。

**[Paper URL](https://proceedings.mlr.press/v202/cui23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cui23a/cui23a.pdf)** 

# Bayes-optimal Learning of Deep Random Networks of Extensive-width
**题目:** 广域深度随机网络的贝斯优化学习

**作者:** Hugo Cui, Florent Krzakala, Lenka Zdeborova

**Abstract:** We consider the problem of learning a target function corresponding to a deep, extensive-width, non-linear neural network with random Gaussian weights. We consider the asymptotic limit where the number of samples, the input dimension and the network width are proportionally large and propose a closed-form expression for the Bayes-optimal test error, for regression and classification tasks. We further compute closed-form expressions for the test errors of ridge regression, kernel and random features regression. We find, in particular, that optimally regularized ridge regression, as well as kernel regression, achieve Bayes-optimal performances, while the logistic loss yields a near-optimal test error for classification. We further show numerically that when the number of samples grows faster than the dimension, ridge and kernel methods become suboptimal, while neural networks achieve test error close to zero from quadratically many samples.

**摘要:** 考虑了与随机高斯权重的深宽非线性神经网络相对应的目标函数的学习问题,考虑了样品数量、输入维度和网络宽度比例较大的渐近限界,并提出了贝伊斯-最佳测试误差、回归和分类任务的闭式表达式,进一步计算了贝伊斯-最佳测试误差、核和随机特征回归的闭式表达式。我们特别发现,优化调整的脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊脊

**[Paper URL](https://proceedings.mlr.press/v202/cui23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cui23b/cui23b.pdf)** 

# A General Representation Learning Framework with Generalization Performance Guarantees
**题目:** 综合性绩效保证的一般代表学习框架

**作者:** Junbiao Cui, Jianqing Liang, Qin Yue, Jiye Liang

**Abstract:** The generalization performance of machine learning methods depends heavily on the quality of data representation. However, existing researches rarely consider representation learning from the perspective of generalization error. In this paper, we prove that generalization error of representation learning function can be estimated effectively by solving two convex optimization problems. Based on it, we propose a general representation learning framework. And then, we apply the proposed framework to two most commonly used nonlinear mapping methods, i.e., kernel based method and deep neural network (DNN), and thus design a kernel selection method and a DNN boosting framework, correspondingly. Finally, extensive experiments verify the effectiveness of the proposed methods.

**摘要:** 机器学习方法的一般化性能很大程度上取决于数据的质量,然而,现有的研究很少从一般化误差的角度考虑表示学习。本文证明,通过解决两个凸优化问题,可以有效地估计表示学习函数的一般化误差。在此基础上,我们提出了一种一般化表示学习框架。然后,我们应用该框架对两种最常用的非线性映射方法,即基于核的方法和深神经网络(DNN),设计相应的核选择方法和DNN增强框架。

**[Paper URL](https://proceedings.mlr.press/v202/cui23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cui23c/cui23c.pdf)** 

# IRNeXt: Rethinking Convolutional Network Design for Image Restoration
**题目:** IRNeXt:对图像恢复的卷积网络设计进行重新思考

**作者:** Yuning Cui, Wenqi Ren, Sining Yang, Xiaochun Cao, Alois Knoll

**Abstract:** We present IRNeXt, a simple yet effective convolutional network architecture for image restoration. Recently, Transformer models have dominated the field of image restoration due to the powerful ability of modeling long-range pixels interactions. In this paper, we excavate the potential of the convolutional neural network (CNN) and show that our CNN-based model can receive comparable or better performance than Transformer models with low computation overhead on several image restoration tasks. By re-examining the characteristics possessed by advanced image restoration algorithms, we discover several key factors leading to the performance improvement of restoration models. This motivates us to develop a novel network for image restoration based on cheap convolution operators. Comprehensive experiments demonstrate that IRNeXt delivers state-of-the-art performance among numerous datasets on a range of image restoration tasks with low computational complexity, including image dehazing, single-image defocus/motion deblurring, image deraining, and image desnowing. https://github.com/c-yn/IRNeXt.

**摘要:** 本文介绍了一种简单而有效的图像恢复网络结构,即IRNeXt。近年来,变形模型由于建模长距离像素相互作用的强大能力,主导了图像恢复领域。本文对变形神经网络(CNN)的潜力进行了挖掘,并表明,基于CNN的模型能够在多个图像恢复任务中获得比变形模型低的计算费用的相等或更好的性能。通过重新研究先进的图像恢复算法所具有的特性,我们发现几个关键因素导致了图像恢复模型的性能提高。综合实验表明,IRNeXt在众多数据集中提供最先进的性能,用于一系列低计算复杂度的图像恢复任务,包括图像调试、单图像调试/运动调试、图像导引和图像调试。 https://github.com/c-yn/IRNeXt。

**[Paper URL](https://proceedings.mlr.press/v202/cui23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cui23d/cui23d.pdf)** 

# Scaling Up Dataset Distillation to ImageNet-1K with Constant Memory
**题目:** 将数据集蒸馏升级到ImageNet-1K,使用恒定存储

**作者:** Justin Cui, Ruochen Wang, Si Si, Cho-Jui Hsieh

**Abstract:** Dataset Distillation is a newly emerging area that aims to distill large datasets into much smaller and highly informative synthetic ones to accelerate training and reduce storage. Among various dataset distillation methods, trajectory-matching-based methods (MTT) have achieved SOTA performance in many tasks, e.g., on CIFAR-10/100. However, due to exorbitant memory consumption when unrolling optimization through SGD steps, MTT fails to scale to large-scale datasets such as ImageNet-1K. Can we scale this SOTA method to ImageNet-1K and does its effectiveness on CIFAR transfer to ImageNet-1K? To answer these questions, we first propose a procedure to exactly compute the unrolled gradient with constant memory complexity, which allows us to scale MTT to ImageNet-1K seamlessly with $\sim 6$x reduction in memory footprint. We further discover that it is challenging for MTT to handle datasets with a large number of classes, and propose a novel soft label assignment that drastically improves its convergence. The resulting algorithm sets new SOTA on ImageNet-1K: we can scale up to 50 IPCs (Image Per Class) on ImageNet-1K on a single GPU (all previous methods can only scale to 2 IPCs on ImageNet-1K), leading to the best accuracy (only 5.9% accuracy drop against full dataset training) while utilizing only 4.2% of the number of data points - an 18.2% absolute gain over prior SOTA.

**摘要:** 数据集蒸馏是一个新出现的领域,旨在将大型数据集蒸馏成较小且具有高度信息性的合成数据集,以加速训练和减少存储量。在各种数据集蒸馏方法中, trajectory-matching-based methods(MTT)在许多任务中,例如CIFAR-10/100中取得了SOTA性能。然而,由于在SGD步骤下展开优化时 memory consumption非常高,MTT无法 scale to large-scale datasets such as ImageNet-1K。我们进一步发现,对于MTT来说,处理大量类别的数据集具有挑战性,并提出了一种新颖的软标签分配,大大改善其收敛性。该算法在ImageNet-1K上设置了新的SOTA:我们可以在ImageNet-1K上的50个IPC(Image Per Class)在单个GPU上(所有以前的方法只能在ImageNet-1K上的2个IPC)进行 scaling,从而达到最佳的精度(完全数据集训练只降低了5.9%的精度),而只使用4.2%的数据点数 - 比以前的SOTA取得18.2%的绝对优势。

**[Paper URL](https://proceedings.mlr.press/v202/cui23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cui23e/cui23e.pdf)** 

# Learning Dynamic Query Combinations for Transformer-based Object Detection and Segmentation
**题目:** 基于变换器的对象检测和分割学习动态查询组合

**作者:** Yiming Cui, Linjie Yang, Haichao Yu

**Abstract:** Transformer-based detection and segmentation methods use a list of learned detection queries to retrieve information from the transformer network and learn to predict the location and category of one specific object from each query. We empirically find that random convex combinations of the learned queries are still good for the corresponding models. We then propose to learn a convex combination with dynamic coefficients based on the high-level semantics of the image. The generated dynamic queries, named as modulated queries, better capture the prior of object locations and categories in the different images. Equipped with our modulated queries, a wide range of DETR-based models achieve consistent and superior performance across multiple tasks (object detection, instance segmentation, panoptic segmentation) and on different benchmarks (MS COCO, CityScapes, YoutubeVIS).

**摘要:** 基于变换器的检测和分割方法使用学习检测查询的列表,从变换器网络中获取信息,并学习预测每个查询中的特定对象的位置和类别。我们实验发现,学习查询的随机凸组合仍然对相应的模型有好处。然后,我们建议学习基于图像的高层次语义的动态系数凸组合。生成的动态查询,称为模块化查询,能够更好地捕捉不同图像中的对象位置和类别的优先次序。

**[Paper URL](https://proceedings.mlr.press/v202/cui23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cui23f/cui23f.pdf)** 

# Adaptive Identification of Populations with Treatment Benefit in Clinical Trials: Machine Learning Challenges and Solutions
**题目:** 临床试验中适应性识别治疗疗效人群:机器学习挑战和解决方案

**作者:** Alicia Curth, Alihan Hüyük, Mihaela Van Der Schaar

**Abstract:** We study the problem of adaptively identifying patient subpopulations that benefit from a given treatment during a confirmatory clinical trial. This type of adaptive clinical trial has been thoroughly studied in biostatistics, but has been allowed only limited adaptivity so far. Here, we aim to relax classical restrictions on such designs and investigate how to incorporate ideas from the recent machine learning literature on adaptive and online experimentation to make trials more flexible and efficient. We find that the unique characteristics of the subpopulation selection problem – most importantly that (i) one is usually interested in finding subpopulations with any treatment benefit (and not necessarily the single subgroup with largest effect) given a limited budget and that (ii) effectiveness only has to be demonstrated across the subpopulation on average – give rise to interesting challenges and new desiderata when designing algorithmic solutions. Building on these findings, we propose AdaGGI and AdaGCPI, two meta-algorithms for subpopulation construction. We empirically investigate their performance across a range of simulation scenarios and derive insights into their (dis)advantages across different settings.

**摘要:** 我们研究了在确认临床试验中适应性识别患者分组群 benefiting from a given treatment的问题。这种适应性临床试验在生物统计学中已经得到深入研究,但迄今为止只允许有限的适应性。在这里,我们的目标是放松对这类设计的经典限制,并研究如何结合最近的机器学习文献关于适应性和在线实验的观念,使试验更加灵活和高效。我们发现分组群选择问题的特点--最重要的是:(i)一个通常对寻找任何治疗利益的分组群感兴趣(而且不一定是最大的单个分组群)在有限的预算下,而(ii)效率只有在分组群中平均显示出来--在设计算法解决方案时产生有趣的挑战和新的愿望。基于这些发现,我们提出了亚群建构的两个元算法,即AdaGGI和AdaGCPI。我们对它们在一系列仿真场景中的表现进行了实证研究,并对它们在不同环境中所具有的优缺点进行了分析。

**[Paper URL](https://proceedings.mlr.press/v202/curth23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/curth23a/curth23a.pdf)** 

# In Search of Insights, Not Magic Bullets: Towards Demystification of the Model Selection Dilemma in Heterogeneous Treatment Effect Estimation
**题目:** 寻找洞察,而不是魔法弹药:对异种治疗效果评价中的模型选择困境的解明

**作者:** Alicia Curth, Mihaela Van Der Schaar

**Abstract:** Personalized treatment effect estimates are often of interest in high-stakes applications – thus, before deploying a model estimating such effects in practice, one needs to be sure that the best candidate from the ever-growing machine learning toolbox for this task was chosen. Unfortunately, due to the absence of counterfactual information in practice, it is usually not possible to rely on standard validation metrics for doing so, leading to a well-known model selection dilemma in the treatment effect estimation literature. While some solutions have recently been investigated, systematic understanding of the strengths and weaknesses of different model selection criteria is still lacking. In this paper, instead of attempting to declare a global ‘winner’, we therefore empirically investigate success- and failure modes of different selection criteria. We highlight that there is a complex interplay between selection strategies, candidate estimators and the data used for comparing them, and provide interesting insights into the relative (dis)advantages of different criteria alongside desiderata for the design of further illuminating empirical studies in this context.

**摘要:** 个人化治疗效果估算往往对高风险应用有兴趣,因此,在实际应用模型估算这种效果之前,必须确保为这项任务选出不断增长的机器学习工具箱中的最佳候选者。不幸的是,由于在实际应用中缺乏反事实信息,因此通常不能依靠标准验证度量来进行,导致治疗效果估算文献中已知的模型选择困境。我们 强调, 选择 战略 、 候选 估计者 和 用于 比较 它们 的 数据 之间 存在 复杂 的 相互 作用, 并 提供 有关 不同 标准 的 相对 ( 不利 ) 利益 的 有趣的 洞察, 并 为 在此 方面 进一步 阐明 实证 研究 的 设计 提供 了 愿望 。

**[Paper URL](https://proceedings.mlr.press/v202/curth23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/curth23b/curth23b.pdf)** 

# Optimal Stochastic Non-smooth Non-convex Optimization through Online-to-Non-convex Conversion
**题目:** 通过在线向非凸转换实现最佳随机非滑非凸优化

**作者:** Ashok Cutkosky, Harsh Mehta, Francesco Orabona

**Abstract:** We present new algorithms for optimizing non-smooth, non-convex stochastic objectives based on a novel analysis technique. This improves the current best-known complexity for finding a $(\delta,\epsilon)$-stationary point from $O(\epsilon^{-4}\delta^{-1})$ stochastic gradient queries to $O(\epsilon^{-3}\delta^{-1})$, which we also show to be optimal. Our primary technique is a reduction from non-smooth non-convex optimization to online learning, after which our results follow from standard regret bounds in online learning. For deterministic and second-order smooth objectives, applying more advanced optimistic online learning techniques enables a new complexity of $O(\epsilon^{-1.5}\delta^{-0.5})$. Our improved non-smooth analysis also immediately recovers all optimal or best-known results for finding $\epsilon$ stationary points of smooth or second-order smooth objectives in both stochastic and deterministic settings.

**摘要:** 基于一种新的分析技术,我们提出了优化非平稳、非凸随机目标的新算法。这改善了当前最常见的复杂性,从$O(\epsilon^{-4}\delta^{-1})$随机梯度查询到$O(\epsilon^{-3}\delta^{-1})$的$(\epsilon^{-3}\delta^{-1})$随机梯度查询,我们还表明它是最优的。我们的主要技术是从非平稳非凸优化到在线学习的减少,然后我们的结果在在线学习中遵循标准的遗憾界限。对于确定性和第二阶滑目标,应用更先进的乐观在线学习技术使$O(\epsilon^{-1.5}\delta^{-0.5})$的新复杂性得以实现。

**[Paper URL](https://proceedings.mlr.press/v202/cutkosky23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cutkosky23a/cutkosky23a.pdf)** 

# Monge, Bregman and Occam: Interpretable Optimal Transport in High-Dimensions with Feature-Sparse Maps
**题目:** 蒙格、布雷格曼和奥卡姆:具有特征粗糙地图的高尺寸可解释的优化运输

**作者:** Marco Cuturi, Michal Klein, Pierre Ablin

**Abstract:** Optimal transport (OT) theory focuses, among all maps $T:\mathbb{R}^d\rightarrow \mathbb{R}^d$ that can morph a probability measure $\mu$ onto another $\nu$, on those that are the “thriftiest”, i.e. such that the average cost $c(x, T(x))$ between $x$ and its image $T(x)$ is as small as possible. Many computational approaches have been proposed to estimate such Monge maps when $c$ is the squared-Euclidean distance, e.g., using entropic maps [Pooladian+2021], or input convex neural networks [Makkuva+2020, Korotin+2020]. We propose a new research direction, that leverages a specific translation invariant cost $c(x, y):=h(x-y)$ inspired by the elastic net. Here, $h:=\tfrac{1}{2}\|\cdot\|_2^2+\tau(\cdot)$, where $\tau$ is a convex function. We highlight a surprising link tying together a generalized entropic map for $h$, Bregman centroids induced by $h$, and the proximal operator of $\tau$. We show how setting $\tau$ to be a sparsity-inducing norm results in the first application of Occam’s razor to transport. These maps yield, mechanically, displacement vectors $\Delta(x):= T(x)-x$ that are sparse, with sparsity patterns that vary depending on $x$. We showcase the ability of our method to estimate meaningful OT maps for high-dimensional single-cell transcription data. We use our methods in the $34000$-d space of gene counts for cells, without using a prior dimensionality reduction, thus retaining the ability to interpret all displacements at the gene level.

**摘要:** 最优传输(OT)理论集中于所有 $T:\mathbb{R}^d\rightarrow \mathbb{R}^d$ 的映射中,可以将概率计量 $\mu$ 变为另一个 $\nu$ 的映射,这些映射是“最经济的”,即平均成本 $c(x, T(x))$ 之间 $x$ 和其图像 $T(x)$ 尽可能小。 许多计算方法已经提议估计这种蒙格映射,当 $c$ 是平方欧几里德距离,例如使用熵映射 [Pooladian+2021] 或输入凸神经网络 [Makkuva+2020, Korotin+2020]。我们展示了如何设置$\tau$作为稀疏诱导规范的结果,在Occam剃刀的第一次应用中进行运输。这些地图产生,机械地,移位向量$\Delta(x):= T(x)-x$是稀疏的,随随$x$而变化的稀疏模式。我们展示了我们方法估计高维单细胞转录数据有意义的OT地图的能力。

**[Paper URL](https://proceedings.mlr.press/v202/cuturi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cuturi23a/cuturi23a.pdf)** 

# From Noisy Fixed-Point Iterations to Private ADMM for Centralized and Federated Learning
**题目:** 从噪音固定点迭代到集中和联合学习的私人ADMM

**作者:** Edwige Cyffers, Aurélien Bellet, Debabrota Basu

**Abstract:** We study differentially private (DP) machine learning algorithms as instances of noisy fixed-point iterations, in order to derive privacy and utility results from this well-studied framework. We show that this new perspective recovers popular private gradient-based methods like DP-SGD and provides a principled way to design and analyze new private optimization algorithms in a flexible manner. Focusing on the widely-used Alternating Directions Method of Multipliers (ADMM) method, we use our general framework derive novel private ADMM algorithms for centralized, federated and fully decentralized learning. We establish strong privacy guarantees for these algorithms, leveraging privacy amplification by iteration and by subsampling. Finally, we provide utility guarantees for the three algorithms using a unified analysis that exploits a recent linear convergence result for noisy fixed-point iterations.

**摘要:** 我们研究了微分的私人(DP)机器学习算法,作为噪声固定点迭代的实例,以便从这个研究良好的框架中提取隐私和实用结果。我们表明,这一新视角能恢复像DP-SGD这样的流行的私人梯度式方法,并提供一种灵活的设计和分析新的私人优化算法的基本方法。我们着重于广泛使用的变向方法(ADMM)方法,使用我们的一般框架提取新的私人ADMM算法,用于集中、联合和完全分散学习。

**[Paper URL](https://proceedings.mlr.press/v202/cyffers23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/cyffers23a/cyffers23a.pdf)** 

# Chameleon: Adapting to Peer Images for Planting Durable Backdoors in Federated Learning
**题目:**  Chameleon:适应同行图像,在联邦学习中规划持久的后门

**作者:** Yanbo Dai, Songze Li

**Abstract:** In a federated learning (FL) system, distributed clients upload their local models to a central server to aggregate into a global model. Malicious clients may plant backdoors into the global model through uploading poisoned local models, causing images with specific patterns to be misclassified into some target labels. Backdoors planted by current attacks are not durable, and vanish quickly once the attackers stop model poisoning. In this paper, we investigate the connection between the durability of FL backdoors and the relationships between benign images and poisoned images (i.e., the images whose labels are flipped to the target label during local training). Specifically, benign images with the original and the target labels of the poisoned images are found to have key effects on backdoor durability. Consequently, we propose a novel attack, Chameleon, which utilizes contrastive learning to further amplify such effects towards a more durable backdoor. Extensive experiments demonstrate that Chameleon significantly extends the backdoor lifespan over baselines by $1.2\times \sim 4\times$, for a wide range of image datasets, backdoor types, and model architectures.

**摘要:** 在联邦学习(FL)系统中,分布式客户端将本地模型上传到中央服务器,并将其汇集到全球模型中。恶意客户端通过上传毒性本地模型将后门植入全球模型,导致具有特定模式的图像被错误分类为某些目标标签。当前攻击 planted backdoors are not durable, and vanish quickly once the attackers stop model poisoning。本文研究了 FL后门的持久性与 benign images and poisoned images (i.e., the images whose labels are flipped to the target label during local training)之间的关系。广泛的实验表明, Chameleon 大大延长了后门的寿命,超过了基线的1.2\times \sim 4\times$,用于广泛的图像数据集、后门类型和模型架构。

**[Paper URL](https://proceedings.mlr.press/v202/dai23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dai23a/dai23a.pdf)** 

# Refined Regret for Adversarial MDPs with Linear Function Approximation
**题目:** 线性函数近似对敌方MDP的改进遗憾

**作者:** Yan Dai, Haipeng Luo, Chen-Yu Wei, Julian Zimmert

**Abstract:** We consider learning in an adversarial Markov Decision Process (MDP) where the loss functions can change arbitrarily over $K$ episodes and the state space can be arbitrarily large. We assume that the Q-function of any policy is linear in some known features, that is, a linear function approximation exists. The best existing regret upper bound for this setting (Luo et al., 2021) is of order $\tilde{\mathcal O}(K^{2/3})$ (omitting all other dependencies), given access to a simulator. This paper provides two algorithms that improve the regret to $\tilde{\mathcal O}(\sqrt K)$ in the same setting. Our first algorithm makes use of a refined analysis of the Follow-the-Regularized-Leader (FTRL) algorithm with the log-barrier regularizer. This analysis allows the loss estimators to be arbitrarily negative and might be of independent interest. Our second algorithm develops a magnitude-reduced loss estimator, further removing the polynomial dependency on the number of actions in the first algorithm and leading to the optimal regret bound (up to logarithmic terms and dependency on the horizon). Moreover, we also extend the first algorithm to simulator-free linear MDPs, which achieves $\tilde{\mathcal O}(K^{8/9})$ regret and greatly improves over the best existing bound $\tilde{\mathcal O}(K^{14/15})$. This algorithm relies on a better alternative to the Matrix Geometric Resampling procedure by Neu & Olkhovskaya (2020), which could again be of independent interest.

**摘要:** 我们考虑学习在敌对马可夫决策过程(MDP)中,损失函数可以任意改变$K$事件,状态空间可以任意大。我们假设任何政策的Q-函数在某些已知特征中是线性,即存在线性函数近似。该设置的最佳 existing regret upper bound (Luo et al., 2021) is of order $\tilde{\mathcal O}(K^{2/3})$ (omitting all other dependencies), given access to a simulator。本论文提供了两个改进$\tilde{\mathcal O}(\sqrt K)$在同一设置中的遗憾算法。我们的第二算法开发了大小减损估计器,进一步消除了第一个算法中对行动数的多项式依赖,并导致了最佳的遗憾边界(到逻辑术语和边界依赖)。此外,我们还扩展了第一个算法到无模拟线性MDP,实现$\tilde{\mathcal O}(K^{8/9})$遗憾和大大改善了现有的最好边界$\tilde{\mathcal O}(K^{14/15})$。

**[Paper URL](https://proceedings.mlr.press/v202/dai23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dai23b/dai23b.pdf)** 

# MultiRobustBench: Benchmarking Robustness Against Multiple Attacks
**题目:** MultiRobustBench:对多重攻击的鲁棒性评判

**作者:** Sihui Dai, Saeed Mahloujifar, Chong Xiang, Vikash Sehwag, Pin-Yu Chen, Prateek Mittal

**Abstract:** The bulk of existing research in defending against adversarial examples focuses on defending against a single (typically bounded $\ell_p$-norm) attack, but for a practical setting, machine learning (ML) models should be robust to a wide variety of attacks. In this paper, we present the first unified framework for considering multiple attacks against ML models. Our framework is able to model different levels of learner’s knowledge about the test-time adversary, allowing us to model robustness against unforeseen attacks and robustness against unions of attacks. Using our framework, we present the first leaderboard, MultiRobustBench (https://multirobustbench.github.io), for benchmarking multiattack evaluation which captures performance across attack types and attack strengths. We evaluate the performance of 16 defended models for robustness against a set of 9 different attack types, including $\ell_p$-based threat models, spatial transformations, and color changes, at 20 different attack strengths (180 attacks total). Additionally, we analyze the state of current defenses against multiple attacks. Our analysis shows that while existing defenses have made progress in terms of average robustness across the set of attacks used, robustness against the worst-case attack is still a big open problem as all existing models perform worse than random guessing.

**摘要:** 针对敌对实例的现有研究的大部分集中在对单一(典型的界限 $\ell_p$-norm)攻击的防御上,但对于实际设置,机器学习(ML)模型应该对广泛的攻击具有鲁棒性。本论文中,我们提出了针对ML模型的多次攻击的第一个统一框架。我们的框架能够模拟学习者对测试时间的对手的知识的不同水平,允许我们对不预见的攻击和攻击联盟的鲁棒性进行建模。针对9种不同的攻击类型,包括基于$ell_p$的威胁模型、空间变换和颜色变化,对16种防御模型的性能进行了评估,分别对20种不同的攻击强度(总共180个攻击)进行了分析,并分析了当前对多个攻击的防御状态。

**[Paper URL](https://proceedings.mlr.press/v202/dai23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dai23c/dai23c.pdf)** 

# Moderately Distributional Exploration for Domain Generalization
**题目:** 域通用化中度分布式探索

**作者:** Rui Dai, Yonggang Zhang, Zhen Fang, Bo Han, Xinmei Tian

**Abstract:** Domain generalization (DG) aims to tackle the distribution shift between training domains and unknown target domains. Generating new domains is one of the most effective approaches, yet its performance gain depends on the distribution discrepancy between the generated and target domains. Distributionally robust optimization is promising to tackle distribution discrepancy by exploring domains in an uncertainty set. However, the uncertainty set may be overwhelmingly large, leading to low-confidence prediction in DG. It is because a large uncertainty set could introduce domains containing semantically different factors from training domains. To address this issue, we propose to perform a $\textit{mo}$derately $\textit{d}$istributional $\textit{e}$xploration (MODE) for domain generalization. Specifically, MODE performs distribution exploration in an uncertainty $\textit{subset}$ that shares the same semantic factors with the training domains. We show that MODE can endow models with provable generalization performance on unknown target domains. The experimental results show that MODE achieves competitive performance compared to state-of-the-art baselines.

**摘要:** 域广义化(DG)旨在解决训练域和未知目标域之间的分布变化。生成新域是最有效的方法之一,但其性能提升取决于生成域和目标域之间的分布差异。分布性强的优化有望通过探索域在不确定集合中解决分布差异。然而,不确定集合可能非常大,导致DG中的低信任预测。这是因为一个大的不确定集合可以引入包含训练域语义上的不同因素的域。实验结果表明,在未知目标域中,MOD能够提供可验证的通用化性能。

**[Paper URL](https://proceedings.mlr.press/v202/dai23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dai23d/dai23d.pdf)** 

# Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning
**题目:** 非政策强化学习的理论认识资格轨迹

**作者:** Brett Daley, Martha White, Christopher Amato, Marlos C. Machado

**Abstract:** Off-policy learning from multistep returns is crucial for sample-efficient reinforcement learning, but counteracting off-policy bias without exacerbating variance is challenging. Classically, off-policy bias is corrected in a per-decision manner: past temporal-difference errors are re-weighted by the instantaneous Importance Sampling (IS) ratio after each action via eligibility traces. Many off-policy algorithms rely on this mechanism, along with differing protocols for cutting the IS ratios (traces) to combat the variance of the IS estimator. Unfortunately, once a trace has been cut, the effect cannot be easily reversed. This has led to the development of credit-assignment strategies that account for multiple past experiences at a time. These trajectory-aware methods have not been extensively analyzed, and their theoretical justification remains uncertain. In this paper, we propose a multistep operator that unifies per-decision and trajectory-aware methods. We prove convergence conditions for our operator in the tabular setting, establishing the first guarantees for several existing methods as well as many new ones. Finally, we introduce Recency-Bounded Importance Sampling (RBIS), which leverages trajectory awareness to perform robustly across $\lambda$-values in an off-policy control task.

**摘要:** 基于多步返回的非政策学习对于实例有效强化学习至关重要,但没有加剧变异的反击非政策偏见是挑战性的。 传统上,非政策偏见是按决策方式纠正的:过去时差误差在通过资格跟踪的每项行动后,由即时重要性抽样(IS)比重重重。 许多非政策算法依靠这一机制,以及截断IS比(跟踪)的不同的协议来对抗IS估计器的变异。 不幸的是,一旦一个跟踪被截断,效果无法轻易逆转。最后,我们引入了 Recency-Bounded Importance Sampling(RBIS),它利用轨迹意识在非政策控制任务中通过$\lambda$-值进行强有力的执行。

**[Paper URL](https://proceedings.mlr.press/v202/daley23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/daley23a/daley23a.pdf)** 

# Efficient displacement convex optimization with particle gradient descent
**题目:** 粒子梯度下降的高效位移凸优化

**作者:** Hadi Daneshmand, Jason D. Lee, Chi Jin

**Abstract:** Particle gradient descent, which uses particles to represent a probability measure and performs gradient descent on particles in parallel, is widely used to optimize functions of probability measures. This paper considers particle gradient descent with a finite number of particles and establishes its theoretical guarantees to optimize functions that are displacement convex in measures. Concretely, for Lipschitz displacement convex functions defined on probability over $R^d$, we prove that $O(1/\epsilon^2)$ particles and $O(d/\epsilon^4)$ iterations are sufficient to find the $\epsilon$-optimal solutions. We further provide improved complexity bounds for optimizing smooth displacement convex functions. An application of our results proves the conjecture of no optimization-barrier up to permutation invariance, proposed by Entezari et al. (2022), for specific two-layer neural networks with two-dimensional inputs uniformly drawn from unit circle.

**摘要:** 粒子梯度降落(英语:Particle gradient descent)是利用粒子作为概率计量,并同时对粒子进行梯度降落,广泛应用于概率计量函数的优化。本文考虑了有限粒子粒子的粒子梯度降落,并确定了其在测量中变位凸函数的优化理论保证。具体而言,对于基于$R^d$的概率定义的利普希茨变位凸函数,我们证明O(1/\epsilon^2)$粒子和O(d/\epsilon^4)$迭代足够找到$\epsilon$-最佳解决方案。

**[Paper URL](https://proceedings.mlr.press/v202/daneshmand23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/daneshmand23a/daneshmand23a.pdf)** 

# Multiple Thinking Achieving Meta-Ability Decoupling for Object Navigation
**题目:** 多思考实现对象导航的元能力分离

**作者:** Ronghao Dang, Lu Chen, Liuyi Wang, Zongtao He, Chengju Liu, Qijun Chen

**Abstract:** We propose a meta-ability decoupling (MAD) paradigm, which brings together various object navigation methods in an architecture system, allowing them to mutually enhance each other and evolve together. Based on the MAD paradigm, we design a multiple thinking (MT) model that leverages distinct thinking to abstract various meta-abilities. Our method decouples meta-abilities from three aspects: input, encoding, and reward while employing the multiple thinking collaboration (MTC) module to promote mutual cooperation between thinking. MAD introduces a novel qualitative and quantitative interpretability system for object navigation. Through extensive experiments on AI2-Thor and RoboTHOR, we demonstrate that our method outperforms state-of-the-art (SOTA) methods on both typical and zero-shot object navigation tasks.

**摘要:** 基于MAD模式,设计了一种多思维(MT)模型,利用不同的思维来抽象各种元能。我们的方法从三个方面分离元能:输入、编码和奖励,同时使用多思维协作(MTC)模块促进思维之间的相互合作。MAD引入了一种新型的物体导航的质量和数量可解释性系统。通过对AI2-Thor和RoboTHOR的广泛实验,我们证明了我们的方法在典型和零射程物体导航任务中胜过最先进的(SOTA)方法。

**[Paper URL](https://proceedings.mlr.press/v202/dang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dang23a/dang23a.pdf)** 

# Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced Data
**题目:** 深度线性网络神经崩溃:从平衡数据到不平衡数据

**作者:** Hien Dang, Tho Tran Huu, Stanley Osher, Hung The Tran, Nhat Ho, Tan Minh Nguyen

**Abstract:** Modern deep neural networks have achieved impressive performance on tasks from image classification to natural language processing. Surprisingly, these complex systems with massive amounts of parameters exhibit the same structural properties in their last-layer features and classifiers across canonical datasets when training until convergence. In particular, it has been observed that the last-layer features collapse to their class-means, and those class-means are the vertices of a simplex Equiangular Tight Frame (ETF). This phenomenon is known as Neural Collapse (NC). Recent papers have theoretically shown that NC emerges in the global minimizers of training problems with the simplified “unconstrained feature model”. In this context, we take a step further and prove the NC occurrences in deep linear networks for the popular mean squared error (MSE) and cross entropy (CE) losses, showing that global solutions exhibit NC properties across the linear layers. Furthermore, we extend our study to imbalanced data for MSE loss and present the first geometric analysis of NC under bias-free setting. Our results demonstrate the convergence of the last-layer features and classifiers to a geometry consisting of orthogonal vectors, whose lengths depend on the amount of data in their corresponding classes. Finally, we empirically validate our theoretical analyses on synthetic and practical network architectures with both balanced and imbalanced scenarios.

**摘要:** 现代深层神经网络从图像分类到自然语言处理的任务都取得了令人印象深刻的性能。令人惊奇的是,这些具有大量参数的复杂系统在训练到收敛时,在它们的最后层特征和在 canonical datasets的分类器中展示了相同的结构性特性。本文还对MSE损伤的失衡数据进行了深入研究,并首次在无偏差环境下对NC进行了几何分析,证明了最后层特征和分类器的收敛性与由正交向量组成的几何学,其长度取决于其相应的类中的数据量。最后,我们以平衡和失衡的场景对合成和实际网络架构的理论分析进行了实证验证。

**[Paper URL](https://proceedings.mlr.press/v202/dang23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dang23b/dang23b.pdf)** 

# Reinforcement Learning Can Be More Efficient with Multiple Rewards
**题目:** 强化学习可以通过多种奖励来提高效率

**作者:** Christoph Dann, Yishay Mansour, Mehryar Mohri

**Abstract:** Reward design is one of the most critical and challenging aspects when formulating a task as a reinforcement learning (RL) problem. In practice, it often takes several attempts of reward specification and learning with it in order to find one that leads to sample-efficient learning of the desired behavior. Instead, in this work, we study whether directly incorporating multiple alternate reward formulations of the same task in a single agent can lead to faster learning. We analyze multi-reward extensions of action-elimination algorithms and prove more favorable instance-dependent regret bounds compared to their single-reward counterparts, both in multi-armed bandits and in tabular Markov decision processes. Our bounds scale for each state-action pair with the inverse of the largest gap among all reward functions. This suggests that learning with multiple rewards can indeed be more sample-efficient, as long as the rewards agree on an optimal policy. We further prove that when rewards do not agree, multi-reward action elimination in multi-armed bandits still learns a policy that is good across all reward functions.

**摘要:** 奖励设计是制定任务作为强化学习(RL)问题的最关键和挑战性方面之一。在实践中,它往往需要多个奖励规范的尝试和学习,以找到一个导致被期望行为的样本有效学习的方案。相反,在这项工作中,我们研究 whether directly incorporating multiple alternate reward formulations of the same task in a single agent can lead to faster learning。我们分析了行动除去算法的多奖扩展,并证明了与其单奖对照者相比,更有利的实例依赖的遗憾边界, both in multi-armed bandits and in tabular Markov decision processes。我们进一步证明,当奖金不一致时,在多武器强盗中消除多奖金行动仍会学习一种在所有奖金功能中都有效的政策。

**[Paper URL](https://proceedings.mlr.press/v202/dann23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dann23a/dann23a.pdf)** 

# Best of Both Worlds Policy Optimization
**题目:** 最佳的两个世界政策优化

**作者:** Christoph Dann, Chen-Yu Wei, Julian Zimmert

**Abstract:** Policy optimization methods are popular reinforcement learning algorithms in practice and recent works have build theoretical foundation for them by proving $\sqrt{T}$ regret bounds even when the losses are adversarial. Such bounds are tight in the worst case but often overly pessimistic. In this work, we show that by carefully designing the regularizer, bonus terms, and learning rates, one can achieve a more favorable $\text{polylog}(T)$ regret bound when the losses are stochastic, without sacrificing the worst-case guarantee in the adversarial regime. Specifically, we show the first best of both worlds guarantee for policy optimization in tabular MDPs by leveraging either a Tsallis entropy or a Shannon entropy regularizer. Then we show that under known transitions, we can further obtain a first-order regret bound in the adversarial regime by leveraging the log barrier regularizer.

**摘要:** 策略优化方法在实践中是普遍的强化学习算法,最近的工作已经为它们建立了理论基础,证明了$sqrt{T}$遗憾的边界,即使损失是敌对的。这种边界在最坏情况下很紧,但往往过于悲观。在这个工作中,我们展示了通过仔细设计规范器、奖金条款和学习率,一个人可以在敌对制度中牺牲最坏情况下获得更有利的$\text{polylog}(T)$遗憾的边界。

**[Paper URL](https://proceedings.mlr.press/v202/dann23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dann23b/dann23b.pdf)** 

# Image generation with shortest path diffusion
**题目:** 最短路径扩散的图像生成

**作者:** Ayan Das, Stathi Fotiadis, Anil Batra, Farhang Nabiei, Fengting Liao, Sattar Vakili, Da-Shan Shiu, Alberto Bernacchia

**Abstract:** The field of image generation has made significant progress thanks to the introduction of Diffusion Models, which learn to progressively reverse a given image corruption. Recently, a few studies introduced alternative ways of corrupting images in Diffusion Models, with an emphasis on blurring. However, these studies are purely empirical and it remains unclear what is the optimal procedure for corrupting an image. In this work, we hypothesize that the optimal procedure minimizes the length of the path taken when corrupting an image towards a given final state. We propose the Fisher metric for the path length, measured in the space of probability distributions. We compute the shortest path according to this metric, and we show that it corresponds to a combination of image sharpening, rather than blurring, and noise deblurring. While the corruption was chosen arbitrarily in previous work, our Shortest Path Diffusion (SPD) determines uniquely the entire spatiotemporal structure of the corruption. We show that SPD improves on strong baselines without any hyperparameter tuning, and outperforms all previous Diffusion Models based on image blurring. Furthermore, any small deviation from the shortest path leads to worse performance, suggesting that SPD provides the optimal procedure to corrupt images. Our work sheds new light on observations made in recent works and provides a new approach to improve diffusion models on images and other types of data.

**摘要:** 由于扩散模型的引入,图像生成领域取得了显著的进步,它们学会逐步逆转给定的图像损坏。最近,一些研究引入了扩散模型中图像损坏的替代方法,强调模糊。然而,这些研究是纯粹的实证性研究,并尚不清楚图像损坏的最佳程序是什么。本研究中,我们假定最佳程序在对定的最终状态进行图像损坏时最小化路径的长度。我们提出了在概率分布空间中测定路径长度的费舍尔度量。我们根据这个度量计算了最短路径,并证明它与图像锐化、模糊和噪声模糊相结合。我们的最短路径扩散(SPD)仅确定了该扩散的整个时空结构。我们显示,SPD在没有任何超参数调谐的情况下在强基线上改善,并且在图像模糊的基础上超过了所有以前的扩散模型。此外,从最短路径的任何小偏差会导致更糟糕的性能,这表明SPD为扩散图像提供了最佳的处理方法。

**[Paper URL](https://proceedings.mlr.press/v202/das23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/das23a/das23a.pdf)** 

# Efficient List-Decodable Regression using Batches
**题目:** 使用批量有效的列表可删除回归

**作者:** Abhimanyu Das, Ayush Jain, Weihao Kong, Rajat Sen

**Abstract:** We demonstrate the use of batches in studying list-decodable linear regression, in which only $\alpha\in (0,1]$ fraction of batches contain genuine samples from a common distribution and the rest can contain arbitrary or even adversarial samples. When genuine batches have $\ge \tilde\Omega(1/\alpha)$ samples each, our algorithm can efficiently find a small list of potential regression parameters, with a high probability that one of them is close to the true parameter. This is the first polynomial time algorithm for list-decodable linear regression, and its sample complexity scales nearly linearly with the dimension of the covariates. The polynomial time algorithm is made possible by the batch structure and may not be feasible without it, as suggested by a recent Statistical Query lower bound (Diakonikolas et al., 2021b).

**摘要:** 我们展示了批量在研究列表可解线性回归中的应用,其中只有$alpha\in (0,1]$批量包含一个共同分布的真样品,其余可以包含任意或甚至敌对的样品。当真批量每批有$\ge\tilde\Omega(1/\alpha)$样品时,我们的算法能够有效地找到一个小列表的潜在回归参数,其中之一接近真参数的概率很高。这是列表可解线性回归的第一个多项式时间算法,它的样品复杂度几乎与协变量的维度相等于线性。

**[Paper URL](https://proceedings.mlr.press/v202/das23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/das23b/das23b.pdf)** 

# Beyond Uniform Lipschitz Condition in Differentially Private Optimization
**题目:** 在不同程度的私人优化中超越统一的利普希茨条件

**作者:** Rudrajit Das, Satyen Kale, Zheng Xu, Tong Zhang, Sujay Sanghavi

**Abstract:** Most prior results on differentially private stochastic gradient descent (DP-SGD) are derived under the simplistic assumption of uniform Lipschitzness, i.e., the per-sample gradients are uniformly bounded. We generalize uniform Lipschitzness by assuming that the per-sample gradients have sample-dependent upper bounds, i.e., per-sample Lipschitz constants, which themselves may be unbounded. We provide principled guidance on choosing the clip norm in DP-SGD for convex over-parameterized settings satisfying our general version of Lipschitzness when the per-sample Lipschitz constants are bounded; specifically, we recommend tuning the clip norm only till values up to the minimum per-sample Lipschitz constant. This finds application in the private training of a softmax layer on top of a deep network pre-trained on public data. We verify the efficacy of our recommendation via experiments on 8 datasets. Furthermore, we provide new convergence results for DP-SGD on convex and nonconvex functions when the Lipschitz constants are unbounded but have bounded moments, i.e., they are heavy-tailed.

**摘要:** 在微分私有随机梯度下降(DP-SGD)上,大多数先前的结果是基于均匀利普希茨度的简化假设,即每样品梯度均匀界限。我们通过假设每样品梯度有样品依赖的上限,即每样品利普希茨常数,而它们本身可能不界限,将均匀利普希茨度一般化。我们在DP-SGD中为凸过参数化设置满足我们一般版本的利普希茨度,当每样品利普希茨常数被界限时,提供了选择剪辑规范的原理指导;具体地说,我们只建议调整剪辑规范,直到每样品利普希茨常数的最低值。此外,我们为DP-SGD提供了新的凸函数和非凸函数的收敛结果。

**[Paper URL](https://proceedings.mlr.press/v202/das23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/das23c/das23c.pdf)** 

# Understanding Self-Distillation in the Presence of Label Noise
**题目:** 理解标签噪声中的自我蒸馏

**作者:** Rudrajit Das, Sujay Sanghavi

**Abstract:** Self-distillation (SD) is the process of first training a "teacher" model and then using its predictions to train a "student" model that has the same architecture. Specifically, the student’s loss is $\big(\xi*\ell(\text{teacher’s predictions}, \text{ student’s predictions}) + (1-\xi)*\ell(\text{given labels}, \text{ student’s predictions})\big)$, where $\ell$ is the loss function and $\xi$ is some parameter $\in [0,1]$. SD has been empirically observed to provide performance gains in several settings. In this paper, we theoretically characterize the effect of SD in two supervised learning problems with noisy labels. We first analyze SD for regularized linear regression and show that in the high label noise regime, the optimal value of $\xi$ that minimizes the expected error in estimating the ground truth parameter is surprisingly greater than 1. Empirically, we show that $\xi > 1$ works better than $\xi \leq 1$ even with the cross-entropy loss for several classification datasets when 50% or 30% of the labels are corrupted. Further, we quantify when optimal SD is better than optimal regularization. Next, we analyze SD in the case of logistic regression for binary classification with random label corruption and quantify the range of label corruption in which the student outperforms the teacher (w.r.t. accuracy). To our knowledge, this is the first result of its kind for the cross-entropy loss.

**摘要:** 自我蒸馏(英语:Self-distillation,缩写SD)是首先训练一个“教师”模型,然后使用其预测来训练一个具有相同的架构的“学生”模型的过程。具体而言,学生损失是$\big(\xi*\ell(\text{教师的预测}, \text{学生的预测}) + (1-\xi)*\ell(\text{给定标签}, \text{学生的预测})\big)$,其中$\ell$是损失函数,$\xi$是某个参数$\in[0.1]$。 SD在实验上被观察到在几个设置中提供性能增益。 Empirically, we show that $\xi > 1$ works better than $\xi \leq 1$ even with the cross-entropy loss for several classification datasets when 50% or 30% of the labels are corrupted. Further, we quantify when optimal SD is better than optimal regularization. Next, we analyze SD in the case of logistic regression for binary classification with random label corruption and quantify the range of label corruption in which the student outperforms the teacher (w.r.t. accuracy). To our knowledge, this is the first result of its kind for the cross-entropy loss.

**[Paper URL](https://proceedings.mlr.press/v202/das23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/das23d/das23d.pdf)** 

# Interval Bound Interpolation for Few-shot Learning with Few Tasks
**题目:** 少数任务的少击学习中 interval bound interpolation

**作者:** Shounak Datta, Sankha Subhra Mullick, Anish Chakrabarty, Swagatam Das

**Abstract:** Few-shot learning aims to transfer the knowledge acquired from training on a diverse set of tasks to unseen tasks from the same task distribution, with a limited amount of labeled data. The underlying requirement for effective few-shot generalization is to learn a good representation of the task manifold. This becomes more difficult when only a limited number of tasks are available for training. In such a few-task few-shot setting, it is beneficial to explicitly preserve the local neighborhoods from the task manifold and exploit this to generate artificial tasks for training. To this end, we introduce the notion of interval bounds from the provably robust training literature to few-shot learning. The interval bounds are used to characterize neighborhoods around the training tasks. These neighborhoods can then be preserved by minimizing the distance between a task and its respective bounds. We then use a novel strategy to artificially form new tasks for training by interpolating between the available tasks and their respective interval bounds. We apply our framework to both model-agnostic meta-learning as well as prototype-based metric-learning paradigms. The efficacy of our proposed approach is evident from the improved performance on several datasets from diverse domains in comparison to recent methods.

**摘要:** 少数射击学习的目标是将从训练中获得的知识转移到不同任务的集合中,从相同的任务分配中,以有限数量的标记数据传递到未知任务。有效的少数射击一般化的基础要求是学习任务多组的良好表现。当只有有限数量的任务供训练使用时,这变得更加困难。在这样的少数任务少数射击设置中,可以明确地保存任务多组的本地社区,并利用此来生成训练的人工任务。为此目的,我们从可证明可靠的训练文献中引入了间隔边界的概念。间隔边界用于描述训练任务周围的社区。这些社区可以通过减少任务与其各自边界之间的距离来保存。然后,我们采用一种新颖的策略,通过对现有的任务与其各自的间隔边界进行插值,以人工形成新的训练任务。我们应用了我们的框架,既适用于模型认知的元学习,又适用于基于原型的元学习范式。

**[Paper URL](https://proceedings.mlr.press/v202/datta23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/datta23a/datta23a.pdf)** 

# Hypervolume Knowledge Gradient: A Lookahead Approach for Multi-Objective Bayesian Optimization with Partial Information
**题目:** 超卷知识梯度:基于部分信息的多目标贝叶斯优化的前瞻性方法

**作者:** Sam Daulton, Maximilian Balandat, Eytan Bakshy

**Abstract:** Bayesian optimization is a popular method for sample efficient multi-objective optimization. However, existing Bayesian optimization techniques fail to effectively exploit common and often-neglected problem structure such as decoupled evaluations, where objectives can be queried independently from one another and each may consume different resources, or multi-fidelity evaluations, where lower fidelity-proxies of the objectives can be evaluated at lower cost. In this work, we propose a general one-step lookahead acquisition function based on the Knowledge Gradient that addresses the complex question of what to evaluate when and at which design points in a principled Bayesian decision-theoretic fashion. Hence, our approach naturally addresses decoupled, multi-fidelity, and standard multi-objective optimization settings in a unified Bayesian decision making framework. By construction, our method is the one-step Bayes-optimal policy for hypervolume maximization. Empirically, we demonstrate that our method improves sample efficiency in a wide variety of synthetic and real-world problems. Furthermore, we show that our method is general-purpose and yields competitive performance in standard (potentially noisy) multi-objective optimization.

**摘要:** 贝叶斯优化是一种高效的多目标优化的流行方法,但现有的贝叶斯优化技术无法有效利用常见的和经常被忽视的问题结构,例如分开评价,目标可以独立查询,每个目标可以消耗不同的资源,或者多真实性评价,目标的低 fidelity-proxies可以低成本评价。实证表明,该方法在多种合成和现实问题中提高了样品效率,同时表明该方法具有通用性,在标准多目标优化中具有竞争性性能。

**[Paper URL](https://proceedings.mlr.press/v202/daulton23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/daulton23a/daulton23a.pdf)** 

# Fast Combinatorial Algorithms for Min Max Correlation Clustering
**题目:** 最小最大相关聚类的快速组合算法

**作者:** Sami Davies, Benjamin Moseley, Heather Newman

**Abstract:** We introduce fast algorithms for correlation clustering with respect to the Min Max objective that provide constant factor approximations on complete graphs. Our algorithms are the first purely combinatorial approximation algorithms for this problem. We construct a novel semi-metric on the set of vertices, which we call the correlation metric, that indicates to our clustering algorithms whether pairs of nodes should be in the same cluster. The paper demonstrates empirically that, compared to prior work, our algorithms sacrifice little in the objective quality to obtain significantly better run-time. Moreover, our algorithms scale to larger networks that are effectively intractable for known algorithms.

**摘要:** 本文介绍了关于最小值目标的关联聚类的快速算法,这些算法为完整的图提供常因近似。这些算法是该问题的第一类纯组合近似算法。我们在顶点集合上构造了一个新半度量,我们称之为关联度量,它指示聚类算法在同一聚类中是否应该有节点的双对。本文以实证证明,与以前的工作相比,我们的算法在目标质量上牺牲很少,以获得显著更好的运行时间。

**[Paper URL](https://proceedings.mlr.press/v202/davies23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/davies23a/davies23a.pdf)** 

# Predictive Flows for Faster Ford-Fulkerson
**题目:** 快速福特-福克森预测流

**作者:** Sami Davies, Benjamin Moseley, Sergei Vassilvitskii, Yuyan Wang

**Abstract:** Recent work has shown that leveraging learned predictions can improve the running time of algorithms for bipartite matching and similar combinatorial problems. In this work, we build on this idea to improve the performance of the widely used Ford-Fulkerson algorithm for computing maximum flows by seeding Ford-Fulkerson with predicted flows. Our proposed method offers strong theoretical performance in terms of the quality of the prediction. We then consider image segmentation, a common use-case of flows in computer vision, and complement our theoretical analysis with strong empirical results.

**摘要:** 最近的研究表明,利用学习预测可以提高算法的运行时间,用于双方匹配和类似的组合问题。在此研究中,我们基于这一想法,通过将福特-福尔克森的预测流程播种,提高广泛使用的福特-福尔克森算法的计算最大流的性能。

**[Paper URL](https://proceedings.mlr.press/v202/davies23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/davies23b/davies23b.pdf)** 

# The Persistent Laplacian for Data Science: Evaluating Higher-Order Persistent Spectral Representations of Data
**题目:** 数据科学的持久拉普拉西亚:评价数据的高阶持久光谱表现

**作者:** Thomas Davies, Zhengchao Wan, Ruben J Sanchez-Garcia

**Abstract:** Persistent homology is arguably the most successful technique in Topological Data Analysis. It combines homology, a topological feature of a data set, with persistence, which tracks the evolution of homology over different scales. The persistent Laplacian is a recent theoretical development that combines persistence with the combinatorial Laplacian, the higher-order extension of the well-known graph Laplacian. Crucially, the Laplacian encode both the homology of a data set, and some additional geometric information not captured by the homology. Here, we provide the first investigation into the efficacy of the persistence Laplacian as an embedding of data for downstream classification and regression tasks. We extend the persistent Laplacian to cubical complexes so it can be used on images, then evaluate its performance as an embedding method on the MNIST and MoleculeNet datasets, demonstrating that it consistently outperforms persistent homology across tasks.

**摘要:** 持久性同理是拓扑数据分析中最为成功的技术。它结合了同理,一个数据集的拓扑特征,与持久性,跟踪不同尺度的同理进化。持久性同理是最近的理论发展,它结合了持久性与组合性同理,是众所周知的拉普拉西亚图的更高阶扩展。关键的是,拉普拉西亚编码了数据集的同理,以及一些由同理没有捕捉的额外几何信息。

**[Paper URL](https://proceedings.mlr.press/v202/davies23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/davies23c/davies23c.pdf)** 

# Mitigating Propagation Failures in Physics-informed Neural Networks using Retain-Resample-Release (R3) Sampling
**题目:** Retain-Resample-Release(R3)样本法在物理信息神经网络中的扩散失败的缓解

**作者:** Arka Daw, Jie Bu, Sifan Wang, Paris Perdikaris, Anuj Karpatne

**Abstract:** Despite the success of physics-informed neural networks (PINNs) in approximating partial differential equations (PDEs), PINNs can sometimes fail to converge to the correct solution in problems involving complicated PDEs. This is reflected in several recent studies on characterizing the "failure modes" of PINNs, although a thorough understanding of the connection between PINN failure modes and sampling strategies is missing. In this paper, we provide a novel perspective of failure modes of PINNs by hypothesizing that training PINNs relies on successful "propagation" of solution from initial and/or boundary condition points to interior points. We show that PINNs with poor sampling strategies can get stuck at trivial solutions if there are propagation failures, characterized by highly imbalanced PDE residual fields. To mitigate propagation failures, we propose a novel Retain-Resample-Release sampling (R3) algorithm that can incrementally accumulate collocation points in regions of high PDE residuals with little to no computational overhead. We provide an extension of R3 sampling to respect the principle of causality while solving time-dependent PDEs. We theoretically analyze the behavior of R3 sampling and empirically demonstrate its efficacy and efficiency in comparison with baselines on a variety of PDE problems.

**摘要:** 尽管物理信息神经网络在近似部分微分方程(PDEs)方面取得了成功,但有时它们无法实现复杂的PDEs问题的正确解决。这反映在对PINN的“失败模式”的几个最近研究中,尽管缺乏对PINN失败模式和采样策略之间的关系的深入了解。本论文通过假设训练PINN依赖于从初始和/或边界条件点到内部点成功“推导”解决的方法,为PINN的失败模式提供了一个新视角。为了减轻传播失败,我们提出了一种新颖的储存-样品-发布样品(R3)算法,该算法能够在低到零的计算费用下,在高PDDE残留区累积聚合点。我们提供了R3样品的扩展,以尊重因果关系原则,同时解决时间依赖的PDEs。我们从理论上分析R3样品的行为,并在不同PDDE问题的基础上,实证其有效性和效率。

**[Paper URL](https://proceedings.mlr.press/v202/daw23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/daw23a/daw23a.pdf)** 

# On the Robustness of Randomized Ensembles to Adversarial Perturbations
**题目:** 随机集群对敌对扰动的鲁棒性

**作者:** Hassan Dbouk, Naresh Shanbhag

**Abstract:** Randomized ensemble classifiers (RECs), where one classifier is randomly selected during inference, have emerged as an attractive alternative to traditional ensembling methods for realizing adversarially robust classifiers with limited compute requirements. However, recent works have shown that existing methods for constructing RECs are more vulnerable than initially claimed, casting major doubts on their efficacy and prompting fundamental questions such as: "When are RECs useful?", "What are their limits?", and "How do we train them?". In this work, we first demystify RECs as we derive fundamental results regarding their theoretical limits, necessary and sufficient conditions for them to be useful, and more. Leveraging this new understanding, we propose a new boosting algorithm (BARRE) for training robust RECs, and empirically demonstrate its effectiveness at defending against strong $\ell_\infty$ norm-bounded adversaries across various network architectures and datasets. Our code can be found at https://github.com/hsndbk4/BARRE.

**摘要:** 随机集群分类器(RECs),其中一个分类器在推导过程中随机选择,已成为实现具有有限的计算要求的敌对鲁棒分类器的传统仿效方法的一个诱人的替代方案。然而,最近的研究表明,现有的建构REC方法比最初的说法更加脆弱,对其有效性产生了重大怀疑,并引发了诸如:"RECs什么时候有用?","它们的局限性是什么?","我们如何训练它们?"等基本问题。我们的代码可以在 https://github.com/hsndbk4/BARRE上找到。

**[Paper URL](https://proceedings.mlr.press/v202/dbouk23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dbouk23a/dbouk23a.pdf)** 

# Pre-computed memory or on-the-fly encoding? A hybrid approach to retrieval augmentation makes the most of your compute
**题目:** 预计算的内存或即时编码?一种求解增强的混合方法使您的计算得到最大效果

**作者:** Michiel De Jong, Yury Zemlyanskiy, Nicholas Fitzgerald, Joshua Ainslie, Sumit Sanghai, Fei Sha, William W. Cohen

**Abstract:** Retrieval-augmented language models such as Fusion-in-Decoder are powerful, setting the state of the art on a variety of knowledge-intensive tasks. However, they are also expensive, due to the need to encode a large number of retrieved passages. Some work avoids this cost by pre-encoding a text corpus into a memory and retrieving dense representations directly. However, pre-encoding memory incurs a severe quality penalty as the memory representations are not conditioned on the current input. We propose LUMEN, a hybrid between these two extremes, pre-computing the majority of the retrieval representation and completing the encoding on the fly using a live encoder that is conditioned on the question and fine-tuned for the task. We show that LUMEN significantly outperforms pure memory on multiple question-answering tasks while being much cheaper than FiD, and outperforms both for any given compute budget. Moreover, the advantage of LUMEN over FiD increases with model size.

**摘要:** 检索增加的语言模型如Fusion-in-Decoder具有强大的功能,在各种知识密集型任务上设置了最新状态。然而,它们也是昂贵的,因为需要编码大量的检索段落。一些工作通过预编码文本体到存储器并直接检索密集型表示来避免这一成本。然而,预编码存储器遭受了严重的质量处罚,因为存储器的表示不取决于当前输入。我们提出了LUMEN,这两个极端之间的混合物,预计算了检索表示的大部分,并用一个预先编码器完成在飞行时的编码。

**[Paper URL](https://proceedings.mlr.press/v202/de-jong23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/de-jong23a/de-jong23a.pdf)** 

# Continuous Spatiotemporal Transformer
**题目:** 连续时空变换器

**作者:** Antonio Henrique De Oliveira Fonseca, Emanuele Zappala, Josue Ortega Caro, David Van Dijk

**Abstract:** Modeling spatiotemporal dynamical systems is a fundamental challenge in machine learning. Transformer models have been very successful in NLP and computer vision where they provide interpretable representations of data. However, a limitation of transformers in modeling continuous dynamical systems is that they are fundamentally discrete time and space models and thus have no guarantees regarding continuous sampling. To address this challenge, we present the Continuous Spatiotemporal Transformer (CST), a new transformer architecture that is designed for modeling of continuous systems. This new framework guarantees a continuous and smooth output via optimization in Sobolev space. We benchmark CST against traditional transformers as well as other spatiotemporal dynamics modeling methods and achieve superior performance in a number of tasks on synthetic and real systems, including learning brain dynamics from calcium imaging data.

**摘要:** 时空动力学系统建模是机器学习的一个基本挑战。变换器模型在NLP和计算机视觉中非常成功,它们提供了可解释的数据表示。然而,在建模时空动力学系统时变换器的局限性在于它们是基本的离散时间和空间模型,因此没有关于连续采样的保证。为了解决这一挑战,我们提出了连续时空变换器(CST),一种为连续系统建模设计的新变换器架构。

**[Paper URL](https://proceedings.mlr.press/v202/de-oliveira-fonseca23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/de-oliveira-fonseca23a/de-oliveira-fonseca23a.pdf)** 

# The Value of Out-of-Distribution Data
**题目:** 离散数据的价值

**作者:** Ashwin De Silva, Rahul Ramesh, Carey Priebe, Pratik Chaudhari, Joshua T Vogelstein

**Abstract:** Generalization error always improves with more in-distribution data. However, it is an open question what happens as we add out-of-distribution (OOD) data. Intuitively, if the OOD data is quite different, it seems more data would harm generalization error, though if the OOD data are sufficiently similar, much empirical evidence suggests that OOD data can actually improve generalization error. We show a counter-intuitive phenomenon: the generalization error of a task can be a non-monotonic function of the amount of OOD data. Specifically, we prove that generalization error can improve with small amounts of OOD data, and then get worse than no OOD data with larger amounts. In other words, there is value in training on small amounts of OOD data. We analytically demonstrate these results via Fisher’s Linear Discriminant on synthetic datasets, and empirically demonstrate them via deep networks on computer vision benchmarks such as MNIST, CIFAR-10, CINIC-10, PACS and DomainNet. In the idealistic setting where we know which samples are OOD, we show that these non-monotonic trends can be exploited using an appropriately weighted objective of the target and OOD empirical risk. While its practical utility is limited, this does suggest that if we can detect OOD samples, then there may be ways to benefit from them. When we do not know which samples are OOD, we show how a number of go-to strategies such as data-augmentation, hyper-parameter optimization and pre-training are not enough to ensure that the target generalization error does not deteriorate with the number of OOD samples in the dataset.

**摘要:** 一般化误差总是随着在分布数据中的数据的增加而有所改善。然而,当我们添加出分布(OOD)数据时发生什么事情是一个开放的问题。如果OOD数据相当不同,那么似乎更多的数据会损害一般化误差,但如果OOD数据足够相似,许多经验证据表明OOD数据实际上可以改进一般化误差。我们显示了一个反直觉现象:任务的一般化误差可能是OOD数据的量度的非单元函数。具体地说,我们证明了一般化误差可以改善小量度的OOD数据,然后 getting worse than no OOD data with larger quantities。在理想化环境中,我们知道哪些样品是OOD时,我们证明这些非单元趋势可以通过适当权重目标和OOD经验风险来利用。虽然其实用性有限,但这表明,如果我们能检测到OOD样品,那么可能有方法从中获益。当我们不知道哪些样品是OOD时,我们证明了数据增量、参数优化和预训练等一系列目标推广策略不足以确保在数据集中的OOD样品数目下目标推广误差不会恶化。

**[Paper URL](https://proceedings.mlr.press/v202/de-silva23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/de-silva23a/de-silva23a.pdf)** 

# High Fidelity Image Counterfactuals with Probabilistic Causal Models
**题目:** 基于概率动因模型的高 Fidelity图像反事实

**作者:** Fabio De Sousa Ribeiro, Tian Xia, Miguel Monteiro, Nick Pawlowski, Ben Glocker

**Abstract:** We present a general causal generative modelling framework for accurate estimation of high fidelity image counterfactuals with deep structural causal models. Estimation of interventional and counterfactual queries for high-dimensional structured variables, such as images, remains a challenging task. We leverage ideas from causal mediation analysis and advances in generative modelling to design new deep causal mechanisms for structured variables in causal models. Our experiments demonstrate that our proposed mechanisms are capable of accurate abduction and estimation of direct, indirect and total effects as measured by axiomatic soundness of counterfactuals.

**摘要:** 本文提出了一种基于深层结构性模型对高 fidelity图像反因子准确估计的一般因子生成模型框架。对图像等高维结构性变量进行干预和反因子查询的估计仍然是一个挑战性的任务。我们利用因子中介分析和生成模型的进步,设计了新的深层结构性变量模型中结构性变量的新因子机制。

**[Paper URL](https://proceedings.mlr.press/v202/de-sousa-ribeiro23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/de-sousa-ribeiro23a/de-sousa-ribeiro23a.pdf)** 

# Learning Noisy OR Bayesian Networks with Max-Product Belief Propagation
**题目:** 学习噪声或贝叶斯网络与最大产品信仰传播

**作者:** Antoine Dedieu, Guangyao Zhou, Dileep George, Miguel Lazaro-Gredilla

**Abstract:** Noisy-OR Bayesian Networks (BNs) are a family of probabilistic graphical models which express rich statistical dependencies in binary data. Variational inference (VI) has been the main method proposed to learn noisy-OR BNs with complex latent structures (Jaakkola & Jordan, 1999; Ji et al., 2020; Buhai et al., 2020). However, the proposed VI approaches either (a) use a recognition network with standard amortized inference that cannot induce "explaining-away"; or (b) assume a simple mean-field (MF) posterior which is vulnerable to bad local optima. Existing MF VI methods also update the MF parameters sequentially which makes them inherently slow. In this paper, we propose parallel max-product as an alternative algorithm for learning noisy-OR BNs with complex latent structures and we derive a fast stochastic training scheme that scales to large datasets. We evaluate both approaches on several benchmarks where VI is the state-of-the-art and show that our method (a) achieves better test performance than Ji et al. (2020) for learning noisy-OR BNs with hierarchical latent structures on large sparse real datasets; (b) recovers a higher number of ground truth parameters than Buhai et al. (2020) from cluttered synthetic scenes; and (c) solves the 2D blind deconvolution problem from Lazaro-Gredilla et al. (2021) and variants - including binary matrix factorization - while VI catastrophically fails and is up to two orders of magnitude slower.

**摘要:** 噪声-OR Bayesian Networks(BNs)是一种基于二进制数据的概率图形模型,表达了丰富的统计依赖性。变量推导(VI)是研究复杂滞后结构的噪声-OR BN的主要方法(Jaakkola & Jordan, 1999; Ji et al., 2020; Buhai et al., 2020)。然而,提议的VI方法要么(a)使用具有标准 amortized推导的识别网络,不能诱导“explaining-away”;要么(b)假设一个简单的平均场(MF)后端,易受不良局部优化的影响。现有MF VI方法也逐次更新MF参数,从而使它们自然减速。我们对两种方法在几个基准上进行了评价,其中VI是最先进的方法,并证明了我们的方法(a)在大量稀疏的实数据集上学习具有层次隐形结构的噪声OR BN时比Ji等人更好的测试性能;(b)从混杂的合成场景中恢复比Buhai等人(2020)的地面真实参数的数目更高;(c)解决了Lazaro-Gredilla等人(2021)和变量(包括二进制矩阵因子化)的2D盲解调问题,而VI则灾难性地失败,并且比Buhai等人(2020)慢到两级。

**[Paper URL](https://proceedings.mlr.press/v202/dedieu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dedieu23a/dedieu23a.pdf)** 

# Learning-Rate-Free Learning by D-Adaptation
**题目:** D-自适应学习-免费学习

**作者:** Aaron Defazio, Konstantin Mishchenko

**Abstract:** The speed of gradient descent for convex Lipschitz functions is highly dependent on the choice of learning rate. Setting the learning rate to achieve the optimal convergence rate requires knowing the distance D from the initial point to the solution set. In this work, we describe a single-loop method, with no back-tracking or line searches, which does not require knowledge of D yet asymptotically achieves the optimal rate of convergence for the complexity class of convex Lipschitz functions. Our approach is the first parameter-free method for this class without additional multiplicative log factors in the convergence rate. We present extensive experiments for SGD and Adam variants of our method, where the method automatically matches hand-tuned learning rates across more than a dozen diverse machine learning problems, including large-scale vision and language problems. Our method is practical, efficient and requires no additional function value or gradient evaluations each step. An implementation is provided in the supplementary material.

**摘要:** 凸利普希茨函数的梯度下降速度高度取决于学习率的选择。设置学习率以达到最佳的收敛率需要知道从初点到解决方案设置的D距离。本文描述了一个单环方法,没有后继或行搜索,不需要D知识,但以渐近的方式实现凸利普希茨函数的复杂度类的最佳收敛率。我们的方法是该类的第一个无参数方法,在收敛率中没有额外的乘法逻辑因子。在 补充 材料 中 提供 了 执行 情况 。

**[Paper URL](https://proceedings.mlr.press/v202/defazio23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/defazio23a/defazio23a.pdf)** 

# Scaling Vision Transformers to 22 Billion Parameters
**题目:** 将视觉变换器扩展到22亿参数

**作者:** Mostafa Dehghani, Josip Djolonga, Basil Mustafa, Piotr Padlewski, Jonathan Heek, Justin Gilmer, Andreas Peter Steiner, Mathilde Caron, Robert Geirhos, Ibrahim Alabdulmohsin, Rodolphe Jenatton, Lucas Beyer, Michael Tschannen, Anurag Arnab, Xiao Wang, Carlos Riquelme Ruiz, Matthias Minderer, Joan Puigcerver, Utku Evci, Manoj Kumar, Sjoerd Van Steenkiste, Gamaleldin Fathy Elsayed, Aravindh Mahendran, Fisher Yu, Avital Oliver, Fantine Huot, Jasmijn Bastings, Mark Collier, Alexey A. Gritsenko, Vighnesh Birodkar, Cristina Nader Vasconcelos, Yi Tay, Thomas Mensink, Alexander Kolesnikov, Filip Pavetic, Dustin Tran, Thomas Kipf, Mario Lucic, Xiaohua Zhai, Daniel Keysers, Jeremiah J. Harmsen, Neil Houlsby

**Abstract:** The scaling of Transformers has driven breakthrough capabilities for language models. At present, the largest large language models (LLMs) contain upwards of 100B parameters. Vision Transformers (ViT) have introduced the same architecture to image and video modelling, but these have not yet been successfully scaled to nearly the same degree; the largest dense ViT contains 4B parameters (Chen et al., 2022). We present a recipe for highly efficient and stable training of a 22B-parameter ViT (ViT-22B) and perform a wide variety of experiments on the resulting model. When evaluated on downstream tasks (often with a lightweight linear model on frozen features), ViT-22B demonstrates increasing performance with scale. We further observe other interesting benefits of scale, including an improved tradeoff between fairness and performance, state-of-the-art alignment to human visual perception in terms of shape/texture bias, and improved robustness. ViT-22B demonstrates the potential for "LLM-like" scaling in vision, and provides key steps towards getting there.

**摘要:** 目前,最大的大型语言模型(LLMs)包含超过100B参数。视觉变换器(ViT)引入了图像和视频建模的相同的架构,但这些尚未成功地达到几乎相同的程度;最大密度的ViT包含4B参数(Chen et al., 2022)。我们提出了一种非常高效和稳定的22B参数ViT(ViT-22B)训练的配方,并对结果模型进行了广泛的实验。当评估下游任务(经常与冷冻特性上的轻量线性模型)时,ViT-22B显示了规模的提高性能。ViT-22B展示了“LLM-like”的视觉扩展的潜力,并为实现这一目标提供了关键步骤。

**[Paper URL](https://proceedings.mlr.press/v202/dehghani23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dehghani23a/dehghani23a.pdf)** 

# Efficient Bound of Lipschitz Constant for Convolutional Layers by Gram Iteration
**题目:** 格拉姆迭代对卷积层的利普希茨定数的有效边界

**作者:** Blaise Delattre, Quentin Barthélemy, Alexandre Araujo, Alexandre Allauzen

**Abstract:** Since the control of the Lipschitz constant has a great impact on the training stability, generalization, and robustness of neural networks, the estimation of this value is nowadays a real scientific challenge. In this paper we introduce a precise, fast, and differentiable upper bound for the spectral norm of convolutional layers using circulant matrix theory and a new alternative to the Power iteration. Called the Gram iteration, our approach exhibits a superlinear convergence. First, we show through a comprehensive set of experiments that our approach outperforms other state-of-the-art methods in terms of precision, computational cost, and scalability. Then, it proves highly effective for the Lipschitz regularization of convolutional neural networks, with competitive results against concurrent approaches.

**摘要:** 由于利普希茨常数的控制对神经网络的训练稳定性、一般化和鲁棒性有很大影响,因此该值的估计是当今一个真正的科学挑战。本文介绍一种使用循环矩阵理论和一种新的 Power迭代的替代方案来确定卷积层光谱规范的精确、快速和可微分的上限。我们称之为Gram迭代,我们的方法显示出超线性收敛性。首先,我们通过一系列综合实验表明,我们的方法在精度、计算成本和可扩展性方面优于其他最先进的方法。

**[Paper URL](https://proceedings.mlr.press/v202/delattre23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/delattre23a/delattre23a.pdf)** 

# Blossom: an Anytime Algorithm for Computing Optimal Decision Trees
**题目:** 花朵:一种用于计算最佳决策树的任何时候算法

**作者:** Emir Demirović, Emmanuel Hebrard, Louis Jean

**Abstract:** We propose a simple algorithm to learn optimal decision trees of bounded depth. This algorithm is essentially an anytime version of the state-of-the-art dynamic programming approach. It has virtually no overhead compared to heuristic methods and is comparable to the best exact methods to prove optimality on most data sets. Experiments show that whereas existing exact methods hardly scale to deep trees, this algorithm learns trees comparable to standard heuristics without computational overhead, and can significantly improve their accuracy when given more computation time, even for deep trees.

**摘要:** 我们提出了一种简单的算法,以学习边界深度的最佳决策树。该算法基本上是最新动态编程方法的任何版本。它实际上没有与热力学方法相比的开支,并且与最优的最精确方法相比较,以证明最优的大多数数据集。实验表明,虽然现有的精确方法很难 scale to deep trees,但该算法在没有计算开支的情况下,可以与标准热力学方法相比较的树学习,并且在给予更多的计算时间时,甚至对深树也能显著提高它们的精度。

**[Paper URL](https://proceedings.mlr.press/v202/demirovic23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/demirovic23a/demirovic23a.pdf)** 

# Optimizing NOTEARS Objectives via Topological Swaps
**题目:** 通过拓扑交换优化注释目标

**作者:** Chang Deng, Kevin Bello, Bryon Aragam, Pradeep Kumar Ravikumar

**Abstract:** Recently, an intriguing class of non-convex optimization problems has emerged in the context of learning directed acyclic graphs (DAGs). These problems involve minimizing a given loss or score function, subject to a non-convex continuous constraint that penalizes the presence of cycles in a graph. In this work, we delve into the optimality challenges associated with this class of non-convex programs. To address these challenges, we propose a bi-level algorithm that leverages the non-convex constraint in a novel way. The outer level of the algorithm optimizes over topological orders by iteratively swapping pairs of nodes within the topological order of a DAG. A key innovation of our approach is the development of an effective method for generating a set of candidate swapping pairs for each iteration. At the inner level, given a topological order, we utilize off-the-shelf solvers that can handle linear constraints. The key advantage of our proposed algorithm is that it is guaranteed to find a local minimum or a KKT point under weaker conditions compared to previous work and finds solutions with lower scores. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches in terms of achieving a better score. Additionally, our method can also be used as a post-processing algorithm to significantly improve the score of other algorithms. Code implementing the proposed method is available at https://github.com/duntrain/topo.

**摘要:** 近来,在学习指向环形图(DAG)方面出现了一种具有吸引力的类别非凸优化问题,这些问题涉及最小化给定的损失或分数函数,受非凸连续约束约束,从而惩罚图中循环的存在。在这个工作中,我们深入研究与该类非凸程序有关的优化挑战。为了解决这些挑战,我们提出了一种双级算法,以一种新颖的方式利用非凸约束。该算法的外层水平通过在DAG的拓扑顺序中迭代交换节点的双对优化。我们的方法的一个关键创新是开发一种有效的方法来生成每个迭代的候选交换双对。我们的提议算法的关键优势是,它可以保证在较弱的条件下找到局部最低值或KKT点,并找到较低分数的解决方案。广泛的实验表明,我们的方法在取得较好的分数方面比最先进的方法高。此外,我们的方法也可以作为后处理算法,以显著改善其他算法的分数。

**[Paper URL](https://proceedings.mlr.press/v202/deng23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/deng23a/deng23a.pdf)** 

# Uncertainty Estimation by Fisher Information-based Evidential Deep Learning
**题目:** 基于鱼类信息的证据深入学习的不确定性估计

**作者:** Danruo Deng, Guangyong Chen, Yang Yu, Furui Liu, Pheng-Ann Heng

**Abstract:** Uncertainty estimation is a key factor that makes deep learning reliable in practical applications. Recently proposed evidential neural networks explicitly account for different uncertainties by treating the network’s outputs as evidence to parameterize the Dirichlet distribution, and achieve impressive performance in uncertainty estimation. However, for high data uncertainty samples but annotated with the one-hot label, the evidence-learning process for those mislabeled classes is over-penalized and remains hindered. To address this problem, we propose a novel method, Fisher Information-based Evidential Deep Learning ($\mathcal{I}$-EDL). In particular, we introduce Fisher Information Matrix (FIM) to measure the informativeness of evidence carried by each sample, according to which we can dynamically reweight the objective loss terms to make the network more focus on the representation learning of uncertain classes. The generalization ability of our network is further improved by optimizing the PAC-Bayesian bound. As demonstrated empirically, our proposed method consistently outperforms traditional EDL-related algorithms in multiple uncertainty estimation tasks, especially in the more challenging few-shot classification settings.

**摘要:** 不确定估计是使深层学习在实际应用中可靠的一个关键因素。最近提出的证据神经网络 explicitly account for different uncertainties by treating the network’s outputs as evidence to parameterize the Dirichlet distribution, and achieve impressive performance in uncertainty estimation。然而,对于高数据不确定样本,但带有一个热标记的样本,这些误标记类的证据学习过程被过分惩罚和阻碍。为了解决这个问题,我们提出了一种新方法,即基于Fisher信息的证据深层学习($\mathcal{I}$-EDL)。通过优化PAC-Bayesian边界,进一步改进了我们的网络的一般化能力。正如实验证明的那样,我们提出的方法在多个不确定性估计任务中,特别是在较难的少数射击分类设置中,一致地超过传统的EDL相关算法。

**[Paper URL](https://proceedings.mlr.press/v202/deng23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/deng23b/deng23b.pdf)** 

# Multi-channel Autobidding with Budget and ROI Constraints
**题目:** 预算和ROI约束的多通道自动调用

**作者:** Yuan Deng, Negin Golrezaei, Patrick Jaillet, Jason Cheuk Nam Liang, Vahab Mirrokni

**Abstract:** In digital online advertising, advertisers procure ad impressions simultaneously on multiple platforms, or so-called channels, such as Google Ads, Meta Ads Manager, etc., each of which consists of numerous ad auctions. We study how an advertiser maximizes total conversion (e.g. ad clicks) while satisfying aggregate return-on-investment (ROI) and budget constraints across all channels. In practice, an advertiser does not have control over, and thus cannot globally optimize, which individual ad auctions she participates in for each channel, and instead authorizes a channel to procure impressions on her behalf: the advertiser can only utilize two levers on each channel, namely setting a per-channel budget and per-channel target ROI. In this work, we first analyze the effectiveness of each of these levers for solving the advertiser’s global multi-channel problem. We show that when an advertiser only optimizes over per-channel ROIs, her total conversion can be arbitrarily worse than what she could have obtained in the global problem. Further, we show that the advertiser can achieve the global optimal conversion when she only optimizes over per-channel budgets. In light of this finding, under a bandit feedback setting that mimics real-world scenarios where advertisers have limited information on ad auctions in each channels and how channels procure ads, we present an efficient learning algorithm that produces per-channel budgets whose resulting conversion approximates that of the global optimal problem.

**摘要:** 在数字在线广告中,广告商在多个平台或所谓的渠道中同时获取广告效果,例如Google Ads、Meta Ads Manager等,每个渠道都包含大量的广告拍卖。我们研究广告商如何最大化总转换(例如广告点击),同时满足所有渠道的总回报(ROI)和预算约束。结果表明,当一个广告商仅在每通道 ROIs 上优化时,其总体转换可能比其在全球问题中所取得的更糟。此外,我们还表明,当广告商仅在每通道预算上优化时,其可以实现全球最佳转换。

**[Paper URL](https://proceedings.mlr.press/v202/deng23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/deng23c/deng23c.pdf)** 

# Surrogate Module Learning: Reduce the Gradient Error Accumulation in Training Spiking Neural Networks
**题目:** 替代模块学习:在训练诱导神经网络中减少梯度误差累积

**作者:** Shikuang Deng, Hao Lin, Yuhang Li, Shi Gu

**Abstract:** Spiking neural networks provide an alternative solution to conventional artificial neural networks with energy-saving and high-efficiency characteristics after hardware implantation. However, due to its non-differentiable activation function and the temporally delayed accumulation in outputs, the direct training of SNNs is extraordinarily tough even adopting a surrogate gradient to mimic the backpropagation. For SNN training, this non-differentiability causes the intrinsic gradient error that would be magnified through layerwise backpropagation, especially through multiple layers. In this paper, we propose a novel approach to reducing gradient error from a new perspective called surrogate module learning (SML). Surrogate module learning tries to construct a shortcut path to back-propagate more accurate gradient to a certain SNN part utilizing the surrogate modules. Then, we develop a new loss function for concurrently training the network and enhancing the surrogate modules’ surrogate capacity. We demonstrate that when the outputs of surrogate modules are close to the SNN output, the fraction of the gradient error drops significantly. Our method consistently and significantly enhances the performance of SNNs on all experiment datasets, including CIFAR-10/100, ImageNet, and ES-ImageNet. For example, for spiking ResNet-34 architecture on ImageNet, we increased the SNN accuracy by 3.46%.

**摘要:** 刺激神经网络是传统人工神经网络的替代方案,具有节能和高效率的特点,但由于其非可区分的活化功能和产出时间延迟的累积,SNN的直接训练非常困难,甚至采用替代梯度来模仿背向运动。对于SNN的训练,这种非区分性会导致通过层级背向运动放大的内在梯度误差,特别是通过多个层级。然后,我们开发了一个新的损耗函数,用于同时培训网络和增强代理模块的代理能力。我们证明,当代理模块的输出接近SNN输出时,梯度误差的比重显著下降。我们的方法一致和显著地提高了所有实验数据集的SNN性能,包括CIFAR-10/100、ImageNet和ES-ImageNet。例如,在ImageNet上 spikingResNet-34架构时,我们增加了SNN精度3.46%。

**[Paper URL](https://proceedings.mlr.press/v202/deng23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/deng23d/deng23d.pdf)** 

# Confidence and Dispersity Speak: Characterizing Prediction Matrix for Unsupervised Accuracy Estimation
**题目:** 自信与扩散论:无监督准确估计的特征预测矩阵

**作者:** Weijian Deng, Yumin Suh, Stephen Gould, Liang Zheng

**Abstract:** This work aims to assess how well a model performs under distribution shifts without using labels. While recent methods study prediction confidence, this work reports prediction dispersity is another informative cue. Confidence reflects whether the individual prediction is certain; dispersity indicates how the overall predictions are distributed across all categories. Our key insight is that a well-performing model should give predictions with high confidence and high dispersity. That is, we need to consider both properties so as to make more accurate estimates. To this end, we use nuclear norm that has been shown to be effective in characterizing both properties. Extensive experiments validate the effectiveness of nuclear norm for various models (e.g., ViT and ConvNeXt), different datasets (e.g., ImageNet and CUB-200), and diverse types of distribution shifts (e.g., style shift and reproduction shift). We show that nuclear norm is more accurate and robust in accuracy estimation than existing methods. Furthermore, we validate the feasibility of other measurements (e.g., mutual information maximization) for characterizing dispersity and confidence. Lastly, we investigate the limitation of the nuclear norm, study its improved variant under severe class imbalance, and discuss potential directions.

**摘要:** 本研究旨在评估一个模型在使用标签的情况下在分布变换下的表现如何。虽然最近的方法研究预测信心,但该研究报告的预测分散性是另一个信息提示。自信反映了个体预测是否确定;分散性表明总体预测如何分布在所有类别中。我们的关键洞察是,一个有良好表现的模型应该给出具有高自信和高分散性的预测。也就是说,我们需要考虑两个特性,以便作出更准确的估计。为此目的,我们使用核规范,它已经证明在描述两个特性方面有效。广泛的实验验证了不同模型(例如ViT和ConvNeXt),不同数据集(例如ImageNet和CUB-200)以及不同的类型的分布变换(例如风格变换和复制变换)。最后,对核标准的局限性进行了研究,研究了在严重类别失衡下核标准的改进变量,探讨了核标准的可能方向。

**[Paper URL](https://proceedings.mlr.press/v202/deng23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/deng23e/deng23e.pdf)** 

# Great Models Think Alike: Improving Model Reliability via Inter-Model Latent Agreement
**题目:** 伟大的模型思考同样:通过模型互许协议提高模型可靠性

**作者:** Ailin Deng, Miao Xiong, Bryan Hooi

**Abstract:** Reliable application of machine learning is of primary importance to the practical deployment of deep learning methods. A fundamental challenge is that models are often unreliable due to overconfidence. In this paper, we estimate a model’s reliability by measuring the agreement between its latent space, and the latent space of a foundation model. However, it is challenging to measure the agreement between two different latent spaces due to their incoherence, e.g., arbitrary rotations and different dimensionality. To overcome this incoherence issue, we design a neighborhood agreement measure between latent spaces and find that this agreement is surprisingly well-correlated with the reliability of a model’s predictions. Further, we show that fusing neighborhood agreement into a model’s predictive confidence in a post-hoc way significantly improves its reliability. Theoretical analysis and extensive experiments on failure detection across various datasets verify the effectiveness of our method on both in-distribution and out-of-distribution settings.

**摘要:** 机器学习的可靠应用对深入学习方法的实际应用具有重要意义。一个基本的挑战是,模型往往由于过度自信而不可靠。本论文通过测量其潜在空间和基础模型的潜在空间之间的协议来估计模型的可靠性。然而,由于它们的不一致性,例如任意旋转和不同维度,很难测量两个不同潜在空间之间的协议。为了克服这种不一致性问题,我们设计了一个潜在空间之间的邻域协议测量,发现这种协议与模型预测的可靠性有着惊人的密切关系。理论分析和各种数据集中故障检测的广泛实验验证了我们的方法在分布中和分布外设置中的效果。

**[Paper URL](https://proceedings.mlr.press/v202/deng23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/deng23f/deng23f.pdf)** 

# Hyperbolic Image-text Representations
**题目:** 高分子图像-文本表示

**作者:** Karan Desai, Maximilian Nickel, Tanmay Rajpurohit, Justin Johnson, Shanmukha Ramakrishna Vedantam

**Abstract:** Visual and linguistic concepts naturally organize themselves in a hierarchy, where a textual concept "dog" entails all images that contain dogs. Despite being intuitive, current large-scale vision and language models such as CLIP do not explicitly capture such hierarchy. We propose MERU, a contrastive model that yields hyperbolic representations of images and text. Hyperbolic spaces have suitable geometric properties to embed tree-like data, so MERU can better capture the underlying hierarchy in image-text datasets. Our results show that MERU learns a highly interpretable and structured representation space while being competitive with CLIP’s performance on standard multi-modal tasks like image classification and image-text retrieval.

**摘要:** 视觉和语言概念自然地组织在层次结构中,在文本概念“狗”中包含所有包含狗的图像。尽管直观,目前的大规模视觉和语言模型如CLIP并不明确地捕捉这种层次结构。我们提出了MERU,一种与CLIP在图像分类和图像文本检索等标准多模态任务中具有竞争性的对比模型。

**[Paper URL](https://proceedings.mlr.press/v202/desai23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/desai23a/desai23a.pdf)** 

# Hardware-Aware Compression with Random Operation Access Specific Tile (ROAST) Hashing
**题目:** 基于随机操作访问特有瓦(ROAST) Hashing的硬件意识压缩

**作者:** Aditya Desai, Keren Zhou, Anshumali Shrivastava

**Abstract:** Advancements in deep learning are often associated with increasing model sizes. Training and deploying large models require sophisticated hardware and incur significantly higher costs. Thus, model compression is a widely explored approach to solving the problem. However, SOTA techniques fall short in one or more desirable aspects of compression - for instance, pruning does not reduce memory for training, quantization can only provide up to 32$\times$ compression, HashedNet is cache-inefficient, etc. This paper proposes a model-agnostic, cache-friendly, and hardware-aware model compression approach: Random Operation Access Specific Tile (ROAST) hashing. ROAST collapses the parameters by clubbing them through a lightweight mapping. While clubbing these parameters, ROAST utilizes cache hierarchies by aligning the memory access pattern with the parameter access pattern. ROAST is up to ${\sim}25\times$ faster to train and ${\sim}50\times$ faster to infer than the popular parameter sharing method HashedNet. Additionally, ROAST introduces global weight sharing, which is empirically and theoretically superior to local weight sharing in HashedNet, and can be of independent interest. With ROAST, we can efficiently train and deploy the model using a much smaller memory footprint ($\sim 10 - 100\times$ lesser) in text and image classification tasks. ROAST-MM kernel implementation is open-source (https://github.com/apd10/RzLinear/tree/stable)

**摘要:** 深度学习的进步往往与模型尺寸的增加有关。培训和部署大型模型需要精巧的硬件,并承受高昂的成本。因此,模型压缩是解决问题的一个广泛研究的途径。然而,SOTA技术在压缩的一个或多个可望方面不足 - 例如,剪切不减少训练的内存,定量化只能提供32$\times$的压缩,HashedNet是缓存效率低的等等。ROAST的训练速度快于${\sim}25\times$,推测速度快于${\sim}50\times$,比流行的参数共享方法HashedNet。此外,ROAST引入了全球权重共享,它在经验上和理论上优于HashedNet的本地权重共享,并且可以具有独立的兴趣。

**[Paper URL](https://proceedings.mlr.press/v202/desai23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/desai23b/desai23b.pdf)** 

# The case for 4-bit precision: k-bit Inference Scaling Laws
**题目:** 四位精度的案例:k位ference Scaling Laws

**作者:** Tim Dettmers, Luke Zettlemoyer

**Abstract:** Quantization methods reduce the number of bits required to represent each parameter in a model, trading accuracy for smaller memory footprints and inference latencies. However, the final model size depends on both the number of parameters of the original model and the rate of compression. For example, a 30B 8-bit model and a 60B 4-bit model have the same number of bits but may have very different zero-shot accuracies. In this work, we study this trade-off by developing inference scaling laws of zero-shot performance in Large Language Models (LLMs) to determine the bit-precision and model size that maximizes zero-shot performance. We run more than 35,000 experiments with 16-bit inputs and k-bit parameters to examine which zero-shot quantization methods improve scaling for 3 to 8-bit precision at scales of 19M to 176B parameters across the LLM families BLOOM, OPT, NeoX/Pythia, and GPT-2. We find that it is challenging to improve the bit-level scaling trade-off, with the only improvements being the use of a small block size – splitting the parameters into small independently quantized blocks – and the quantization data type being used (e.g., Int vs Float). Overall, our findings show that 4-bit precision is almost universally optimal for total model bits and zero-shot accuracy.

**摘要:** 量化方法可以减少模型中每个参数的数量,以减少存储脚印和推导延迟的交易精度。然而,最终模型大小取决于原始模型的参数数目和压缩率。例如,30B 8-bit模型和60B 4-bit模型具有相同的数量的位数,但可能具有非常不同的零射击精度。在这个工作中,我们研究了用大语言模型(LLMs)中零射击性能推导分级法来确定零射击性能最大化的比特精度和模型大小。我们发现,改进 bit-level scaling trade-off具有挑战性,唯一的改进是使用小块大小 — — 将参数分成独立量化的小块 — — 和使用量化数据类型(例如Int vs Float)。

**[Paper URL](https://proceedings.mlr.press/v202/dettmers23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dettmers23a/dettmers23a.pdf)** 

# Fairness in Matching under Uncertainty
**题目:** 在不确定情况下匹配的公平

**作者:** Siddartha Devic, David Kempe, Vatsal Sharan, Aleksandra Korolova

**Abstract:** The prevalence and importance of algorithmic two-sided marketplaces has drawn attention to the issue of fairness in such settings. Algorithmic decisions are used in assigning students to schools, users to advertisers, and applicants to job interviews. These decisions should heed the preferences of individuals, and simultaneously be fair with respect to their merits (synonymous with fit, future performance, or need). Merits conditioned on observable features are always uncertain, a fact that is exacerbated by the widespread use of machine learning algorithms to infer merit from the observables. As our key contribution, we carefully axiomatize a notion of individual fairness in the two-sided marketplace setting which respects the uncertainty in the merits; indeed, it simultaneously recognizes uncertainty as the primary potential cause of unfairness and an approach to address it. We design a linear programming framework to find fair utility-maximizing distributions over allocations, and we show that the linear program is robust to perturbations in the estimated parameters of the uncertain merit distributions, a key property in combining the approach with machine learning techniques.

**摘要:** 基于可观察特征的功绩总是不确定,这是由于广泛应用机器学习算法来从可观察的功绩推断功绩而加剧的事实。 作为我们的关键贡献,我们仔细考虑了在两边市场环境中尊重功绩的不确定的个人公平的概念;事实上,它同时认识到不确定是不公平的主要潜在原因和解决方法。我们设计了线性编程框架,以找到公平的实用最大化分配比分配的分配,并表明线性程序对不确定的功绩分配估计参数的扰动是强有力的,这是结合方法和机器学习技术的关键特性。

**[Paper URL](https://proceedings.mlr.press/v202/devic23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/devic23a/devic23a.pdf)** 

# Efficient Parametric Approximations of Neural Network Function Space Distance
**题目:** 神经网络功能空间距离的有效参数近似

**作者:** Nikita Dhawan, Sicong Huang, Juhan Bae, Roger Baker Grosse

**Abstract:** It is often useful to compactly summarize important properties of model parameters and training data so that they can be used later without storing and/or iterating over the entire dataset. As a specific case, we consider estimating the Function Space Distance (FSD) over a training set, i.e. the average discrepancy between the outputs of two neural networks. We propose a Linearized Activation Function TRick (LAFTR) and derive an efficient approximation to FSD for ReLU neural networks. The key idea is to approximate the architecture as a linear network with stochastic gating. Despite requiring only one parameter per unit of the network, our approach outcompetes other parametric approximations with larger memory requirements. Applied to continual learning, our parametric approximation is competitive with state-of-the-art nonparametric approximations, which require storing many training examples. Furthermore, we show its efficacy in estimating influence functions accurately and detecting mislabeled examples without expensive iterations over the entire dataset.

**摘要:** 对模型参数和训练数据的重要特性进行简洁的总结,以便在整个数据集中不存储和/或迭代后再使用。作为具体例,我们考虑在训练集上估计函数空间距离(FSD),即两个神经网络的输出的平均差异。我们提出了线性化激活函数TRick(LAFTR)并为ReLU神经网络提取FSD的有效近似。关键思想是将结构与随机抽取的线性网络近似。尽管需要网络单元仅一个参数,但我们的方法比其他更大的内存要求的参数近似更优。此外,我们证明了它在准确估计影响函数和检测错误标记的实例时的有效性,而无需在整个数据集上进行昂贵的迭代。

**[Paper URL](https://proceedings.mlr.press/v202/dhawan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dhawan23a/dhawan23a.pdf)** 

# A Large-Scale Study of Probabilistic Calibration in Neural Network Regression
**题目:** 神经网络回归的概率校正研究

**作者:** Victor Dheur, Souhaib Ben Taieb

**Abstract:** Accurate probabilistic predictions are essential for optimal decision making. While neural network miscalibration has been studied primarily in classification, we investigate this in the less-explored domain of regression. We conduct the largest empirical study to date to assess the probabilistic calibration of neural networks. We also analyze the performance of recalibration, conformal, and regularization methods to enhance probabilistic calibration. Additionally, we introduce novel differentiable recalibration and regularization methods, uncovering new insights into their effectiveness. Our findings reveal that regularization methods offer a favorable tradeoff between calibration and sharpness. Post-hoc methods exhibit superior probabilistic calibration, which we attribute to the finite-sample coverage guarantee of conformal prediction. Furthermore, we demonstrate that quantile recalibration can be considered as a specific case of conformal prediction. Our study is fully reproducible and implemented in a common code base for fair comparisons.

**摘要:** 精确的概率预测是最佳决策的关键。虽然神经网络误校正主要研究于分类中,但我们对这种误校正进行了较少研究的回归领域研究。我们对神经网络的概率校正进行了最大实证研究。我们还分析了校正、校正和校正方法的性能,以提高概率校正。此外,我们引入了新的可微分校正和校正方法,揭示了这些方法的有效性。我们的研究是完全可重复的,并在共同的代码基础中实现公平的比较。

**[Paper URL](https://proceedings.mlr.press/v202/dheur23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dheur23a/dheur23a.pdf)** 

# Nearly Minimax Optimal Regret for Learning Linear Mixture Stochastic Shortest Path
**题目:** 学习线性混合物随机最短路径的几乎最小优化遗憾

**作者:** Qiwei Di, Jiafan He, Dongruo Zhou, Quanquan Gu

**Abstract:** We study the Stochastic Shortest Path (SSP) problem with a linear mixture transition kernel, where an agent repeatedly interacts with a stochastic environment and seeks to reach certain goal state while minimizing the cumulative cost. Existing works often assume a strictly positive lower bound of the cost function or an upper bound of the expected length for the optimal policy. In this paper, we propose a new algorithm to eliminate these restrictive assumptions. Our algorithm is based on extended value iteration with a fine-grained variance-aware confidence set, where the variance is estimated recursively from high-order moments. Our algorithm achieves an $\tilde{\mathcal{O}}(dB_*\sqrt{K})$ regret bound, where $d$ is the dimension of the feature mapping in the linear transition kernel, $B_*$ is the upper bound of the total cumulative cost for the optimal policy, and $K$ is the number of episodes. Our regret upper bound matches the $\Omega(dB_*\sqrt{K})$ lower bound of linear mixture SSPs in Min et al. (2022), which suggests that our algorithm is nearly minimax optimal.

**摘要:** 我们研究了线性混合过渡核的随机最短路径(SSP)问题,其中一个代理 repeatedly interacts with a stochastic environment and seeks to reach certain goal state while minimizing the cumulative cost. Existing works often assume a strictly positive lower bound of the cost function or an upper bound of the expected length for the optimal policy. In this paper, we propose a new algorithm to eliminate these restrictive assumptions. Our algorithm is based on extended value iteration with a fine-grained variance-aware confidence set, where the variance is estimated recursively from high-order moments. Our algorithm achieves a $\tilde{\mathcal{O}}(dB_*\sqrt{K})$ regret bound, where $d$ is the dimension of the feature mapping in the linear transition kernel,我们的遗憾上界与Min 等人(2022)的线性混合SPs $\Omega(dB_*\sqrt{K})$下界匹配,这表明我们的算法几乎是最小最优。

**[Paper URL](https://proceedings.mlr.press/v202/di23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/di23a/di23a.pdf)** 

# On Over-Squashing in Message Passing Neural Networks: The Impact of Width, Depth, and Topology
**题目:** 信息传递神经网络中的过度干扰:宽度、深度和拓扑的影响

**作者:** Francesco Di Giovanni, Lorenzo Giusti, Federico Barbero, Giulia Luise, Pietro Lio, Michael M. Bronstein

**Abstract:** Message Passing Neural Networks (MPNNs) are instances of Graph Neural Networks that leverage the graph to send messages over the edges. This inductive bias leads to a phenomenon known as over-squashing, where a node feature is insensitive to information contained at distant nodes. Despite recent methods introduced to mitigate this issue, an understanding of the causes for over-squashing and of possible solutions are lacking. In this theoretical work, we prove that: (i) Neural network width can mitigate over-squashing, but at the cost of making the whole network more sensitive; (ii) Conversely, depth cannot help mitigate over-squashing: increasing the number of layers leads to over-squashing being dominated by vanishing gradients; (iii) The graph topology plays the greatest role, since over-squashing occurs between nodes at high commute time. Our analysis provides a unified framework to study different recent methods introduced to cope with over-squashing and serves as a justification for a class of methods that fall under graph rewiring.

**摘要:** 信息传递神经网络(MPNNs)是 Graph Neural Networks 的实例,它利用图形来传递消息。这种诱导性偏见导致了被称为超散的现象,其中一个节点特征对位于远程节点中的信息不敏感。尽管最近引入了方法来缓解这个问题,对超散的原因和可能解决办法的理解不足。本文的分析提供了一种统一的框架,以研究处理过分浪费的各种新方法,并为属于图再配线的类别提供依据。

**[Paper URL](https://proceedings.mlr.press/v202/di-giovanni23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/di-giovanni23a/di-giovanni23a.pdf)** 

# Nearly-Linear Time and Streaming Algorithms for Outlier-Robust PCA
**题目:** 近线性时间和流域算法

**作者:** Ilias Diakonikolas, Daniel Kane, Ankit Pensia, Thanasis Pittas

**Abstract:** We study principal component analysis (PCA), where given a dataset in $\mathbb R^d$ from a distribution, the task is to find a unit vector $v$ that approximately maximizes the variance of the distribution after being projected along $v$. Despite being a classical task, standard estimators fail drastically if the data contains even a small fraction of outliers, motivating the problem of robust PCA. Recent work has developed computationally-efficient algorithms for robust PCA that either take super-linear time or have sub-optimal error guarantees. Our main contribution is to develop a nearly linear time algorithm for robust PCA with near-optimal error guarantees. We also develop a single-pass streaming algorithm for robust PCA with memory usage nearly-linear in the dimension.

**摘要:** 本文研究了主要组件分析(PCA),从分布式$\mathbb R^d$中给出的数据集,其任务是找到一个单位向量$v$,在$v$沿线投影后大约最大化分布的变量。虽然这是一个经典的任务,标准估计器如果数据包含微小偏差,则会严重失败,从而引发了鲁棒PCA的问题。最近的工作已经开发了计算效率高的鲁棒PCA算法,它们 either take super-linear time or have sub-optimal error guarantees。我们的主要贡献是为鲁棒PCA开发近线性时间算法,具有近最佳错误保证。

**[Paper URL](https://proceedings.mlr.press/v202/diakonikolas23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/diakonikolas23a/diakonikolas23a.pdf)** 

# Near-Optimal Cryptographic Hardness of Agnostically Learning Halfspaces and ReLU Regression under Gaussian Marginals
**题目:** 高斯边界下渐进学习半空间和ReLU回归的 near-optimal暗号硬度

**作者:** Ilias Diakonikolas, Daniel Kane, Lisheng Ren

**Abstract:** We study the task of agnostically learning halfspaces under the Gaussian distribution. Specifically, given labeled examples $(\\mathbf{x},y)$ from an unknown distribution on $\\mathbb{R}^n \\times \\{\pm 1 \\}$, whose marginal distribution on $\\mathbf{x}$ is the standard Gaussian and the labels $y$ can be arbitrary, the goal is to output a hypothesis with 0-1 loss $\\mathrm{OPT}+\\epsilon$, where $\\mathrm{OPT}$ is the 0-1 loss of the best-fitting halfspace. We prove a near-optimal computational hardness result for this task, under the widely believed sub-exponential time hardness of the Learning with Errors (LWE) problem. Prior hardness results are either qualitatively suboptimal or apply to restricted families of algorithms. Our techniques extend to yield near-optimal lower bounds for related problems, including ReLU regression.

**摘要:** 我们研究Gaussian分布下无知学习半空间的任务。具体而言,给出标记例$(\\mathbf{x},y)$从$\\mathbb{R}^n\\times上的未知分布中,其边缘分布$\\mathbf{x}$是标准Gaussian分布,标记$y$可以任意,目标是输出0-1损失的假设$\\mathrm{OPT}+\\epsilon$,其中$\\mathrm{OPT}$是最佳半空间0-1损失的假设。我们证明了这个任务的 near-optimal计算硬度结果,在被广泛认为的误差学习(LWE)问题下。

**[Paper URL](https://proceedings.mlr.press/v202/diakonikolas23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/diakonikolas23b/diakonikolas23b.pdf)** 

# Improving Graph Generation by Restricting Graph Bandwidth
**题目:** 通过限制图带宽改进图形生成

**作者:** Nathaniel Lee Diamant, Alex M Tseng, Kangway V. Chuang, Tommaso Biancalani, Gabriele Scalia

**Abstract:** Deep graph generative modeling has proven capable of learning the distribution of complex, multi-scale structures characterizing real-world graphs. However, one of the main limitations of existing methods is their large output space, which limits generation scalability and hinders accurate modeling of the underlying distribution. To overcome these limitations, we propose a novel approach that significantly reduces the output space of existing graph generative models. Specifically, starting from the observation that many real-world graphs have low graph bandwidth, we restrict graph bandwidth during training and generation. Our strategy improves both generation scalability and quality without increasing architectural complexity or reducing expressiveness. Our approach is compatible with existing graph generative methods, and we describe its application to both autoregressive and one-shot models. We extensively validate our strategy on synthetic and real datasets, including molecular graphs. Our experiments show that, in addition to improving generation efficiency, our approach consistently improves generation quality and reconstruction accuracy. The implementation is made available.

**摘要:** 深层图形生成模型已经证明能够学习复杂、多尺度结构特征的现实图形分布。然而,现有方法的主要局限性之一是其巨大的输出空间,这限制了生成的可扩展性和阻碍了基本分布的准确建模。为了克服这些局限性,我们提出了一种新的方法,大大降低了现有图形生成模型的输出空间。具体而言,从许多现实图形具有低图形带宽的观察出发,我们在训练和生成过程中限制了图形带宽。我们对包括分子图在内的合成数据和实数据集的策略进行了广泛的验证。我们的实验表明,除了提高发电效率外,我们的方法也不断提高发电质量和重建精度。

**[Paper URL](https://proceedings.mlr.press/v202/diamant23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/diamant23a/diamant23a.pdf)** 

# Forward-Backward Gaussian Variational Inference via JKO in the Bures-Wasserstein Space
**题目:** 布雷斯-瓦塞尔斯坦空间的JKO向后高斯变量ference

**作者:** Michael Ziyang Diao, Krishna Balasubramanian, Sinho Chewi, Adil Salim

**Abstract:** Variational inference (VI) seeks to approximate a target distribution $\pi$ by an element of a tractable family of distributions. Of key interest in statistics and machine learning is Gaussian VI, which approximates $\pi$ by minimizing the Kullback-Leibler (KL) divergence to $\pi$ over the space of Gaussians. In this work, we develop the (Stochastic) Forward-Backward Gaussian Variational Inference (FB-GVI) algorithm to solve Gaussian VI. Our approach exploits the composite structure of the KL divergence, which can be written as the sum of a smooth term (the potential) and a non-smooth term (the entropy) over the Bures-Wasserstein (BW) space of Gaussians endowed with the Wasserstein distance. For our proposed algorithm, we obtain state-of-the-art convergence guarantees when $\pi$ is log-smooth and log-concave, as well as the first convergence guarantees to first-order stationary solutions when $\pi$ is only log-smooth.

**摘要:** 变量推导(VI)旨在通过一个可处理的分布家族的元素近似目标分布$\pi$。在统计和机器学习中,主要的兴趣是高斯sian VI,它通过最小化高斯sians空间上的Kullback-Leibler(KL)偏差$\pi$。在这个工作中,我们开发了高斯sian VI的(Stochastic)Forward-Backward高斯sian Variational Inference(FB-GVI)算法,以求解高斯sian VI。我们的方法利用高斯sians Bures-Wasserstein(BW)空间上的平滑术语(势头)和非平滑术语(熵)的复合结构,可以写成与Waterstein距离有关的平滑术语的总数。

**[Paper URL](https://proceedings.mlr.press/v202/diao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/diao23a/diao23a.pdf)** 

# Subset-Based Instance Optimality in Private Estimation
**题目:**  Private Estimation中基于子集的实例优化

**作者:** Travis Dick, Alex Kulesza, Ziteng Sun, Ananda Theertha Suresh

**Abstract:** We propose a new definition of instance optimality for differentially private estimation algorithms. Our definition requires an optimal algorithm to compete, simultaneously for every dataset $D$, with the best private benchmark algorithm that (a) knows $D$ in advance and (b) is evaluated by its worst-case performance on large subsets of $D$. That is, the benchmark algorithm need not perform well when potentially extreme points are added to $D$; it only has to handle the removal of a small number of real data points that already exist. This makes our benchmark significantly stronger than those proposed in prior work. We nevertheless show, for real-valued datasets, how to construct private algorithms that achieve our notion of instance optimality when estimating a broad class of dataset properties, including means, quantiles, and $\ell_p$-norm minimizers. For means in particular, we provide a detailed analysis and show that our algorithm simultaneously matches or exceeds the asymptotic performance of existing algorithms under a range of distributional assumptions.

**摘要:** 我们提出了一种不同的私人估计算法实例优化的新定义。我们的定义要求一个最佳算法同时对每个数据集$D$进行竞争,与最佳的私人基准算法(a)事先知道$D$和(b)在$D$的大型子集上评估其最坏情况。也就是说,基准算法在潜在极端点被添加到$D$时不需要很好地执行;它只需要处理已经存在的少数实际数据点的除去。这使得我们的基准比以前的工作更强。尽管如此,我们对实际值的数据集展示了如何构建私人算法来实现我们的实例优化概念,在估计数据集属性的广泛类别时,包括手段、数量和$\ell_p$-norm minimizers。针对手段,我们提供了详细的分析,并表明,我们算法在一系列分布假设下同时匹配或超过现有算法的渐近性能。

**[Paper URL](https://proceedings.mlr.press/v202/dick23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dick23a/dick23a.pdf)** 

# Pareto Manifold Learning: Tackling multiple tasks via ensembles of single-task models
**题目:** Pareto多重学习:通过单任务模型的组合来处理多个任务

**作者:** Nikolaos Dimitriadis, Pascal Frossard, François Fleuret

**Abstract:** In Multi-Task Learning (MTL), tasks may compete and limit the performance achieved on each other, rather than guiding the optimization to a solution, superior to all its single-task trained counterparts. Since there is often not a unique solution optimal for all tasks, practitioners have to balance tradeoffs between tasks’ performance, and resort to optimality in the Pareto sense. Most MTL methodologies either completely neglect this aspect, and instead of aiming at learning a Pareto Front, produce one solution predefined by their optimization schemes, or produce diverse but discrete solutions. Recent approaches parameterize the Pareto Front via neural networks, leading to complex mappings from tradeoff to objective space. In this paper, we conjecture that the Pareto Front admits a linear parameterization in parameter space, which leads us to propose Pareto Manifold Learning, an ensembling method in weight space. Our approach produces a continuous Pareto Front in a single training run, that allows to modulate the performance on each task during inference. Experiments on multi-task learning benchmarks, ranging from image classification to tabular datasets and scene understanding, show that Pareto Manifold Learning outperforms state-of-the-art single-point algorithms, while learning a better Pareto parameterization than multi-point baselines.

**摘要:** 在多任务学习(MTL)中,任务可以互相竞争并限制完成的性能,而不是引导优化到一个解决方案,优于所有其单任务训练的同类。由于对于所有任务往往没有唯一的优化解决方案,实践者必须平衡任务性能之间的权衡,并从帕雷托意义上寻求优化。大多数MTL方法要么完全忽略这一方面,要么针对学习帕雷托阵线,生成一个由其优化方案预定义的解决方案,要么产生不同的但离散的解决方案。通过对多任务学习基准的实验,从图像分类到表格数据集和场景理解,证明了帕雷托多重学习比多点基准更优于最先进的单点算法,同时学习了比多点基准更好的帕雷托参数化。

**[Paper URL](https://proceedings.mlr.press/v202/dimitriadis23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dimitriadis23a/dimitriadis23a.pdf)** 

# Bayesian Reparameterization of Reward-Conditioned Reinforcement Learning with Energy-based Models
**题目:** 基于能量模型的 reward-conditioned reinforcement learning的贝叶斯参数化

**作者:** Wenhao Ding, Tong Che, Ding Zhao, Marco Pavone

**Abstract:** Recently, reward-conditioned reinforcement learning (RCRL) has gained popularity due to its simplicity, flexibility, and off-policy nature. However, we will show that current RCRL approaches are fundamentally limited and fail to address two critical challenges of RCRL – improving generalization on high reward-to-go (RTG) inputs, and avoiding out-of-distribution (OOD) RTG queries during testing time. To address these challenges when training vanilla RCRL architectures, we propose Bayesian Reparameterized RCRL (BR-RCRL), a novel set of inductive biases for RCRL inspired by Bayes’ theorem. BR-RCRL removes a core obstacle preventing vanilla RCRL from generalizing on high RTG inputs – a tendency that the model treats different RTG inputs as independent values, which we term “RTG Independence". BR-RCRL also allows us to design an accompanying adaptive inference method, which maximizes total returns while avoiding OOD queries that yield unpredictable behaviors in vanilla RCRL methods. We show that BR-RCRL achieves state-of-the-art performance on the Gym-Mujoco and Atari offline RL benchmarks, improving upon vanilla RCRL by up to 11%.

**摘要:** 最近, reward-conditioned reinforcement learning(RCRL)由于其简单、灵活和非政策性质 gained popularity. However, we will show that current RCRL approaches are fundamentally limited and fail to address two critical challenges of RCRL – improving generalization on high reward-to-go (RTG) inputs, and avoiding out-of-distribution (OOD) RTG queries during testing time. To address these challenges when training vanilla RCRL architectures, we propose Bayesian Reparameterized RCRL (BR-RCRL), a novel set of inductive biases for RCRL inspired by Bayes’ theorem. BR-RCRL removes a core obstacle preventing vanilla RCRL from generalizing on high RTG inputs – a tendency that the model treats different RTG inputs as independent values, which we term “RTG Independence”. BR-RCBR-RCRL在 Gym-Mujoco 和 Atari 非线性 RL 的基准上达到最先进的性能,改善了Vanilla RCRL 的性能 jopa 11% 。

**[Paper URL](https://proceedings.mlr.press/v202/ding23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ding23a/ding23a.pdf)** 

# DSGD-CECA: Decentralized SGD with Communication-Optimal Exact Consensus Algorithm
**题目:** DSGD-CECA:基于通信优化的精确共识算法的分散式GD

**作者:** Lisang Ding, Kexin Jin, Bicheng Ying, Kun Yuan, Wotao Yin

**Abstract:** Decentralized Stochastic Gradient Descent (SGD) is an emerging neural network training approach that enables multiple agents to train a model collaboratively and simultaneously. Rather than using a central parameter server to collect gradients from all the agents, each agent keeps a copy of the model parameters and communicates with a small number of other agents to exchange model updates. Their communication, governed by the communication topology and gossip weight matrices, facilitates the exchange of model updates. The state-of-the-art approach uses the dynamic one-peer exponential-2 topology, achieving faster training times and improved scalability than the ring, grid, torus, and hypercube topologies. However, this approach requires a power-of-2 number of agents, which is impractical at scale. In this paper, we remove this restriction and propose Decentralized SGD with Communication-optimal Exact Consensus Algorithm (DSGD-CECA), which works for any number of agents while still achieving state-of-the-art properties. In particular, DSGD-CECA incurs a unit per-iteration communication overhead and an $\tilde{O}(n^3)$ transient iteration complexity. Our proof is based on newly discovered properties of gossip weight matrices and a novel approach to combine them with DSGD’s convergence analysis. Numerical experiments show the efficiency of DSGD-CECA.

**摘要:** 分散型随机梯度降落(英语:Decentralized Stochastic Gradient Descent,简称SGD)是一种新兴的神经网络训练方法,使多个代理人能够协同和同时训练模型。每个代理人使用中央参数服务器来收集梯度,每个代理人保留模型参数的拷贝,并与少数其他代理人交流模型更新。他们的通信,由通信拓扑和流言量矩阵管理,促进模型更新的交换。本文提出了一种基于通信优化的精确共识算法(DSGD-CECA)的分散式DSGD,该算法在实现最先端特性的同时,适用于任何数组代理。DSGD-CECA特别涉及一个单元每迭代通信总费用和一个 $\tilde{O}(n^3)$ 暂态迭代复杂性。我们的证明是基于新发现的 gossip weight matrices 的特性和一种新方法,将它们与DSGD的融合分析结合起来。

**[Paper URL](https://proceedings.mlr.press/v202/ding23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ding23b/ding23b.pdf)** 

# Open-Vocabulary Universal Image Segmentation with MaskCLIP
**题目:** 基于 MaskCLIP的开放口语通用图像分割

**作者:** Zheng Ding, Jieke Wang, Zhuowen Tu

**Abstract:** In this paper, we tackle an emerging computer vision task, open-vocabulary universal image segmentation, that aims to perform semantic/instance/panoptic segmentation (background semantic labeling + foreground instance segmentation) for arbitrary categories of text-based descriptions in inference time. We first build a baseline method by directly adopting pre-trained CLIP models without finetuning or distillation. We then develop MaskCLIP, a Transformer-based approach with a MaskCLIP Visual Encoder, which is an encoder-only module that seamlessly integrates mask tokens with a pre-trained ViT CLIP model for semantic/instance segmentation and class prediction. MaskCLIP learns to efficiently and effectively utilize pre-trained partial/dense CLIP features within the MaskCLIP Visual Encoder that avoids the time-consuming student-teacher training process. MaskCLIP outperforms previous methods for semantic/instance/panoptic segmentation on ADE20K and PASCAL datasets. We show qualitative illustrations for MaskCLIP with online custom categories. Project website: https://maskclip.github.io.

**摘要:** 本文针对一种新兴的计算机视觉任务,即基于语义/实例/泛光分割(背景语义标记+前置实例分割)的基于文本的任意类别的文本描述在推导时间,首先通过直接采用预训练的CLIP模型,而不进行微调或蒸馏,构建一个基线方法,然后开发 MaskCLIP,一种基于变换的基于 MaskCLIP视觉编码器的方法,该模块是仅编码器的模块,它将预训练的ViT CLIP模型用于语义/实例分割和类别预测的 MaskCLIP符号无缝地集成。 MaskCLIP学习在 MaskCLIP视觉编码器内有效地利用预训练的局部/浓密CLIP特征,避免耗时的学生-教师培训过程。我们为MaskCLIP提供在线定制类别的质量图示。项目网站: https://maskclip.github.io。

**[Paper URL](https://proceedings.mlr.press/v202/ding23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ding23c/ding23c.pdf)** 

# Entity Divider with Language Grounding in Multi-Agent Reinforcement Learning
**题目:** 多干事强化学习中语言基础的实体分担器

**作者:** Ziluo Ding, Wanpeng Zhang, Junpeng Yue, Xiangjun Wang, Tiejun Huang, Zongqing Lu

**Abstract:** We investigate the use of natural language to drive the generalization of policies in multi-agent settings. Unlike single-agent settings, the generalization of policies should also consider the influence of other agents. Besides, with the increasing number of entities in multi-agent settings, more agent-entity interactions are needed for language grounding, and the enormous search space could impede the learning process. Moreover, given a simple general instruction, e.g., beating all enemies, agents are required to decompose it into multiple subgoals and figure out the right one to focus on. Inspired by previous work, we try to address these issues at the entity level and propose a novel framework for language grounding in multi-agent reinforcement learning, entity divider (EnDi). EnDi enables agents to independently learn subgoal division at the entity level and act in the environment based on the associated entities. The subgoal division is regularized by agent modeling to avoid subgoal conflicts and promote coordinated strategies. Empirically, EnDi demonstrates the strong generalization ability to unseen games with new dynamics and expresses the superiority over existing methods. The code is available at https://github.com/PKU-RL/EnDi.

**摘要:** 我们研究了自然语言在多代理环境中的策略的一般化。与单代理环境不同,政策的一般化还应考虑其他代理的影响。此外,随着多代理环境中的实体数量的增加,语言基础需要更多的代理-实体交互,并且巨大的搜索空间可能阻碍学习过程。此外,给一个简单的一般指令,例如打败所有敌人,代理需要将其分解为多个子目标,并找出正确的目标。受先前的工作启发,我们试图在实体一级解决这些问题,并提出一种新的语言基础框架,用于多代理强化学习,实体分担器(EnDi)。EnDi允许代理在实体一级独立学习子目标分担,并在相关实体的基础上在环境中行动。子目标分配通过代理建模进行规范化,以避免子目标冲突和促进协调战略。 EnDi在实证上显示了与新动态无关的游戏具有很强的一般化能力,并表达了现有方法的优越性。

**[Paper URL](https://proceedings.mlr.press/v202/ding23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ding23d/ding23d.pdf)** 

# PixelAsParam: A Gradient View on Diffusion Sampling with Guidance
**题目:** PixelAsParam:基于指导的扩散采样的梯度视图

**作者:** Anh-Dung Dinh, Daochang Liu, Chang Xu

**Abstract:** Diffusion models recently achieved state-of-the-art in image generation. They mainly utilize the denoising framework, which leverages the Langevin dynamics process for image sampling. Recently, the guidance method has modified this process to add conditional information to achieve a controllable generator. However, the current guidance on denoising processes suffers from the trade-off between diversity, image quality, and conditional information. In this work, we propose to view this guidance sampling process from a gradient view, where image pixels are treated as parameters being optimized, and each mathematical term in the sampling process represents one update direction. This perspective reveals more insights into the conflict problems between updated directions on the pixels, which cause the trade-off as mentioned previously. We investigate the conflict problems and propose to solve them by a simple projection method. The experimental results evidently improve over different baselines on datasets with various resolutions.

**摘要:** 扩散模型最近在图像生成中实现了最先进的技术。它们主要使用了标记框架,利用兰格文动态过程进行标记。最近,标记方法修改了这个过程,以增加条件信息,实现可控生成器。然而,标记过程的当前指导 suffers from the trade-off between diversity, image quality, and conditional information. In this work, we propose to view this guidance sampling process from a gradient view, where image pixels are treated as parameters being optimized, and each mathematical term in the sampling process represents one update direction. This perspective reveals more insights into the conflict problems between updated directions on the pixels, which cause the trade-off as mentioned previously. We investigate the conflict problems and propose to solve them by a simple projection method.实验结果明显改善了不同分辨率的数据集的不同基线。

**[Paper URL](https://proceedings.mlr.press/v202/dinh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dinh23a/dinh23a.pdf)** 

# Second-Order Optimization with Lazy Hessians
**题目:** 二级优化与懒惰的希西亚人

**作者:** Nikita Doikov, El Mahdi Chayti, Martin Jaggi

**Abstract:** We analyze Newton’s method with lazy Hessian updates for solving general possibly non-convex optimization problems. We propose to reuse a previously seen Hessian for several iterations while computing new gradients at each step of the method. This significantly reduces the overall arithmetic complexity of second-order optimization schemes. By using the cubic regularization technique, we establish fast global convergence of our method to a second-order stationary point, while the Hessian does not need to be updated each iteration. For convex problems, we justify global and local superlinear rates for lazy Newton steps with quadratic regularization, which is easier to compute. The optimal frequency for updating the Hessian is once every $d$ iterations, where $d$ is the dimension of the problem. This provably improves the total arithmetic complexity of second-order algorithms by a factor $\sqrt{d}$.

**摘要:** 我们用懒惰的希西亚更新来分析牛顿方法,以解决一般可能的非凸优化问题。我们建议在每次方法步骤中计算新的梯度时,重新使用先前看到的希西亚步骤。这大大降低了第二阶优化方案的整体算术复杂度。通过使用立方规则化技术,我们建立了我们方法的快速全球收敛到第二阶静止点,而希西亚不需要每次迭代更新。对于凸问题,我们证明了懒惰的牛顿步骤的全球和局部超线性率和二次规则化,这更容易计算。

**[Paper URL](https://proceedings.mlr.press/v202/doikov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/doikov23a/doikov23a.pdf)** 

# Polynomial Preconditioning for Gradient Methods
**题目:** 梯度方法的多项式预备条件

**作者:** Nikita Doikov, Anton Rodomanov

**Abstract:** We study first-order methods with preconditioning for solving structured convex optimization problems. We propose a new family of preconditioners generated by the symmetric polynomials. They provide the first-order optimization methods with a provable improvement of the condition number, cutting the gaps between highest eigenvalues, without explicit knowledge of the actual spectrum. We give a stochastic interpretation of this preconditioning in terms of the coordinate volume sampling and compare it with other classical approaches, including the Chebyshev polynomials. We show how to incorporate a polynomial preconditioning into the Gradient and Fast Gradient Methods and establish their better global complexity bounds. Finally, we propose a simple adaptive search procedure that automatically ensures the best polynomial preconditioning for the Gradient Method, minimizing the objective along a low-dimensional Krylov subspace. Numerical experiments confirm the efficiency of our preconditioning strategies for solving various machine learning problems.

**摘要:** 我们研究了结构凸优化问题的初级预选方法。我们提出了由对称多项式生成的预选器的新家族。它们为初级优化方法提供了条件数的可证明改进,减少最高固有值之间的差距,而没有明确的实际频谱知识。我们给出了坐标体采样的这种预选方法的随机解释,并与其他经典方法,包括切比谢夫多项式,比较。我们展示了如何将多项式预选方法纳入梯度和快速梯度方法,并建立其更好的全球复杂度边界。最后,我们提出了一种简单的适应性搜索程序,它自动确保梯度方法的最佳多项式预选,使目标在低维克里洛夫子空间范围内最小化。数值实验证实了我们解决各种机器学习问题的预制策略的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/doikov23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/doikov23b/doikov23b.pdf)** 

# On Data Manifolds Entailed by Structural Causal Models
**题目:** 结构动因模型对数据变形的影响

**作者:** Ricardo Dominguez-Olmedo, Amir-Hossein Karimi, Georgios Arvanitidis, Bernhard Schölkopf

**Abstract:** The geometric structure of data is an important inductive bias in machine learning. In this work, we characterize the data manifolds entailed by structural causal models. The strengths of the proposed framework are twofold: firstly, the geometric structure of the data manifolds is causally informed, and secondly, it enables causal reasoning about the data manifolds in an interventional and a counterfactual sense. We showcase the versatility of the proposed framework by applying it to the generation of causally-grounded counterfactual explanations for machine learning classifiers, measuring distances along the data manifold in a differential geometric-principled manner.

**摘要:** 数据的几何结构是机器学习中的一个重要诱导性偏差,本文对结构性因果模型所伴随的数据变形特征进行了分析,提出了两个优点:第一,数据变形的几何结构是因果地知的,第二,它使数据变形在干预性和反因果意义下能够进行因果推理。

**[Paper URL](https://proceedings.mlr.press/v202/dominguez-olmedo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dominguez-olmedo23a/dominguez-olmedo23a.pdf)** 

# Towards Understanding and Reducing Graph Structural Noise for GNNs
**题目:** 实现GNN图结构噪声的理解和减少

**作者:** Mingze Dong, Yuval Kluger

**Abstract:** Graph neural networks (GNNs) have emerged as a powerful paradigm to learn from relational data mostly through applying the message passing mechanism. However, this approach may exhibit suboptimal performance when applied to graphs possessing various structural issues. In this work, we focus on understanding and alleviating the effect of graph structural noise on GNN performance. To evaluate the graph structural noise in real data, we propose edge signal-to-noise ratio (ESNR), a novel metric evaluating overall edge noise level with respect to data features or labels based on random matrix theory. We have found striking concordance between the proposed ESNR metric and the GNN performance in various simulated and real data. To reduce the effect of the noise, we propose GPS (Graph Propensity Score) graph rewiring, which estimates the edge likelihood for rewiring data graphs based on self-supervised link prediction. We provide a theoretical guarantee for GPS graph rewiring and demonstrate its efficacy by comprehensive benchmarks.

**摘要:** 图神经网络(GNNs)是通过应用信息传递机制学习关系数据的一种有力的范式,然而,应用于具有多种结构问题的图则时,这种方法可能表现出不优越的性能。本文着重了解和减轻图结构噪声对GNN性能的影响。为评价实数据图结构噪声,我们提出了边缘信号-噪声比(ESNR),一种基于随机矩阵理论的数据特征或标签的整体边缘噪声水平评价的新度量。我们发现该度量与GNN性能在各种模拟和实数据中具有显著的一致性。我们为GPS图再配电提供了理论保证,并通过综合的指标证明其有效性。

**[Paper URL](https://proceedings.mlr.press/v202/dong23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dong23a/dong23a.pdf)** 

# SpeedDETR: Speed-aware Transformers for End-to-end Object Detection
**题目:** SpeedDETR:基于速度的变换器用于端到端对象检测

**作者:** Peiyan Dong, Zhenglun Kong, Xin Meng, Peng Zhang, Hao Tang, Yanzhi Wang, Chih-Hsien Chou

**Abstract:** Vision Transformers (ViTs) have continuously achieved new milestones in object detection. However, the considerable computation and memory burden compromise their efficiency and generalization of deployment on resource-constraint devices. Besides, efficient transformer-based detectors designed by existing works can hardly achieve a realistic speedup, especially on multi-core processors (e.g., GPUs). The main issue is that the current literature solely concentrates on building algorithms with minimal computation, oblivious that the practical latency can also be affected by the memory access cost and the degree of parallelism. Therefore, we propose SpeedDETR, a novel speed-aware transformer for end-to-end object detectors, achieving high-speed inference on multiple devices. Specifically, we design a latency prediction model which can directly and accurately estimate the network latency by analyzing network properties, hardware memory access pattern, and degree of parallelism. Following the effective local-to-global visual modeling process and the guidance of the latency prediction model, we build our hardware-oriented architecture design and develop a new family of SpeedDETR. Experiments on the MS COCO dataset show SpeedDETR outperforms current DETR-based methods on Tesla V100. Even acceptable speed inference can be achieved on edge GPUs.

**摘要:** 视觉变换器(ViTs)在物体检测中不断实现新里程碑,但计算和存储负载的严重影响使它们在资源约束设备上具有效率和推广性。此外,由现有工程设计的高效变换器-based detectors几乎无法实现现实的加速,特别是在多核处理器(例如GPU)上。主要问题是,目前的文献只集中于用最小计算构建算法,忽略实际的延迟也可能受到存储访问成本和平行性程度的影响。因此,我们提出了SpeedDETR,一种面向端到端对象检测器的新速度敏捷变换器,在多个设备上实现高速推断。经过有效的局部到全球视觉建模过程和延迟预测模型的指导,我们构建了面向硬件的架构设计和开发了新的SpeedDETR家族。MS COCO数据集的实验显示,SpeedDETR比目前的DETR基于 Tesla V100的方法更好。

**[Paper URL](https://proceedings.mlr.press/v202/dong23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dong23b/dong23b.pdf)** 

# Understand and Modularize Generator Optimization in ELECTRA-style Pretraining
**题目:** 了解和模块化发电机优化在ELECTRA样式预训练中

**作者:** Chengyu Dong, Liyuan Liu, Hao Cheng, Jingbo Shang, Jianfeng Gao, Xiaodong Liu

**Abstract:** Despite the effectiveness of ELECTRA-style pre-training, their performance is dependent on the careful selection of the model size for the auxiliary generator, leading to high trial-and-error costs. In this paper, we present the first systematic study of this problem. Our theoretical investigation highlights the importance of controlling the generator capacity in ELECTRA-style training. Meanwhile, we found it is not handled properly in the original ELECTRA design, leading to the sensitivity issue. Specifically, since adaptive optimizers like Adam will cripple the weighing of individual losses in the joint optimization, the original design fails to control the generator training effectively. To regain control over the generator, we modularize the generator optimization by decoupling the generator optimizer and discriminator optimizer completely, instead of simply relying on the weighted objective combination. Our simple technique reduced the sensitivity of ELECTRA training significantly and obtains considerable performance gain compared to the original design.

**摘要:** 尽管电子式预训练有效率,但其性能取决于辅助发电机的模型尺寸的仔细选择,从而导致了高试错成本。本论文首次系统研究了这一问题。我们的理论研究突出了在电子式训练中控制发电机容量的重要性。同时,我们发现该问题在原型电子设计中没有妥善处理,导致了敏感问题。具体而言,由于亚当等自适应优化器会使联合优化中的个人损失的权重降低,原型设计无法有效控制发电机训练。我们的简单的技术大大降低了ELECTRA培训的敏感性,与原来的设计相比取得了相当大的性能提升。

**[Paper URL](https://proceedings.mlr.press/v202/dong23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dong23c/dong23c.pdf)** 

# Diversity-enhancing Generative Network for Few-shot Hypothesis Adaptation
**题目:** 微型假设适应性提高多样性生成网络

**作者:** Ruijiang Dong, Feng Liu, Haoang Chi, Tongliang Liu, Mingming Gong, Gang Niu, Masashi Sugiyama, Bo Han

**Abstract:** Generating unlabeled data has been recently shown to help address the few-shot hypothesis adaptation (FHA) problem, where we aim to train a classifier for the target domain with a few labeled target-domain data and a well-trained source-domain classifier (i.e., a source hypothesis), for the additional information of the highly-compatible unlabeled data. However, the generated data of the existing methods are extremely similar or even the same. The strong dependency among the generated data will lead the learning to fail. In this paper, we propose a diversity-enhancing generative network (DEG-Net) for the FHA problem, which can generate diverse unlabeled data with the help of a kernel independence measure: the Hilbert-Schmidt independence criterion (HSIC). Specifically, DEG-Net will generate data via minimizing the HSIC value (i.e., maximizing the independence) among the semantic features of the generated data. By DEG-Net, the generated unlabeled data are more diverse and more effective for addressing the FHA problem. Experimental results show that the DEG-Net outperforms existing FHA baselines and further verifies that generating diverse data plays an important role in addressing the FHA problem.

**摘要:** 非标记数据的生成最近被证明有助于解决少数射击假设适应(FHA)问题,我们的目标是训练一些标记目标域数据的对象分类器和一个经过训练的源域分类器(即源假设),以提供高度兼容的非标记数据的额外信息。然而,现有方法的生成数据非常相似或甚至相同。生成数据之间的强依赖性将导致学习失败。基于DEG-Net,生成的无标签数据更多样化,更有效解决房委会问题。实验结果表明,DEG-Net超越现有房委会的基准,进一步验证了数据的多样化在解决房委会问题方面起着重要的作用。

**[Paper URL](https://proceedings.mlr.press/v202/dong23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dong23d/dong23d.pdf)** 

# PASTA: Pessimistic Assortment Optimization
**题目:** PASTA:悲观品揃优化

**作者:** Juncheng Dong, Weibin Mo, Zhengling Qi, Cong Shi, Ethan X Fang, Vahid Tarokh

**Abstract:** We consider a fundamental class of assortment optimization problems in an offline data-driven setting. The firm does not know the underlying customer choice model but has access to an offline dataset consisting of the historically offered assortment set, customer choice, and revenue. The objective is to use the offline dataset to find an optimal assortment. Due to the combinatorial nature of assortment optimization, the problem of insufficient data coverage is likely to occur in the offline dataset. Therefore, designing a provably efficient offline learning algorithm becomes a significant challenge. To this end, based on the principle of pessimism, we propose a novel algorithm called Pessimistic ASsortment opTimizAtion (PASTA for short), which can correctly identify the optimal assortment by only requiring the offline data to cover the optimal assortment under general settings. In particular, we establish the first regret bound for the offline assortment optimization problem under the celebrated multinomial logit model (MNL). We also propose an efficient computational procedure to solve our pessimistic assortment optimization problem. Our numerical studies demonstrate the superiority of the proposed method over the existing baseline method.

**摘要:** 我们考虑了一种基本类别的在线数据驱动设置的在线优化问题。公司不了解潜在的客户选择模型,但可以访问由历史提供的在线数据集、客户选择和收入组成的在线数据集。目标是利用在线数据集寻找最佳的在线优化。由于在线优化的组合性,在线数据集可能出现不足的数据覆盖问题。因此,设计可证明有效的在线学习算法成为一个重要的挑战。本文还提出了一种有效的计算方法,以解决我们悲观的分类优化问题。我们的数值研究表明,该方法优于现有的基线方法。

**[Paper URL](https://proceedings.mlr.press/v202/dong23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dong23e/dong23e.pdf)** 

# Adaptively Weighted Data Augmentation Consistency Regularization for Robust Optimization under Concept Shift
**题目:** 基于适应权重的数据增量一致性规范化,实现基于概念转变的鲁棒优化

**作者:** Yijun Dong, Yuege Xie, Rachel Ward

**Abstract:** Concept shift is a prevailing problem in natural tasks like medical image segmentation where samples usually come from different subpopulations with variant correlations between features and labels. One common type of concept shift in medical image segmentation is the "information imbalance" between label-sparse samples with few (if any) segmentation labels and label-dense samples with plentiful labeled pixels. Existing distributionally robust algorithms have focused on adaptively truncating/down-weighting the "less informative" (i.e., label-sparse in our context) samples. To exploit data features of label-sparse samples more efficiently, we propose an adaptively weighted online optimization algorithm — AdaWAC — to incorporate data augmentation consistency regularization in sample reweighting. Our method introduces a set of trainable weights to balance the supervised loss and unsupervised consistency regularization of each sample separately. At the saddle point of the underlying objective, the weights assign label-dense samples to the supervised loss and label-sparse samples to the unsupervised consistency regularization. We provide a convergence guarantee by recasting the optimization as online mirror descent on a saddle point problem. Our empirical results demonstrate that AdaWAC not only enhances the segmentation performance and sample efficiency but also improves the robustness to concept shift on various medical image segmentation tasks with different UNet-style backbones.

**摘要:** 概念移位是医学图像分割等自然任务中普遍存在的问题,样品通常来自不同次群,特征与标签之间有变异相关性。一种常见的概念移位在医学图像分割中是带有少量(如果存在)分割标签的标签偏差样品和带有大量标签像素的标签浓度样品之间的“信息不平衡”。现有的分布性鲁棒算法主要针对“少信息”样品(即在我们的上下文中带有标签偏差样品)进行自适应切削/减重。在基准目标的鞍点上,权重将标签浓度样品分配给受监督的损伤样品,标签紧缩样品分配给不受监督的一致性校正。我们通过重构鞍点问题上的在线镜下下降的优化来提供收敛性保证。我们的实证结果表明,AdaWAC不仅提高了分段性能和样品效率,而且提高了不同UNet样式后骨的医学图像分段任务的概念转变的鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/dong23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dong23f/dong23f.pdf)** 

# Does Sparsity Help in Learning Misspecified Linear Bandits?
**题目:** 节俭能帮助学习错误的线性 Bandits 吗?

**作者:** Jialin Dong, Lin Yang

**Abstract:** Recently, the study of linear misspecified bandits has generated intriguing implications of the hardness of learning in bandits and reinforcement learning (RL). In particular, Du et al. (2020) shows that even if a learner is given linear features in $\mathbb{R}^d$ that approximate the rewards in a bandit or RL with a uniform error of $\varepsilon$, searching for an $O(\varepsilon)$-optimal action requires pulling at least $\Omega(\exp(d))$ queries. Furthermore, Lattimore et al. (2020) show that a degraded $O(\varepsilon\sqrt{d})$-optimal solution can be learned within $\operatorname{poly}(d/\varepsilon)$ queries. Yet it is unknown whether a structural assumption on the ground-truth parameter, such as sparsity, could break $\varepsilon\sqrt{d}$ barrier. In this paper, we address this question by showing that algorithms can obtain $O(\varepsilon)$-optimal actions by querying $\tilde{O}(\exp(m\varepsilon))$ actions, where $m$ is the sparsity parameter, removing the $\exp(d)$-dependence. We further show (with an information-theoretical lower bound) that this is the best possible if one demands an error $ m^{\delta}\varepsilon$ for $0<\delta<1$. We further show that $\operatorname{poly}(m/\varepsilon)$ bounds are possible when the linear features are "good”. These results provide a nearly complete picture of how sparsity can help in misspecified bandit learning and provide a deeper understanding of when linear features are “useful” for bandit and reinforcement learning with misspecification.

**摘要:** 近来,线性误区分带子的研究产生了在带子和增强学习(RL)中学习的硬度的引人注目的影响,特别是Du等人(2020)表明,即使一个学习者在$\mathbb{R}^d$中获得线性特征,以$\varepsilon$的均匀误差近似带子或RL中的奖励,寻找$O(\varepsilon)$-最佳行动需要至少引取$\Omega(\exp(d))$查询。此外,Lattimore等人(2020)表明, degradated $O(\varepsilon\sqrt{d})$-最佳解决方案可以在$\operatorname{poly}(d/\varepsilon)$查询中学习。我们进一步表明(具有信息理论较低的边界)如果要求一个错误$ m^{\delta}\varepsilon$为$0<\delta<1$,这是最好的可能。我们进一步表明$\operatorname{poly}(m/\varepsilon)$边界在线性特征“好”时是可能的。

**[Paper URL](https://proceedings.mlr.press/v202/dong23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dong23g/dong23g.pdf)** 

# Symmetry-Aware Robot Design with Structured Subgroups
**题目:** 有结构子群的对称意识机器人设计

**作者:** Heng Dong, Junyu Zhang, Tonghan Wang, Chongjie Zhang

**Abstract:** Robot design aims at learning to create robots that can be easily controlled and perform tasks efficiently. Previous works on robot design have proven its ability to generate robots for various tasks. However, these works searched the robots directly from the vast design space and ignored common structures, resulting in abnormal robots and poor performance. To tackle this problem, we propose a Symmetry-Aware Robot Design (SARD) framework that exploits the structure of the design space by incorporating symmetry searching into the robot design process. Specifically, we represent symmetries with the subgroups of the dihedral group and search for the optimal symmetry in structured subgroups. Then robots are designed under the searched symmetry. In this way, SARD can design efficient symmetric robots while covering the original design space, which is theoretically analyzed. We further empirically evaluate SARD on various tasks, and the results show its superior efficiency and generalizability.

**摘要:** 机器人设计的目的在于学习制造机器人,使其可以轻松控制并有效地完成任务。机器人设计上以前的工作已经证明了它能够为各种任务生成机器人的能力。然而,这些工作直接从巨大的设计空间搜索机器人,忽略了共同结构,导致了异常机器人和低性能。为了解决这个问题,我们提出了一种对称性机器人设计(SARD)框架,它通过将对称性搜索纳入机器人设计过程来利用设计空间的结构。具体而言,我们代表双面组的子组的对称性,并在结构子组中寻找最佳对称性。然后,机器人在搜索的对称性下设计。我们 进一步 在 各种 任务 上 对 ARD 进行 实证 评价, 结果 表明 它 具有 较高 的 效率 和 可 推广性 。

**[Paper URL](https://proceedings.mlr.press/v202/dong23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dong23h/dong23h.pdf)** 

# DoCoFL: Downlink Compression for Cross-Device Federated Learning
**题目:** DoCoFL: Cross-Device Federated Learning的 Downlink压缩

**作者:** Ron Dorfman, Shay Vargaftik, Yaniv Ben-Itzhak, Kfir Yehuda Levy

**Abstract:** Many compression techniques have been proposed to reduce the communication overhead of Federated Learning training procedures. However, these are typically designed for compressing model updates, which are expected to decay throughout training. As a result, such methods are inapplicable to downlink (i.e., from the parameter server to clients) compression in the cross-device setting, where heterogeneous clients may appear only once during training and thus must download the model parameters. Accordingly, we propose DoCoFL – a new framework for downlink compression in the cross-device setting. Importantly, DoCoFL can be seamlessly combined with many uplink compression schemes, rendering it suitable for bi-directional compression. Through extensive evaluation, we show that DoCoFL offers significant bi-directional bandwidth reduction while achieving competitive accuracy to that of a baseline without any compression.

**摘要:** 许多压缩技术被提议以减少联邦学习培训程序的通信费用。然而,这些技术通常用于压缩模型更新,预期在整个培训过程中会变质。因此,这些方法在交叉设备设置中无法应用于下链(即从参数服务器到客户端)压缩,在交叉设备设置中异质客户端可能出现一次,因此必须下载模型参数。因此,我们提议DoCoFL — 跨设备设置中的下链压缩的新框架。

**[Paper URL](https://proceedings.mlr.press/v202/dorfman23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dorfman23a/dorfman23a.pdf)** 

# Meta-Learning the Inductive Bias of Simple Neural Circuits
**题目:** 简单神经回路诱导偏见的代谢学习

**作者:** Will Dorrell, Maria Yuffa, Peter E. Latham

**Abstract:** Training data is always finite, making it unclear how to generalise to unseen situations. But, animals do generalise, wielding Occam’s razor to select a parsimonious explanation of their observations. How they do this is called their inductive bias, and it is implicitly built into the operation of animals’ neural circuits. This relationship between an observed circuit and its inductive bias is a useful explanatory window for neuroscience, allowing design choices to be understood normatively. However, it is generally very difficult to map circuit structure to inductive bias. Here, we present a neural network tool to bridge this gap. The tool meta-learns the inductive bias by learning functions that a neural circuit finds easy to generalise, since easy-to-generalise functions are exactly those the circuit chooses to explain incomplete data. In systems with analytically known inductive bias, i.e. linear and kernel regression, our tool recovers it. Generally, we show it can flexibly extract inductive biases from supervised learners, including spiking neural networks, and show how it could be applied to real animals. Finally, we use our tool to interpret recent connectomic data illustrating our intended use: understanding the role of circuit features through the resulting inductive bias.

**摘要:** 训练数据总是有限的,使它不明确如何将观察到的情况归纳为一般化。但是,动物确实会归纳为一般化,用奥卡姆剃刀选择他们观察的 Parsimonious解释。他们如何做到这一点叫做他们的诱导偏见,并且它隐含地被建入动物神经回路的操作中。观察到的电路与其诱导偏见之间的关系是神经科学的一个有用的解释窗口,允许设计选择被规范地理解。然而,通常很难将电路结构映射成诱导偏见。一般来说,我们表明它可以灵活地从受监督的学习者中提取诱导偏见,包括尖峰神经网络,并展示它如何应用于实际动物。最后,我们使用我们的工具来解释最近的连接体数据,说明我们打算的用途:通过由此产生的诱导偏见来理解电路特征的作用。

**[Paper URL](https://proceedings.mlr.press/v202/dorrell23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dorrell23a/dorrell23a.pdf)** 

# Self-Repellent Random Walks on General Graphs - Achieving Minimal Sampling Variance via Nonlinear Markov Chains
**题目:** 一般图形上的自阻随机行走-通过非线性马可夫链实现最小采样变量

**作者:** Vishwaraj Doshi, Jie Hu, Do Young Eun

**Abstract:** We consider random walks on discrete state spaces, such as general undirected graphs, where the random walkers are designed to approximate a target quantity over the network topology via sampling and neighborhood exploration in the form of Markov chain Monte Carlo (MCMC) procedures. Given any Markov chain corresponding to a target probability distribution, we design a self-repellent random walk (SRRW) which is less likely to transition to nodes that were highly visited in the past, and more likely to transition to seldom visited nodes. For a class of SRRWs parameterized by a positive real $\alpha$, we prove that the empirical distribution of the process converges almost surely to the the target (stationary) distribution of the underlying Markov chain kernel. We then provide a central limit theorem and derive the exact form of the arising asymptotic co-variance matrix, which allows us to show that the SRRW with a stronger repellence (larger $\alpha$) always achieves a smaller asymptotic covariance, in the sense of Loewner ordering of co-variance matrices. Especially for SRRW-driven MCMC algorithms, we show that the decrease in the asymptotic sampling variance is of the order $O(1/\alpha)$, eventually going down to zero. Finally, we provide numerical simulations complimentary to our theoretical results, also empirically testing a version of SRRW with $\alpha$ increasing in time to combine the benefits of smaller asymptotic variance due to large $\alpha$, with empirically observed faster mixing properties of SRRW with smaller $\alpha$.

**摘要:** 我们考虑在离散状态空间上的随机行走,例如一般非向导图,其中随机行走者被设计以通过采样和邻近探索在网络拓扑上近似一个目标数量,以马可夫链蒙特卡罗(MCMC)程序的形式。考虑到任何符合目标概率分布的马可夫链,我们设计了自阻随机行走(SRRW),它不太可能过渡到过去被高度访问的节点,而且更有可能过渡到很少访问的节点。然后给出一个中心限度定理,并推导产生渐近共变矩阵的精确形式,使我们能够证明,具有更强的阻力(较大的$\alpha$)的SRRW总是达到较小的渐近共变,这在共变矩阵的 Loewner排序意义上。

**[Paper URL](https://proceedings.mlr.press/v202/doshi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/doshi23a/doshi23a.pdf)** 

# Linear Time GPs for Inferring Latent Trajectories from Neural Spike Trains
**题目:** 神经螺旋列车受干扰的线性时间GP

**作者:** Matthew Dowling, Yuan Zhao, Il Memming Park

**Abstract:** Latent Gaussian process (GP) models are widely used in neuroscience to uncover hidden state evolutions from sequential observations, mainly in neural activity recordings. While latent GP models provide a principled and powerful solution in theory, the intractable posterior in non-conjugate settings necessitates approximate inference schemes, which may lack scalability. In this work, we propose cvHM, a general inference framework for latent GP models leveraging Hida-Matérn kernels and conjugate computation variational inference (CVI). With cvHM, we are able to perform variational inference of latent neural trajectories with linear time complexity for arbitrary likelihoods. The reparameterization of stationary kernels using Hida-Matérn GPs helps us connect the latent variable models that encode prior assumptions through dynamical systems to those that encode trajectory assumptions through GPs. In contrast to previous work, we use bidirectional information filtering, leading to a more concise implementation. Furthermore, we employ the Whittle approximate likelihood to achieve highly efficient hyperparameter learning.

**摘要:** 隐形高斯过程(GP)模型在神经科学中广泛应用,以揭示从序列观察中隐形状态演化,主要是在神经活动记录中。隐形GP模型在理论上提供一个基本和强有力的解决方案,但非合并设置中的不可解后需要近似推理方案,可能缺乏可扩展性。在此工作中,我们提出了 cvHM,一种利用Hida-Matérn核和合并计算变量推理(CVI)的隐形GP模型的一般推理框架。与以往的工作相比,我们使用双向信息滤波,从而实现更简洁的实现。此外,我们采用惠特尔近似概率实现高效率的超参数学习。

**[Paper URL](https://proceedings.mlr.press/v202/dowling23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dowling23a/dowling23a.pdf)** 

# On the Convergence Rate of Gaussianization with Random Rotations
**题目:** 随机旋转的几何化收敛率

**作者:** Felix Draxler, Lars Kühmichel, Armand Rousselot, Jens Müller, Christoph Schnoerr, Ullrich Koethe

**Abstract:** Gaussianization is a simple generative model that can be trained without backpropagation. It has shown compelling performance on low dimensional data. As the dimension increases, however, it has been observed that the convergence speed slows down. We show analytically that the number of required layers scales linearly with the dimension for Gaussian input. We argue that this is because the model is unable to capture dependencies between dimensions. Empirically, we find the same linear increase in cost for arbitrary input $p(x)$, but observe favorable scaling for some distributions. We explore potential speed-ups and formulate challenges for further research.

**摘要:** 高斯建模是一种简单的生成模型,可以不带背向的训练。它显示了低维数据的强有力性能。随着维度的增加,人们观察到收敛速度减慢。我们分析显示,所需的层数以高斯输入的维度为线性尺度。我们认为这是因为该模型无法捕捉维度间的依赖性。

**[Paper URL](https://proceedings.mlr.press/v202/draxler23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/draxler23a/draxler23a.pdf)** 

# PaLM-E: An Embodied Multimodal Language Model
**题目:** PaLM-E:嵌入式多模语言模型

**作者:** Danny Driess, Fei Xia, Mehdi S. M. Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, Wenlong Huang, Yevgen Chebotar, Pierre Sermanet, Daniel Duckworth, Sergey Levine, Vincent Vanhoucke, Karol Hausman, Marc Toussaint, Klaus Greff, Andy Zeng, Igor Mordatch, Pete Florence

**Abstract:** Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.

**摘要:** 大语言模型 excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning.我们的评估表明,PaLM-E是一个单个大型的嵌入式多模模型,能够处理多种嵌入式推理任务,从多种观察模式到多种嵌入式,并且显示出积极的传递:该模型从互联网规模的语言、视觉和视觉语言领域中进行多种联合训练中获益。

**[Paper URL](https://proceedings.mlr.press/v202/driess23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/driess23a/driess23a.pdf)** 

# Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC
**题目:** 减少、再利用、回收:基于能源扩散模型和MCMC的复合发电

**作者:** Yilun Du, Conor Durkan, Robin Strudel, Joshua B. Tenenbaum, Sander Dieleman, Rob Fergus, Jascha Sohl-Dickstein, Arnaud Doucet, Will Sussman Grathwohl

**Abstract:** Since their introduction, diffusion models have quickly become the prevailing approach to generative modeling in many domains. They can be interpreted as learning the gradients of a time-varying sequence of log-probability density functions. This interpretation has motivated classifier-based and classifier-free guidance as methods for post-hoc control of diffusion models. In this work, we build upon these ideas using the score-based interpretation of diffusion models, and explore alternative ways to condition, modify, and reuse diffusion models for tasks involving compositional generation and guidance. In particular, we investigate why certain types of composition fail using current techniques and present a number of solutions. We conclude that the sampler (not the model) is responsible for this failure and propose new samplers, inspired by MCMC, which enable successful compositional generation. Further, we propose an energy-based parameterization of diffusion models which enables the use of new compositional operators and more sophisticated, Metropolis-corrected samplers. Intriguingly we find these samplers lead to notable improvements in compositional generation across a wide variety of problems such as classifier-guided ImageNet modeling and compositional text-to-image generation.

**摘要:** 自其引入以来,扩散模型在许多领域迅速成为产生模型的主流方法。它们可以被解释为学习逻辑概率密度函数时序变化的梯度。这一解释为扩散模型的后时控制方法提供了基于分类器和无分类器的指导。在这个工作中,我们利用分数的扩散模型的解释来构建这些想法,并探索条件、修改和重用扩散模型的替代方法,用于涉及组合生成和指导的任务。同时,我们提出了一种基于能量的扩散模型参数化方法,使新的组合运算器和更先进的Metropolis校正样本器能够使用。令人惊奇的是,这些样本器在分类器指导的ImageNet模型和组合文本-到-图像生成等多种问题中对组合生成产生显著的改进。

**[Paper URL](https://proceedings.mlr.press/v202/du23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/du23a/du23a.pdf)** 

# Multi-task Representation Learning for Pure Exploration in Linear Bandits
**题目:** 线性带子纯探险的多任务表现学习

**作者:** Yihan Du, Longbo Huang, Wen Sun

**Abstract:** Despite the recent success of representation learning in sequential decision making, the study of the pure exploration scenario (i.e., identify the best option and minimize the sample complexity) is still limited. In this paper, we study multi-task representation learning for best arm identification in linear bandit (RepBAI-LB) and best policy identification in contextual linear bandit (RepBPI-CLB), two popular pure exploration settings with wide applications, e.g., clinical trials and web content optimization. In these two problems, all tasks share a common low-dimensional linear representation, and our goal is to leverage this feature to accelerate the best arm (policy) identification process for all tasks. For these problems, we design computationally and sample efficient algorithms DouExpDes and C-DouExpDes, which perform double experimental designs to plan optimal sample allocations for learning the global representation. We show that by learning the common representation among tasks, our sample complexity is significantly better than that of the native approach which solves tasks independently. To the best of our knowledge, this is the first work to demonstrate the benefits of representation learning for multi-task pure exploration.

**摘要:** 尽管在序列决策中的表示学习最近取得成功,研究纯探索场景(即识别最佳选择和最小化样品复杂度)仍然有限。本文研究了多任务表示学习在线性带子中的最佳手臂识别(RepBAI-LB)和上下文线性带子中的最佳政策识别(RepBPI-CLB),两个具有广泛应用的流行纯探索设置,例如临床试验和Web内容优化。我们证明,通过学习任务间的共同表现,我们的样品复杂性比独立解决任务的原先方法要好得多,这是我们最能知的首次证明多任务纯探索的表示学习的好处的工作。

**[Paper URL](https://proceedings.mlr.press/v202/du23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/du23b/du23b.pdf)** 

# Nonparametric Generative Modeling with Conditional Sliced-Wasserstein Flows
**题目:** 条件 Sliced-Wasserstein流动的非参数生成模型

**作者:** Chao Du, Tianbo Li, Tianyu Pang, Shuicheng Yan, Min Lin

**Abstract:** Sliced-Wasserstein Flow (SWF) is a promising approach to nonparametric generative modeling but has not been widely adopted due to its suboptimal generative quality and lack of conditional modeling capabilities. In this work, we make two major contributions to bridging this gap. First, based on a pleasant observation that (under certain conditions) the SWF of joint distributions coincides with those of conditional distributions, we propose Conditional Sliced-Wasserstein Flow (CSWF), a simple yet effective extension of SWF that enables nonparametric conditional modeling. Second, we introduce appropriate inductive biases of images into SWF with two techniques inspired by local connectivity and multiscale representation in vision research, which greatly improve the efficiency and quality of modeling images. With all the improvements, we achieve generative performance comparable with many deep parametric generative models on both conditional and unconditional tasks in a purely nonparametric fashion, demonstrating its great potential.

**摘要:** 断层-瓦瑟斯坦流是非参数化生成模型的一个有前途的途径,但由于其低最佳的生成质量和缺乏条件建模能力,尚未被广泛采用。在这项工作中,我们为填补这一差距作出了两个主要贡献。首先,基于(在某些条件下)联合分布的SWF与条件分布的SWF相符,我们提出条件断层-瓦瑟斯坦流(CSWF)是一种简单但有效的SWF扩展,可实现非参数化条件建模。通过所有改进,在条件和非条件的任务上,我们实现了与许多深参数生成模型相等的生成性能,并以纯非参数的方式证明了其巨大的潜力。

**[Paper URL](https://proceedings.mlr.press/v202/du23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/du23c/du23c.pdf)** 

# Subsample Ridge Ensembles: Equivalences and Generalized Cross-Validation
**题目:** 下个实例山脊综合体:等价和综合交叉评价

**作者:** Jin-Hong Du, Pratik Patil, Arun K. Kuchibhotla

**Abstract:** We study subsampling-based ridge ensembles in the proportional asymptotics regime, where the feature size grows proportionally with the sample size such that their ratio converges to a constant. By analyzing the squared prediction risk of ridge ensembles as a function of the explicit penalty $\lambda$ and the limiting subsample aspect ratio $\phi_s$ (the ratio of the feature size to the subsample size), we characterize contours in the $(\lambda, \phi_s)$-plane at any achievable risk. As a consequence, we prove that the risk of the optimal full ridgeless ensemble (fitted on all possible subsamples) matches that of the optimal ridge predictor. In addition, we prove strong uniform consistency of generalized cross-validation (GCV) over the subsample sizes for estimating the prediction risk of ridge ensembles. This allows for GCV-based tuning of full ridgeless ensembles without sample splitting and yields a predictor whose risk matches optimal ridge risk.

**摘要:** 我们研究了基于子样本的脊柱组合在比例渐近模式下,特征大小与样本大小相对于,使得它们的比率趋于常数。通过分析脊柱组合的平方预测风险作为明确惩罚$\lambda$的函数和有限子样本方面比例$\phi_s$(特征大小与子样本大小的比率),在任何可实现风险下,我们对$(\lambda, \phi_s)$-平面的轮廓特征进行了描述。因此,我们证明了最佳完全脊柱组合(适用于所有可能的子样)的风险与最佳脊柱预测器的风险相匹配。此外,我们证明了对脊柱组合的预测风险估计的一般化交叉验证(GCV)的强统一一致性。

**[Paper URL](https://proceedings.mlr.press/v202/du23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/du23d/du23d.pdf)** 

# On Uni-Modal Feature Learning in Supervised Multi-Modal Learning
**题目:** 基于多模教学的单模特征学习

**作者:** Chenzhuang Du, Jiaye Teng, Tingle Li, Yichen Liu, Tianyuan Yuan, Yue Wang, Yang Yuan, Hang Zhao

**Abstract:** We abstract the features (i.e. learned representations) of multi-modal data into 1) uni-modal features, which can be learned from uni-modal training, and 2) paired features, which can only be learned from cross-modal interactions. Multi-modal models are expected to benefit from cross-modal interactions on the basis of ensuring uni-modal feature learning. However, recent supervised multi-modal late-fusion training approaches still suffer from insufficient learning of uni-modal features on each modality. We prove that this phenomenon does hurt the model’s generalization ability. To this end, we propose to choose a targeted late-fusion learning method for the given supervised multi-modal task from Uni-Modal Ensemble (UME) and the proposed Uni-Modal Teacher (UMT), according to the distribution of uni-modal and paired features. We demonstrate that, under a simple guiding strategy, we can achieve comparable results to other complex late-fusion or intermediate-fusion methods on various multi-modal datasets, including VGG-Sound, Kinetics-400, UCF101, and ModelNet40.

**摘要:** 我们将多模数据的特征(即学习表现)归纳为(1)单模特征,可从单模训练中学习,(2)双模特征,可仅从跨模交互中学习。多模模型期望在保证单模特征学习的基础上从跨模交互中获益。然而,最近监管的多模晚期融合训练方法仍 suffer from insufficient learning of uni-modal features on each modality. We prove that this phenomenon does hurt the model’s generalization ability. To this end, we propose to choose a targeted late-fusion learning method for the given supervised multi-modal task from Uni-Modal Ensemble (UME) and the proposed Uni-Modal Teacher (UMT), according to the distribution of uni-modal and paired features.我们证明,在简单的指导策略下,我们可以在各种多模数据集,包括VGG-Sound、Kinetics-400、UCF101和ModelNet40上实现与其他复杂的晚融合或中间融合方法相比的结果。

**[Paper URL](https://proceedings.mlr.press/v202/du23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/du23e/du23e.pdf)** 

# Guiding Pretraining in Reinforcement Learning with Large Language Models
**题目:** 用大型语言模型进行强化学习的指导预训练

**作者:** Yuqing Du, Olivia Watkins, Zihan Wang, Cédric Colas, Trevor Darrell, Pieter Abbeel, Abhishek Gupta, Jacob Andreas

**Abstract:** Reinforcement learning algorithms typically struggle in the absence of a dense, well-shaped reward function. Intrinsically motivated exploration methods address this limitation by rewarding agents for visiting novel states or transitions, but these methods offer limited benefits in large environments where most discovered novelty is irrelevant for downstream tasks. We describe a method that uses background knowledge from text corpora to shape exploration. This method, called ELLM (Exploring with LLMs) rewards an agent for achieving goals suggested by a language model prompted with a description of the agent’s current state. By leveraging large-scale language model pretraining, ELLM guides agents toward human-meaningful and plausibly useful behaviors without requiring a human in the loop. We evaluate ELLM in the Crafter game environment and the Housekeep robotic simulator, showing that ELLM-trained agents have better coverage of common-sense behaviors during pretraining and usually match or improve performance on a range of downstream tasks.

**摘要:** 强化学习算法通常在缺乏密集的、良好形状的奖励函数的情况下进行斗争。内在动机的探索方法通过奖励代理来访问新状态或过渡来解决这一限制,但这些方法在大型环境中提供有限的好处,其中发现的最新事物对下游任务无关紧要。我们描述一种方法,它利用文本 corpora的背景知识来塑造探索。我们对ELLM在Crafter游戏环境和Housekeep机器人模拟器中进行了评估,表明ELLM训练的人员在预训练期间能更好地了解常识行为,并且通常在一系列下游任务中能匹配或提高性能。

**[Paper URL](https://proceedings.mlr.press/v202/du23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/du23f/du23f.pdf)** 

# A Flexible Diffusion Model
**题目:** 弹性扩散模型

**作者:** Weitao Du, He Zhang, Tao Yang, Yuanqi Du

**Abstract:** Denoising diffusion (score-based) generative models have become a popular choice for modeling complex data. Recently, a deep connection between forward-backward stochastic differential equations (SDEs) and diffusion-based models has been established, leading to the development of new SDE variants such as sub-VP and critically-damped Langevin. Despite the empirical success of some hand-crafted forward SDEs, many potentially promising forward SDEs remain unexplored. In this work, we propose a general framework for parameterizing diffusion models, particularly the spatial part of forward SDEs, by leveraging the symplectic and Riemannian geometry of the data manifold. We introduce a systematic formalism with theoretical guarantees and connect it with previous diffusion models. Finally, we demonstrate the theoretical advantages of our method from a variational optimization perspective. We present numerical experiments on synthetic datasets, MNIST and CIFAR10 to validate the effectiveness of our framework.

**摘要:** 扩散(基于分数)生成模型的定义已成为复杂数据建模的热门选择。最近,建立了前后随机微分方程(SDEs)与扩散建模之间的深远联系,导致了新的SDE变量,例如副VP和临界damped Langevin。尽管一些手工制订的扩散SDEs取得了一定的实证成功,但许多潜在的扩散SDEs仍未被探索。在本文中,我们提出了扩散模型的参数化一般框架,特别是扩散SDEs的空间部分,通过利用数据流形的交集和黎曼几何。我们引入了理论保证的系统形式主义,并将其与以前扩散模型联系起来。最后,我们从变量优化的角度展示了我们的方法的理论优势。我们对合成数据集、MNIST和CIFAR10进行了数值实验,验证了我们的框架的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/du23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/du23g/du23g.pdf)** 

# Fast Excess Risk Rates via Offset Rademacher Complexity
**题目:** 利用逆差雷达马切尔复杂度快速超额风险率

**作者:** Chenguang Duan, Yuling Jiao, Lican Kang, Xiliang Lu, Jerry Zhijian Yang

**Abstract:** Based on the offset Rademacher complexity, this work outlines a systematical framework for deriving sharp excess risk bounds in statistical learning without Bernstein condition. In addition to recovering fast rates in a unified way for some parametric and nonparametric supervised learning models with minimum identifiability assumptions, we also obtain new and improved results for LAD (sparse) linear regression and deep logistic regression with deep ReLU neural networks, respectively.

**摘要:** 基于雷达马切尔的补偿复杂性,本文概述了在无伯恩斯坦条件下的统计学学习中得出明显的过高风险边界的系统框架。除了统一地恢复一些具有最小可识别假设的参数化和非参数化监督学习模型的快速率,我们还分别得到了新的和改进的结果,分别是LAD(节点)线性回归和深度逻辑回归,分别是深度ReLU神经网络。

**[Paper URL](https://proceedings.mlr.press/v202/duan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/duan23a/duan23a.pdf)** 

# Are Diffusion Models Vulnerable to Membership Inference Attacks?
**题目:** 扩散模型是否易受会员侵害攻击?

**作者:** Jinhao Duan, Fei Kong, Shiqi Wang, Xiaoshuang Shi, Kaidi Xu

**Abstract:** Diffusion-based generative models have shown great potential for image synthesis, but there is a lack of research on the security and privacy risks they may pose. In this paper, we investigate the vulnerability of diffusion models to Membership Inference Attacks (MIAs), a common privacy concern. Our results indicate that existing MIAs designed for GANs or VAE are largely ineffective on diffusion models, either due to inapplicable scenarios (e.g., requiring the discriminator of GANs) or inappropriate assumptions (e.g., closer distances between synthetic samples and member samples). To address this gap, we propose Step-wise Error Comparing Membership Inference (SecMI), a query-based MIA that infers memberships by assessing the matching of forward process posterior estimation at each timestep. SecMI follows the common overfitting assumption in MIA where member samples normally have smaller estimation errors, compared with hold-out samples. We consider both the standard diffusion models, e.g., DDPM, and the text-to-image diffusion models, e.g., Latent Diffusion Models and Stable Diffusion. Experimental results demonstrate that our methods precisely infer the membership with high confidence on both of the two scenarios across multiple different datasets. Code is available at https://github.com/jinhaoduan/SecMI.

**摘要:** 基于扩散的生成模型显示了图像合成的巨大潜力,但对它们可能带来的安全和隐私风险缺乏研究。本文研究了扩散模型对成员ference攻击(MIA)的脆弱性,这是一个共同的隐私问题。我们的结果表明,现有为GAN或VAE设计的MIA在扩散模型上大体上是无效的,要么是由于不适用的场景(例如需要GAN的鉴别器)或不恰当的假设(例如合成样品和成员样品之间的距离更近)。我们考虑了标准扩散模型,例如DDPM,以及文本到图像扩散模型,例如拉特扩散模型和稳定扩散。实验结果表明,我们的方法能够准确地推断在多个不同数据集中这两个场景中的成员。

**[Paper URL](https://proceedings.mlr.press/v202/duan23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/duan23b/duan23b.pdf)** 

# Bayesian Progressive Deep Topic Model with Knowledge Informed Textual Data Coarsening Process
**题目:** 基于知识的文本数据粗糙化过程的贝叶斯进化深度主题模型

**作者:** Zhibin Duan, Xinyang Liu, Yudi Su, Yishi Xu, Bo Chen, Mingyuan Zhou

**Abstract:** Deep topic models have shown an impressive ability to extract multi-layer document latent representations and discover hierarchical semantically meaningful topics.However, most deep topic models are limited to the single-step generative process, despite the fact that the progressive generative process has achieved impressive performance in modeling image data. To this end, in this paper, we propose a novel progressive deep topic model that consists of a knowledge-informed textural data coarsening process and a corresponding progressive generative model. The former is used to build multi-level observations ranging from concrete to abstract, while the latter is used to generate more concrete observations gradually. Additionally, we incorporate a graph-enhanced decoder to capture the semantic relationships among words at different levels of observation. Furthermore, we perform a theoretical analysis of the proposed model based on the principle of information theory and show how it can alleviate the well-known "latent variable collapse" problem. Finally, extensive experiments demonstrate that our proposed model effectively improves the ability of deep topic models, resulting in higher-quality latent document representations and topics.

**摘要:** 本文提出了一种基于知识的纹理数据粗糙化过程和相应的累进累进累进模型的新型累进性主题模型,该模型用于建构从具体到抽象的多种层次的观察,而后者则用于逐步生成更具体的观察。此外,本文还采用了图形增强解码器来捕捉不同层次的观察中词语之间的语义关系。同时,基于信息理论原理,对拟议模型进行了理论分析,表明该模型能够缓解已知的“潜在变量崩溃”问题。最后,广泛的实验表明,拟议模型有效地提高了深度主题模型的能力,从而产生高质量的潜在文档表示和主题。

**[Paper URL](https://proceedings.mlr.press/v202/duan23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/duan23c/duan23c.pdf)** 

# Are Equivariant Equilibrium Approximators Beneficial?
**题目:** 等价均衡近似是有益的 吗?

**作者:** Zhijian Duan, Yunxuan Ma, Xiaotie Deng

**Abstract:** Recently, remarkable progress has been made by approximating Nash equilibrium (NE), correlated equilibrium (CE), and coarse correlated equilibrium (CCE) through function approximation that trains a neural network to predict equilibria from game representations. Furthermore, equivariant architectures are widely adopted in designing such equilibrium approximators in normal-form games. In this paper, we theoretically characterize the benefits and limitations of equivariant equilibrium approximators. For the benefits, we show that they enjoy better generalizability than general ones and can achieve better approximations when the payoff distribution is permutation-invariant. For the limitations, we discuss their drawbacks in terms of equilibrium selection and social welfare. Together, our results help to understand the role of equivariance in equilibrium approximators.

**摘要:** 通过函数近似,训练神经网络从游戏表现中预测平衡,通过近似纳什均衡(NE)、相关均衡(CE)和粗相关均衡(CCE)取得了显著的进展。此外,等效架构在设计正常形式游戏中广泛采用等效均衡近似器。本文从理论上描述了等效均衡近似器的优点和局限性。

**[Paper URL](https://proceedings.mlr.press/v202/duan23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/duan23d/duan23d.pdf)** 

# Evaluating Self-Supervised Learning via Risk Decomposition
**题目:** 通过风险分解评估自我监督的学习

**作者:** Yann Dubois, Tatsunori Hashimoto, Percy Liang

**Abstract:** Self-supervised learning (SSL) is typically evaluated using a single metric (linear probing on ImageNet), which neither provides insight into tradeoffs between models nor highlights how to improve them. To address this, we propose an SSL risk decomposition, which generalizes the classical approximation-estimation decomposition. Our decomposition consists of four error terms: approximation, representation usability, probe generalization, and encoder generalization. We provide efficient estimators for each term and use them to analyze the effect of 30 design choices on 169 SSL vision models evaluated on ImageNet. Our analysis gives valuable insights for designing and using SSL models. For example, it highlights the main source of errors and shows how to improve SSL in specific settings (full- vs few-shot) by trading off error components.

**摘要:** 自我监督学习(SSL)通常以单一的度量(ImageNet上的线性探测)来评估,它既不提供模型间的交易洞察,也不突出如何改进它们。为了解决这个问题,我们提出了一个SSL风险分解,它一般化了经典的近似-估计分解。我们的分解由四个错误条款组成:近似、表示可用性、探测一般化和编码器一般化。我们为每个术语提供有效的估计者,并使用它们来分析在ImageNet上评估的169个SSL视觉模型的30个设计选择的影响。我们的分析为设计和使用SSL模型提供了宝贵的洞察。

**[Paper URL](https://proceedings.mlr.press/v202/dubois23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dubois23a/dubois23a.pdf)** 

# Fully Dynamic Submodular Maximization over Matroids
**题目:** 完全动态的子模态最大化在模板上

**作者:** Paul Duetting, Federico Fusco, Silvio Lattanzi, Ashkan Norouzi-Fard, Morteza Zadimoghaddam

**Abstract:** Maximizing monotone submodular functions under a matroid constraint is a classic algorithmic problem with multiple applications in data mining and machine learning. We study this classic problem in the fully dynamic setting, where elements can be both inserted and deleted in real-time. Our main result is a randomized algorithm that maintains an efficient data structure with an $\tilde{O}(k^2)$ amortized update time (in the number of additions and deletions) and yields a $4$-approximate solution, where $k$ is the rank of the matroid.

**摘要:** 在矩阵约束下最大化单调子模块函数是数据挖掘和机器学习中应用的经典算法问题。我们研究了这一经典问题在完全动态设置中,其中元素可以在实时插入和删除。我们的主要结果是随机化算法,它保持了具有$\tilde{O}(k^2)$ amortized更新时间(在增加和删除的数目中)的高效数据结构,并给出了一个$4$的近似解决方案,其中$k$是矩阵的等级。

**[Paper URL](https://proceedings.mlr.press/v202/duetting23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/duetting23a/duetting23a.pdf)** 

# Optimal No-Regret Learning for One-Sided Lipschitz Functions
**题目:** 对单边利普希茨函数的优化无记号学习

**作者:** Paul Duetting, Guru Guruganesh, Jon Schneider, Joshua Ruizhi Wang

**Abstract:** Inspired by applications in pricing and contract design, we study the maximization of one-sided Lipschitz functions, which only provide the (weaker) guarantee that they do not grow too quickly in one direction. We show that it is possible to learn a maximizer for such a function while incurring $O(\log \log T)$ total regret (with a universal constant independent of the number of discontinuities / complexity of the function). This regret bound is asymptotically optimal in $T$ due to a lower bound of Kleinberg and Leighton. By applying this algorithm, we show that one can sell digital goods to multiple buyers and learn the optimal linear contract in the principal-agent setting while incurring at most $O(\log \log T)$ regret.

**摘要:** 基于定价和合同设计的应用,我们研究了单边利普希茨函数的最大化,这些函数只提供(较弱的)保证,它们不会在一个方向增长得太快。我们证明,在产生$O(\log \log T)$总遗憾时,可以学习一个最大化函数(具有独立于函数的连续性/复杂性数的通用常数)。

**[Paper URL](https://proceedings.mlr.press/v202/duetting23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/duetting23b/duetting23b.pdf)** 

# Integrating Prior Knowledge in Contrastive Learning with Kernel
**题目:** 整合原先知识与核对应学习

**作者:** Benoit Dufumier, Carlo Alberto Barbano, Robin Louiset, Edouard Duchesnay, Pietro Gori

**Abstract:** Data augmentation is a crucial component in unsupervised contrastive learning (CL). It determines how positive samples are defined and, ultimately, the quality of the learned representation. In this work, we open the door to new perspectives for CL by integrating prior knowledge, given either by generative models - viewed as prior representations - or weak attributes in the positive and negative sampling. To this end, we use kernel theory to propose a novel loss, called decoupled uniformity, that i) allows the integration of prior knowledge and ii) removes the positive-negative coupling in the original InfoNCE loss. We draw a connection between contrastive learning and the conditional mean embedding theory to derive tight bounds on the downstream classification loss. In an unsupervised setting, we empirically demonstrate that CL benefits from generative models to improve its representation both on natural and medical images. In a weakly supervised scenario, our framework outperforms other unconditional and conditional CL approaches.

**摘要:** 数据增强是无监督的对比性学习(CL)中的一个关键组成部分,它决定了如何确定正样品,最终决定了学习表现的质量。在这项工作中,我们通过整合前知识,通过生成模型(视作前表现)或在正面和负样品中弱属性,为CL开放了新的视角。为此目的,我们使用核理论提出一种新损失,称为脱耦合均匀性,即(i)允许整合前知识,(ii)消除原始InfoNCE损失中的正负耦合。在缺乏监督的情况下,我们的框架优于其他无条件和条件的 CL 方法。

**[Paper URL](https://proceedings.mlr.press/v202/dufumier23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dufumier23a/dufumier23a.pdf)** 

# Q-Flow: Generative Modeling for Differential Equations of Open Quantum Dynamics with Normalizing Flows
**题目:** Q-Flow:开放量子动力学微分方程与正常化流的生成模型

**作者:** Owen M Dugan, Peter Y. Lu, Rumen Dangovski, Di Luo, Marin Soljacic

**Abstract:** Studying the dynamics of open quantum systems can enable breakthroughs both in fundamental physics and applications to quantum engineering and quantum computation. Since the density matrix $\rho$, which is the fundamental description for the dynamics of such systems, is high-dimensional, customized deep generative neural networks have been instrumental in modeling $\rho$. However, the complex-valued nature and normalization constraints of $\rho$, as well as its complicated dynamics, prohibit a seamless connection between open quantum systems and the recent advances in deep generative modeling. Here we lift that limitation by utilizing a reformulation of open quantum system dynamics to a partial differential equation (PDE) for a corresponding probability distribution $Q$, the Husimi Q function. Thus, we model the Q function seamlessly with off-the-shelf deep generative models such as normalizing flows. Additionally, we develop novel methods for learning normalizing flow evolution governed by high-dimensional PDEs based on the Euler method and the application of the time-dependent variational principle. We name the resulting approach Q-Flow and demonstrate the scalability and efficiency of Q-Flow on open quantum system simulations, including the dissipative harmonic oscillator and the dissipative bosonic model. Q-Flow is superior to conventional PDE solvers and state-of-the-art physics-informed neural network solvers, especially in high-dimensional systems.

**摘要:** 研究开放量子系统动力学可以使基础物理学和量子工程和量子计算的应用取得突破。因为密度矩阵$rho$是这种系统动力学的基本描述,是高维、定制的深度生成神经网络在$rho$建模中起到了重要作用。然而,$rho$的复杂值性质和规范约束以及其复杂的动力学,禁止开放量子系统与深生成建模的最新进展之间的无缝连接。此外,我们开发了基于欧勒方法和时间依赖变异原理的高维PDEs控制流演化规范化的新方法。我们命名了结果的方法Q-Flow,并证明了Q-Flow在开放量子系统仿真中,包括散发谐振振器和散发波子模型的可扩展性和效率。Q-Flow优于传统的PDE求解器和最先进的物理信息神经网络求解器,特别是在高维系统中。

**[Paper URL](https://proceedings.mlr.press/v202/dugan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dugan23a/dugan23a.pdf)** 

# Adaptive Whitening in Neural Populations with Gain-modulating Interneurons
**题目:** 神经群内增益调节性神经元适应性白化

**作者:** Lyndon Duong, David Lipshutz, David Heeger, Dmitri Chklovskii, Eero P Simoncelli

**Abstract:** Statistical whitening transformations play a fundamental role in many computational systems, and may also play an important role in biological sensory systems. Existing neural circuit models of adaptive whitening operate by modifying synaptic interactions; however, such modifications would seem both too slow and insufficiently reversible. Motivated by the extensive neuroscience literature on gain modulation, we propose an alternative model that adaptively whitens its responses by modulating the gains of individual neurons. Starting from a novel whitening objective, we derive an online algorithm that whitens its outputs by adjusting the marginal variances of an overcomplete set of projections. We map the algorithm onto a recurrent neural network with fixed synaptic weights and gain-modulating interneurons. We demonstrate numerically that sign-constraining the gains improves robustness of the network to ill-conditioned inputs, and a generalization of the circuit achieves a form of local whitening in convolutional populations, such as those found throughout the visual or auditory systems.

**摘要:** 统计白化变换在许多计算系统中起着根本作用,在生物感官系统中也起着重要的作用。现存的适应性白化神经回路模型通过修改神经相互作用进行操作,但这些修改似乎过于缓慢和无法逆转。我们根据有关增益调节的广泛神经科学文献,提出了一种适应性白化的替代模型,通过调节个体神经元的增益来调节其反应。从一种新颖的白化目标出发,我们得出一种在线算法,通过调整超完投影的边缘变异来使其输出白化。我们用数值证明,信号约束 gains 改善了网络对不良输入的鲁棒性,并且电路的一般化在卷积群中达到局部白化的形式,例如在视觉或听觉系统中发现的。

**[Paper URL](https://proceedings.mlr.press/v202/duong23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/duong23a/duong23a.pdf)** 

# Generalization Bounds using Data-Dependent Fractal Dimensions
**题目:** 使用数据依赖的断面维度的一般化边界

**作者:** Benjamin Dupuis, George Deligiannidis, Umut Simsekli

**Abstract:** Providing generalization guarantees for modern neural networks has been a crucial task in statistical learning. Recently, several studies have attempted to analyze the generalization error in such settings by using tools from fractal geometry. While these works have successfully introduced new mathematical tools to apprehend generalization, they heavily rely on a Lipschitz continuity assumption, which in general does not hold for neural networks and might make the bounds vacuous. In this work, we address this issue and prove fractal geometry-based generalization bounds without requiring any Lipschitz assumption. To achieve this goal, we build up on a classical covering argument in learning theory and introduce a data-dependent fractal dimension. Despite introducing a significant amount of technical complications, this new notion lets us control the generalization error (over either fixed or random hypothesis spaces) along with certain mutual information (MI) terms. To provide a clearer interpretation to the newly introduced MI terms, as a next step, we introduce a notion of ‘geometric stability’ and link our bounds to the prior art. Finally, we make a rigorous connection between the proposed data-dependent dimension and topological data analysis tools, which then enables us to compute the dimension in a numerically efficient way. We support our theory with experiments conducted on various settings.

**摘要:** 为现代神经网络提供广义保证一直是统计学学习中的一个关键任务。最近,几项研究试图通过从分形几何中使用工具来分析这种设置中的广义误差。虽然这些研究成功地引入了新的数学工具来理解广义,但它们严重依赖于 Lipschitz连续性假设,这一般不适用于神经网络,可能使边界空洞。为了为新引入的MI术语提供更清晰的解释,我们作为下一步引入了“几何稳定性”的概念,并将我们的界限与现有技术联系起来。最后,我们将提议的数据依赖维度与拓扑数据分析工具之间进行严格的联系,从而使我们能够以数值效率的方式计算维度。

**[Paper URL](https://proceedings.mlr.press/v202/dupuis23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dupuis23a/dupuis23a.pdf)** 

# Multi-Objective Population Based Training
**题目:** 多目标人口训练

**作者:** Arkadiy Dushatskiy, Alexander Chebykin, Tanja Alderliesten, Peter Bosman

**Abstract:** Population Based Training (PBT) is an efficient hyperparameter optimization algorithm. PBT is a single-objective algorithm, but many real-world hyperparameter optimization problems involve two or more conflicting objectives. In this work, we therefore introduce a multi-objective version of PBT, MO-PBT. Our experiments on diverse multi-objective hyperparameter optimization problems (Precision/Recall, Accuracy/Fairness, Accuracy/Adversarial Robustness) show that MO-PBT outperforms random search, single-objective PBT, and the state-of-the-art multi-objective hyperparameter optimization algorithm MO-ASHA.

**摘要:** 基于人口训练(PBT)是一种高效的参数优化算法。PBT是一个单目标算法,但许多实物参数优化问题涉及两个或多个相互冲突的目标。因此,我们介绍了PBT的多目标版本,MO-PBT。我们对多种多目标参数优化问题(精确/回忆、准确/公平、准确/敌对鲁棒)的实验表明,MO-PBT优于随机搜索、单目标PBT和最先进的多目标参数优化算法MO-ASHA。

**[Paper URL](https://proceedings.mlr.press/v202/dushatskiy23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dushatskiy23a/dushatskiy23a.pdf)** 

# Neural Diffusion Processes
**题目:** 神经扩散过程

**作者:** Vincent Dutordoir, Alan Saul, Zoubin Ghahramani, Fergus Simpson

**Abstract:** Neural network approaches for meta-learning distributions over functions have desirable properties such as increased flexibility and a reduced complexity of inference. Building on the successes of denoising diffusion models for generative modelling, we propose Neural Diffusion Processes (NDPs), a novel approach that learns to sample from a rich distribution over functions through its finite marginals. By introducing a custom attention block we are able to incorporate properties of stochastic processes, such as exchangeability, directly into the NDP’s architecture. We empirically show that NDPs can capture functional distributions close to the true Bayesian posterior, demonstrating that they can successfully emulate the behaviour of Gaussian processes and surpass the performance of neural processes. NDPs enable a variety of downstream tasks, including regression, implicit hyperparameter marginalisation, non-Gaussian posterior prediction and global optimisation.

**摘要:** 神经网络方法对函数的元学习分布具有增加灵活性和降低推理复杂性等理想的特性。基于代数建模的扩散模型的成功,我们提出了神经扩散过程(NDPs),一种新的方法,它通过有限边界学习从函数的丰富分布中采样。通过引入定制的注意块,我们能够将随机过程的特性,如交换性,直接纳入NDP的架构。我们实验证明,NDPs能够捕捉与真正的贝叶斯后方相近的函数分布,证明它们能够成功地模拟高斯过程的行为并超越神经过程的性能。

**[Paper URL](https://proceedings.mlr.press/v202/dutordoir23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/dutordoir23a/dutordoir23a.pdf)** 

# FAENet: Frame Averaging Equivariant GNN for Materials Modeling
**题目:** FAENet:材料建模框架平均等价GNN

**作者:** Alexandre Agm Duval, Victor Schmidt, Alex Hernández-Garcı́a, Santiago Miret, Fragkiskos D. Malliaros, Yoshua Bengio, David Rolnick

**Abstract:** Applications of machine learning techniques for materials modeling typically involve functions that are known to be equivariant or invariant to specific symmetries. While graph neural networks (GNNs) have proven successful in such applications, conventional GNN approaches that enforce symmetries via the model architecture often reduce expressivity, scalability or comprehensibility. In this paper, we introduce (1) a flexible, model-agnostic framework based on stochastic frame averaging that enforces E(3) equivariance or invariance, without any architectural constraints; (2) FAENet: a simple, fast and expressive GNN that leverages stochastic frame averaging to process geometric information without constraints. We prove the validity of our method theoretically and demonstrate its superior accuracy and computational scalability in materials modeling on the OC20 dataset (S2EF, IS2RE) as well as common molecular modeling tasks (QM9, QM7-X).

**摘要:** 材料建模的机器学习技术通常涉及函数,这些函数被认为是对特定对称的等价或不等价。虽然图形神经网络(GNN)在这些应用中已经证明了成功,传统的GNN方法通过模型架构来实现对称,往往降低了表达性、可扩展性或理解性。本文介绍了(1)基于随机框架平均的灵活模型 agnostic框架,实现E(3)等价或不等价,无建筑约束;(2)FAENet:一种简单、快速和表达性的GNN,利用随机框架平均来处理无约束的几何信息。

**[Paper URL](https://proceedings.mlr.press/v202/duval23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/duval23a/duval23a.pdf)** 

# Blackout Diffusion: Generative Diffusion Models in Discrete-State Spaces
**题目:** 停电扩散:离散状态空间中的生成扩散模型

**作者:** Javier E. Santos, Zachary R. Fox, Nicholas Lubbers, Yen Ting Lin

**Abstract:** Typical generative diffusion models rely on a Gaussian diffusion process for training the backward transformations, which can then be used to generate samples from Gaussian noise. However, real world data often takes place in discrete-state spaces, including many scientific applications. Here, we develop a theoretical formulation for arbitrary discrete-state Markov processes in the forward diffusion process using exact (as opposed to variational) analysis. We relate the theory to the existing continuous-state Gaussian diffusion as well as other approaches to discrete diffusion, and identify the corresponding reverse-time stochastic process and score function in the continuous-time setting, and the reverse-time mapping in the discrete-time setting. As an example of this framework, we introduce “Blackout Diffusion”, which learns to produce samples from an empty image instead of from noise. Numerical experiments on the CIFAR-10, Binarized MNIST, and CelebA datasets confirm the feasibility of our approach. Generalizing from specific (Gaussian) forward processes to discrete-state processes without a variational approximation sheds light on how to interpret diffusion models, which we discuss.

**摘要:** 典型的生成扩散模型依赖于高斯扩散过程来训练后向变换,然后可以用于产生高斯噪声的样品。然而,实物数据经常发生在离散状态空间中,包括许多科学应用。在此,我们开发了使用精确的(与变异性)分析对未来扩散过程中任意离散状态马可夫过程的理论公式。我们将理论与现有的连续状态高斯扩散以及离散扩散的其他方法联系起来,并确定相应的逆时随机过程和进度函数在连续时间设置中,以及逆时映射在离散时间设置中。CIFAR-10、 Binarized MNIST和CelebA数据集的数值实验证实了我们的方法的可行性。从特定(Gaussian)进化过程到没有变量近似的离散状态过程的一般化,揭示了如何解释扩散模型,我们讨论了这一点。

**[Paper URL](https://proceedings.mlr.press/v202/santos23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/santos23a/santos23a.pdf)** 

# The Computational Complexity of Concise Hypersphere Classification
**题目:** 简洁超球分类的计算复杂性

**作者:** Eduard Eiben, Robert Ganian, Iyad A. Kanj, Sebastian Ordyniak, Stefan Szeider

**Abstract:** Hypersphere classification is a classical and foundational method that can provide easy-to-process explanations for the classification of real-valued as well as binary data. However, obtaining an (ideally concise) explanation via hypersphere classification is much more difficult when dealing with binary data as opposed to real-valued data. In this paper, we perform the first complexity-theoretic study of the hypersphere classification problem for binary data. We use the fine-grained parameterized complexity paradigm to analyze the impact of structural properties that may be present in the input data as well as potential conciseness constraints. Our results include not only stronger lower bounds but also a number of new fixed-parameter algorithms for hypersphere classification of binary data, which can find an exact and concise explanation when one exists.

**摘要:** 超球分类是一种经典和基础的方法,可以为实值数据和二进制数据的分类提供易于处理的解释。然而,在处理二进制数据时,通过超球分类获得(理想简洁的)解释比实值数据更困难。本文对二进制数据的超球分类问题进行了首次复杂性理论研究,采用细微参数化复杂性范式分析了输入数据中可能存在的结构性特性以及潜在的简洁性约束的影响。

**[Paper URL](https://proceedings.mlr.press/v202/eiben23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/eiben23a/eiben23a.pdf)** 

# E$(n)$ Equivariant Message Passing Simplicial Networks
**题目:** E$(n)$ 传递简单网络的等价消息

**作者:** Floor Eijkelboom, Rob Hesselink, Erik J Bekkers

**Abstract:** This paper presents $\mathrm{E}(n)$ Equivariant Message Passing Simplicial Networks (EMPSNs), a novel approach to learning on geometric graphs and point clouds that is equivariant to rotations, translations, and reflections. EMPSNs can learn high-dimensional simplex features in graphs (e.g. triangles), and use the increase of geometric information of higher-dimensional simplices in an $\mathrm{E}(n)$ equivariant fashion. EMPSNs simultaneously generalize $\mathrm{E}(n)$ Equivariant Graph Neural Networks to a topologically more elaborate counterpart and provide an approach for including geometric information in Message Passing Simplicial Networks, thereby serving as a proof of concept for combining geometric and topological information in graph learning. The results indicate that EMPSNs can leverage the benefits of both approaches, leading to a general increase in performance when compared to either method individually, being on par with state-of-the-art approaches for learning on geometric graphs. Moreover, the results suggest that incorporating geometric information serves as an effective measure against over-smoothing in message passing networks, especially when operating on high-dimensional simplicial structures.

**摘要:** 该文介绍了一种新的对几何图和点云的学习方法,是对旋转、翻译和反射等价的。 EMPSN可以学习图(例如三角形)中高维简化特征,并以等价的方式利用高维简化的几何信息的增加。 EMPSN同时将等价图神经网络推广到拓扑上更精确的类别,并提供一种包括几何信息在 message passing simple networks中的方法,从而证明了在图学中结合几何和拓扑信息的概念。结果表明,EMPSN可以利用两种方法的优点,在单一方法上总体提高性能,与最先进的几何图学习方法相等。此外,结果表明,采用几何信息作为信息传递网络中过多的干扰的有效措施,特别是在操作高维简单结构时。

**[Paper URL](https://proceedings.mlr.press/v202/eijkelboom23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/eijkelboom23a/eijkelboom23a.pdf)** 

# Performative Recommendation: Diversifying Content via Strategic Incentives
**题目:** 执行建议:通过战略激励来多样化内容

**作者:** Itay Eilat, Nir Rosenfeld

**Abstract:** The primary goal in recommendation is to suggest relevant content to users, but optimizing for accuracy often results in recommendations that lack diversity. To remedy this, conventional approaches such as re-ranking improve diversity by presenting more diverse items. Here we argue that to promote inherent and prolonged diversity, the system must encourage its creation. Towards this, we harness the performative nature of recommendation, and show how learning can incentivize strategic content creators to create diverse content. Our approach relies on a novel form of regularization that anticipates strategic changes to content, and penalizes for content homogeneity. We provide analytic and empirical results that demonstrate when and how diversity can be incentivized, and experimentally demonstrate the utility of our approach on synthetic and semi-synthetic data.

**摘要:** 建议的主要目标是向用户提供相关内容,但对准确性进行优化往往会导致缺乏多样性的建议。为了解决这一问题,传统的方法如重新排序以提出更多多样性项目来改善多样性。这里我们认为,为了促进固有和长期多样性,系统必须鼓励其创造。为此,我们利用建议的执行性性质,并展示学习如何鼓励战略内容创造者创造多样性内容。我们的方法依赖于一种新形式的规范化,预测内容的战略变化,并惩罚内容的均匀性。我们提供分析和实证结果,说明什么时候和如何可以鼓励多样性,并实验证明我们对合成和半合成数据的方法有用。

**[Paper URL](https://proceedings.mlr.press/v202/eilat23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/eilat23a/eilat23a.pdf)** 

# Hyperparameters in Reinforcement Learning and How To Tune Them
**题目:** 强化学习中的超参数及如何调制它们

**作者:** Theresa Eimer, Marius Lindauer, Roberta Raileanu

**Abstract:** In order to improve reproducibility, deep reinforcement learning (RL) has been adopting better scientific practices such as standardized evaluation metrics and reporting. However, the process of hyperparameter optimization still varies widely across papers, which makes it challenging to compare RL algorithms fairly. In this paper, we show that hyperparameter choices in RL can significantly affect the agent’s final performance and sample efficiency, and that the hyperparameter landscape can strongly depend on the tuning seed which may lead to overfitting. We therefore propose adopting established best practices from AutoML, such as the separation of tuning and testing seeds, as well as principled hyperparameter optimization (HPO) across a broad search space. We support this by comparing multiple state-of-the-art HPO tools on a range of RL algorithms and environments to their hand-tuned counterparts, demonstrating that HPO approaches often have higher performance and lower compute overhead. As a result of our findings, we recommend a set of best practices for the RL community, which should result in stronger empirical results with fewer computational costs, better reproducibility, and thus faster progress. In order to encourage the adoption of these practices, we provide plug-and-play implementations of the tuning algorithms used in this paper at https://github.com/facebookresearch/how-to-autorl.

**摘要:** 为了提高可复制性,深度增强学习(RL)已经采用了更好的科学实践,例如标准化评价指标和报告。然而,高参数优化的过程在论文中仍然有很大差异,这使得公平地比较RL算法具有挑战性。本论文中,我们表明,RL中的高参数选择可以显著影响代理的最终性能和样品效率,高参数景观也严重依赖于调制种子,这可能导致过度匹配。我们通过对多种RL算法和环境中的多个最先进的HPO工具进行比较,证明HPO方法往往具有较高的性能和较低的计算成本。 结果,我们建议为RL社区制定一套最佳实践,以减少计算成本,提高可复制性,从而更快地取得经验结果。 为了鼓励采用这些实践,我们提供在本论文中使用的调制算法的插件和游戏实现 https://github.com/facebookresearch/how-to-autorl。

**[Paper URL](https://proceedings.mlr.press/v202/eimer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/eimer23a/eimer23a.pdf)** 

# Fairness in Streaming Submodular Maximization over a Matroid Constraint
**题目:** 马特罗伊约束下的 Streaming Submodular Maximization中的公平性

**作者:** Marwa El Halabi, Federico Fusco, Ashkan Norouzi-Fard, Jakab Tardos, Jakub Tarnawski

**Abstract:** Streaming submodular maximization is a natural model for the task of selecting a representative subset from a large-scale dataset. If datapoints have sensitive attributes such as gender or race, it becomes important to enforce fairness to avoid bias and discrimination. This has spurred significant interest in developing fair machine learning algorithms. Recently, such algorithms have been developed for monotone submodular maximization under a cardinality constraint. In this paper, we study the natural generalization of this problem to a matroid constraint. We give streaming algorithms as well as impossibility results that provide trade-offs between efficiency, quality and fairness. We validate our findings empirically on a range of well-known real-world applications: exemplar-based clustering, movie recommendation, and maximum coverage in social networks.

**摘要:** 流域子模态最大化是 choosing a representative subset from a large-scale dataset 的任务的自然模型,如果数据点具有敏感属性,如性别或种族,就必须执行公平,避免偏见和歧视,这使得开发公平机器学习算法具有重大的兴趣。最近,这种算法已经被开发为单调子模态最大化在基数约束下。

**[Paper URL](https://proceedings.mlr.press/v202/el-halabi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/el-halabi23a/el-halabi23a.pdf)** 

# Difference of submodular minimization via DC programming
**题目:** 通过DC编程的子模块化最小化差异

**作者:** Marwa El Halabi, George Orfanides, Tim Hoheisel

**Abstract:** Minimizing the difference of two submodular (DS) functions is a problem that naturally occurs in various machine learning problems. Although it is well known that a DS problem can be equivalently formulated as the minimization of the difference of two convex (DC) functions, existing algorithms do not fully exploit this connection. A classical algorithm for DC problems is called the DC algorithm (DCA). We introduce variants of DCA and its complete form (CDCA) that we apply to the DC program corresponding to DS minimization. We extend existing convergence properties of DCA, and connect them to convergence properties on the DS problem. Our results on DCA match the theoretical guarantees satisfied by existing DS algorithms, while providing a more complete characterization of convergence properties. In the case of CDCA, we obtain a stronger local minimality guarantee. Our numerical results show that our proposed algorithms outperform existing baselines on two applications: speech corpus selection and feature selection.

**摘要:** 最小化两个子模函数的差异是各种机器学习问题中自然出现的问题。虽然众所周知,一个DS问题可以与两个凸函数的差异的最小化等式化,但现有的算法不能充分利用这种连接。DC问题的一个经典算法叫做DC算法(DCA)。我们引入DCA的变形及其完整的形式(CDCA),并将其应用于DC程序的DS最小化。我们扩展DCA的现有收敛特性,并将其连接到DS问题上的收敛特性。DCA的结果与现有的DS算法满足的理论保证相匹配,同时提供更完整的收敛特性的特征化。我们的数值结果表明,我们提出的算法在两种应用中优于现有的基准:语音体选择和特征选择。

**[Paper URL](https://proceedings.mlr.press/v202/el-halabi23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/el-halabi23b/el-halabi23b.pdf)** 

# Graph Positional Encoding via Random Feature Propagation
**题目:** 通过随机特性推广的图位编码

**作者:** Moshe Eliasof, Fabrizio Frasca, Beatrice Bevilacqua, Eran Treister, Gal Chechik, Haggai Maron

**Abstract:** Two main families of node feature augmentation schemes have been explored for enhancing GNNs: random features and spectral positional encoding. Surprisingly, however, there is still no clear understanding of the relation between these two augmentation schemes. Here we propose a novel family of positional encoding schemes which draws a link between the above two approaches and improves over both. The new approach, named Random Feature Propagation (RFP), is inspired by the power iteration method and its generalizations. It concatenates several intermediate steps of an iterative algorithm for computing the dominant eigenvectors of a propagation matrix, starting from random node features. Notably, these propagation steps are based on graph-dependent propagation operators that can be either predefined or learned. We explore the theoretical and empirical benefits of RFP. First, we provide theoretical justifications for using random features, for incorporating early propagation steps, and for using multiple random initializations. Then, we empirically demonstrate that RFP significantly outperforms both spectral PE and random features in multiple node classification and graph classification benchmarks.

**摘要:** 为增强GNN,研究了两个主要类别的节点特征增强方案:随机特征和光谱定位编码。然而,令人惊奇的是,目前还没有明确了解这两个增强方案之间的关系。我们提出了一种新类别的定位编码方案,该方案将上述两种方法之间的联系提取起来,并改进了两者。新的方法,名为随机特征推广(RFP),是源自功率迭代方法及其一般化。它将迭代算法的几个中间步骤归纳为计算传播矩阵的主导特征向量,从随机节点特征开始。首先,我们为使用随机特征、引入早期传播步骤和使用多个随机初始化提供了理论依据,然后,通过实验证明,在多节点分类和图形分类指标中,RFP在谱 PE和随机特征方面的表现显著 superiors both spectral PE and random features.

**[Paper URL](https://proceedings.mlr.press/v202/eliasof23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/eliasof23a/eliasof23a.pdf)** 

# Improving Graph Neural Networks with Learnable Propagation Operators
**题目:** 利用可学习传播操作器改进图形神经网络

**作者:** Moshe Eliasof, Lars Ruthotto, Eran Treister

**Abstract:** Graph Neural Networks (GNNs) are limited in their propagation operators. In many cases, these operators often contain non-negative elements only and are shared across channels, limiting the expressiveness of GNNs. Moreover, some GNNs suffer from over-smoothing, limiting their depth. On the other hand, Convolutional Neural Networks (CNNs) can learn diverse propagation filters, and phenomena like over-smoothing are typically not apparent in CNNs. In this paper, we bridge these gaps by incorporating trainable channel-wise weighting factors $\omega$ to learn and mix multiple smoothing and sharpening propagation operators at each layer. Our generic method is called $\omega$GNN, and is easy to implement. We study two variants: $\omega$GCN and $\omega$GAT. For $\omega$GCN, we theoretically analyse its behaviour and the impact of $\omega$ on the obtained node features. Our experiments confirm these findings, demonstrating and explaining how both variants do not over-smooth. Additionally, we experiment with 15 real-world datasets on node- and graph-classification tasks, where our $\omega$GCN and $\omega$GAT perform on par with state-of-the-art methods.

**摘要:** 图神经网络(GNN)在其传播操作者中受到限制。在许多情况下,这些操作者往往只包含非负性元素,并且在各通道中共享,限制GNN的表达性。此外,一些GNN也遭受了过度吸烟,限制了它们的深度。另一方面,volutional Neural Networks(CNNs)可以学习各种传播滤波器,并且像过度吸烟这样的现象通常在CNN中并不明显。在这个论文中,我们通过引入可训练的通道wise权重因子(英语:weighting factors)来修饰这些缺口,以便在每个层上学习和混合多个平滑和锐化传播操作者。我们的通用方法叫做$\omega$GNN,并易于实现。我们研究两个变量:$\omega$GCN和$\omega$GAT。此外,我们尝试了15个实世界数据集在节点和图类别任务上,其中我们的$omega$GCN和$omega$GAT与最先进的方法相等。

**[Paper URL](https://proceedings.mlr.press/v202/eliasof23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/eliasof23b/eliasof23b.pdf)** 

# Phase Transitions in the Detection of Correlated Databases
**题目:** 相相关数据库检测阶段过渡

**作者:** Dor Elimelech, Wasim Huleihel

**Abstract:** We study the problem of detecting the correlation between two Gaussian databases $\mathsf{X}\in\mathbb{R}^{n\times d}$ and $\mathsf{Y}^{n\times d}$, each composed of $n$ users with $d$ features. This problem is relevant in the analysis of social media, computational biology, etc. We formulate this as a hypothesis testing problem: under the null hypothesis, these two databases are statistically independent. Under the alternative, however, there exists an unknown permutation $\sigma$ over the set of $n$ users (or, row permutation), such that $\mathsf{X}$ is $\rho$-correlated with $\mathsf{Y}^\sigma$, a permuted version of $\mathsf{Y}$. We determine sharp thresholds at which optimal testing exhibits a phase transition, depending on the asymptotic regime of $n$ and $d$. Specifically, we prove that if $\rho^2d\to0$, as $d\to\infty$, then weak detection (performing slightly better than random guessing) is statistically impossible, irrespectively of the value of $n$. This compliments the performance of a simple test that thresholds the sum all entries of $\mathsf{X}^T\mathsf{Y}$. Furthermore, when $d$ is fixed, we prove that strong detection (vanishing error probability) is impossible for any $\rho<\rho^\star$, where $\rho^\star$ is an explicit function of $d$, while weak detection is again impossible as long as $\rho^2d=o(1)$, as $n\to\infty$. These results close significant gaps in current recent related studies.

**摘要:** 我们研究了两个高斯数据库 $\mathsf{X}\in\mathbb{R}^{n\times d}$ 和 $\mathsf{Y}^{n\times d}$ 之间关联的检测问题,每个由 $n$ 用户组成,具有 $d$ 特征。 该问题在社交媒体 、 计算生物学等分析中具有意义。 我们将此定为假设测试问题:在空假设下,这两个数据库是统计上独立的。 然而,在替代方案下,存在一个未知的 permutation $\sigma$ 在 $n$ 用户集合上(或,行 permutation ), 使得 $\mathsf{X}$ 与 $\rho$ - 关联的 $\mathsf{Y}^\sigma$, 是 $\mathsf{Y}$这样可以完成一个简单的测试,它将$d$的所有输入的总值计算为阈值。 此外,当$d$被固定时,我们证明 strong detection (vanishing error probability) 对于任何$rho<\rho^\star$是不可能的,其中$rho^\star$是一个$d$的显式函数,而 weak detection 则再次是不可能的,只要$rho^2d=o(1)$,即$n\to\infty$。

**[Paper URL](https://proceedings.mlr.press/v202/elimelech23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/elimelech23a/elimelech23a.pdf)** 

# A new near-linear time algorithm for k-nearest neighbor search using a compressed cover tree
**题目:** 利用压缩覆盖树进行近线性时间算法的近邻搜索

**作者:** Yury Elkin, Vitaliy Kurlin

**Abstract:** Given a reference set R of n points and a query set Q of m points in a metric space, this paper studies an important problem of finding k-nearest neighbors of every point q of Q in the set R in a near-linear time. In the paper at ICML 2006, Beygelzimer, Kakade, and Langford introduced a cover tree and attempted to prove that this tree can be built in O(n log n) time while the nearest neighbor search can be done O(n log m) time with a hidden dimensionality factor. In 2015, section 5.3 of Curtin’s PhD pointed out that the proof of the latter claim can have a serious gap in time complexity estimation. A paper at TopoInVis 2022 reported explicit counterexamples for a key step in the proofs of both claims. The past obstacles will be overcome by a simpler compressed cover tree on the reference set R. The first new algorithm constructs a compressed cover tree in O(n log n) time. The second new algorithm finds all k-nearest neighbors of all points from Q using a compressed cover tree in time O(m(k+log n)log k) with a hidden dimensionality factor depending on point distributions of the sets R,Q but not on their sizes.

**摘要:** 给出了 n点的参考集合R和 m点的查询集合Q,本文研究了在近线性时间里在集合R中每点Q的k-最近邻的发现的一个重要问题。在ICML2006年的论文中,贝格尔齐默、卡卡德和兰格福德引入了覆盖树,并试图证明该树可以在O(n log n)时间建造,而最近邻的搜索可以在O(n log m)时间进行,以隐藏维度因子。第二种新的算法利用时间 O(m(k+log n)log k) 压缩覆盖树找到所有Q点的k-最近邻,其隐藏维度因子取决于集合 R,Q的点分布,但不取决于它们的大小。

**[Paper URL](https://proceedings.mlr.press/v202/elkin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/elkin23a/elkin23a.pdf)** 

# Motion Question Answering via Modular Motion Programs
**题目:** 通过模块化运动程序回答运动问题

**作者:** Mark Endo, Joy Hsu, Jiaman Li, Jiajun Wu

**Abstract:** In order to build artificial intelligence systems that can perceive and reason with human behavior in the real world, we must first design models that conduct complex spatio-temporal reasoning over motion sequences. Moving towards this goal, we propose the HumanMotionQA task to evaluate complex, multi-step reasoning abilities of models on long-form human motion sequences. We generate a dataset of question-answer pairs that require detecting motor cues in small portions of motion sequences, reasoning temporally about when events occur, and querying specific motion attributes. In addition, we propose NSPose, a neuro-symbolic method for this task that uses symbolic reasoning and a modular design to ground motion through learning motion concepts, attribute neural operators, and temporal relations. We demonstrate the suitability of NSPose for the HumanMotionQA task, outperforming all baseline methods.

**摘要:** 为了建立在现实世界中能够感知和推理人类行为的人工智能系统,我们必须首先设计模型来对运动序列进行复杂时空推理。为了实现这一目标,我们提出了HumanMotionQA任务,以评价模型在长形人类运动序列上的复杂、多步推理能力。我们生成了一个数据集的问答对,需要在运动序列的小部分检测运动提示,对事件发生时进行时空推理,并查询特定运动属性。此外,我们提出了NSPose,一种使用符号推理和模块化设计的神经符号方法,通过学习运动概念、属性神经操作者和时间关系来实现地面运动。

**[Paper URL](https://proceedings.mlr.press/v202/endo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/endo23a/endo23a.pdf)** 

# Learning Perturbations to Explain Time Series Predictions
**题目:** 学习障碍解释时间序列预测

**作者:** Joseph Enguehard

**Abstract:** Explaining predictions based on multivariate time series data carries the additional difficulty of handling not only multiple features, but also time dependencies. It matters not only what happened, but also when, and the same feature could have a very different impact on a prediction depending on this time information. Previous work has used perturbation-based saliency methods to tackle this issue, perturbing an input using a trainable mask to discover which features at which times are driving the predictions. However these methods introduce fixed perturbations, inspired from similar methods on static data, while there seems to be little motivation to do so on temporal data. In this work, we aim to explain predictions by learning not only masks, but also associated perturbations. We empirically show that learning these perturbations significantly improves the quality of these explanations on time series data.

**摘要:** 基于多变量时间序列的数据解释预测,不仅涉及多个特征,也涉及时间依赖性。它不仅涉及发生什么,而且涉及何时,并且同样的特征可以根据时间信息对预测产生非常不同的影响。以前的工作使用了基于扰动的偏差方法来解决这一问题,用训练可变的面具扰动输入来发现哪些特征在何时驱动预测。然而,这些方法引入了固定扰动,从静态数据上类似的方法获得灵感,但似乎在时间数据上没有多少动机。

**[Paper URL](https://proceedings.mlr.press/v202/enguehard23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/enguehard23a/enguehard23a.pdf)** 

# Regret Minimization and Convergence to Equilibria in General-sum Markov Games
**题目:** 对总sum马可夫游戏的缩小和均衡表示遗憾

**作者:** Liad Erez, Tal Lancewicki, Uri Sherman, Tomer Koren, Yishay Mansour

**Abstract:** An abundance of recent impossibility results establish that regret minimization in Markov games with adversarial opponents is both statistically and computationally intractable. Nevertheless, none of these results preclude the possibility of regret minimization under the assumption that all parties adopt the same learning procedure. In this work, we present the first (to our knowledge) algorithm for learning in general-sum Markov games that provides sublinear regret guarantees when executed by all agents. The bounds we obtain are for $\textit{swap regret}$, and thus, along the way, imply convergence to a $\textit{correlated}$ equilibrium. Our algorithm is decentralized, computationally efficient, and does not require any communication between agents. Our key observation is that online learning via policy optimization in Markov games essentially reduces to a form of $\textit{weighted}$ regret minimization, with $\textit{unknown}$ weights determined by the path length of the agents’ policy sequence. Consequently, controlling the path length leads to weighted regret objectives for which sufficiently adaptive algorithms provide sublinear regret guarantees.

**摘要:** 许多最近的不可能结果表明,与对手的马可夫游戏中遗憾的最小化 both statistically and computationally intractable. 尽管如此,这些结果都没有排除在所有各方采用相同的学习程序下遗憾的最小化的可能性。在这个工作中,我们提出了第一个(我们知道的)在一般sum马可夫游戏中学习的算法,它提供由所有代理执行时的次线性遗憾保证。我们得到的边界为$\textit{swap regret}$,因此,沿途,意味着对$\textit{correlated}$平衡的收敛。我们的算法是分散的,计算效率很高,并且不需要代理之间的任何通信。我们的主要观察是,通过策略优化的在线学习在马可夫游戏中基本上减少到一种形式的$\textit{weighted}$遗憾最小化,而$\textit{unknown}$重量由代理人的策略序列路径长度决定。

**[Paper URL](https://proceedings.mlr.press/v202/erez23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/erez23a/erez23a.pdf)** 

# Delayed Bandits: When Do Intermediate Observations Help?
**题目:** 延迟盗窃: 中期观察什么时候能帮助 呢?

**作者:** Emmanuel Esposito, Saeed Masoudian, Hao Qiu, Dirk Van Der Hoeven, Nicolò Cesa-Bianchi, Yevgeny Seldin

**Abstract:** We study a $K$-armed bandit with delayed feedback and intermediate observations. We consider a model, where intermediate observations have a form of a finite state, which is observed immediately after taking an action, whereas the loss is observed after an adversarially chosen delay. We show that the regime of the mapping of states to losses determines the complexity of the problem, irrespective of whether the mapping of actions to states is stochastic or adversarial. If the mapping of states to losses is adversarial, then the regret rate is of order $\sqrt{(K+d)T}$ (within log factors), where $T$ is the time horizon and $d$ is a fixed delay. This matches the regret rate of a $K$-armed bandit with delayed feedback and without intermediate observations, implying that intermediate observations are not helpful. However, if the mapping of states to losses is stochastic, we show that the regret grows at a rate of $\sqrt{\bigl(K+\min\{|\mathcal{S}|,d\}\bigr)T}$ (within log factors), implying that if the number $|\mathcal{S}|$ of states is smaller than the delay, then intermediate observations help. We also provide refined high-probability regret upper bounds for non-uniform delays, together with experimental validation of our algorithms.

**摘要:** 我们研究了带有延迟反馈和中间观察的$K$武装 bandit。我们考虑了一个模型,其中中间观察具有一个形式的有限状态,即在采取行动后立即观察到,而损失则在敌对选择的延迟后观察到。我们证明,状态对损失的映射的模式决定了问题的复杂性,不管行动对状态的映射是随机还是敌对的。如果状态对损失的映射是敌对的,那么遗憾率是$\sqrt{(K+d)T}$(在日志因子内)的顺序,$T$是时空和$d$是固定的延迟。这与带有延迟反馈和没有中间观察的$K$武装 bandit的遗憾率相匹配,暗示中间观察是无效的。然而,如果状态对损失的映射是随机性,我们表明遗憾增长的速率为$sqrt{\bigl(K+\min\{|\mathcal{S}|,d\}\bigr)T}$(在ログ因子内),这意味着如果状态$|\mathcal{S}|$的数目比延迟小,那么中间观测有助于。

**[Paper URL](https://proceedings.mlr.press/v202/esposito23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/esposito23a/esposito23a.pdf)** 

# Scaling Spherical CNNs
**题目:** 尺度球形CNN

**作者:** Carlos Esteves, Jean-Jacques Slotine, Ameesh Makadia

**Abstract:** Spherical CNNs generalize CNNs to functions on the sphere, by using spherical convolutions as the main linear operation. The most accurate and efficient way to compute spherical convolutions is in the spectral domain (via the convolution theorem), which is still costlier than the usual planar convolutions. For this reason, applications of spherical CNNs have so far been limited to small problems that can be approached with low model capacity. In this work, we show how spherical CNNs can be scaled for much larger problems. To achieve this, we make critical improvements including novel variants of common model components, an implementation of core operations to exploit hardware accelerator characteristics, and application-specific input representations that exploit the properties of our model. Experiments show our larger spherical CNNs reach state-of-the-art on several targets of the QM9 molecular benchmark, which was previously dominated by equivariant graph neural networks, and achieve competitive performance on multiple weather forecasting tasks. Our code is available at https://github.com/google-research/spherical-cnn.

**摘要:** 球形CNN一般化CNN为球面的函数,用球形卷曲作为主线性操作。计算球形卷曲的最准确和最有效的方法是在光谱域(通过卷曲定理)中,这仍然比通常的平面卷曲更昂贵。因此,球形CNN的应用迄今仅限于小问题,可以与低模型容量接近。实验显示,我们的大型球形CNN在QM9分子基准的几个目标上达到最先进的水平,此前由等效图神经网络主导,并在多个天气预报任务上取得竞争性表现。

**[Paper URL](https://proceedings.mlr.press/v202/esteves23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/esteves23a/esteves23a.pdf)** 

# Stochastic Gradient Descent under Markovian Sampling Schemes
**题目:** 马可维亚采样计划下的随机梯度下降

**作者:** Mathieu Even

**Abstract:** We study a variation of vanilla stochastic gradient descent where the optimizer only has access to a Markovian sampling scheme. These schemes encompass applications that range from decentralized optimization with a random walker (token algorithms), to RL and online system identification problems. We focus on obtaining rates of convergence under the least restrictive assumptions possible on the underlying Markov chain and on the functions optimized. We first unveil the theoretical lower bound for methods that sample stochastic gradients along the path of a Markov chain, making appear a dependency in the hitting time of the underlying Markov chain. We then study Markov chain SGD (MC-SGD) under much milder regularity assumptions than prior works. We finally introduce MC-SAG, an alternative to MC-SGD with variance reduction, that only depends on the hitting time of the Markov chain, therefore obtaining a communication-efficient token algorithm.

**摘要:** 我们研究了瓦尼拉随机梯度下降的变异,其中优化器只可访问马可夫采样方案。这些方案包括由分散优化与随机步行者(token算法)到RL和在线系统识别问题的应用程序。我们着眼于在潜在的马可夫链和优化函数上尽可能的最小限制性假设下获得收敛率。我们首先揭示了基于马可夫链的随机梯度样本方法的理论下界限,从而在触发马可夫链的触发时间上显示出依赖性。

**[Paper URL](https://proceedings.mlr.press/v202/even23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/even23a/even23a.pdf)** 

# Continual Learning in Linear Classification on Separable Data
**题目:** 分离数据线性分类的持续学习

**作者:** Itay Evron, Edward Moroshko, Gon Buzaglo, Maroun Khriesh, Badea Marjieh, Nathan Srebro, Daniel Soudry

**Abstract:** We analyze continual learning on a sequence of separable linear classification tasks with binary labels. We show theoretically that learning with weak regularization reduces to solving a sequential max-margin problem, corresponding to a special case of the Projection Onto Convex Sets (POCS) framework. We then develop upper bounds on the forgetting and other quantities of interest under various settings with recurring tasks, including cyclic and random orderings of tasks. We discuss several practical implications to popular training practices like regularization scheduling and weighting. We point out several theoretical differences between our continual classification setting and a recently studied continual regression setting.

**摘要:** 我们对可分离线性分类任务的序列进行连续学习分析,并用二进制标记进行分离线性分类任务。我们从理论上证明,与弱规则化学习减少到解决序列最大边际问题,符合投影向凸集(POCS)框架的特殊情况。然后,我们开发了在重复任务下 forgetting和其他数量的上限,包括任务的循环和随机排序。我们讨论了规范化计划和权重等流行训练实践的几种实际影响。

**[Paper URL](https://proceedings.mlr.press/v202/evron23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/evron23a/evron23a.pdf)** 

# A Connection between One-Step RL and Critic Regularization in Reinforcement Learning
**题目:** 一个步骤RL与强化学习中的关键规范化之间的联系

**作者:** Benjamin Eysenbach, Matthieu Geist, Sergey Levine, Ruslan Salakhutdinov

**Abstract:** As with any machine learning problem with limited data, effective offline RL algorithms require careful regularization to avoid overfitting. One class of methods, known as one-step RL, perform just one step of policy improvement. These methods, which include advantage-weighted regression and conditional behavioral cloning, are thus simple and stable, but can have limited asymptotic performance. A second class of methods, known as critic regularization, perform many steps of policy improvement with a regularized objective. These methods typically require more compute but have appealing lower-bound guarantees. In this paper, we draw a connection between these methods: applying a multi-step critic regularization method with a regularization coefficient of 1 yields the same policy as one-step RL. While our theoretical results require assumptions (e.g., deterministic dynamics), our experiments nevertheless show that our analysis makes accurate, testable predictions about practical offline RL methods (CQL and one-step RL) with commonly-used hyperparameters.

**摘要:** 与有限数据的任何机器学习问题一样,有效的非线性RL算法需要小心的规范化以避免过度匹配。一个类方法,称为一个步骤RL,只执行一个政策改进步骤。这些方法包括优越权重回归和条件行为克隆,因此简单稳定,但具有有限的渐近性能。虽然我们的理论结果需要假设(例如确定性动力学),但我们的实验表明,我们的分析能够用常用的超参数对实际的非线性RL方法(CQL和单步RL)作出准确、可测试的预测。

**[Paper URL](https://proceedings.mlr.press/v202/eysenbach23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/eysenbach23a/eysenbach23a.pdf)** 

# Neural Status Registers
**题目:** 神经状态登记册

**作者:** Lukas Faber, Roger Wattenhofer

**Abstract:** We study the problem of learning comparisons between numbers with neural networks. Despite comparisons being a seemingly simple problem, we find that both general-purpose models such as multilayer perceptrons (MLPs) as well as arithmetic architectures such as the Neural Arithmetic Logic Unit (NALU) struggle with learning comparisons. Neither architecture can extrapolate to much larger numbers than those seen in the training set. We propose a novel differentiable architecture, the Neural Status Register (NSR) to solve this problem. We experimentally validate the NSR in various settings. We can combine the NSR with other neural models to solve interesting problems such as piecewise-defined arithmetic, comparison of digit images, recurrent problems, or finding shortest paths in graphs. The NSR outperforms all baseline architectures, especially when it comes to extrapolating to larger numbers.

**摘要:** 我们研究了与神经网络的数字进行学习比较的问题。尽管比较是一个看似简单的问题,但我们发现两个通用模型,如多层感应器(MLPs)以及神经算术架构,如神经算术逻辑单元(NALU),都与学习比较作斗争。

**[Paper URL](https://proceedings.mlr.press/v202/faber23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/faber23a/faber23a.pdf)** 

# Learning Rate Schedules in the Presence of Distribution Shift
**题目:** 在分布 Shift 的出现下学习率表

**作者:** Matthew Fahrbach, Adel Javanmard, Vahab Mirrokni, Pratik Worah

**Abstract:** We design learning rate schedules that minimize regret for SGD-based online learning in the presence of a changing data distribution. We fully characterize the optimal learning rate schedule for online linear regression via a novel analysis with stochastic differential equations. For general convex loss functions, we propose new learning rate schedules that are robust to distribution shift, and give upper and lower bounds for the regret that only differ by constants. For non-convex loss functions, we define a notion of regret based on the gradient norm of the estimated models and propose a learning schedule that minimizes an upper bound on the total expected regret. Intuitively, one expects changing loss landscapes to require more exploration, and we confirm that optimal learning rate schedules typically have higher learning rates in the presence of distribution shift. Finally, we provide experiments that illustrate these learning rate schedules and their regret.

**摘要:** 我们设计了基于SGD的在线学习时间表,以减少改变数据分布时的遗憾。我们用随机微分方程进行新分析,全面描述了在线线性回归的最佳学习时间表。对于一般凸形损失函数,我们提出了新的学习时间表,以保证分布移动的鲁棒性,并给出仅以常数来区别的上下边界。对于非凸形损失函数,我们定义了基于估计模型的梯度规范的遗憾的概念,并提出了减少总预期遗憾的上限边界的学习时间表。

**[Paper URL](https://proceedings.mlr.press/v202/fahrbach23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fahrbach23a/fahrbach23a.pdf)** 

# Predicting Rare Events by Shrinking Towards Proportional Odds
**题目:** 按比例偏差缩小预测罕见事件

**作者:** Gregory Faletto, Jacob Bien

**Abstract:** Training classifiers is difficult with severe class imbalance, but many rare events are the culmination of a sequence with much more common intermediate outcomes. For example, in online marketing a user first sees an ad, then may click on it, and finally may make a purchase; estimating the probability of purchases is difficult because of their rarity. We show both theoretically and through data experiments that the more abundant data in earlier steps may be leveraged to improve estimation of probabilities of rare events. We present PRESTO, a relaxation of the proportional odds model for ordinal regression. Instead of estimating weights for one separating hyperplane that is shifted by separate intercepts for each of the estimated Bayes decision boundaries between adjacent pairs of categorical responses, we estimate separate weights for each of these transitions. We impose an L1 penalty on the differences between weights for the same feature in adjacent weight vectors in order to shrink towards the proportional odds model. We prove that PRESTO consistently estimates the decision boundary weights under a sparsity assumption. Synthetic and real data experiments show that our method can estimate rare probabilities in this setting better than both logistic regression on the rare category, which fails to borrow strength from more abundant categories, and the proportional odds model, which is too inflexible.

**摘要:** 例如,在在线营销中,用户首先看到一个广告,然后可以点击它,最后可以购买;估计购买的概率是由于其稀有性而困难的。我们通过理论和数据实验表明,在早期的步骤中,较丰富的数据可以被用来提高稀有事件的概率的估计。我们对邻近的重量向量中相同特征的重量之间的差额施加L1惩罚,以便缩小到比例概率模型。我们证明, PRESTO在稀疏假设下持续估计决策边界重量。合成和实际数据实验表明,我们的方法能够比从较丰富的类别借力不足的稀疏类别的后勤回归和 too inflexible的比例概率模型更好地估计这种条件中的稀疏概率。

**[Paper URL](https://proceedings.mlr.press/v202/faletto23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/faletto23a/faletto23a.pdf)** 

# Free-Form Variational Inference for Gaussian Process State-Space Models
**题目:** 高斯过程状态空间模型自由形式变量ference

**作者:** Xuhui Fan, Edwin V. Bonilla, Terence O’Kane, Scott A Sisson

**Abstract:** Gaussian process state-space models (GPSSMs) provide a principled and flexible approach to modeling the dynamics of a latent state, which is observed at discrete-time points via a likelihood model. However, inference in GPSSMs is computationally and statistically challenging due to the large number of latent variables in the model and the strong temporal dependencies between them. In this paper, we propose a new method for inference in Bayesian GPSSMs, which overcomes the drawbacks of previous approaches, namely over-simplified assumptions, and high computational requirements. Our method is based on free-form variational inference via stochastic gradient Hamiltonian Monte Carlo within the inducing-variable formalism. Furthermore, by exploiting our proposed variational distribution, we provide a collapsed extension of our method where the inducing variables are marginalized analytically. We also showcase results when combining our framework with particle MCMC methods. We show that, on six real-world datasets, our approach can learn transition dynamics and latent states more accurately than competing methods.

**摘要:** 高斯过程状态空间模型(GPSSMs)为通过概率模型在离散时点观察的潜在状态动力学提供一种原则性和灵活的建模方法。然而,GPSSMs的推导是由于模型中的大量潜在变量和它们之间的强烈时间依赖性,在计算和统计上具有挑战性。本文提出了 Bayesian GPSSMs的推导新方法,克服了以往方法的弊端,即过度简化假设和高计算要求。我们的方法基于在诱导变量形式中通过随机梯度汉密尔顿蒙特卡罗的自由形式变量推导。我们证明,在6个实物数据集中,我们的方法比其他方法更准确地学习过渡动力学和潜在状态。

**[Paper URL](https://proceedings.mlr.press/v202/fan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fan23a/fan23a.pdf)** 

# Optimizing DDPM Sampling with Shortcut Fine-Tuning
**题目:** 用短cut微调优化DDPM采样

**作者:** Ying Fan, Kangwook Lee

**Abstract:** In this study, we propose Shortcut Fine-Tuning (SFT), a new approach for addressing the challenge of fast sampling of pretrained Denoising Diffusion Probabilistic Models (DDPMs). SFT advocates for the fine-tuning of DDPM samplers through the direct minimization of Integral Probability Metrics (IPM), instead of learning the backward diffusion process. This enables samplers to discover an alternative and more efficient sampling shortcut, deviating from the backward diffusion process. Inspired by a control perspective, we propose a new algorithm SFT-PG: Shortcut Fine-Tuning with Policy Gradient, and prove that under certain assumptions, gradient descent of diffusion models with respect to IPM is equivalent to performing policy gradient. To our best knowledge, this is the first attempt to utilize reinforcement learning (RL) methods to train diffusion models. Through empirical evaluation, we demonstrate that our fine-tuning method can further enhance existing fast DDPM samplers, resulting in sample quality comparable to or even surpassing that of the full-step model across various datasets.

**摘要:** 在研究中,我们提出了短cut微调(SFT),一种解决预处理扩散概率模型(DDPM)的快速抽样挑战的新方法。SFT主张通过直接最小化积分概率度量(IPM)来对DDPM抽样器进行微调,而不是学习后继扩散过程。这使得抽样器能够从后继扩散过程中偏离,发现一种更有效的替代抽样短cut。通过实证评价,我们证明了我们的微调方法能够进一步提高现有快速DDPM样品器,从而使样品质量与全步模型相等甚至超过了不同数据集。

**[Paper URL](https://proceedings.mlr.press/v202/fan23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fan23b/fan23b.pdf)** 

# LSDS++ : Dual Sampling for Accelerated k-means++
**题目:** LSDS++ : 加速k-means的双重采样++

**作者:** Chenglin Fan, Ping Li, Xiaoyun Li

**Abstract:** k-means clustering is an important problem in machine learning and statistics. The k-means++ initialization algorithm has driven new acceleration strategies and theoretical analysis for solving the k-means clustering problem. The state-of-the-art variant, called LocalSearch++, adds extra local search steps upon k-means++ to achieve constant approximation error in expectation. In this paper, we propose a new variant named LSDS++, which improves the sampling efficiency of LocalSearch++ via a strategy called dual sampling. By defining a new capture graph based on the concept of coreset, we show that the proposed LSDS++ is able to achieve the same expected constant error with reduced complexity. Experiments are conducted to justify the benefit of LSDS++ in practice.

**摘要:** k-means群化是机器学习和统计学中的一个重要问题。k-means++初始化算法为解决k-means群化问题提供了新的加速策略和理论分析。最先进的变量,叫做LocalSearch++,在k-means++上增加了额外的局部搜索步骤,以实现预期中的定常近似误差。本论文提出了一种名为LSDS++的新变量,它通过一种叫做双样本的策略,提高了LocalSearch++的样本效率。

**[Paper URL](https://proceedings.mlr.press/v202/fan23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fan23c/fan23c.pdf)** 

# Smart Initial Basis Selection for Linear Programs
**题目:** 线性程序的智能初始基础选择

**作者:** Zhenan Fan, Xinglu Wang, Oleksandr Yakovenko, Abdullah Ali Sivas, Owen Ren, Yong Zhang, Zirui Zhou

**Abstract:** The simplex method, introduced by Dantzig more than half a century ago, is still to date one of the most efficient methods for solving large-scale linear programming (LP) problems. While the simplex method is known to have the finite termination property under mild assumptions, the number of iterations until optimality largely depends on the choice of initial basis. Existing strategies for selecting an advanced initial basis are mostly rule-based. These rules usually require extensive expert knowledge and empirical study to develop. Yet, many of them fail to exhibit consistent improvement, even for LP problems that arise in a single application scenario. In this paper, we propose a learning-based approach for initial basis selection. We employ graph neural networks as a building block and develop a model that attempts to capture the relationship between LP problems and their optimal bases. In addition, during the inference phase, we supplement the learning-based prediction with linear algebra tricks to ensure the validity of the generated initial basis. We validate the effectiveness of our proposed strategy by extensively testing it with state-of-the-art simplex solvers, including the open-source solver HiGHS and the commercial solver OptVerse. Through these rigorous experiments, we demonstrate that our strategy achieves substantial speedup and consistently outperforms existing rule-based methods. Furthermore, we extend the proposed approach to generating restricted master problems for column generation methods and present encouraging numerical results.

**摘要:** 简化法在半个世纪前由丹茨基引入,至今仍是解决大规模线性规划(LP)问题的最有效的方法之一。虽然简化法在温和假设下具有有限终止特性,但最大程度的迭代数取决于初始基础的选择。目前的选定高级初始基础的策略大多是基于规则的。这些规则通常需要广泛的专家知识和经验性研究来开发。然而,其中许多都未能表现出一致的改进,即使是在单个应用场景中出现的LP问题。此外,在推理阶段,我们还用线性代数技巧补充基于学习的预测,以确保生成的初始基础的有效性。我们通过广泛测试最先进的单元求解器,包括开放源求解器HGHS和商业求解器OptVerse,验证了我们所提议的策略的有效性。通过这些严格的实验,我们证明了我们所提议的策略能够大幅提高速度,并一致超越现有的规则求解方法。

**[Paper URL](https://proceedings.mlr.press/v202/fan23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fan23d/fan23d.pdf)** 

# General Covariance Data Augmentation for Neural PDE Solvers
**题目:** 神经PDE求解器的一般可变性数据增强

**作者:** Vladimir Fanaskov, Tianchi Yu, Alexander Rudikov, Ivan Oseledets

**Abstract:** The growing body of research shows how to replace classical partial differential equation (PDE) integrators with neural networks. The popular strategy is to generate the input-output pairs with a PDE solver, train the neural network in the regression setting, and use the trained model as a cheap surrogate for the solver. The bottleneck in this scheme is the number of expensive queries of a PDE solver needed to generate the dataset. To alleviate the problem, we propose a computationally cheap augmentation strategy based on general covariance and simple random coordinate transformations. Our approach relies on the fact that physical laws are independent of the coordinate choice, so the change in the coordinate system preserves the type of a parametric PDE and only changes PDE’s data (e.g., initial conditions, diffusion coefficient). For tried neural networks and partial differential equations, proposed augmentation improves test error by 23% on average. The worst observed result is a 17% increase in test error for multilayer perceptron, and the best case is a 80% decrease for dilated residual network.

**摘要:** 研究的不断增长表明,如何用神经网络取代经典偏微分方程(PDE)积分器。流行的策略是用PDE求解器生成输入输出对,在回归设置中训练神经网络,并使用训练模型作为求解器的廉价替代品。这个方案的瓶颈是求解器需要生成数据集的昂贵查询数目。为了缓解问题,我们提出了基于一般共变和简单的随机坐标变换的计算性廉价增加策略。我们的方法依赖于物理法是独立于坐标选择的事实,所以坐标系统的变化保留了参数PDE的类型,并且只改变PDE的数据(例如初始条件、扩散系数)。最糟糕的实验结果是多层感应器测试误差增加17%,最佳的实验结果是扩散剩余网络测试误差减少80%。

**[Paper URL](https://proceedings.mlr.press/v202/fanaskov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fanaskov23a/fanaskov23a.pdf)** 

# The Fast Johnson-Lindenstrauss Transform Is Even Faster
**题目:** 快速的约翰逊-林登斯特劳斯变换甚至更快

**作者:** Ora Nova Fandina, Mikael Møller Høgsgaard, Kasper Green Larsen

**Abstract:** The Johnson-Lindenstaruss lemma (Johnson & Lindenstrauss, 1984) is a cornerstone result in dimensionality reduction, stating it is possible to embed a set of $n$ points in $d$-dimensional Euclidean space into optimal $k=O(\varepsilon^{-2} \ln n)$ dimensions, while preserving all pairwise distances to within a factor $(1 \pm \varepsilon)$. The seminal Fast Johnson-Lindenstrauss (Fast JL) transform by Ailon and Chazelle (SICOMP’09) supports computing the embedding of a data point in $O(d \ln d +k \ln^2 n)$ time, where the $d \ln d$ term comes from multiplication with a $d \times d$ Hadamard matrix and the $k \ln^2 n$ term comes from multiplication with a sparse $k \times d$ matrix. Despite the Fast JL transform being more than a decade old, it is one of the fastest dimensionality reduction techniques for many tradeoffs between $\varepsilon, d$ and $n$. In this work, we give a surprising new analysis of the Fast JL transform, showing that the $k \ln^2 n$ term in the embedding time can be improved to $(k \ln^2 n)/\alpha$ for an $\alpha = \Omega(\min\{\varepsilon^{-1}\ln(1/\varepsilon), \ln n\})$. The improvement follows by using an even sparser matrix. We complement our improved analysis with a lower bound showing that our new analysis is in fact tight.

**摘要:** Johnson-Lindenstaruss lemma(Johnson & Lindenstrauss, 1984)是维度降解的基石结果,指出可以在d$-维欧几何空间中嵌入$n$点的集合,同时保存所有对数距离到一个因子$(1\pm \varepsilon)$内。在这项工作中,我们给出了快速JL变换的令人惊奇的新分析,显示在嵌入时间中$k \ln^2 n$语法可以改进到$(k \ln^2 n)/\alpha$为$\alpha = \Omega(\min\{\varepsilon^{-1}\ln(1/\varepsilon),\ln n\})$。

**[Paper URL](https://proceedings.mlr.press/v202/fandina23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fandina23a/fandina23a.pdf)** 

# Regression with Label Permutation in Generalized Linear Model
**题目:** 广义线性模型中的标签变换回归

**作者:** Guanhua Fang, Ping Li

**Abstract:** The assumption that response and predictor belong to the same statistical unit may be violated in practice. Unbiased estimation and recovery of true label ordering based on unlabeled data are challenging tasks and have attracted increasing attentions in the recent literature. In this paper, we present a relatively complete analysis of label permutation problem for the generalized linear model with multivariate responses. The theory is established under different scenarios, with knowledge of true parameters, with partial knowledge of underlying label permutation matrix and without any knowledge. Our results remove the stringent conditions required by the current literature and are further extended to the missing observation setting which has never been considered in the field of label permutation problem. On computational side, we propose two methods, "maximum likelihood estimation" algorithm and "two-step estimation" algorithm, to accommodate for different settings. When the proportion of permuted labels is moderate, both methods work effectively. Multiple numerical experiments are provided and corroborate our theoretical findings.

**摘要:** 本文对基于未标记数据的 true label 序列的偏离估计和恢复进行了较为全面的分析,并提出了一种具有多变量响应的广义线性模型的标签变换问题。该理论建立在不同的场景下,具有真实参数的了解,具有潜在的标签变换矩阵的部分知识,并且无知识。我们的结果消除了当前文献所要求的严格条件,并进一步扩展到在标签变换问题领域从未考虑过的缺失观测设置。通过多次数值实验,验证了本文的理论结果。

**[Paper URL](https://proceedings.mlr.press/v202/fang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fang23a/fang23a.pdf)** 

# Robust Collaborative Learning with Linear Gradient Overhead
**题目:** 基于线性梯度的鲁棒协作学习

**作者:** Sadegh Farhadkhani, Rachid Guerraoui, Nirupam Gupta, Lê-Nguyên Hoang, Rafael Pinot, John Stephan

**Abstract:** Collaborative learning algorithms, such as distributed SGD (or D-SGD), are prone to faulty machines that may deviate from their prescribed algorithm because of software or hardware bugs, poisoned data or malicious behaviors. While many solutions have been proposed to enhance the robustness of D-SGD to such machines, previous works either resort to strong assumptions (trusted server, homogeneous data, specific noise model) or impose a gradient computational cost that is several orders of magnitude higher than that of D-SGD. We present MoNNA, a new algorithm that (a) is provably robust under standard assumptions and (b) has a gradient computation overhead that is linear in the fraction of faulty machines, which is conjectured to be tight. Essentially, MoNNA uses Polyak’s momentum of local gradients for local updates and nearest-neighbor averaging (NNA) for global mixing, respectively. While MoNNA is rather simple to implement, its analysis has been more challenging and relies on two key elements that may be of independent interest. Specifically, we introduce the mixing criterion of $(\alpha, \lambda)$-reduction to analyze the non-linear mixing of non-faulty machines, and present a way to control the tension between the momentum and the model drifts. We validate our theory by experiments on image classification and make our code available at https://github.com/LPD-EPFL/robust-collaborative-learning.

**摘要:** 合作学习算法,如分布式SGD(或D-SGD),容易产生故障的机器,它们可能因软件或硬件错误、毒性数据或恶意行为而偏离其预定算法。虽然为提高D-SGD的鲁棒性提出了许多解决方案,但以前的工作要么采用强的假设(信任服务器、均匀数据、特定噪声模型)或强加比D-SGD高几阶的梯度计算成本。虽然MoNNA的实现相当简单,但它的分析更加挑战性,并且依赖于两个关键元素,这些元素可能具有独立的兴趣。具体地说,我们引入了$(\alpha, \lambda)$-reduction的混合标准,以分析非故障机器的非线性混合,并给出了控制动量和模型漂移之间的张力的方法。

**[Paper URL](https://proceedings.mlr.press/v202/farhadkhani23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/farhadkhani23a/farhadkhani23a.pdf)** 

# Neural FIM for learning Fisher information metrics from point cloud data
**题目:** 从点云数据中学习鱼类信息度量

**作者:** Oluwadamilola Fasina, Guillaume Huguet, Alexander Tong, Yanlei Zhang, Guy Wolf, Maximilian Nickel, Ian Adelstein, Smita Krishnaswamy

**Abstract:** Although data diffusion embeddings are ubiquitous in unsupervised learning and have proven to be a viable technique for uncovering the underlying intrinsic geometry of data, diffusion embeddings are inherently limited due to their discrete nature. To this end, we propose neural FIM, a method for computing the Fisher information metric (FIM) from point cloud data - allowing for a continuous manifold model for the data. Neural FIM creates an extensible metric space from discrete point cloud data such that information from the metric can inform us of manifold characteristics such as volume and geodesics. We demonstrate Neural FIM’s utility in selecting parameters for the PHATE visualization method as well as its ability to obtain information pertaining to local volume illuminating branching points and cluster centers embeddings of a toy dataset and two single-cell datasets of IPSC reprogramming and PBMCs (immune cells).

**摘要:** 尽管数据扩散嵌入式在无监督的学习中普遍存在,并且证明是揭示数据内在几何的可行的技术,但扩散嵌入式由于其离散性质而具有局限性。为此,我们提出了一种基于点云数据计算费舍尔信息量子(FIM)的方法--允许数据的连续多变模型。

**[Paper URL](https://proceedings.mlr.press/v202/fasina23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fasina23a/fasina23a.pdf)** 

# Stochastic Policy Gradient Methods: Improved Sample Complexity for Fisher-non-degenerate Policies
**题目:** 随机政策梯度方法:渔业非退化政策的样品复杂性提高

**作者:** Ilyas Fatkhullin, Anas Barakat, Anastasia Kireeva, Niao He

**Abstract:** Recently, the impressive empirical success of policy gradient (PG) methods has catalyzed the development of their theoretical foundations. Despite the huge efforts directed at the design of efficient stochastic PG-type algorithms, the understanding of their convergence to a globally optimal policy is still limited. In this work, we develop improved global convergence guarantees for a general class of Fisher-non-degenerate parameterized policies which allows to address the case of continuous state action spaces. First, we propose a Normalized Policy Gradient method with Implicit Gradient Transport (N-PG-IGT) and derive a $\tilde{\mathcal{O}}(\varepsilon^{-2.5})$ sample complexity of this method for finding a global $\varepsilon$-optimal policy. Improving over the previously known $\tilde{\mathcal{O}}(\varepsilon^{-3})$ complexity, this algorithm does not require the use of importance sampling or second-order information and samples only one trajectory per iteration. Second, we further improve this complexity to $\tilde{ \mathcal{\mathcal{O}} }(\varepsilon^{-2})$ by considering a Hessian-Aided Recursive Policy Gradient ((N)-HARPG) algorithm enhanced with a correction based on a Hessian-vector product. Interestingly, both algorithms are $(i)$ simple and easy to implement: single-loop, do not require large batches of trajectories and sample at most two trajectories per iteration; $(ii)$ computationally and memory efficient: they do not require expensive subroutines at each iteration and can be implemented with memory linear in the dimension of parameters.

**摘要:** 最近,政策梯度(PG)方法的令人印象深刻的实证成功催化了其理论基础的发展。尽管致力于设计有效的随机PG型算法,其对全球最佳政策的收敛性的认识仍然有限。在这项工作中,我们为费舍尔非退化参数化政策的一般类开发了改进的全球收敛性保证,以解决连续状态行动空间的案例。首先,我们提出了一种与隐形梯度运输(N-PG-IGT)的标准化政策梯度方法,并得出一个全球$\varepsilon$-最佳政策的$\tilde{\mathcal{O}}(\varepsilon^{-2.5})$样本复杂度。其次,我们进一步改进了这一复杂性,通过考虑一个基于希斯sian向量产物的修正增强的希斯sian-辅助回归策略梯度(N)-HARPG算法,使$\tilde{ \mathcal{\mathcal{O}} }(\varepsilon^{-2})$更加复杂。

**[Paper URL](https://proceedings.mlr.press/v202/fatkhullin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fatkhullin23a/fatkhullin23a.pdf)** 

# Parallel Neurosymbolic Integration with Concordia
**题目:** 并行神经符号集成与康科迪亚

**作者:** Jonathan Feldstein, Modestas Jurčius, Efthymia Tsamoura

**Abstract:** Parallel neurosymbolic architectures have been applied effectively in NLP by distilling knowledge from a logic theory into a deep model. However, prior art faces several limitations including supporting restricted forms of logic theories and relying on the assumption of independence between the logic and the deep network. We present Concordia, a framework overcoming the limitations of prior art. Concordia is agnostic both to the deep network and the logic theory offering support for a wide range of probabilistic theories. Our framework can support supervised training of both components and unsupervised training of the neural component. Concordia has been successfully applied to tasks beyond NLP and data classification, improving the accuracy of state-of-the-art on collective activity detection, entity linking and recommendation tasks.

**摘要:** 并行神经符号结构在NLP中被有效地应用,从逻辑理论中提炼知识成为深层模型。然而,前瞻性技术面临 several limitations including supporting restricted forms of logic theories and relying on the assumption of independence between the logic and the deep network。我们介绍 Concordia,一种克服前瞻性技术的框架。 Concordia对深层网络和逻辑理论具有 agnostic 性,为广泛的概率理论提供支持。我们的框架可以支持两个组件的监督训练和神经组件的监督训练。 Concordia已经成功地应用于NLP和数据分类以外的任务,提高了集体活动检测、实体连接和推荐任务的精度。

**[Paper URL](https://proceedings.mlr.press/v202/feldstein23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/feldstein23a/feldstein23a.pdf)** 

# Why Target Networks Stabilise Temporal Difference Methods
**题目:** 为什么目标网络稳定时间差的方法

**作者:** Mattie Fellows, Matthew J. A. Smith, Shimon Whiteson

**Abstract:** Integral to recent successes in deep reinforcement learning has been a class of temporal difference methods that use infrequently updated target values for policy evaluation in a Markov Decision Process. Yet a complete theoretical explanation for the effectiveness of target networks remains elusive. In this work, we provide an analysis of this popular class of algorithms, to finally answer the question: “why do target networks stabilise TD learning”? To do so, we formalise the notion of a partially fitted policy evaluation method, which describes the use of target networks and bridges the gap between fitted methods and semigradient temporal difference algorithms. Using this framework we are able to uniquely characterise the so-called deadly triad–the use of TD updates with (nonlinear) function approximation and off-policy data–which often leads to nonconvergent algorithms.This insight leads us to conclude that the use of target networks can mitigate the effects of poor conditioning in the Jacobian of the TD update. Instead, we show that under mild regularity con- ditions and a well tuned target network update frequency, convergence can be guaranteed even in the extremely challenging off-policy sampling and nonlinear function approximation setting.

**摘要:** 深入增强学习中最近取得的成就不可缺少的是一种用于马可夫决策过程中 policy 评价的时差方法,这种方法不经常更新目标值。然而,对目标网络的有效性仍缺乏完全的理论解释。本文对这一流行的算法类别进行了分析,最后回答了“为什么目标网络稳定TD学习?”利用这一框架,我们能够独一无二地描述所谓的致命三环——使用非网络函数近似和非政策数据的TD更新——这常常导致非收敛算法。 这一洞察让我们得出结论,使用目标网络可以减轻在TD更新的雅各布条件下不良影响。

**[Paper URL](https://proceedings.mlr.press/v202/fellows23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fellows23a/fellows23a.pdf)** 

# Weighted Sampling without Replacement for Deep Top-$k$ Classification
**题目:** 深层顶-$k$分类的无置换权重样本

**作者:** Dieqiao Feng, Yuanqi Du, Carla P Gomes, Bart Selman

**Abstract:** The top-$k$ classification accuracy is a crucial metric in machine learning and is often used to evaluate the performance of deep neural networks. These networks are typically trained using the cross-entropy loss, which optimizes for top-$1$ classification and is considered optimal in the case of infinite data. However, in real-world scenarios, data is often noisy and limited, leading to the need for more robust losses. In this paper, we propose using the Weighted Sampling Without Replacement (WSWR) method as a learning objective for top-$k$ loss. While traditional methods for evaluating WSWR-based top-$k$ loss are computationally impractical, we show a novel connection between WSWR and Reinforcement Learning (RL) and apply well-established RL algorithms to estimate gradients. We compared our method with recently proposed top-$k$ losses in various regimes of noise and data size for the prevalent use case of $k = 5$. Our experimental results reveal that our method consistently outperforms all other methods on the top-$k$ metric for noisy datasets, has more robustness on extreme testing scenarios, and achieves competitive results on training with limited data.

**摘要:** 顶端$k$分类精度是机器学习中的一个关键指标,经常用于评价深层神经网络的性能。这些网络通常是通过交叉熵损失进行训练,以优化顶端$1$分类,并在无限数据的情况下被认为是最优的。然而,在现实世界中的场景中,数据经常有噪声和限制,导致需要更强的损失。实验结果表明,该方法在高噪声数据集 metrics上始终优于其他方法,在极端测试场景中具有较强的鲁棒性,在有限数据的训练中取得了较强的训练效果。

**[Paper URL](https://proceedings.mlr.press/v202/feng23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/feng23a/feng23a.pdf)** 

# Improved Online Learning Algorithms for CTR Prediction in Ad Auctions
**题目:** 在广告拍卖中提高CTR预测的在线学习算法

**作者:** Zhe Feng, Christopher Liaw, Zixin Zhou

**Abstract:** In this work, we investigate the online learning problem of revenue maximization in ad auctions, where the seller needs to learn the click-through rates (CTRs) of each ad candidate and charge the price of the winner through a pay-per-click manner. We focus on two models of the advertisers’ strategic behaviors. First, we assume that the advertiser is completely myopic; i.e. in each round, they aim to maximize their utility only for the current round. In this setting, we develop an online mechanism based on upper-confidence bounds that achieves a tight $O(\sqrt{T})$ regret in the worst-case and negative regret when the values are static across all the auctions and there is a gap between the highest expected value (i.e. value multiplied by their CTR) and second highest expected value ad. Next, we assume that the advertiser is non-myopic and cares about their long term utility. This setting is much more complex since an advertiser is incentivized to influence the mechanism by bidding strategically in earlier rounds. In this setting, we provide an algorithm to achieve negative regret for the static valuation setting (with a positive gap), which is in sharp contrast with the prior work that shows $O(T^{2/3})$ regret when the valuation is generated by adversary.

**摘要:** 在这项工作中,我们研究了广告拍卖中的收入最大化在线学习问题,卖方需要学习每个广告候选人的点击率(CTRs)和通过一次点击收费的方式收取赢家的价格。我们关注广告商的战略行为的两个模型。首先,我们假设广告商完全是线性;即在每个轮中,他们的目标是仅为当前轮最大化其实用价值。由于广告商在早期竞标时被鼓励通过策略性竞标来影响机制,所以这个设置更加复杂。在这个设置中,我们提供了一个实现静态估价设置(有正差)负遗憾的算法,与以前的工作截然相反,当估价由对手生成时显示$O(T^{2/3})$遗憾。

**[Paper URL](https://proceedings.mlr.press/v202/feng23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/feng23b/feng23b.pdf)** 

# Fractional Denoising for 3D Molecular Pre-training
**题目:** 3D分子预训练的分形标记

**作者:** Shikun Feng, Yuyan Ni, Yanyan Lan, Zhi-Ming Ma, Wei-Ying Ma

**Abstract:** Coordinate denoising is a promising 3D molecular pre-training method, which has achieved remarkable performance in various downstream drug discovery tasks. Theoretically, the objective is equivalent to learning the force field, which is revealed helpful for downstream tasks. Nevertheless, there are two challenges for coordinate denoising to learn an effective force field, i.e. low coverage samples and isotropic force field. The underlying reason is that molecular distributions assumed by existing denoising methods fail to capture the anisotropic characteristic of molecules. To tackle these challenges, we propose a novel hybrid noise strategy, including noises on both dihedral angel and coordinate. However, denoising such hybrid noise in a traditional way is no more equivalent to learning the force field. Through theoretical deductions, we find that the problem is caused by the dependency of the input conformation for covariance. To this end, we propose to decouple the two types of noise and design a novel fractional denoising method (Frad), which only denoises the latter coordinate part. In this way, Frad enjoys both the merits of sampling more low-energy structures and the force field equivalence. Extensive experiments show the effectiveness of Frad in molecule representation, with a new state-of-the-art on 9 out of 12 tasks of QM9 and on 7 out of 8 targets of MD17.

**摘要:** 协调噪声是一种具有前景的3D分子预训练方法,在各个下游药物发现任务中取得了显著的性能。理论上,目标与学习力场等同,对下游任务有帮助。然而,协调噪声学习有效的力场有两个挑战,即低覆盖样本和同向力场。根本原因是现有的噪声方法所假设的分子分布不能捕捉分子的同向特性。为了解决这些挑战,我们提出了一种新颖的混合噪声策略,包括双面天使和坐标的噪声。为此,我们提议将两种噪声分离,设计一种新的分离噪声方法(Frad),它只对后一个坐标部分产生噪声。这样,Frad既具有较低能量的样本结构的优点,又具有强场等价性。

**[Paper URL](https://proceedings.mlr.press/v202/feng23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/feng23c/feng23c.pdf)** 

# Improved Algorithms for White-Box Adversarial Streams
**题目:** 对白盒敌对流的改进算法

**作者:** Ying Feng, David Woodruff

**Abstract:** We study streaming algorithms in the white-box adversarial stream model, where the internal state of the streaming algorithm is revealed to an adversary who adaptively generates the stream updates, but the algorithm obtains fresh randomness unknown to the adversary at each time step. We incorporate cryptographic assumptions to construct robust algorithms against such adversaries. We propose efficient algorithms for sparse recovery of vectors, low rank recovery of matrices and tensors, as well as low rank plus sparse recovery of matrices, i.e., robust PCA. Unlike deterministic algorithms, our algorithms can report when the input is not sparse or low rank even in the presence of such an adversary. We use these recovery algorithms to improve upon and solve new problems in numerical linear algebra and combinatorial optimization on white-box adversarial streams. For example, we give the first efficient algorithm for outputting a matching in a graph with insertions and deletions to its edges provided the matching size is small, and otherwise we declare the matching size is large. We also improve the approximation versus memory tradeoff of previous work for estimating the number of non-zero elements in a vector and computing the matrix rank.

**摘要:** 本文研究了白箱敌对流模型中的流向算法,其中流向算法的内部状态被发现的敌方可以自适应生成流向更新,但算法在每次步骤中获取敌方未知的新鲜随机性。我们结合密码学假设来构建对这种敌方的鲁棒算法。我们提出了用于向量稀疏恢复、矩阵和 tensors的低级恢复、以及矩阵的低级和稀疏恢复的高效算法,即鲁棒PCA。与确定性算法不同,我们的算法可以在敌方的存在下报告输入不稀疏或低级时。例如,我们给出了第一个有效的算法,以满足匹配的大小为小,并声明匹配的大小为大,以输出在图中插入和删除其边缘的匹配,并且改进了以前的工作对估计向量中非零元素数和计算矩阵序列的近似与内存交换。

**[Paper URL](https://proceedings.mlr.press/v202/feng23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/feng23d/feng23d.pdf)** 

# Non-stationary Reinforcement Learning under General Function Approximation
**题目:** 一般函数近似下的非静态强化学习

**作者:** Songtao Feng, Ming Yin, Ruiquan Huang, Yu-Xiang Wang, Jing Yang, Yingbin Liang

**Abstract:** General function approximation is a powerful tool to handle large state and action spaces in a broad range of reinforcement learning (RL) scenarios. However, theoretical understanding of non-stationary MDPs with general function approximation is still limited. In this paper, we make the first such an attempt. We first propose a new complexity metric called dynamic Bellman Eluder (DBE) dimension for non-stationary MDPs, which subsumes majority of existing tractable RL problems in static MDPs as well as non-stationary MDPs. Based on the proposed complexity metric, we propose a novel confidence-set based model-free algorithm called SW-OPEA, which features a sliding window mechanism and a new confidence set design for non-stationary MDPs. We then establish an upper bound on the dynamic regret for the proposed algorithm, and show that SW-OPEA is provably efficient as long as the variation budget is not significantly large. We further demonstrate via examples of non-stationary linear and tabular MDPs that our algorithm performs better in small variation budget scenario than the existing UCB-type algorithms. To the best of our knowledge, this is the first dynamic regret analysis in non-stationary MDPs with general function approximation.

**摘要:** 一般函数近似是在广泛的增强学习(RL)场景中处理大型状态和行动空间的有力工具,但与一般函数近似的非静态MDP的理论理解仍然有限。在本文中,我们首次提出一种新的复杂度度量,称为动态贝尔曼厄鲁德(DBE)维度的非静态MDP,它将静态MDP和非静态MDP中现有可处理RL问题的大部分部分归纳起来。基于拟议的复杂度量量,我们提出了一种新的基于模型的无模型算法,称为SW-OPEA,它具有滑窗机制和非静态MDP的新信任度量设计。通过非静态线性和 tabular MDP的实例,进一步证明,我们的算法在小变量预算场景下比现有的UCB型算法表现得更好。这是我们所知的第一个具有一般函数近似的非静态MDP动态遗憾分析。

**[Paper URL](https://proceedings.mlr.press/v202/feng23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/feng23e/feng23e.pdf)** 

# Random Matrix Analysis to Balance between Supervised and Unsupervised Learning under the Low Density Separation Assumption
**题目:** 基于低密度分离假设的随机矩阵分析,研究监督和非监督学习之间的平衡

**作者:** Vasilii Feofanov, Malik Tiomoko, Aladin Virmaux

**Abstract:** We propose a theoretical framework to analyze semi-supervised classification under the low density separation assumption in a high-dimensional regime. In particular, we introduce QLDS, a linear classification model, where the low density separation assumption is implemented via quadratic margin maximization. The algorithm has an explicit solution with rich theoretical properties, and we show that particular cases of our algorithm are the least-square support vector machine in the supervised case, the spectral clustering in the fully unsupervised regime, and a class of semi-supervised graph-based approaches. As such, QLDS establishes a smooth bridge between these supervised and unsupervised learning methods. Using recent advances in the random matrix theory, we formally derive a theoretical evaluation of the classification error in the asymptotic regime. As an application, we derive a hyperparameter selection policy that finds the best balance between the supervised and the unsupervised terms of our learning criterion. Finally, we provide extensive illustrations of our framework, as well as an experimental study on several benchmarks to demonstrate that QLDS, while being computationally more efficient, improves over cross-validation for hyperparameter selection, indicating a high promise of the usage of random matrix theory for semi-supervised model selection.

**摘要:** 本文提出了一种基于高维模式下的低密度分离假设的半监督分类理论框架,具体介绍了QLDS,一种基于二次边界最大化实现低密度分离假设的线性分类模型。该算法具有丰富的理论特性的明示解,并表明该算法的特定案例是受监督的最小方形支持矢量机、完全不受监督的光谱集群和半监督的基于图形的方法。最后,我们提供了我们框架的广泛说明,以及对几个基准的实验研究,以证明QLDS虽然在计算上更有效,但对超参数选择的交叉验证也较好,表明在半监督模型选择中使用随机矩阵理论具有很高的前景。

**[Paper URL](https://proceedings.mlr.press/v202/feofanov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/feofanov23a/feofanov23a.pdf)** 

# SurCo: Learning Linear SURrogates for COmbinatorial Nonlinear Optimization Problems
**题目:** SurCo:学习非线性优化问题的线性替代品

**作者:** Aaron M Ferber, Taoan Huang, Daochen Zha, Martin Schubert, Benoit Steiner, Bistra Dilkina, Yuandong Tian

**Abstract:** Optimization problems with nonlinear cost functions and combinatorial constraints appear in many real-world applications but remain challenging to solve efficiently compared to their linear counterparts. To bridge this gap, we propose $\textbf{\emph{\texttt{SurCo}}}$ that learns linear $\underline{\text{Sur}}$rogate costs which can be used in existing $\underline{\text{Co}}$mbinatorial solvers to output good solutions to the original nonlinear combinatorial optimization problem. The surrogate costs are learned end-to-end with nonlinear loss by differentiating through the linear surrogate solver, combining the flexibility of gradient-based methods with the structure of linear combinatorial optimization. We propose three $\texttt{SurCo}$ variants: $\texttt{SurCo}-\texttt{zero}$ for individual nonlinear problems, $\texttt{SurCo}-\texttt{prior}$ for problem distributions, and $\texttt{SurCo}-\texttt{hybrid}$ to combine both distribution and problem-specific information. We give theoretical intuition motivating $\texttt{SurCo}$, and evaluate it empirically. Experiments show that $\texttt{SurCo}$ finds better solutions faster than state-of-the-art and domain expert approaches in real-world optimization problems such as embedding table sharding, inverse photonic design, and nonlinear route planning.

**摘要:** 非线性成本函数和组合约束的优化问题在许多实际应用中出现,但与其线性同类相比仍难以有效解决。为了弥补这一差距,我们建议$\textbf{\emph{\texttt{SurCo}}}$ learns linear $\underline{\text{Sur}}$rogate costs which can be used in existing $\underline{\text{Co}}$mbinatorial solvers to output good solutions to the original nonlinear combinatorial optimization problem. The surrogate costs are learned end-to-end with nonlinear loss by differentiating through the linear surrogate solver, combining the flexibility of gradient-based methods with the structure of linear combinatorial optimization. We propose three $\texttt{SurCo}$ variants: $\texttt{SurCo}-\texttt{zero}$ for individual non我们给出了激励$\texttt{SurCo}$的理论直觉,并以实证方法对其进行评价。实验表明,$\texttt{SurCo}$在嵌入表 sharding 、 反向光学设计和非线性路线规划等实世界优化问题上比最先进的领域专家方法更快地找到更好的解决方案。

**[Paper URL](https://proceedings.mlr.press/v202/ferber23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ferber23a/ferber23a.pdf)** 

# Scaling Laws for Multilingual Neural Machine Translation
**题目:** 多语言神经机翻译的尺度法则

**作者:** Patrick Fernandes, Behrooz Ghorbani, Xavier Garcia, Markus Freitag, Orhan Firat

**Abstract:** In this work, we provide a large-scale empirical study of the scaling properties of multilingual neural machine translation models. We examine how increases in the model size affect the model performance and investigate the role of the individual language pair weights on the scaling behavior. We find that these weights only affect the multiplicative factor of the scaling law, and in particular, the scaling exponent is unaffected by them. Through a novel joint scaling law formulation, we compute the effective number of parameters allocated to each language pair and examine the role of language similarity in the scaling behavior of our models. We find little evidence that language similarity has any impact. In contrast, “direction” of the multilinguality plays a significant role, with models translating from multiple languages into English having a larger number of effective parameters per task than their reversed counterparts. Finally, we leverage our observations to predict the performance of multilingual models trained with any language weighting at any scale, greatly reducing efforts required for language balancing in large multilingual models. Our findings apply to both in-domain and out-of-domain test sets and to multiple evaluation metrics, such as ChrF and BLEURT.

**摘要:** 本文对多语言神经机翻译模型的校准特性进行了大规模实证研究,探讨了模型大小的增加对模型性能的影响,并探讨了单个语言对校准行为的权重的作用。我们发现这些权重只影响校准法的乘法因素,特别是校准指数不受它们的影响。通过新的联合校准法公式,我们计算了分配给每个语言对的有效参数数目,并研究了语言相似性在我们的模型校准行为中的作用。最后,我们利用我们的观察来预测在任何规模的语言权衡下训练的多语言模型的性能,大大降低了大型多语言模型中语言平衡所需的努力。我们的发现适用于内域和外域测试组以及诸如 ChrF 和 BLEURT 等多种评价指标。

**[Paper URL](https://proceedings.mlr.press/v202/fernandes23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fernandes23a/fernandes23a.pdf)** 

# Constant Matters: Fine-grained Error Bound on Differentially Private Continual Observation
**题目:** 常量问题:微粒误差对不同程度的私有连续观察

**作者:** Hendrik Fichtenberger, Monika Henzinger, Jalaj Upadhyay

**Abstract:** We study fine-grained error bounds for differentially private algorithms for counting under continual observation. Our main insight is that the matrix mechanism when using lower-triangular matrices can be used in the continual observation model. More specifically, we give an explicit factorization for the counting matrix $M_\mathsf{count}$ and upper bound the error explicitly. We also give a fine-grained analysis, specifying the exact constant in the upper bound. Our analysis is based on upper and lower bounds of the completely bounded norm (cb-norm) of $M_\mathsf{count}$. Along the way, we improve the best-known bound of 28 years by Mathias (SIAM Journal on Matrix Analysis and Applications, 1993) on the cb-norm of $M_\mathsf{count}$ for a large range of the dimension of $M_\mathsf{count}$. Furthermore, we are the first to give concrete error bounds for various problems under continual observation such as binary counting, maintaining a histogram, releasing an approximately cut-preserving synthetic graph, many graph-based statistics, and substring and episode counting. Finally, we note that our result can be used to get a fine-grained error bound for non-interactive local learning and the first lower bounds on the additive error for $(\epsilon,\delta)$-differentially-private counting under continual observation. Subsequent to this work, Henzinger et al. (SODA, 2023) showed that our factorization also achieves fine-grained mean-squared error.

**摘要:** 我们研究了在连续观测下计数的微粒误差边界。我们的主要洞察是,在使用低三角矩阵时的矩阵机制可以用于连续观测模型。具体地说,我们给出了计算矩阵$M_\mathsf{count}$和上边界的误差的明 factorization。我们还给出了微粒分析,指定了上边界中的精确常数。我们的分析基于$M_\mathsf{count}$的完全边界规范(cb-norm)的上边界和下边界。在此过程中,我们改进了马蒂亚斯(SIAM Journal on Matrix Analysis and Applications, 1993)关于$M_\mathsf{count}$的cb-norm的28年界限。最后,我们注意到我们的结果可以用于获得非交互性局部学习的微粒误差界和在持续观察下$(\epsilon,\delta)$-differentially-private计数的增量误差上的第一个较低界限。

**[Paper URL](https://proceedings.mlr.press/v202/fichtenberger23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fichtenberger23a/fichtenberger23a.pdf)** 

# Adapting to game trees in zero-sum imperfect information games
**题目:** 适应零sum不完美信息游戏中的游戏树

**作者:** Côme Fiegel, Pierre Menard, Tadashi Kozuno, Remi Munos, Vianney Perchet, Michal Valko

**Abstract:** Imperfect information games (IIG) are games in which each player only partially observes the current game state. We study how to learn $\epsilon$-optimal strategies in a zero-sum IIG through self-play with trajectory feedback. We give a problem-independent lower bound $\widetilde{\mathcal{O}}(H(A_{\mathcal{X}}+B_{\mathcal{Y}})/\epsilon^2)$ on the required number of realizations to learn these strategies with high probability, where $H$ is the length of the game, $A_{\mathcal{X}}$ and $B_{\mathcal{Y}}$ are the total number of actions for the two players. We also propose two Follow the Regularized leader (FTRL) algorithms for this setting: Balanced FTRL which matches this lower bound, but requires the knowledge of the information set structure beforehand to define the regularization; and Adaptive FTRL which needs $\widetilde{\mathcal{O}}(H^2(A_{\mathcal{X}}+B_{\mathcal{Y}})/\epsilon^2)$ realizations without this requirement by progressively adapting the regularization to the observations.

**摘要:** 不完全信息游戏(英语:imperfect information games,IIG)是每个玩家只部分观察当前游戏状态的游戏。我们研究如何通过自演和轨迹反馈在零sumIIG中学习$epsilon$-最佳策略。我们给出一个问题独立的下界 $\widetilde{\mathcal{O}}(H(A_{\mathcal{X}}+B_{\mathcal{Y}})/\epsilon^2)$,根据需要的实现数 learned these strategies with high probability, where $H$ is the length of the game, $A_{\mathcal{X}}$ and $B_{\mathcal{Y}}$ are the total number of actions for the two players。同时,我们还提出了两个遵循规则化领袖(FTRL)算法:平衡FTRL,该算法符合这个较低的界限,但需要事先了解信息集结构来定义规则化;和适应FTRL,该算法不需要$\widetilde{\mathcal{O}}(H^2(A_{\mathcal{X}}+B_{\mathcal{Y}})/\epsilon^2)$实现,而不需要这个要求,通过逐步将规则化适应到观测中。

**[Paper URL](https://proceedings.mlr.press/v202/fiegel23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fiegel23a/fiegel23a.pdf)** 

# User-defined Event Sampling and Uncertainty Quantification in Diffusion Models for Physical Dynamical Systems
**题目:** 物理动态系统扩散模型中的用户定义事件样本和不确定性定量

**作者:** Marc Anton Finzi, Anudhyan Boral, Andrew Gordon Wilson, Fei Sha, Leonardo Zepeda-Nunez

**Abstract:** Diffusion models are a class of probabilistic generative models that have been widely used as a prior for image processing tasks like text conditional generation and inpainting. We demonstrate that these models can be adapted to make predictions and provide uncertainty quantification for chaotic dynamical systems. In these applications, diffusion models can implicitly represent knowledge about outliers and extreme events; however, querying that knowledge through conditional sampling or measuring probabilities is surprisingly difficult. Existing methods for conditional sampling at inference time seek mainly to enforce the constraints, which is insufficient to match the statistics of the distribution or compute the probability of the chosen events. To achieve these ends, optimally one would use the conditional score function, but its computation is typically intractable. In this work, we develop a probabilistic approximation scheme for the conditional score function which provably converges to the true distribution as the noise level decreases. With this scheme we are able to sample conditionally on nonlinear user-defined events at inference time, and matches data statistics even when sampling from the tails of the distribution.

**摘要:** 扩散模型是一种广为应用的概率生成模型,用于图像处理任务,如文本条件生成和油漆。我们证明,这些模型可用于预测和为混沌动态系统提供不确定性定量化。在这些应用中,扩散模型可以隐含地代表关于异常和极端事件的知识;然而,通过条件抽样或测量概率查询知识是令人惊奇的困难。在此基础上,我们开发了条件分数函数的概率近似方案,该方案在噪声水平下降时可证明地趋同到真分布。该方案能够在非线性用户定义事件的推断时条件样本,并且在从分布尾巴抽取样本时也能匹配数据统计。

**[Paper URL](https://proceedings.mlr.press/v202/finzi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/finzi23a/finzi23a.pdf)** 

# ACAT: Adversarial Counterfactual Attention for Classification and Detection in Medical Imaging
**题目:** ACAT:医学影像分类和检测方面的反事实关注

**作者:** Alessandro Fontanella, Antreas Antoniou, Wenwen Li, Joanna Wardlaw, Grant Mair, Emanuele Trucco, Amos Storkey

**Abstract:** In some medical imaging tasks and other settings where only small parts of the image are informative for the classification task, traditional CNNs can sometimes struggle to generalise. Manually annotated Regions of Interest (ROI) are often used to isolate the most informative parts of the image. However, these are expensive to collect and may vary significantly across annotators. To overcome these issues, we propose a framework that employs saliency maps to obtain soft spatial attention masks that modulate the image features at different scales. We refer to our method as Adversarial Counterfactual Attention (ACAT). ACAT increases the baseline classification accuracy of lesions in brain CT scans from $71.39 %$ to $72.55 %$ and of COVID-19 related findings in lung CT scans from $67.71 %$ to $70.84 %$ and exceeds the performance of competing methods. We investigate the best way to generate the saliency maps employed in our architecture and propose a way to obtain them from adversarially generated counterfactual images. They are able to isolate the area of interest in brain and lung CT scans without using any manual annotations. In the task of localising the lesion location out of 6 possible regions, they obtain a score of $65.05 %$ on brain CT scans, improving the score of $61.29 %$ obtained with the best competing method.

**摘要:** 在某些医学影像任务和其他设置中,只有图像的小型部分为分类任务提供信息,传统的CNN有时会难以推广。手动注释的兴趣区域(ROI)经常用于区分图像的最有信息的部分。然而,这些费用昂贵,并且在注释者之间可能有很大差异。为了克服这些问题,我们提出了一种框架,它使用利点图来获取柔软的空间注意力面具,以不同尺度调制图像特征。我们把我们的方法称为敌方反事实注意力(ACAT)。ACAT提高了脑部CT扫描的损伤的基准分类精度,从$71.39 %$到$72.55 %$,以及肺部CT扫描的COVID-19相关发现从$67.71 %$到$70.84 %$,超过了竞争方法的性能。我们研究了在我们的架构中应用的利点图的最好方法,并建议从敌对生成的反事实图像中获取它们的方法。它们能够在没有使用任何手动注释的情况下分离大脑和肺部CT扫描中感兴趣的区域。在6个可能区域中定位损伤位置的任务中,它们在脑CT扫描中获得了65.05 %$的分数,提高了61.29 %$的分数,以最佳的竞争方法获得。

**[Paper URL](https://proceedings.mlr.press/v202/fontanella23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fontanella23a/fontanella23a.pdf)** 

# Explainable Data-Driven Optimization: From Context to Decision and Back Again
**题目:** 基于数据的解释性优化:从上下文到决策,然后重返

**作者:** Alexandre Forel, Axel Parmentier, Thibaut Vidal

**Abstract:** Data-driven optimization uses contextual information and machine learning algorithms to find solutions to decision problems with uncertain parameters. While a vast body of work is dedicated to interpreting machine learning models in the classification setting, explaining decision pipelines involving learning algorithms remains unaddressed. This lack of interpretability can block the adoption of data-driven solutions as practitioners may not understand or trust the recommended decisions. We bridge this gap by introducing a counterfactual explanation methodology tailored to explain solutions to data-driven problems. We introduce two classes of explanations and develop methods to find nearest explanations of random forest and nearest-neighbor predictors. We demonstrate our approach by explaining key problems in operations management such as inventory management and routing.

**摘要:** 基于数据的优化利用上下文信息和机器学习算法求解不确定参数的决策问题。 While a vast body of work is dedicated to interpreting machine learning models in the classification setting, explaining decision pipelines involving learning algorithms remains unaddressed. This lack of interpretability can block the adoption of data-driven solutions as practitioners may not understand or trust the recommended decisions. We bridge this gap by introducing a counterfactual explanation methodology tailored to explain solutions to data-driven problems. We introduce two classes of explanations and develop methods to find nearest explanations of random forest and nearest-neighbour predictors. We demonstrate our approach by explaining key problems in operations management such as inventory management and routing.

**[Paper URL](https://proceedings.mlr.press/v202/forel23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/forel23a/forel23a.pdf)** 

# Hardness of Independent Learning and Sparse Equilibrium Computation in Markov Games
**题目:** 马可夫游戏中独立学习和节余平衡计算的难度

**作者:** Dylan J Foster, Noah Golowich, Sham M. Kakade

**Abstract:** We consider the problem of decentralized multi-agent reinforcement learning in Markov games. A fundamental question is whether there exist algorithms that, when run independently by all agents, lead to no-regret for each player, analogous to celebrated convergence results for no-regret learning in normal-form games. While recent work has shown that such algorithms exist for restricted settings (notably, when regret is defined with respect to deviations to Markov policies), the question of whether independent no-regret learning can be achieved in the standard Markov game framework was open. We provide a decisive negative resolution to this problem, both from a computational and statistical perspective. We show that: • Under the complexity-theoretic assumption that PPAD $\neq$ P, there is no polynomial-time algorithm that attains no-regret in two-player general-sum Markov games when executed independently by all players, even when the game is known to the algorithm designer. • When the game is unknown, no algorithm, efficient or otherwise, can achieve no-regret without observing exponentially many episodes in the number of players. These results are proven via lower bounds for a simpler problem we refer to as SparseCCE, in which the goal is to compute a coarse correlated equilibrium that is “sparse” in the sense that it can be represented as a mixture of a small number of product policies.

**摘要:** 我们考虑了分散多代理强化学习在马可夫游戏中的问题。一个基本问题是,是否存在由所有代理人独立运行的算法,导致每个玩家的无悔,类似于正常形式游戏中的 celebrated convergence results for no-regret learning。虽然最近的研究表明,这些算法存在于限制设置(尤其是在对马可夫政策的偏差定义时),问题是否可以在标准马可夫游戏框架中实现独立的无悔学习是开放的。我们提供了对这个问题的决定性消极解决,从计算和统计角度。•当游戏未知时,没有有效的或其它的算法能够实现无悔,而没有观察到指数性的许多玩家数量的事件。这些结果通过较低的边界证明了我们称之为 SparseCCE的更简单的问题,其目标是计算一个粗糙的相关均衡,它可以作为少量的产品政策的混合物表示。

**[Paper URL](https://proceedings.mlr.press/v202/foster23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/foster23a/foster23a.pdf)** 

# Disentangled Generative Models for Robust Prediction of System Dynamics
**题目:** 系统动力学鲁棒预测的分散生成模型

**作者:** Stathi Fotiadis, Mario Lino Valencia, Shunlong Hu, Stef Garasto, Chris D Cantwell, Anil Anthony Bharath

**Abstract:** The use of deep neural networks for modelling system dynamics is increasingly popular, but long-term prediction accuracy and out-of-distribution generalization still present challenges. In this study, we address these challenges by considering the parameters of dynamical systems as factors of variation of the data and leverage their ground-truth values to disentangle the representations learned by generative models. Our experimental results in phase-space and observation-space dynamics, demonstrate the effectiveness of latent-space supervision in producing disentangled representations, leading to improved long-term prediction accuracy and out-of-distribution robustness.

**摘要:** 深度神经网络在系统动力学建模中的应用日益普遍,但长期预测精度和非分布推广仍存在着挑战。本研究通过考虑动态系统参数为数据变化的因素,利用它们的基实值来分离生成模型学习的表示,解决了这些挑战。

**[Paper URL](https://proceedings.mlr.press/v202/fotiadis23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fotiadis23a/fotiadis23a.pdf)** 

# Can Forward Gradient Match Backpropagation?
**题目:** 能向前推进梯度匹配后向推进?

**作者:** Louis Fournier, Stephane Rivaud, Eugene Belilovsky, Michael Eickenberg, Edouard Oyallon

**Abstract:** Forward Gradients - the idea of using directional derivatives in forward differentiation mode - have recently been shown to be utilizable for neural network training while avoiding problems generally associated with backpropagation gradient computation, such as locking and memorization requirements. The cost is the requirement to guess the step direction, which is hard in high dimensions. While current solutions rely on weighted averages over isotropic guess vector distributions, we propose to strongly bias our gradient guesses in directions that are much more promising, such as feedback obtained from small, local auxiliary networks. For a standard computer vision neural network, we conduct a rigorous study systematically covering a variety of combinations of gradient targets and gradient guesses, including those previously presented in the literature. We find that using gradients obtained from a local loss as a candidate direction drastically improves on random noise in Forward Gradient methods.

**摘要:** 前向梯度(英语:Forward Gradients)-在前向微分模式中使用方向导数的概念-最近被证明可用于神经网络训练,同时避免与后向梯度计算有关的一般问题,例如锁定和记忆要求。成本是推测步方向的需要,在高维方面是困难的。目前的解决方案依赖于比等离子推测向量分布的权重平均,但我们建议将我们的梯度推测强偏于较有希望的方向,例如从小、局部辅助网络获得的反馈。结果表明,采用局部损失的梯度作为候选方向,在进度梯度方法中对随机噪声进行了显著改进。

**[Paper URL](https://proceedings.mlr.press/v202/fournier23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fournier23a/fournier23a.pdf)** 

# Last Switch Dependent Bandits with Monotone Payoff Functions
**题目:** 使用单调支付功能的最后开关依赖性强盗

**作者:** Ayoub Foussoul, Vineet Goyal, Orestis Papadigenopoulos, Assaf Zeevi

**Abstract:** In a recent work, Laforgue et al. introduce the model of last switch dependent (LSD) bandits, in an attempt to capture nonstationary phenomena induced by the interaction between the player and the environment. Examples include satiation, where consecutive plays of the same action lead to decreased performance, or deprivation, where the payoff of an action increases after an interval of inactivity. In this work, we take a step towards understanding the approximability of planning LSD bandits, namely, the (NP-hard) problem of computing an optimal arm-pulling strategy under complete knowledge of the model. In particular, we design the first efficient constant approximation algorithm for the problem and show that, under a natural monotonicity assumption on the payoffs, its approximation guarantee (almost) matches the state-of-the-art for the special and well-studied class of recharging bandits (also known as delay-dependent). In this attempt, we develop new tools and insights for this class of problems, including a novel higher-dimensional relaxation and the technique of mirroring the evolution of virtual states. We believe that these novel elements could potentially be used for approaching richer classes of action-induced nonstationary bandits (e.g., special instances of restless bandits). In the case where the model parameters are initially unknown, we develop an online learning adaptation of our algorithm for which we provide sublinear regret guarantees against its full-information counterpart.

**摘要:** 在最近的研究中,拉福格等人引入了最后开关依赖(LSD)带子的模型,以试图捕捉由播放器与环境之间的相互作用所引起的非静态现象。例如,饱和,即连续播放相同的动作导致性能下降,或剥夺,即动作的回报在不活跃的间隔之后增加。在这个研究中,我们迈出了一步来了解规划LSD带子的近似性,即在完全了解该模型下计算一个最佳臂推力策略的(NP-hard)问题。在这一尝试中,我们为这一类问题开发了新的工具和洞察力,包括一种新的高维松弛和模拟虚拟状态的演化技术。我们相信这些新元素可以用于接近行动诱发的非静态 bandits的更丰富的类别(例如不稳定的 bandits的特殊例子)。

**[Paper URL](https://proceedings.mlr.press/v202/foussoul23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/foussoul23a/foussoul23a.pdf)** 

# A Theoretical Analysis of the Learning Dynamics under Class Imbalance
**题目:** 课堂失衡下的学习动力学理论分析

**作者:** Emanuele Francazi, Marco Baity-Jesi, Aurelien Lucchi

**Abstract:** Data imbalance is a common problem in machine learning that can have a critical effect on the performance of a model. Various solutions exist but their impact on the convergence of the learning dynamics is not understood. Here, we elucidate the significant negative impact of data imbalance on learning, showing that the learning curves for minority and majority classes follow sub-optimal trajectories when training with a gradient-based optimizer. This slowdown is related to the imbalance ratio and can be traced back to a competition between the optimization of different classes. Our main contribution is the analysis of the convergence of full-batch (GD) and stochastic gradient descent (SGD), and of variants that renormalize the contribution of each per-class gradient. We find that GD is not guaranteed to decrease the loss for each class but that this problem can be addressed by performing a per-class normalization of the gradient. With SGD, class imbalance has an additional effect on the direction of the gradients: the minority class suffers from a higher directional noise, which reduces the effectiveness of the per-class gradient normalization. Our findings not only allow us to understand the potential and limitations of strategies involving the per-class gradients, but also the reason for the effectiveness of previously used solutions for class imbalancesuch as oversampling.

**摘要:** 数据失衡是机器学习中的一个常见问题,它对模型性能产生重大影响。不同的解决方案存在,但它们对学习动力学的收敛性的影响却没有被理解。在这里,我们阐明了数据失衡对学习的影响,显示了少数和多数类学习曲线在训练时以梯度为基础的优化器遵循亚优化轨迹。这种减速与失衡比例有关,可以追溯到不同类的优化之间的竞争。我们的主要贡献是分析全批(GD)和随机梯度下降(SGD)的收敛性,以及使每类梯度的贡献再正常化的变量。我们发现GD并不保证减少每类损失,但可以通过每类梯度的正常化来解决这个问题。研究结果表明,类别失衡对梯度方向具有额外的影响:少数类 suffers from a higher directional noise, which reduces the effectiveness of the per-class gradient normalization。

**[Paper URL](https://proceedings.mlr.press/v202/francazi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/francazi23a/francazi23a.pdf)** 

# SparseGPT: Massive Language Models Can be Accurately Pruned in One-Shot
**题目:** SparseGPT:大规模语言模型在一次射击中可以准确地剪切

**作者:** Elias Frantar, Dan Alistarh

**Abstract:** We show for the first time that large-scale generative pretrained transformer (GPT) family models can be pruned to at least 50% sparsity in one-shot, without any retraining, at minimal loss of accuracy. This is achieved via a new pruning method called SparseGPT, specifically designed to work efficiently and accurately on massive GPT-family models. We can execute SparseGPT on the largest available open-source models, OPT-175B and BLOOM-176B, in under 4.5 hours, and can reach 60% unstructured sparsity with negligible increase in perplexity: remarkably, more than 100 billion weights from these models can be ignored at inference time. SparseGPT generalizes to semi-structured (2:4 and 4:8) patterns, and is compatible with weight quantization approaches. The code is available at: https://github.com/IST-DASLab/sparsegpt.

**摘要:** 我们首次展示了大规模的生成预制变换器(GPT)家族模型可以在一次射击中至少削减50%的稀疏度,不经过任何重新训练,在最小精度损失的情况下实现。这通过一种新的削减方法,叫做SparseGPT,专门设计为在大规模GPT家族模型上有效和准确工作。我们可以在4.5小时内执行SparseGPT在最大可用的 open-source模型,OPT-175B和BLOOM-176B上,并且可以达到60%的非结构稀疏度,忽略不计的困惑增加:令人惊奇的是,从这些模型中超过100亿的重量可以在推断时被忽略。

**[Paper URL](https://proceedings.mlr.press/v202/frantar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/frantar23a/frantar23a.pdf)** 

# Learning Temporally AbstractWorld Models without Online Experimentation
**题目:** 无在线实验的临时抽象世界模型学习

**作者:** Benjamin Freed, Siddarth Venkatraman, Guillaume Adrien Sartoretti, Jeff Schneider, Howie Choset

**Abstract:** Agents that can build temporally abstract representations of their environment are better able to understand their world and make plans on extended time scales, with limited computational power and modeling capacity. However, existing methods for automatically learning temporally abstract world models usually require millions of online environmental interactions and incentivize agents to reach every accessible environmental state, which is infeasible for most real-world robots both in terms of data efficiency and hardware safety. In this paper, we present an approach for simultaneously learning sets of skills and temporally abstract, skill-conditioned world models purely from offline data, enabling agents to perform zero-shot online planning of skill sequences for new tasks. We show that our approach performs comparably to or better than a wide array of state-of-the-art offline RL algorithms on a number of simulated robotics locomotion and manipulation benchmarks, while offering a higher degree of adaptability to new goals. Finally, we show that our approach offers a much higher degree of robustness to perturbations in environmental dynamics, compared to policy-based methods.

**摘要:** 具有有限的计算能力和建模能力的代理人能够更好地理解自己的世界,并且在扩展时间尺度上做计划。然而,现有的自动学习时间抽象世界模型的方法通常需要数百万的在线环境交互,并鼓励代理人达到所有可访问的环境状态,这对于大多数现实机器人来说既在数据效率,又在硬件安全性方面是不可能的。我们证明,我们的方法在数种仿真机器人运动和操纵基准上具有与或较好的性能,同时对新目标具有较高的适应性。最后,我们证明,我们的方法在环境动力学中对扰动具有比基于政策的方法更高的鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/freed23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/freed23a/freed23a.pdf)** 

# A Coupled Flow Approach to Imitation Learning
**题目:** 模仿学习的耦合流方法

**作者:** Gideon Joseph Freund, Elad Sarafian, Sarit Kraus

**Abstract:** In reinforcement learning and imitation learning, an object of central importance is the state distribution induced by the policy. It plays a crucial role in the policy gradient theorem, and references to it–along with the related state-action distribution–can be found all across the literature. Despite its importance, the state distribution is mostly discussed indirectly and theoretically, rather than being modeled explicitly. The reason being an absence of appropriate density estimation tools. In this work, we investigate applications of a normalizing flow based model for the aforementioned distributions. In particular, we use a pair of flows coupled through the optimality point of the Donsker-Varadhan representation of the Kullback-Leibler (KL) divergence, for distribution matching based imitation learning. Our algorithm, Coupled Flow Imitation Learning (CFIL), achieves state-of-the-art performance on benchmark tasks with a single expert trajectory and extends naturally to a variety of other settings, including the subsampled and state-only regimes.

**摘要:** 在强化学习和仿真学习中,一个中心重要对象是政策所诱导的状态分布。它在政策梯度定理中起着关键作用,并与相关状态-行动分布相关的参考文献可以找到。尽管具有重要意义,状态分布在理论上和间接讨论,而不是直接建模。原因在于缺乏适当的密度估计工具。我们的联合流仿真学习(Coupled Flow Imitation Learning,CFIL)算法在单一专家轨迹的基准任务中实现了最先进的性能,并自然地扩展到其他各种环境,包括子样和仅状态的模式。

**[Paper URL](https://proceedings.mlr.press/v202/freund23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/freund23a/freund23a.pdf)** 

# Simple Hardware-Efficient Long Convolutions for Sequence Modeling
**题目:** 简单硬件高效长卷序列建模

**作者:** Daniel Y Fu, Elliot L Epstein, Eric Nguyen, Armin W Thomas, Michael Zhang, Tri Dao, Atri Rudra, Christopher Re

**Abstract:** State space models (SSMs) have high performance on long sequence modeling but require sophisticated initialization techniques and specialized implementations for high quality and runtime performance. We study whether a simple alternative can match SSMs in performance and efficiency: directly learning long convolutions over the sequence. We find that a key requirement to achieving high performance is keeping the convolution kernels smooth. We find that simple interventions-such as squashing the kernel weights-result in smooth kernels and recover SSM performance on a range of tasks including the long range arena, image classification, language modeling, and brain data modeling. Next, we develop FlashButterfly, an IO-aware algorithm to improve the runtime performance of long convolutions. FlashButterfly appeals to classic Butterfly decompositions of the convolution to reduce GPU memory IO and increase FLOP utilization. FlashButterfly speeds up convolutions by 2.2$\times$, and allows us to train on Path256, a challenging task with sequence length 64K, where we set state-of-the-art by 29.1 points while training 7.2$\times$ faster than prior work. Lastly, we introduce an extension to FlashButterfly that learns the coefficients of the Butterfly decomposition, increasing expressivity without increasing runtime. Using this extension, we outperform a Transformer on WikiText103 by 0.2 PPL with 30% fewer parameters.

**摘要:** 状态空间模型(SSM)在长序列建模上具有很高的性能,但需要复杂的初始化技术和专门的实现,以提高质量和运行时间性能。我们研究一个简单的替代方案是否能够在性能和效率上匹配SSM:直接学习长序列的卷曲。我们发现,实现高性能的关键要求是保持卷曲核平滑。FlashButterfly将卷曲速度提高2.2$\times$,并允许我们在 Path256上进行训练,这是一个具有序列长度64K的挑战性任务,在训练时我们比以前的工作更快的29.1点设置了最先进的技术。最后,我们引入了一个扩展,它学习了蝴蝶分解的系数,增加表达性而不增加运行时间。

**[Paper URL](https://proceedings.mlr.press/v202/fu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fu23a/fu23a.pdf)** 

# MonoNeRF: Learning Generalizable NeRFs from Monocular Videos without Camera Poses
**题目:** MonoNeRF:从无摄像机姿态的单眼视频中学习通用的NeRF

**作者:** Yang Fu, Ishan Misra, Xiaolong Wang

**Abstract:** We propose a generalizable neural radiance fields - MonoNeRF, that can be trained on large-scale monocular videos of moving in static scenes without any ground-truth annotations of depth and camera poses. MonoNeRF follows an Autoencoder-based architecture, where the encoder estimates the monocular depth and the camera pose, and the decoder constructs a Multiplane NeRF representation based on the depth encoder feature, and renders the input frames with the estimated camera. The learning is supervised by the reconstruction error. Once the model is learned, it can be applied to multiple applications including depth estimation, camera pose estimation, and single-image novel view synthesis. More qualitative results are available at: https://oasisyang.github.io/mononerf.

**摘要:** 我们提出了一种可推广的神经辐射场--MonoNeRF,该场可以在无深度和摄像机姿态的任何地面真实注释的情况下在静态场景中移动的大规模单眼视频上进行训练。MonoNeRF遵循了基于自动编码器的架构,其中编码器估计单眼深度和摄像机姿态,解码器构建基于深度编码器特征的多平面NeRF表示,并用估计摄像机渲染输入帧。学习由重建错误监督。一旦学习模型,它可以应用于包括深度估计、摄像机姿态估计和单图像新视图合成在内的多个应用。

**[Paper URL](https://proceedings.mlr.press/v202/fu23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fu23b/fu23b.pdf)** 

# Go Beyond Imagination: Maximizing Episodic Reachability with World Models
**题目:** 超越想象:用世界模型最大化 episodic可达度

**作者:** Yao Fu, Run Peng, Honglak Lee

**Abstract:** Efficient exploration is a challenging topic in reinforcement learning, especially for sparse reward tasks. To deal with the reward sparsity, people commonly apply intrinsic rewards to motivate agents to explore the state space efficiently. In this paper, we introduce a new intrinsic reward design called GoBI - Go Beyond Imagination, which combines the traditional lifelong novelty motivation with an episodic intrinsic reward that is designed to maximize the stepwise reachability expansion. More specifically, we apply learned world models to generate predicted future states with random actions. States with more unique predictions that are not in episodic memory are assigned high intrinsic rewards. Our method greatly outperforms previous state-of-the-art methods on 12 of the most challenging Minigrid navigation tasks and improves the sample efficiency on locomotion tasks from DeepMind Control Suite.

**摘要:** 有效探索是增强学习的一个挑战性课题,特别是对于稀有奖励任务。为了解决 reward sparsity问题,人们通常应用内在奖励来激励代理人有效探索状态空间。本文介绍一种新的内在奖励设计,称为GoBI-Go Beyond Imagination,它将传统的终身新奇动机结合到一个 episodic内在奖励设计,以最大化逐步可达扩展。具体地说,我们应用学习世界模型来用随机行动生成预测未来状态。

**[Paper URL](https://proceedings.mlr.press/v202/fu23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fu23c/fu23c.pdf)** 

# Specializing Smaller Language Models towards Multi-Step Reasoning
**题目:** 面向多步骤推理的较小语言模型

**作者:** Yao Fu, Hao Peng, Litu Ou, Ashish Sabharwal, Tushar Khot

**Abstract:** The surprising ability of Large Language Models (LLMs) to perform well on complex reasoning with only few-shot chain-of-thought prompts is believed to emerge only in very large-scale models. We show that such abilities can, in fact, be distilled down from GPT-3.5 (≥ 175B) to T5 variants (≤ 11B). We propose model specialization, to specialize the model’s ability towards a target task. The hypothesis is that large models (commonly viewed as larger than 100B) have strong modeling power such that they can perform a large spectrum of tasks. Small models (commonly viewed as smaller than 10B) have limited model capacity, but if we specialize their capacity towards a target task, the model can achieve decent performance improvements. We use multi-step math reasoning as our testbed because it is a very typical emergent ability. We show two important aspects of model abilities: (1) balancing language model’s performance on multiple tasks is a delicate matter, as improvements on one task may compromise other tasks; (2) yet by intentionally paying the price of decreased generic ability, we can clearly improve across different model scales smaller than 10B towards a specialized multi-step math reasoning ability. We further give comprehensive discussions about important design choices for better generalization, including the data format mixture and the start model checkpoint. We hope our practice and discoveries can serve as an important attempt towards specialized smaller models in the new research paradigm set by LLMs.

**摘要:** 大型语言模型(LLMs)的令人惊讶的能力是,它们只在非常大规模的模型中表现得很好,我们证明这种能力实际上可以从GPT-3.5(≥175B)到T5变异(≤11B)中提炼出来。我们提议模型专业化,以专门化模型的能力,以完成目标任务。假设是,大型模型(通常被看作大于100B)具有很强的建模能力,可以完成大量任务。小模型(通常被看作小于10B)具有有限的建模能力,但如果我们专门化它们的能力,则可以取得良好的性能改善。我们展示了模型能力的两个重要方面:(一)在多个任务上平衡语言模型的性能是一个微妙的问题,因为改进一个任务可能损害其他任务;(二)通过有意支付降低通用能力的价格,我们能够明显改善不同模型规模小于10B的特殊多步数学推理能力。我们进一步对数据格式混合和启动模型检查点等重要的设计选择进行全面讨论,希望我们的实践和发现能够成为LLM新研究范式中针对小模型的重要尝试。

**[Paper URL](https://proceedings.mlr.press/v202/fu23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fu23d/fu23d.pdf)** 

# Accelerated Stochastic Optimization Methods under Quasar-convexity
**题目:** 夸萨凸度下的加速度随机优化方法

**作者:** Qiang Fu, Dongchu Xu, Ashia Camage Wilson

**Abstract:** Non-convex optimization plays a key role in a growing number of machine learning applications. This motivates the identification of specialized structure that enables sharper theoretical analysis. One such identified structure is quasar-convexity, a non-convex generalization of convexity that subsumes convex functions. Existing algorithms for minimizing quasar-convex functions in the stochastic setting have either high complexity or slow convergence, which prompts us to derive a new class of stochastic methods for optimizing smooth quasar-convex functions. We demonstrate that our algorithms have fast convergence and outperform existing algorithms on several examples, including the classical problem of learning linear dynamical systems. We also present a unified analysis of our newly proposed algorithms and a previously studied deterministic algorithm.

**摘要:** 非凸优化在日益增长的机器学习应用中起着关键作用,这推动了能够更精确的理论分析的专门结构的识别。其中一种识别的结构是凸形结构,是凸形结构的非凸形一般化,它将凸形函数归纳为凸形函数。在随机环境中,现有的凸形函数最小化算法具有高复杂性或慢的收敛性,这促使我们推导出一种新的滑形凸形函数优化的随机方法类别。我们证明了我们的算法具有快速收敛性和在几个例子中优于现有的算法,包括学习线性动力学系统经典问题。

**[Paper URL](https://proceedings.mlr.press/v202/fu23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fu23e/fu23e.pdf)** 

# Meta-learning Parameterized Skills
**题目:** 元学习参数化技能

**作者:** Haotian Fu, Shangqun Yu, Saket Tiwari, Michael Littman, George Konidaris

**Abstract:** We propose a novel parameterized skill-learning algorithm that aims to learn transferable parameterized skills and synthesize them into a new action space that supports efficient learning in long-horizon tasks. We propose to leverage off-policy Meta-RL combined with a trajectory-centric smoothness term to learn a set of parameterized skills. Our agent can use these learned skills to construct a three-level hierarchical framework that models a Temporally-extended Parameterized Action Markov Decision Process. We empirically demonstrate that the proposed algorithms enable an agent to solve a set of highly difficult long-horizon (obstacle-course and robot manipulation) tasks.

**摘要:** 我们提出了一种新的参数化技能学习算法,旨在学习可转让的参数化技能,并将其合成为一种新的行动空间,以支持长期目标任务的有效学习。我们建议利用非政策的Meta-RL结合 trajectory-centric smoothness术语,学习一套参数化技能。我们的代理人可以使用这些学习技能来构建一个三层层次层次结构,以建模一个临时扩展的参数化行动马可夫决策过程。

**[Paper URL](https://proceedings.mlr.press/v202/fu23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fu23f/fu23f.pdf)** 

# NeRFool: Uncovering the Vulnerability of Generalizable Neural Radiance Fields against Adversarial Perturbations
**题目:** NeRFool:揭示一般化神经辐射场对敌对扰动的脆弱性

**作者:** Yonggan Fu, Ye Yuan, Souvik Kundu, Shang Wu, Shunyao Zhang, Yingyan Celine Lin

**Abstract:** Generalizable Neural Radiance Fields (GNeRF) are one of the most promising real-world solutions for novel view synthesis, thanks to their cross-scene generalization capability and thus the possibility of instant rendering on new scenes. While adversarial robustness is essential for real-world applications, little study has been devoted to understanding its implication on GNeRF. We hypothesize that because GNeRF is implemented by conditioning on the source views from new scenes, which are often acquired from the Internet or third-party providers, there are potential new security concerns regarding its real-world applications. Meanwhile, existing understanding and solutions for neural networks’ adversarial robustness may not be applicable to GNeRF, due to its 3D nature and uniquely diverse operations. To this end, we present NeRFool, which to the best of our knowledge is the first work that sets out to understand the adversarial robustness of GNeRF. Specifically, NeRFool unveils the vulnerability patterns and important insights regarding GNeRF’s adversarial robustness. Built upon the above insights gained from NeRFool, we further develop NeRFool$^+$, which integrates two techniques capable of effectively attacking GNeRF across a wide range of target views, and provide guidelines for defending against our proposed attacks. We believe that our NeRFool/NeRFool$^+$ lays the initial foundation for future innovations in developing robust real-world GNeRF solutions. Our codes are available at: https://github.com/GATECH-EIC/NeRFool.

**摘要:** 广义神经辐射场(GNeRF)是新型视图合成的最有前途的现实解决方案之一,其跨场景广义化能力,因此在新的视图上具有瞬时渲染的可能。虽然对现实应用来说,敌对鲁棒性至关重要,但对于GNeRF的影响的研究却很少。我们假设,由于GNeRF是基于源视图的条件实现的,这些视图往往是从互联网或第三方提供者获得的,因此对其现实应用存在潜在的新安全问题。同时,现有的神经网络敌对鲁棒性的理解和解决方案可能无法适用于GNeRF,因为它的3D性质和独特多样的操作。为此,我们提出了GNeRFool,这是我们最了解GNeRF敌对鲁棒性的第一个工作。具体而言,NeRFool揭示了GNeRF的敌对鲁棒性方面的脆弱性模式和重要洞察力。基于以上从NeRFool获得的洞察力,我们进一步开发NeRFool$^+$,它集成了两个能够有效攻击GNeRF的目标视角的技巧,并提供防御我们提出的攻击的准则。我们相信我们的NeRFool/NeRFool$^+$为发展鲁棒的现实世界GNeRF解决方案的未来创新奠定了初步基础。

**[Paper URL](https://proceedings.mlr.press/v202/fu23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/fu23g/fu23g.pdf)** 

# Hierarchies of Reward Machines
**题目:** 奖励机器的等级

**作者:** Daniel Furelos-Blanco, Mark Law, Anders Jonsson, Krysia Broda, Alessandra Russo

**Abstract:** Reward machines (RMs) are a recent formalism for representing the reward function of a reinforcement learning task through a finite-state machine whose edges encode subgoals of the task using high-level events. The structure of RMs enables the decomposition of a task into simpler and independently solvable subtasks that help tackle long-horizon and/or sparse reward tasks. We propose a formalism for further abstracting the subtask structure by endowing an RM with the ability to call other RMs, thus composing a hierarchy of RMs (HRM). We exploit HRMs by treating each call to an RM as an independently solvable subtask using the options framework, and describe a curriculum-based method to learn HRMs from traces observed by the agent. Our experiments reveal that exploiting a handcrafted HRM leads to faster convergence than with a flat HRM, and that learning an HRM is feasible in cases where its equivalent flat representation is not.

**摘要:** 奖励机器(RMs)是通过有限状态机器代表增强学习任务的奖励函数的一种新形式主义,其边缘使用高层次事件编码任务的子目标。 RMs的结构使任务分解为较简单的和独立可解决的子任务,帮助解决长期水平和/或稀疏的奖励任务。我们建议通过赋予一个RM与调用其他RMs的能力进一步抽象化子任务结构的形式主义,从而组成一个RM(HRM)的层次结构。

**[Paper URL](https://proceedings.mlr.press/v202/furelos-blanco23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/furelos-blanco23a/furelos-blanco23a.pdf)** 

# Why Random Pruning Is All We Need to Start Sparse
**题目:** 为什么随机采伐是我们唯一需要开始的备用

**作者:** Advait Harshal Gadhikar, Sohom Mukherjee, Rebekka Burkholz

**Abstract:** Random masks define surprisingly effective sparse neural network models, as has been shown empirically. The resulting sparse networks can often compete with dense architectures and state-of-the-art lottery ticket pruning algorithms, even though they do not rely on computationally expensive prune-train iterations and can be drawn initially without significant computational overhead. We offer a theoretical explanation of how random masks can approximate arbitrary target networks if they are wider by a logarithmic factor in the inverse sparsity $1 / \log(1/\text{sparsity})$. This overparameterization factor is necessary at least for 3-layer random networks, which elucidates the observed degrading performance of random networks at higher sparsity. At moderate to high sparsity levels, however, our results imply that sparser networks are contained within random source networks so that any dense-to-sparse training scheme can be turned into a computationally more efficient sparse-to-sparse one by constraining the search to a fixed random mask. We demonstrate the feasibility of this approach in experiments for different pruning methods and propose particularly effective choices of initial layer-wise sparsity ratios of the random source network. As a special case, we show theoretically and experimentally that random source networks also contain strong lottery tickets.

**摘要:** 随机面具定义具有惊人的效率的稀疏神经网络模型,如实例显示。结果的稀疏网络经常与密集架构和最先进的抽奖券剪切算法竞争,尽管它们不依赖计算上昂贵的剪切训练迭代,并且可以在最初没有重大的计算费用的情况下绘制。我们给出了随机面具在逆稀疏度$1 / \log(1/\text{sparsity})$中的一个逻辑因子以宽度为准的随机目标网络的理论解释。然而,在中等至高稀疏度水平下,我们的结果表明稀疏网络包含在随机源网络中,因此任何密度到稀疏的训练方案都可以通过约束搜索到固定的随机面具来转换为计算上更有效的稀疏到稀疏的方案。我们在不同剪切方法的实验中证明了这种方法的可行性,并提出了随机源网络的初始层wise稀疏率的特别有效的选择。

**[Paper URL](https://proceedings.mlr.press/v202/gadhikar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gadhikar23a/gadhikar23a.pdf)** 

# Cell-Free Latent Go-Explore
**题目:** 无细胞潜入探索

**作者:** Quentin Gallouédec, Emmanuel Dellandrea

**Abstract:** In this paper, we introduce Latent Go-Explore (LGE), a simple and general approach based on the Go-Explore paradigm for exploration in reinforcement learning (RL). Go-Explore was initially introduced with a strong domain knowledge constraint for partitioning the state space into cells. However, in most real-world scenarios, drawing domain knowledge from raw observations is complex and tedious. If the cell partitioning is not informative enough, Go-Explore can completely fail to explore the environment. We argue that the Go-Explore approach can be generalized to any environment without domain knowledge and without cells by exploiting a learned latent representation. Thus, we show that LGE can be flexibly combined with any strategy for learning a latent representation. Our results indicate that LGE, although simpler than Go-Explore, is more robust and outperforms state-of-the-art algorithms in terms of pure exploration on multiple hard-exploration environments including Montezuma’s Revenge. The LGE implementation is available as open-source at https://github.com/qgallouedec/lge.

**摘要:** 本文介绍了基于增强学习的探索模式的简便和一般方法,即隐性探索(英语:Latent Go-Explore,简称LGE) 。 Go-Explore最初是基于分割状态空间的强域知识约束来引入的。然而,在大多数实世界场景中,从原始观测中提取域知识是复杂的和枯燥的。如果细胞分割不够信息性,Go-Explore完全无法探索环境。我们认为,隐性表示可以通过利用学习的隐性表示来推广到无域知识和无细胞的环境。我们的结果表明,LGE虽然比Go-Explore更简单,但更坚固,并且在包括蒙特苏玛的复仇在内的多个硬探索环境的纯探险方面比最先进的算法高。

**[Paper URL](https://proceedings.mlr.press/v202/gallouedec23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gallouedec23a/gallouedec23a.pdf)** 

# Graph Reinforcement Learning for Network Control via Bi-Level Optimization
**题目:** 通过双级优化实现网络控制图增强学习

**作者:** Daniele Gammelli, James Harrison, Kaidi Yang, Marco Pavone, Filipe Rodrigues, Francisco C. Pereira

**Abstract:** Optimization problems over dynamic networks have been extensively studied and widely used in the past decades to formulate numerous real-world problems. However, (1) traditional optimization-based approaches do not scale to large networks, and (2) the design of good heuristics or approximation algorithms often requires significant manual trial-and-error. In this work, we argue that data-driven strategies can automate this process and learn efficient algorithms without compromising optimality. To do so, we present network control problems through the lens of reinforcement learning and propose a graph network-based framework to handle a broad class of problems. Instead of naively computing actions over high-dimensional graph elements, e.g., edges, we propose a bi-level formulation where we (1) specify a desired next state via RL, and (2) solve a convex program to best achieve it, leading to drastically improved scalability and performance. We further highlight a collection of desirable features to system designers, investigate design decisions, and present experiments on real-world control problems showing the utility, scalability, and flexibility of our framework.

**摘要:** 在动态网络上优化问题已经得到广泛研究和广泛应用,用于制订数个现实问题。然而,(1)传统的基于优化的方法并不适用于大型网络,(2)设计好的启发式或近似算法往往需要大量手动的尝试和误差。在这个工作中,我们认为数据驱动策略能够自动化这一过程并学习有效的算法,而不会损害优化。为此,我们通过增强学习的透镜提出网络控制问题,并提出基于图形网络的框架来处理广泛的问题。我们进一步向系统设计者展示一系列理想的功能,研究设计决策,并展示实际控制问题的实验,显示了我们的框架的实用性、可扩展性和灵活性。

**[Paper URL](https://proceedings.mlr.press/v202/gammelli23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gammelli23a/gammelli23a.pdf)** 

# Why Is Public Pretraining Necessary for Private Model Training?
**题目:** 为什么公共预备培训对私人模式培训是必要的?

**作者:** Arun Ganesh, Mahdi Haghifam, Milad Nasr, Sewoong Oh, Thomas Steinke, Om Thakkar, Abhradeep Guha Thakurta, Lun Wang

**Abstract:** In the privacy-utility tradeoff of a model trained on benchmark language and vision tasks, remarkable improvements have been widely reported when the model is pretrained on public data. Some gain is expected as these models inherit the benefits of transfer learning, which is the standard motivation in non-private settings. However, the stark contrast in the gain of pretraining between non-private and private machine learning suggests that the gain in the latter is rooted in a fundamentally different cause. To explain this phenomenon, we hypothesize that the non-convex loss landscape of a model training necessitates the optimization algorithm to go through two phases. In the first, the algorithm needs to select a good “basin” in the loss landscape. In the second, the algorithm solves an easy optimization within that basin. The former is a harder problem to solve with private data, while the latter is harder to solve with public data due to a distribution shift or data scarcity. Guided by this intuition, we provide theoretical constructions that provably demonstrate the separation between private training with and without public pretraining. Further, systematic experiments on CIFAR10 and Librispeech provide supporting evidence for our hypothesis.

**摘要:** 在基于基准语言和视觉任务的模型的私用交易中,当模型在公共数据上进行预处理时,已广泛报道了显著的改进。有些收益是预期的,因为这些模型继承了传输学习的收益,这是非私人环境中的标准动机。然而,非私人和私人机器学习之间的预训练收益的鲜明对比表明,后者的收益根源于根本不同的原因。为了解释这一现象,我们假设模型训练的非凸损失景观需要优化算法经过两个阶段。基于这一直觉,我们提供了理论构造,证明了私人训练与公共预训练之间的分离。此外,系统性实验在CIFAR10和Librispeech中提供了支持的证据支持我们的假设。

**[Paper URL](https://proceedings.mlr.press/v202/ganesh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ganesh23a/ganesh23a.pdf)** 

# Do Perceptually Aligned Gradients Imply Robustness?
**题目:** 感知相位梯度是否影响鲁棒性?

**作者:** Roy Ganz, Bahjat Kawar, Michael Elad

**Abstract:** Adversarially robust classifiers possess a trait that non-robust models do not - Perceptually Aligned Gradients (PAG). Their gradients with respect to the input align well with human perception. Several works have identified PAG as a byproduct of robust training, but none have considered it as a standalone phenomenon nor studied its own implications. In this work, we focus on this trait and test whether Perceptually Aligned Gradients imply Robustness. To this end, we develop a novel objective to directly promote PAG in training classifiers and examine whether models with such gradients are more robust to adversarial attacks. Extensive experiments on multiple datasets and architectures validate that models with aligned gradients exhibit significant robustness, exposing the surprising bidirectional connection between PAG and robustness. Lastly, we show that better gradient alignment leads to increased robustness and harness this observation to boost the robustness of existing adversarial training techniques.

**摘要:** 敌对鲁棒分类器具有非鲁棒模型不具备的特性--感知相位梯度(PAG)。它们对输入的梯度与人类感知相一致。几个工作已经确定了 PAG 作为鲁棒训练的副产物,但没有一个认为它是一个独立现象,也没有研究其自身影响。在这个工作中,我们着重于这一特性,并测试是否感知相位梯度意味着鲁棒性。为此目的,我们开发了一个新的目标,直接促进 PAG 在训练分类器中,并检查是否具有这种梯度的模型对敌对攻击更加鲁棒。最后,我们表明,更好的梯度排列导致增强的鲁棒性,并利用这一观察提高现有的敌对训练技术鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/ganz23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ganz23a/ganz23a.pdf)** 

# Solving Linear Programs with Fast Online Learning Algorithms
**题目:** 快速在线学习算法解决线性程序

**作者:** Wenzhi Gao, Dongdong Ge, Chunlin Sun, Yinyu Ye

**Abstract:** This paper presents fast first-order methods for solving linear programs (LPs) approximately. We adapt online linear programming algorithms to offline LPs and obtain algorithms that avoid any matrix multiplication. We also introduce a variable-duplication technique that copies each variable $K$ times and reduces the optimality gap and constraint violation by a factor of $\sqrt{K}$. Furthermore, we show how online algorithms can be effectively integrated into sifting, a column generation scheme for large-scale LPs. Numerical experiments demonstrate that our methods can serve as either an approximate direct solver, or an initialization subroutine for exact LP solving.

**摘要:** 本文概述了解决线性程序(LPs)的快速第一阶方法。我们将在线线性编程算法适应到非线性LPs,并获得避免矩阵乘法的算法。我们还引入了一个复制每个变量$K$时间的变量-重复技术,并通过$sqrt{K}$的一个因素减少最佳性间隙和约束侵犯。此外,我们还展示了在线算法如何有效地集成到筛选、大尺度LPs的列生成方案中。

**[Paper URL](https://proceedings.mlr.press/v202/gao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gao23a/gao23a.pdf)** 

# Gradient Descent Finds the Global Optima of Two-Layer Physics-Informed Neural Networks
**题目:** 梯度起落发现双层物理成像神经网络的全球优化

**作者:** Yihang Gao, Yiqi Gu, Michael Ng

**Abstract:** The main aim of this paper is to conduct the convergence analysis of the gradient descent for two-layer physics-informed neural networks (PINNs). Here, the loss function involves derivatives of neural network outputs with respect to its inputs, so the interaction between the trainable parameters is more complicated compared with simple regression and classification tasks. We first develop the positive definiteness of Gram matrices and prove that the gradient flow finds the global optima of the empirical loss under over-parameterization. Then, we demonstrate that the standard gradient descent converges to the global optima of the loss with proper choices of learning rates. The framework of our analysis works for various categories of PDEs (e.g., linear second-order PDEs) and common types of network initialization (LecunUniform etc.). Our theoretical results do not need a very strict hypothesis for training samples and have a looser requirement on the network width compared with some previous works.

**摘要:** 本文的主要目的是对二层物理信息神经网络的梯度下降进行收敛性分析,在此,损失函数涉及神经网络输出的导数及其输入,因此可训练的参数间的相互作用与简单的回归和分类任务相比更加复杂。首先,我们开发了格拉姆矩阵的正确定性,并证明梯度流在超参数化下找到经验损失的全球最佳值。然后,我们证明了标准梯度下降与适当选择学习率的损失的全球最佳值收敛。我们的理论结果对训练样本不需要非常严格的假设,并且与一些以前的工作相比,对网络宽度的要求较宽。

**[Paper URL](https://proceedings.mlr.press/v202/gao23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gao23b/gao23b.pdf)** 

# Generalizing Neural Wave Functions
**题目:** 神经波函数的一般化

**作者:** Nicholas Gao, Stephan Günnemann

**Abstract:** Recent neural network-based wave functions have achieved state-of-the-art accuracies in modeling ab-initio ground-state potential energy surface. However, these networks can only solve different spatial arrangements of the same set of atoms. To overcome this limitation, we present Graph-learned orbital embeddings (Globe), a neural network-based reparametrization method that can adapt neural wave functions to different molecules. Globe learns representations of local electronic structures that generalize across molecules via spatial message passing by connecting molecular orbitals to covalent bonds. Further, we propose a size-consistent wave function Ansatz, the Molecular orbital network (Moon), tailored to jointly solve Schrödinger equations of different molecules. In our experiments, we find Moon converging in 4.5 times fewer steps to similar accuracy as previous methods or to lower energies given the same time. Further, our analysis shows that Moon’s energy estimate scales additively with increased system sizes, unlike previous work where we observe divergence. In both computational chemistry and machine learning, we are the first to demonstrate that a single wave function can solve the Schrödinger equation of molecules with different atoms jointly.

**摘要:** 近年来,基于神经网络的波函数在模拟ab-initio地面状态势能表面方面取得了最先进的精度。然而,这些网络只能解决同一组原子的不同空间配置。为了克服这一限制,我们提出了 Graph-learned orbital embeddings(Globe),一种基于神经网络的校正方法,可以将神经波函数适应不同的分子。Globe学习了通过将分子轨道连接到共价键的空间信息传递到各个分子的局部电子结构的表示。此外,我们的分析表明,月球能量估计量随着系统尺寸的增加而增大,与我们观察到的偏差不同。在计算化学和机器学习中,我们是第一个证明单波函数能够共同解决不同原子分子的施罗丁格方程。

**[Paper URL](https://proceedings.mlr.press/v202/gao23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gao23c/gao23c.pdf)** 

# On the Impact of Algorithmic Recourse on Social Segregation
**题目:** 算法对社会隔离的影响

**作者:** Ruijiang Gao, Himabindu Lakkaraju

**Abstract:** As predictive models seep into several real-world applications, it has become critical to ensure that individuals who are negatively impacted by the outcomes of these models are provided with a means for recourse. To this end, there has been a growing body of research on algorithmic recourse in recent years. While recourses can be extremely beneficial to affected individuals, their implementation at a large scale can lead to potential data distribution shifts and other unintended consequences. However, there is little to no research on understanding the impact of algorithmic recourse after implementation. In this work, we address the aforementioned gaps by making one of the first attempts at analyzing the delayed societal impact of algorithmic recourse. To this end, we theoretically and empirically analyze the recourses output by state-of-the-art algorithms. Our analysis demonstrates that large-scale implementation of recourses by end users may exacerbate social segregation. To address this problem, we propose novel algorithms which leverage implicit and explicit conditional generative models to not only minimize the chance of segregation but also provide realistic recourses. Extensive experimentation with real-world datasets demonstrates the efficacy of the proposed approaches.

**摘要:** 由于预测模型渗透到多个现实应用中,因此必须确保这些模型的成果对受影响的个人提供一种手段。为此目的,近年来对算法资源的研究量不断增加。虽然资源对受影响的个人非常有益,但其大规模的实施可能导致潜在的数据分布变迁和其他不意后果。然而,在实现后对算法资源的影响的研究很少到没有研究。在这个工作中,我们通过对算法资源延迟社会影响的第一次尝试来解决上述差距。为此目的,我们从理论上和经验上分析了最先进的算法的资源产出。为了解决这一问题,我们提出了新的算法,利用隐含和明确的条件生成模型,不仅减少分离的可能性,而且提供现实的资源。

**[Paper URL](https://proceedings.mlr.press/v202/gao23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gao23d/gao23d.pdf)** 

# DDGR: Continual Learning with Deep Diffusion-based Generative Replay
**题目:** DDGR: Deep Diffusion-based Generative Replay的持续学习

**作者:** Rui Gao, Weiwei Liu

**Abstract:** Popular deep-learning models in the field of image classification suffer from catastrophic forgetting—models will forget previously acquired skills when learning new ones. Generative replay (GR), which typically consists of a generator and a classifier, is an efficient way to mitigate catastrophic forgetting. However, conventional GR methods only focus on a single instruction relationship (generator-to-classifier), where the generator synthesizes samples for previous tasks to instruct the training of the classifier, while ignoring the ways in which the classifier can benefit the generator. In addition, most generative replay methods typically reuse the generated samples to update the generator, which causes the samples regenerated by the generator deviating from the distribution of previous tasks. To overcome these two issues, we propose a novel approach, called deep diffusion-based generative replay (DDGR), which adopts a diffusion model as the generator and calculates an instruction-operator through the classifier to instruct the generation of samples. Extensive experiments in class incremental (CI) and class incremental with repetition (CIR) settings demonstrate the advantages of DDGR. Our code is available at https://github.com/xiaocangshengGR/DDGR.

**摘要:** 在图像分类领域流行的深入学习模型遭受灾难性遗忘 — — 模型在学习新技能时会忘记先前获得的技能。生成性重演(GR),通常由生成器和分类器组成,是减轻灾难性遗忘的有效方法。然而,传统的GR方法只集中于单一的指令关系(生成器与分类器),其中生成器合成了以前任务的样本,指导分类器的培训,同时忽略了分类器可以受益于生成器的方式。为了克服这两个问题,我们提出了一种新的方法,叫做深扩散-based generative replay(DDGR),它采用扩散模型作为生成器,并通过分类器计算指令操作器来指导样品的生成。

**[Paper URL](https://proceedings.mlr.press/v202/gao23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gao23e/gao23e.pdf)** 

# PAL: Program-aided Language Models
**题目:** PAL:程序辅助语言模型

**作者:** Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig

**Abstract:** Large language models (LLMs) have demonstrated an impressive ability to perform arithmetic and symbolic reasoning tasks, when provided with a few examples at test time ("few-shot prompting"). Much of this success can be attributed to prompting methods such as "chain-of-thought", which employ LLMs for both understanding the problem description by decomposing it into steps, as well as solving each step of the problem. While LLMs seem to be adept at this sort of step-by-step decomposition, LLMs often make logical and arithmetic mistakes in the solution part, even when the problem is decomposed correctly. In this paper, we present Program-Aided Language models (PAL): a novel approach that uses the LLM to read natural language problems and generate programs as the intermediate reasoning steps, but offloads the solution step to a runtime such as a Python interpreter. With PAL, decomposing the natural language problem into runnable steps remains the only learning task for the LLM, while solving is delegated to the interpreter. We demonstrate this synergy between a neural LLM and a symbolic interpreter across 13 mathematical, symbolic, and algorithmic reasoning tasks from BIG-Bench Hard and others. In all these natural language reasoning tasks, generating code using an LLM and reasoning using a Python interpreter leads to more accurate results than much larger models. For example, PAL using Codex achieves state-of-the-art few-shot accuracy on GSM8K, surpassing PaLM which uses chain-of-thought by absolute 15% top-1.

**摘要:** 大型语言模型(LLMs)在测试时提供了一些实例时,表现出了执行算术和符号推理任务的令人印象深刻的能力(“小射击推理”(few-shot prompting)。这一成功很大程度上可以归功于推理方法,例如“ chain-of-thought”( chain-of-thought),它使用LLMs来理解问题描述,分解它为步骤,以及解决问题的每个步骤。在PAL中,将自然语言问题分解为可运行的步骤仍然是LLM的唯一学习任务,而解决则被委托给解释者。我们通过 BIG-Bench Hard和其他的13个数学、符号和算法推理任务显示了神经LLM和符号解释者之间的协同作用。在所有这些自然语言推理任务中,使用LLM生成代码和使用Python解释器推理导致比更大的模型更准确的结果。

**[Paper URL](https://proceedings.mlr.press/v202/gao23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gao23f/gao23f.pdf)** 

# Out-of-Domain Robustness via Targeted Augmentations
**题目:** 通过目标增量实现外域鲁棒性

**作者:** Irena Gao, Shiori Sagawa, Pang Wei Koh, Tatsunori Hashimoto, Percy Liang

**Abstract:** Models trained on one set of domains often suffer performance drops on unseen domains, e.g., when wildlife monitoring models are deployed in new camera locations. In this work, we study principles for designing data augmentations for out-of-domain (OOD) generalization. In particular, we focus on real-world scenarios in which some domain-dependent features are robust, i.e., some features that vary across domains are predictive OOD. For example, in the wildlife monitoring application above, image backgrounds vary across camera locations but indicate habitat type, which helps predict the species of photographed animals. Motivated by theoretical analysis on a linear setting, we propose targeted augmentations, which selectively randomize spurious domain-dependent features while preserving robust ones. We prove that targeted augmentations improve OOD performance, allowing models to generalize better with fewer domains. In contrast, existing approaches such as generic augmentations, which fail to randomize domain-dependent features, and domain-invariant augmentations, which randomize all domain-dependent features, both perform poorly OOD. In experiments on three real-world datasets, we show that targeted augmentations set new states-of-the-art for OOD performance by 3.2-15.2%.

**摘要:** 对一组域进行训练的模型往往在未见域内性能下降,例如在新的摄像机位置部署野生动物监测模型时。在这项工作中,我们研究了外域(OOD)一般化设计数据增强的原理。特别是,我们着重于一些域依赖特征的现实场景,即一些域间变化的特征是可预测的OOD。例如,在上面的野生动物监测应用中,图像背景在摄像机位置上有所不同,但显示了栖息地类型,这有助于预测拍摄动物的种类。与此相反,现有的方法如 generic augmentations, 不能随机化域依赖性特征,以及 domain-invariant augmentations, 可以随机化所有域依赖性特征,两者都 perform poorly OOD 。 在三个实物数据集的实验中,我们表明,目标 augmentations 将 OOD 性能 提高 3.2-15.2% 。

**[Paper URL](https://proceedings.mlr.press/v202/gao23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gao23g/gao23g.pdf)** 

# Scaling Laws for Reward Model Overoptimization
**题目:** 薪酬模型过度优化的尺度法

**作者:** Leo Gao, John Schulman, Jacob Hilton

**Abstract:** In reinforcement learning from human feedback, it is common to optimize against a reward model trained to predict human preferences. Because the reward model is an imperfect proxy, optimizing its value too much can hinder ground truth performance, in accordance with Goodhart’s law. This effect has been frequently observed, but not carefully measured due to the expense of collecting human preference data. In this work, we use a synthetic setup in which a fixed “gold-standard” reward model plays the role of humans, providing labels used to train a proxy reward model. We study how the gold reward model score changes as we optimize against the proxy reward model using either reinforcement learning or best-of-$n$ sampling. We find that this relationship follows a different functional form depending on the method of optimization, and that in both cases its coefficients scale smoothly with the number of reward model parameters. We also study the effect on this relationship of the size of the reward model dataset, the number of reward model and policy parameters, and the coefficient of the KL penalty added to the reward in the reinforcement learning setup. We explore the implications of these empirical results for theoretical considerations in AI alignment.

**摘要:** 由于奖励模型是一个不完备的代理,优化其价值会妨碍根据古德哈特的法则实现地面真实性能。这一效应经常被观察到,但由于收集人类偏好数据的成本而没有仔细测量。在这个工作中,我们使用一种合成的设置,其中一个固定的“黄金标准”奖励模型发挥了人类的作用,提供用于训练代理奖励模型的标签。我们研究了黄金奖励模型的得分如何变化,因为我们利用增强学习或$n$最佳样本对代理奖励模型进行优化。本文还研究了增强学习设置中奖赏模型数据集大小、奖赏模型和政策参数数目以及加加奖金的KL处罚系数对这种关系的影响,并探讨了这些实证结果对人工智能匹配的理论考虑的影响。

**[Paper URL](https://proceedings.mlr.press/v202/gao23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gao23h/gao23h.pdf)** 

# The Unreasonable Effectiveness of Few-shot Learning for Machine Translation
**题目:** 机器翻译的少 shot学习的无理有效性

**作者:** Xavier Garcia, Yamini Bansal, Colin Cherry, George Foster, Maxim Krikun, Melvin Johnson, Orhan Firat

**Abstract:** We demonstrate the potential of few-shot translation systems, trained with unpaired language data, for both high and low-resource language pairs. We show that with only 5 examples of high-quality translation data shown at inference, a transformer decoder-only model trained solely with self-supervised learning, is able to match specialized supervised state-of-the-art models as well as more general commercial translation systems. In particular, we outperform the best performing system on the WMT’21 English-Chinese news translation task by only using five examples of English-Chinese parallel data at inference. Furthermore, the resulting models are two orders of magnitude smaller than state-of-the-art language models. We then analyze the factors which impact the performance of few-shot translation systems, and highlight that the quality of the few-shot demonstrations heavily determines the quality of the translations generated by our models. Finally, we show that the few-shot paradigm also provides a way to control certain attributes of the translation — we show that we are able to control for regional varieties and formality using only a five examples at inference, paving the way towards controllable machine translation systems.

**摘要:** 我们展示了用不相配语言数据训练的少数射击翻译系统对高和低资源语言双语的潜力。我们表明,仅用推导中显示的高质量翻译数据的5个例子,一个仅由自我监督学习训练的变换器解码器模型能够匹配专门监督的最先进的模型以及更通用的商业翻译系统。最后,我们证明了“少 shot”模式还提供了一种控制翻译的某些属性的方法 — 我们证明了我们能够控制区域多样性和形式性,仅使用五个推理例子,为可控制的机器翻译系统铺平了道路。

**[Paper URL](https://proceedings.mlr.press/v202/garcia23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/garcia23a/garcia23a.pdf)** 

# RLSbench: Domain Adaptation Under Relaxed Label Shift
**题目:** RLSbench:宽松标签 Shift下的域名适应

**作者:** Saurabh Garg, Nick Erickson, James Sharpnack, Alex Smola, Sivaraman Balakrishnan, Zachary Chase Lipton

**Abstract:** Despite the emergence of principled methods for domain adaptation under label shift, their sensitivity to shifts in class conditional distributions is precariously under explored. Meanwhile, popular deep domain adaptation heuristics tend to falter when faced with label proportions shifts. While several papers modify these heuristics in attempts to handle label proportions shifts, inconsistencies in evaluation standards, datasets, and baselines make it difficult to gauge the current best practices. In this paper, we introduce RLSbench, a large-scale benchmark for relaxed label shift, consisting of $>$500 distribution shift pairs spanning vision, tabular, and language modalities, with varying label proportions. Unlike existing benchmarks, which primarily focus on shifts in class-conditional $p(x|y)$, our benchmark also focuses on label marginal shifts. First, we assess 13 popular domain adaptation methods, demonstrating more widespread failures under label proportion shifts than were previously known. Next, we develop an effective two-step meta-algorithm that is compatible with most domain adaptation heuristics: (i) pseudo-balance the data at each epoch; and (ii) adjust the final classifier with target label distribution estimate. The meta-algorithm improves existing domain adaptation heuristics under large label proportion shifts, often by 2–10% accuracy points, while conferring minimal effect ($<$0.5%) when label proportions do not shift. We hope that these findings and the availability of RLSbench will encourage researchers to rigorously evaluate proposed methods in relaxed label shift settings. Code is publicly available at https://github.com/acmi-lab/RLSbench.

**摘要:** 尽管在标签迁移下出现了基于原则的域适应方法,但对类条件分布中的迁移的敏感性仍未得到充分探讨。与此同时,流行的深度域适应算法在面对标签比例迁移时往往会不稳定。虽然一些论文在处理标签比例迁移的尝试中修改了这些算法,但评价标准、数据集和基线的不一致性使得衡量当前最佳做法变得困难。首先,我们评估了13种流行的领域适应方法,展示了在标签比例移位下比以前更广泛的失败。接下来,我们开发了一个有效的两步元算法,与大多数领域适应算法相容: (i)在每个时代伪平衡数据; (ii)调整目标标签分布估计的最终分类器。元算法在大型标签比例移位下改进现有领域适应算法,通常以2–10%的精度点,在标签比例不移位时给予最小效果($<$0.5%)。我们希望这些发现和RLSbench的可用性将鼓励研究人员在放松标签比例设置中严格评估拟议的方法。

**[Paper URL](https://proceedings.mlr.press/v202/garg23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/garg23a/garg23a.pdf)** 

# RankMe: Assessing the Downstream Performance of Pretrained Self-Supervised Representations by Their Rank
**题目:** RankMe:按职级评估预设自我监督的代表的下游表现

**作者:** Quentin Garrido, Randall Balestriero, Laurent Najman, Yann Lecun

**Abstract:** Joint-Embedding Self Supervised Learning (JE-SSL) has seen a rapid development, with the emergence of many method variations but only few principled guidelines that would help practitioners to successfully deploy them. The main reason for that pitfall comes from JE-SSL’s core principle of not employing any input reconstruction therefore lacking visual cues of unsuccessful training. Adding non informative loss values to that, it becomes difficult to deploy SSL on a new dataset for which no labels can help to judge the quality of the learned representation. In this study, we develop a simple unsupervised criterion that is indicative of the quality of the learned JE-SSL representations: their effective rank. Albeit simple and computationally friendly, this method —coined RankMe— allows one to assess the performance of JE-SSL representations, even on different downstream datasets, without requiring any labels. A further benefit of RankMe is that it does not have any training or hyper-parameters to tune. Through thorough empirical experiments involving hundreds of training episodes, we demonstrate how RankMe can be used for hyperparameter selection with nearly no reduction in final performance compared to the current selection method that involve a dataset’s labels. We hope that RankMe will facilitate the deployment of JE-SSL towards domains that do not have the opportunity to rely on labels for representations’ quality assessment.

**摘要:** Joint-Embedding Self Supervised Learning(JE-SSL)经历了快速的发展,出现了许多方法变异,但只有少数原则性的指导方针,可以帮助实践者成功地部署它们。该陷阱的主要原因来自JE-SSL的核心原则,不使用任何输入重建,因此缺乏失败训练的视觉提示。RankMe的另一个好处是它没有任何训练或超参数来调制。通过涉及数百个训练片段的深入经验实验,我们展示了 RankMe如何使用超参数选择,与当前的选择方法相比,几乎没有降低最终性能,这涉及数据集的标签。我们希望 RankMe将促进 JE-SSL的部署到没有机会依靠标签来评估表现的质量的领域。

**[Paper URL](https://proceedings.mlr.press/v202/garrido23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/garrido23a/garrido23a.pdf)** 

# Self-supervised learning of Split Invariant Equivariant representations
**题目:** 分割不变等价表示的自监督学习

**作者:** Quentin Garrido, Laurent Najman, Yann Lecun

**Abstract:** Recent progress has been made towards learning invariant or equivariant representations with self-supervised learning. While invariant methods are evaluated on large scale datasets, equivariant ones are evaluated in smaller, more controlled, settings. We aim at bridging the gap between the two in order to learn more diverse representations that are suitable for a wide range of tasks. We start by introducing a dataset called 3DIEBench, consisting of renderings from 3D models over 55 classes and more than 2.5 million images where we have full control on the transformations applied to the objects. We further introduce a predictor architecture based on hypernetworks to learn equivariant representations with no possible collapse to invariance. We introduce SIE (Split Invariant-Equivariant) which combines the hypernetwork-based predictor with representations split in two parts, one invariant, the other equivariant, to learn richer representations. We demonstrate significant performance gains over existing methods on equivariance related tasks from both a qualitative and quantitative point of view. We further analyze our introduced predictor and show how it steers the learned latent space. We hope that both our introduced dataset and approach will enable learning richer representations without supervision in more complex scenarios. Code and data are available at https://github.com/garridoq/SIE.

**摘要:** 近来,人们已经朝着自监督学习学习的无变形或等变形表示学习方向迈进。 While invariant methods are evaluated on large scale datasets, equivariant ones are evaluated in smaller, more controlled, settings. We aim at bridging the gap between the two in order to learn more diverse representations that are suitable for a wide range of tasks. We start by introducing a dataset called 3DIEBench, consisting of renderings from 3D models over 55 classes and more than 2.5 million images where we have full control on the transformations applied to the objects. We further introduce a predictor architecture based on hypernetworks to learn equivariant representations with no possible collapse to invariance. We introduce SIE (Split Invariant-Equivariant) which combines the hypernetwork-based predictor with representations split in two parts我们从质量和数量两个方面都证明了对等效相关任务的现有方法的显著提高。我们进一步分析了我们引入的预测器,并展示它如何指导学习的潜在空间。我们希望我们引入的数据集和方法能够在更复杂的场景中,无监督地学习更丰富的表现。代码和数据可于 https://github.com/garridoq/SIE。

**[Paper URL](https://proceedings.mlr.press/v202/garrido23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/garrido23b/garrido23b.pdf)** 

# Federated Heavy Hitter Recovery under Linear Sketching
**题目:** 基于线性图案的联邦重型夹具回收

**作者:** Adria Gascon, Peter Kairouz, Ziteng Sun, Ananda Theertha Suresh

**Abstract:** Motivated by real-life deployments of multi-round federated analytics with secure aggregation, we investigate the fundamental communication-accuracy tradeoffs of the heavy hitter discovery and approximate (open-domain) histogram problems under a linear sketching constraint. We propose efficient algorithms based on local subsampling and invertible bloom look-up tables (IBLTs). We also show that our algorithms are information-theoretically optimal for a broad class of interactive schemes. The results show that the linear sketching constraint does increase the communication cost for both tasks by introducing an extra linear dependence on the number of users in a round. Moreover, our results also establish a separation between the communication cost for heavy hitter discovery and approximate histogram in the multi-round setting. The dependence on the number of rounds $R$ is at most logarithmic for heavy hitter discovery whereas that of approximate histogram is $\Theta(\sqrt{R})$. We also empirically demonstrate our findings.

**摘要:** 基于安全集群的多轮联合分析的实时部署,我们研究了在线性草图约束下对重阻探测和近似(开放域)Histogram问题的基本通信精度权衡。我们提出了基于局部副样本和可逆花表(IBLTs)的高效算法。我们还表明,我们的算法是信息理论上最优的广泛交互方案类别。结果表明,线性草图约束通过引入一个额外的线性依赖于一轮的用户数量来增加两个任务的通信成本。此外,我们还建立了重阻探测和近似Histogram的通信成本的区分。我们还通过实验证明了我们的发现.

**[Paper URL](https://proceedings.mlr.press/v202/gascon23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gascon23a/gascon23a.pdf)** 

# On the Global Convergence of Fitted Q-Iteration with Two-layer Neural Network Parametrization
**题目:** 双层神经网络参数化适配Q迭代的全球收敛

**作者:** Mudit Gaur, Vaneet Aggarwal, Mridul Agarwal

**Abstract:** Deep Q-learning based algorithms have been applied successfully in many decision making problems, while their theoretical foundations are not as well understood. In this paper, we study a Fitted Q-Iteration with two-layer ReLU neural network parameterization, and find the sample complexity guarantees for the algorithm. Our approach estimates the Q-function in each iteration using a convex optimization problem. We show that this approach achieves a sample complexity of $\tilde{\mathcal{O}}(1/\epsilon^{2})$, which is order-optimal. This result holds for a countable state-spaces and does not require any assumptions such as a linear or low rank structure on the MDP.

**摘要:** 基于深层Q-学习的算法在许多决策问题中得到了成功应用,但它们的理论基础并不十分清楚。本文研究了与二层ReLU神经网络参数化相结合的拟合Q-迭代,并找出该算法的样品复杂性保证。我们的方法利用凸优化问题估计每个迭代的Q-函数。我们证明,该方法达到$\tilde{\mathcal{O}}(1/\epsilon^{2})$的样品复杂性,这是有序优化的。

**[Paper URL](https://proceedings.mlr.press/v202/gaur23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gaur23a/gaur23a.pdf)** 

# A Reinforcement Learning Framework for Dynamic Mediation Analysis
**题目:** 动态调解分析的强化学习框架

**作者:** Lin Ge, Jitao Wang, Chengchun Shi, Zhenke Wu, Rui Song

**Abstract:** Mediation analysis learns the causal effect transmitted via mediator variables between treatments and outcomes, and receives increasing attention in various scientific domains to elucidate causal relations. Most existing works focus on point-exposure studies where each subject only receives one treatment at a single time point. However, there are a number of applications (e.g., mobile health) where the treatments are sequentially assigned over time and the dynamic mediation effects are of primary interest. Proposing a reinforcement learning (RL) framework, we are the first to evaluate dynamic mediation effects in settings with infinite horizons. We decompose the average treatment effect into an immediate direct effect, an immediate mediation effect, a delayed direct effect, and a delayed mediation effect. Upon the identification of each effect component, we further develop robust and semi-parametrically efficient estimators under the RL framework to infer these causal effects. The superior performance of the proposed method is demonstrated through extensive numerical studies, theoretical results, and an analysis of a mobile health dataset. A Python implementation of the proposed procedure is available at https://github.com/linlinlin97/MediationRL.

**摘要:** 介导分析是通过介导器变量来传递治疗与结果之间的因果效应,并在各种科学领域得到越来越广泛的关注,以阐明因果关系。目前的大多数研究主要集中在各个对象在同一时间点只接受一次治疗的点暴露研究上。然而,有若干应用(例如移动健康)在时间上顺序分配治疗和动态介导效应具有主要意义。提出强化学习(RL)框架,我们是第一个在无边界环境下评价动态介导效应的机构。我们将平均治疗效应分解为直接效应、直接中介效应、延迟直接效应和延迟中介效应。该方法的优越性能通过广泛的数值研究、理论结果和移动健康数据集的分析证明。该方法的Python实现可以在 https://github.com/linlinlin97/MediationRL 上实现。

**[Paper URL](https://proceedings.mlr.press/v202/ge23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ge23a/ge23a.pdf)** 

# Compositional Score Modeling for Simulation-Based Inference
**题目:** 基于仿真ference的复合分数建模

**作者:** Tomas Geffner, George Papamakarios, Andriy Mnih

**Abstract:** Neural Posterior Estimation methods for simulation-based inference can be ill-suited for dealing with posterior distributions obtained by conditioning on multiple observations, as they tend to require a large number of simulator calls to learn accurate approximations. In contrast, Neural Likelihood Estimation methods can handle multiple observations at inference time after learning from individual observations, but they rely on standard inference methods, such as MCMC or variational inference, which come with certain performance drawbacks. We introduce a new method based on conditional score modeling that enjoys the benefits of both approaches. We model the scores of the (diffused) posterior distributions induced by individual observations, and introduce a way of combining the learned scores to approximately sample from the target posterior distribution. Our approach is sample-efficient, can naturally aggregate multiple observations at inference time, and avoids the drawbacks of standard inference methods.

**摘要:** 基于仿真推导的神经后推导方法对通过条件化对多个观察获得后分布的处理不适,因为它们往往需要大量的模拟器调用来学习准确的近似。相反,神经概率推导方法可以从个别观察学习后处理多个观察,但它们依赖于标准推导方法,例如MCMC或变异推导,这些方法具有一定的性能缺陷。我们引入一种基于条件性分数建模的新方法,它可以利用两种方法的优点。我们的方法具有样品效率,可以自然地在推导时间聚集多个观察,避免了标准推导方法的缺点。

**[Paper URL](https://proceedings.mlr.press/v202/geffner23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/geffner23a/geffner23a.pdf)** 

# Cramming: Training a Language Model on a single GPU in one day.
**题目:** 编码: 在一天内在一个GPU上培训一个语言模型.

**作者:** Jonas Geiping, Tom Goldstein

**Abstract:** Recent trends in language modeling have focused on increasing performance through scaling, and have resulted in an environment where training language models is out of reach for most researchers and practitioners. While most in the community are asking how to push the limits of extreme computation, we ask the opposite question: How far can we get with a single GPU in just one day? We investigate the downstream performance achievable with a transformer-based language model trained completely from scratch with masked language modeling for a single day on a single consumer GPU. Aside from re-analyzing nearly all components of the pretraining pipeline for this scenario and providing a modified pipeline with performance close to BERT, we investigate why scaling down is hard, and which modifications actually improve performance in this scenario. We provide evidence that even in this constrained setting, performance closely follows scaling laws observed in large-compute settings. Through the lens of scaling laws, we categorize a range of recent improvements to training and architecture and discuss their merit and practical applicability (or lack thereof) for the limited compute setting. We provide code to reproduce all experiments at github.com/JonasGeiping/cramming .

**摘要:** 语言建模中最近的趋势集中于通过规模化提高性能,并导致培训语言模型对于大多数研究者和实践者来说是无法实现的环境。在社区中大多数人正在询问如何推展极端计算的限度时,我们提出相反的问题:我们仅仅在一个日内能用单个GPU取得多远?我们研究了在单个用户GPU上用变换器为基础的语言模型完成的下游性能,完全从零开始训练,并用掩盖语言建模来完成一个日。除了重新分析该场景的预训练管道的几乎所有组成部分以及提供与BERT接近性能的修改管道,我们还研究了为什么降低规模化是困难的,以及哪些修改实际上在这一场景中提高了性能。通过扩展法的视角,我们对培训和架构的最新改进进行了分类,并讨论了它们的优点和有限的计算设置的实际适用性(或不足)。我们提供了在 github.com/JonasGeiping/cramming中复制所有实验的代码。

**[Paper URL](https://proceedings.mlr.press/v202/geiping23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/geiping23a/geiping23a.pdf)** 

# Transformers Meet Directed Graphs
**题目:** 变换器满足指示图

**作者:** Simon Geisler, Yujia Li, Daniel J Mankowitz, Ali Taylan Cemgil, Stephan Günnemann, Cosmin Paduraru

**Abstract:** Transformers were originally proposed as a sequence-to-sequence model for text but have become vital for a wide range of modalities, including images, audio, video, and undirected graphs. However, transformers for directed graphs are a surprisingly underexplored topic, despite their applicability to ubiquitous domains, including source code and logic circuits. In this work, we propose two direction- and structure-aware positional encodings for directed graphs: (1) the eigenvectors of the Magnetic Laplacian — a direction-aware generalization of the combinatorial Laplacian; (2) directional random walk encodings. Empirically, we show that the extra directionality information is useful in various downstream tasks, including correctness testing of sorting networks and source code understanding. Together with a data-flow-centric graph construction, our model outperforms the prior state of the art on the Open Graph Benchmark Code2 relatively by 14.7%.

**摘要:** 变换器最初被提议为文本的序列到序列模型,但已成为包括图像、音频、视频和非导引图在内的多种模态的关键。然而,对导引图的变换器是一个令人惊奇的未被研究的主题,尽管它们适用于所有领域,包括源代码和逻辑电路。在这个工作中,我们提议了两个对导引图的方向和结构意识的定位编码:(1)磁性拉普拉西亚的自向向向 — 组合拉普拉西亚的方向意识的一般化;(2)方向随机行走编码。

**[Paper URL](https://proceedings.mlr.press/v202/geisler23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/geisler23a/geisler23a.pdf)** 

# Memory-Based Meta-Learning on Non-Stationary Distributions
**题目:** 基于记忆的非站点分布的元学习

**作者:** Tim Genewein, Gregoire Deletang, Anian Ruoss, Li Kevin Wenliang, Elliot Catt, Vincent Dutordoir, Jordi Grau-Moya, Laurent Orseau, Marcus Hutter, Joel Veness

**Abstract:** Memory-based meta-learning is a technique for approximating Bayes-optimal predictors. Under fairly general conditions, minimizing sequential prediction error, measured by the log loss, leads to implicit meta-learning. The goal of this work is to investigate how far this interpretation can be realized by current sequence prediction models and training regimes. The focus is on piecewise stationary sources with unobserved switching-points, which arguably capture an important characteristic of natural language and action-observation sequences in partially observable environments. We show that various types of memory-based neural models, including Transformers, LSTMs, and RNNs can learn to accurately approximate known Bayes-optimal algorithms and behave as if performing Bayesian inference over the latent switching-points and the latent parameters governing the data distribution within each segment.

**摘要:** 基于记忆的元学习是 approximating Bayes-optimal predictors的一个技术。在相当一般的条件下,通过测定日志损失的序列预测误差的最小化,导致隐形元学习。本研究的目的是研究目前的序列预测模型和训练制度如何实现这一解释。重点是基于不被观察的交换点的单片静态源,它们可以在部分可观察环境中捕捉自然语言和行动观察序列的重要特征。我们证明,各种基于记忆的神经模型,包括变换器、LSTM和RNN可以学习准确地 approximate已知的Bayes-optimal算法,并表现为在潜在的交换点和每个分段内数据分布的潜在参数上执行Bayesian推理。

**[Paper URL](https://proceedings.mlr.press/v202/genewein23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/genewein23a/genewein23a.pdf)** 

# Towards Reliable Neural Specifications
**题目:** 走向可靠的神经规范

**作者:** Chuqin Geng, Nham Le, Xiaojie Xu, Zhaoyue Wang, Arie Gurfinkel, Xujie Si

**Abstract:** Having reliable specifications is an unavoidable challenge in achieving verifiable correctness, robustness, and interpretability of AI systems. Existing specifications for neural networks are in the paradigm of data as specification. That is, the local neighborhood centering around a reference input is considered to be correct (or robust). While existing specifications contribute to verifying adversarial robustness, a significant problem in many research domains, our empirical study shows that those verified regions are somewhat tight, and thus fail to allow verification of test set inputs, making them impractical for some real-world applications. To this end, we propose a new family of specifications called neural representation as specification. This form of specifications uses the intrinsic information of neural networks, specifically neural activation patterns (NAPs), rather than input data to specify the correctness and/or robustness of neural network predictions. We present a simple statistical approach to mining neural activation patterns. To show the effectiveness of discovered NAPs, we formally verify several important properties, such as various types of misclassifications will never happen for a given NAP, and there is no ambiguity between different NAPs. We show that by using NAP, we can verify a significant region of the input space, while still recalling 84% of the data on MNIST. Moreover, we can push the verifiable bound to 10 times larger on the CIFAR10 benchmark. Thus, we argue that NAPs can potentially be used as a more reliable and extensible specification for neural network verification.

**摘要:** 具有可靠的规格是实现可验证的正确性、鲁棒性和AI系统可解释性的不可避免的挑战。现有的神经网络规格是作为规格的数据范式。即,围绕参考输入的局部邻域被认为是正确的(或鲁棒)。虽然现有规格有助于验证敌对鲁棒性,在许多研究领域是一个重大问题,我们的实证研究表明这些验证区域相当紧固,因此不能允许测试集输入的验证,使得它们对某些现实应用来说是不实用的。为此,我们提出了一种新的规格家族,称为神经网络的规格。我们提出了一种简单的统计方法来挖掘神经激活模式。为了证明发现NAP的有效性,我们正式验证了几个重要特性,例如不同的类型的错误分类对一个NAP永远不会发生,而不同NAP之间没有歧义。我们证明,通过NAP,我们能够验证输入空间的一个重要区域,同时仍然回顾MNIST上的84%的数据。此外,我们还可以在CIFAR10基准上将可核查的界限推到10倍大。

**[Paper URL](https://proceedings.mlr.press/v202/geng23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/geng23a/geng23a.pdf)** 

# Oracles & Followers: Stackelberg Equilibria in Deep Multi-Agent Reinforcement Learning
**题目:** Oracles & Followers: 深层多代理强化学习中的斯坦克尔伯格均衡

**作者:** Matthias Gerstgrasser, David C. Parkes

**Abstract:** Stackelberg equilibria arise naturally in a range of popular learning problems, such as in security games or indirect mechanism design, and have received increasing attention in the reinforcement learning literature. We present a general framework for implementing Stackelberg equilibria search as a multi-agent RL problem, allowing a wide range of algorithmic design choices. We discuss how previous approaches can be seen as specific instantiations of this framework. As a key insight, we note that the design space allows for approaches not previously seen in the literature, for instance by leveraging multitask and meta-RL techniques for follower convergence. We propose one such approach using contextual policies, and evaluate it experimentally on both standard and novel benchmark domains, showing greatly improved sample efficiency compared to previous approaches. Finally, we explore the effect of adopting algorithm designs outside the borders of our framework.

**摘要:** 斯坦克尔伯格均衡在安全游戏或间接机制设计等一系列流行学习问题中自然产生,在强化学习文献中得到了越来越广泛的关注。我们提出了一种实现斯坦克尔伯格均衡搜索的通用框架,作为多代理RL问题,允许广泛的算法设计选择。我们讨论了如何将以前的方法视为该框架的具体实例。作为关键的洞察,我们注意到设计空间允许在文献中未见的方法,例如利用多任务和元RL技术实现追随者融合。

**[Paper URL](https://proceedings.mlr.press/v202/gerstgrasser23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gerstgrasser23a/gerstgrasser23a.pdf)** 

# Approximately Optimal Core Shapes for Tensor Decompositions
**题目:** 近乎最佳的内核形状,用于张力分解

**作者:** Mehrdad Ghadiri, Matthew Fahrbach, Gang Fu, Vahab Mirrokni

**Abstract:** This work studies the combinatorial optimization problem of finding an optimal core tensor shape, also called multilinear rank, for a size-constrained Tucker decomposition. We give an algorithm with provable approximation guarantees for its reconstruction error via connections to higher-order singular values. Specifically, we introduce a novel Tucker packing problem, which we prove is NP-hard, and give a polynomial-time approximation scheme based on a reduction to the 2-dimensional knapsack problem with a matroid constraint. We also generalize our techniques to tree tensor network decompositions. We implement our algorithm using an integer programming solver, and show that its solution quality is competitive with (and sometimes better than) the greedy algorithm that uses the true Tucker decomposition loss at each step, while also running up to 1000x faster.

**摘要:** 本文研究了基于大小约束的图克分解的优化问题,即求出一个优化核心张量形状,又称多线性级数。我们给出了一个可证明的近似算法,通过连接到高阶单数值来保证其重建误差。具体地说,我们引入了一个新颖的图克包装问题,我们证明它是NP-hard,并给出一个基于一个矩阵约束的二维皮夹问题减少的多项式时间近似方案。我们还将我们的技术推广到树张量网络分解。

**[Paper URL](https://proceedings.mlr.press/v202/ghadiri23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ghadiri23a/ghadiri23a.pdf)** 

# GAT: Guided Adversarial Training with Pareto-optimal Auxiliary Tasks
**题目:** GAT:指导敌对训练与 Pareto-最佳辅助任务

**作者:** Salah Ghamizi, Jingfeng Zhang, Maxime Cordy, Mike Papadakis, Masashi Sugiyama, Yves Le Traon

**Abstract:** While leveraging additional training data is well established to improve adversarial robustness, it incurs the unavoidable cost of data collection and the heavy computation to train models. To mitigate the costs, we propose *Guided Adversarial Training * (GAT), a novel adversarial training technique that exploits auxiliary tasks under a limited set of training data. Our approach extends single-task models into multi-task models during the min-max optimization of adversarial training, and drives the loss optimization with a regularization of the gradient curvature across multiple tasks. GAT leverages two types of auxiliary tasks: self-supervised tasks, where the labels are generated automatically, and domain-knowledge tasks, where human experts provide additional labels. Experimentally, under limited data, GAT increases the robust accuracy on CIFAR-10 up to four times (from 11% to 42% robust accuracy) and the robust AUC of CheXpert medical imaging dataset from 50% to 83%. On the full CIFAR-10 dataset, GAT outperforms eight state-of-the-art adversarial training strategies. Our large study across five datasets and six tasks demonstrates that task augmentation is an efficient alternative to data augmentation, and can be key to achieving both clean and robust performances.

**摘要:** 为了减轻成本,我们提出了 *Guided Adversarial Training * (GAT),一种新的敌对训练技术,在有限的训练数据下利用辅助任务。我们的方法将单项任务模型扩展到多项任务模型,在敌对训练的最小-最大优化中,并通过在多个任务中调整梯度曲率来驱动损失优化。GAT利用两个类型的辅助任务:自监督任务,其中标签是自动生成的,和领域知识任务,其中人类专家提供额外标签。在整个CIFAR-10数据集中,GAT超过了8种最先进的敌对训练策略。我们对5个数据集和6个任务进行的大规模研究表明,任务增加是数据增加的有效替代品,并且可以是实现清洁和强有力的业绩的关键。

**[Paper URL](https://proceedings.mlr.press/v202/ghamizi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ghamizi23a/ghamizi23a.pdf)** 

# On User-Level Private Convex Optimization
**题目:** 用户级私有凸优化

**作者:** Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Raghu Meka, Chiyuan Zhang

**Abstract:** We introduce a new mechanism for stochastic convex optimization (SCO) with user-level differential privacy guarantees. The convergence rates of this mechanism are similar to those in the prior work of Levy et al. 2021 and Narayanan et al. 2022, but with two important improvements. Our mechanism does not require any smoothness assumptions on the loss. Furthermore, our bounds are also the first where the minimum number of users needed for user-level privacy has no dependence on the dimension and only a logarithmic dependence on the desired excess error. The main idea underlying the new mechanism is to show that the optimizers of strongly convex losses have low local deletion sensitivity, along with a new output perturbation method for functions with low local deletion sensitivity, which could be of independent interest.

**摘要:** 我们引入了一种具有用户级微分隐私保障的随机凸优化新机制。该机制的收敛率与勒维等人(英语:Levy et al. 2021)和纳拉扬安等人(英语:Narayanan et al. 2022)以前的工作相似,但有两个重要的改进。我们的机制不需要对损失进行任何平滑假设。此外,我们的边界也是第一个用于用户级隐私所需的最小用户数目不依赖维度,仅依赖 desired excess error的 logaritmic 依赖。

**[Paper URL](https://proceedings.mlr.press/v202/ghazi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ghazi23a/ghazi23a.pdf)** 

# Contextual Reliability: When Different Features Matter in Different Contexts
**题目:** 上下文可靠性:在不同的上下文中不同特征有意义

**作者:** Gaurav Rohit Ghosal, Amrith Setlur, Daniel S. Brown, Anca Dragan, Aditi Raghunathan

**Abstract:** Deep neural networks often fail catastrophically by relying on spurious correlations. Most prior work assumes a clear dichotomy into spurious and reliable features; however, this is often unrealistic. For example, most of the time we do not want an autonomous car to simply copy the speed of surrounding cars—we don’t want our car to run a red light if a neighboring car does so. However, we cannot simply enforce invariance to next-lane speed, since it could provide valuable information about an unobservable pedestrian at a crosswalk. Thus, universally ignoring features that are sometimes (but not always) reliable can lead to non-robust performance. We formalize a new setting called contextual reliability which accounts for the fact that the "right" features to use may vary depending on the context. We propose and analyze a two-stage framework called Explicit Non-spurious feature Prediction (ENP) which first identifies the relevant features to use for a given context, then trains a model to rely exclusively on these features. Our work theoretically and empirically demonstrates the advantages of ENP over existing methods and provides new benchmarks for contextual reliability.

**摘要:** 深层神经网络往往因依赖虚构相关性而灾难性地失败。大多数前行工作都将虚构和可靠的特征分割成明确的二元关系,然而,这往往是不现实的。例如,我们通常不希望一个自主的汽车简单地复制周围的汽车的速度——如果邻近的汽车这样做的话,我们不希望我们的汽车开红灯。然而,我们不能简单地强制对下行车速的不变性,因为它可以提供关于横行车上不可见的行人的价值信息。我们提出了和分析了一种名为“显式非问题特征预测”(ENP)的两阶段框架,它首先识别用于特定上下文的相关的特征,然后训练模型完全依赖于这些特征。

**[Paper URL](https://proceedings.mlr.press/v202/ghosal23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ghosal23a/ghosal23a.pdf)** 

# Reinforcement Learning from Passive Data via Latent Intentions
**题目:** 通过潜在意图从消极数据中学习增强

**作者:** Dibya Ghosh, Chethan Anand Bhateja, Sergey Levine

**Abstract:** Passive observational data, such as human videos, is abundant and rich in information, yet remains largely untapped by current RL methods. Perhaps surprisingly, we show that passive data, despite not having reward or action labels, can still be used to learn features that accelerate downstream RL. Our approach learns from passive data by modeling intentions: measuring how the likelihood of future outcomes change when the agent acts to achieve a particular task. We propose a temporal difference learning objective to learn about intentions, resulting in an algorithm similar to conventional RL, but which learns entirely from passive data. When optimizing this objective, our agent simultaneously learns representations of states, of policies, and of possible outcomes in an environment, all from raw observational data. Both theoretically and empirically, this scheme learns features amenable for value prediction for downstream tasks, and our experiments demonstrate the ability to learn from many forms of passive data, including cross-embodiment video data and YouTube videos.

**摘要:** 例如人类视频的消极观察数据是丰富的信息,但仍未被当前RL方法所利用。也许令人惊讶的是,我们显示,尽管没有奖励或行动标签,但消极数据仍可用于学习加速下游RL的特征。我们的方法通过建模意向 learned from passive data: measuring how the likelihood of future outcomes change when the agent acts to achieve a particular task。我们提出了一个关于意向学习的临时差异目标,结果与传统的RL类似,但完全从消极数据学习的算法。理论上和实践上,该方案学习了可用于下游任务价值预测的特征,我们的实验证明了能够从多种形式的消极数据中学习的能力,包括交叉映射视频数据和YouTube视频。

**[Paper URL](https://proceedings.mlr.press/v202/ghosh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ghosh23a/ghosh23a.pdf)** 

# Harmonic Neural Networks
**题目:** 和谐神经网络

**作者:** Atiyo Ghosh, Antonio Andrea Gentile, Mario Dagrada, Chul Lee, Seong-Hyok Sean Kim, Hyukgeun Cha, Yunjun Choi, Dongho Kim, Jeong-Il Kye, Vincent Emanuel Elfving

**Abstract:** Harmonic functions are abundant in nature, appearing in limiting cases of Maxwell’s, Navier-Stokes equations, the heat and the wave equation. Consequently, there are many applications of harmonic functions from industrial process optimisation to robotic path planning and the calculation of first exit times of random walks. Despite their ubiquity and relevance, there have been few attempts to incorporate inductive biases towards harmonic functions in machine learning contexts. In this work, we demonstrate effective means of representing harmonic functions in neural networks and extend such results also to quantum neural networks to demonstrate the generality of our approach. We benchmark our approaches against (quantum) physics-informed neural networks, where we show favourable performance.

**摘要:** 谐波函数在自然界中非常广泛,在马克斯韦尔、纳维尔-斯托克斯方程、热和波方程的有限例子中出现。因此,从工业过程优化到机器人路径规划和随机步行的首次退出时间的计算等多种谐波函数的应用。尽管它们是普遍的和有意义的,但很少有人尝试在机器学习环境中引入对谐波函数的诱导偏见。

**[Paper URL](https://proceedings.mlr.press/v202/ghosh23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ghosh23b/ghosh23b.pdf)** 

# Dividing and Conquering a BlackBox to a Mixture of Interpretable Models: Route, Interpret, Repeat
**题目:** 将黑箱分割成可解释模型的混合物:路径、解释、重复

**作者:** Shantanu Ghosh, Ke Yu, Forough Arabshahi, Kayhan Batmanghelich

**Abstract:** ML model design either starts with an interpretable model or a Blackbox and explains it post hoc. Blackbox models are flexible but difficult to explain, while interpretable models are inherently explainable. Yet, interpretable models require extensive ML knowledge and tend to be less flexible, potentially underperforming than their Blackbox equivalents. This paper aims to blur the distinction between a post hoc explanation of a Blackbox and constructing interpretable models. Beginning with a Blackbox, we iteratively carve out a mixture of interpretable models and a residual network. The interpretable models identify a subset of samples and explain them using First Order Logic (FOL), providing basic reasoning on concepts from the Blackbox. We route the remaining samples through a flexible residual. We repeat the method on the residual network until all the interpretable models explain the desired proportion of data. Our extensive experiments show that our route, interpret, and repeat approach (1) identifies a richer diverse set of instance-specific concepts with high concept completeness via interpretable models by specializing in various subsets of data without compromising in performance, (2) identifies the relatively “harder” samples to explain via residuals, (3) outperforms the interpretable by-design models by significant margins during test-time interventions, (4) can be used to fix the shortcut learned by the original Blackbox.

**摘要:** ML模型设计 either starts with an interpretable model or a Blackbox and explains it post hoc. Blackbox models are flexible but difficult to explain, while interpretable models are inherently explainable. Yet, interpretable models require extensive ML knowledge and tend to be less flexible, potentially underperforming than their Blackbox equivalents. This paper aims to blur the distinction between a post hoc explanation of a Blackbox and constructing interpretable models. Starting with a Blackbox, we iteratively carve out a mixture of interpretable models and a residual network. The interpretable models identify a subset of samples and explain them using First Order Logic (FOL), providing basic reasoning on concepts from the Blackbox. We route the remaining samples through a flexible residual. We repeat the method on the residual network until all the interpretable models explain the desired proportion of data我们的广泛实验表明,我们的路径、解释和重复方法(一)通过可解释模型,通过对不同数据子集的专门化来识别具有较高概念完整性的实例特异概念的更丰富多样的集合,(二)通过剩余来解释相对较“硬”的样品,(三)在测试时的干预中大大超过可解释的副设计模型,(四)可以用来修正原版黑箱学习的捷径。

**[Paper URL](https://proceedings.mlr.press/v202/ghosh23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ghosh23c/ghosh23c.pdf)** 

# Looped Transformers as Programmable Computers
**题目:** 循环变换器作为可编程计算机

**作者:** Angeliki Giannou, Shashank Rajput, Jy-Yong Sohn, Kangwook Lee, Jason D. Lee, Dimitris Papailiopoulos

**Abstract:** We present a framework for using transformer networks as universal computers by programming them with specific weights and placing them in a loop. Our input sequence acts as a punchcard, consisting of instructions and memory for data read/writes. We demonstrate that a constant number of encoder layers can emulate basic computing blocks, including lexicographic operations, non-linear functions, function calls, program counters, and conditional branches. Using this framework, we emulate a computer using a simple instruction-set architecture, which allows us to map iterative algorithms to programs that can be executed by a constant depth looped transformer network. We show how a single frozen transformer, instructed by its input, can emulate a basic calculator, a basic linear algebra library, and even a full backpropagation, in-context learning algorithm. Our findings reveal the potential of transformer networks as programmable compute units and offer insight into the mechanics of attention.

**摘要:** 我们提出了一种用于将变换器网络应用于通用计算机的框架,通过将它们以特定重量编程并将其置于一个循环中。我们的输入序列作为字符串,由数据阅读/写的指令和记忆组成。我们证明,一定数量的编码层可以仿真基本计算块,包括词汇操作、非线性函数、函数调用、程序计数器和条件分支。使用这个框架,我们仿真一个使用简单的指令集架构的计算机,它允许我们将迭代算法映射到可由一个连续深度循环变换器网络执行的程序。我们的发现揭示了变换器网络作为可编程的计算单元的潜力,并提供了对注意力的机理的洞察。

**[Paper URL](https://proceedings.mlr.press/v202/giannou23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/giannou23a/giannou23a.pdf)** 

# Generalized Disparate Impact for Configurable Fairness Solutions in ML
**题目:** ML中可配置公平解决方案的一般化差异影响

**作者:** Luca Giuliani, Eleonora Misino, Michele Lombardi

**Abstract:** We make two contributions in the field of AI fairness over continuous protected attributes. First, we show that the Hirschfeld-Gebelein-Renyi (HGR) indicator (the only one currently available for such a case) is valuable but subject to a few crucial limitations regarding semantics, interpretability, and robustness. Second, we introduce a family of indicators that are: 1) complementary to HGR in terms of semantics; 2) fully interpretable and transparent; 3) robust over finite samples; 4) configurable to suit specific applications. Our approach also allows us to define fine-grained constraints to permit certain types of dependence and forbid others selectively. By expanding the available options for continuous protected attributes, our approach represents a significant contribution to the area of fair artificial intelligence.

**摘要:** 我们对持续保护属性的人工智能公平性作了两个贡献。首先,我们证明了希尔施菲尔德-盖贝莱因-雷尼(HGR)指标(目前唯一可用于这种案例)具有价值,但有几个关键性限制,包括语义、解释性和鲁棒性。其次,我们引入了一系列指标,这些指标是: 1)在语义方面相辅相成HGR; 2)完全可解释和透明; 3)在有限样本上鲁棒; 4)可配置以适应特定应用。我们的方法还允许我们定义细微约束,允许某些类型的依赖性,并选择性禁止其他类型。

**[Paper URL](https://proceedings.mlr.press/v202/giuliani23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/giuliani23a/giuliani23a.pdf)** 

# Multicalibration as Boosting for Regression
**题目:** 多校正为退化增益

**作者:** Ira Globus-Harris, Declan Harrison, Michael Kearns, Aaron Roth, Jessica Sorrell

**Abstract:** We study the connection between multicalibration and boosting for squared error regression. First we prove a useful characterization of multicalibration in terms of a “swap regret” like condition on squared error. Using this characterization, we give an exceedingly simple algorithm that can be analyzed both as a boosting algorithm for regression and as a multicalibration algorithm for a class $\mathcal{H}$ that makes use only of a standard squared error regression oracle for $\mathcal{H}$. We give a weak learning assumption on $\mathcal{H}$ that ensures convergence to Bayes optimality without the need to make any realizability assumptions — giving us an agnostic boosting algorithm for regression. We then show that our weak learning assumption on $\mathcal{H}$ is both necessary and sufficient for multicalibration with respect to $\mathcal{H}$ to imply Bayes optimality, answering an open question. We also show that if $\mathcal{H}$ satisfies our weak learning condition relative to another class $\mathcal{C}$ then multicalibration with respect to $\mathcal{H}$ implies multicalibration with respect to $\mathcal{C}$. Finally we investigate the empirical performance of our algorithm experimentally.

**摘要:** 我们研究了多校正与平方误差回归的增强之间的联系。首先,我们证明了多校正在平方误差上具有“swap regret”等条件的有用特性。通过这种特性,我们给出了一个非常简单的算法,可以作为回归的增强算法和类 $\mathcal{H}$的多校正算法进行分析,该算法只使用了$\mathcal{H}$的标准平方误差回归口号。我们还表明,如果$\mathcal{H}$满足我们与另一个类$\mathcal{C}$相比的弱学习条件,那么对$\mathcal{H}$的多校准意味着对$\mathcal{C}$的多校准。最后,我们实验研究了我们的算法的实证性能。

**[Paper URL](https://proceedings.mlr.press/v202/globus-harris23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/globus-harris23a/globus-harris23a.pdf)** 

# Adversarial robustness of amortized Bayesian inference
**题目:** 退化贝叶斯推理的敌对鲁棒性

**作者:** Manuel Gloeckler, Michael Deistler, Jakob H. Macke

**Abstract:** Bayesian inference usually requires running potentially costly inference procedures separately for every new observation. In contrast, the idea of amortized Bayesian inference is to initially invest computational cost in training an inference network on simulated data, which can subsequently be used to rapidly perform inference (i.e., to return estimates of posterior distributions) for new observations. This approach has been applied to many real-world models in the sciences and engineering, but it is unclear how robust the approach is to adversarial perturbations in the observed data. Here, we study the adversarial robustness of amortized Bayesian inference, focusing on simulation-based estimation of multi-dimensional posterior distributions. We show that almost unrecognizable, targeted perturbations of the observations can lead to drastic changes in the predicted posterior and highly unrealistic posterior predictive samples, across several benchmark tasks and a real-world example from neuroscience. We propose a computationally efficient regularization scheme based on penalizing the Fisher information of the conditional density estimator, and show how it improves the adversarial robustness of amortized Bayesian inference.

**摘要:** 贝叶斯推理通常需要为每个新观察单独运行潜在成本的推理程序。相反, amortized Bayesian推理的目的是在模拟数据上训练推理网络,从而快速执行推理(即返回后继分布的估计)的新观察。这一方法在科学和工程领域已经应用到许多真实世界模型,但目前尚不清楚该方法对观察数据中的敌对扰动有多强。研究表明,几乎无法识别的、目标的观测扰动,在多个基准任务和神经科学实例中,可能导致预测后期和高度不现实的后期预测样本的大幅变化。我们提出了一种基于惩罚条件密度估计器的费舍尔信息的计算效率高的调节方案,并表明该方案如何提高 amortized Bayesian inference的敌对鲁棒。

**[Paper URL](https://proceedings.mlr.press/v202/gloeckler23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gloeckler23a/gloeckler23a.pdf)** 

# Efficient RL via Disentangled Environment and Agent Representations
**题目:** 透过分散环境及代理代表机构的有效管制

**作者:** Kevin Gmelin, Shikhar Bahl, Russell Mendonca, Deepak Pathak

**Abstract:** Agents that are aware of the separation between the environments and themselves can leverage this understanding to form effective representations of visual input. We propose an approach for learning such structured representations for RL algorithms, using visual knowledge of the agent, which is often inexpensive to obtain, such as its shape or mask. This is incorporated into the RL objective using a simple auxiliary loss. We show that our method, SEAR (Structured Environment-Agent Representations), outperforms state-of-the-art model-free approaches over 18 different challenging visual simulation environments spanning 5 different robots.

**摘要:** 了解环境与自身之间的隔离的代理人可以利用这种理解来形成有效的视觉输入的表示。我们提出了一种方法来学习RL算法中的这种结构化表示,使用代理人的视觉知识,这种知识往往是获得的廉价,例如它的形状或面具。

**[Paper URL](https://proceedings.mlr.press/v202/gmelin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gmelin23a/gmelin23a.pdf)** 

# Aligning Language Models with Preferences through $f$-divergence Minimization
**题目:** 通过$f$-差异最小化将语言模型与选项相匹配

**作者:** Dongyoung Go, Tomasz Korbak, Germàn Kruszewski, Jos Rozen, Nahyeon Ryu, Marc Dymetman

**Abstract:** Aligning language models with preferences can be posed as approximating a target distribution representing some desired behavior. Existing approaches differ both in the functional form of the target distribution and the algorithm used to approximate it. For instance, Reinforcement Learning from Human Feedback (RLHF) corresponds to minimizing a reverse KL from an implicit target distribution arising from a KL penalty in the objective. On the other hand, Generative Distributional Control (GDC) has an explicit target distribution and minimizes a forward KL from it using the Distributional Policy Gradient (DPG) algorithm. In this paper, we propose a new approach, $f$-DPG, which allows the use of any $f$-divergence to approximate any target distribution that can be evaluated. $f$-DPG unifies both frameworks (RLHF, GDC) and the approximation methods (DPG, RL with KL penalties). We show the practical benefits of various choices of divergence objectives and demonstrate that there is no universally optimal objective but that different divergences present different alignment and diversity trade-offs. We show that Jensen-Shannon divergence strikes a good balance between these objectives, and frequently outperforms forward KL divergence by a wide margin, leading to significant improvements over prior work. These distinguishing characteristics between divergences persist as the model size increases, highlighting the importance of selecting appropriate divergence objectives.

**摘要:** 与偏好匹配的语言模型可以被提出为近似一个目标分布,代表某些期望的行为。现有的方法在目标分布的函数形式和近似算法上都不同。例如,从人类反馈中学习增强(RLHF)与从目标中的KL惩罚产生隐含目标分布的反向 KL 的最小化相符。另一方面,生成分布控制(GDC)具有明确的目标分布,并利用分配策略梯度(DPG)算法从它中最小化 forward KL 。在这篇文章中,我们提出了一种新的方法,$f$-DPG,它允许使用任何$f$-divergence来近似任何可以评估的目标分布。分析了不同选择的差异目标的实际效益,并表明,没有普遍的理想目标,但不同的差异存在着不同的整合和多样性折衷。我们表明,詹森-尚农差异在这些目标之间有着良好的平衡,并且经常以较大的幅度超越前作的KL差异,从而大大改善前作的工作。

**[Paper URL](https://proceedings.mlr.press/v202/go23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/go23a/go23a.pdf)** 

# Robust Consensus in Ranking Data Analysis: Definitions, Properties and Computational Issues
**题目:** 排名数据分析的稳固共识:定义、属性和计算问题

**作者:** Morgane Goibert, Clément Calauzènes, Ekhine Irurozki, Stephan Clémençon

**Abstract:** As the issue of robustness in AI systems becomes vital, statistical learning techniques that are reliable even in presence of partly contaminated data have to be developed. Preference data, in the form of (complete) rankings in the simplest situations, are no exception and the demand for appropriate concepts and tools is all the more pressing given that technologies fed by or producing this type of data ($\textit{e.g.}$ search engines, recommending systems) are now massively deployed. However, the lack of vector space structure for the set of rankings ($\textit{i.e.}$ the symmetric group $\mathfrak{S}_n$) and the complex nature of statistics considered in ranking data analysis make the formulation of robustness objectives in this domain challenging. In this paper, we introduce notions of robustness, together with dedicated statistical methods, for $\textit{Consensus Ranking}$ the flagship problem in ranking data analysis, aiming at summarizing a probability distribution on $\mathfrak{S}_n$ by a $\textit{median}$ ranking. Precisely, we propose specific extensions of the popular concept of breakdown point, tailored to consensus ranking, and address the related computational issues. Beyond the theoretical contributions, the relevance of the approach proposed is supported by an experimental study.

**摘要:** 随着人工智能系统鲁棒性问题日益重要,即使存在部分污染的数据,也必须发展可靠的统计学习技术。在最简单的情况下,偏好数据(完整的)排名形式也不例外,而对适当的概念和工具的需求则更加迫切,因为这种类型的数据(搜索引擎、推荐系统等)被提供或生产的技术现在正在大规模部署。然而,对排名的集合缺乏向量空间结构(对称群 $\mathfrak{S}_n$)和在排名数据分析中考虑的统计的复杂性使得在这一领域制定鲁棒性目标成为挑战。本文结合专门的统计方法,对排序数据分析中 flagship 问题 $\textit{Consensus Ranking}$ 提出鲁棒性的概念,旨在通过 $\textit{median}$ 排序对 $\mathfrak{S}_n$ 的概率分布进行总结。具体地,我们提出了针对 consensus 排序的流行概念的具体扩展,并解决相关计算问题。

**[Paper URL](https://proceedings.mlr.press/v202/goibert23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/goibert23a/goibert23a.pdf)** 

# Learning Distributions over Quantum Measurement Outcomes
**题目:** 量子测量结果上的学习分配

**作者:** Weiyuan Gong, Scott Aaronson

**Abstract:** Shadow tomography for quantum states provides a sample efficient approach for predicting the measurement outcomes of quantum systems. However, these shadow tomography procedures yield poor bounds if there are more than two outcomes per measurement. In this paper, we consider a general problem of learning properties from quantum states: given an unknown $d$-dimensional quantum state $\rho$ and $M$ unknown quantum measurements $\mathcal{M}_1,...,\mathcal{M}_M$ with $K\geq 2$ outcomes, estimating the probability distribution for applying $\mathcal{M}_i$ on $\rho$ to within total variation distance $\epsilon$. Compared to the special case when $K=2$, we have to learn unknown distributions instead of values. Here, we propose an online shadow tomography procedure that solves this problem with high success probability requiring $\tilde{O}(K\log^2M\log d/\epsilon^4)$ copies of $\rho$. We further prove an information-theoretic lower bound showing that at least $\Omega(\min\{d^2,K+\log M\}/\epsilon^2)$ copies of $\rho$ are required to solve this problem with high success probability. Our shadow tomography procedure requires sample complexity with only logarithmic dependence on $M$ and $d$ and is sample-optimal concerning the dependence on $K$.

**摘要:** 量子状态的阴影 tomography为量子系统测量结果的预测提供了一个高效的样本方法。然而,这些阴影 tomography程序如果每个测量结果有两个以上,就会产生较差的边界。我们考虑从量子状态学习性质的一个一般问题:给定未知$d$维量子状态$\rho$和$M$未知量子测量$\mathcal{M}_1,...,\mathcal{M}_M$和$K\geq2$结果,估计应用$\rho$上的$\mathcal{M}_i$在总变异距离$\epsilon$范围内的概率分布。我们进一步证明了一个信息理论较低的界限,表明至少需要$\Omega(\min\{d^2,K+\log M\}/\epsilon^2)$复制$\rho$来解决这个问题,成功率很高。

**[Paper URL](https://proceedings.mlr.press/v202/gong23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gong23a/gong23a.pdf)** 

# Convergence of Proximal Point and Extragradient-Based Methods Beyond Monotonicity: the Case of Negative Comonotonicity
**题目:** 近点和超梯度法的超越单元性趋同:负单元性案例

**作者:** Eduard Gorbunov, Adrien Taylor, Samuel Horváth, Gauthier Gidel

**Abstract:** Algorithms for min-max optimization and variational inequalities are often studied under monotonicity assumptions. Motivated by non-monotone machine learning applications, we follow the line of works (Diakonikolas et al., 2021; Lee & Kim, 2021; Pethick et al., 2022; Bohm,2022) aiming at going beyond monotonicity by considering the weaker negative comonotonicity assumption. In this work, we provide tight complexity analyses for the Proximal Point (PP), Extragradient (EG), and Optimistic Gradient (OG) methods in this setup, closing several questions on their working guarantees beyond monotonicity. In particular, we derive the first non-asymptotic convergence rates for PP under negative comonotonicity and star-negative comonotonicity and show their tightness via constructing worst-case examples; we also relax the assumptions for the last-iterate convergence guarantees for EG and OG and prove the tightness of the existing best-iterate guarantees for EG and OG via constructing counter-examples.

**摘要:** 最小-最大优化和变异不等式算法经常被研究在单调性假设下。基于非单调机学习应用,我们遵循工作线(Diakonikolas et al., 2021; Lee & Kim, 2021; Pethick et al., 2022; Bohm,2022)以考虑较弱的负单调性假设,以超越单调性。特别是,我们从负同位素和星负同位素下的PP的非渐近收敛率导出了第一个非渐近收敛率,并通过构建最坏情况下的例子证明它们的紧缩性;我们还通过构建反例证明了现有最佳同位素和最佳同位素的紧缩性。

**[Paper URL](https://proceedings.mlr.press/v202/gorbunov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gorbunov23a/gorbunov23a.pdf)** 

# Adaptive Annealed Importance Sampling with Constant Rate Progress
**题目:** 随时速进度调整 Annealed Importance Sampling

**作者:** Shirin Goshtasbpour, Victor Cohen, Fernando Perez-Cruz

**Abstract:** Annealed Importance Sampling (AIS) synthesizes weighted samples from an intractable distribution given its unnormalized density function. This algorithm relies on a sequence of interpolating distributions bridging the target to an initial tractable distribution such as the well-known geometric mean path of unnormalized distributions which is assumed to be suboptimal in general. In this paper, we prove that the geometric annealing corresponds to the distribution path that minimizes the KL divergence between the current particle distribution and the desired target when the feasible change in the particle distribution is constrained. Following this observation, we derive the constant rate discretization schedule for this annealing sequence, which adjusts the schedule to the difficulty of moving samples between the initial and the target distributions. We further extend our results to $f$-divergences and present the respective dynamics of annealing sequences based on which we propose the Constant Rate AIS (CR-AIS) algorithm and its efficient implementation for $\alpha$-divergences. We empirically show that CR-AIS performs well on multiple benchmark distributions while avoiding the computationally expensive tuning loop in existing Adaptive AIS.

**摘要:** 摘要通过对非均匀密度函数的非均匀分布进行分量分析,对非均匀分布的均匀分布进行了分量分析,结果表明,该分量分析方法对非均匀分布的均匀分布进行分量分析,并确定了该分量分析方法对非均匀分布的均匀分布进行分量分析。我们进一步扩展到$f$的差异,并给出了基于该算法的求解序列的动态,并为$alpha$的差异提出了定速AIS(CR-AIS)算法及其有效的实现。我们实验证明CR-AIS在多个基准分布中表现良好,同时避免了现有的适应性AIS中计算成本昂贵的调谐环。

**[Paper URL](https://proceedings.mlr.press/v202/goshtasbpour23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/goshtasbpour23a/goshtasbpour23a.pdf)** 

# Formalizing Preferences Over Runtime Distributions
**题目:** 格式化运行时间分配的优先次序

**作者:** Devon R. Graham, Kevin Leyton-Brown, Tim Roughgarden

**Abstract:** When trying to solve a computational problem, we are often faced with a choice between algorithms that are guaranteed to return the right answer but differ in their runtime distributions (e.g., SAT solvers, sorting algorithms). This paper aims to lay theoretical foundations for such choices by formalizing preferences over runtime distributions. It might seem that we should simply prefer the algorithm that minimizes expected runtime. However, such preferences would be driven by exactly how slow our algorithm is on bad inputs, whereas in practice we are typically willing to cut off occasional, sufficiently long runs before they finish. We propose a principled alternative, taking a utility-theoretic approach to characterize the scoring functions that describe preferences over algorithms. These functions depend on the way our value for solving our problem decreases with time and on the distribution from which captimes are drawn. We describe examples of realistic utility functions and show how to leverage a maximum-entropy approach for modeling underspecified captime distributions. Finally, we show how to efficiently estimate an algorithm’s expected utility from runtime samples.

**摘要:** 当试图解决计算问题时,我们经常面临一种保证返回正确答案的算法之间的选择,但它们的运行时间分布有所不同(例如,SAT求解者、排序算法)。本论文旨在通过形式化运行时间分布上的偏好为这些选择奠定理论基础。我们可能认为,我们应该简单地偏好最小预期运行时间的算法。然而,这种偏好将取决于我们的算法在不良输入上的速度有多慢,而实际上,我们通常愿意在它们完成之前切断偶尔的、足够长的运行。本文描述了实际实用函数的实例,并展示了如何利用最大熵方法对未指定的时限分布进行建模。最后,我们展示了如何从运行时间样本中有效地估计算法的预期实用性。

**[Paper URL](https://proceedings.mlr.press/v202/graham23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/graham23a/graham23a.pdf)** 

# Topological Point Cloud Clustering
**题目:** 拓扑点云集

**作者:** Vincent Peter Grande, Michael T Schaub

**Abstract:** We present Topological Point Cloud Clustering (TPCC), a new method to cluster points in an arbitrary point cloud based on their contribution to global topological features. TPCC synthesizes desirable features from spectral clustering and topological data analysis and is based on considering the spectral properties of a simplicial complex associated to the considered point cloud. As it is based on considering sparse eigenvector computations, TPCC is similarly easy to interpret and implement as spectral clustering. However, by focusing not just on a single matrix associated to a graph created from the point cloud data, but on a whole set of Hodge-Laplacians associated to an appropriately constructed simplicial complex, we can leverage a far richer set of topological features to characterize the data points within the point cloud and benefit from the relative robustness of topological techniques against noise. We test the performance of TPCC on both synthetic and real-world data and compare it with classical spectral clustering.

**摘要:** 本文介绍了一种基于它们对全球拓扑特征的贡献的任意点云中点群的新方法,即拓扑点群集(TPCC)。TPCC是基于考虑与考虑的点云关联的简单复合物的光谱特性的拓扑数据分析和光谱聚类的理想特征的合成方法。TPCC基于考虑稀疏的自向量计算,同样易于解释和实现光谱聚类。然而,通过关注与点云数据创建的图形关联的单一矩阵,而关注与恰当构造的简单复合物关联的整套Hodge-Laplacians,我们可以利用更丰富的拓扑特征集来描述点云内的数据点,并从拓扑技术相对鲁棒性对噪声产生好处。我们对TPCC在合成数据和实物数据上的表现进行了测试,并与经典光谱集群进行了比较。

**[Paper URL](https://proceedings.mlr.press/v202/grande23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/grande23a/grande23a.pdf)** 

# On Sampling with Approximate Transport Maps
**题目:** 与交通 Maps 有关的抽样

**作者:** Louis Grenioux, Alain Oliviero Durmus, Eric Moulines, Marylou Gabrié

**Abstract:** Transport maps can ease the sampling of distributions with non-trivial geometries by transforming them into distributions that are easier to handle. The potential of this approach has risen with the development of Normalizing Flows (NF) which are maps parameterized with deep neural networks trained to push a reference distribution towards a target. NF-enhanced samplers recently proposed blend (Markov chain) Monte Carlo methods with either (i) proposal draws from the flow or (ii) a flow-based reparametrization. In both cases, the quality of the learned transport conditions performance. The present work clarifies for the first time the relative strengths and weaknesses of these two approaches. Our study concludes that multimodal targets can be reliably handled with flow-based proposals up to moderately high dimensions. In contrast, methods relying on reparametrization struggle with multimodality but are more robust otherwise in high-dimensional settings and under poor training. To further illustrate the influence of target-proposal adequacy, we also derive a new quantitative bound for the mixing time of the Independent Metropolis-Hastings sampler.

**摘要:** 这种方法的潜力随着NF(Normalizing Flows)的开发而增加,这些是与深层神经网络进行参数化的地图,训练以推向目标的参考分布。NF增强的样本器最近提出了混合(Markov chain)的蒙特卡罗方法,其中 either(i)提议从流动中提取或(ii)基于流动的校正。在这两个情况下,学习的运输条件性能的质量。本研究首次澄清了这两个方法的相对优势和弱点。为了进一步说明目标提议的充分性的影响,我们还给出了独立 Metropolis-Hastings样品的混合时间的新定量界限。

**[Paper URL](https://proceedings.mlr.press/v202/grenioux23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/grenioux23a/grenioux23a.pdf)** 

# Hidden Symmetries of ReLU Networks
**题目:** ReLU网络的隐形对称

**作者:** Elisenda Grigsby, Kathryn Lindsey, David Rolnick

**Abstract:** The parameter space for any fixed architecture of feedforward ReLU neural networks serves as a proxy during training for the associated class of functions - but how faithful is this representation? It is known that many different parameter settings $\theta$ can determine the same function $f$. Moreover, the degree of this redundancy is inhomogeneous: for some networks, the only symmetries are permutation of neurons in a layer and positive scaling of parameters at a neuron, while other networks admit additional hidden symmetries. In this work, we prove that, for any network architecture where no layer is narrower than the input, there exist parameter settings with no hidden symmetries. We also describe a number of mechanisms through which hidden symmetries can arise, and empirically approximate the functional dimension of different network architectures at initialization. These experiments indicate that the probability that a network has no hidden symmetries decreases towards 0 as depth increases, while increasing towards 1 as width and input dimension increase.

**摘要:** 任何固定的Feedforward ReLU神经网络的参数空间在训练相关类函数时都充当代理函数 - 但这种表示有多可靠? 众所周知,许多不同的参数设置$\theta$可以确定相同的函数$f$。 此外,这种冗余度的程度是不均匀的:对于某些网络,唯一的对称是神经元在一个层中的变换和在神经元上的参数的正级化,而其他网络则承认额外隐藏的对称。这些实验表明,网络没有隐形对称的概率随着深度的增加而降低到0,而随着宽度和输入维度的增加而增加到1。

**[Paper URL](https://proceedings.mlr.press/v202/grigsby23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/grigsby23a/grigsby23a.pdf)** 

# EF21-P and Friends: Improved Theoretical Communication Complexity for Distributed Optimization with Bidirectional Compression
**题目:** EF21-P与朋友:双向压缩实现分布优化的理论通信复杂性提高

**作者:** Kaja Gruntkowska, Alexander Tyurin, Peter Richtárik

**Abstract:** In this work we focus our attention on distributed optimization problems in the context where the communication time between the server and the workers is non-negligible. We obtain novel methods supporting bidirectional compression (both from the server to the workers and vice versa) that enjoy new state-of-the-art theoretical communication complexity for convex and nonconvex problems. Our bounds are the first that manage to decouple the variance/error coming from the workers-to-server and server-to-workers compression, transforming a multiplicative dependence to an additive one. Moreover, in the convex regime, we obtain the first bounds that match the theoretical communication complexity of gradient descent. Even in this convex regime, our algorithms work with biased gradient estimators, which is non-standard and requires new proof techniques that may be of independent interest. Finally, our theoretical results are corroborated through suitable experiments.

**摘要:** 在这一工作中,我们集中注意在服务器与工人之间的通信时间是不可忽略的上下文中分布优化问题。我们获得支持双向压缩的新方法(从服务器到工人和逆向)来享受凸和非凸问题的最新理论通信复杂性。我们的边界是第一个能够将从工人到服务器和服务器到工人压缩的变异/误差分离的边界,将乘法依赖转化为添加性边界。此外,在凸模式中,我们获得符合梯度下降理论通信复杂性的第一边界。

**[Paper URL](https://proceedings.mlr.press/v202/gruntkowska23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gruntkowska23a/gruntkowska23a.pdf)** 

# NerfDiff: Single-image View Synthesis with NeRF-guided Distillation from 3D-aware Diffusion
**题目:** NerfDiff:基于3D感知扩散的NeRF导引蒸馏的单图像视图合成

**作者:** Jiatao Gu, Alex Trevithick, Kai-En Lin, Joshua M. Susskind, Christian Theobalt, Lingjie Liu, Ravi Ramamoorthi

**Abstract:** Novel view synthesis from a single image requires inferring occluded regions of objects and scenes whilst simultaneously maintaining semantic and physical consistency with the input. Existing approaches condition neural radiance fields (NeRF) on local image features, projecting points to the input image plane, and aggregating 2D features to perform volume rendering. However, under severe occlusion, this projection fails to resolve uncertainty, resulting in blurry renderings that lack details. In this work, we propose NerfDiff, which addresses this issue by distilling the knowledge of a 3D-aware conditional diffusion model (CDM) into NeRF through synthesizing and refining a set of virtual views at test-time. We further propose a novel NeRF-guided distillation algorithm that simultaneously generates 3D consistent virtual views from the CDM samples, and finetunes the NeRF based on the improved virtual views. Our approach significantly outperforms existing NeRF-based and geometry-free approaches on challenging datasets including ShapeNet, ABO, and Clevr3D.

**摘要:** 单一图像的新视图合成需要推导对象和场景的隐蔽区域,同时保持与输入的语义和物理一致性。现有的方法是对局部图像特征的条件神经辐射场(NeRF),投影点到输入图像平面,并集结2D特征来进行体积渲染。然而,在严重隐蔽的情况下,这种渲染无法解决不确定性,导致缺乏细节的模糊渲染。我们的方法大大超过现有的基于NeRF和无几何的方法在挑战数据集,包括ShapeNet、ABO和Clevr3D。

**[Paper URL](https://proceedings.mlr.press/v202/gu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gu23a/gu23a.pdf)** 

# DecompDiff: Diffusion Models with Decomposed Priors for Structure-Based Drug Design
**题目:** DecompDiff:基于结构药物设计的分散模型

**作者:** Jiaqi Guan, Xiangxin Zhou, Yuwei Yang, Yu Bao, Jian Peng, Jianzhu Ma, Qiang Liu, Liang Wang, Quanquan Gu

**Abstract:** Designing 3D ligands within a target binding site is a fundamental task in drug discovery. Existing structured-based drug design methods treat all ligand atoms equally, which ignores different roles of atoms in the ligand for drug design and can be less efficient for exploring the large drug-like molecule space. In this paper, inspired by the convention in pharmaceutical practice, we decompose the ligand molecule into two parts, namely arms and scaffold, and propose a new diffusion model, DecompDiff, with decomposed priors over arms and scaffold. In order to facilitate the decomposed generation and improve the properties of the generated molecules, we incorporate both bond diffusion in the model and additional validity guidance in the sampling phase. Extensive experiments on CrossDocked2020 show that our approach achieves state-of-the-art performance in generating high-affinity molecules while maintaining proper molecular properties and conformational stability, with up to $-8.39$ Avg. Vina Dock score and $24.5%$ Success Rate. The code is provided at https://github.com/bytedance/DecompDiff

**摘要:** 药物 discovery中,在目标结合点内设计三维配体是一项基本任务。现有的基于结构的药物设计方法处理所有配体原子均匀,这忽略了配体中原子的不同作用,对药物设计具有较小效率,对于探索大型药物相似分子空间具有较小效率。本文根据药物实践的惯例,将配体分子分解为两个部分,即臂和架子,并提出一种新的扩散模型,DecompDiff,与臂和架子相比的分解前置。CrossDocked2020的广泛实验表明,我们的方法在生成高亲和分子的同时保持适当的分子性质和符合性稳定性方面达到最先进的性能,最高可达$-8.39 Avg. Vina Dock分数和$24.5%成功率。代码提供于 https://github.com/bytedance/DecompDiff

**[Paper URL](https://proceedings.mlr.press/v202/guan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guan23a/guan23a.pdf)** 

# On Excess Mass Behavior in Gaussian Mixture Models with Orlicz-Wasserstein Distances
**题目:** 奥利奇-瓦塞尔斯坦距离高斯混合模型中的过量质量行为

**作者:** Aritra Guha, Nhat Ho, Xuanlong Nguyen

**Abstract:** Dirichlet Process mixture models (DPMM) in combination with Gaussian kernels have been an important modeling tool for numerous data domains arising from biological, physical, and social sciences. However, this versatility in applications does not extend to strong theoretical guarantees for the underlying parameter estimates, for which only a logarithmic rate is achieved. In this work, we (re)introduce and investigate a metric, named Orlicz-Wasserstein distance, in the study of the Bayesian contraction behavior for the parameters. We show that despite the overall slow convergence guarantees for all the parameters, posterior contraction for parameters happens at almost polynomial rates in outlier regions of the parameter space. Our theoretical results provide new insight in understanding the convergence behavior of parameters arising from various settings of hierarchical Bayesian nonparametric models. In addition, we provide an algorithm to compute the metric by leveraging Sinkhorn divergences and validate our findings through a simulation study.

**摘要:** Dirichlet过程混合模型(DPMM)与高斯核结合是生物学、物理学和社会科学产生的各种数据领域的重要建模工具。然而,这种应用的多样性并不延伸到对基本参数估计的强理论保证,仅达到一个 logaritmic率。在这个工作中,我们对参数的贝叶斯收缩行为的研究中引入和研究了一个名为Orlicz-Wasserstein距离的度量。此外,我们提供了一个利用辛克霍恩偏差计算度量算法,并通过仿真研究验证了我们的发现。

**[Paper URL](https://proceedings.mlr.press/v202/guha23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guha23a/guha23a.pdf)** 

# Conformalization of Sparse Generalized Linear Models
**题目:** 备用通用线性模型的规范化

**作者:** Etash Kumar Guha, Eugene Ndiaye, Xiaoming Huo

**Abstract:** Given a sequence of observable variables $\{(x_1, y_1), \ldots, (x_n, y_n)\}$, the conformal prediction method estimates a confidence set for $y_{n+1}$ given $x_{n+1}$ that is valid for any finite sample size by merely assuming that the joint distribution of the data is permutation invariant. Although attractive, computing such a set is computationally infeasible in most regression problems. Indeed, in these cases, the unknown variable $y_{n+1}$ can take an infinite number of possible candidate values, and generating conformal sets requires retraining a predictive model for each candidate. In this paper, we focus on a sparse linear model with only a subset of variables for prediction and use numerical continuation techniques to approximate the solution path efficiently. The critical property we exploit is that the set of selected variables is invariant under a small perturbation of the input data. Therefore, it is sufficient to enumerate and refit the model only at the change points of the set of active features and smoothly interpolate the rest of the solution via a Predictor-Corrector mechanism. We show how our path-following algorithm accurately approximates conformal prediction sets and illustrate its performance using synthetic and real data examples.

**摘要:** 基于可观测变量 $\{(x_1, y_1), \ldots, (x_n, y_n)\}$的序列,对$y_{n+1}$给出的任意有限样本大小的可信集估计值$x_{n+1}$,仅假设数据的联合分布是变换不变。虽然具有吸引力,计算这种集在大多数回归问题中是不可计算的。事实上,在这些情况下,未知的变量$y_{n+1}$可以获得无穷的候选值,生成可信集需要重新训练每个候选者的预测模型。因此,仅在激活特征集的改变点上列举和修改模型,并通过预测器-纠正器机制顺利间polate其余的解决方案是足够的。我们展示了我们的路径跟踪算法如何准确地近似符合性预测集,并用合成和实数据例子说明其性能。

**[Paper URL](https://proceedings.mlr.press/v202/guha23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guha23b/guha23b.pdf)** 

# Privacy-Aware Compression for Federated Learning Through Numerical Mechanism Design
**题目:** 数值机制设计为联邦学习提供隐私意识的压缩

**作者:** Chuan Guo, Kamalika Chaudhuri, Pierre Stock, Michael Rabbat

**Abstract:** In private federated learning (FL), a server aggregates differentially private updates from a large number of clients in order to train a machine learning model. The main challenge in this setting is balancing privacy with both classification accuracy of the learnt model as well as the number of bits communicated between the clients and server. Prior work has achieved a good trade-off by designing a privacy-aware compression mechanism, called the minimum variance unbiased (MVU) mechanism, that numerically solves an optimization problem to determine the parameters of the mechanism. This paper builds upon it by introducing a new interpolation procedure in the numerical design process that allows for a far more efficient privacy analysis. The result is the new Interpolated MVU mechanism that is more scalable, has a better privacy-utility trade-off, and provides SOTA results on communication-efficient private FL on a variety of datasets.

**摘要:** 在私营联合学习(FL)中,服务器会从大量客户中分别集聚私有更新,以训练机器学习模型。该设置的主要挑战是平衡学习模型的分类准确性以及客户端与服务器之间通信的数位。以前的工作通过设计一个隐私意识压缩机制,称为最小偏差不偏倚(MVU)机制,以数值解决优化问题来确定该机制的参数。本论文以引入数字设计过程中的新的插值程序为基础,允许进行更有效的隐私分析。结果是新的插值MVU机制更可扩展,具有更好的隐私-实用性交换,并提供在多种数据集上通信效率高的私有FL的SOTA结果。

**[Paper URL](https://proceedings.mlr.press/v202/guo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guo23a/guo23a.pdf)** 

# Out-of-Distribution Generalization of Federated Learning via Implicit Invariant Relationships
**题目:** 通过隐性不变关系的非分布联邦学习的一般化

**作者:** Yaming Guo, Kai Guo, Xiaofeng Cao, Tieru Wu, Yi Chang

**Abstract:** Out-of-distribution generalization is challenging for non-participating clients of federated learning under distribution shifts. A proven strategy is to explore those invariant relationships between input and target variables, working equally well for non-participating clients. However, learning invariant relationships is often in an explicit manner from data, representation, and distribution, which violates the federated principles of privacy-preserving and limited communication. In this paper, we propose FedIIR, which implicitly learns invariant relationships from parameter for out-of-distribution generalization, adhering to the above principles. Specifically, we utilize the prediction disagreement to quantify invariant relationships and implicitly reduce it through inter-client gradient alignment. Theoretically, we demonstrate the range of non-participating clients to which FedIIR is expected to generalize and present the convergence results for FedIIR in the massively distributed with limited communication. Extensive experiments show that FedIIR significantly outperforms relevant baselines in terms of out-of-distribution generalization of federated learning.

**摘要:** 非分布广义化对非参与学习的客户在分布转移下具有挑战性。一个已证明的策略是探索输入和目标变量之间的不变量关系,对非参与客户同样有效。然而,学习不变量关系往往是从数据、表现和分布中明确地学习的,这违反了保护隐私和有限的通信的联邦原则。本文提出了基于上述原则的非分布广义化参数不变量关系的FedeIIR方法,该方法将不变量关系从参数中学习,具体利用预测分歧来量化不变量关系,并通过客户间梯度调整减少不变量关系。理论上,我们证明了FedIIR预计将推广到非参与的客户范围,并展示了FedIIR在大规模分布的有限通信中收敛结果。广泛的实验表明,FedIIR在非分布的联邦学习推广方面明显超过了相关基线。

**[Paper URL](https://proceedings.mlr.press/v202/guo23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guo23b/guo23b.pdf)** 

# FeDXL: Provable Federated Learning for Deep X-Risk Optimization
**题目:** FeDXL:为深度X-Risk优化提供联邦化学习

**作者:** Zhishuai Guo, Rong Jin, Jiebo Luo, Tianbao Yang

**Abstract:** In this paper, we tackle a novel federated learning (FL) problem for optimizing a family of X-risks, to which no existing FL algorithms are applicable. In particular, the objective has the form of $\mathbb{E}_{\mathbf{z}\sim \mathcal{S}_1} f(\mathbb{E}_{\mathbf{z}’\sim\mathcal{S}_2} \ell(\mathbf{w}; \mathbf{z}, \mathbf{z}’))$, where two sets of data $\mathcal S_1, \mathcal S_2$ are distributed over multiple machines, $\ell(\cdot; \cdot,\cdot)$ is a pairwise loss that only depends on the prediction outputs of the input data pairs $(\mathbf{z}, \mathbf{z}’)$. This problem has important applications in machine learning, e.g., AUROC maximization with a pairwise loss, and partial AUROC maximization with a compositional loss. The challenges for designing an FL algorithm for X-risks lie in the non-decomposability of the objective over multiple machines and the interdependency between different machines. To this end, we propose an active-passive decomposition framework that decouples the gradient’s components with two types, namely active parts and passive parts, where the active parts depend on local data that are computed with the local model and the passive parts depend on other machines that are communicated/computed based on historical models and samples. Under this framework, we design two FL algorithms (FeDXL) for handling linear and nonlinear $f$, respectively, based on federated averaging and merging and develop a novel theoretical analysis to combat the latency of the passive parts and the interdependency between the local model parameters and the involved data for computing local gradient estimators. We establish both iteration and communication complexities and show that using the historical samples and models for computing the passive parts do not degrade the complexities. We conduct empirical studies of FeDXL for deep AUROC and partial AUROC maximization, and demonstrate their performance compared with several baselines.

**摘要:** 本文讨论了一种用于优化X风险家族的联邦学习(FL)问题,对该问题不适用现有FL算法。具体而言,该目标具有$\mathbb{E}_{\mathbf{z}\sim \mathcal{S}_1} f(\mathbb{E}_{\mathbf{z}’\sim\mathcal{S}_2} \ell(\mathbf{w}; \mathbf{z}, \mathbf{z}’))$的形式,其中两个数据集$\mathcal S_1, \mathcal S_2$分布于多个机器,$\ell(\cdot; \cdot,\cdot)$是基于输入数据对$(\mathbf{z}, \mathbf{z}’)$的预测输出的对数损失。该问题在机器为此,我们提出了一种主动- passive分解框架,将梯度组件与两个类型分开,即主动部件和 passive部件,其中主动部件依赖于与局部模型计算的局部数据,而 passive部件依赖于基于历史模型和样品的其他机器进行通信/计算。在此框架下,我们设计了两个FL算法(FeDXL),分别用于处理线性 $f$和非线性 $f$,分别基于联邦平均和合并,并开发了一种新的理论分析,以对抗被动部件的延迟和局部模型参数与计算局部梯度估计器的有关数据之间的相互依赖。本文对 FeDXL 的深度AUROC 和局部AUROC 最大化进行了实证研究,并对 FeDXL 的性能与几种基线进行了比较。

**[Paper URL](https://proceedings.mlr.press/v202/guo23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guo23c/guo23c.pdf)** 

# Provably Efficient Representation Learning with Tractable Planning in Low-Rank POMDP
**题目:** 低级强积金计划中可调规划的有效代表性学习

**作者:** Jiacheng Guo, Zihao Li, Huazheng Wang, Mengdi Wang, Zhuoran Yang, Xuezhou Zhang

**Abstract:** In this paper, we study representation learning in partially observable Markov Decision Processes (POMDPs), where the agent learns a decoder function that maps a series of high-dimensional raw observations to a compact representation and uses it for more efficient exploration and planning. We focus our attention on the sub-classes of $\gamma$-observable and decodable POMDPs, for which it has been shown that statistically tractable learning is possible, but there has not been any computationally efficient algorithm. We first present an algorithm for decodable PMMDPs that combines maximum likelihood estimation (MLE) and optimism in the face of uncertainty (OFU) to perform representation learning and achieve efficient sample complexity, while only calling supervised learning computational oracles. We then show how to adapt this algorithm to also work in the broader class of $\gamma$-observable POMDPs.

**摘要:** 本文研究了部分可观测的马可夫决策过程(POMDP)中的表示学习,其中代理 learns a decoder function that maps a series of high-dimensional raw observations to a compact representation and uses it for more efficient exploration and planning. 研究了$\gamma$-observable and decodable POMDP的分类,其中已经表明,统计学上可操作的学习是可能的,但没有任何计算效率高的算法。

**[Paper URL](https://proceedings.mlr.press/v202/guo23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guo23d/guo23d.pdf)** 

# Analyzing Privacy Leakage in Machine Learning via Multiple Hypothesis Testing: A Lesson From Fano
**题目:** 通过多假设测试对机器学习中的隐私漏洩进行分析:法诺教导

**作者:** Chuan Guo, Alexandre Sablayrolles, Maziar Sanjabi

**Abstract:** Differential privacy (DP) is by far the most widely accepted framework for mitigating privacy risks in machine learning. However, exactly how small the privacy parameter $\epsilon$ needs to be to protect against certain privacy risks in practice is still not well-understood. In this work, we study data reconstruction attacks for discrete data and analyze it under the framework of multiple hypothesis testing. For a learning algorithm satisfying $(\alpha, \epsilon)$-Renyi DP, we utilize different variants of the celebrated Fano’s inequality to upper bound the attack advantage of a data reconstruction adversary. Our bound can be numerically computed to relate the parameter $\epsilon$ to the desired level of privacy protection in practice, and complements the empirical evidence for the effectiveness of DP against data reconstruction attacks even at relatively large values of $\epsilon$.

**摘要:** 微分隐私(英语:Differential privacy,缩写:DP)是机器学习中最广泛接受的减少隐私风险框架。然而,隐私参数$\epsilon$在实践中需要如何保护某些隐私风险仍未得到充分理解。在这个工作中,我们研究离散数据的数据重建攻击,并分析它在多个假设测试的框架下。为满足$(\alpha,\epsilon)$-Renyi DP的学习算法,我们利用了著名的Fano不平等的不同的变量来上限约束数据重建对手的攻击优势。

**[Paper URL](https://proceedings.mlr.press/v202/guo23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guo23e/guo23e.pdf)** 

# Linkless Link Prediction via Relational Distillation
**题目:** 基于关系提馏的无链接预测

**作者:** Zhichun Guo, William Shiao, Shichang Zhang, Yozen Liu, Nitesh V Chawla, Neil Shah, Tong Zhao

**Abstract:** Graph Neural Networks (GNNs) have shown exceptional performance in the task of link prediction. Despite their effectiveness, the high latency brought by non-trivial neighborhood data dependency limits GNNs in practical deployments. Conversely, the known efficient MLPs are much less effective than GNNs due to the lack of relational knowledge. In this work, to combine the advantages of GNNs and MLPs, we start with exploring direct knowledge distillation (KD) methods for link prediction, i.e., predicted logit-based matching and node representation-based matching. Upon observing direct KD analogs do not perform well for link prediction, we propose a relational KD framework, Linkless Link Prediction (LLP), to distill knowledge for link prediction with MLPs. Unlike simple KD methods that match independent link logits or node representations, LLP distills relational knowledge that is centered around each (anchor) node to the student MLP. Specifically, we propose rank-based matching and distribution-based matching strategies that complement each other. Extensive experiments demonstrate that LLP boosts the link prediction performance of MLPs with significant margins and even outperforms the teacher GNNs on 7 out of 8 benchmarks. LLP also achieves a 70.68x speedup in link prediction inference compared to GNNs on the large-scale OGB dataset.

**摘要:**  Graph Neural Networks (GNNs)在链路预测任务中显示出异常的性能,尽管其有效性很高,但非平凡的邻域数据依赖性限制GNNs在实际部署中。相反,已知的高效MLPs由于缺乏关联知识而比GNNs的有效性要低得多。在这个工作中,为了结合GNNs和MLPs的优点,我们开始探索链路预测的直接知识蒸馏(KD)方法,即基于逻辑的预测匹配和基于节点表示匹配。在观察直接KD模拟器对链路预测的性能不好时,我们提出了一种关系性KD框架, Linkless Link Prediction(LLP),以与MLPs进行链路预测的知识蒸馏。具体而言,我们提出了基于等级的匹配和基于分布的匹配策略,它们相互补充。广泛的实验表明,LLP在8个基准中的7个指标中提高了MLP的链路预测性能,甚至超过了GNN的教师。LLP在大范围OGB数据集中,在链路预测推导中也取得了70.68倍的提高。

**[Paper URL](https://proceedings.mlr.press/v202/guo23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guo23f/guo23f.pdf)** 

# FedBR: Improving Federated Learning on Heterogeneous Data via Local Learning Bias Reduction
**题目:** FedBR:通过减少局部学习偏见改善异性数据的联合学习

**作者:** Yongxin Guo, Xiaoying Tang, Tao Lin

**Abstract:** Federated Learning (FL) is a way for machines to learn from data that is kept locally, in order to protect the privacy of clients. This is typically done using local SGD, which helps to improve communication efficiency. However, such a scheme is currently constrained by slow and unstable convergence due to the variety of data on different clients’ devices. In this work, we identify three under-explored phenomena of biased local learning that may explain these challenges caused by local updates in supervised FL. As a remedy, we propose FedBR, a novel unified algorithm that reduces the local learning bias on features and classifiers to tackle these challenges. FedBR has two components. The first component helps to reduce bias in local classifiers by balancing the output of the models. The second component helps to learn local features that are similar to global features, but different from those learned from other data sources. We conducted several experiments to test FedBR and found that it consistently outperforms other SOTA FL methods. Both of its components also individually show performance gains. Our code is available at https://github.com/lins-lab/fedbr.

**摘要:** 联邦学习(FL)是机器从本地存储的数据学习的一种方式,以保护客户隐私。这通常是使用本地SGD来完成,以提高通信效率。然而,这种方案目前由于不同客户设备上的数据的多样性而受到缓慢和不稳定的收敛性限制。在这个工作中,我们确定了偏见的本地学习的三个未被研究的现象,这些现象可能解释了由本地更新引起的这些挑战。作为一种补救办法,我们提议FeedBR,一种新的统一算法,减少了在特征和分类器上的局部学习偏见,以应对这些挑战。FeedBR有两个组成部分。我们进行了几个实验来测试FedBR,并发现它能连续超越其他SOTA FL方法。它的两个组件也分别显示出性能的提高。我们的代码在 https://github.com/lins-lab/fedbr 上。

**[Paper URL](https://proceedings.mlr.press/v202/guo23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guo23g/guo23g.pdf)** 

# Hierarchical Grammar-Induced Geometry for Data-Efficient Molecular Property Prediction
**题目:** 数据高效分子属性预测的层次式语法导数几何

**作者:** Minghao Guo, Veronika Thost, Samuel W Song, Adithya Balachandran, Payel Das, Jie Chen, Wojciech Matusik

**Abstract:** The prediction of molecular properties is a crucial task in the field of material and drug discovery. The potential benefits of using deep learning techniques are reflected in the wealth of recent literature. Still, these techniques are faced with a common challenge in practice: Labeled data are limited by the cost of manual extraction from literature and laborious experimentation. In this work, we propose a data-efficient property predictor by utilizing a learnable hierarchical molecular grammar that can generate molecules from grammar production rules. Such a grammar induces an explicit geometry of the space of molecular graphs, which provides an informative prior on molecular structural similarity. The property prediction is performed using graph neural diffusion over the grammar-induced geometry. On both small and large datasets, our evaluation shows that this approach outperforms a wide spectrum of baselines, including supervised and pre-trained graph neural networks. We include a detailed ablation study and further analysis of our solution, showing its effectiveness in cases with extremely limited data.

**摘要:** 分子性质的预测是材料和药物发现领域的一个关键任务。使用深度学习技术带来的潜在利益反映在最近的文献中。然而,这些技术在实践中面临着一个共同的挑战:标记数据受到文献和 laborious experimentation的手工提取成本的限制。在这个工作中,我们提议利用可学习的层次分子语法,从语法生产规则中产生分子。这种语法诱导了分子图空间的明确几何,提供了分子结构相似性的信息。我们包括详细的解冻研究和进一步分析我们的解决方案,显示其在极限数据的情况下的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/guo23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guo23h/guo23h.pdf)** 

# Graph Neural Networks with Learnable and Optimal Polynomial Bases
**题目:** 具有可学习和最佳多项式基础的图神经网络

**作者:** Yuhe Guo, Zhewei Wei

**Abstract:** Polynomial filters, a kind of Graph Neural Networks, typically use a predetermined polynomial basis and learn the coefficients from the training data. It has been observed that the effectiveness of the model is highly dependent on the property of the polynomial basis. Consequently, two natural and fundamental questions arise: Can we learn a suitable polynomial basis from the training data? Can we determine the optimal polynomial basis for a given graph and node features? In this paper, we propose two spectral GNN models that provide positive answers to the questions posed above. First, inspired by Favard’s Theorem, we propose the FavardGNN model, which learns a polynomial basis from the space of all possible orthonormal bases. Second, we examine the supposedly unsolvable definition of optimal polynomial basis from Wang et al. (2022) and propose a simple model, OptBasisGNN, which computes the optimal basis for a given graph structure and graph signal. Extensive experiments are conducted to demonstrate the effectiveness of our proposed models. Our code is available at https://github.com/yuziGuo/FarOptBasis.

**摘要:** 多项式滤波器(英语:Polynomial filters)是一种 Graph Neural Networks,通常使用预定多项式基础,并从训练数据中学习多项式系数。人们观察到该模型的有效性很大程度上取决于多项式基础的性质。因此,出现了两个自然和基本问题:我们能从训练数据中学习一个合适的多项式基础吗?我们能确定给定的图形和节点特征的最佳多项式基础吗?在本文中,我们提出了两个光谱GNN模型,为上述问题提供积极的答案。为了证明我们提出的模型的有效性,我们进行了广泛的实验,我们的代码可以在 https://github.com/yuziGuo/FarOptBasis 上找到。

**[Paper URL](https://proceedings.mlr.press/v202/guo23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guo23i/guo23i.pdf)** 

# LongCoder: A Long-Range Pre-trained Language Model for Code Completion
**题目:** LongCoder:编码完成的远程预训练语言模型

**作者:** Daya Guo, Canwen Xu, Nan Duan, Jian Yin, Julian Mcauley

**Abstract:** In this paper, we introduce a new task for code completion that focuses on handling long code input and propose a sparse Transformer model, called LongCoder, to address this task. LongCoder employs a sliding window mechanism for self-attention and introduces two types of globally accessible tokens - bridge tokens and memory tokens - to improve performance and efficiency. Bridge tokens are inserted throughout the input sequence to aggregate local information and facilitate global interaction, while memory tokens are included to highlight important statements that may be invoked later and need to be memorized, such as package imports and definitions of classes, functions, or structures. We conduct experiments on a newly constructed dataset that contains longer code context and the publicly available CodeXGLUE benchmark. Experimental results demonstrate that LongCoder achieves superior performance on code completion tasks compared to previous models while maintaining comparable efficiency in terms of computational resources during inference.

**摘要:** 本文介绍了一种面向处理长代码输入的新代码完成任务,并提出了一种名为LongCoder的稀疏变换模型,以解决这一任务。LongCoder采用滑动窗口机制来自我注意,并引入了两个类型的全球可访问的符号——桥牌符号和内存符号——以提高性能和效率。桥牌符号在输入序列中插入,以汇集本地信息并促进全球交互,而内存符号则包括在内,以突出重要的声明,如包导入和类别、函数或结构的定义。我们对包含长代码上下文的新数据集和公开的CodeXGLUE基准进行了实验。实验结果表明,LongCoder在编码完成任务时,与以往的模型相比,具有较高的性能,同时在推导过程中保持可比的计算资源效率。

**[Paper URL](https://proceedings.mlr.press/v202/guo23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guo23j/guo23j.pdf)** 

# Estimating Heterogeneous Treatment Effects: Mutual Information Bounds and Learning Algorithms
**题目:** 估计异性治疗效果:相互信息界限和学习算法

**作者:** Xingzhuo Guo, Yuchen Zhang, Jianmin Wang, Mingsheng Long

**Abstract:** Estimating heterogeneous treatment effects (HTE) from observational studies is rising in importance due to the widespread accumulation of data in many fields. Due to the selection bias behind the inaccessibility of counterfactual data, the problem differs fundamentally from supervised learning in a challenging way. However, existing works on modeling selection bias and corresponding algorithms do not naturally generalize to non-binary treatment spaces. To address this limitation, we propose to use mutual information to describe selection bias in estimating HTE and derive a novel error bound using the mutual information between the covariates and the treatments, which is the first error bound to cover general treatment schemes including multinoulli or continuous spaces. We then bring forth theoretically justified algorithms, the Mutual Information Treatment Network (MitNet), using adversarial optimization to reduce selection bias and obtain more accurate HTE estimations. Our algorithm reaches remarkable performance in both simulation study and empirical evaluation.

**摘要:** 由于在许多领域广泛积累数据,对异性治疗效应的估计在观察研究中日益重要。由于对反事实数据的不可访问性背后的选择偏差,这一问题在根本上与监督学习不同,在挑战性的方式。然而,现有的模式化选择偏差和相应的算法并不自然地推广到非二进制处理空间。为了解决这一局限性,我们提议使用相互信息来描述选择偏差在估计HTE时,并利用共变量和处理之间的相互信息来推导一种新的误差约束,这是覆盖多元或连续空间的一般治疗方案的第一个误差约束。该算法在仿真研究和实证评价中具有显著的性能.

**[Paper URL](https://proceedings.mlr.press/v202/guo23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guo23k/guo23k.pdf)** 

# Identifying Useful Learnwares for Heterogeneous Label Spaces
**题目:** 识别异性标签空间的有用的学习工具

**作者:** Lan-Zhe Guo, Zhi Zhou, Yu-Feng Li, Zhi-Hua Zhou

**Abstract:** The learnware paradigm aims to build a learnware market containing numerous learnwares, each of which is a well-performing machine learning model with a corresponding specification to describe its functionality so that future users can identify useful models for reuse according to their own requirements. With the learnware paradigm, model developers can spontaneously submit models to the market without leaking data privacy, and users can leverage models in the market to accomplish different machine learning tasks without having to build models from scratch. Recent studies have attempted to realize the model specification through Reduced Kernel Mean Embedding (RKME). In this paper, we make an attempt to improve the effectiveness of RKME specification for heterogeneous label spaces, where the learnware market does not contain a model that has the same label space as the user’s task, by considering a class-specific model specification explicitly, along with a class-wise learnware identification method. Both theoretical and empirical analyses show that our proposal can quickly and accurately find useful learnwares that satisfy users’ requirements. Moreover, we find that for a specific task, reusing a small model identified via the specification performs better than directly reusing a pre-trained generic big model.

**摘要:** 学习软件范式旨在构建一个包含多种学习软件的学习软件市场,其中每个是具有相应的规范的机器学习模型,以描述其功能,使未来的用户能够根据自己的需要识别再利用有用的模型。学习软件范式允许模型开发者自发地向市场提交模型,而不泄露数据隐私,用户可以利用市场中的模型来完成不同的机器学习任务,而不需从零构建模型。本文通过明确考虑类别模型规范和类别 learnware识别方法,试图提高RKME规范在用户任务中没有相同的标签空间的异型标签空间的有效性。理论和实证分析表明,我们的建议能够快速准确地找到满足用户需求的有用的 learnware。此外,我们发现,在特定任务中,通过规范识别的小模型的重用比直接重用预训练的通用大型模型更有效。

**[Paper URL](https://proceedings.mlr.press/v202/guo23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guo23l/guo23l.pdf)** 

# High-dimensional Location Estimation via Norm Concentration for Subgamma Vectors
**题目:** 用标准浓度对子伽玛向量进行高维定位估计

**作者:** Shivam Gupta, Jasper C.H. Lee, Eric Price

**Abstract:** In location estimation, we are given $n$ samples from a known distribution $f$ shifted by an unknown translation $\lambda$, and want to estimate $\lambda$ as precisely as possible. Asymptotically, the maximum likelihood estimate achieves the Cramér-Rao bound of error $\mathcal N(0, \frac{1}{n\mathcal I})$, where $\mathcal I$ is the Fisher information of $f$. However, the $n$ required for convergence depends on $f$, and may be arbitrarily large. We build on the theory using smoothed estimators to bound the error for finite $n$ in terms of $\mathcal I_r$, the Fisher information of the $r$-smoothed distribution. As $n \to \infty$, $r \to 0$ at an explicit rate and this converges to the Cramér-Rao bound. We (1) improve the prior work for 1-dimensional $f$ to converge for constant failure probability in addition to high probability, and (2) extend the theory to high-dimensional distributions. In the process, we prove a new bound on the norm of a high-dimensional random variable whose 1-dimensional projections are subgamma, which may be of independent interest.

**摘要:** 在定位估计中,我们得到一个已知的分布 $f$ 的 $n$ 样本,由一个未知的翻译 $\lambda$ 移动,并希望尽可能准确地估计 $\lambda$ 。 Asymptotically, 最大概率估计达到 Cramér-Rao 误差 $\mathcal N(0, \frac{1}{n\mathcal I})$ 的界限,其中 $\mathcal I$ 是 $f$ 的 Fisher 信息。 然而, 需要的 $n$ 取决于 $f$, 并可能任意大. 我们建立在使用平滑估计器的理论上,以 $\mathcal I_r$ 、 $r$-smoothed 分布的 Fisher 信息来界限有限 $n$ 的误差。 As $n \to \infty$在此过程中,我们证明了一种新的对高维随机变量的规范,其1维投影是次元,这可能具有独立的兴趣。

**[Paper URL](https://proceedings.mlr.press/v202/gupta23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gupta23a/gupta23a.pdf)** 

# GRAFENNE: Learning on Graphs with Heterogeneous and Dynamic Feature Sets
**题目:** GRAFENNE:基于异质和动态特征集的图形学习

**作者:** Shubham Gupta, Sahil Manchanda, Sayan Ranu, Srikanta J. Bedathur

**Abstract:** Graph neural networks (GNNs), in general, are built on the assumption of a static set of features characterizing each node in a graph. This assumption is often violated in practice. Existing methods partly address this issue through feature imputation. However, these techniques (i) assume uniformity of feature set across nodes, (ii) are transductive by nature, and (iii) fail to work when features are added or removed over time. In this work, we address these limitations through a novel GNN framework called GRAFENNE. GRAFENNE performs a novel allotropic transformation on the original graph, wherein the nodes and features are decoupled through a bipartite encoding. Through a carefully chosen message passing framework on the allotropic transformation, we make the model parameter size independent of the number of features and thereby inductive to both unseen nodes and features. We prove that GRAFENNE is at least as expressive as any of the existing message-passing GNNs in terms of Weisfeiler-Leman tests, and therefore, the additional inductivity to unseen features does not come at the cost of expressivity. In addition, as demonstrated over four real-world graphs, GRAFENNE empowers the underlying GNN with high empirical efficacy and the ability to learn in continual fashion over streaming feature sets.

**摘要:** 图神经网络(GNNs)一般建立在描述图中的每个节点的静态特征集合的假设上。这一假设经常在实践中被违反。现有的方法部分解决了这一问题,通过特征归纳。然而,这些技术(i)假设在节点间的特征集合均匀,(ii)是自然的导数,(iii)在特征添加或移除时不能工作。在这个工作中,我们通过一种名为GRAFENNE的新GNN框架来解决这些限制。GRAFENNE在原图上进行了新 allotropic 变换,其中节点和特征被通过双方编码分离。通过仔细选择的传递信息框架在 allotropic 变换上,我们使模型参数大小独立于特征的数量,从而诱导到既未见的节点和特征。我们证明,GRAFENNE在Weisfeiler-Leman测试中至少像任何现有的传递消息的GNN一样具有表达性,因此,对隐形特征的额外的诱导性并不以表达性为代价。此外,正如在四个实物图中所证明的那样,GRAFENNE赋予了潜在的GNN具有很高的实证效用和在流域特征集上不断学习的能力。

**[Paper URL](https://proceedings.mlr.press/v202/gupta23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gupta23b/gupta23b.pdf)** 

# Online Platt Scaling with Calibeating
**题目:** 校正在线板尺度

**作者:** Chirag Gupta, Aaditya Ramdas

**Abstract:** We present an online post-hoc calibration method, called Online Platt Scaling (OPS), which combines the Platt scaling technique with online logistic regression. We demonstrate that OPS smoothly adapts between i.i.d. and non-i.i.d. settings with distribution drift. Further, in scenarios where the best Platt scaling model is itself miscalibrated, we enhance OPS by incorporating a recently developed technique called calibeating to make it more robust. Theoretically, our resulting OPS+calibeating method is guaranteed to be calibrated for adversarial outcome sequences. Empirically, it is effective on a range of synthetic and real-world datasets, with and without distribution drifts, achieving superior performance without hyperparameter tuning. Finally, we extend all OPS ideas to the beta scaling method.

**摘要:** 提出了一种在线随机校正方法,即在线板型校正(OPS),它将板型校正技术与在线物流回归结合起来。我们证明,OPS在分布漂移的i.i.d.和非i.i.d.设置之间顺利适应。此外,在最佳板型校正模型本身被误校正的场景中,我们通过采用一种最近开发的技术,即校正来提高OPS的鲁棒性。理论上,我们的结果的OPS+校正方法保证会为敌对结果序列校正。

**[Paper URL](https://proceedings.mlr.press/v202/gupta23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gupta23c/gupta23c.pdf)** 

# Multi-Task Structural Learning using Local Task Similarity induced Neuron Creation and Removal
**题目:** 使用局部任务相似性诱导的多任务结构学习

**作者:** Naresh Kumar Gurulingan, Bahram Zonooz, Elahe Arani

**Abstract:** Multi-task learning has the potential to improve generalization by maximizing positive transfer between tasks while reducing task interference. Fully achieving this potential is hindered by manually designed architectures that remain static throughout training. On the contrary, learning in the brain occurs through structural changes that are in tandem with changes in synaptic strength. Thus, we propose Multi-Task Structural Learning (MTSL) that simultaneously learns the multi-task architecture and its parameters. MTSL begins with an identical single-task network for each task and alternates between a task-learning phase and a structural-learning phase. In the task learning phase, each network specializes in the corresponding task. In each of the structural learning phases, starting from the earliest layer, locally similar task layers first transfer their knowledge to a newly created group layer before being removed. MTSL then uses the group layer in place of the corresponding removed task layers and moves on to the next layers. Our empirical results show that MTSL achieves competitive generalization with various baselines and improves robustness to out-of-distribution data.

**摘要:** 多任务学习具有提高总体化的潜力,通过最大化任务间的积极转移,同时减少任务干涉。完全实现这一潜力,是由于手动设计的架构在训练过程中保持静态而阻碍的。相反,大脑中的学习是通过结构性变化进行的,这些结构性变化与 сина普强度的变化同步进行的。因此,我们建议采用多任务结构性学习(MTSL)来同时学习多任务架构及其参数。MTSL由每个任务的同一单任务网络开始,并由一个任务学习阶段和一个结构性学习阶段进行交互。MTSL使用组层代替相应的移除任务层,然后移动到下层。我们的实证结果表明,MTSL能够与不同的基线进行竞争的一般化,并提高非分布数据的鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/gurulingan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gurulingan23a/gurulingan23a.pdf)** 

# Conditionally Strongly Log-Concave Generative Models
**题目:** 条件强的逻辑凹凸生成模型

**作者:** Florentin Guth, Etienne Lempereur, Joan Bruna, Stéphane Mallat

**Abstract:** There is a growing gap between the impressive results of deep image generative models and classical algorithms that offer theoretical guarantees. The former suffer from mode collapse or memorization issues, limiting their application to scientific data. The latter require restrictive assumptions such as log-concavity to escape the curse of dimensionality. We partially bridge this gap by introducing conditionally strongly log-concave (CSLC) models, which factorize the data distribution into a product of conditional probability distributions that are strongly log-concave. This factorization is obtained with orthogonal projectors adapted to the data distribution. It leads to efficient parameter estimation and sampling algorithms, with theoretical guarantees, although the data distribution is not globally log-concave. We show that several challenging multiscale processes are conditionally log-concave using wavelet packet orthogonal projectors. Numerical results are shown for physical fields such as the $\varphi^4$ model and weak lensing convergence maps with higher resolution than in previous works.

**摘要:** 深度图像生成模型和经典算法提供了理论保证的令人印象深刻的结果之间存在着越来越大的差距。前者受模式崩溃或记忆问题影响,限制其应用于科学数据。后者需要限制性假设,例如逻辑凹陷,以逃避维度的诅咒。我们通过引入条件强的逻辑凹陷(CSLC)模型,将数据分布归因化为条件概率分布的产物,这些分布具有很强的逻辑凹陷。这种归因化是通过对数据分布的正交投影机获得的。对像$\varphi^4$模型这样的物理场和比以前的工作更高分辨率的弱透镜收敛图进行了数值计算。

**[Paper URL](https://proceedings.mlr.press/v202/guth23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guth23a/guth23a.pdf)** 

# DRew: Dynamically Rewired Message Passing with Delay
**题目:** DRew: 动态重新配线的邮件以延迟传递

**作者:** Benjamin Gutteridge, Xiaowen Dong, Michael M. Bronstein, Francesco Di Giovanni

**Abstract:** Message passing neural networks (MPNNs) have been shown to suffer from the phenomenon of over-squashing that causes poor performance for tasks relying on long-range interactions. This can be largely attributed to message passing only occurring locally, over a node’s immediate neighbours. Rewiring approaches attempting to make graphs ’more connected’, and supposedly better suited to long-range tasks, often lose the inductive bias provided by distance on the graph since they make distant nodes communicate instantly at every layer. In this paper we propose a framework, applicable to any MPNN architecture, that performs a layer-dependent rewiring to ensure gradual densification of the graph. We also propose a delay mechanism that permits skip connections between nodes depending on the layer and their mutual distance. We validate our approach on several long-range tasks and show that it outperforms graph Transformers and multi-hop MPNNs.

**摘要:** 消息传递神经网络(MPNNs)被证明遭受了过度调用现象,导致依赖长距离交互的任务的性能低下。这主要归因于消息传递仅发生在一个节点的邻近区域上。重新配线方法试图使图形“更连通”,并被认为是更适合长距离任务,经常失去在图形上的距离所提供的诱导偏差,因为它们使远程节点在每个层上立即通信。本论文提出了一种框架,适用于任何MPNN架构,它执行层依赖的重新配线以确保图形的渐进密度。

**[Paper URL](https://proceedings.mlr.press/v202/gutteridge23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/gutteridge23a/gutteridge23a.pdf)** 

# Kernel Logistic Regression Approximation of an Understandable ReLU Neural Network
**题目:** ReLU神经网络的内核逻辑回归近似

**作者:** Marie Guyomard, Susana Barbosa, Lionel Fillatre

**Abstract:** This paper proposes an understandable neural network whose score function is modeled as an additive sum of univariate spline functions. It extends usual understandable models like generative additive models, spline-based models, and neural additive models. It is shown that this neural network can be approximated by a logistic regression whose inputs are obtained with a non-linear preprocessing of input data. This preprocessing depends on the neural network initialization but this paper establishes that it can be replaced by a non random kernel-based preprocessing that no longer depends on the initialization. Hence, the convergence of the training process is guaranteed and the solution is unique for a given training dataset.

**摘要:** 本文提出了一种可理解的神经网络 whose score function is modeled as an additive sum of univariate spline functions. It extends usual understandable models like generative additive models, spline-based models, and neural additive models. It is shown that this neural network can be approximated by a logistic regression whose inputs are obtained with a non-linear preprocessing of input data. This preprocessing depends on the neural network initialization but this paper establishes that it can be replaced by a non random kernel-based preprocessing that no longer depends on the initialization. Hence, the convergence of the training process is guaranteed and the solution is unique for a given training dataset.

**[Paper URL](https://proceedings.mlr.press/v202/guyomard23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/guyomard23a/guyomard23a.pdf)** 

# Conformal Prediction Sets for Graph Neural Networks
**题目:** 图神经网络的一致预测集

**作者:** Soroush H. Zargarbashi, Simone Antonelli, Aleksandar Bojchevski

**Abstract:** Despite the widespread use of graph neural networks (GNNs) we lack methods to reliably quantify their uncertainty. We propose a conformal procedure to equip GNNs with prediction sets that come with distribution-free guarantees – the output set contains the true label with arbitrarily high probability. Our post-processing procedure can wrap around any (pretrained) GNN, and unlike existing methods, results in meaningful sets even when the model provides only the top class. The key idea is to diffuse the node-wise conformity scores to incorporate neighborhood information. By leveraging the network homophily we construct sets with comparable or better efficiency (average size) and significantly improved singleton hit ratio (correct sets of size one). In addition to an extensive empirical evaluation, we investigate the theoretical conditions under which smoothing provably improves efficiency.

**摘要:** 尽管广泛使用图神经网络(GNN),我们缺乏可靠地定量其不确定性的方法。我们提出了一种符合程序来装备GNNs的预报集,带有无分配保证的输出集包含有任意高概率的真标签。我们的后处理程序可以包围任何(预定)GNN,和与现有方法不同,即使该模型只提供上层类别,也能产生有意义的集。关键思想是扩散节点一致性分数,以便纳入社区信息。通过利用网络同性恋,我们构建具有比较或更好的效率的集(平均大小)和显著改善单元击中率(大小一的正确集)。

**[Paper URL](https://proceedings.mlr.press/v202/h-zargarbashi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/h-zargarbashi23a/h-zargarbashi23a.pdf)** 

# Social learning spontaneously emerges by searching optimal heuristics with deep reinforcement learning
**题目:** 通过深入强化学习寻找最佳的启发方法,社会学习自然产生

**作者:** Seungwoong Ha, Hawoong Jeong

**Abstract:** How have individuals of social animals in nature evolved to learn from each other, and what would be the optimal strategy for such learning in a specific environment? Here, we address both problems by employing a deep reinforcement learning model to optimize the social learning strategies (SLSs) of agents in a cooperative game in a multi-dimensional landscape. Throughout the training for maximizing the overall payoff, we find that the agent spontaneously learns various concepts of social learning, such as copying, focusing on frequent and well-performing neighbors, self-comparison, long-term cooperation between agents, and the importance of balancing between individual and social learning, without any explicit guidance or prior knowledge about the system. The SLS from a fully trained agent outperforms all of the traditional, baseline SLSs in terms of mean payoff. We demonstrate the superior performance of the reinforcement learning agent in various environments, including temporally changing environments and real social networks, which also verifies the adaptability of our framework to different social settings.

**摘要:** 自然界社会动物的个体如何演化来相互学习,在特定环境中学习的最优策略是什么? 在此,我们通过采用深度强化学习模型来解决两个问题,以优化在多维环境中的合作游戏中代理人的社会学习策略(SLS)。在全面回报的训练中,我们发现代理人自发地学习社会学习的各种概念,例如复制、集中于频繁的良好表现的邻居、自我比较、代理人之间的长期合作以及个体与社会学习之间平衡的重要性,而没有明确的指导或系统方面的事先知识。我们证明了增强学习剂在不同环境中的表现优越,包括环境 temporally changing 和真实社会网络,这也验证了我们的框架适应不同社会环境的能力。

**[Paper URL](https://proceedings.mlr.press/v202/ha23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ha23a/ha23a.pdf)** 

# Convex Geometry of ReLU-layers, Injectivity on the Ball and Local Reconstruction
**题目:** ReLU层凸几何、球上的注射性和局部重建

**作者:** Daniel Haider, Martin Ehler, Peter Balazs

**Abstract:** The paper uses a frame-theoretic setting to study the injectivity of a ReLU-layer on the closed ball of $\mathbb{R}^n$ and its non-negative part. In particular, the interplay between the radius of the ball and the bias vector is emphasized. Together with a perspective from convex geometry, this leads to a computationally feasible method of verifying the injectivity of a ReLU-layer under reasonable restrictions in terms of an upper bound of the bias vector. Explicit reconstruction formulas are provided, inspired by the duality concept from frame theory. All this gives rise to the possibility of quantifying the invertibility of a ReLU-layer and a concrete reconstruction algorithm for any input vector on the ball.

**摘要:** 本文利用框架理论设置对$\mathbb{R}^n$闭球及其非负部分的ReLU层的注入性进行了研究,特别强调了球的半径与偏向矢量之间的相互作用,并结合凸几何学的视角,提出了在偏向矢量上合理的限制下验证ReLU层的注入性的一种可行的计算方法。

**[Paper URL](https://proceedings.mlr.press/v202/haider23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/haider23a/haider23a.pdf)** 

# Robust Counterfactual Explanations for Neural Networks With Probabilistic Guarantees
**题目:** 具有概率保证的神经网络的鲁棒反事实解释

**作者:** Faisal Hamman, Erfaun Noorani, Saumitra Mishra, Daniele Magazzeni, Sanghamitra Dutta

**Abstract:** There is an emerging interest in generating robust counterfactual explanations that would remain valid if the model is updated or changed even slightly. Towards finding robust counterfactuals, existing literature often assumes that the original model $m$ and the new model $M$ are bounded in the parameter space, i.e., $\|\text{Params}(M){-}\text{Params}(m)\|{<}\Delta$. However, models can often change significantly in the parameter space with little to no change in their predictions or accuracy on the given dataset. In this work, we introduce a mathematical abstraction termed naturally-occurring model change, which allows for arbitrary changes in the parameter space such that the change in predictions on points that lie on the data manifold is limited. Next, we propose a measure – that we call Stability – to quantify the robustness of counterfactuals to potential model changes for differentiable models, e.g., neural networks. Our main contribution is to show that counterfactuals with sufficiently high value of Stability as defined by our measure will remain valid after potential “naturally-occurring” model changes with high probability (leveraging concentration bounds for Lipschitz function of independent Gaussians). Since our quantification depends on the local Lipschitz constant around a data point which is not always available, we also examine practical relaxations of our proposed measure and demonstrate experimentally how they can be incorporated to find robust counterfactuals for neural networks that are close, realistic, and remain valid after potential model changes.

**摘要:** 为了寻找可靠的反事实,现有文献经常假设元模型$m$和新模型$M$在参数空间中被界限,即$\|\text{Params}(M){-}\text{Params}(m)\|{<}\Delta$。然而,模型在参数空间中往往会发生显著变化,其预测或数据集的准确性几乎没有变化。我们的主要贡献是表明,在潜在的“自然发生”模型变化后(高概率的拉普希茨函数的浓度边界提取)具有足够高的稳定性值的反因子仍然有效。由于我们的定量依赖于一个数据点周围的局部拉普希茨常数,所以我们还研究了我们提出的措施的实际放松,并通过实验证明,如何将这些反因子纳入到能找到接近、现实和在潜在模型变化后保持有效神经网络的强性反因子。

**[Paper URL](https://proceedings.mlr.press/v202/hamman23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hamman23a/hamman23a.pdf)** 

# Wrapped Cauchy Distributed Angular Softmax for Long-Tailed Visual Recognition
**题目:** 编织凸凹分布式角软体,用于长尺度视觉识别

**作者:** Boran Han

**Abstract:** Addressing imbalanced or long-tailed data is a major challenge in visual recognition tasks due to disparities between training and testing distributions and issues with data noise. We propose the Wrapped Cauchy Distributed Angular Softmax (WCDAS), a novel softmax function that incorporates data-wise Gaussian-based kernels into the angular correlation between feature representations and classifier weights, effectively mitigating noise and sparse sampling concerns. The class-wise distribution of angular representation becomes a sum of these kernels. Our theoretical analysis reveals that the wrapped Cauchy distribution excels the Gaussian distribution in approximating mixed distributions. Additionally, WCDAS uses trainable concentration parameters to dynamically adjust the compactness and margin of each class. Empirical results confirm label-aware behavior in these parameters and demonstrate WCDAS’s superiority over other state-of-the-art softmax-based methods in handling long-tailed visual recognition across multiple benchmark datasets. The code is public available.

**摘要:** 解决不平衡或长尾数据是由于训练和测试分布的差异以及数据噪声问题在视觉识别任务中的一个主要挑战。我们提出了包带柯西分布角软max(WCDAS),一种新的软max函数,它将基于数据的高斯核结合到特征表示和分类器重量之间的角相关性,有效地减轻噪声和稀疏采样问题。角表示的分类分布成为这些核的总数。我们的理论分析显示包带柯西分布在近似混合分布时优于高斯分布。实验结果证实了这些参数中的标签意识行为,并证明WCDAS在处理多个基准数据集的长尾视觉识别方面比其他最先进的软max基于方法具有优势。

**[Paper URL](https://proceedings.mlr.press/v202/han23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/han23a/han23a.pdf)** 

# On the Impact of Knowledge Distillation for Model Interpretability
**题目:** 知识蒸馏对模型解释性的影响

**作者:** Hyeongrok Han, Siwon Kim, Hyun-Soo Choi, Sungroh Yoon

**Abstract:** Several recent studies have elucidated why knowledge distillation (KD) improves model performance. However, few have researched the other advantages of KD in addition to its improving model performance. In this study, we have attempted to show that KD enhances the interpretability as well as the accuracy of models. We measured the number of concept detectors identified in network dissection for a quantitative comparison of model interpretability. We attributed the improvement in interpretability to the class-similarity information transferred from the teacher to student models. First, we confirmed the transfer of class-similarity information from the teacher to student model via logit distillation. Then, we analyzed how class-similarity information affects model interpretability in terms of its presence or absence and degree of similarity information. We conducted various quantitative and qualitative experiments and examined the results on different datasets, different KD methods, and according to different measures of interpretability. Our research showed that KD models by large models could be used more reliably in various fields. The code is available at https://github.com/Rok07/KD_XAI.git.

**摘要:** 研究表明,知识蒸馏能提高模型性能,但是,除了提高模型性能外,还研究了KD的其他优点。在研究中,我们试图证明KD能提高模型的解释性和准确性。我们测量了在网络分离中识别的概念探测器的数目,以便对模型的解释性进行定量比较。我们归功于从教师向学生模型转移的类别相似性信息。首先,通过逻辑蒸馏证实了从教师向学生模型转移的类别相似性信息,然后分析了类别相似性信息如何影响模型的解释性。我们进行了各种定量和质量实验,并对不同数据集、不同KD方法和不同可解释度的测量结果进行了研究。我们的研究表明,大型模型的KD模型可以在不同领域中更可靠地使用。

**[Paper URL](https://proceedings.mlr.press/v202/han23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/han23b/han23b.pdf)** 

# Alternately Optimized Graph Neural Networks
**题目:** 交互优化图形神经网络

**作者:** Haoyu Han, Xiaorui Liu, Haitao Mao, Mohamadali Torkamani, Feng Shi, Victor Lee, Jiliang Tang

**Abstract:** Graph Neural Networks (GNNs) have greatly advanced the semi-supervised node classification task on graphs. The majority of existing GNNs are trained in an end-to-end manner that can be viewed as tackling a bi-level optimization problem. This process is often inefficient in computation and memory usage. In this work, we propose a new optimization framework for semi-supervised learning on graphs from a multi-view learning perspective. The proposed framework can be conveniently solved by the alternating optimization algorithms, resulting in significantly improved efficiency. Extensive experiments demonstrate that the proposed method can achieve comparable or better performance with state-of-the-art baselines while it has significantly better computation and memory efficiency.

**摘要:** 图神经网络(GNNs)在图上大大提高了半监督节点分类任务。现有GNN的大多数是以一种端到端的方式训练的,可视作解决两级优化问题。这一过程在计算和记忆使用方面往往效率低下。在这个工作中,我们提出了一种基于多视角学习视角的图上半监督学习的优化框架。

**[Paper URL](https://proceedings.mlr.press/v202/han23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/han23c/han23c.pdf)** 

# System Identification of Neural Systems: If We Got It Right, Would We Know?
**题目:** 神经系统系统系统识别:如果我们正确,我们会知道吗?

**作者:** Yena Han, Tomaso A Poggio, Brian Cheung

**Abstract:** Artificial neural networks are being proposed as models of parts of the brain. The networks are compared to recordings of biological neurons, and good performance in reproducing neural responses is considered to support the model’s validity. A key question is how much this system identification approach tells us about brain computation. Does it validate one model architecture over another? We evaluate the most commonly used comparison techniques, such as a linear encoding model and centered kernel alignment, to correctly identify a model by replacing brain recordings with known ground truth models. System identification performance is quite variable; it also depends significantly on factors independent of the ground truth architecture, such as stimuli images. In addition, we show the limitations of using functional similarity scores in identifying higher-level architectural motifs.

**摘要:** 人工神经网络作为大脑部分模型被提议。这些网络与生物神经元的记录进行比较,并考虑在复制神经反应方面良好的性能来支持模型的有效性。一个关键问题是,这种系统识别方法对大脑计算的了解有多大。它是否能使一个模型架构在另一个模型架构上得到有效性?我们评估最常用的比较技术,例如线性编码模型和中心核对应,以替换大脑记录与已知的地面真实模型来正确识别模型。系统识别性能非常变化,它也依赖于独立于地面真实架构的因素,例如刺激图像。此外,我们还显示了在识别高层次建筑动词时使用功能相似性分数的局限性。

**[Paper URL](https://proceedings.mlr.press/v202/han23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/han23d/han23d.pdf)** 

# Total Variation Graph Neural Networks
**题目:** 全变图神经网络

**作者:** Jonas Berg Hansen, Filippo Maria Bianchi

**Abstract:** Recently proposed Graph Neural Networks (GNNs) for vertex clustering are trained with an unsupervised minimum cut objective, approximated by a Spectral Clustering (SC) relaxation. However, the SC relaxation is loose and, while it offers a closed-form solution, it also yields overly smooth cluster assignments that poorly separate the vertices. In this paper, we propose a GNN model that computes cluster assignments by optimizing a tighter relaxation of the minimum cut based on graph total variation (GTV). The cluster assignments can be used directly to perform vertex clustering or to implement graph pooling in a graph classification framework. Our model consists of two core components: i) a message-passing layer that minimizes the $\ell_1$ distance in the features of adjacent vertices, which is key to achieving sharp transitions between clusters; ii) an unsupervised loss function that minimizes the GTV of the cluster assignments while ensuring balanced partitions. Experimental results show that our model outperforms other GNNs for vertex clustering and graph classification.

**摘要:** 本文提出了一种基于图总变异(GTV)的最小切削更紧的松弛算法来计算最小切削目标的GNN模型,该算法可以直接用于实现最小切削或在图分类框架中实现图聚合。我们的模型由两个核心组成: (i)一个 message-passing layer that minimizes the $\ell_1$ distance in the features of adjacent vertices, which is key to achieving sharp transitions between clusters; (ii)一个没有监督的损失函数,该函数能最小化最小切削的GTV。实验结果表明,该模型在顶点聚类和图类别方面优于其他GNN模型。

**[Paper URL](https://proceedings.mlr.press/v202/hansen23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hansen23a/hansen23a.pdf)** 

# Learning Physical Models that Can Respect Conservation Laws
**题目:** 学习能尊重保护法的物理模型

**作者:** Derek Hansen, Danielle C. Maddix, Shima Alizadeh, Gaurav Gupta, Michael W. Mahoney

**Abstract:** Recent work in scientific machine learning (SciML) has focused on incorporating partial differential equation (PDE) information into the learning process. Much of this work has focused on relatively "easy” PDE operators (e.g., elliptic and parabolic), with less emphasis on relatively “hard” PDE operators (e.g., hyperbolic). Within numerical PDEs, the latter problem class requires control of a type of volume element or conservation constraint, which is known to be challenging. Delivering on the promise of SciML requires seamlessly incorporating both types of problems into the learning process. To address this issue, we propose ProbConserv, a framework for incorporating constraints into a generic SciML architecture. To do so, ProbConserv combines the integral form of a conservation law with a Bayesian update. We provide a detailed analysis of ProbConserv on learning with the Generalized Porous Medium Equation (GPME), a widely-applicable parameterized family of PDEs that illustrates the qualitative properties of both easier and harder PDEs. ProbConserv is effective for easy GPME variants, performing well with state-of-the-art competitors; and for harder GPME variants it outperforms other approaches that do not guarantee volume conservation. ProbConserv seamlessly enforces physical conservation constraints, maintains probabilistic uncertainty quantification (UQ), and deals well with shocks and heteroscedasticity. In each case, it achieves superior predictive performance on downstream tasks.

**摘要:** 最近在科学机器学习(SciML)中的研究重点是将部分微分方程(PDE)信息纳入学习过程。该研究的大部分重点是相对“轻松”的PDE操作符(例如椭圆和抛物),较少的重点是相对“硬”的PDE操作符(例如高分子)。在数值PDEs中,后者的问题类需要控制一个类型的体积元素或保护约束,这被认为是挑战性的。ProbConserv提供了一个关于学习的广义多孔介质方程(GPME)的详细分析,该方程是PDEs的一个广泛适用的参数化家族,它说明了更易和更难的PDEs的质量特性。 ProbConserv适用于更易的GPME变量,与最先进的竞争者表现良好;对于更难的GPME变量,它优于其他方法,不能保证储量。 ProbConserv无缝地强制执行物理储量约束,保持概率不确定性定量化(UQ),并处理冲击和异质性。

**[Paper URL](https://proceedings.mlr.press/v202/hansen23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hansen23b/hansen23b.pdf)** 

# On Pre-Training for Visuo-Motor Control: Revisiting a Learning-from-Scratch Baseline
**题目:** 对视力-运动控制的预训练:回顾从 Scratch 学习的基线

**作者:** Nicklas Hansen, Zhecheng Yuan, Yanjie Ze, Tongzhou Mu, Aravind Rajeswaran, Hao Su, Huazhe Xu, Xiaolong Wang

**Abstract:** In this paper, we examine the effectiveness of pre-training for visuo-motor control tasks. We revisit a simple Learning-from-Scratch (LfS) baseline that incorporates data augmentation and a shallow ConvNet, and find that this baseline is surprisingly competitive with recent approaches (PVR, MVP, R3M) that leverage frozen visual representations trained on large-scale vision datasets – across a variety of algorithms, task domains, and metrics in simulation and on a real robot. Our results demonstrate that these methods are hindered by a significant domain gap between the pre-training datasets and current benchmarks for visuo-motor control, which is alleviated by finetuning. Based on our findings, we provide recommendations for future research in pre-training for control and hope that our simple yet strong baseline will aid in accurately benchmarking progress in this area. Code: https://github.com/gemcollector/learning-from-scratch.

**摘要:** 在本文中,我们考察了视觉运动控制任务的预训练的有效性。我们再次回顾了一个简单的从Scratch学习(LfS)基础线,它包含数据增强和浅浅的ConvNet,并发现这一基础线与最近的方法(PVR、MVP、R3M)具有惊人的竞争性,它们利用在大规模视觉数据集上训练的冻结视觉表现 — — 在模拟和实物机器人中的多种算法、任务领域和度量。

**[Paper URL](https://proceedings.mlr.press/v202/hansen23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hansen23c/hansen23c.pdf)** 

# Leveraging Demonstrations to Improve Online Learning: Quality Matters
**题目:** 利用演示改善网上学习:质量问题

**作者:** Botao Hao, Rahul Jain, Tor Lattimore, Benjamin Van Roy, Zheng Wen

**Abstract:** We investigate the extent to which offline demonstration data can improve online learning. It is natural to expect some improvement, but the question is how, and by how much? We show that the degree of improvement must depend on the quality of the demonstration data. To generate portable insights, we focus on Thompson sampling (TS) applied to a multi-armed bandit as a prototypical online learning algorithm and model. The demonstration data is generated by an expert with a given competence level, a notion we introduce. We propose an informed TS algorithm that utilizes the demonstration data in a coherent way through Bayes’ rule and derive a prior-dependent Bayesian regret bound. This offers insight into how pretraining can greatly improve online performance and how the degree of improvement increases with the expert’s competence level. We also develop a practical, approximate informed TS algorithm through Bayesian bootstrapping and show substantial empirical regret reduction through experiments.

**摘要:** 我们研究了在线演示数据能够提高在线学习的程度。当然可以期望一些改进,但问题是如何,以及多少?我们表明,改进程度必须取决于演示数据的质量。为了产生可移动的洞察力,我们着重于汤普森采样(TS)应用于多武器的 bandit,作为一种原型在线学习算法和模型。演示数据由一个具有一定能力的专家生成,我们引入了一个概念。我们提出了一种有知识的TS算法,它通过贝伊斯规则以一致的方式利用演示数据,并产生一个事先依赖的贝伊斯遗憾约束。通过贝叶斯的启动,我们还开发了一种实用的、近似的基于信息的TS算法,并通过实验显示了明显的经验减少遗憾。

**[Paper URL](https://proceedings.mlr.press/v202/hao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hao23a/hao23a.pdf)** 

# Coupled Variational Autoencoder
**题目:** 耦合变量自动编码器

**作者:** Xiaoran Hao, Patrick Shafto

**Abstract:** Variational auto-encoders are powerful probabilistic models in generative tasks but suffer from generating low-quality samples which are caused by the holes in the prior. We propose the Coupled Variational Auto-Encoder (C-VAE), which formulates the VAE problem as one of Optimal Transport (OT) between the prior and data distributions. The C-VAE allows greater flexibility in priors and natural resolution of the prior hole problem by enforcing coupling between the prior and the data distribution and enables flexible optimization through the primal, dual, and semi-dual formulations of entropic OT. Simulations on synthetic and real data show that the C-VAE outperforms alternatives including VAE, WAE, and InfoVAE in fidelity to the data, quality of the latent representation, and in quality of generated samples.

**摘要:** 耦合变量自动编码器(C-VAE)是编码器与数据分布之间的最优传输(OT)之一,它允许在预先和数据分布之间进行耦合,从而使预先和预先孔问题具有更大的灵活性和自然解决性,并通过熵OT的初始、双重和半双重公式实现灵活的优化。 对合成和实际数据的仿真表明,C-VAE在 fidelity to the data, quality of the latent representation, and in quality of generated samples等方面比VAE、WAE和InfoVAE更优越。

**[Paper URL](https://proceedings.mlr.press/v202/hao23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hao23b/hao23b.pdf)** 

# GNOT: A General Neural Operator Transformer for Operator Learning
**题目:** GNOT:操作员学习的一般神经操作员变换器

**作者:** Zhongkai Hao, Zhengyi Wang, Hang Su, Chengyang Ying, Yinpeng Dong, Songming Liu, Ze Cheng, Jian Song, Jun Zhu

**Abstract:** Learning partial differential equations’ (PDEs) solution operators is an essential problem in machine learning. However, there are several challenges for learning operators in practical applications like the irregular mesh, multiple input functions, and complexity of the PDEs’ solution. To address these challenges, we propose a general neural operator transformer (GNOT), a scalable and effective transformer-based framework for learning operators. By designing a novel heterogeneous normalized attention layer, our model is highly flexible to handle multiple input functions and irregular meshes. Besides, we introduce a geometric gating mechanism which could be viewed as a soft domain decomposition to solve the multi-scale problems. The large model capacity of the transformer architecture grants our model the possibility to scale to large datasets and practical problems. We conduct extensive experiments on multiple challenging datasets from different domains and achieve a remarkable improvement compared with alternative methods. Our code and data are publicly available at https://github.com/thu-ml/GNOT.

**摘要:**  learn partial differential equations’ (PDEs) solution operators 是机器学习中的一个重要问题。然而,在实际应用中,学习操作员存在一些挑战,如不规则网格、多输入函数和PDEs解决方案的复杂性。为了解决这些挑战,我们提出了一种通用神经运算器变换器(GNOT),一种可扩展和有效的变换器基础框架,用于学习操作员。通过设计一种新颖的异质正常化注意力层,我们的模型非常灵活地处理多输入函数和不规则网格。此外,我们引入了一种几何测定机制,可视作软域分解来解决多尺度问题。我们对不同域的多个挑战性数据集进行了广泛的实验,与其他方法相比取得了显著的改进。我们的代码和数据在 https://github.com/thu-ml/GNOT上公开。

**[Paper URL](https://proceedings.mlr.press/v202/hao23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hao23c/hao23c.pdf)** 

# Algorithmic Collective Action in Machine Learning
**题目:** 机器学习中的算法集体行动

**作者:** Moritz Hardt, Eric Mazumdar, Celestine Mendler-Dünner, Tijana Zrnic

**Abstract:** We initiate a principled study of algorithmic collective action on digital platforms that deploy machine learning algorithms. We propose a simple theoretical model of a collective interacting with a firm’s learning algorithm. The collective pools the data of participating individuals and executes an algorithmic strategy by instructing participants how to modify their own data to achieve a collective goal. We investigate the consequences of this model in three fundamental learning-theoretic settings: nonparametric optimal learning, parametric risk minimization, and gradient-based optimization. In each setting, we come up with coordinated algorithmic strategies and characterize natural success criteria as a function of the collective’s size. Complementing our theory, we conduct systematic experiments on a skill classification task involving tens of thousands of resumes from a gig platform for freelancers. Through more than two thousand model training runs of a BERT-like language model, we see a striking correspondence emerge between our empirical observations and the predictions made by our theory. Taken together, our theory and experiments broadly support the conclusion that algorithmic collectives of exceedingly small fractional size can exert significant control over a platform’s learning algorithm.

**摘要:** 我们开始对部署机器学习算法的数字平台的算法集体行动的理论研究。我们提出了一个与公司学习算法互动的集体的简单理论模型。该集体将参与者的数据合并并,并通过指导参与者如何修改自己的数据实现集体目标,执行一种算法策略。我们对这一模型在三个基本学习理论环境中的影响进行了研究:非参数优化学习、参数风险最小化和梯度优化。在每个环境中,我们提出了协调的算法策略,并以集体大小的函数来描述自然成功标准。通过超过两千个类似BERT语言模型的模型训练,我们看到我们的经验观察与理论所作的预测之间出现明显的相符性。 结合起来,我们的理论和实验广泛支持了超小微分大小的算法集能够对平台学习算法产生重大控制。

**[Paper URL](https://proceedings.mlr.press/v202/hardt23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hardt23a/hardt23a.pdf)** 

# Gaussian Process Priors for Systems of Linear Partial Differential Equations with Constant Coefficients
**题目:** 常系数线性微分方程系统高斯过程序列

**作者:** Marc Harkonen, Markus Lange-Hegermann, Bogdan Raita

**Abstract:** Partial differential equations (PDEs) are important tools to model physical systems and including them into machine learning models is an important way of incorporating physical knowledge. Given any system of linear PDEs with constant coefficients, we propose a family of Gaussian process (GP) priors, which we call EPGP, such that all realizations are exact solutions of this system. We apply the Ehrenpreis-Palamodov fundamental principle, which works as a non-linear Fourier transform, to construct GP kernels mirroring standard spectral methods for GPs. Our approach can infer probable solutions of linear PDE systems from any data such as noisy measurements, or pointwise defined initial and boundary conditions. Constructing EPGP-priors is algorithmic, generally applicable, and comes with a sparse version (S-EPGP) that learns the relevant spectral frequencies and works better for big data sets. We demonstrate our approach on three families of systems of PDEs, the heat equation, wave equation, and Maxwell’s equations, where we improve upon the state of the art in computation time and precision, in some experiments by several orders of magnitude.

**摘要:** 部分微分方程(Partial differential equations,PDEs)是建模物理系统的重要工具,并将其纳入机器学习模型是实现物理知识的重要途径。考虑到任何具有恒定系数的线性PDEs的系统,我们提出了一种高斯过程(GP)序列,我们称之为EPGP,使得所有实现都是该系统的精确解决方法。我们应用 Ehrenpreis-Palamodov基本原理,作为非线性傅立叶变换,构建GP核以反映GP的标准光谱方法。我们展示了我们对三类PDEs系统的方法:热方程、波方程和麦克斯韦方程,其中我们在一些实验中提高了计算时间和精度的先进性。

**[Paper URL](https://proceedings.mlr.press/v202/harkonen23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/harkonen23a/harkonen23a.pdf)** 

# Theoretical Guarantees of Learning Ensembling Strategies with Applications to Time Series Forecasting
**题目:** 基于时间序列预测的模拟策略学习理论保障

**作者:** Hilaf Hasson, Danielle C. Maddix, Bernie Wang, Gaurav Gupta, Youngsuk Park

**Abstract:** Ensembling is among the most popular tools in machine learning (ML) due to its effectiveness in minimizing variance and thus improving generalization. Most ensembling methods for black-box base learners fall under the umbrella of "stacked generalization," namely training an ML algorithm that takes the inferences from the base learners as input. While stacking has been widely applied in practice, its theoretical properties are poorly understood. In this paper, we prove a novel result, showing that choosing the best stacked generalization from a (finite or finite-dimensional) family of stacked generalizations based on cross-validated performance does not perform "much worse" than the oracle best. Our result strengthens and significantly extends the results in Van der Laan et al. (2007). Inspired by the theoretical analysis, we further propose a particular family of stacked generalizations in the context of probabilistic forecasting, each one with a different sensitivity for how much the ensemble weights are allowed to vary across items, timestamps in the forecast horizon, and quantiles. Experimental results demonstrate the performance gain of the proposed method.

**摘要:** 模拟是机器学习(ML)中最受欢迎的工具之一,因为它在最小化变异和改进一般化方面的有效性。对于黑箱基础学习者来说,大多数模拟方法属于“堆栈一般化”的伞下,即训练一个从基础学习者所得的推理作为输入的ML算法。在实际应用中,堆栈是广泛的,其理论性质却被理解得很差。基于理论分析,我们进一步提出一种基于概率预测的堆叠一般化,每个堆叠一般化具有不同程度的敏感性,可以根据项目、预测视角的时间标记和量值来决定组合权重的大小。实验结果证明了该方法的性能提高。

**[Paper URL](https://proceedings.mlr.press/v202/hasson23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hasson23a/hasson23a.pdf)** 

# Global Context Vision Transformers
**题目:** 全球背景视觉转换器

**作者:** Ali Hatamizadeh, Hongxu Yin, Greg Heinrich, Jan Kautz, Pavlo Molchanov

**Abstract:** We propose global context vision transformer (GC ViT), a novel architecture that enhances parameter and compute utilization for computer vision. Our method leverages global context self-attention modules, joint with standard local self-attention, to effectively and efficiently model both long and short-range spatial interactions, without the need for expensive operations such as computing attention masks or shifting local windows. In addition, we address the lack of the inductive bias in ViTs, and propose to leverage a modified fused inverted residual blocks in our architecture. Our proposed GC ViT achieves state-of-the-art results across image classification, object detection and semantic segmentation tasks. On ImageNet-1K dataset for classification, the variants of GC ViT with 51M, 90M and 201M parameters achieve 84.3%, 85.0% and 85.7% Top-1 accuracy, respectively, at 224 image resolution and without any pre-training, hence surpassing comparably-sized prior art such as CNN-based ConvNeXt and ViT-based MaxViT and Swin Transformer by a large margin. Pre-trained GC ViT backbones in downstream tasks of object detection, instance segmentation, and semantic segmentation using MS COCO and ADE20K datasets outperform prior work consistently. Specifically, GC ViT with a 4-scale DINO detection head achieves a box AP of 58.3 on MS COCO dataset.

**摘要:** 本文提出了一种新型的计算机视觉参数和计算利用的全球上下文视觉变换器(GC ViT)。该方法利用全球上下文自我关注模块,结合标准的局部自我关注,有效地和高效地模拟长距离和短距离空间相互作用,无需像计算注意力面具或移动局部窗口等昂贵操作。此外,我们解决了ViT中的诱导偏差的不足,并建议在我们的架构中利用改进的融合逆转残余块。在ImageNet-1K分类数据集中,具有51M、90M和201M参数的GC ViT变量分别达到84.3%、85.0%和85.7%的最高-1精度,在24个图像分辨率和没有预训练的情况下,大大超过了基于CNN的ConvNeXt和ViT的MaxViT和Swin变换器等相等规模的先进技术。

**[Paper URL](https://proceedings.mlr.press/v202/hatamizadeh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hatamizadeh23a/hatamizadeh23a.pdf)** 

# Counterfactual Analysis in Dynamic Latent State Models
**题目:** 动态潜在状态模型的反事实分析

**作者:** Martin B Haugh, Raghav Singal

**Abstract:** We provide an optimization-based framework to perform counterfactual analysis in a dynamic model with hidden states. Our framework is grounded in the “abduction, action, and prediction” approach to answer counterfactual queries and handles two key challenges where (1) the states are hidden and (2) the model is dynamic. Recognizing the lack of knowledge on the underlying causal mechanism and the possibility of infinitely many such mechanisms, we optimize over this space and compute upper and lower bounds on the counterfactual quantity of interest. Our work brings together ideas from causality, state-space models, simulation, and optimization, and we apply it on a breast cancer case study. To the best of our knowledge, we are the first to compute lower and upper bounds on a counterfactual query in a dynamic latent-state model.

**摘要:** 我们提供一种基于优化的框架,以执行具有隐藏状态的动态模型的反事实分析。我们的框架是基于“诱导、行动和预测”的方法来回答反事实查询,并处理两个关键挑战:(1)状态隐藏,(2)模型动态。认识到潜在的因果机制缺乏知识和无限的此类机制的可能性,我们在这一空间上优化并计算反事实数量的上限和下限。我们的工作结合了因果关系、状态空间模型、仿真和优化的概念,并将其应用于乳腺癌个案研究。

**[Paper URL](https://proceedings.mlr.press/v202/haugh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/haugh23a/haugh23a.pdf)** 

# Sampling-based Nyström Approximation and Kernel Quadrature
**题目:** 基于样本的Nyström近似和核方程

**作者:** Satoshi Hayakawa, Harald Oberhauser, Terry Lyons

**Abstract:** We analyze the Nyström approximation of a positive definite kernel associated with a probability measure. We first prove an improved error bound for the conventional Nyström approximation with i.i.d. sampling and singular-value decomposition in the continuous regime; the proof techniques are borrowed from statistical learning theory. We further introduce a refined selection of subspaces in Nyström approximation with theoretical guarantees that is applicable to non-i.i.d. landmark points. Finally, we discuss their application to convex kernel quadrature and give novel theoretical guarantees as well as numerical observations.

**摘要:** 分析了与概率计量有关的正确定核的尼斯通近似,首先证明了常用尼斯通近似的i.i.d.采样和单值分解的改进误差;证明技术是从统计学学习理论中借用;进一步介绍了与非i.i.d.标志点适用的理论保证的尼斯通近似子空间的精细选择;最后讨论了它们对凸核方程的应用,并给出了新的理论保证和数值观察。

**[Paper URL](https://proceedings.mlr.press/v202/hayakawa23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hayakawa23a/hayakawa23a.pdf)** 

# Width and Depth Limits Commute in Residual Networks
**题目:** 在剩余网络上通勤的宽度和深度限制

**作者:** Soufiane Hayou, Greg Yang

**Abstract:** We show that taking the width and depth to infinity in a deep neural network with skip connections, when branches are scaled by $1/\sqrt{depth}$, result in the same covariance structure no matter how that limit is taken. This explains why the standard infinite-width-then-depth approach provides practical insights even for networks with depth of the same order as width. We also demonstrate that the pre-activations, in this case, have Gaussian distributions which has direct applications in Bayesian deep learning. We conduct extensive simulations that show an excellent match with our theoretical findings.

**摘要:** 我们证明,在跳跃连接的深度神经网络中,将宽度和深度带到无限度时,当分支以$1/\sqrt{depth}$尺度时,无论该限度如何都会产生相同的共变结构,这说明了标准无限宽度-然后深度方法甚至为与宽度相同的深度的网络提供了实用的洞察。我们还证明了预激活在这一情况下具有高斯分布,它在贝叶斯深层学习中具有直接应用。

**[Paper URL](https://proceedings.mlr.press/v202/hayou23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hayou23a/hayou23a.pdf)** 

# A Generalization of ViT/MLP-Mixer to Graphs
**题目:** ViT/MLP-Mixer对图形的一般化

**作者:** Xiaoxin He, Bryan Hooi, Thomas Laurent, Adam Perold, Yann Lecun, Xavier Bresson

**Abstract:** Graph Neural Networks (GNNs) have shown great potential in the field of graph representation learning. Standard GNNs define a local message-passing mechanism which propagates information over the whole graph domain by stacking multiple layers. This paradigm suffers from two major limitations, over-squashing and poor long-range dependencies, that can be solved using global attention but significantly increases the computational cost to quadratic complexity. In this work, we propose an alternative approach to overcome these structural limitations by leveraging the ViT/MLP-Mixer architectures introduced in computer vision. We introduce a new class of GNNs, called Graph ViT/MLP-Mixer, that holds three key properties. First, they capture long-range dependency and mitigate the issue of over-squashing as demonstrated on Long Range Graph Benchmark and TreeNeighbourMatch datasets. Second, they offer better speed and memory efficiency with a complexity linear to the number of nodes and edges, surpassing the related Graph Transformer and expressive GNN models. Third, they show high expressivity in terms of graph isomorphism as they can distinguish at least 3-WL non-isomorphic graphs. We test our architecture on 4 simulated datasets and 7 real-world benchmarks, and show highly competitive results on all of them. The source code is available for reproducibility at: https://github.com/XiaoxinHe/Graph-ViT-MLPMixer.

**摘要:** 图神经网络(GNNs)在图表示学习领域显示出巨大的潜力。标准GNNs定义了一个本地消息传递机制,通过堆叠多个层传播整个图域的信息。这一范式遭受了两个主要的限制,过度浪费和较差的长期依赖,可以用全球注意力解决,但大大增加了二次复杂度的计算成本。在这个工作中,我们提出了利用ViT/MLP-Mixer在计算机视觉中引入的架构来克服这些结构性限制的替代方法。我们引入了新的GNN类别,叫做Graph ViT/MLP-Mixer,它拥有三个关键属性。其次,它们提供更好的速度和存储效率,以复杂线性向节点和边缘的数目,超越相关图形变换器和表达式GNN模型。第三,它们在图形同构性方面表现出很高的表达性,因为它们可以区分至少3-WL非同构图形。我们测试我们的架构在4个模拟数据集和7个真实世界基准上,并且在所有这些上显示高竞争力的结果。

**[Paper URL](https://proceedings.mlr.press/v202/he23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/he23a/he23a.pdf)** 

# Domain Adaptation for Time Series Under Feature and Label Shifts
**题目:** 特徵及标签 Shifts下时间系列域调整

**作者:** Huan He, Owen Queen, Teddy Koker, Consuelo Cuevas, Theodoros Tsiligkaridis, Marinka Zitnik

**Abstract:** Unsupervised domain adaptation (UDA) enables the transfer of models trained on source domains to unlabeled target domains. However, transferring complex time series models presents challenges due to the dynamic temporal structure variations across domains. This leads to feature shifts in the time and frequency representations. Additionally, the label distributions of tasks in the source and target domains can differ significantly, posing difficulties in addressing label shifts and recognizing labels unique to the target domain. Effectively transferring complex time series models remains a formidable problem. We present RAINCOAT, the first model for both closed-set and universal domain adaptation on complex time series. RAINCOAT addresses feature and label shifts by considering both temporal and frequency features, aligning them across domains, and correcting for misalignments to facilitate the detection of private labels. Additionally, RAINCOAT improves transferability by identifying label shifts in target domains. Our experiments with 5 datasets and 13 state-of-the-art UDA methods demonstrate that RAINCOAT can improve transfer learning performance by up to 16.33% and can handle both closed-set and universal domain adaptation.

**摘要:** 无监督域适应(UDA)可将源域训练模型转移到未标记目标域。然而,复杂时间序列模型的转移是由于源域间动态时间结构的变化而引起的挑战。这导致在时间和频率表示中出现特征转变。此外,源域和目标域的任务的标签分布可能有很大差异,从而在处理标签转变和识别目标域特有标签方面造成困难。有效的复杂时间序列模型的转移仍然是一个艰巨的问题。我们提出了RAINCOAT,第一个基于复杂时间序列的闭合集和通用域适应模型。RAINCOAT通过考虑时间和频率特征,将它们整合在域间,并纠正误差以促进检测私人标签。此外,RAINCOAT通过识别目标域的标签变换来提高传输能力。我们对5个数据集和13个最先进的UDA方法的实验表明,RAINCOAT可以提高传输学习性能最大16.33%,并能够处理封闭集合和通用域的适应。

**[Paper URL](https://proceedings.mlr.press/v202/he23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/he23b/he23b.pdf)** 

# Contrastive Learning Meets Homophily: Two Birds with One Stone
**题目:** 反向学习与同性恋相遇:两只鸟与一块石头

**作者:** Dongxiao He, Jitao Zhao, Rui Guo, Zhiyong Feng, Di Jin, Yuxiao Huang, Zhen Wang, Weixiong Zhang

**Abstract:** Graph Contrastive Learning (GCL) has recently enjoyed great success as an efficient self-supervised representation learning approach. However, the existing methods have focused on designing of contrastive modes and used data augmentation with a rigid and inefficient one-to-one sampling strategy. We adopted node neighborhoods to extend positive samplings and made avoided resorting to data augmentation to create different views. We also considered the homophily problem in Graph Neural Networks (GNNs) between the inter-class node pairs. The key novelty of our method hinged upon analyzing this GNNs problem and integrating the GCL sampling strategy with homophily discrimination, where we solved these two significant problems using one approach. We introduced a new parameterized neighbor sampling component to replace the conventional sub-optimal samplings. By keeping and updating the neighbor sets, both the positive sampling of GCL and the message passing of GNNs can be optimized. Moreover, we theoretically proved that the new method provided a lower bound of mutual information for unsupervised semantic learning, and it can also keep the lower bound with downstream tasks. In essence, our method is a new self-supervised approach, which we refer to as group discrimination, and it can make the downstream fine-tuning efficient. Our extensive empirical results demonstrate that the new method can significantly outperform the existing GCL methods because the former can solve the homophily problem in a self-supervised way with the new group discrimination method used.

**摘要:**  Graph Contrastive Learning(GCL)最近作为一种有效的自我监督的表示学习方法取得了巨大的成功。然而,现有的方法已经集中于设计对比模式,并使用一种刚性和不效率的单对单采样策略来增加数据。我们采用节点邻域以扩展正采样,并避免使用数据增加来创建不同的视角。我们还考虑了 Graph Neural Networks(GNNs)中类别间节点对之间的同性恋问题。我们的方法的关键新颖之处在于分析GNNs的问题,并结合同性恋歧视的GCL采样策略,其中我们用一种方法解决了这两个重要问题。我们引入了新的参数化邻域采样组件以取代传统的次优采样。此外,我们从理论上证明,该新方法为无监督语义学习提供了较低的相互信息界限,并能够与下游任务保持较低的界限。本质上,我们的方法是一种新的自我监督方法,我们称之为群体歧视,可以使下游的微调效率提高。

**[Paper URL](https://proceedings.mlr.press/v202/he23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/he23c/he23c.pdf)** 

# Nearly Minimax Optimal Reinforcement Learning for Linear Markov Decision Processes
**题目:** 线性马可夫决策过程的近乎最小最优强化学习

**作者:** Jiafan He, Heyang Zhao, Dongruo Zhou, Quanquan Gu

**Abstract:** We study reinforcement learning (RL) with linear function approximation. For episodic time-inhomogeneous linear Markov decision processes (linear MDPs) whose transition probability can be parameterized as a linear function of a given feature mapping, we propose the first computationally efficient algorithm that achieves the nearly minimax optimal regret $\tilde O(d\sqrt{H^3K})$, where $d$ is the dimension of the feature mapping, $H$ is the planning horizon, and $K$ is the number of episodes. Our algorithm is based on a weighted linear regression scheme with a carefully designed weight, which depends on a new variance estimator that (1) directly estimates the variance of the optimal value function, (2) monotonically decreases with respect to the number of episodes to ensure a better estimation accuracy, and (3) uses a rare-switching policy to update the value function estimator to control the complexity of the estimated value function class. Our work provides a complete answer to optimal RL with linear MDPs, and the developed algorithm and theoretical tools may be of independent interest.

**摘要:** 我们研究了基于线性函数近似的增强学习(RL)。 对于周期性时间不均匀的线性马可夫决策过程(线性MDP),其过渡概率可以作为给定的特征映射的线性函数参数化,我们提出了实现几乎最小值的最优遗憾$\tilde O(d\sqrt{H^3K})$的第一个计算效率高的算法,其中$d$是特征映射的维度,$H$是规划地平线,$K$是事件的数量。通过线性MDP对最佳RL给出了完整的答案,开发的算法和理论工具可能具有独立的兴趣。

**[Paper URL](https://proceedings.mlr.press/v202/he23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/he23d/he23d.pdf)** 

# CRISP: Curriculum based Sequential neural decoders for Polar code family
**题目:** CRISP:基于课程的波尔代码家族的序列神经解码器

**作者:** S Ashwin Hebbar, Viraj Vivek Nadkarni, Ashok Vardhan Makkuva, Suma Bhat, Sewoong Oh, Pramod Viswanath

**Abstract:** Polar codes are widely used state-of-the-art codes for reliable communication that have recently been included in the $5^{\text{th}}$ generation wireless standards ($5$G). However, there still remains room for design of polar decoders that are both efficient and reliable in the short blocklength regime. Motivated by recent successes of data-driven channel decoders, we introduce a novel $\textbf{ C}$ur${\textbf{RI}}$culum based $\textbf{S}$equential neural decoder for $\textbf{P}$olar codes (CRISP). We design a principled curriculum, guided by information-theoretic insights, to train CRISP and show that it outperforms the successive-cancellation (SC) decoder and attains near-optimal reliability performance on the $\text{Polar}(32,16)$ and $\text{Polar}(64,22)$ codes. The choice of the proposed curriculum is critical in achieving the accuracy gains of CRISP, as we show by comparing against other curricula. More notably, CRISP can be readily extended to Polarization-Adjusted-Convolutional (PAC) codes, where existing SC decoders are significantly less reliable. To the best of our knowledge, CRISP constructs the first data-driven decoder for PAC codes and attains near-optimal performance on the $\text{PAC}(32,16)$ code.

**摘要:** 极性码是用于可靠通信的最先进的码,最近已列入 $5^{\text{th}}$生成无线标准($5$G)。然而,仍然有空间设计极性码器,它们在短块长度模式中具有效率和可靠性。基于数据驱动的通道解码器的近期成功,我们引入了一种新颖的 curriculum-based $\textbf{C}$ur${\textbf{RI}}$equential neural decoder for $\textbf{P}$olar codes (CRISP)。我们设计了一个基于信息理论洞察的原理课程,以训练 CRISP,并证明它超越了连续切除(SC)解码器,并在$\text{Polar}(32,16)$和$\text{Polar}(64,22)$代码上达到 near-optimal的可靠性性能。更值得注意的是,CRISP可以轻易地扩展到偏振-调整-演变(PAC)代码,那里现有的SC解码器非常不可靠。我们所知,CRISP构建了第一个基于数据的PAC代码解码器,并在$\text{PAC}(32,16)$代码上达到 near-optimal性能。

**[Paper URL](https://proceedings.mlr.press/v202/hebbar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hebbar23a/hebbar23a.pdf)** 

# Sketch-Flip-Merge: Mergeable Sketches for Private Distinct Counting
**题目:** Sketch-Flip-Merge:用于私人独立计数的合并图案

**作者:** Jonathan Hehir, Daniel Ting, Graham Cormode

**Abstract:** Data sketching is a critical tool for distinct counting, enabling multisets to be represented by compact summaries that admit fast cardinality estimates. Because sketches may be merged to summarize multiset unions, they are a basic building block in data warehouses. Although many practical sketches for cardinality estimation exist, none provide privacy when merging. We propose the first practical cardinality sketches that are simultaneously mergeable, differentially private (DP), and have low empirical errors. These introduce a novel randomized algorithm for performing logical operations on noisy bits, a tight privacy analysis, and provably optimal estimation. Our sketches dramatically outperform existing theoretical solutions in simulations and on real-world data.

**摘要:** 数据绘图是独立计数的一个关键工具,使多组可由包含快速的基数估计的紧凑总结来表示。因为绘图可以合并以总结多组结合,它们是数据仓库的基本建筑物。虽然有许多实用的基数估计绘图存在,但没有一个提供在合并时的隐私。我们提出了第一个可同时合并的实用基数绘图,具有微分私有(DP)和低经验误差。这些绘图介绍了一种新的随机算法,用于在噪声 bit 上进行逻辑操作,严格的隐私分析和可证明的最优估计。

**[Paper URL](https://proceedings.mlr.press/v202/hehir23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hehir23a/hehir23a.pdf)** 

# Functional Neural Networks: Shift invariant models for functional data with applications to EEG classification
**题目:** 功能神经网络:移动功能数据不变模型,应用于EG分类

**作者:** Florian Heinrichs, Mavin Heim, Corinna Weber

**Abstract:** It is desirable for statistical models to detect signals of interest independently of their position. If the data is generated by some smooth process, this additional structure should be taken into account. We introduce a new class of neural networks that are shift invariant and preserve smoothness of the data: functional neural networks (FNNs). For this, we use methods from functional data analysis (FDA) to extend multi-layer perceptrons and convolutional neural networks to functional data. We propose different model architectures, show that the models outperform a benchmark model from FDA in terms of accuracy and successfully use FNNs to classify electroencephalography (EEG) data.

**摘要:** 统计模型可以独立于其位置检测感兴趣的信号,如果数据由某种平滑过程生成,则该额外的结构应予以考虑。我们引入一种新的神经网络类别,它们是变异不变的,并保持数据的平滑性:功能神经网络(FNNs)。为此,我们使用功能数据分析(FDA)的方法来扩展多层感应器和卷曲神经网络到功能数据。我们提出了不同的模型架构,表明模型在准确性方面比FDA的基准模型高,并成功使用FNNs来分类电脑学(EEG)数据。

**[Paper URL](https://proceedings.mlr.press/v202/heinrichs23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/heinrichs23a/heinrichs23a.pdf)** 

# Distance Weighted Supervised Learning for Offline Interaction Data
**题目:** 远程权重监控在线互动数据学习

**作者:** Joey Hejna, Jensen Gao, Dorsa Sadigh

**Abstract:** Sequential decision making algorithms often struggle to leverage different sources of unstructured offline interaction data. Imitation learning (IL) methods based on supervised learning are robust, but require optimal demonstrations, which are hard to collect. Offline goal-conditioned reinforcement learning (RL) algorithms promise to learn from sub-optimal data, but face optimization challenges especially with high-dimensional data. To bridge the gap between IL and RL, we introduce Distance Weighted Supervised Learning or DWSL, a supervised method for learning goal-conditioned policies from offline data. DWSL models the entire distribution of time-steps between states in offline data with only supervised learning, and uses this distribution to approximate shortest path distances. To extract a policy, we weight actions by their reduction in distance estimates. Theoretically, DWSL converges to an optimal policy constrained to the data distribution, an attractive property for offline learning, without any bootstrapping. Across all datasets we test, DWSL empirically maintains behavior cloning as a lower bound while still exhibiting policy improvement. In high-dimensional image domains, DWSL surpasses the performance of both prior goal-conditioned IL and RL algorithms. Visualizations and code can be found at https://sites.google.com/view/dwsl/home.

**摘要:** 基于监控学习的仿真学习(IL)方法是坚固的,但需要最优的演示,很难收集。 Offline目标条件增强学习(RL)算法承诺从次优数据学习,但面对优化挑战,特别是与高维数据。为了弥补IL和RL之间的差距,我们引入 Distance Weighted Supervised Learning(英语:Distance Weighted Supervised Learning)或DWSL(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWSL)(英语:DWS在理论上,DWSL会趋向于一个优化政策,限制在数据分配上,是在线学习的一个引人注目的属性,而不需要任何启动。在测试的所有数据集中,DWSL以经验上保持行为克隆作为较低的界限,同时展示政策改善。

**[Paper URL](https://proceedings.mlr.press/v202/hejna23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hejna23a/hejna23a.pdf)** 

# Group Equivariant Fourier Neural Operators for Partial Differential Equations
**题目:** 部分微分方程群等价傅立叶神经运算器

**作者:** Jacob Helwig, Xuan Zhang, Cong Fu, Jerry Kurtin, Stephan Wojtowytsch, Shuiwang Ji

**Abstract:** We consider solving partial differential equations (PDEs) with Fourier neural operators (FNOs), which operate in the frequency domain. Since the laws of physics do not depend on the coordinate system used to describe them, it is desirable to encode such symmetries in the neural operator architecture for better performance and easier learning. While encoding symmetries in the physical domain using group theory has been studied extensively, how to capture symmetries in the frequency domain is under-explored. In this work, we extend group convolutions to the frequency domain and design Fourier layers that are equivariant to rotations, translations, and reflections by leveraging the equivariance property of the Fourier transform. The resulting $G$-FNO architecture generalizes well across input resolutions and performs well in settings with varying levels of symmetry. Our code is publicly available as part of the AIRS library (https://github.com/divelab/AIRS).

**摘要:** 我们考虑用傅立叶神经运算器(FNO)解决部分微分方程(PDEs),这些运算器在频率域内运行。由于物理学的法律不依赖于用来描述它们的坐标系统,因此最好在神经运算器架构中编码这些对称,以提高性能和更容易学习。在使用群理论编码物理域中的对称已经得到广泛研究,如何捕捉频率域中的对称仍未得到充分研究。

**[Paper URL](https://proceedings.mlr.press/v202/helwig23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/helwig23a/helwig23a.pdf)** 

# Training-Free Neural Active Learning with Initialization-Robustness Guarantees
**题目:** 无训练的神经活动学习与初始化-活力保证

**作者:** Apivich Hemachandra, Zhongxiang Dai, Jasraj Singh, See-Kiong Ng, Bryan Kian Hsiang Low

**Abstract:** Existing neural active learning algorithms have aimed to optimize the predictive performance of neural networks (NNs) by selecting data for labelling. However, other than a good predictive performance, being robust against random parameter initializations is also a crucial requirement in safety-critical applications. To this end, we introduce our expected variance with Gaussian processes (EV-GP) criterion for neural active learning, which is theoretically guaranteed to select data points which lead to trained NNs with both (a) good predictive performances and (b) initialization robustness. Importantly, our EV-GP criterion is training-free, i.e., it does not require any training of the NN during data selection, which makes it computationally efficient. We empirically demonstrate that our EV-GP criterion is highly correlated with both initialization robustness and generalization performance, and show that it consistently outperforms baseline methods in terms of both desiderata, especially in situations with limited initial data or large batch sizes.

**摘要:** 现有的神经主动学习算法旨在通过选择数据来优化神经网络(NN)的预测性能。然而,除了良好的预测性能外,对随机参数初始化具有鲁棒性也是安全关键应用中的一个关键要求。为此目的,我们引入了神经主动学习的高斯过程(EV-GP)标准,理论上保证可以选择训练的NN具有(a)良好预测性能和(b)初始化鲁棒性的数据点。我们以实例证明,我们的EV-GP标准与初始化鲁棒性和一般化性能有着高度的相关性,并证明它在两个愿望方面,特别是在有限的初始数据或大量批量大小的情况下,始终超过了基准方法。

**[Paper URL](https://proceedings.mlr.press/v202/hemachandra23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hemachandra23a/hemachandra23a.pdf)** 

# A Study of Global and Episodic Bonuses for Exploration in Contextual MDPs
**题目:** 基于背景的MDP研究全球和 episodic奖金

**作者:** Mikael Henaff, Minqi Jiang, Roberta Raileanu

**Abstract:** Exploration in environments which differ across episodes has received increasing attention in recent years. Current methods use some combination of global novelty bonuses, computed using the agent’s entire training experience, and episodic novelty bonuses, computed using only experience from the current episode. However, the use of these two types of bonuses has been ad-hoc and poorly understood. In this work, we shed light on the behavior of these two types of bonuses through controlled experiments on easily interpretable tasks as well as challenging pixel-based settings. We find that the two types of bonuses succeed in different settings, with episodic bonuses being most effective when there is little shared structure across episodes and global bonuses being effective when more structure is shared. We develop a conceptual framework which makes this notion of shared structure precise by considering the variance of the value function across contexts, and which provides a unifying explanation of our empirical results. We furthermore find that combining the two bonuses can lead to more robust performance across different degrees of shared structure, and investigate different algorithmic choices for defining and combining global and episodic bonuses based on function approximation. This results in an algorithm which sets a new state of the art across 16 tasks from the MiniHack suite used in prior work, and also performs robustly on Habitat and Montezuma’s Revenge.

**摘要:** 当前的方法使用一些全球新颖奖金的组合,用代理人的整个训练经验计算,以及周期性新颖奖金,仅使用当前事件的经验计算。然而,这两个类型的奖金的使用是临时性的,而且被理解得很差。在这个工作中,我们通过对易于解释的任务的控制实验,以及 challenging pixel-based settings,揭示了这两个类型的奖金的行为。我们发现,这两个类型的奖金在不同的设置中成功,在周期性奖金最有效,当在各个事件中共享的结构较少时,以及全球奖金最有效,当更多的结构被共享时。我们开发了一个概念框架,通过考虑价值函数在上下文中的变化,使共享结构的概念更加精确,并为我们的经验结果提供统一的解释。 此外,我们发现,将这两个奖金结合起来,可以在不同程度的共享结构中产生更强的性能,并研究了基于函数近似的定义和结合全球和 episodic奖金的不同算法选择。

**[Paper URL](https://proceedings.mlr.press/v202/henaff23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/henaff23a/henaff23a.pdf)** 

# Robust Camera Pose Refinement for Multi-Resolution Hash Encoding
**题目:** 多分辨率哈希编码的鲁棒摄像机姿态精细

**作者:** Hwan Heo, Taekyung Kim, Jiyoung Lee, Jaewon Lee, Soohyun Kim, Hyunwoo J. Kim, Jin-Hwa Kim

**Abstract:** Multi-resolution hash encoding has recently been proposed to reduce the computational cost of neural renderings, such as NeRF. This method requires accurate camera poses for the neural renderings of given scenes. However, contrary to previous methods jointly optimizing camera poses and 3D scenes, the naive gradient-based camera pose refinement method using multi-resolution hash encoding severely deteriorates performance. We propose a joint optimization algorithm to calibrate the camera pose and learn a geometric representation using efficient multi-resolution hash encoding. Showing that the oscillating gradient flows of hash encoding interfere with the registration of camera poses, our method addresses the issue by utilizing smooth interpolation weighting to stabilize the gradient oscillation for the ray samplings across hash grids. Moreover, the curriculum training procedure helps to learn the level-wise hash encoding, further increasing the pose refinement. Experiments on the novel-view synthesis datasets validate that our learning frameworks achieve state-of-the-art performance and rapid convergence of neural rendering.

**摘要:** 多分辨率海丝编码最近被提议,以降低神经渲染的计算成本,例如NeRF。该方法要求对特定场景的神经渲染进行精确的摄像头姿态。然而,与以往联合优化摄像头姿态和3D场景的方法相反,使用多分辨率海丝编码的原始梯度based摄像头姿态精细方法严重降低了性能。我们提议采用联合优化算法校正摄像头姿态并学习高效多分辨率海丝编码的几何表示。基于新视合成数据集的实验验证了我们的学习框架能够实现最先进的性能和快速的神经渲染。

**[Paper URL](https://proceedings.mlr.press/v202/heo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/heo23a/heo23a.pdf)** 

# Generalized Teacher Forcing for Learning Chaotic Dynamics
**题目:** 强迫教师学习混沌动力学

**作者:** Florian Hess, Zahra Monfared, Manuel Brenner, Daniel Durstewitz

**Abstract:** Chaotic dynamical systems (DS) are ubiquitous in nature and society. Often we are interested in reconstructing such systems from observed time series for prediction or mechanistic insight, where by reconstruction we mean learning geometrical and invariant temporal properties of the system in question (like attractors). However, training reconstruction algorithms like recurrent neural networks (RNNs) on such systems by gradient-descent based techniques faces severe challenges. This is mainly due to exploding gradients caused by the exponential divergence of trajectories in chaotic systems. Moreover, for (scientific) interpretability we wish to have as low dimensional reconstructions as possible, preferably in a model which is mathematically tractable. Here we report that a surprisingly simple modification of teacher forcing leads to provably strictly all-time bounded gradients in training on chaotic systems, and, when paired with a simple architectural rearrangement of a tractable RNN design, piecewise-linear RNNs (PLRNNs), allows for faithful reconstruction in spaces of at most the dimensionality of the observed system. We show on several DS that with these amendments we can reconstruct DS better than current SOTA algorithms, in much lower dimensions. Performance differences were particularly compelling on real world data with which most other methods severely struggled. This work thus led to a simple yet powerful DS reconstruction algorithm which is highly interpretable at the same time.

**摘要:** 混沌动力学系统(DS)在自然界和社会中普遍存在。我们经常对从观察时间序列进行预测或机械洞察的这种系统进行重构感兴趣,而重构是指学习有关系统的几何和不变时间特性(如引力器)。然而,通过梯度下降技术在这些系统上训练重构算法,如循环神经网络(RNNs),面临严峻的挑战。这主要是由于混沌系统轨迹的指数偏差引起的爆炸梯度。我们报告指出,教师强迫的 surprisingly simple modification leads to provably strictly all-time bounded gradients in training on chaotic systems, and, when paired with a simple architectural rearrangement of a tractable RNN design, piecewise-linear RNNs (PLRNNs), allows for faithful reconstruction in spaces of at most the dimensionality of the observed system. 我们在一些DS上展示了,通过这些修正,我们可以比当前的SOTA算法更有效地重建DS,在更低的维度中。

**[Paper URL](https://proceedings.mlr.press/v202/hess23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hess23a/hess23a.pdf)** 

# Causal Modeling of Policy Interventions From Treatment-Outcome Sequences
**题目:** 治疗结果序列政策干预的因果建模

**作者:** Çağlar Hızlı, S. T. John, Anne Tuulikki Juuti, Tuure Tapani Saarinen, Kirsi Hannele Pietiläinen, Pekka Marttinen

**Abstract:** A treatment policy defines when and what treatments are applied to affect some outcome of interest. Data-driven decision-making requires the ability to predict what happens if a policy is changed. Existing methods that predict how the outcome evolves under different scenarios assume that the tentative sequences of future treatments are fixed in advance, while in practice the treatments are determined stochastically by a policy and may depend, for example, on the efficiency of previous treatments. Therefore, the current methods are not applicable if the treatment policy is unknown or a counterfactual analysis is needed. To handle these limitations, we model the treatments and outcomes jointly in continuous time, by combining Gaussian processes and point processes. Our model enables the estimation of a treatment policy from observational sequences of treatments and outcomes, and it can predict the interventional and counterfactual progression of the outcome after an intervention on the treatment policy (in contrast with the causal effect of a single treatment). We show with real-world and semi-synthetic data on blood glucose progression that our method can answer causal queries more accurately than existing alternatives.

**摘要:** 治疗策略定义了治疗方法在何时及何时应用,以影响某些利益结果。基于数据的决策要求能够预测政策更改时发生什么情况。现有的预测结果在不同的场景下如何演变的方法假设未来治疗的暂行序列是事先确定的,而实践中,治疗方法是由政策定量决定的,可能取决于,例如,以前的治疗方法的效率。因此,如果治疗政策未知或需要反事实分析,当前的方法不适用。该模型可从观察治疗和结果的序列进行治疗政策的估计,并可预测治疗政策介入后结果的介入和反事实进展(与单一治疗的因果效应相反)。我们通过实物和半合成的血液葡萄糖进化数据表明,该方法比现有的替代方法更准确地回答因果问题。

**[Paper URL](https://proceedings.mlr.press/v202/hizli23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hizli23a/hizli23a.pdf)** 

# Monotonicity and Double Descent in Uncertainty Estimation with Gaussian Processes
**题目:** 高斯过程的不确定性估计中的单元性和双发

**作者:** Liam Hodgkinson, Chris Van Der Heide, Fred Roosta, Michael W. Mahoney

**Abstract:** Despite their importance for assessing reliability of predictions, uncertainty quantification (UQ) measures in machine learning models have only recently begun to be rigorously characterized. One prominent issue is the curse of dimensionality: it is commonly believed that the marginal likelihood should be reminiscent of cross-validation metrics and both should deteriorate with larger input dimensions. However, we prove that by tuning hyperparameters to maximize marginal likelihood (the empirical Bayes procedure), performance, as measured by the marginal likelihood, improves monotonically with the input dimension. On the other hand, cross-validation metrics exhibit qualitatively different behavior that is characteristic of double descent. Cold posteriors, which have recently attracted interest due to their improved performance in certain settings, appear to exacerbate these phenomena. We verify empirically that our results hold for real data, beyond our considered assumptions, and we explore consequences involving synthetic covariates.

**摘要:** 尽管它们对评估预测的可靠性具有重要意义,但机器学习模型中的不确定性定量化(UQ)措施只是最近开始进行严格的定量化。一个突出的问题是维度的诅咒:人们普遍认为边缘概率应该与交叉验证度类似,并且两者都应该随着较大的输入维度而恶化。然而,我们证明通过调制超参数以最大化边缘概率(经验贝伊斯程序)来衡量性能,以边缘概率为指标,与输入维度进行单调改进。我们通过实验验证了我们的结果符合实际数据,超出了我们考虑的假设,并探讨了涉及合成系数的后果。

**[Paper URL](https://proceedings.mlr.press/v202/hodgkinson23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hodgkinson23a/hodgkinson23a.pdf)** 

# AdaBoost is not an Optimal Weak to Strong Learner
**题目:** AdaBoost不是最佳弱者强者

**作者:** Mikael Møller Høgsgaard, Kasper Green Larsen, Martin Ritzert

**Abstract:** AdaBoost is a classic boosting algorithm for combining multiple inaccurate classifiers produced by a weak learner, to produce a strong learner with arbitrarily high accuracy when given enough training data. Determining the optimal number of samples necessary to obtain a given accuracy of the strong learner, is a basic learning theoretic question. Larsen and Ritzert (NeurIPS’22) recently presented the first provably optimal weak-to-strong learner. However, their algorithm is somewhat complicated and it remains an intriguing question whether the prototypical boosting algorithm AdaBoost also makes optimal use of training samples. In this work, we answer this question in the negative. Concretely, we show that the sample complexity of AdaBoost, and other classic variations thereof, are sub-optimal by at least one logarithmic factor in the desired accuracy of the strong learner.

**摘要:** AdaBoost是一个经典的增强算法,用于结合一个弱 learner产生的多个不准确分类器,在给足够的训练数据时产生一个具有任意高精度的强 learner。确定获得强 learner的特定精度所需的最优样本数是一个基本的学习理论问题。 Larsen和Ritzert(NeurIPS’22)最近提出了第一个可证明的最优弱到强 learner。

**[Paper URL](https://proceedings.mlr.press/v202/hogsgaard23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hogsgaard23a/hogsgaard23a.pdf)** 

# Dual Propagation: Accelerating Contrastive Hebbian Learning with Dyadic Neurons
**题目:** 双向扩散:加速反向 Hebbian学习

**作者:** Rasmus Høier, D. Staudt, Christopher Zach

**Abstract:** Activity difference based learning algorithms—such as contrastive Hebbian learning and equilibrium propagation—have been proposed as biologically plausible alternatives to error back-propagation. However, on traditional digital chips these algorithms suffer from having to solve a costly inference problem twice, making these approaches more than two orders of magnitude slower than back-propagation. In the analog realm equilibrium propagation may be promising for fast and energy efficient learning, but states still need to be inferred and stored twice. Inspired by lifted neural networks and compartmental neuron models we propose a simple energy based compartmental neuron model, termed dual propagation, in which each neuron is a dyad with two intrinsic states. At inference time these intrinsic states encode the error/activity duality through their difference and their mean respectively. The advantage of this method is that only a single inference phase is needed and that inference can be solved in layerwise closed-form. Experimentally we show on common computer vision datasets, including Imagenet32x32, that dual propagation performs equivalently to back-propagation both in terms of accuracy and runtime.

**摘要:** 基于活动差异的学习算法,例如对比性黑比亚学习和平衡传播,已经被提出为错误后传的生物学可行的替代方案。然而,传统的数字芯片上,这些算法不得不解决一个昂贵的推理问题两次,使得这些方法比后传慢两阶以上。在模拟领域,平衡传播对于快速、高效的学习很有希望,但状态仍需要推导和存储两次。该方法的优点是,仅需要一个推理阶段,并且可以以层级封闭形式求解推理。实验表明,在包括Imagenet32x32在内的一般的计算机视觉数据集中,双向传播在精度和运行时间上与后向传播相等。

**[Paper URL](https://proceedings.mlr.press/v202/hoier23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hoier23a/hoier23a.pdf)** 

# Multi-Task Off-Policy Learning from Bandit Feedback
**题目:** 多任务非警察从盗贼反馈中学习

**作者:** Joey Hong, Branislav Kveton, Manzil Zaheer, Sumeet Katariya, Mohammad Ghavamzadeh

**Abstract:** Many practical problems involve solving similar tasks. In recommender systems, the tasks can be users with similar preferences; in search engines, the tasks can be items with similar affinities. To learn statistically efficiently, the tasks can be organized in a hierarchy, where the task affinity is captured using an unknown latent parameter. We study the problem of off-policy learning for similar tasks from logged bandit feedback. To solve the problem, we propose a hierarchical off-policy optimization algorithm HierOPO. The key idea is to estimate the task parameters using the hierarchy and then act pessimistically with respect to them. To analyze the algorithm, we develop novel Bayesian error bounds. Our bounds are the first in off-policy learning that improve with a more informative prior and capture statistical gains due to hierarchical models. Therefore, they are of a general interest. HierOPO also performs well in practice. Our experiments demonstrate the benefits of using the hierarchy over solving each task independently.

**摘要:** 在推荐系统中,任务可以是具有相似偏好的用户;在搜索引擎中,任务可以是具有相似关联的物品。为了有效地学习统计,任务可以组织在层次结构中,其中任务关联通过未知的潜在参数被捕获。我们研究了从登录带子反馈中获取类似任务的非政策学习问题。为了解决这个问题,我们提出了一种层次结构的非政策优化算法 HierOPO。关键思想是利用层次结构估计任务参数,然后对它们采取悲观的行动。我们的实验证明了使用层次结构在独立解决每个任务上的优势。

**[Paper URL](https://proceedings.mlr.press/v202/hong23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hong23a/hong23a.pdf)** 

# Constrained Optimization via Exact Augmented Lagrangian and Randomized Iterative Sketching
**题目:** 通过精确增强拉grangian和随机迭代绘图的约束优化

**作者:** Ilgee Hong, Sen Na, Michael W. Mahoney, Mladen Kolar

**Abstract:** We consider solving equality-constrained nonlinear, nonconvex optimization problems. This class of problems appears widely in a variety of applications in machine learning and engineering, ranging from constrained deep neural networks, to optimal control, to PDE-constrained optimization. We develop an adaptive inexact Newton method for this problem class. In each iteration, we solve the Lagrangian Newton system inexactly via a randomized iterative sketching solver, and select a suitable stepsize by performing line search on an exact augmented Lagrangian merit function. The randomized solvers have advantages over deterministic linear system solvers by significantly reducing per-iteration flops complexity and storage cost, when equipped with suitable sketching matrices. Our method adaptively controls the accuracy of the randomized solver and the penalty parameters of the exact augmented Lagrangian, to ensure that the inexact Newton direction is a descent direction of the exact augmented Lagrangian. This allows us to establish a global almost sure convergence. We also show that a unit stepsize is admissible locally, so that our method exhibits a local linear convergence. Furthermore, we prove that the linear convergence can be strengthened to superlinear convergence if we gradually sharpen the adaptive accuracy condition on the randomized solver. We demonstrate the superior performance of our method on benchmark nonlinear problems in CUTEst test set, constrained logistic regression with data from LIBSVM, and a PDE-constrained problem.

**摘要:** 我们考虑解决平等约束的非线性、非凸优化问题。该类问题广泛应用于机器学习和工程中,从约束的深神经网络到优化控制,到PDE约束的优化。我们开发了一个适应性不准确的牛顿方法来解决该类问题。在每次迭代中,我们通过一个随机迭代草图求解器不准确地解决拉格兰吉安牛顿系统,并通过执行一个精确增强拉格兰吉安功绩函数的行搜索选择一个适当的步骤大小。该方法以适应性控制随机求解器的精度和精确增量拉格兰吉安的惩罚参数,以确保不准确的牛顿方向是精确增量拉格兰吉安的下降方向。这使得我们能够建立一个几乎确定的全球收敛。我们还表明,单元级数是可接受的局部收敛,因此我们的方法显示出局部线性收敛。此外,我们证明,如果我们逐步提高随机求解器的适应性精度条件,线性收敛可以增强到超线性收敛。

**[Paper URL](https://proceedings.mlr.press/v202/hong23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hong23b/hong23b.pdf)** 

# Revisiting Data-Free Knowledge Distillation with Poisoned Teachers
**题目:** 与毒师回顾数据自由知识精馏

**作者:** Junyuan Hong, Yi Zeng, Shuyang Yu, Lingjuan Lyu, Ruoxi Jia, Jiayu Zhou

**Abstract:** Data-free knowledge distillation (KD) helps transfer knowledge from a pre-trained model (known as the teacher model) to a smaller model (known as the student model) without access to the original training data used for training the teacher model. However, the security of the synthetic or out-of-distribution (OOD) data required in data-free KD is largely unknown and under-explored. In this work, we make the first effort to uncover the security risk of data-free KD w.r.t. untrusted pre-trained models. We then propose Anti-Backdoor Data-Free KD (ABD), the first plug-in defensive method for data-free KD methods to mitigate the chance of potential backdoors being transferred. We empirically evaluate the effectiveness of our proposed ABD in diminishing transferred backdoor knowledge while maintaining compatible downstream performances as the vanilla KD. We envision this work as a milestone for alarming and mitigating the potential backdoors in data-free KD. Codes are released at https://github.com/illidanlab/ABD .

**摘要:** 数据自由知识蒸馏(KD)帮助从预备训练模型(称为教师模型)转移知识到较小的模型(称为学生模型)而不访问用于训练教师模型的原始训练数据。然而,数据自由KD所需的合成或非分布(OOD)数据的安全性在很大程度上是未知和未研究的。在这个工作中,我们首先努力揭示数据自由KD的安全性风险,即不信任预备训练模型。代码可以在 https://github.com/illidanlab/ABD 上发布。

**[Paper URL](https://proceedings.mlr.press/v202/hong23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hong23c/hong23c.pdf)** 

# simple diffusion: End-to-end diffusion for high resolution images
**题目:** 简单扩散:用于高分辨率图像的端到端扩散

**作者:** Emiel Hoogeboom, Jonathan Heek, Tim Salimans

**Abstract:** Currently, applying diffusion models in pixel space of high resolution images is difficult. Instead, existing approaches focus on diffusion in lower dimensional spaces (latent diffusion), or have multiple super-resolution levels of generation referred to as cascades. The downside is that these approaches add additional complexity to the diffusion framework. This paper aims to improve denoising diffusion for high resolution images while keeping the model as simple as possible. The paper is centered around the research question: How can one train a standard denoising diffusion models on high resolution images, and still obtain performance comparable to these alternate approaches? The four main findings are: 1) the noise schedule should be adjusted for high resolution images, 2) It is sufficient to scale only a particular part of the architecture, 3) dropout should be added at specific locations in the architecture, and 4) downsampling is an effective strategy to avoid high resolution feature maps. Combining these simple yet effective techniques, we achieve state-of-the-art on image generation among diffusion models without sampling modifiers on ImageNet.

**摘要:** 当前,在高分辨率图像的像素空间中应用扩散模型是困难的,而现有的方法则集中于低维空间(潜在扩散)的扩散,或具有多个超分辨率生成水平,称为 cascades,其弊端在于这些方法对扩散框架增加了额外的复杂性。本文以研究问题为中心:如何在高分辨率图像上训练标准的噪声扩散模型,并取得与这些替代方法相比的性能?四个主要发现是:(一)应调整高分辨率图像的噪声时间表,(二)仅限于建筑的特定部分,(三)应在建筑的特定地点添加排队,(四)低采样是避免高分辨率特征地图的有效策略。

**[Paper URL](https://proceedings.mlr.press/v202/hoogeboom23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hoogeboom23a/hoogeboom23a.pdf)** 

# Causal Strategic Classification: A Tale of Two Shifts
**题目:** 动机战略分类:两个转变的故事

**作者:** Guy Horowitz, Nir Rosenfeld

**Abstract:** When users can benefit from certain predictive outcomes, they may be prone to act to achieve those outcome, e.g., by strategically modifying their features. The goal in strategic classification is therefore to train predictive models that are robust to such behavior. However, the conventional framework assumes that changing features does not change actual outcomes, which depicts users as "gaming" the system. Here we remove this assumption, and study learning in a causal strategic setting where true outcomes do change. Focusing on accuracy as our primary objective, we show how strategic behavior and causal effects underlie two complementing forms of distribution shift. We characterize these shifts, and propose a learning algorithm that balances between these two forces and over time, and permits end-to-end training. Experiments on synthetic and semi-synthetic data demonstrate the utility of our approach.

**摘要:** 当用户能够从某些预测结果中获益时,他们可能倾向于采取行动实现这些结果,例如通过战略修改其特征。因此,战略分类的目标是训练对这种行为的强有力的预测模型。然而,传统的框架假设改变特征不会改变实际结果,这表明用户是“游戏”系统。在这里,我们删除了这个假设,并研究在因果战略环境中学习,真正的结果会发生变化。

**[Paper URL](https://proceedings.mlr.press/v202/horowitz23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/horowitz23a/horowitz23a.pdf)** 

# Fair and Accurate Decision Making through Group-Aware Learning
**题目:** 通过有小组意识的学习来作出公平和准确的决策

**作者:** Ramtin Hosseini, Li Zhang, Bhanu Garg, Pengtao Xie

**Abstract:** The integration of machine learning models in various real-world applications is becoming more prevalent to assist humans in their daily decision-making tasks as a result of recent advancements in this field. However, it has been discovered that there is a tradeoff between the accuracy and fairness of these decision-making tasks. In some cases, these AI systems can be unfair by exhibiting bias or discrimination against certain social groups, which can have severe consequences in real life. Inspired by one of the most well-known human learning skills called grouping, we address this issue by proposing a novel machine learning (ML) framework where the ML model learns to group a diverse set of problems into distinct subgroups to solve each subgroup using its specific sub-model. Our proposed framework involves three stages of learning, which are formulated as a three-level optimization problem: 1) grouping problems into subgroups, 2) learning group-specific sub-models for problem-solving, and 3) updating group assignments of training examples by minimizing validation loss. These three learning stages are performed end-to-end in a joint manner using gradient descent. To improve fairness and accuracy, we develop an efficient optimization algorithm to solve this three-level optimization problem. To further decrease the risk of overfitting in small datasets using our LBG method, we incorporate domain adaptation techniques in the second stage of training. We further apply our method to differentiable neural architecture search (NAS) methods.

**摘要:** 由于这一领域最近的进步,机器学习模型在各种现实应用中的应用越来越普遍,以协助人类在日常决策任务中作出决策。然而,人们发现,这些决策任务的准确性和公平性之间存在着交换关系。在某些情况下,这些人工智能系统可能通过对某些社会群体的偏见或歧视而不公平,从而在现实生活中产生严重后果。我们提出的框架包括三个学习阶段,这些阶段是作为三个层次优化问题拟定的:(一)将问题分组为分组,(二)学习问题解决的特定小组模型,以及(三)通过最小化验证损失更新训练实例的小组分配。这些三个学习阶段是通过梯度下降共同完成的,为了提高公平性和准确性,我们开发了一个有效的优化算法来解决这个三个层次优化问题。

**[Paper URL](https://proceedings.mlr.press/v202/hosseini23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hosseini23a/hosseini23a.pdf)** 

# Approximation Algorithms for Fair Range Clustering
**题目:** 公平范围集群的近似算法

**作者:** Sedjro Salomon Hotegni, Sepideh Mahabadi, Ali Vakilian

**Abstract:** This paper studies the fair range clustering problem in which the data points are from different demographic groups and the goal is to pick $k$ centers with the minimum clustering cost such that each group is at least minimally represented in the centers set and no group dominates the centers set. More precisely, given a set of $n$ points in a metric space $(P, d)$ where each point belongs to one of the $\ell$ different demographics (i.e., $P = P_1 \uplus P_2 \uplus \cdots \uplus P_\ell$) and a set of $\ell$ intervals $[\alpha_1, \beta_1], \cdots, [\alpha_\ell, \beta_\ell]$ on desired number of centers from each group, the goal is to pick a set of $k$ centers $C$ with minimum $\ell_p$-clustering cost (i.e., $(\sum_{v\in P} d(v,C)^p)^{1/p}$) such that for each group $i\in \ell$, $|C\cap P_i| \in [\alpha_i, \beta_i]$. In particular, the fair range $\ell_p$-clustering captures fair range $k$-center, $k$-median and $k$-means as its special cases. In this work, we provide an efficient constant factor approximation algorithm for the fair range $\ell_p$-clustering for all values of $p\in [1,\infty)$.

**摘要:** 本文研究了数据点来自不同人口组的公平范围聚类问题,目标是选取$k$中心的最小聚类成本,使得每个组至少在中心集合中得到最小表示,并且没有一个组占中心集合的主导地位。更确切地说,在 metric空间$(P, d)$中,给定一个$n$点的集合,其中每个点属于$k$不同人口组之一(即$P = P_1 \uplus P_2 \uplus \cdots \uplus P_\ell$)和一个$k$间隔的集合$[\alpha_1, \beta_1], \cdots, [\alpha_\ell, \beta_\ell]$,在每个组中所需的中心数量上,目标是选取一个$k$中心的集合$C$,在此工作中,我们为所有$p\in [1,\infty)$值的公平范围$\ell_p$-clustering提供了有效的常数因子近似算法。

**[Paper URL](https://proceedings.mlr.press/v202/hotegni23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hotegni23a/hotegni23a.pdf)** 

# Decoding Layer Saliency in Language Transformers
**题目:** 语言变换器中的层宽度解码

**作者:** Elizabeth Mary Hou, Gregory David Castanon

**Abstract:** In this paper, we introduce a strategy for identifying textual saliency in large-scale language models applied to classification tasks. In visual networks where saliency is more well-studied, saliency is naturally localized through the convolutional layers of the network; however, the same is not true in modern transformer-stack networks used to process natural language. We adapt gradient-based saliency methods for these networks, propose a method for evaluating the degree of semantic coherence of each layer, and demonstrate consistent improvement over numerous other methods for textual saliency on multiple benchmark classification datasets. Our approach requires no additional training or access to labelled data, and is comparatively very computationally efficient.

**摘要:** 本文介绍了一种用于分类任务的大规模语言模型中的文本关联识别策略。在较深入研究的视觉网络中,关联是通过网络的卷积层自然地定位的;然而,现代变换堆网络中用于处理自然语言的关联并不如此。我们对这些网络的梯度关联方法进行了调整,提出了评价每个层语义关联度的方法,并证明了在多个基准分类数据集上对文本关联的许多其他方法的一致改进。

**[Paper URL](https://proceedings.mlr.press/v202/hou23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hou23a/hou23a.pdf)** 

# PromptBoosting: Black-Box Text Classification with Ten Forward Passes
**题目:** PromptBoosting:十进制的黑箱文本分类

**作者:** Bairu Hou, Joe O’Connor, Jacob Andreas, Shiyu Chang, Yang Zhang

**Abstract:** We describe PromptBoosting, a query-efficient procedure for building a text classifier from a neural language model (LM) without access to the LM’s parameters, gradients, or hidden representations. This form of "black-box" classifier training has become increasingly important as the cost of training and inference in large-scale LMs has grown. But existing black-box LM classifier learning approaches are themselves computationally inefficient, typically specializing LMs to the target task by searching in a large space of (discrete or continuous) prompts using zeroth-order optimization methods. Instead of directly optimizing in prompt space, PromptBoosting obtains a small pool of prompts via a gradient-free approach and then constructs a large pool of weak learners by pairing these prompts with different elements of the LM’s output distribution. These weak learners are then ensembled using the AdaBoost algorithm. The entire learning process requires only a small number of forward passes and no backward pass. Experiments show that PromptBoosting achieves state-of-the-art performance in multiple black-box few-shot classification tasks, and matches or outperforms full fine-tuning in both few-shot and standard learning paradigms, while training 10x faster than existing black-box methods.

**摘要:** 我们描述了基于神经语言模型(LM)建立文本分类器的查询效率的程序PromptBoosting,该程序不需要访问LM的参数、梯度或隐藏表示。由于在大型LM中训练和推导成本的增加,这种“黑箱”分类器训练的形式变得越来越重要。但现有的黑箱LM分类器学习方法本身是计算效率低的,通常通过搜索(散布或连续)提示以零阶优化方法将LM专门用于目标任务。实验表明,PromptBoosting在多个黑箱数 shot分类任务中实现了最先进的性能,同时在数 shot和标准学习范式中完全匹配或优于现有的黑箱方法,同时训练的速度比现有的黑箱方法快10倍。

**[Paper URL](https://proceedings.mlr.press/v202/hou23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hou23b/hou23b.pdf)** 

# Sparse Learning of Dynamical Systems in RKHS: An Operator-Theoretic Approach
**题目:** RKHS动态系统 Sparse Learning: An Operator-Theoretic Approach

**作者:** Boya Hou, Sina Sanjari, Nathan Dahlin, Subhonmesh Bose, Umesh Vaidya

**Abstract:** Transfer operators provide a rich framework for representing the dynamics of very general, nonlinear dynamical systems. When interacting with reproducing kernel Hilbert spaces (RKHS), descriptions of dynamics often incur prohibitive data storage requirements, motivating dataset sparsification as a precursory step to computation. Further, in practice, data is available in the form of trajectories, introducing correlation between samples. In this work, we present a method for sparse learning of transfer operators from $\beta$-mixing stochastic processes, in both discrete and continuous time, and provide sample complexity analysis extending existing theoretical guarantees for learning from non-sparse, i.i.d. data. In addressing continuous-time settings, we develop precise descriptions using covariance-type operators for the infinitesimal generator that aids in the sample complexity analysis. We empirically illustrate the efficacy of our sparse embedding approach through deterministic and stochastic nonlinear system examples.

**摘要:** 传输运算器提供了一种非常通用的非线性动态系统动态的丰富框架。当与复制内核希尔伯特空间(RKHS)相互作用时,动态的描述往往会引起禁止的数据存储要求,促使数据集散化成为计算的先驱步骤。此外,在实践中,数据可用轨迹形式,引入样品之间的相关性。通过确定性和随机性非线性系统实例,实例说明了稀疏嵌入方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/hou23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hou23c/hou23c.pdf)** 

# Probably Anytime-Safe Stochastic Combinatorial Semi-Bandits
**题目:** 可能随时安全的随机组合半带

**作者:** Yunlong Hou, Vincent Y. F. Tan, Zixin Zhong

**Abstract:** Motivated by concerns about making online decisions that incur undue amount of risk at each time step, in this paper, we formulate the probably anytime-safe stochastic combinatorial semi-bandits problem. In this problem, the agent is given the option to select a subset of size at most $K$ from a set of $L$ ground items. Each item is associated to a certain mean reward as well as a variance that represents its risk. To mitigate the risk that the agent incurs, we require that with probability at least $1-\delta$, over the entire horizon of time $T$, each of the choices that the agent makes should contain items whose sum of variances does not exceed a certain variance budget. We call this probably anytime-safe constraint. Under this constraint, we design and analyze an algorithm PASCombUCB that minimizes the regret over the horizon of time $T$. By developing accompanying information-theoretic lower bounds, we show that under both the problem-dependent and problem-independent paradigms, PASCombUCB is almost asymptotically optimal. Experiments are conducted to corroborate our theoretical findings. Our problem setup, the proposed PASCombUCB algorithm, and novel analyses are applicable to domains such as recommendation systems and transportation in which an agent is allowed to choose multiple items at a single time step and wishes to control the risk over the whole time horizon.

**摘要:** 基于对在线决策产生不合理的风险的关注,本文提出了一种可能任何时候安全的随机组合半带子问题。在该问题中,代理人可从$L$地面项目中选择最大$K$的大小子集。每个项目都与某种平均奖赏以及代表其风险的变量关联。为了减轻代理人所承受的风险,我们要求在整个时间 $T$ 的范围内,每个代理人所作的选择都应该包含变量不超过一定变量预算的物品。我们称之为可能任何时候安全的约束。通过对相关信息理论下限的开发,我们证明,在问题依赖和问题独立的范式下,PASCombUCB几乎是渐近的最优。我们进行了实验,证实了我们的理论发现。我们的问题设置、所提议的PASCombUCB算法和新的分析适用于推荐系统和运输等领域,其中一个代理人可以在单一步骤选择多个项目并希望在整个时间范围内控制风险。

**[Paper URL](https://proceedings.mlr.press/v202/hou23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hou23d/hou23d.pdf)** 

# Automatic Data Augmentation via Invariance-Constrained Learning
**题目:** 基于变量约束学习的自动数据增强

**作者:** Ignacio Hounie, Luiz F. O. Chamon, Alejandro Ribeiro

**Abstract:** Underlying data structures, such as symmetries or invariance to transformations, are often exploited to improve the solution of learning tasks. However, embedding these properties in models or learning algorithms can be challenging and computationally intensive. Data augmentation, on the other hand, induces these symmetries during training by applying multiple transformations to the input data. Despite its ubiquity, its effectiveness depends on the choices of which transformations to apply, when to do so, and how often. In fact, there is both empirical and theoretical evidence that the indiscriminate use of data augmentation can introduce biases that outweigh its benefits. This work tackles these issues by automatically adapting the data augmentation while solving the learning task. To do so, it formulates data augmentation as an invariance constrained learning problem and leverages Monte Carlo Markov Chain (MCMC) sampling to solve it. The result is an algorithm that not only does away with a priori searches for augmentation distributions, but also dynamically controls if and when data augmentation is applied. We validate empirically our theoretical developments in automatic data augmentation benchmarks for CIFAR and ImageNet-100 datasets. Furthermore, our experiments show how this approach can be used to gather insights on the actual symmetries underlying a learning task.

**摘要:** 基础数据结构,如对变换的对称或不变性,经常被利用以改善学习任务的解决。然而,将这些属性嵌入模型或学习算法可能具有挑战性和计算强度。数据增强,另一方面,通过对输入数据应用多种变换来诱导这些对称。尽管其普遍性,其有效性取决于应用哪些变换的选择,什么时候这样做,以及多长时间。事实上,有经验和理论证据表明,数据增强不偏不倚的使用可以引入比重其利益的偏见。结果为一种算法,它不仅消除了对增量分布的优先搜索,而且动态控制了数据增量是否和什么时候被应用。我们通过实证验证了我们对CIFAR和ImageNet-100数据集的自动数据增量基准的理论发展。

**[Paper URL](https://proceedings.mlr.press/v202/hounie23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hounie23a/hounie23a.pdf)** 

# Thompson Sampling with Diffusion Generative Prior
**题目:** 汤普森样本与扩散生成前者

**作者:** Yu-Guan Hsieh, Shiva Kasiviswanathan, Branislav Kveton, Patrick Blöbaum

**Abstract:** In this work, we initiate the idea of using denoising diffusion models to learn priors for online decision making problems. We specifically focus on bandit meta-learning, aiming to learn a policy that performs well across bandit tasks of a same class. To this end, we train a diffusion model that learns the underlying task distribution and combine Thompson sampling with the learned prior to deal with new tasks at test time. Our posterior sampling algorithm carefully balances between the learned prior and the noisy observations that come from the learner’s interaction with the environment. To capture realistic bandit scenarios, we propose a novel diffusion model training procedure that trains from incomplete and noisy data, which could be of independent interest. Finally, our extensive experiments clearly demonstrate the potential of the proposed approach.

**摘要:** 在这一工作中,我们提出了利用分离模型来学习在线决策问题。我们特别着重于分离元学习,目的在于学习一个能够跨同类分离任务的策略。为此目的,我们训练了一种分离模型,它学习了基本任务分配,并结合汤普森的抽样与学习者进行测试时处理新的任务。我们的后采样算法仔细平衡了学习者与环境的交互作用带来的噪声观察。

**[Paper URL](https://proceedings.mlr.press/v202/hsieh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hsieh23a/hsieh23a.pdf)** 

# Tighter Analysis for ProxSkip
**题目:** ProxSkip更严格的分析

**作者:** Zhengmian Hu, Heng Huang

**Abstract:** In this paper, we provide a tighter analysis for ProxSkip, an algorithm that allows fewer proximal operator computations to solve composite optimization problems. We improve the existing decreasing speed of Lyapunov function from $\mathcal{O}(p^2)$ to $\mathcal{O}(p)$, when $p$, the frequency of the proximal operators is small enough. Our theoretical analysis also reveals the drawbacks of using large step sizes for gradient descent in ProxSkip when the proximal operator part is the bottleneck. Our main motivation comes from the continuous limit in which the original analysis of ProxSkip fails to guarantee convergence when both the step size $\gamma$ and frequency $p$ tend to zero. We construct a counterexample to demonstrate why such counterintuitive behavior occurs for the original analysis and then propose a novel Lyapunov function variant to construct a tighter analysis, avoiding the problem of the old one. Such a new Lyapunov function can be directly extended to many other variants of ProxSkip. When applied to stochastic gradient setup, our analysis leads to an improved proximal operator complexity for SProxSkip from $\mathcal{O}(\sqrt{\frac{1}{\varepsilon\mu^2}}\log(\frac{1}{\varepsilon}))$ to $\mathcal{O}(\sqrt{\kappa}\log(\frac{1}{\varepsilon}))$.

**摘要:** 本文为ProxSkip提供了较紧的分析方法,该算法允许较少的近接算子计算来解决复合优化问题。我们改进了从$\mathcal{O}(p^2)$到$\mathcal{O}(p)$的拉普诺夫函数的现有减速速度,当p$近接算子的频率足够小时。我们的理论分析还揭示了当近接算子部分是瓶颈时,在ProxSkip中使用大阶梯大小来梯度下降的缺点。当应用于随机梯度设置时,我们的分析导致SProxSkip的近接操作复杂性从$\mathcal{O}(\sqrt{\frac{1}{\varepsilon\mu^2}}\log(\frac{1}{\varepsilon}))$到$\mathcal{O}(\sqrt{\kappa}\log(\frac{1}{\varepsilon}))$。

**[Paper URL](https://proceedings.mlr.press/v202/hu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hu23a/hu23a.pdf)** 

# Omnipredictors for Constrained Optimization
**题目:** 约束优化的万能预测器

**作者:** Lunjia Hu, Inbal Rachel Livni Navon, Omer Reingold, Chutong Yang

**Abstract:** The notion of omnipredictors (Gopalan, Kalai, Reingold, Sharan and Wieder ITCS 2022), suggested a new paradigm for loss minimization. Rather than learning a predictor based on a known loss function, omnipredictors can easily be post-processed to minimize any one of a rich family of loss functions compared with the loss of hypotheses in a class $\mathcal C$. It has been shown that such omnipredictors exist and are implied (for all convex and Lipschitz loss functions) by the notion of multicalibration from the algorithmic fairness literature. In this paper, we introduce omnipredictors for constrained optimization and study their complexity and implications. The notion that we introduce allows the learner to be unaware of the loss function that will be later assigned as well as the constraints that will be later imposed, as long as the subpopulations that are used to define these constraints are known. We show how to obtain omnipredictors for constrained optimization problems, relying on appropriate variants of multicalibration. We also investigate the implications of this notion when the constraints used are so-called group fairness notions.

**摘要:** 全预知器的概念(Gopalan, Kalai, Reingold, Sharan and Wieder ITCS 2022),提出了一种新的损失最小化范式。在学习基于已知的损失函数的预知器时,全预知器很容易被后处理,以减少与类$\mathcal C$中假设的损失相比的财富函数家族中的任何一个。已经证明,这种全预知器存在,并由算法公平性文献中的多校正概念所暗示(对于所有凸和利普希茨损失函数)。研究了基于多校正的适当变量,如何获得约束优化问题的万能预测器,并探讨了当使用约束是所谓的群公平概念时,这一概念的影响。

**[Paper URL](https://proceedings.mlr.press/v202/hu23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hu23b/hu23b.pdf)** 

# GFlowNet-EM for Learning Compositional Latent Variable Models
**题目:** GFlowNet-EM用于学习组合性潜在变量模型

**作者:** Edward J Hu, Nikolay Malkin, Moksh Jain, Katie E Everett, Alexandros Graikos, Yoshua Bengio

**Abstract:** Latent variable models (LVMs) with discrete compositional latents are an important but challenging setting due to a combinatorially large number of possible configurations of the latents. A key tradeoff in modeling the posteriors over latents is between expressivity and tractable optimization. For algorithms based on expectation-maximization (EM), the E-step is often intractable without restrictive approximations to the posterior. We propose the use of GFlowNets, algorithms for sampling from an unnormalized density by learning a stochastic policy for sequential construction of samples, for this intractable E-step. By training GFlowNets to sample from the posterior over latents, we take advantage of their strengths as amortized variational inference algorithms for complex distributions over discrete structures. Our approach, GFlowNet-EM, enables the training of expressive LVMs with discrete compositional latents, as shown by experiments on non-context-free grammar induction and on images using discrete variational autoencoders (VAEs) without conditional independence enforced in the encoder.

**摘要:** 随机变量模型(LVMs)是随机变量与离散组合性变量之间的一个重要,但具有挑战性的设置,因为随机变量具有大量可能的配置。在模型化随机变量上随机变量之间的关键交换是表达性和可调性优化。对于基于预期-最大化(EM)的算法,随机变量与随机变量之间,随机变量通常是无法求解的。我们建议使用GFlowNets,即通过学习随机变量对随机变量进行序列构造的随机策略来从非正常密度采样的算法,用于这种无法求解的随机变量步骤。我们的方法,GFlowNet-EM,可以训练具有离散的成分缓存的表达式VM,如在非文体自由语法诱导实验和使用离散变量自动编码器(VAEs)的图像中所显示的,无条件的独立性在编码器中强制执行。

**[Paper URL](https://proceedings.mlr.press/v202/hu23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hu23c/hu23c.pdf)** 

# Blockwise Stochastic Variance-Reduced Methods with Parallel Speedup for Multi-Block Bilevel Optimization
**题目:** 多块双层优化的单块随机变量减速方法

**作者:** Quanqi Hu, Zi-Hao Qiu, Zhishuai Guo, Lijun Zhang, Tianbao Yang

**Abstract:** In this paper, we consider non-convex multi-block bilevel optimization (MBBO) problems, which involve $m\gg 1$ lower level problems and have important applications in machine learning. Designing a stochastic gradient and controlling its variance is more intricate due to the hierarchical sampling of blocks and data and the unique challenge of estimating hyper-gradient. We aim to achieve three nice properties for our algorithm: (a) matching the state-of-the-art complexity of standard BO problems with a single block; (b) achieving parallel speedup by sampling $I$ blocks and sampling $B$ samples for each sampled block per-iteration; (c) avoiding the computation of the inverse of a high-dimensional Hessian matrix estimator. However, it is non-trivial to achieve all of these by observing that existing works only achieve one or two of these properties. To address the involved challenges for achieving (a, b, c), we propose two stochastic algorithms by using advanced blockwise variance-reduction techniques for tracking the Hessian matrices (for low-dimensional problems) or the Hessian-vector products (for high-dimensional problems), and prove an iteration complexity of $O(\frac{m\epsilon^{-3}\mathbb{I}(I \textless m)}{I\sqrt{I}}+\frac{m\epsilon^{-3}}{I\sqrt{B}})$ for finding an $\epsilon$-stationary point under appropriate conditions. We also conduct experiments to verify the effectiveness of the proposed algorithms comparing with existing MBBO algorithms.

**摘要:** 本文讨论了非凸多块双层优化问题,涉及$m\gg1$低层问题,并具有重要的机理学习应用。设计随机梯度和控制其变异是由于分层抽样和数据以及估计超梯度的独特挑战而更加复杂。我们的目标是为我们的算法实现三个漂亮的特性: (a)与单块匹配标准BO问题的最先进的复杂性; (b)通过每迭代抽样$I$块和抽样$B$样品实现平行加速; (c)避免对高维希斯基矩阵估计器的反演计算。为了解决实现(a,b,c)所涉及的挑战,我们提出了两个随机算法,用先进的分块向变量减小技术追踪黑森矩阵(低维问题)或黑森向量产物(高维问题),并证明$O(\frac{m\epsilon^{-3}\mathbb{I}(I \textless m)}{I\sqrt{I}}+\frac{m\epsilon^{-3}}{I\sqrt{B}})$的迭代复杂性,在适当条件下找到$\epsilon$-静态点。

**[Paper URL](https://proceedings.mlr.press/v202/hu23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hu23d/hu23d.pdf)** 

# Language Instructed Reinforcement Learning for Human-AI Coordination
**题目:** 语言指导强化学习为人-人工智能协调

**作者:** Hengyuan Hu, Dorsa Sadigh

**Abstract:** One of the fundamental quests of AI is to produce agents that coordinate well with humans. This problem is challenging, especially in domains that lack high quality human behavioral data, because multi-agent reinforcement learning (RL) often converges to different equilibria from the ones that humans prefer. We propose a novel framework, instructRL, that enables humans to specify what kind of strategies they expect from their AI partners through natural language instructions. We use pretrained large language models to generate a prior policy conditioned on the human instruction and use the prior to regularize the RL objective. This leads to the RL agent converging to equilibria that are aligned with human preferences. We show that instructRL converges to human-like policies that satisfy the given instructions in a proof-of-concept environment as well as the challenging Hanabi benchmark. Finally, we show that knowing the language instruction significantly boosts human-AI coordination performance in human evaluations in Hanabi.

**摘要:** 人工知能的基本任务之一是产生与人类协调的代理人。这一问题是挑战性的,特别是在缺乏高质量的人类行为数据的领域,因为多代理增强学习(RL)往往会与人类偏好的不同平衡。我们提出了一种新框架,instructRL,它使人类能够指定他们期望从他们的人工知能伙伴通过自然语言指令来采取什么样的策略。我们使用保留大的语言模型来生成基于人类指令的预先政策,并使用预先来规范RL目标。最后,我们证明,掌握语言教学在汉纳比人的评价中大大提高了人-人工智能协调性能。

**[Paper URL](https://proceedings.mlr.press/v202/hu23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hu23e/hu23e.pdf)** 

# Surface Snapping Optimization Layer for Single Image Object Shape Reconstruction
**题目:** 单一图像对象形状重建的表面剪贴优化层

**作者:** Yuan-Ting Hu, Alex Schwing, Raymond A. Yeh

**Abstract:** Reconstructing the 3D shape of objects observed in a single image is a challenging task. Recent approaches rely on visual cues extracted from a given image learned from a deep net. In this work, we leverage recent advances in monocular scene understanding to incorporate an additional geometric cue of surface normals. For this, we proposed a novel optimization layer that encourages the face normals of the reconstructed shape to be aligned with estimated surface normals. We develop a computationally efficient conjugate-gradient-based method that avoids the computation of a high-dimensional sparse matrix. We show this framework to achieve compelling shape reconstruction results on the challenging Pix3D and ShapeNet datasets.

**摘要:** 对单一图像中观察到的物体的3D形状进行再构造是一项艰巨的任务。最近的方法依赖于从深网中学习的特定图像中提取的视觉提示。在这项工作中,我们利用单眼场景理解的最新进展,结合了表面正常物体的额外几何提示。为此,我们提出了一种新的优化层,鼓励重建形状的面部正常物体与估计表面正常物体相匹配。我们开发了一个计算效率高、基于共轭梯度的方法,避免计算高维稀疏矩阵。

**[Paper URL](https://proceedings.mlr.press/v202/hu23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hu23f/hu23f.pdf)** 

# Learning to Learn from APIs: Black-Box Data-Free Meta-Learning
**题目:** 学习从API中学习:Black-Box数据自由的元学习

**作者:** Zixuan Hu, Li Shen, Zhenyi Wang, Baoyuan Wu, Chun Yuan, Dacheng Tao

**Abstract:** Data-free meta-learning (DFML) aims to enable efficient learning of new tasks by meta-learning from a collection of pre-trained models without access to the training data. Existing DFML work can only meta-learn from (i) white-box and (ii) small-scale pre-trained models (iii) with the same architecture, neglecting the more practical setting where the users only have inference access to the APIs with arbitrary model architectures and model scale inside. To solve this issue, we propose a Bi-level Data-free Meta Knowledge Distillation (BiDf-MKD) framework to transfer more general meta knowledge from a collection of black-box APIs to one single meta model. Specifically, by just querying APIs, we inverse each API to recover its training data via a zero-order gradient estimator and then perform meta-learning via a novel bi-level meta knowledge distillation structure, in which we design a boundary query set recovery technique to recover a more informative query set near the decision boundary. In addition, to encourage better generalization within the setting of limited API budgets, we propose task memory replay to diversify the underlying task distribution by covering more interpolated tasks. Extensive experiments in various real-world scenarios show the superior performance of our BiDf-MKD framework.

**摘要:** 数据自由的元学习(DFML)旨在通过从预训练模型的集合中进行元学习,使新任务的有效学习,而不需要访问训练数据。现有DFML的工作只能从(i)白盒和(ii)小规模预训练模型(iii)中获得元学习,同时忽略了较实际的设置,用户只能通过任意模型架构和模型尺度 inference访问API。为了解决这个问题,我们提出了一种双级数据自由元知识蒸馏(BiDf-MKD)框架,将从一个黑盒API集合中转移到一个单元元模型的一般元知识。此外,为了鼓励在设定有限的API预算范围内更好的推广,我们提出了任务内存重演,通过覆盖更多插值任务来多样化任务分配。

**[Paper URL](https://proceedings.mlr.press/v202/hu23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hu23g/hu23g.pdf)** 

# For Pre-Trained Vision Models in Motor Control, Not All Policy Learning Methods are Created Equal
**题目:** 对于汽车控制中的预训练视觉模型,并非所有政策学习方法均为

**作者:** Yingdong Hu, Renhao Wang, Li Erran Li, Yang Gao

**Abstract:** In recent years, increasing attention has been directed to leveraging pre-trained vision models for motor control. While existing works mainly emphasize the importance of this pre-training phase, the arguably equally important role played by downstream policy learning during control-specific fine-tuning is often neglected. It thus remains unclear if pre-trained vision models are consistent in their effectiveness under different control policies. To bridge this gap in understanding, we conduct a comprehensive study on 14 pre-trained vision models using 3 distinct classes of policy learning methods, including reinforcement learning (RL), imitation learning through behavior cloning (BC), and imitation learning with a visual reward function (VRF). Our study yields a series of intriguing results, including the discovery that the effectiveness of pre-training is highly dependent on the choice of the downstream policy learning algorithm. We show that conventionally accepted evaluation based on RL methods is highly variable and therefore unreliable, and further advocate for using more robust methods like VRF and BC. To facilitate more universal evaluations of pre-trained models and their policy learning methods in the future, we also release a benchmark of 21 tasks across 3 different environments alongside our work.

**摘要:** 近年来,对运动控制的预训练视觉模型的利用日益受到关注。虽然现有的工作主要强调了预训练阶段的重要性,但控制特定微调过程中下游政策学习所发挥的同样重要作用却常常被忽视。因此,是否在不同控制政策下预训练视觉模型的有效性是一致的仍然不明。为了弥补这一差距,我们对14种预训练视觉模型进行了综合研究,使用3种不同的策略学习方法,包括强化学习(RL)、通过行为克隆学习(BC)和具有视觉奖励函数的模仿学习(VRF)。我们证明,传统的基于RL方法的评价是高度变异的,因此不可靠,并进一步提倡使用较强的方法,如VRF和BC。为了在将来更容易对预训练模型及其政策学习方法进行更普遍的评价,我们同时在三个不同环境中发布了21个任务的基准。

**[Paper URL](https://proceedings.mlr.press/v202/hu23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hu23h/hu23h.pdf)** 

# Beyond Lipschitz Smoothness: A Tighter Analysis for Nonconvex Optimization
**题目:** Beyond Lipschitz Smoothness:非凸优化的更强的分析

**作者:** Zhengmian Hu, Xidong Wu, Heng Huang

**Abstract:** Negative and positive curvatures affect optimization in different ways. However, a lot of existing optimization theories are based on the Lipschitz smoothness assumption, which cannot differentiate between the two. In this paper, we propose to use two separate assumptions for positive and negative curvatures, so that we can study the different implications of the two. We analyze the Lookahead and Local SGD methods as concrete examples. Both of them require multiple copies of model parameters and communication among them for every certain period of time in order to prevent divergence. We show that the minimum communication frequency is inversely proportional to the negative curvature, and when the negative curvature becomes zero, we recover the existing theory results for convex optimization. Finally, both experimentally and theoretically, we demonstrate that modern neural networks have highly unbalanced positive/negative curvatures. Thus, an analysis based on separate positive and negative curvatures is more pertinent.

**摘要:** 负曲线和负曲线在不同方面影响优化。然而,许多现有的优化理论都基于利普希茨平滑假设,不能区分两种曲线。本论文提议为负曲线和负曲线使用两种不同的假设,以便研究两种曲线的不同影响。我们将Locahead和LocalSGD方法作为具体例子分析。两者都要求模型参数的多个拷贝和在每个特定时间段间的通信,以防止误差。因此, 基于不同的正向和负向曲率的分析更为恰当.

**[Paper URL](https://proceedings.mlr.press/v202/hu23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hu23i/hu23i.pdf)** 

# Understanding the Impact of Adversarial Robustness on Accuracy Disparity
**题目:** 理解敌对鲁棒性对精度差异的影响

**作者:** Yuzheng Hu, Fan Wu, Hongyang Zhang, Han Zhao

**Abstract:** While it has long been empirically observed that adversarial robustness may be at odds with standard accuracy and may have further disparate impacts on different classes, it remains an open question to what extent such observations hold and how the class imbalance plays a role within. In this paper, we attempt to understand this question of accuracy disparity by taking a closer look at linear classifiers under a Gaussian mixture model. We decompose the impact of adversarial robustness into two parts: an inherent effect that will degrade the standard accuracy on all classes due to the robustness constraint, and the other caused by the class imbalance ratio, which will increase the accuracy disparity compared to standard training. Furthermore, we also show that such effects extend beyond the Gaussian mixture model, by generalizing our data model to the general family of stable distributions. More specifically, we demonstrate that while the constraint of adversarial robustness consistently degrades the standard accuracy in the balanced class setting, the class imbalance ratio plays a fundamentally different role in accuracy disparity compared to the Gaussian case, due to the heavy tail of the stable distribution. We additionally perform experiments on both synthetic and real-world datasets to corroborate our theoretical findings. Our empirical results also suggest that the implications may extend to nonlinear models over real-world datasets. Our code is publicly available on GitHub at https://github.com/Accuracy-Disparity/AT-on-AD.

**摘要:** 本文试图通过对高斯混合模型下的线性分类器进行更深入的分析来理解这种精度差异问题。我们将敌对鲁棒性的影响分解为两个部分:一种因鲁棒性约束而降低所有类的标准精度的固有效应,另一部分是由于类不平衡比率所引起的效应,这将提高与标准训练相比的精度差异。更具体地说,我们证明,虽然敌对鲁棒性约束在平衡类设置中的标准准确度不断降低,但类不平衡比在准确度差异方面与高斯案例相比具有根本不同的作用,因为稳定分布的重尾。此外,我们还对合成和实世界数据集进行了实验,以证实我们的理论发现。我们的实证结果也表明,这些影响可能扩展到实世界数据集的非线性模型。

**[Paper URL](https://proceedings.mlr.press/v202/hu23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hu23j/hu23j.pdf)** 

# Reinforcement Learning in Low-rank MDPs with Density Features
**题目:** 密度特征的低级MDP强化学习

**作者:** Audrey Huang, Jinglin Chen, Nan Jiang

**Abstract:** MDPs with low-rank transitions—that is, the transition matrix can be factored into the product of two matrices, left and right—is a highly representative structure that enables tractable learning. The left matrix enables expressive function approximation for value-based learning and has been studied extensively. In this work, we instead investigate sample-efficient learning with density features, i.e., the right matrix, which induce powerful models for state-occupancy distributions. This setting not only sheds light on leveraging unsupervised learning in RL, but also enables plug-in solutions for settings like convex RL. In the offline setting, we propose an algorithm for off-policy estimation of occupancies that can handle non-exploratory data. Using this as a subroutine, we further devise an online algorithm that constructs exploratory data distributions in a level-by-level manner. As a central technical challenge, the additive error of occupancy estimation is incompatible with the multiplicative definition of data coverage. In the absence of strong assumptions like reachability, this incompatibility easily leads to exponential error blow-up, which we overcome via novel technical tools. Our results also readily extend to the representation learning setting, when the density features are unknown and must be learned from an exponentially large candidate set.

**摘要:** 具有低级过渡的MDP — — 即过渡矩阵可以作为两个矩阵的产物,即左和右 — — 是一个高度代表性的结构,可以进行易于处理的学习。左矩阵为基于价值的学习提供表达函数近似,并被广泛研究。作为一个核心技术挑战,占用率估计的增量误差与数据覆盖的乘法定义是不兼容的。在缺乏像可达性这样的强假设的情况下,这种不兼容性很容易导致指数误差膨胀,我们通过新的技术工具克服了这一问题。

**[Paper URL](https://proceedings.mlr.press/v202/huang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23a/huang23a.pdf)** 

# Composer: Creative and Controllable Image Synthesis with Composable Conditions
**题目:** 编剧:具有可编写条件的创造性和可控制的图像合成

**作者:** Lianghua Huang, Di Chen, Yu Liu, Yujun Shen, Deli Zhao, Jingren Zhou

**Abstract:** Recent large-scale generative models learned on big data are capable of synthesizing incredible images yet suffer from limited controllability. This work offers a new generation paradigm that allows flexible control of the output image, such as spatial layout and palette, while maintaining the synthesis quality and model creativity. With compositionality as the core idea, we first decompose an image into representative factors, and then train a diffusion model with all these factors as the conditions to recompose the input. At the inference stage, the rich intermediate representations work as composable elements, leading to a huge design space (i.e., exponentially proportional to the number of decomposed factors) for customizable content creation. It is noteworthy that our approach, which we call Composer, supports various levels of conditions, such as text description as the global information, depth map and sketch as the local guidance, color histogram for low-level details, etc. Besides improving controllability, we confirm that Composer serves as a general framework and facilitates a wide range of classical generative tasks without retraining. Code and models will be made available.

**摘要:** 最近在大型数据上学习的大规模生成模型能够合成难以置信的图像,但受到有限的控制性。这项工作提供了一种新的代谢模式,允许输出图像的灵活控制,例如空间布局和 palette,同时保持合成质量和模型创造性。作为核心思想的组合性,我们首先将图像分解为代表因素,然后训练一个扩散模型以所有这些因素为条件重新组合输入。除了提高可控性外,我们确认Composer是通用框架,并且可以进行广泛的经典生成任务,无需重新训练。

**[Paper URL](https://proceedings.mlr.press/v202/huang23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23b/huang23b.pdf)** 

# Model-Aware Contrastive Learning: Towards Escaping the Dilemmas
**题目:** 认识模型的反向学习:如何逃避困境

**作者:** Zizheng Huang, Haoxing Chen, Ziqi Wen, Chao Zhang, Huaxiong Li, Bo Wang, Chunlin Chen

**Abstract:** Contrastive learning (CL) continuously achieves significant breakthroughs across multiple domains. However, the most common InfoNCE-based methods suffer from some dilemmas, such as uniformity-tolerance dilemma (UTD) and gradient reduction, both of which are related to a $\mathcal{P}_{ij}$ term. It has been identified that UTD can lead to unexpected performance degradation. We argue that the fixity of temperature is to blame for UTD. To tackle this challenge, we enrich the CL loss family by presenting a Model-Aware Contrastive Learning (MACL) strategy, whose temperature is adaptive to the magnitude of alignment that reflects the basic confidence of the instance discrimination task, then enables CL loss to adjust the penalty strength for hard negatives adaptively. Regarding another dilemma, the gradient reduction issue, we derive the limits of an involved gradient scaling factor, which allows us to explain from a unified perspective why some recent approaches are effective with fewer negative samples, and summarily present a gradient reweighting to escape this dilemma. Extensive remarkable empirical results in vision, sentence, and graph modality validate our approach’s general improvement for representation learning and downstream tasks.

**摘要:** 反向学习(CL)在多个领域中不断取得重大突破。然而,最常见的基于InfoNCE的方法遭受一些困境,如均匀性宽容困境(UTD)和梯度降低,两者都与$\mathcal{P}_{ij}$术语有关。UTD可能导致意外的性能下降。我们认为温度的固定性是UTD的罪魁祸首。关于另一个困境,梯度减小问题,我们推导了涉及梯度尺度因素的局限性,这让我们从统一的角度解释为什么一些最近的方法在较少的负样本下有效,并简要地提出梯度重估以逃避这一困境。

**[Paper URL](https://proceedings.mlr.press/v202/huang23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23c/huang23c.pdf)** 

# High-dimensional Clustering onto Hamiltonian Cycle
**题目:** 对汉密尔顿周期的高维集群

**作者:** Tianyi Huang, Shenghui Cheng, Stan Z. Li, Zhengjun Zhang

**Abstract:** Clustering aims to group unlabelled samples based on their similarities and is widespread in high-dimensional data analysis. However, most of the clustering methods merely generate pseudo labels and thus are unable to simultaneously present the similarities between different clusters and outliers. This paper proposes a new framework called High-dimensional Clustering onto Hamiltonian Cycle (HCHC) to solve the above problems. First, HCHC combines global structure with local structure in one objective function for deep clustering, improving the labels as relative probabilities, to mine the similarities between different clusters while keeping the local structure in each cluster. Then, the anchors of different clusters are sorted on the optimal Hamiltonian cycle generated by the cluster similarities and mapped on the circumference of a circle. Finally, a sample with a higher probability of a cluster will be mapped closer to the corresponding anchor. In this way, our framework allows us to appreciate three aspects visually and simultaneously - clusters (formed by samples with high probabilities), cluster similarities (represented as circular distances), and outliers (recognized as dots far away from all clusters). The theoretical analysis and experiments illustrate the superiority of HCHC.

**摘要:** 聚类的目的在于基于其相似性聚类无标记的样品,并广泛应用于高维数据分析中。然而,大多数聚类方法只是生成伪标记,因此无法同时显示不同聚类和异常之间的相似性。本文提出了一种新的框架,称为高维聚类(High-dimensional Clustering onto Hamiltonian Cycle,HCHCHC)来解决上述问题。这样,我们的框架可以同时 vizual 地评价三个方面:聚类(由高概率的样品组成),聚类相似性(以圆形距离表示)和异常(以远离所有聚类的点表示)。

**[Paper URL](https://proceedings.mlr.press/v202/huang23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23d/huang23d.pdf)** 

# Banker Online Mirror Descent: A Universal Approach for Delayed Online Bandit Learning
**题目:** 银行网上 Mirror Descent:延迟网上盗版学习的通用方法

**作者:** Jiatai Huang, Yan Dai, Longbo Huang

**Abstract:** We propose Banker Online Mirror Descent (Banker-OMD), a novel framework generalizing the classical Online Mirror Descent (OMD) technique in the online learning literature. The Banker-OMD framework almost completely decouples feedback delay handling and the task-specific OMD algorithm design, thus facilitating the design of new algorithms capable of efficiently and robustly handling feedback delays. Specifically, it offers a general methodology for achieving $\widetilde{\mathcal O}(\sqrt{T} + \sqrt{D})$-style regret bounds in online bandit learning tasks with delayed feedback, where $T$ is the number of rounds and $D$ is the total feedback delay. We demonstrate the power of Banker-OMD by applications to two important bandit learning scenarios with delayed feedback, including delayed scale-free adversarial Multi-Armed Bandits (MAB) and delayed adversarial linear bandits. Banker-OMD leads to the first delayed scale-free adversarial MAB algorithm achieving $\widetilde{\mathcal O}(\sqrt{K}L(\sqrt T+\sqrt D))$ regret and the first delayed adversarial linear bandit algorithm achieving $\widetilde{\mathcal O}(\text{poly}(n)(\sqrt{T} + \sqrt{D}))$ regret. As a corollary, the first application also implies $\widetilde{\mathcal O}(\sqrt{KT}L)$ regret for non-delayed scale-free adversarial MABs, which is the first to match the $\Omega(\sqrt{KT}L)$ lower bound up to logarithmic factors and can be of independent interest.

**摘要:** 我们提出了Banker Online Mirror Descent(Banker-OMD),一种新颖的框架,概述了在线学习文献中经典的 Online Mirror Descent(OMD)技术。Banker-OMD框架几乎完全分离了反馈延迟处理和任务特有OMD算法的设计,从而便利了处理反馈延迟的新型算法的设计。具体而言,它提供了实现$\widetilde{\mathcal O}(\sqrt{T} + \sqrt{D})$-style regret bounds的在线反叛学习任务时,带有延迟反馈,其中$T$是轮数和$D$是总反馈延迟。我们通过应用两个重要的反叛学习场景,包括带有延迟反馈的无尺度反叛多武装反叛(MAB)和带有延迟线性反叛反叛反叛反叛。Banker-OMD导致了第一个 belated scale-free adversarial MAB算法实现$widetilde{\mathcal O}(\sqrt{K}L(\sqrt T+\sqrt D))$遗憾和第一个 belated adversarial linear bandit algorithm实现$widetilde{\mathcal O}(\text{poly}(n)(\sqrt{T} + \sqrt{D}))$遗憾。

**[Paper URL](https://proceedings.mlr.press/v202/huang23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23e/huang23e.pdf)** 

# Fast Algorithms for Distributed k-Clustering with Outliers
**题目:** 分布式k-类别与异常的快速算法

**作者:** Junyu Huang, Qilong Feng, Ziyun Huang, Jinhui Xu, Jianxin Wang

**Abstract:** In this paper, we study the $k$-clustering problems with outliers in distributed setting. The current best results for the distributed $k$-center problem with outliers have quadratic local running time with communication cost dependent on the aspect ratio $\Delta$ of the given instance, which may constraint the scalability of the algorithms for handling large-scale datasets. To achieve better communication cost for the problem with faster local running time, we propose an inliers-recalling sampling method, which avoids guessing the optimal radius of the given instance, and can achieve a 4-round bi-criteria $(14(1+\epsilon),1+\epsilon)$-approximation with linear local running time in the data size and communication cost independent of the aspect ratio. To obtain a more practical algorithm for the problem, we propose another space-narrowing sampling method, which automatically adjusts the sample size to adapt to different outliers distributions on each machine, and can achieve a 2-round bi-criteria $(14(1+\epsilon),1+\epsilon)$-approximation with communication cost independent of the number of outliers. We show that, if the data points are randomly partitioned across machines, our proposed sampling-based methods can be extended to the $k$-median/means problems with outliers, and can achieve $(O(\frac{1}{\epsilon^2}),1+\epsilon)$-approximation with communication cost independent of the number of outliers. Empirical experiments suggest that the proposed 2-round distributed algorithms outperform other state-of-the-art algorithms.

**摘要:** 本文研究了分布式设置中与异常的$k$-clustering问题。分布式$k$-center问题目前的最佳结果是与与异常的二次局部运行时间有通信成本依赖于所给出的实例的视角比$\Delta$,这可能限制了处理大规模数据集的算法的可扩展性。为了实现与较快的局部运行时间问题更好的通信成本,我们提出了一种基于异常的采样方法,避免推测所给出的实例的最佳半径,并可实现四轮双标准$(14(1+\epsilon),1+\epsilon)$-近似与数据大小中的线性局部运行时间和通信成本依赖于视角比。为了获得更实用的算法,我们提出了另一个空间缩小采样方法,该方法自动调整样品大小以适应每个机器上的不同异常分布,并可实现2环双标准$(14(1+\epsilon),1+\epsilon)$-与异常数相近的通信成本 independent of the number of outliers。我们证明,如果数据点在机器间随机分割,我们提出的基于采样的方法可以扩展到与异常数相近的$k$-介质/平均问题,并可实现$(O(\frac{1}{\epsilon^2}),1+\epsilon)$-与异常数相近的通信成本 independent of the number of outliers。

**[Paper URL](https://proceedings.mlr.press/v202/huang23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23f/huang23f.pdf)** 

# Searching Large Neighborhoods for Integer Linear Programs with Contrastive Learning
**题目:** 基于对比学习的整数线性程序搜索大邻域

**作者:** Taoan Huang, Aaron M Ferber, Yuandong Tian, Bistra Dilkina, Benoit Steiner

**Abstract:** Integer Linear Programs (ILPs) are powerful tools for modeling and solving a large number of combinatorial optimization problems. Recently, it has been shown that Large Neighborhood Search (LNS), as a heuristic algorithm, can find high-quality solutions to ILPs faster than Branch and Bound. However, how to find the right heuristics to maximize the performance of LNS remains an open problem. In this paper, we propose a novel approach, CL-LNS, that delivers state-of-the-art anytime performance on several ILP benchmarks measured by metrics including the primal gap, the primal integral, survival rates and the best performing rate. Specifically, CL-LNS collects positive and negative solution samples from an expert heuristic that is slow to compute and learns a more efficient one with contrastive learning. We use graph attention networks and a richer set of features to further improve its performance.

**摘要:** 整数线性程序(ILPs)是建模和解决大量组合优化问题的有力工具,最近已经证明,大型邻域搜索(LNS)作为启发式算法,能够比分支和 Bound更快找到高质量的ILP解决方案。然而,如何找到正确的启发式来最大化LNS的性能仍然是一个开放的问题。

**[Paper URL](https://proceedings.mlr.press/v202/huang23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23g/huang23g.pdf)** 

# On Coresets for Clustering in Small Dimensional Euclidean spaces
**题目:** 在小维欧几何空间中的集群核心集

**作者:** Lingxiao Huang, Ruiyuan Huang, Zengfeng Huang, Xuan Wu

**Abstract:** We consider the problem of constructing small coresets for $k$-Median in Euclidean spaces. Given a large set of data points $P\subset \mathbb{R}^d$, a coreset is a much smaller set $S\subset \mathbb{R}^d$, so that the $k$-Median costs of any $k$ centers w.r.t. $P$ and $S$ are close. Existing literature mainly focuses on the high-dimension case and there has been great success in obtaining dimension-independent bounds, whereas the case for small $d$ is largely unexplored. Considering many applications of Euclidean clustering algorithms are in small dimensions and the lack of systematic studies in the current literature, this paper investigates coresets for $k$-Median in small dimensions. For small $d$, a natural question is whether existing near-optimal dimension-independent bounds can be significantly improved. We provide affirmative answers to this question for a range of parameters. Moreover, new lower bound results are also proved, which are the highest for small $d$. In particular, we completely settle the coreset size bound for $1$-d $k$-Median (up to log factors). Interestingly, our results imply a strong separation between $1$-d $1$-Median and $1$-d $2$-Median. As far as we know, this is the first such separation between $k=1$ and $k=2$ in any dimension.

**摘要:** 我们考虑了在欧几里空间中构造$k$-Median的小型核心集的问题。考虑到一个大的数据点集$P\subset \mathbb{R}^d$,一个核心集是一个较小的集$S\subset \mathbb{R}^d$,因此任何$k$中心的$k$-Median成本与$P$和$S$接近。现有文献主要集中于高维的案例,在获得独立维度边界方面取得了很大的成功,而对于小$d$的案例则基本上没有研究。考虑到欧几里类聚类算法的许多应用在小维度和当前文献中缺乏系统研究,本文研究了在小维度中$k$-Median的核心集。对于小$d$来说,一个自然的问题是现有的接近最佳独立维度边界是否能够得到显著的改善。我们为具体而言,我们完全解决了对1$-d $k$-Median的内核子大小的约束(直到日志因素)。有趣的是,我们的结果暗示了1$-d $1$-Median和1$-d $2$-Median之间的强烈分离。

**[Paper URL](https://proceedings.mlr.press/v202/huang23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23h/huang23h.pdf)** 

# Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models
**题目:** Make-An-Audio:基于快速增强扩散模型的文本到音频生成

**作者:** Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, Zhou Zhao

**Abstract:** Large-scale multimodal generative modeling has created milestones in text-to-image and text-to-video generation. Its application to audio still lags behind for two main reasons: the lack of large-scale datasets with high-quality text-audio pairs, and the complexity of modeling long continuous audio data. In this work, we propose Make-An-Audio with a prompt-enhanced diffusion model that addresses these gaps by 1) introducing pseudo prompt enhancement with a distill-then-reprogram approach, it alleviates data scarcity with orders of magnitude concept compositions by using language-free audios; 2) leveraging spectrogram autoencoder to predict the self-supervised audio representation instead of waveforms. Together with robust contrastive language-audio pretraining (CLAP) representations, Make-An-Audio achieves state-of-the-art results in both objective and subjective benchmark evaluation. Moreover, we present its controllability and generalization for X-to-Audio with "No Modality Left Behind", for the first time unlocking the ability to generate high-definition, high-fidelity audios given a user-defined modality input. Audio samples are available at https://Make-An-Audio.github.io

**摘要:** 大型多模生成模型在文本到图像和文本到视频生成中创造了里程碑。其在音频领域的应用仍然落后,原因主要有两个:缺乏具有高质量的文本-音频对的大规模数据集,以及模拟长连续的音频数据的复杂性。本研究中,我们提出了一种快速增强扩散模型来解决这些缺口:(一)采用蒸馏-然后再编程方法引入伪快速增强;(二)利用语言自由的音频来减少数据短缺;(三)利用光谱自动编码器预测自监督的音频表示,而不是波形;(四)与强有力的对比性语言-音频预训练(CLAP)表示相结合,使Make-An-Audio在客观和主观的基准评价中取得了最先进的成果。此外,我们首次展示了X-to-Audio的可控性和通用性,使用“No Modality Left Behind”实现生成高精确、高真实性音频的能力,提供用户定义的模态输入。

**[Paper URL](https://proceedings.mlr.press/v202/huang23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23i/huang23i.pdf)** 

# The Power of Uniform Sampling for k-Median
**题目:** k-Median的统一采样能力

**作者:** Lingxiao Huang, Shaofeng H.-C. Jiang, Jianing Lou

**Abstract:** We study the power of uniform sampling for $k$-Median in various metric spaces. We relate the query complexity for approximating $k$-Median, to a key parameter of the dataset, called the balancedness $\beta \in (0, 1]$ (with $1$ being perfectly balanced). We show that any algorithm must make $\Omega(1 / \beta)$ queries to the point set in order to achieve $O(1)$-approximation for $k$-Median. This particularly implies existing constructions of coresets, a popular data reduction technique, cannot be query-efficient. On the other hand, we show a simple uniform sample of $\mathrm{poly}(k \epsilon^{-1} \beta^{-1})$ points suffices for $(1 + \epsilon)$-approximation for $k$-Median for various metric spaces, which nearly matches the lower bound. We conduct experiments to verify that in many real datasets, the balancedness parameter is usually well bounded, and that the uniform sampling performs consistently well even for the case with moderately large balancedness, which justifies that uniform sampling is indeed a viable approach for solving $k$-Median.

**摘要:** 我们研究了不同度量空间中$k$-Median的均匀抽样能力。我们将近似$k$-Median的查询复杂性与数据集的一个关键参数,即平衡度$\beta \in (0, 1]$($1$完全平衡)联系起来。我们证明,任何算法都必须向点集合做$\Omega(1 / \beta)$查询,以达到$k$-Median的O(1)$-近似。这特别意味着现有的核子集构造,一种流行的数据减少技术,不能是查询效率的。我们进行了实验验证,在许多实数据集中,平衡参数通常是有限的,并且均匀抽样在中等程度大的平衡情况下也表现良好,这证明均匀抽样是解决$k$-Median问题的有效方法。

**[Paper URL](https://proceedings.mlr.press/v202/huang23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23j/huang23j.pdf)** 

# Reparameterized Policy Learning for Multimodal Trajectory Optimization
**题目:** 参数化策略学习,实现多模式预测优化

**作者:** Zhiao Huang, Litian Liang, Zhan Ling, Xuanlin Li, Chuang Gan, Hao Su

**Abstract:** We investigate the challenge of parametrizing policies for reinforcement learning (RL) in high-dimensional continuous action spaces. Our objective is to develop a multimodal policy that overcomes limitations inherent in the commonly-used Gaussian parameterization. To achieve this, we propose a principled framework that models the continuous RL policy as a generative model of optimal trajectories. By conditioning the policy on a latent variable, we derive a novel variational bound as the optimization objective, which promotes exploration of the environment. We then present a practical model-based RL method, called Reparameterized Policy Gradient (RPG), which leverages the multimodal policy parameterization and learned world model to achieve strong exploration capabilities and high data efficiency. Empirical results demonstrate that our method can help agents evade local optima in tasks with dense rewards and solve challenging sparse-reward environments by incorporating an object-centric intrinsic reward. Our method consistently outperforms previous approaches across a range of tasks. Code and supplementary materials are available on the project page https://haosulab.github.io/RPG/

**摘要:** 我们研究了高维连续行动空间中强化学习(RL)参数化政策的挑战。我们的目标是开发一种克服常用高斯参数化中的局限性的多模态政策。为此,我们提出了一种基于原则的框架,将持续RL政策建模为优化轨迹的生成模型。通过对潜在变量条件化政策,我们得出一种新的变量边界作为优化目标,从而促进环境的探索。实验结果表明,我们的方法能够帮助代理人在具有密集奖励的任务中避开局部优化,并通过整合对象中心的内在奖励来解决挑战的稀有奖励环境。我们的方法在一系列任务中始终超过了以往的方法。

**[Paper URL](https://proceedings.mlr.press/v202/huang23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23k/huang23k.pdf)** 

# Theoretical Bounds on the Network Community Profile from Low-rank Semi-definite Programming
**题目:** 低级半定义编程中网络社区 Profile的理论界限

**作者:** Yufan Huang, C. Seshadhri, David F. Gleich

**Abstract:** We study a new connection between a technical measure called $\mu$-conductance that arises in the study of Markov chains for sampling convex bodies and the network community profile that characterizes size-resolved properties of clusters and communities in social and information networks. The idea of $\mu$-conductance is similar to the traditional graph conductance, but disregards sets with small volume. We derive a sequence of optimization problems including a low-rank semi-definite program from which we can derive a lower bound on the optimal $\mu$-conductance value. These ideas give the first theoretically sound bound on the behavior of the network community profile for a wide range of cluster sizes. The algorithm scales up to graphs with hundreds of thousands of nodes and we demonstrate how our framework validates the predicted structures of real-world graphs.

**摘要:** 我们研究了一个叫做$\mu$-conductance的技术措施之间的新连接,它在研究凸体样本的马可夫链和在社交和信息网络中的群落和群落的大小解决特性的网络社区 профил中产生。$\mu$-conductance的概念与传统的图形导引类似,但不考虑小容量的设置。我们导出了一系列优化问题,包括一个低级半确定程序,从中我们可以导出最优$\mu$-conductance值上的较低的界限。

**[Paper URL](https://proceedings.mlr.press/v202/huang23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23l/huang23l.pdf)** 

# NeuralStagger: Accelerating Physics-constrained Neural PDE Solver with Spatial-temporal Decomposition
**题目:** NeuralStagger:加速物理约束的神经PDE求解器与空间-时空分解

**作者:** Xinquan Huang, Wenlei Shi, Qi Meng, Yue Wang, Xiaotian Gao, Jia Zhang, Tie-Yan Liu

**Abstract:** Neural networks have shown great potential in accelerating the solution of partial differential equations (PDEs). Recently, there has been a growing interest in introducing physics constraints into training neural PDE solvers to reduce the use of costly data and improve the generalization ability. However, these physics constraints, based on certain finite dimensional approximations over the function space, must resolve the smallest scaled physics to ensure the accuracy and stability of the simulation, resulting in high computational costs from large input, output, and neural networks. This paper proposes a general acceleration methodology called NeuralStagger by spatially and temporally decomposing the original learning tasks into several coarser-resolution subtasks. We define a coarse-resolution neural solver for each subtask, which requires fewer computational resources, and jointly train them with the vanilla physics-constrained loss by simply arranging their outputs to reconstruct the original solution. Due to the perfect parallelism between them, the solution is achieved as fast as a coarse-resolution neural solver. In addition, the trained solvers bring the flexibility of simulating with multiple levels of resolution. We demonstrate the successful application of NeuralStagger on 2D and 3D fluid dynamics simulations, which leads to an additional $10\sim100\times$ speed-up. Moreover, the experiment also shows that the learned model could be well used for optimal control.

**摘要:** 神经网络在加速 partial differential equations (PDEs) 的求解方面具有巨大的潜力。最近,人们对引入物理约束在训练神经元PDE求解者中,以减少使用昂贵的数据并提高广义化能力的兴趣越来越大。然而,这些物理约束,基于函数空间上的某些有限维近似,必须解决最小规模的物理约束,以确保模拟的准确性和稳定性,从而导致大输入、输出和神经网络的高计算成本。我们定义了每个次级任务的粗分辨率神经元求解器,需要较少的计算资源,并通过简单的配置输出来重新构造原来的求解器联合训练它们与瓦尼拉物理约束的损失。由于它们之间的完美平行性,求解器的实现速度与粗分辨率神经元求解器一样快。此外,训练的求解器带有多层次的求解的灵活性。

**[Paper URL](https://proceedings.mlr.press/v202/huang23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23m/huang23m.pdf)** 

# Policy Contrastive Imitation Learning
**题目:** 政策反差模仿学习

**作者:** Jialei Huang, Zhao-Heng Yin, Yingdong Hu, Yang Gao

**Abstract:** Adversarial imitation learning (AIL) is a popular method that has recently achieved much success. However, the performance of AIL is still unsatisfactory on the more challenging tasks. We find that one of the major reasons is due to the low quality of AIL discriminator representation. Since the AIL discriminator is trained via binary classification that does not necessarily discriminate the policy from the expert in a meaningful way, the resulting reward might not be meaningful either. We propose a new method called Policy Contrastive Imitation Learning (PCIL) to resolve this issue. PCIL learns a contrastive representation space by anchoring on different policies and uses a smooth cosine-similarity-based reward to encourage imitation learning. Our proposed representation learning objective can be viewed as a stronger version of the AIL objective and provide a more meaningful comparison between the agent and the policy. From a theoretical perspective, we show the validity of our method using the apprenticeship learning framework. Furthermore, our empirical evaluation on the DeepMind Control suite demonstrates that PCIL can achieve state-of-the-art performance. Finally, qualitative results suggest that PCIL builds a smoother and more meaningful representation space for imitation learning.

**摘要:** 敌对仿真学习(英语:Adversarial imitation learning,缩写:AIL)是一项最近取得巨大成功的方法。然而,AIL的性能仍不令人满意,在较复杂的任务中,我们发现其主要原因之一是其低质量的AIL区分器的表示。由于AIL区分器通过二进制分类进行训练,并不必然从专家中区分政策,结果的奖励也不一定有意义。为了解决这个问题,我们提出了一种名为 Policy Contrastive Imitation Learning(英语:Policy Contrastive Imitation Learning,缩写:PCIL)的新方法。从理论角度来看,我们证明了使用实习学习框架的方法的有效性。此外,我们对 DeepMind控制套件的实证评价表明,PCIL能够达到最先进的性能。最后,定性结果表明,PCIL可以建立更平滑、更有意义的模仿学习表现空间。

**[Paper URL](https://proceedings.mlr.press/v202/huang23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23n/huang23n.pdf)** 

# Are Large Kernels Better Teachers than Transformers for ConvNets?
**题目:** 大型核能比转换器更适合康文网的教师吗?

**作者:** Tianjin Huang, Lu Yin, Zhenyu Zhang, Li Shen, Meng Fang, Mykola Pechenizkiy, Zhangyang Wang, Shiwei Liu

**Abstract:** This paper reveals a new appeal of the recently emerged large-kernel Convolutional Neural Networks (ConvNets): as the teacher in Knowledge Distillation (KD) for small-kernel ConvNets. While Transformers have led state-of-the-art (SOTA) performance in various fields with ever-larger models and labeled data, small-kernel ConvNets are considered more suitable for resource-limited applications due to the efficient convolution operation and compact weight sharing. KD is widely used to boost the performance of small-kernel ConvNets. However, previous research shows that it is not quite effective to distill knowledge (e.g., global information) from Transformers to small-kernel ConvNets, presumably due to their disparate architectures. We hereby carry out a first-of-its-kind study unveiling that modern large-kernel ConvNets, a compelling competitor to Vision Transformers, are remarkably more effective teachers for small-kernel ConvNets, due to more similar architectures. Our findings are backed up by extensive experiments on both logit-level and feature-level KD "out of the box", with no dedicated architectural nor training recipe modifications. Notably, we obtain the best-ever pure ConvNet under 30M parameters with 83.1% top-1 accuracy on ImageNet, outperforming current SOTA methods including ConvNeXt V2 and Swin V2. We also find that beneficial characteristics of large-kernel ConvNets, e.g., larger effective receptive fields, can be seamlessly transferred to students through this large-to-small kernel distillation. Code is available at: https://github.com/VITA-Group/SLaK.

**摘要:** 本文揭示了大型内核卷积神经网络(ConvNets)的新吸引力:作为小内核卷积神经网络知识蒸馏(KD)的教师。虽然变换器在各种领域都带有 ever-larger模型和标签数据,但小内核卷积神经网络由于有效卷积操作和紧凑的权重共享,更适合资源有限的应用程序。KD广泛用于提高小内核卷积神经网络性能。然而,以往的研究显示,从变换器到小内核卷积神经网络的知识蒸馏(例如全球信息)并不十分有效,这可能是由于它们不同的架构。我们的发现得到了广泛的实验,包括logit级和功能级KD“从箱子外”的实验,没有专门的建筑或训练配方修改。我们得到了在ImageNet上最高精度83.1%的30M参数下最纯的ConvNet,超过了目前的SOTA方法,包括ConvNeXt V2和Swin V2.我们还发现,大内核ConvNets的有益特性,例如更大的有效接收场,可以通过大到小内核蒸馏直接转移给学生。

**[Paper URL](https://proceedings.mlr.press/v202/huang23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23o/huang23o.pdf)** 

# Achieving Linear Speedup in Non-IID Federated Bilevel Learning
**题目:** 非IID联邦双层学习中的线性加速

**作者:** Minhui Huang, Dewei Zhang, Kaiyi Ji

**Abstract:** Federated bilevel learning has received increasing attention in various emerging machine learning and communication applications. Recently, several Hessian-vector-based algorithms have been proposed to solve the federated bilevel optimization problem. However, several important properties in federated learning such as the partial client participation and the linear speedup for convergence (i.e., the convergence rate and complexity are improved linearly with respect to the number of sampled clients) in the presence of non-i.i.d. datasets, still remain open. In this paper, we fill these gaps by proposing a new federated bilevel algorithm named FedMBO with a novel client sampling scheme in the federated hypergradient estimation. We show that FedMBO achieves a convergence rate of $\mathcal{O}\big(\frac{1}{\sqrt{nK}}+\frac{1}{K}+\frac{\sqrt{n}}{K^{3/2}}\big)$ on non-i.i.d. datasets, where $n$ is the number of participating clients in each round, and $K$ is the total number of iteration. This is the first theoretical linear speedup result for non-i.i.d. federated bilevel optimization. Extensive experiments validate our theoretical results and demonstrate the effectiveness of our proposed method.

**摘要:** 联邦双层学习在各种新兴的机器学习和通信应用中得到了越来越广泛的关注。最近,为了解决联邦双层优化问题,提出了几个基于希斯sian向量算法。然而,在非I.i.d.数据集的存在下,联邦双层学习中的几个重要特性,如部分客户端参与和线性加速收敛(即收敛率和复杂度在随样对象数目上线性改进)以及非I.i.d.数据集的存在,仍然保持开放。这是非联合双层优化的第一个理论线性加速结果。广泛的实验验证了我们的理论结果,并证明了我们提出的方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/huang23p.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23p/huang23p.pdf)** 

# Federated Linear Contextual Bandits with User-level Differential Privacy
**题目:** 联邦线性构造 Bandits 与用户层面的差异性隐私

**作者:** Ruiquan Huang, Huanyu Zhang, Luca Melis, Milan Shen, Meisam Hejazinia, Jing Yang

**Abstract:** This paper studies federated linear contextual bandits under the notion of user-level differential privacy (DP). We first introduce a unified federated bandits framework that can accommodate various definitions of DP in the sequential decision-making setting. We then formally introduce user-level central DP (CDP) and local DP (LDP) in the federated bandits framework, and investigate the fundamental trade-offs between the learning regrets and the corresponding DP guarantees in a federated linear contextual bandits model. For CDP, we propose a federated algorithm termed as $\texttt{ROBIN}$ and show that it is near-optimal in terms of the number of clients $M$ and the privacy budget $\varepsilon$ by deriving nearly-matching upper and lower regret bounds when user-level DP is satisfied. For LDP, we obtain several lower bounds, indicating that learning under user-level $(\varepsilon,\delta)$-LDP must suffer a regret blow-up factor at least $\min\{1/\varepsilon,M\}$ or $\min\{1/\sqrt{\varepsilon},\sqrt{M}\}$ under different conditions.

**摘要:** 本文研究了联邦线性上下文带子在用户层次微分隐私(DP)的概念下,首先介绍了一种统一的联邦线性上下文带子框架,可以容纳在序列决策环境中各种 DP 的定义。然后在联邦线性上下文带子框架中正式引入用户层次中央DP(CDP)和局部DP(LDP),并在联邦线性上下文带子模型中研究学习遗憾和相应的DP 保证之间的基本交易权衡。对于LDP,我们得到了几个较低的界限,表明在用户级$(\varepsilon,\delta)$-LDP下学习必须在不同的条件下至少有$\min\{1/\varepsilon,M\}$或$\min\{1/\sqrt{\varepsilon},\sqrt{M}\}$的遗憾吹爆因子。

**[Paper URL](https://proceedings.mlr.press/v202/huang23q.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huang23q/huang23q.pdf)** 

# Straightening Out the Straight-Through Estimator: Overcoming Optimization Challenges in Vector Quantized Networks
**题目:** 精简直通估计器:在向量化网络中克服优化挑战

**作者:** Minyoung Huh, Brian Cheung, Pulkit Agrawal, Phillip Isola

**Abstract:** This work examines the challenges of training neural networks using vector quantization using straight-through estimation. We find that the main cause of training instability is the discrepancy between the model embedding and the code-vector distribution. We identify the factors that contribute to this issue, including the codebook gradient sparsity and the asymmetric nature of the commitment loss, which leads to misaligned code-vector assignments. We propose to address this issue via affine re-parameterization of the code vectors. Additionally, we introduce an alternating optimization to reduce the gradient error introduced by the straight-through estimation. Moreover, we propose an improvement to the commitment loss to ensure better alignment between the codebook representation and the model embedding. These optimization methods improve the mathematical approximation of the straight-through estimation and, ultimately, the model performance. We demonstrate the effectiveness of our methods on several common model architectures, such as AlexNet, ResNet, and ViT, across various tasks, including image classification and generative modeling.

**摘要:** 本文研究了使用直流估计量化向量化训练神经网络的挑战,发现训练不稳定的主要原因是模型嵌入与代码向量分布之间的差异。我们确定了导致这一问题的原因,包括代码簿梯度稀疏和承诺损失的不对称性质,导致代码向量分配错位。我们建议通过精细重新参数化代码向量来解决这个问题。此外,我们引入了代换优化来减少直流估计所引入的梯度误差。此外,我们建议改进承诺损失,确保代码簿表示与模型嵌入之间的更佳匹配。我们证明了我们的方法在多个常见的模型架构上,如AlexNet、ResNet和ViT,在各种任务中,包括图像分类和生成模型方面的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/huh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huh23a/huh23a.pdf)** 

# Cut your Losses with Squentropy
**题目:** 用Squentropy减少损失

**作者:** Like Hui, Mikhail Belkin, Stephen Wright

**Abstract:** Nearly all practical neural models for classification are trained using the cross-entropy loss. Yet this ubiquitous choice is supported by little theoretical or empirical evidence. Recent work (Hui & Belkin, 2020) suggests that training using the (rescaled) square loss is often superior in terms of the classification accuracy. In this paper we propose the "squentropy" loss, which is the sum of two terms: the cross-entropy loss and the average square loss over the incorrect classes. We provide an extensive set of experiment on multi-class classification problems showing that the squentropy loss outperforms both the pure cross-entropy and rescaled square losses in terms of the classification accuracy. We also demonstrate that it provides significantly better model calibration than either of these alternative losses and, furthermore, has less variance with respect to the random initialization. Additionally, in contrast to the square loss, squentropy loss can frequently be trained using exactly the same optimization parameters, including the learning rate, as the standard cross-entropy loss, making it a true ”plug-and-play” replacement. Finally, unlike the rescaled square loss, multiclass squentropy contains no parameters that need to be adjusted.

**摘要:** 几乎所有实用的分类神经模型都采用交叉熵损失进行训练,然而这种普遍的选择却缺乏理论或实证证据。最近的研究(Hui & Belkin, 2020)表明,使用(再校正)平方损失的训练往往在分类精度方面优越。本论文提出了“斜率”损失,即两个术语的总数:交叉熵损失和误类平均平方损失。我们提供了关于多类分类问题的广泛实验,表明斜率损失在分类精度方面优于纯交叉熵和再校正的平方损失。此外,与正方形损失相比,散曲损伤经常可以通过使用与标准交叉散曲损伤相同的优化参数进行训练,包括学习率,使它成为真正的“插-和-玩”替代品。

**[Paper URL](https://proceedings.mlr.press/v202/hui23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hui23a/hui23a.pdf)** 

# SOM-CPC: Unsupervised Contrastive Learning with Self-Organizing Maps for Structured Representations of High-Rate Time Series
**题目:** SOM-CPC:高阶时间序列结构性表现的自组织地图非监督反向学习

**作者:** Iris A.M. Huijben, Arthur Andreas Nijdam, Sebastiaan Overeem, Merel M Van Gilst, Ruud Van Sloun

**Abstract:** Continuous monitoring with an ever-increasing number of sensors has become ubiquitous across many application domains. However, acquired time series are typically high-dimensional and difficult to interpret. Expressive deep learning (DL) models have gained popularity for dimensionality reduction, but the resulting latent space often remains difficult to interpret. In this work we propose SOM-CPC, a model that visualizes data in an organized 2D manifold, while preserving higher-dimensional information. We address a largely unexplored and challenging set of scenarios comprising high-rate time series, and show on both synthetic and real-life data (physiological data and audio recordings) that SOM-CPC outperforms strong baselines like DL-based feature extraction, followed by conventional dimensionality reduction techniques, and models that jointly optimize a DL model and a Self-Organizing Map (SOM). SOM-CPC has great potential to acquire a better understanding of latent patterns in high-rate data streams.

**摘要:** 连续监测的传感器数目不断增加,在许多应用领域都普遍存在。然而,获得的时间序列通常是高维和难以解释的。表达式深层学习(DL)模型在减小维度方面得到了广泛的欢迎,但由此产生的潜在空间往往仍然难以解释。在这个工作中,我们提出了 SOM-CPC,一种可视化数据的模型,同时保存高维信息的组织二维多变形。我们针对包括高速时间序列在内的大量未探索和挑战性的场景,并在合成和现实数据(生理数据和音频记录)上显示 SOM-CPC超过了基于DL特征的强基线,其次是传统的减小维度技术,以及联合优化DL模型和自组织地图的模型。SOM-CPC具有巨大的潜力,能够更好地了解高速数据流中的潜在模式。

**[Paper URL](https://proceedings.mlr.press/v202/huijben23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/huijben23a/huijben23a.pdf)** 

# One-Shot Federated Conformal Prediction
**题目:** 单击联邦一致预测

**作者:** Pierre Humbert, Batiste Le Bars, Aurélien Bellet, Sylvain Arlot

**Abstract:** In this paper, we present a Conformal Prediction method that computes prediction sets in a one-shot Federated Learning (FL) setting. More specifically, we introduce a novel quantile-of-quantiles estimator and prove that for any distribution, it is possible to compute prediction sets with desired coverage in only one round of communication. To mitigate privacy issues, we also describe a locally differentially private version of our estimator. Finally, over a wide range of experiments, we show that our method returns prediction sets with coverage and length very similar to those obtained in a centralized setting. These results demonstrate that our method is well-suited for one-shot Federated Learning.

**摘要:** 本文提出了一种在一击联合学习(FL)环境中计算预测集合的符合预测方法,具体介绍了一种新的量子定量估计器,并证明在任何分布中,仅在一个通信周期中,可以计算具有预期覆盖范围的预测集合。为了减轻隐私问题,我们还描述了我们的估计器的局部差异性私人版本。最后,在广泛的实验中,我们证明了该方法能返回具有覆盖范围和长度的预测集合,与集中环境非常相似。这些结果表明该方法适用于一击联合学习。

**[Paper URL](https://proceedings.mlr.press/v202/humbert23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/humbert23a/humbert23a.pdf)** 

# The Impact of Exploration on Convergence and Performance of Multi-Agent Q-Learning Dynamics
**题目:** 探索对多代理Q-学习动力学的融合与性能的影响

**作者:** Aamal Hussain, Francesco Belardinelli, Dario Paccagnan

**Abstract:** Understanding the impact of exploration on the behaviour of multi-agent learning has, so far, benefited from the restriction to potential, or network zero-sum games in which convergence to an equilibrium can be shown. Outside of these classes, learning dynamics rarely converge and little is known about the effect of exploration in the face of non-convergence. To progress this front, we study the smooth Q- Learning dynamics. We show that, in any network game, exploration by agents results in the convergence of Q-Learning to a neighbourhood of an equilibrium. This holds independently of whether the dynamics reach the equilibrium or display complex behaviours. We show that increasing the exploration rate decreases the size of this neighbourhood and also decreases the ability of all agents to improve their payoffs. Furthermore, in a broad class of games, the payoff performance of Q-Learning dynamics, measured by Social Welfare, decreases when the exploration rate increases. Our experiments show this to be a general phenomenon, namely that exploration leads to improved convergence of Q-Learning, at the cost of payoff performance.

**摘要:** 了解探索对多代理学习行为的影响,迄今为止,已经从对潜在的限制或网络零总游戏中获益,其中可以显示对平衡的收敛性。在这些类别之外,学习动力学很少收敛,对探索对非收敛性的影响也很少知晓。为了推进这一方面,我们研究了平滑的Q-学习动力学。我们表明,在任何网络游戏中,代理探索的结果是Q-学习对平衡的邻域收敛性。这不取决于动力学是否达到平衡或显示复杂的行为。我们表明,增加探索率降低了这个邻域的大小,同时也降低了所有代理提高回报的能力。此外,在广泛的类别的游戏中,由社会福利衡量的Q-学习动力学的回报性能在提高探索率时下降。我们的实验表明,这是一种普遍现象,即探索导致了提高Q-学习的收敛性,而代价是回报性能。

**[Paper URL](https://proceedings.mlr.press/v202/hussain23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hussain23a/hussain23a.pdf)** 

# Combinatorial Neural Bandits
**题目:** 综合性神经损伤

**作者:** Taehyun Hwang, Kyuwook Chai, Min-Hwan Oh

**Abstract:** We consider a contextual combinatorial bandit problem where in each round a learning agent selects a subset of arms and receives feedback on the selected arms according to their scores. The score of an arm is an unknown function of the arm’s feature. Approximating this unknown score function with deep neural networks, we propose algorithms: Combinatorial Neural UCB ($\texttt{CN-UCB}$) and Combinatorial Neural Thompson Sampling ($\texttt{CN-TS}$). We prove that $\texttt{CN-UCB}$ achieves $\tilde{\mathcal{O}}(\tilde{d} \sqrt{T})$ or $\tilde{\mathcal{O}}(\sqrt{\tilde{d} T K})$ regret, where $\tilde{d}$ is the effective dimension of a neural tangent kernel matrix, $K$ is the size of a subset of arms, and $T$ is the time horizon. For $\texttt{CN-TS}$, we adapt an optimistic sampling technique to ensure the optimism of the sampled combinatorial action, achieving a worst-case (frequentist) regret of $\tilde{\mathcal{O}}(\tilde{d} \sqrt{TK})$. To the best of our knowledge, these are the first combinatorial neural bandit algorithms with regret performance guarantees. In particular, $\texttt{CN-TS}$ is the first Thompson sampling algorithm with the worst-case regret guarantees for the general contextual combinatorial bandit problem. The numerical experiments demonstrate the superior performances of our proposed algorithms.

**摘要:** 我们考虑了一个上下文组合带子问题,在每个循环中,学习代理选择一个臂子集,并根据其分数对所选的臂进行反馈。一个臂的分数是臂的特征的一个未知函数。通过对这一未知分数函数进行深入神经网络的近似,我们提出了算法:组合神经 UCB($\texttt{CN-UCB}$)和组合神经 Thompson Sampling($\texttt{CN-TS}$)。我们证明$\texttt{CN-UCB}$实现$\tilde{\mathcal{O}}(\tilde{d} \sqrt{T})$或$\tilde{\mathcal{O}}(\sqrt{\tilde{d} T K})$遗憾,其中$\tilde{d}$是神经有形核矩阵的有效维度根据我们所知,这些是第一个具有遗憾性能保证的组合神经带子算法,特别是$\texttt{CN-TS}$是第一个具有最糟糕的遗憾性能保证的汤普森采样算法,用于一般上下文组合带子问题。数值实验证明了我们提出的算法的优越性能。

**[Paper URL](https://proceedings.mlr.press/v202/hwang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hwang23a/hwang23a.pdf)** 

# MAGANet: Achieving Combinatorial Generalization by Modeling a Group Action
**题目:** MAGANet:通过建模小组行动实现综合推广

**作者:** Geonho Hwang, Jaewoong Choi, Hyunsoo Cho, Myungjoo Kang

**Abstract:** Combinatorial generalization refers to the ability to collect and assemble various attributes from diverse data to generate novel unexperienced data. This ability is considered a necessary passing point for achieving human-level intelligence. To achieve this ability, previous unsupervised approaches mainly focused on learning the disentangled representation, such as the variational autoencoder. However, recent studies discovered that the disentangled representation is insufficient for combinatorial generalization and is not even correlated. In this regard, we propose a novel framework for data generation that can robustly generalize under these distribution shift situations. Instead of representing each data, our model discovers the fundamental transformation between a pair of data by simulating a group action. To test the combinatorial generalizability, we evaluated our model in two settings: Recombination-to-Element and Recombination-to-Range. The experiments demonstrated that our method has quantitatively and qualitatively superior generalizability and generates better images than traditional models.

**摘要:** 组合广义化是指从不同数据中收集和组装各种属性,以生成新无经验的数据。这一能力被认为是实现人类水平智能的必要过渡点。为了实现这一能力,以前的未经监督的方法主要集中在学习异构的表示,例如变异的自动编码器。然而,最近的研究发现异构的表示对于组合广义化来说不足,甚至连相关性都没有。在这方面,我们提出了一种新的数据生成框架,能够在这些分布变换情况下强有力地广义化。实验表明,我们的方法具有较高的定量和质量通用性,比传统的模型产生更好的图像。

**[Paper URL](https://proceedings.mlr.press/v202/hwang23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hwang23b/hwang23b.pdf)** 

# Information-Theoretic State Space Model for Multi-View Reinforcement Learning
**题目:** 多视力增强学习信息理论状态空间模型

**作者:** Hyeongjoo Hwang, Seokin Seo, Youngsoo Jang, Sungyoon Kim, Geon-Hyeong Kim, Seunghoon Hong, Kee-Eung Kim

**Abstract:** Multi-View Reinforcement Learning (MVRL) seeks to find an optimal control for an agent given multi-view observations from various sources. Despite recent advances in multi-view learning that aim to extract the latent representation from multi-view data, it is not straightforward to apply them to control tasks, especially when the observations are temporally dependent on one another. The problem can be even more challenging if the observations are intermittently missing for a subset of views. In this paper, we introduce Fuse2Control (F2C), an information-theoretic approach to capturing the underlying state space model from the sequences of multi-view observations. We conduct an extensive set of experiments in various control tasks showing that our method is highly effective in aggregating task-relevant information across many views, that scales linearly with the number of views while retaining robustness to arbitrary missing view scenarios.

**摘要:** 多视增强学习(英语:Multi-View Reinforcement Learning,简称MVRL)是针对多视观察的代理人寻找多视观察的最优控制方法。尽管多视学习的目标是从多视数据中提取隐形表示,但对控制任务应用它们并不简单,特别是当观察是相互间接依赖的时空时,问题甚至更难以解决,如果观察为一组视图间断缺失,则问题更加严重。本文介绍了多视观察的序列中获取基本状态空间模型的信息理论方法Fuse2Control(F2C)。

**[Paper URL](https://proceedings.mlr.press/v202/hwang23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/hwang23c/hwang23c.pdf)** 

# Under-Counted Tensor Completion with Neural Incorporation of Attributes
**题目:** 不计数的特徵神经整合的承载完成

**作者:** Shahana Ibrahim, Xiao Fu, Rebecca Hutchinson, Eugene Seo

**Abstract:** Systematic under-counting effects are observed in data collected across many disciplines, e.g., epidemiology and ecology. Under-counted tensor completion (UC-TC) is well-motivated for many data analytics tasks, e.g., inferring the case numbers of infectious diseases at unobserved locations from under-counted case numbers in neighboring regions. However, existing methods for similar problems often lack supports in theory, making it hard to understand the underlying principles and conditions beyond empirical successes. In this work, a low-rank Poisson tensor model with an expressive unknown nonlinear side information extractor is proposed for under-counted multi-aspect data. A joint low-rank tensor completion and neural network learning algorithm is designed to recover the model. Moreover, the UC-TC formulation is supported by theoretical analysis showing that the fully counted entries of the tensor and each entry’s under-counting probability can be provably recovered from partial observations—under reasonable conditions. To our best knowledge, the result is the first to offer theoretical supports for under-counted multi-aspect data completion. Simulations and real-data experiments corroborate the theoretical claims.

**摘要:** 系统性低数值效应在许多学科收集的数据中被观察,例如流行病学和生态学。低数值指数完成(UC-TC)对于许多数据分析任务具有良好的动力,例如从邻近地区低数值指数中推断在未观察的地点感染疾病的病例数目。然而,类似问题的现有方法往往缺乏理论支持,使得难以理解经验成功之外的根本原则和条件。此外,UC-TC的公式由理论分析支持,证明在合理的条件下,能从部分观测中证明充分计数的张量器的输入和每个输入的计数概率。我们最了解的结果是第一个为计数不足的多方面数据完成提供理论支持的。

**[Paper URL](https://proceedings.mlr.press/v202/ibrahim23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ibrahim23a/ibrahim23a.pdf)** 

# On the Identifiability and Estimation of Causal Location-Scale Noise Models
**题目:** 因果位置尺度噪声模型的辨识及估算

**作者:** Alexander Immer, Christoph Schultheiss, Julia E Vogt, Bernhard Schölkopf, Peter Bühlmann, Alexander Marx

**Abstract:** We study the class of location-scale or heteroscedastic noise models (LSNMs), in which the effect $Y$ can be written as a function of the cause $X$ and a noise source $N$ independent of $X$, which may be scaled by a positive function $g$ over the cause, i.e., $Y = f(X) + g(X)N$. Despite the generality of the model class, we show the causal direction is identifiable up to some pathological cases. To empirically validate these theoretical findings, we propose two estimators for LSNMs: an estimator based on (non-linear) feature maps, and one based on neural networks. Both model the conditional distribution of $Y$ given $X$ as a Gaussian parameterized by its natural parameters. When the feature maps are correctly specified, we prove that our estimator is jointly concave, and a consistent estimator for the cause-effect identification task. Although the the neural network does not inherit those guarantees, it can fit functions of arbitrary complexity, and reaches state-of-the-art performance across benchmarks.

**摘要:** 我们研究了位置尺度或异性噪声模型(LSNMs)的类别,其中效应$Y$可以写成因子$X$的函数和噪声源$N$独立于$X$的函数,可以通过因子上的正函数$g$进行尺度,即$Y = f(X) + g(X)N$。尽管模型类的一般性,我们显示因子方向可识别到某些病理案例。为了实证验证这些理论发现,我们建议LSNMs的两个估计者:一个基于(非线性)特征地图的估计者,一个基于神经网络的估计者。尽管神经网络没有继承这些保证,但它可以适应任意复杂性的功能,并达到最先进的性能。

**[Paper URL](https://proceedings.mlr.press/v202/immer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/immer23a/immer23a.pdf)** 

# Stochastic Marginal Likelihood Gradients using Neural Tangent Kernels
**题目:** 使用神经 Tangent核的随机边缘概率梯度

**作者:** Alexander Immer, Tycho F. A. Van Der Ouderaa, Mark Van Der Wilk, Gunnar Ratsch, Bernhard Schölkopf

**Abstract:** Selecting hyperparameters in deep learning greatly impacts its effectiveness but requires manual effort and expertise. Recent works show that Bayesian model selection with Laplace approximations can allow to optimize such hyperparameters just like standard neural network parameters using gradients and on the training data. However, estimating a single hyperparameter gradient requires a pass through the entire dataset, limiting the scalability of such algorithms. In this work, we overcome this issue by introducing lower bounds to the linearized Laplace approximation of the marginal likelihood. In contrast to previous estimators, these bounds are amenable to stochastic-gradient-based optimization and allow to trade off estimation accuracy against computational complexity. We derive them using the function-space form of the linearized Laplace, which can be estimated using the neural tangent kernel. Experimentally, we show that the estimators can significantly accelerate gradient-based hyperparameter optimization.

**摘要:** 在深层学习中选择超参数极大地影响其效率,但需要手动努力和专业知识。最近的研究表明,与拉普拉斯近似模型选择可以像标准神经网络参数一样,利用梯度和训练数据优化这些超参数。然而,估计单个超参数梯度需要通过整个数据集,限制这些算法的可扩展性。在这个研究中,我们通过引入边缘概率的线性化拉普拉斯近似的较低边界来克服这一问题。实验表明,这些估计器可以大大加快基于梯度的超参数优化。

**[Paper URL](https://proceedings.mlr.press/v202/immer23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/immer23b/immer23b.pdf)** 

# Differentially Private Hierarchical Clustering with Provable Approximation Guarantees
**题目:** 具有可提供近似保证的差异性私有 hierarchical clustering

**作者:** Jacob Imola, Alessandro Epasto, Mohammad Mahdian, Vincent Cohen-Addad, Vahab Mirrokni

**Abstract:** Hierarchical Clustering is a popular unsupervised machine learning method with decades of history and numerous applications. We initiate the study of differentially-private approximation algorithms for hierarchical clustering under the rigorous framework introduced by Dasgupta (2016). We show strong lower bounds for the problem: that any $\epsilon$-DP algorithm must exhibit $O(|V|^2/ \epsilon)$-additive error for an input dataset $V$. Then, we exhibit a polynomial-time approximation algorithm with $O(|V|^{2.5}/ \epsilon)$-additive error, and an exponential-time algorithm that meets the lower bound. To overcome the lower bound, we focus on the stochastic block model, a popular model of graphs, and, with a separation assumption on the blocks, propose a private $1+o(1)$ approximation algorithm which also recovers the blocks exactly. Finally, we perform an empirical study of our algorithms and validate their performance.

**摘要:** 层次聚类是一个具有数十年历史和众多应用的不受监督的通用机器学习方法。我们开始在达斯古普塔(2016)引入的严格框架下对层次聚类进行微分private近似算法的研究。我们给出了问题的强下界限:任何$\epsilon$-DP算法必须显示$O(|V|^2/\epsilon)$-输入数据集$V$的附加误差。然后,我们展示了与$O(|V|^{2.5}/\epsilon)$-附加误差的多项式时间近似算法,以及满足下界限的指数时间算法。

**[Paper URL](https://proceedings.mlr.press/v202/imola23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/imola23a/imola23a.pdf)** 

# Neural Network Accelerated Implicit Filtering: Integrating Neural Network Surrogates With Provably Convergent Derivative Free Optimization Methods
**题目:** 神经网络加速隐式滤波:用可信地趋同的导数自由优化方法集成神经网络替代品

**作者:** Brian Irwin, Eldad Haber, Raviv Gal, Avi Ziv

**Abstract:** In this paper, we introduce neural network accelerated implicit filtering (NNAIF), a novel family of methods for solving noisy derivative free (i.e. black box, zeroth order) optimization problems. NNAIF intelligently combines the established literature on implicit filtering (IF) optimization methods with a neural network (NN) surrogate model of the objective function, resulting in accelerated derivative free methods for unconstrained optimization problems. The NN surrogate model consists of a fixed number of parameters, which can be as few as $\approx 1.3 \times 10^{4}$, that are updated as NNAIF progresses. We show that NNAIF directly inherits the convergence properties of IF optimization methods, and thus NNAIF is guaranteed to converge towards a critical point of the objective function under appropriate assumptions. Numerical experiments with $31$ noisy problems from the CUTEst optimization benchmark set demonstrate the benefits and costs associated with NNAIF. These benefits include NNAIF’s ability to minimize structured functions of several thousand variables much more rapidly than well-known alternatives, such as Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and finite difference based variants of gradient descent (GD) and BFGS, as well as its namesake IF.

**摘要:** 本文介绍了神经网络加速隐式滤波(英语:neural network accelerated implicit filtering, NNAIF),一种用于解决噪声导数自由(即黑箱、零阶)优化问题的新方法。NNAIF智能地结合了关于隐式滤波(IF)优化方法的既定文献和目标函数神经网络(NN)替代模型,从而为不受约束的优化问题提供加速导数自由的方法。NN替代模型由数值参数组成,数值可少于$\approx 1.3 \times 10^{4}$,随NNAIF进度而更新。这些好处包括NNAIF能够减少数千个变量结构函数的速度比已知的替代方案更快,例如Covariance Matrix Adaptation Evolution Strategy(CMA-ES)和有限差分基于梯度下降的变量(GD)和BFGS,以及其命名为IF。

**[Paper URL](https://proceedings.mlr.press/v202/irwin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/irwin23a/irwin23a.pdf)** 

# Principled Offline RL in the Presence of Rich Exogenous Information
**题目:** 在丰富的外来信息存在下,原则上 Offline RL

**作者:** Riashat Islam, Manan Tomar, Alex Lamb, Yonathan Efroni, Hongyu Zang, Aniket Rajiv Didolkar, Dipendra Misra, Xin Li, Harm Van Seijen, Remi Tachet Des Combes, John Langford

**Abstract:** Learning to control an agent from offline data collected in a rich pixel-based visual observation space is vital for real-world applications of reinforcement learning (RL). A major challenge in this setting is the presence of input information that is hard to model and irrelevant to controlling the agent. This problem has been approached by the theoretical RL community through the lens of exogenous information, i.e., any control-irrelevant information contained in observations. For example, a robot navigating in busy streets needs to ignore irrelevant information, such as other people walking in the background, textures of objects, or birds in the sky. In this paper, we focus on the setting with visually detailed exogenous information and introduce new offline RL benchmarks that offer the ability to study this problem. We find that contemporary representation learning techniques can fail on datasets where the noise is a complex and time-dependent process, which is prevalent in practical applications. To address these, we propose to use multi-step inverse models to learn Agent-Centric Representations for Offline-RL (ACRO). Despite being simple and reward-free, we show theoretically and empirically that the representation created by this objective greatly outperforms baselines.

**摘要:** 基于 rich pixel的视觉观测空间收集的非线性数据控制代理是增强学习(RL)的现实应用中至关重要的。在这个设置中的一个主要挑战是难以建模和与控制代理无关的输入信息的存在。这一问题已被理论RL社区通过外源信息的镜头来解决,即观察中包含的任何控制无关的信息。例如,在繁忙的街道上导航的机器人需要忽略无关的信息,例如其他人在背景,物体的纹理或天空中的鸟类。我们发现,当代的表示学习技术在数据集中可能失败,因为噪声是一个复杂的时间依赖的过程,在实际应用中是普遍的。为了解决这些问题,我们建议使用多步逆模型学习 Offline-RL(ACRO)的代理中心表示。

**[Paper URL](https://proceedings.mlr.press/v202/islam23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/islam23a/islam23a.pdf)** 

# Unveiling the Latent Space Geometry of Push-Forward Generative Models
**题目:** 推向生成模型的潜在空间几何揭示

**作者:** Thibaut Issenhuth, Ugo Tanielian, Jeremie Mary, David Picard

**Abstract:** Many deep generative models are defined as a push-forward of a Gaussian measure by a continuous generator, such as Generative Adversarial Networks (GANs) or Variational Auto-Encoders (VAEs). This work explores the latent space of such deep generative models. A key issue with these models is their tendency to output samples outside of the support of the target distribution when learning disconnected distributions. We investigate the relationship between the performance of these models and the geometry of their latent space. Building on recent developments in geometric measure theory, we prove a sufficient condition for optimality in the case where the dimension of the latent space is larger than the number of modes. Through experiments on GANs, we demonstrate the validity of our theoretical results and gain new insights into the latent space geometry of these models. Additionally, we propose a truncation method that enforces a simplicial cluster structure in the latent space and improves the performance of GANs.

**摘要:** 许多深层生成模型被连续生成器定义为高斯量度的推向,例如生成敌机网络(GANs)或变量自动编码器(VAEs)。该研究探讨了这些深层生成模型的潜在空间。这些模型的一个关键问题是它们在学习分离分布时,在目标分布的支持之外输出样品的倾向。我们研究了这些模型的性能与它们的潜在空间几何之间的关系。本文还提出了一种简洁的缓存空间集群结构和提高GAN性能的切换方法。

**[Paper URL](https://proceedings.mlr.press/v202/issenhuth23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/issenhuth23a/issenhuth23a.pdf)** 

# CO-BED: Information-Theoretic Contextual Optimization via Bayesian Experimental Design
**题目:** CO-BED:基于贝叶斯实验设计的信息理论背景优化

**作者:** Desi R. Ivanova, Joel Jennings, Tom Rainforth, Cheng Zhang, Adam Foster

**Abstract:** We formalize the problem of contextual optimization through the lens of Bayesian experimental design and propose CO-BED—a general, model-agnostic framework for designing contextual experiments using information-theoretic principles. After formulating a suitable information-based objective, we employ black-box variational methods to simultaneously estimate it and optimize the designs in a single stochastic gradient scheme. In addition, to accommodate discrete actions within our framework, we propose leveraging continuous relaxation schemes, which can naturally be integrated into our variational objective. As a result, CO-BED provides a general and automated solution to a wide range of contextual optimization problems. We illustrate its effectiveness in a number of experiments, where CO-BED demonstrates competitive performance even when compared to bespoke, model-specific alternatives.

**摘要:** 本文通过贝叶斯实验设计的视角对语境优化问题进行了形式化,并提出了一种基于信息理论的语境实验设计的一般模型性框架,即CO-BED(英语:CO-BED) 。 在拟定合适的基于信息的目标后,我们采用黑箱变量方法同时估计和优化单一随机梯度方案中的设计。此外,为了适应我们框架内的离散行动,我们建议利用连续放松方案,这些方案可以自然地集成到我们的变量目标中。

**[Paper URL](https://proceedings.mlr.press/v202/ivanova23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ivanova23a/ivanova23a.pdf)** 

# DoG is SGD’s Best Friend: A Parameter-Free Dynamic Step Size Schedule
**题目:** DoG是SGD最好的朋友:一个无参数动态步骤大小日程表

**作者:** Maor Ivgi, Oliver Hinder, Yair Carmon

**Abstract:** We propose a tuning-free dynamic SGD step size formula, which we call Distance over Gradients (DoG). The DoG step sizes depend on simple empirical quantities (distance from the initial point and norms of gradients) and have no “learning rate” parameter. Theoretically, we show that, for stochastic convex optimization, a slight variation of the DoG formula enjoys strong, high-probability parameter-free convergence guarantees and iterate movement bounds. Empirically, we consider a broad range of vision and language transfer learning tasks, and show that DoG’s performance is close to that of SGD with tuned learning rate. We also propose a per-layer variant of DoG that generally outperforms tuned SGD, approaching the performance of tuned Adam. A PyTorch implementation of our algorithms is available at https://github.com/formll/dog.

**摘要:** 我们提出了自由调动的动态SGD步量公式,我们称之为“梯度上距离”(DoG) 。 DoG步量取决于简单的经验量(距离梯度的初始点和标准)和没有“学习率”参数。理论上,我们显示,对于随机凸优化,DoG公式的轻微变异享受着强有力的、高概率的参数自由收敛性保证和迭代运动边界。

**[Paper URL](https://proceedings.mlr.press/v202/ivgi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ivgi23a/ivgi23a.pdf)** 

# Maximal Initial Learning Rates in Deep ReLU Networks
**题目:** Deep ReLU网络初始学习率最大

**作者:** Gaurav Iyer, Boris Hanin, David Rolnick

**Abstract:** Training a neural network requires choosing a suitable learning rate, which involves a trade-off between speed and effectiveness of convergence. While there has been considerable theoretical and empirical analysis of how large the learning rate can be, most prior work focuses only on late-stage training. In this work, we introduce the maximal initial learning rate $\eta^{\ast}$ - the largest learning rate at which a randomly initialized neural network can successfully begin training and achieve (at least) a given threshold accuracy. Using a simple approach to estimate $\eta^{\ast}$, we observe that in constant-width fully-connected ReLU networks, $\eta^{\ast}$ behaves differently from the maximum learning rate later in training. Specifically, we find that $\eta^{\ast}$ is well predicted as a power of depth $\times$ width, provided that (i) the width of the network is sufficiently large compared to the depth, and (ii) the input layer is trained at a relatively small learning rate. We further analyze the relationship between $\eta^{\ast}$ and the sharpness $\lambda_{1}$ of the network at initialization, indicating they are closely though not inversely related. We formally prove bounds for $\lambda_{1}$ in terms of depth $\times$ width that align with our empirical results.

**摘要:** 神经网络的训练需要选择合适的学习速率,这涉及速度和收敛效率之间的交易。虽然有相当大的理论和经验分析,学习速率有多大,但大多数以前的工作只集中在后期训练。在这个工作中,我们介绍了最大初始学习速率 $\eta^{\ast}$ - 一个随机初始化神经网络能够成功地开始训练并达到(至少)给定的阈值精度的最大学习速率。我们进一步分析了网络在初始化时$\eta^{\ast}$与 sharpness $\lambda_{1}$之间的关系,表明它们密切相关,但不是逆相关。

**[Paper URL](https://proceedings.mlr.press/v202/iyer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/iyer23a/iyer23a.pdf)** 

# Data-Driven Subgroup Identification for Linear Regression
**题目:** 线性回归数据驱动子群识别

**作者:** Zachary Izzo, Ruishan Liu, James Zou

**Abstract:** Medical studies frequently require to extract the relationship between each covariate and the outcome with statistical confidence measures. To do this, simple parametric models are frequently used (e.g. coefficients of linear regression) but always fitted on the whole dataset. However, it is common that the covariates may not have a uniform effect over the whole population and thus a unified simple model can miss the heterogeneous signal. For example, a linear model may be able to explain a subset of the data but fail on the rest due to the nonlinearity and heterogeneity in the data. In this paper, we propose DDGroup (data-driven group discovery), a data-driven method to effectively identify subgroups in the data with a uniform linear relationship between the features and the label. DDGroup outputs an interpretable region in which the linear model is expected to hold. It is simple to implement and computationally tractable for use. We show theoretically that, given a large enough sample, DDGroup recovers a region where a single linear model with low variance is well-specified (if one exists), and experiments on real-world medical datasets confirm that it can discover regions where a local linear model has improved performance. Our experiments also show that DDGroup can uncover subgroups with qualitatively different relationships which are missed by simply applying parametric approaches to the whole dataset.

**摘要:** 医学研究经常需要用统计可靠度来提取每个变量与结果之间的关系。为此,常用简单的参数模型(例如线性回归的系数)但总是在整个数据集上安装。然而,变量可能不会对整个人口产生统一的影响,因此统一的简单模型可能会错过异质信号。例如,线性模型可能能够解释数据的子集,但由于数据中的非线性和异质性,在其他数据上失败。我们从理论上证明,在足够大的样本中,DDGroup能找到一个具有低变异的单一线性模型(如果存在的话)的区域,并通过实物医疗数据集的实验证实它能够发现一个局部线性模型的性能提高的区域。

**[Paper URL](https://proceedings.mlr.press/v202/izzo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/izzo23a/izzo23a.pdf)** 

# Efficient Training of Language Models using Few-Shot Learning
**题目:** 使用短距离学习的语言模型的有效培训

**作者:** Sashank J. Reddi, Sobhan Miryoosefi, Stefani Karp, Shankar Krishnan, Satyen Kale, Seungyeon Kim, Sanjiv Kumar

**Abstract:** Large deep learning models have achieved state-of-the-art performance across various natural language processing (NLP) tasks and demonstrated remarkable few-shot learning performance. However, training them is often challenging and resource-intensive. In this paper, we study an efficient approach to train language models using few-shot learners. We show that, by leveraging the fast learning nature of few-shot learners, one can train language models efficiently in a stagewise manner. Our main insight is that stacking a good few-shot learner on a good small language model provides a good initializer for a larger language model. Using this insight and building upon progressive stacking approaches, we develop novel approaches for training such networks in a stagewise manner. Furthermore, we also provide a theoretical framework and accompanying empirical studies to support our insights, thereby creating a theoretical foundation for progressive stacking. Finally, we provide empirical results to demonstrate the effectiveness of our approach in reducing the training time of few-shot learners.

**摘要:** 大型深度学习模型在各种自然语言处理(NLP)任务中取得了最先进的性能,并展示了显著的少数射击学习性能。然而,训练它们往往具有挑战性和资源密集性。本论文研究了利用少数射击学习者训练语言模型的有效方法。我们表明,通过利用少数射击学习者快速学习的性质,可以以阶段性的方式有效地训练语言模型。我们的主要洞察是,在良好的小型语言模型上堆叠一个好少数射击学习者,为一个较大的语言模型提供了一个好的初始化器。最后,我们提供了实证结果,以证明我们的方法在减少少 shot learners的训练时间方面是有效的。

**[Paper URL](https://proceedings.mlr.press/v202/j-reddi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/j-reddi23a/j-reddi23a.pdf)** 

# Scalable Adaptive Computation for Iterative Generation
**题目:** 可 skalable adaptive computing for Iterative Generation

**作者:** Allan Jabri, David J. Fleet, Ting Chen

**Abstract:** Natural data is redundant yet predominant architectures tile computation uniformly across their input and output space. We propose the Recurrent Interface Network (RIN), an attention-based architecture that decouples its core computation from the dimensionality of the data, enabling adaptive computation for more scalable generation of high-dimensional data. RINs focus the bulk of computation (i.e. global self-attention) on a set of latent tokens, using cross-attention to read and write (i.e. route) information between latent and data tokens. Stacking RIN blocks allows bottom-up (data to latent) and top-down (latent to data) feedback, leading to deeper and more expressive routing. While this routing introduces challenges, this is less problematic in recurrent computation settings where the task (and routing problem) changes gradually, such as iterative generation with diffusion models. We show how to leverage recurrence by conditioning the latent tokens at each forward pass of the reverse diffusion process with those from prior computation, i.e. latent self-conditioning. RINs yield state-of-the-art pixel diffusion models for image and video generation, scaling to1024×1024 images without cascades or guidance, while being domain-agnostic and up to 10× more efficient than 2D and 3D U-Nets.

**摘要:** 自然数据是冗余的,但占主导地位的架构在输入和输出空间中均匀地进行计算。我们提出了一种基于注意力的架构,它将核心的计算与数据的维度分离,为高维数据的更可扩展的生成提供适应性计算。RIN集中了大部分计算(即全球自我注意)的集合 latent tokens,使用交叉注意读写(即路由) latent 和 data tokens 之间信息。我们展示了如何利用逆扩散过程的每个向前传递条件下,与先前的计算条件下,即潜在的自我条件下的隐形符号来利用复发。RIN提供最先进的像素扩散模型用于图像和视频生成,在无 cascades 或 指导的情况下,可扩展到1024×1024图像,同时具有域无误性和比2D 和 3D U-Nets 更高效的10×。

**[Paper URL](https://proceedings.mlr.press/v202/jabri23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jabri23a/jabri23a.pdf)** 

# Unconstrained Online Learning with Unbounded Losses
**题目:** 无限制的在线学习与无限制的损失

**作者:** Andrew Jacobsen, Ashok Cutkosky

**Abstract:** Algorithms for online learning typically require one or more boundedness assumptions: that the domain is bounded, that the losses are Lipschitz, or both. In this paper, we develop a new setting for online learning with unbounded domains and non-Lipschitz losses. For this setting we provide an algorithm which guarantees $R_{T}(u)\le \tilde O(G\|u\|\sqrt{T}+L\|u\|^{2}\sqrt{T})$ regret on any problem where the subgradients satisfy $\|g_{t}\|\le G+L\|w_{t}\|$, and show that this bound is unimprovable without further assumptions. We leverage this algorithm to develop new saddle-point optimization algorithms that converge in duality gap in unbounded domains, even in the absence of meaningful curvature. Finally, we provide the first algorithm achieving non-trivial dynamic regret in an unbounded domain for non-Lipschitz losses, as well as a matching lower bound. The regret of our dynamic regret algorithm automatically improves to a novel $L^{*}$ bound when the losses are smooth.

**摘要:** 在线学习算法通常需要一个或多个边界假设:域是边界的,损失是リップ茨的,或者两者。本文开发了与无边界域和非リップ茨损失的在线学习的新设置。为此设置提供了保证在任何问题上$R_{T}(u)\le \tilde O(G\|u\|\sqrt{T}+L\|u\|^{2}\sqrt{T})$后悔的算法,其中子梯度满足$\|g_{t}\|\le G+L\|w_{t}\|$,并证明此边界没有进一步假设的改进。我们利用该算法开发了新的鞍点优化算法,在无边界域中的二元间隙,即使不存在有意义的曲线。最后,我们提供了第一个实现无边界域内非リップ茨

**[Paper URL](https://proceedings.mlr.press/v202/jacobsen23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jacobsen23a/jacobsen23a.pdf)** 

# Multi-Objective GFlowNets
**题目:** 多目标GFlowNets

**作者:** Moksh Jain, Sharath Chandra Raparthy, Alex Hernández-Garcı́a, Jarrid Rector-Brooks, Yoshua Bengio, Santiago Miret, Emmanuel Bengio

**Abstract:** We study the problem of generating diverse candidates in the context of Multi-Objective Optimization. In many applications of machine learning such as drug discovery and material design, the goal is to generate candidates which simultaneously optimize a set of potentially conflicting objectives. Moreover, these objectives are often imperfect evaluations of some underlying property of interest, making it important to generate diverse candidates to have multiple options for expensive downstream evaluations. We propose Multi-Objective GFlowNets (MOGFNs), a novel method for generating diverse Pareto optimal solutions, based on GFlowNets. We introduce two variants of MOGFNs: MOGFN-PC, which models a family of independent sub-problems defined by a scalarization function, with reward-conditional GFlowNets, and MOGFN-AL, which solves a sequence of sub-problems defined by an acquisition function in an active learning loop. Our experiments on wide variety of synthetic and benchmark tasks demonstrate advantages of the proposed methods in terms of the Pareto performance and importantly, improved candidate diversity, which is the main contribution of this work.

**摘要:** 我们研究在多目标优化中生成不同的候选者的问题。在许多机器学习应用中,例如药物发现和材料设计,目标是同时优化一系列潜在冲突的目标的候选者。此外,这些目标往往是某些潜在利益属性的不完善评价,因此重要的是生成不同的候选者,以便有多种选择进行昂贵的下游评价。我们提出了基于GFlowNets的多目标GFlowNets(MOGFNs),一种基于GFlowNets的生成多派托优化解决方案的新方法。我们对各种合成和基准任务的实验表明,提出的方法在帕雷托性能方面具有优势,而且重要的是,改进了候选人的多样性,这是这项工作的主要贡献。

**[Paper URL](https://proceedings.mlr.press/v202/jain23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jain23a/jain23a.pdf)** 

# The Price of Differential Privacy under Continual Observation
**题目:** 持续观察下的差额隐私价格

**作者:** Palak Jain, Sofya Raskhodnikova, Satchit Sivakumar, Adam Smith

**Abstract:** We study the accuracy of differentially private mechanisms in the continual release model. A continual release mechanism receives a sensitive dataset as a stream of $T$ inputs and produces, after receiving each input, an output that is accurate for all the inputs received so far. We provide the first strong lower bounds on the error of continual release mechanisms. In particular, for two fundamental problems that are closely related to empirical risk minimization and widely studied and used in the standard (batch) model, we prove that the worst case error of every continual release algorithm is $\tilde \Omega(T^{1/3})$ times larger than that of the best batch algorithm. Previous work shows only a $\Omega(\log T)$ gap between the worst case error achievable in these two models. We also formulate a model that allows for adaptively selected inputs, thus capturing dependencies that arise in many applications of continual release. Even though, in general, both privacy and accuracy are harder to attain in this model, we show that our lower bounds are matched by the error of simple algorithms that work even for adaptively selected inputs.

**摘要:** 我们研究了连续释放模型中的微分私有机制的准确性。一个连续释放机制接收到$T$输入的敏感数据集,并在接收每个输入后,产生对迄今所接收的所有输入的准确的输出。我们提供了连续释放机制错误的第一个强弱的下界限。特别是,对于两个与经验风险最小化密切相关的基本问题,并在标准(批量)模型中广泛研究和使用,我们证明每个连续释放算法的最坏情况下的错误是$\tilde \Omega(T^{1/3})$比最佳批量算法的倍大。尽管一般来说,在这一模型中,隐私和准确性都很难实现,但我们证明了我们的较低的边界是通过简单的算法的误差匹配的,这些算法甚至适用于自适应选择的输入。

**[Paper URL](https://proceedings.mlr.press/v202/jain23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jain23b/jain23b.pdf)** 

# Graph Ladling: Shockingly Simple Parallel GNN Training without Intermediate Communication
**题目:** 图拉丁:无中间通信的惊人的平行GNN训练

**作者:** Ajay Kumar Jaiswal, Shiwei Liu, Tianlong Chen, Ying Ding, Zhangyang Wang

**Abstract:** Graphs are omnipresent and GNNs are a powerful family of neural networks for learning over graphs. Despite their popularity, scaling GNNs either by deepening or widening suffers from prevalent issues of $\textit{unhealthy gradients, over-smoothening, information squashing}$, which often lead to sub-standard performance. In this work, we are interested in exploring a principled way to scale GNNs capacity without deepening or widening, which can improve its performance across multiple small and large graphs. Motivated by the recent intriguing phenomenon of model soups, which suggest that fine-tuned weights of multiple large-language pre-trained models can be merged to a better minima, we argue to exploit the fundamentals of model soups to mitigate the aforementioned issues of memory bottleneck and trainability during GNNs scaling. More specifically, we propose not to deepen or widen current GNNs, but instead present $\textbf{first data-centric perspective}$ of model soups to build powerful GNNs by dividing giant graph data to build independently and parallelly trained multiple comparatively weaker GNNs without any intermediate communication, and $\textit{combining their strength}$ using a greedy interpolation soup procedure to achieve state-of-the-art performance. Moreover, we provide a wide variety of model soup preparation techniques by leveraging state-of-the-art graph sampling and graph partitioning approaches that can handle large graph data structures. Our extensive experiments across many real-world small and large graphs, illustrate the effectiveness of our approach and point towards a promising orthogonal direction for GNN scaling. Codes are available at: https://github.com/VITA-Group/graph_ladling

**摘要:** 图形是无处不在的,GNN是学习图形的神经网络的一个强大的家族。尽管它们很受欢迎,GNN的规模 either by deepening or widening受到$\textit{unhealthy gradients, over-smoothening, information squashing}$的普遍问题的影响,这些问题往往会导致低标准的性能。在这个工作中,我们对探索GNN的性能 without deepening or widening的原理性方法感兴趣,这可以提高其在多个小和大的图形中性能。更具体地说,我们建议不加深或扩大当前GNN,而是提供$\textbf{first data-centric perspective}$模型汤以建立强大的GNN,通过分隔巨型图数据来独立并同时训练多个相对较弱的GNN,没有任何中间通信,并使用贪婪插值汤程序实现最先进的性能。此外,我们通过利用最先进的图样和图分离方法来提供多种模型汤的准备技术,能够处理大型图数据结构。

**[Paper URL](https://proceedings.mlr.press/v202/jaiswal23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jaiswal23a/jaiswal23a.pdf)** 

# Instant Soup: Cheap Pruning Ensembles in A Single Pass Can Draw Lottery Tickets from Large Models
**题目:** 即时汤:单一门票的廉价采摘集会从大型模型中抽出彩票

**作者:** Ajay Kumar Jaiswal, Shiwei Liu, Tianlong Chen, Ying Ding, Zhangyang Wang

**Abstract:** Large pre-trained transformers have been receiving explosive attention in the past few years, due to their acculturation for numerous downstream applications via fine-tuning, but their exponentially increasing parameter counts are becoming a primary hurdle to even just fine-tune them without industry-standard hardware. Recently, Lottery Ticket Hypothesis (LTH) and its variants, have been exploited to prune these large pre-trained models generating subnetworks which can achieve similar performance as their dense counterparts, but LTH pragmatism is enormously inhibited by repetitive full training and pruning routine of iterative magnitude pruning (IMP) which worsens with increasing model size. Motivated by the recent observations of model soups, which suggest that fine-tuned weights of multiple models can be merged to a better minima, we propose Instant Soup Pruning (ISP) to generate lottery ticket quality subnetworks, using a fraction of the original IMP cost by replacing the expensive intermediate pruning stages of IMP with computationally efficient weak mask generation and aggregation routine. More specifically, during the mask generation stage, ISP takes a small handful of iterations using varying training protocols and data subsets to generate many weak and noisy subnetworks, and superpose them to average out the noise creating a high-quality denoised subnetwork. Our extensive experiments and ablation on two popular large-scale pre-trained models: $\texttt{CLIP} (unexplored in pruning till date)$ and $\texttt{BERT}$ across multiple benchmark vision $\texttt{\{MNIST, SVHN, Cars, GTSRB, CIFAR-10, CIFAR-100\}}$ and language datasets $\texttt{\{MNLI, QNLI, QQP, SST, ...\}}$ validate the effectiveness of ISP compared to several state-of-the-art pruning methods. Additionally, we show that ISP can be easily modified with minimal overhead to produce benefits comparable to model soups, without the prerequisite to generate multiple candidates fine-tuned models. Codes are available at: https://github.com/VITA-Group/instant_soup.

**摘要:** 大型预训练的变压器在过去几年中得到了爆炸性的关注,因为它们通过精细调制对许多下游应用进行培养,但它们指数增长的参数数目正成为没有工业标准硬件的精细调制它们的首要障碍。基于最近对模型汤的观察,认为多个模型的微调重量可以合并为较好的最小值,我们提出了快速汤剪切(Instant Soup Pruning,ISP)来生成彩票票质子网络,用原先的IMP成本的一小部分,将昂贵的中间剪切阶段替换为计算效率低的弱面具生成和集群程序。我们对两个流行的大规模预训练模型进行了广泛的实验和分析: $\texttt{CLIP}(未开发的剪切方法)$和 $\texttt{BERT}$在多个基准视图上 $\texttt{\{MNIST, SVHN, Cars, GTSRB, CIFAR-10, CIFAR-100\}}$和语言数据集 $\texttt{\{MNLI, QNLI, QQP, SST,...\}}$验证了ISP的有效性,与几种最新剪切方法相比。

**[Paper URL](https://proceedings.mlr.press/v202/jaiswal23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jaiswal23b/jaiswal23b.pdf)** 

# Exploring the Benefits of Training Expert Language Models over Instruction Tuning
**题目:** 探讨培训专家语言模型在教学教学上的优势

**作者:** Joel Jang, Seungone Kim, Seonghyeon Ye, Doyoung Kim, Lajanugen Logeswaran, Moontae Lee, Kyungjae Lee, Minjoon Seo

**Abstract:** Recently, Language Models (LMs) instruction-tuned on multiple tasks, also known as multitask-prompted fine-tuning (MT), have shown capabilities to generalize to unseen tasks. Previous work has shown that scaling the number of finetuning datasets and instructions is the key component in making stronger MT LMs. In this work, we report surprising findings that show an expert LM trained on just a single task can outperform an MT LM trained with 300+ different tasks on 11 different unseen datasets and on 13 datasets of the BIG-bench benchmark by an average of 3.20% and 1.29%, respectively. This finding casts doubt on the previously held belief that simply scaling the number of tasks makes stronger MT LMs. Leveraging this finding, we further show that this distributed approach of training multiple expert LMs instead of a single MT LM for zero-shot inference possesses many benefits including (1) avoiding negative task transfer that often occurs during instruction tuning, (2) being able to continually learn new tasks without having to re-train on previous tasks to avoid catastrophic forgetting, and (3) showing compositional capabilities when merging individual experts together.

**摘要:** 最近,语言模型(LMs)在多个任务上调制的指令,也被称为多任务即时调制(MT),显示了将未知任务一般化的能力。以前的工作显示了调制数据集和指令的数目是制造更强的MTLMs的关键组成部分。在这个工作中,我们报告了显示在11个不同未知数据集和13个 BIG-bench基准数据集中以3.20%和1.29%的平均水平训练的MTLM能够胜过一个单一任务训练的专家LM的令人惊讶的发现。利用这一发现,我们进一步表明,这种分布式培训多个专家LM,而不是单个MTLM的零射击推理方法具有许多好处,包括:(一)避免在教学调制过程中经常出现的负任务转移;(二)能够不断学习新的任务,而不需重新培训以前的任务,以避免灾难性忘记;(三)在将个别专家合并时显示组合能力。

**[Paper URL](https://proceedings.mlr.press/v202/jang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jang23a/jang23a.pdf)** 

# Learning to Boost Training by Periodic Nowcasting Near Future Weights
**题目:** 学习通过定期更新近未来体重来增强训练

**作者:** Jinhyeok Jang, Woo-Han Yun, Won Hwa Kim, Youngwoo Yoon, Jaehong Kim, Jaeyeon Lee, Byungok Han

**Abstract:** Recent complicated problems require large-scale datasets and complex model architectures, however, it is difficult to train such large networks due to high computational issues. Significant efforts have been made to make the training more efficient such as momentum, learning rate scheduling, weight regularization, and meta-learning. Based on our observations on 1) high correlation between past eights and future weights, 2) conditions for beneficial weight prediction, and 3) feasibility of weight prediction, we propose a more general framework by intermittently skipping a handful of epochs by periodically forecasting near future weights, i.e., a Weight Nowcaster Network (WNN). As an add-on module, WNN predicts the future weights to make the learning process faster regardless of tasks and architectures. Experimental results show that WNN can significantly save actual time cost for training with an additional marginal time to train WNN. We validate the generalization capability of WNN under various tasks, and demonstrate that it works well even for unseen tasks. The code and pre-trained model are available at https://github.com/jjh6297/WNN.

**摘要:** 最近的复杂问题需要大规模的数据集和复杂的模型架构,但由于高计算问题,很难训练大型网络。为了提高训练效率,已经作出了大量努力,例如:动量、学习率调度、体重调节和元学习。基于我们对(1)过去八分和未来重量之间的高相关性、(2)有益的重量预测条件和(3)重量预测的可行性的观察,我们建议通过周期性预测近未来重量,即一个重量分级网络(WNN)间歇地跳过一小 handful of epochs,提出一个更通用的框架。作为一个附加模块,WNN预测未来重量,使学习过程更快,而不影响任务和架构。实验结果表明,WNN可以大幅节省训练实际时间的费用。我们验证了WNN在各种任务下通用能力,并证明它甚至适用于未见任务。代码和预训练模型可于 https://github.com/jjh6297/WNN。

**[Paper URL](https://proceedings.mlr.press/v202/jang23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jang23b/jang23b.pdf)** 

# Unscented Autoencoder
**题目:** 未scented自动编码器

**作者:** Faris Janjos, Lars Rosenbaum, Maxim Dolgov, J. Marius Zoellner

**Abstract:** The Variational Autoencoder (VAE) is a seminal approach in deep generative modeling with latent variables. Interpreting its reconstruction process as a nonlinear transformation of samples from the latent posterior distribution, we apply the Unscented Transform (UT) – a well-known distribution approximation used in the Unscented Kalman Filter (UKF) from the field of filtering. A finite set of statistics called sigma points, sampled deterministically, provides a more informative and lower-variance posterior representation than the ubiquitous noise-scaling of the reparameterization trick, while ensuring higher-quality reconstruction. We further boost the performance by replacing the Kullback-Leibler (KL) divergence with the Wasserstein distribution metric that allows for a sharper posterior. Inspired by the two components, we derive a novel, deterministic-sampling flavor of the VAE, the Unscented Autoencoder (UAE), trained purely with regularization-like terms on the per-sample posterior. We empirically show competitive performance in Fréchet Inception Distance scores over closely-related models, in addition to a lower training variance than the VAE.

**摘要:** 变量自动编码器(Varitional Autoencoder,VAE)是基于潜伏变量进行深层生成模型的一个重要方法。它作为潜伏后向分布的样品非线性变换的重建过程,我们从滤波领域应用了无scented Transform(UT)——在无scented Kalman Filter(UKF)中使用的一种众所周知的分布近似。基于这两个组件的启发,我们得出一种新颖的确定性采样特性的VAE,即无scented Autoencoder(UAE),在每样品后部训练的纯正规则术语。我们通过实验显示了弗雷切特初始距离的竞争性表现,比VAE更低的训练差。

**[Paper URL](https://proceedings.mlr.press/v202/janjos23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/janjos23a/janjos23a.pdf)** 

# Curiosity in Hindsight: Intrinsic Exploration in Stochastic Environments
**题目:** 逆向好奇心:在随机环境中内在探索

**作者:** Daniel Jarrett, Corentin Tallec, Florent Altché, Thomas Mesnard, Remi Munos, Michal Valko

**Abstract:** Consider the problem of exploration in sparse-reward or reward-free environments, such as in Montezuma’s Revenge. In the curiosity-driven paradigm, the agent is rewarded for how much each realized outcome differs from their predicted outcome. But using predictive error as intrinsic motivation is fragile in stochastic environments, as the agent may become trapped by high-entropy areas of the state-action space, such as a "noisy TV". In this work, we study a natural solution derived from structural causal models of the world: Our key idea is to learn representations of the future that capture precisely the unpredictable aspects of each outcome—which we use as additional input for predictions, such that intrinsic rewards only reflect the predictable aspects of world dynamics. First, we propose incorporating such hindsight representations into models to disentangle "noise" from "novelty", yielding Curiosity in Hindsight: a simple and scalable generalization of curiosity that is robust to stochasticity. Second, we instantiate this framework for the recently introduced BYOL-Explore algorithm as our prime example, resulting in the noise-robust BYOL-Hindsight. Third, we illustrate its behavior under a variety of different stochasticities in a grid world, and find improvements over BYOL-Explore in hard-exploration Atari games with sticky actions. Notably, we show state-of-the-art results in exploring Montezuma’s Revenge with sticky actions, while preserving performance in the non-sticky setting.

**摘要:** 例如《蒙特苏玛的复仇》中的探索问题:在好奇心驱动的范式中,代理人被奖励,因为每个实现的结果与其预见的结果有多么不同。但在随机环境中,使用预测误差作为内在动机是脆弱的,因为代理人可能被“噪音电视”等状态行动空间的高 entropy区域困住。首先,我们提议将这些后视表示纳入模型中,以将“噪声”与“新事物”分开,从而产生“后视”的好奇心:一种简单可扩展的对随机性强的好奇心一般化。其次,我们将最近引入的BYOL-Explore算法作为我们的主要例子,从而产生噪声强的BYOL-Hindsight。

**[Paper URL](https://proceedings.mlr.press/v202/jarrett23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jarrett23a/jarrett23a.pdf)** 

# BiRT: Bio-inspired Replay in Vision Transformers for Continual Learning
**题目:** BiRT:持续学习的视觉变换器中生物灵感的重演

**作者:** Kishaan Jeeveswaran, Prashant Shivaram Bhat, Bahram Zonooz, Elahe Arani

**Abstract:** The ability of deep neural networks to continually learn and adapt to a sequence of tasks has remained challenging due to catastrophic forgetting of previously learned tasks. Humans, on the other hand, have a remarkable ability to acquire, assimilate, and transfer knowledge across tasks throughout their lifetime without catastrophic forgetting. The versatility of the brain can be attributed to the rehearsal of abstract experiences through a complementary learning system. However, representation rehearsal in vision transformers lacks diversity, resulting in overfitting and consequently, performance drops significantly compared to raw image rehearsal. Therefore, we propose BiRT, a novel representation rehearsal-based continual learning approach using vision transformers. Specifically, we introduce controllable noises at various stages of the vision transformer and enforce consistency in predictions with respect to an exponential moving average of the working model. Our method provides consistent performance gain over raw image and vanilla representation rehearsal on several challenging CL benchmarks while being memory efficient and robust to natural and adversarial corruptions.

**摘要:** 深层神经网络的持续学习和适应任务序列的能力,由于以往学习任务的灾难性遗忘,仍然是挑战性的。另一方面,人类在一生中无灾难性遗忘的情况下,有显著的能力获得、同化和传递知识。大脑的多样性可归因于通过互补学习系统进行抽象经验的练习。然而,视觉变换器的演示练习缺乏多样性,导致过度适应,因此,性能与原始图像演示相比大幅下降。因此,我们提出了一种基于视觉变换器的新型演示演示持续学习方法,即BiRT。具体地说,我们在视觉变换器的各个阶段引入可控噪声,并对工作模型的指数移动平均进行预测。该方法在几个具有挑战性的CLC指标的原始图像和瓦尼拉表现试演上提供一致的性能提升,同时具有良好的记忆效率和对自然和敌对腐败的鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/jeeveswaran23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jeeveswaran23a/jeeveswaran23a.pdf)** 

# Recovering Top-Two Answers and Confusion Probability in Multi-Choice Crowdsourcing
**题目:** 重拾多选择集群资源中的两大答案和混淆概率

**作者:** Hyeonsu Jeong, Hye Won Chung

**Abstract:** Crowdsourcing has emerged as an effective platform for labeling large amounts of data in a cost- and time-efficient manner. Most previous work has focused on designing an efficient algorithm to recover only the ground-truth labels of the data. In this paper, we consider multi-choice crowdsourcing tasks with the goal of recovering not only the ground truth, but also the most confusing answer and the confusion probability. The most confusing answer provides useful information about the task by revealing the most plausible answer other than the ground truth and how plausible it is. To theoretically analyze such scenarios, we propose a model in which there are the top two plausible answers for each task, distinguished from the rest of the choices. Task difficulty is quantified by the probability of confusion between the top two, and worker reliability is quantified by the probability of giving an answer among the top two. Under this model, we propose a two-stage inference algorithm to infer both the top two answers and the confusion probability. We show that our algorithm achieves the minimax optimal convergence rate. We conduct both synthetic and real data experiments and demonstrate that our algorithm outperforms other recent algorithms. We also show the applicability of our algorithms in inferring the difficulty of tasks and in training neural networks with top-two soft labels.

**摘要:** 大量数据的标记在成本和时间效率上已成为一个有效的平台,大部分以前的工作都集中在设计一个有效的算法来恢复数据的地面事实标记。本文,我们考虑了多选择的大量数据标记的任务,目标是恢复不仅地面事实,而且最混淆的答案和混淆概率。最混淆的答案通过揭示地面事实以外的最可信的答案以及它有多可信的信息提供有关任务的有益信息。在该模型下,我们提出了一种双级推导算法,以推导两个顶端答案和误解概率,并表明该算法达到最小值的最优收敛率。我们进行了合成和实数据实验,并证明该算法优于其他近来算法。我们还表明该算法在推导任务难度和训练两个顶端软标签的神经网络中的应用性。

**[Paper URL](https://proceedings.mlr.press/v202/jeong23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jeong23a/jeong23a.pdf)** 

# Leveraging Label Non-Uniformity for Node Classification in Graph Neural Networks
**题目:** 图神经网络中节点分类的标签不一致性利用

**作者:** Feng Ji, See Hian Lee, Hanyang Meng, Kai Zhao, Jielong Yang, Wee Peng Tay

**Abstract:** In node classification using graph neural networks (GNNs), a typical model generates logits for different class labels at each node. A softmax layer often outputs a label prediction based on the largest logit. We demonstrate that it is possible to infer hidden graph structural information from the dataset using these logits. We introduce the key notion of label non-uniformity, which is derived from the Wasserstein distance between the softmax distribution of the logits and the uniform distribution. We demonstrate that nodes with small label non-uniformity are harder to classify correctly. We theoretically analyze how the label non-uniformity varies across the graph, which provides insights into boosting the model performance: increasing training samples with high non-uniformity or dropping edges to reduce the maximal cut size of the node set of small non-uniformity. These mechanisms can be easily added to a base GNN model. Experimental results demonstrate that our approach improves the performance of many benchmark base models.

**摘要:** 在使用图神经网络(GNN)的节点分类中,一个典型的模型在每个节点生成不同类别的标签的标签。 Softmax层经常输出基于最大标签的标签预报。我们证明,使用这些标签可以推导隐藏的图结构信息。我们引入了标签不一致的关键概念,该概念是从逻辑的 Softmax分布和均匀分布之间的Waterstein距离得出的。我们证明,与小标签不一致的节点更难正确分类。我们从理论上分析了标签不一致在图中如何变化,从而提供提高模型性能的洞察力:增加与高非一致的训练样本或减少小非一致的节点集合的最大切削尺寸的边缘。这些机制可以轻易地添加到一个基本GNN模型。实验结果表明,我们的方法提高了许多基准模型的性能。

**[Paper URL](https://proceedings.mlr.press/v202/ji23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ji23a/ji23a.pdf)** 

# Bidirectional Adaptation for Robust Semi-Supervised Learning with Inconsistent Data Distributions
**题目:** 对不一致数据分布的鲁棒半监督学习的双向适应

**作者:** Lin-Han Jia, Lan-Zhe Guo, Zhi Zhou, Jie-Jing Shao, Yuke Xiang, Yu-Feng Li

**Abstract:** Semi-supervised learning (SSL) suffers from severe performance degradation when labeled and unlabeled data come from inconsistent data distributions. However, there is still a lack of sufficient theoretical guidance on how to alleviate this problem. In this paper, we propose a general theoretical framework that demonstrates how distribution discrepancies caused by pseudo-label predictions and target predictions can lead to severe generalization errors. Through theoretical analysis, we identify three main reasons why previous SSL algorithms cannot perform well with inconsistent distributions: coupling between the pseudo-label predictor and the target predictor, biased pseudo labels, and restricted sample weights. To address these challenges, we introduce a practical framework called Bidirectional Adaptation that can adapt to the distribution of unlabeled data for debiased pseudo-label prediction and to the target distribution for debiased target prediction, thereby mitigating these shortcomings. Extensive experimental results demonstrate the effectiveness of our proposed framework.

**摘要:** 半监督学习(英语:semi-supervised learning,缩写为SSL)在不一致的数据分布中出现标记和不标记数据时,其性能严重恶化。然而,如何缓解这一问题仍缺乏足够的理论指导。本文提出了一种一般理论框架,说明伪标记预测和目标预测所引起的分布差异如何导致严重推广误差。为了解决这些问题,我们引入了一种名为双向适应的实用框架,该框架可以适应不标记数据的分布,用于偏见伪标记预测,以及偏见目标预测的目标分布,从而减轻这些缺陷。

**[Paper URL](https://proceedings.mlr.press/v202/jia23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jia23a/jia23a.pdf)** 

# Short-lived High-volume Bandits
**题目:** 短寿命高体积强盗

**作者:** Su Jia, Nishant Oli, Ian Anderson, Paul Duff, Andrew A Li, R. Ravi

**Abstract:** Modern platforms leverage randomized experiments to make informed decisions from a given set of alternatives. As a particularly challenging scenario, these alternatives can potentially have (i) high volume, with thousands of new items being released each hour, and (ii) short lifetime, either due to the contents’ transient nature, or some underlying non-stationarity that impels the learner to treat the same item as non-identical copies across time. We consider a multiplay bandits model. In each round a set of $k=n^\rho$ actions that will be available for $w$ rounds arrives, each of whose mean reward is drawn from a fixed known distribution. The learner selects a multiset of $n$ actions at a time. We propose an $\ell$-Layered Sieve Policy that recursively refines the action space for $\ell\leq w$ times. We show that for any given $\rho>0$, with suitable $\ell$, the policy achieves $\tilde O (n^{-\min \{\rho, \frac 12 (1+\frac 1w)^{-1}\}})$ regret. We also complement this result with an $\Omega (n^{-\min \{\rho, \frac 12\}})$ lower bound. We further validate the effectiveness of our Sieve Policy via numerical simulations and a field experiment in a large content card serving platform.

**摘要:** 现代平台利用随机化实验来从给定的替代方案中做出知情的决定。作为一个特别挑战性的场景,这些替代方案可能有(i)高容量,每小时发布成千上万新项目,以及(ii)短寿命,要么是由于内容的过渡性,要么是由于某种潜在的非静态性,使学习者以非同等的复制方式处理同一项目。我们考虑一个多玩的 bandits 模型。在每个循环中,一个 $k=n^\rho$ 行动的集合会为 $w$ 轮到提供,每个平均奖赏是从固定的已知分布中提取。我们还用$\Omega(n^{-\min \{\rho, \frac 12\}})$下限来补充这个结果。我们通过数值模拟和在一个大型内容卡服务平台的现场实验进一步验证了我们的筛选策略的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/jia23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jia23b/jia23b.pdf)** 

# Smooth Non-stationary Bandits
**题目:** 平滑非静态强盗

**作者:** Su Jia, Qian Xie, Nathan Kallus, Peter I. Frazier

**Abstract:** In many applications of online decision making, the environment is non-stationary and it is therefore crucial to use bandit algorithms that handle changes. Most existing approaches are designed to protect against non-smooth changes, constrained only by total variation or Lipschitzness over time, where they guarantee $T^{2/3}$ regret. However, in practice environments are often changing smoothly, so such algorithms may incur higher-than-necessary regret in these settings and do not leverage information on the rate of change. In this paper, we study a non-stationary two-arm bandit problem where we assume an arm’s mean reward is a $\beta$-Hölder function over (normalized) time, meaning it is $(\beta-1)$-times Lipschitz-continuously differentiable. We show the first separation between the smooth and non-smooth regimes by presenting a policy with $T^{3/5}$ regret for $\beta=2$. We complement this result by a $T^{\frac{\beta+1}{2\beta+1}}$ lower bound for any integer $\beta\ge 1$, which matches our upper bound for $\beta=2$.

**摘要:** 在网络决策的许多应用中,环境是非静态的,因此使用处理变化的带式算法是至关重要的。大多数现有的方法是为了防止非平稳的变化,仅限于时间的总变化或利普希茨性,它们保证了$T^{2/3}$的遗憾。然而,在实践中,环境经常变化顺利,因此这些算法可能在这些设置中产生比必要更大的遗憾,并不会利用变化的速率的信息。我们用任何整数$\beta\ge 1$的$T^{\frac{\beta+1}{2\beta+1}}$下限来补充这个结果,这符合我们对$\beta=2$的上限。

**[Paper URL](https://proceedings.mlr.press/v202/jia23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jia23c/jia23c.pdf)** 

# A Unified Optimization Framework of ANN-SNN Conversion: Towards Optimal Mapping from Activation Values to Firing Rates
**题目:** ANN-SNN转换的统一优化框架:从活化值到启动率的优化映射

**作者:** Haiyan Jiang, Srinivas Anumasa, Giulia De Masi, Huan Xiong, Bin Gu

**Abstract:** Spiking Neural Networks (SNNs) have gained significant attention for their energy-efficient and fast-inference capabilities, but training SNNs from scratch can be challenging due to the discrete nature of spikes. One alternative method is to convert an Artificial Neural Network (ANN) into an SNN, known as ANN-SNN conversion. Currently, existing ANN-SNN conversion methods often involve redesigning the ANN with a new activation function, rather than utilizing the traditional ReLU, and converting it to an SNN. However, these methods do not take into account the potential performance loss between the regular ANN with ReLU and the tailored ANN. In this work, we propose a unified optimization framework for ANN-SNN conversion that considers both performance loss and conversion error. To achieve this, we introduce the SlipReLU activation function, which is a weighted sum of the threshold-ReLU and the step function. Theoretical analysis demonstrates that conversion error can be zero on a range of shift values $\delta \in [-0.5,0.5]$ rather than a fixed shift term 0.5. We evaluate our SlipReLU method on CIFAR datasets, which shows that SlipReLU outperforms current ANN-SNN conversion methods and supervised training methods in terms of accuracy and latency. To the best of our knowledge, this is the first ANN-SNN conversion method that enables SNN inference using only 1 time step. Code is available at https://github.com/HaiyanJiang/SNN_Conversion_unified.

**摘要:** 人工神经网络(SNN)的转换方法之一是将人工神经网络(ANN)转换为SNN,称为ANN-SNN转换。 目前,现有的ANN-SNN转换方法通常涉及重新设计ANN,使用新的激活功能,而不是使用传统的ReLU,并将其转换为SNN。然而,这些方法不考虑与ReLU和定制ANN的常规ANN之间的潜在性能损失。理论分析表明,转换误差可以在变换值 $\delta \in [-0.5,0.5]$范围内为零,而不是固定变换期0.5。我们对CIFAR数据集的SlipReLU方法进行了评估,表明SlipReLU比当前的ANN-SNN转换方法高,并且在精度和延迟方面监督培训方法。

**[Paper URL](https://proceedings.mlr.press/v202/jiang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jiang23a/jiang23a.pdf)** 

# VIMA: Robot Manipulation with Multimodal Prompts
**题目:** VIMA:多模板机器人操纵

**作者:** Yunfan Jiang, Agrim Gupta, Zichen Zhang, Guanzhi Wang, Yongqiang Dou, Yanjun Chen, Li Fei-Fei, Anima Anandkumar, Yuke Zhu, Linxi Fan

**Abstract:** Prompt-based learning has emerged as a successful paradigm in natural language processing, where a single general-purpose language model can be instructed to perform any task specified by input prompts. Yet task specification in robotics comes in various forms, such as imitating one-shot demonstrations, following language instructions, and reaching visual goals. They are often considered different tasks and tackled by specialized models. We show that a wide spectrum of robot manipulation tasks can be expressed with multimodal prompts, interleaving textual and visual tokens. Accordingly, we develop a new simulation benchmark that consists of thousands of procedurally-generated tabletop tasks with multimodal prompts, 600K+ expert trajectories for imitation learning, and a four-level evaluation protocol for systematic generalization. We design a transformer-based robot agent, VIMA, that processes these prompts and outputs motor actions autoregressively. VIMA features a recipe that achieves strong model scalability and data efficiency. It outperforms alternative designs in the hardest zero-shot generalization setting by up to $2.9\times$ task success rate given the same training data. With $10\times$ less training data, VIMA still performs $2.7\times$ better than the best competing variant. Code and video demos are available at https://vimalabs.github.io

**摘要:** 在自然语言处理中,基于即时学习已成为一个成功的范式,其中一个通用语言模型可以指导通过输入即时执行任何指定的任务。然而,机器人中的任务规范在各种形式出现,例如模仿一击演示、遵循语言指令和实现视觉目标。它们通常被认为是不同的任务,并由专门的模型处理。VIMA具有实现强的模型可扩展性和数据效率的配方。它在最困难的零射击一般化设置中超越了$2.9任务成功率与相同的训练数据相比的替代设计。与$10少的训练数据相比,VIMA仍比最好的竞争变量更好的$2.7。代码和视频 demo在 https://vimalabs.github.io

**[Paper URL](https://proceedings.mlr.press/v202/jiang23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jiang23b/jiang23b.pdf)** 

# Estimating Causal Effects using a Multi-task Deep Ensemble
**题目:** 使用多任务深集估计诱因效应

**作者:** Ziyang Jiang, Zhuoran Hou, Yiling Liu, Yiman Ren, Keyu Li, David Carlson

**Abstract:** A number of methods have been proposed for causal effect estimation, yet few have demonstrated efficacy in handling data with complex structures, such as images. To fill this gap, we propose Causal Multi-task Deep Ensemble (CMDE), a novel framework that learns both shared and group-specific information from the study population. We provide proofs demonstrating equivalency of CDME to a multi-task Gaussian process (GP) with a coregionalization kernel a priori. Compared to multi-task GP, CMDE efficiently handles high-dimensional and multi-modal covariates and provides pointwise uncertainty estimates of causal effects. We evaluate our method across various types of datasets and tasks and find that CMDE outperforms state-of-the-art methods on a majority of these tasks.

**摘要:** 为了填补这一空白,我们提出了一种新的框架,即Cusal Multi-task Deep Ensemble(CMDE),它从研究对象中学习共享和群体特有的信息。我们提供证明证明CDME与一个共同区域化内核的多任务高斯过程(GP)具有等价性。与多任务GP相比,CMDE有效地处理高维和多模量变量,并提供点wise不确定的因果影响估计。我们对各种数据集和任务中的方法进行了评估,发现CMDE在大多数任务中胜过最先进的方法。

**[Paper URL](https://proceedings.mlr.press/v202/jiang23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jiang23c/jiang23c.pdf)** 

# Online Restless Bandits with Unobserved States
**题目:** 网上无休止的强盗与未被观察到的国家

**作者:** Bowen Jiang, Bo Jiang, Jian Li, Tao Lin, Xinbing Wang, Chenghu Zhou

**Abstract:** We study the online restless bandit problem, where each arm evolves according to a Markov chain independently, and the reward of pulling an arm depends on both the current state of the corresponding Markov chain and the pulled arm. The agent (decision maker) does not know the transition functions and reward functions, and cannot observe the states of arms even after pulling. The goal is to sequentially choose which arms to pull so as to maximize the expected cumulative rewards collected. In this paper, we propose TSEETC, a learning algorithm based on Thompson Sampling with Episodic Explore-Then-Commit. The algorithm proceeds in episodes of increasing length and each episode is divided into exploration and exploitation phases. During the exploration phase, samples of action-reward pairs are collected in a round-robin fashion and utilized to update the posterior distribution as a mixture of Dirichlet distributions. At the beginning of the exploitation phase, TSEETC generates a sample from the posterior distribution as true parameters. It then follows the optimal policy for the sampled model for the rest of the episode. We establish the Bayesian regret bound $\tilde {\mathcal{O}}(\sqrt{T})$ for TSEETC, where $T$ is the time horizon. We show through simulations that TSEETC outperforms existing algorithms in regret.

**摘要:** 我们研究了网络无休止的盗贼问题,其中每个手臂独立根据马可夫链演化,而拉动手臂的报酬取决于相应的马可夫链和拉动手臂的当前状态。代理人(决策者)不知道过渡函数和报酬函数,甚至在拉动之后也无法观察手臂的状况。目标是连续选择拉动哪些手臂,以最大化所预期的累积报酬。在开发阶段开始时,TSEETC将后方分布的样本生成为真参数,然后对样本模型的剩余部分采取最佳策略。我们为TSEETC建立了 Bayesian regret bound $\tilde {\mathcal{O}}(\sqrt{T})$, 其中 $T$ 是时间地平线。

**[Paper URL](https://proceedings.mlr.press/v202/jiang23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jiang23d/jiang23d.pdf)** 

# Detecting Out-of-distribution Data through In-distribution Class Prior
**题目:** 通过前置分发类检测非分发数据

**作者:** Xue Jiang, Feng Liu, Zhen Fang, Hong Chen, Tongliang Liu, Feng Zheng, Bo Han

**Abstract:** Given a pre-trained in-distribution (ID) model, the inference-time out-of-distribution (OOD) detection aims to recognize OOD data during the inference stage. However, some representative methods share an unproven assumption that the probability that OOD data belong to every ID class should be the same, i.e., these OOD-to-ID probabilities actually form a uniform distribution. In this paper, we show that this assumption makes the above methods incapable when the ID model is trained with class-imbalanced data.Fortunately, by analyzing the causal relations between ID/OOD classes and features, we identify several common scenarios where the OOD-to-ID probabilities should be the ID-class-prior distribution and propose two strategies to modify existing inference-time detection methods: 1) replace the uniform distribution with the ID-class-prior distribution if they explicitly use the uniform distribution; 2) otherwise, reweight their scores according to the similarity between the ID-class-prior distribution and the softmax outputs of the pre-trained model. Extensive experiments show that both strategies can improve the OOD detection performance when the ID model is pre-trained with imbalanced data, reflecting the importance of ID-class prior in OOD detection.

**摘要:** 基于预训练的内部分布(ID)模型,推导时间外分布(OOD)检测的目的在于在推导阶段识别OOD数据。然而,一些代表性的方法共享一个未经证实的假设,即OOD数据属于每个ID类的概率应该相同,即这些OOD-到ID概率实际上构成一个统一的分布。通过对ID/OOD类与特征之间的因果关系进行分析,我们确定了几个共同的场景,其中OOD-to-ID概率应该是ID-class-prior分布,并提出了两种修改现有推断时间检测方法的方法: 1)如果它们明确使用均匀分布,则将均匀分布换成ID-class-prior分布; 2)否则,根据ID-class-prior分布与预训练模型的软最大输出的相似性重新权重其分数。

**[Paper URL](https://proceedings.mlr.press/v202/jiang23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jiang23e/jiang23e.pdf)** 

# Towards Stable and Efficient Adversarial Training against $l_1$ Bounded Adversarial Attacks
**题目:** 以稳固和高效的敌对训练为目标,对抗 $1.1的受限敌对攻击

**作者:** Yulun Jiang, Chen Liu, Zhichao Huang, Mathieu Salzmann, Sabine Susstrunk

**Abstract:** We address the problem of stably and efficiently training a deep neural network robust to adversarial perturbations bounded by an $l_1$ norm. We demonstrate that achieving robustness against $l_1$-bounded perturbations is more challenging than in the $l_2$ or $l_\infty$ cases, because adversarial training against $l_1$-bounded perturbations is more likely to suffer from catastrophic overfitting and yield training instabilities. Our analysis links these issues to the coordinate descent strategy used in existing methods. We address this by introducing Fast-EG-$l_1$, an efficient adversarial training algorithm based on Euclidean geometry and free of coordinate descent. Fast-EG-$l_1$ comes with no additional memory costs and no extra hyper-parameters to tune. Our experimental results on various datasets demonstrate that Fast-EG-$l_1$ yields the best and most stable robustness against $l_1$-bounded adversarial attacks among the methods of comparable computational complexity. Code and the checkpoints are available at https://github.com/IVRL/FastAdvL.

**摘要:** 我们解决了由$l_1$规范约束的敌对扰动强有力的深神经网络稳固和有效的训练问题。我们证明,在$l_2$或$l_\infty$案例中实现对$l_1$约束扰动的鲁棒性比挑战性更大,因为对$l_1$约束扰动的敌对训练更有可能 suffer from catastrophic overfitting and yield training instabilities。我们的分析将这些问题与现有方法中使用的坐标下降策略联系起来。我们通过引入快速EG-$l_1$,基于欧氏几何和无坐标下降的高效的敌对训练算法来解决这个问题。代码和检查点可以在 https://github.com/IVRL/FastAdvL上找到。

**[Paper URL](https://proceedings.mlr.press/v202/jiang23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jiang23f/jiang23f.pdf)** 

# Learning Unnormalized Statistical Models via Compositional Optimization
**题目:** 通过组合优化学习非正常统计模型

**作者:** Wei Jiang, Jiayu Qin, Lingyu Wu, Changyou Chen, Tianbao Yang, Lijun Zhang

**Abstract:** Learning unnormalized statistical models (e.g., energy-based models) is computationally challenging due to the complexity of handling the partition function. To eschew this complexity, noise-contrastive estimation (NCE) has been proposed by formulating the objective as the logistic loss of the real data and the artificial noise. However, as found in previous works, NCE may perform poorly in many tasks due to its flat loss landscape and slow convergence. In this paper, we study a direct approach for optimizing the negative log-likelihood of unnormalized models from the perspective of compositional optimization. To tackle the partition function, a noise distribution is introduced such that the log partition function can be written as a compositional function whose inner function can be estimated with stochastic samples. Hence, the objective can be optimized by stochastic compositional optimization algorithms. Despite being a simple method, we demonstrate that it is more favorable than NCE by (1) establishing a fast convergence rate and quantifying its dependence on the noise distribution through the variance of stochastic estimators; (2) developing better results for one-dimensional Gaussian mean estimation by showing our objective has a much favorable loss landscape and hence our method enjoys faster convergence; (3) demonstrating better performance on multiple applications, including density estimation, out-of-distribution detection, and real image generation.

**摘要:** 学习非正常统计模型(例如基于能量的模型)是由于处理分区函数的复杂性而具有计算挑战性。为了避免这种复杂性,提出了噪声对比估计(NCE),将目标定为实际数据的物流损失和人工噪声。然而,如以往的工作所发现,NCE在许多任务中由于其平滑的损失景观和缓慢的收敛性可能 perform poorly。本文从组合优化的角度研究了优化非正常模型负逻辑概率的直接方法。该方法虽然简单,但通过(一)建立快速收敛率并通过随机估计器的变异量量化其对噪声分布的依赖性;(二)通过显示目标具有较有利的损失景观,为单维高斯平均估计提供更好的结果,从而使该方法具有较快的收敛性;(三)在多个应用中表现出较好的性能,包括密度估计、外散检测和真实图像生成。

**[Paper URL](https://proceedings.mlr.press/v202/jiang23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jiang23g/jiang23g.pdf)** 

# Approximate Causal Effect Identification under Weak Confounding
**题目:** 弱混淆下近似因果识别

**作者:** Ziwei Jiang, Lai Wei, Murat Kocaoglu

**Abstract:** Causal effect estimation has been studied by many researchers when only observational data is available. Sound and complete algorithms have been developed for pointwise estimation of identifiable causal queries. For non-identifiable causal queries, researchers developed polynomial programs to estimate tight bounds on causal effect. However, these are computationally difficult to optimize for variables with large support sizes. In this paper, we analyze the effect of "weak confounding’" on causal estimands. More specifically, under the assumption that the unobserved confounders that render a query non-identifiable have small entropy, we propose an efficient linear program to derive the upper and lower bounds of the causal effect. We show that our bounds are consistent in the sense that as the entropy of unobserved confounders goes to zero, the gap between the upper and lower bound vanishes. Finally, we conduct synthetic and real data simulations to compare our bounds with the bounds obtained by the existing work that cannot incorporate such entropy constraints and show that our bounds are tighter for the setting with weak confounders.

**摘要:** 对可辨认的因果查询进行点wise估计,开发了健全和完整的算法。 对于非辨认的因果查询,研究人员开发了多项式程序来估计因果效应的狭窄边界。然而,对于大支持大小的变量来说,这些变量是计算上难以优化的。本文分析了“弱混淆”对因果估计数的影响。具体地说,根据假设使查询不可辨认的未观察的混淆者具有小熵,我们提出了一种有效的线性程序来推导因果效应的上和下边界。我们证明我们的边界是一致的,因为当未观察的混淆者的熵达到零时,上和下边界之间的差距就会消失。最后,我们进行了合成和实际数据仿真,以比较我们界限与现有工作所取得的界限,这些界限不能包含这样的熵约束,并表明我们界限对于弱混淆条件来说更紧。

**[Paper URL](https://proceedings.mlr.press/v202/jiang23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jiang23h/jiang23h.pdf)** 

# MEWL: Few-shot multimodal word learning with referential uncertainty
**题目:** MEWL:少 shot多型词汇学习与参考不确定

**作者:** Guangyuan Jiang, Manjie Xu, Shiji Xin, Wei Liang, Yujia Peng, Chi Zhang, Yixin Zhu

**Abstract:** Without explicit feedback, humans can rapidly learn the meaning of words. Children can acquire a new word after just a few passive exposures, a process known as fast mapping. This word learning capability is believed to be the most fundamental building block of multimodal understanding and reasoning. Despite recent advancements in multimodal learning, a systematic and rigorous evaluation is still missing for human-like word learning in machines. To fill in this gap, we introduce the MachinE Word Learning (MEWL) benchmark to assess how machines learn word meaning in grounded visual scenes. MEWL covers human’s core cognitive toolkits in word learning: cross-situational reasoning, bootstrapping, and pragmatic learning. Specifically, MEWL is a few-shot benchmark suite consisting of nine tasks for probing various word learning capabilities. These tasks are carefully designed to be aligned with the children’s core abilities in word learning and echo the theories in the developmental literature. By evaluating multimodal and unimodal agents’ performance with a comparative analysis of human performance, we notice a sharp divergence in human and machine word learning. We further discuss these differences between humans and machines and call for human-like few-shot word learning in machines.

**摘要:** 没有明确的反馈,人类可以快速地学习词义。在少数被动的曝光后,儿童可以获得新的词义,这一过程被称为快速映射。这一词义学习能力被认为是多模态理解和推理的最基本的建筑物。尽管多模态学习最近取得了进展,但对于机器中的类似人类的词义学习仍然缺乏系统和严格的评价。为了填补这个空白,我们引入MachineE词义学习(MEWL)基准来评估机器如何在基础的视觉场景中学习词义。MEWL涵盖词义学习中人类的核心认知工具包:交叉情景推理、引导和实用学习。这些任务 carefully designed to be aligned with the children’s core abilities in word learning and echo the theories in the developmental literature. By evaluating multimodal and unimodal agents’ performance with a comparative analysis of human performance, we notice a sharp divergence in human and machine word learning. We further discuss these differences between humans and machines and call for human-like few-shot word learning in machines. 这些任务 carefully designed to be aligned with the children’s core abilities in word learning and echo the theories in the developmental literature. By evaluating multimodal and unimodal agents’ performance with a comparative analysis of human performance, we notice a sharp divergence in human and machine word learning. We further discuss these differences between humans and machines and call for human-like few-shot word learning in machines.

**[Paper URL](https://proceedings.mlr.press/v202/jiang23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jiang23i/jiang23i.pdf)** 

# NeuralSlice: Neural 3D Triangle Mesh Reconstruction via Slicing 4D Tetrahedral Meshes
**题目:** NeuralSlice:神经3D三角网格重建通过剪切4D四面网格

**作者:** Chenbo Jiang, Jie Yang, Shwai He, Yu-Kun Lai, Lin Gao

**Abstract:** Learning-based high-fidelity reconstruction of 3D shapes with varying topology is a fundamental problem in computer vision and computer graphics. Recent advances in learning 3D shapes using explicit and implicit representations have achieved impressive results in 3D modeling. However, the template-based explicit representation is limited by fixed topology, and the implicit representation, although flexible with arbitrary topology, requires a large number of sampled points to regress the surface, which is computationally expensive. In this work, we propose a novel 3D shape representation named NeuralSlice, which represents a 3D shape as the intersection of a 4D tetrahedral mesh and a 4D hyperplane. A novel network is designed to incorporate the proposed representation flexibly, which learns a deformable 4D template and a parameter for slicing 4D hyperplane to reconstruct the 3D object. To learn the local deformation of the 4D template, we further propose a spatial-aware network to locate the 4D points within the 3D feature volume of input shape via positional encoding, which leverages the local geometrical feature to guide the 4D deformation. By addressing the 3D problem in a higher 4D space, our method supports flexible topology changes while being highly efficient. Our method is guaranteed to produce manifold meshes. NeuralSlice outperforms the state-of-the-art explicit-based approaches in terms of reconstruction quality. Compared with implicit approaches, by avoiding point sampling, our method is 10 times faster than the implicit approaches, and better preserves thin structures. NeuralSlice has the capability of representing various shapes and topologies using a single 4D tetrahedral mesh. The corresponding code can be found on GitHub at https://github.com/IGLICT/NEURALSLICE

**摘要:** 基于学习的具有不同拓扑的3D形状的高可靠性重建是计算机视觉和计算机图形的基本问题。最近在学习使用显式和隐式表示的3D形状方面取得的进展在3D建模中取得了令人印象深刻的结果。然而,基于模板的显式表示受到固定拓扑的限制,而隐式表示虽然具有任意拓扑的灵活性,需要大量的样品点来回归表面,这在计算上是昂贵的。为了学习4D模板的局部变形,我们进一步提出一个空间意识的网络,通过定位编码在输入形状的3D特征体积内定位4D点,从而利用局部几何特征来指导4D变形。通过解决高4D空间的3D问题,我们的方法支持灵活的拓扑变化,同时具有很高的效率。我们的方法保证可以产生多重网格。NeuralSlice超越了最先进的明确的重建质量方法。与隐形方法相比,通过避免点采样,我们的方法比隐形方法快10倍,更有效地保存薄型结构。

**[Paper URL](https://proceedings.mlr.press/v202/jiang23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jiang23j/jiang23j.pdf)** 

# Effective Structured Prompting by Meta-Learning and Representative Verbalizer
**题目:** 基于Meta-Learning和代表验证器的有效的结构化提示

**作者:** Weisen Jiang, Yu Zhang, James Kwok

**Abstract:** Prompt tuning for pre-trained masked language models (MLM) has shown promising performance in natural language processing tasks with few labeled examples. It tunes a prompt for the downstream task, and a verbalizer is used to bridge the predicted token and label prediction. Due to the limited training data, prompt initialization is crucial for prompt tuning. Recently, MetaPrompting (Hou et al., 2022) uses meta-learning to learn a shared initialization for all task-specific prompts. However, a single initialization is insufficient to obtain good prompts for all tasks and samples when the tasks are complex. Moreover, MetaPrompting requires tuning the whole MLM, causing a heavy burden on computation and memory as the MLM is usually large. To address these issues, we use a prompt pool to extract more task knowledge and construct instance-dependent prompts via attention. We further propose a novel soft verbalizer (RepVerb) which constructs label embedding from feature embeddings directly. Combining meta-learning the prompt pool and RepVerb, we propose MetaPrompter for effective structured prompting. MetaPrompter is parameter-efficient as only the pool is required to be tuned. Experimental results demonstrate that MetaPrompter performs better than the recent state-of-the-arts and RepVerb outperforms existing soft verbalizers.

**摘要:** 预训练的隐形语言模型(MLM)的调试显示了在自然语言处理任务中具有少数标记的例子的良好表现。它调试了下游任务的调试,并使用调试器来桥接预定的符号和标记预测。由于有限的训练数据,调试的初始化对于调试至关重要。最近,MetaPrompting(Hou et al., 2022)使用Meta-learning来学习所有任务特定调试的共享初始化。然而,单一的初始化不足以获得所有任务和样品的良好调试。结合元学习的提示池和RepVerb,我们提出了有效的结构提示的MetaPrompter。MetaPrompter是参数效率高的,因为只有该池需要调动。实验结果表明MetaPrompter比最新技术性能更好,而RepVerb比现有的软语法化器更好。

**[Paper URL](https://proceedings.mlr.press/v202/jiang23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jiang23k/jiang23k.pdf)** 

# Understanding Incremental Learning of Gradient Descent: A Fine-grained Analysis of Matrix Sensing
**题目:** 渐进进进化学习的理解:矩阵感知的细微分析

**作者:** Jikai Jin, Zhiyuan Li, Kaifeng Lyu, Simon Shaolei Du, Jason D. Lee

**Abstract:** It is believed that Gradient Descent (GD) induces an implicit bias towards good generalization in training machine learning models. This paper provides a fine-grained analysis of the dynamics of GD for the matrix sensing problem, whose goal is to recover a low-rank ground-truth matrix from near-isotropic linear measurements. It is shown that GD with small initialization behaves similarly to the greedy low-rank learning heuristics and follows an incremental learning procedure: GD sequentially learns solutions with increasing ranks until it recovers the ground truth matrix. Compared to existing works which only analyze the first learning phase for rank-1 solutions, our result provides characterizations for the whole learning process. Moreover, besides the over-parameterized regime that many prior works focused on, our analysis of the incremental learning procedure also applies to the under-parameterized regime. Finally, we conduct numerical experiments to confirm our theoretical findings.

**摘要:** 本文为矩阵感知问题提供了精细的矩阵动力学分析,其目标是从近等离子线性测量中恢复低级地基实矩阵。该研究表明,具有小初始化的矩阵行为类似于贪婪的低级 learning heuristics,并遵循渐进 learning 程序: 矩阵在恢复地基实矩阵之前,在渐进 learning 程序的基础上,逐级地学习解决方案。与现有研究只对 rank-1 解决方案的初级学习阶段进行分析的研究相比,我们的结果为整个学习过程提供了特征。最后, 我们进行了数值实验, 证实了我们的理论发现.

**[Paper URL](https://proceedings.mlr.press/v202/jin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jin23a/jin23a.pdf)** 

# Thompson Sampling with Less Exploration is Fast and Optimal
**题目:** 汤普森采样与少量探索是快速和最佳

**作者:** Tianyuan Jin, Xianglin Yang, Xiaokui Xiao, Pan Xu

**Abstract:** We propose $\epsilon$-Exploring Thompson Sampling ($\epsilon$-TS), a modified version of the Thompson Sampling (TS) algorithm for multi-armed bandits. In $\epsilon$-TS, arms are selected greedily based on empirical mean rewards with probability $1-\epsilon$, and based on posterior samples obtained from TS with probability $\epsilon$. Here, $\epsilon\in(0,1)$ is a user-defined constant. By reducing exploration, $\epsilon$-TS improves computational efficiency compared to TS while achieving better regret bounds. We establish that $\epsilon$-TS is both minimax optimal and asymptotically optimal for various popular reward distributions, including Gaussian, Bernoulli, Poisson, and Gamma. A key technical advancement in our analysis is the relaxation of the requirement for a stringent anti-concentration bound of the posterior distribution, which was necessary in recent analyses that achieved similar bounds. As a result, $\epsilon$-TS maintains the posterior update structure of TS while minimizing alterations, such as clipping the sampling distribution or solving the inverse of the Kullback-Leibler (KL) divergence between reward distributions, as done in previous work. Furthermore, our algorithm is as easy to implement as TS, but operates significantly faster due to reduced exploration. Empirical evaluations confirm the efficiency and optimality of $\epsilon$-TS.

**摘要:** 我们提出:$epsilon-Exploring Thompson Sampling ($\epsilon$-TS), 为多武器 bandits 的 Thompson Sampling (TS) 算法的修改版本. 在 $\epsilon$-TS 中, 武器 是 贪婪地根据 概率 $\epsilon$ 的 经验 平均 奖励 选择, 并 根据 概率 $\epsilon$ 的 TS 获得 的 后方 样本 。 这里, $\epsilon\in(0,1)$ 是 用户 定义 的 常数. 通过 减少 探索, $\epsilon$-TS 改进 了 与 TS 相比 的 计算 效率, 同时 达到 更好 的 遗憾 边界 。 我们 确定 $\e因此,$\epsilon$-TS可以保持TS的后置更新结构,同时最小化修改,如剪切样品分布或像以前的工作那样解决 Kullback-Leibler (KL) 间的奖励分布的逆差。此外,我们的算法同样易于实现,但由于较少的探索,运行得更快。经验评估证实$\epsilon$-TS的效率和最佳性。

**[Paper URL](https://proceedings.mlr.press/v202/jin23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jin23b/jin23b.pdf)** 

# R-U-SURE? Uncertainty-Aware Code Suggestions By Maximizing Utility Across Random User Intents
**题目:** R-U-SURE?通过在随机用户意图中最大化实用性来认识不确定性的代码建议

**作者:** Daniel D. Johnson, Daniel Tarlow, Christian Walder

**Abstract:** Large language models show impressive results at predicting structured text such as code, but also commonly introduce errors and hallucinations in their output. When used to assist software developers, these models may make mistakes that users must go back and fix, or worse, introduce subtle bugs that users may miss entirely. We propose Randomized Utility-driven Synthesis of Uncertain REgions (R-U-SURE), an approach for building uncertainty-aware suggestions based on a decision-theoretic model of goal-conditioned utility, using random samples from a generative model as a proxy for the unobserved possible intents of the end user. Our technique combines minimum-Bayes-risk decoding, dual decomposition, and decision diagrams in order to efficiently produce structured uncertainty summaries, given only sample access to an arbitrary generative model of code and an optional AST parser. We demonstrate R-U-SURE on three developer-assistance tasks, and show that it can be applied different user interaction patterns without retraining the model and leads to more accurate uncertainty estimates than token-probability baselines. We also release our implementation as an open-source library at https://github.com/google-research/r_u_sure.

**摘要:** 大型语言模型在预测结构性文本(例如代码)时显示出令人印象深刻的结果,但也经常在输出中引入错误和幻觉。当这些模型用于协助软件开发者时,这些模型可能产生用户必须返回并修正的错误,或者更糟糕的是,引入用户可能完全错过的微妙错误。我们建议采用随机实用工具驱动的无确定区域综合(R-U-SURE),一种基于目标条件实用工具的决策理论模型的无确定意识建议的构建方法,使用生成模型的随机样本作为最终用户可能未观察到的潜在意图的代理。我们的技术结合了最小贝斯风险解码、双重分解和决策图,以有效生成结构性无确定摘要,仅提供给任意代码生成模型和可选AST解析器的样本访问。我们展示了R-U-SURE在三个开发人员协助任务上,并表明它可以在没有重新训练模型的情况下应用不同的用户交互模式,从而比托克概率基线更准确的不确定性估计。我们还在 https://github.com/google-research/r_u_sure 上作为开放源库发布我们的实现。

**[Paper URL](https://proceedings.mlr.press/v202/johnson23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/johnson23a/johnson23a.pdf)** 

# Automatically Auditing Large Language Models via Discrete Optimization
**题目:** 通过离散优化自动审核大型语言模型

**作者:** Erik Jones, Anca Dragan, Aditi Raghunathan, Jacob Steinhardt

**Abstract:** Auditing large language models for unexpected behaviors is critical to preempt catastrophic deployments, yet remains challenging. In this work, we cast auditing as an optimization problem, where we automatically search for input-output pairs that match a desired target behavior. For example, we might aim to find a non-toxic input that starts with “Barack Obama” that a model maps to a toxic output. This optimization problem is difficult to solve as the set of feasible points is sparse, the space is discrete, and the language models we audit are non-linear and high-dimensional. To combat these challenges, we introduce a discrete optimization algorithm, ARCA, that jointly and efficiently optimizes over inputs and outputs. Our approach automatically uncovers derogatory completions about celebrities (e.g. "Barack Obama is a legalized unborn" –$>$ "child murderer"), produces French inputs that complete to English outputs, and finds inputs that generate a specific name. Our work offers a promising new tool to uncover models’ failure-modes before deployment. Content Warning: This paper contains examples that may be offensive in nature.

**摘要:** 对意外行为的大型语言模型进行审计是防止灾难性部署的关键,但仍然是挑战性的。在这个工作中,我们将审计作为优化问题,我们自动寻找符合预期目标行为的输入输出对。例如,我们可能的目标是找到与“巴拉克·奥巴马”开始的非毒性输入,该模型映射出毒性输出。由于 feasible points的集合稀疏,空间是离散,而我们审计的语言模型是非线性和高维的,所以很难解决这种优化问题。我们的工作提供了一种有望的新工具,以揭示模型在部署前失效模式。

**[Paper URL](https://proceedings.mlr.press/v202/jones23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jones23a/jones23a.pdf)** 

# On the Expressive Power of Geometric Graph Neural Networks
**题目:** 几何图神经网络的表达能力

**作者:** Chaitanya K. Joshi, Cristian Bodnar, Simon V Mathis, Taco Cohen, Pietro Lio

**Abstract:** The expressive power of Graph Neural Networks (GNNs) has been studied extensively through the Weisfeiler-Leman (WL) graph isomorphism test. However, standard GNNs and the WL framework are inapplicable for geometric graphs embedded in Euclidean space, such as biomolecules, materials, and other physical systems. In this work, we propose a geometric version of the WL test (GWL) for discriminating geometric graphs while respecting the underlying physical symmetries: permutations, rotation, reflection, and translation. We use GWL to characterise the expressive power of geometric GNNs that are invariant or equivariant to physical symmetries in terms of distinguishing geometric graphs. GWL unpacks how key design choices influence geometric GNN expressivity: (1) Invariant layers have limited expressivity as they cannot distinguish one-hop identical geometric graphs; (2) Equivariant layers distinguish a larger class of graphs by propagating geometric information beyond local neighbourhoods; (3) Higher order tensors and scalarisation enable maximally powerful geometric GNNs; and (4) GWL’s discrimination-based perspective is equivalent to universal approximation. Synthetic experiments supplementing our results are available at https://github.com/chaitjo/geometric-gnn-dojo

**摘要:**  Graph Neural Networks(GNN)的表达能力通过Weisfeiler-Leman(WL)图同构性测试进行了广泛研究。然而,标准GNN和WL框架不适用于在欧几里亚空间内嵌入的几何图,如生物分子、材料和其他物理系统。在本文中,我们建议采用WL测试(GWL)的几何版本,以区分几何图 while respecting the underlying physical symmetries: permutations, rotation, reflection, and translation。GWL揭示了关键设计选择如何影响几何GNN表达性: (1)不变层具有有限的表达性,因为它们不能区分一个hop相同的几何图; (2)等变层通过在局部地区以外传播几何信息来区分更大的图类; (3)高阶拉伸和标量化使最大功率的几何GNN; (4)GWL基于歧视的视角等同于普遍近似。

**[Paper URL](https://proceedings.mlr.press/v202/joshi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/joshi23a/joshi23a.pdf)** 

# Data-Efficient Contrastive Self-supervised Learning: Most Beneficial Examples for Supervised Learning Contribute the Least
**题目:** 数据效率相反的自我监督学习:监督学习最有益的例子最有助于

**作者:** Siddharth Joshi, Baharan Mirzasoleiman

**Abstract:** Self-supervised learning (SSL) learns high-quality representations from large pools of unlabeled training data. As datasets grow larger, it becomes crucial to identify the examples that contribute the most to learning such representations. This enables efficient SSL by reducing the volume of data required. Nevertheless, quantifying the value of examples for SSL has remained an open question. In this work, we address this problem for the first time, by proving that examples that contribute the most to contrastive SSL are those that have the most similar augmentations to other examples, in expectation. We provide rigorous guarantees for the generalization performance of contrastive learning on such subsets. Through extensive experiments, we show that we can safely exclude 20% of examples from CIFAR100 and 40% from STL10 and TinyImageNet, without affecting downstream task performance. In general, subsets selected by our method outperform random subsets by over 3% across these datasets. Interestingly, we also discover the subsets that contribute the most to contrastive learning are those that contribute the least to supervised learning.

**摘要:** 自我监督学习(SSL)从不标记训练数据的大池中学习高质量的表示。随着数据集的增长,识别那些最有助于学习这些表示的实例变得至关重要。这通过减少所需数据的数量来实现有效的SSL。然而,SSL的实例价值的定量仍然是一个开放的问题。在这个工作中,我们第一次解决了这个问题,证明那些最有助于对比性SSL的实例是那些对其他实例有最相似的增加的实例,在期望中。我们为这些实例的对比性学习的一般化性能提供严格的保证。有趣的是,我们还发现那些对对比性学习最有贡献的子集是那些对监督性学习最有贡献的子集。

**[Paper URL](https://proceedings.mlr.press/v202/joshi23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/joshi23b/joshi23b.pdf)** 

# Robust Subtask Learning for Compositional Generalization
**题目:** 复合广义化鲁棒子任务学习

**作者:** Kishor Jothimurugan, Steve Hsu, Osbert Bastani, Rajeev Alur

**Abstract:** Compositional reinforcement learning is a promising approach for training policies to perform complex long-horizon tasks. Typically, a high-level task is decomposed into a sequence of subtasks and a separate policy is trained to perform each subtask. In this paper, we focus on the problem of training subtask policies in a way that they can be used to perform any task; here, a task is given by a sequence of subtasks. We aim to maximize the worst-case performance over all tasks as opposed to the average-case performance. We formulate the problem as a two agent zero-sum game in which the adversary picks the sequence of subtasks. We propose two RL algorithms to solve this game: one is an adaptation of existing multi-agent RL algorithms to our setting and the other is an asynchronous version which enables parallel training of subtask policies. We evaluate our approach on two multi-task environments with continuous states and actions and demonstrate that our algorithms outperform state-of-the-art baselines.

**摘要:** 复合强化学习是训练策略执行复杂长期任务的一个有前途的途径。通常,高级别任务分解为次级任务的序列,并训练一个单独的策略执行每个次级任务。本论文着重讨论训练次级任务策略的问题,以使它们能够用于执行任何任务;在这里,任务由次级任务的序列给出。我们的目标是使所有任务的最坏情况达到最优,而不是平均情况。我们拟定问题为两个代理零sum游戏,其中对手选择次级任务的序列。我们提出了两个RL算法来解决该游戏:一种是适应现有的多代理RL算法到我们的设置,而另一种是使次级任务策略进行并行训练的非同步版本。我们对连续状态和行动的两个多任务环境的处理方法进行了评估,并证明了我们的算法超过了最先进的基线。

**[Paper URL](https://proceedings.mlr.press/v202/jothimurugan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jothimurugan23a/jothimurugan23a.pdf)** 

# On Bridging the Gap between Mean Field and Finite Width Deep Random Multilayer Perceptron with Batch Normalization
**题目:** 批量规范与深随机多层感应器的平均场与有限宽间隙的结合

**作者:** Amir Joudaki, Hadi Daneshmand, Francis Bach

**Abstract:** Mean-field theory is widely used in theoretical studies of neural networks. In this paper, we analyze the role of depth in the concentration of mean-field predictions for Gram matrices of hidden representations in deep multilayer perceptron (MLP) with batch normalization (BN) at initialization. It is postulated that the mean-field predictions suffer from layer-wise errors that amplify with depth. We demonstrate that BN avoids this error amplification with depth. When the chain of hidden representations is rapidly mixing, we establish a concentration bound for a mean-field model of Gram matrices. To our knowledge, this is the first concentration bound that does not become vacuous with depth for standard MLPs with a finite width.

**摘要:** 中场理论在神经网络理论研究中被广泛应用。本文分析了在初始化时与批量规范化(BN)相结合的深层多层感知tron(MLP)中隐藏的格拉姆矩阵中中中场预测的深度浓度作用,推测中场预测 suffer from layer-wise errors that amplify with depth. We demonstrate that BN avoids this error amplification with depth. When the chain of hidden representations is rapidly mixing, we establish a concentration bound for a mean-field model of Gram matrices. To our knowledge, this is the first concentration bound that does not become vacuous with depth for standard MLPs with a finite width.

**[Paper URL](https://proceedings.mlr.press/v202/joudaki23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/joudaki23a/joudaki23a.pdf)** 

# FARE: Provably Fair Representation Learning with Practical Certificates
**题目:** 分享:用实际证书学习可行的公平代表

**作者:** Nikola Jovanović, Mislav Balunovic, Dimitar Iliev Dimitrov, Martin Vechev

**Abstract:** Fair representation learning (FRL) is a popular class of methods aiming to produce fair classifiers via data preprocessing. Recent regulatory directives stress the need for FRL methods that provide practical certificates, i.e., provable upper bounds on the unfairness of any downstream classifier trained on preprocessed data, which directly provides assurance in a practical scenario. Creating such FRL methods is an important challenge that remains unsolved. In this work, we address that challenge and introduce FARE (Fairness with Restricted Encoders), the first FRL method with practical fairness certificates. FARE is based on our key insight that restricting the representation space of the encoder enables the derivation of practical guarantees, while still permitting favorable accuracy-fairness tradeoffs for suitable instantiations, such as one we propose based on fair trees. To produce a practical certificate, we develop and apply a statistical procedure that computes a finite sample high-confidence upper bound on the unfairness of any downstream classifier trained on FARE embeddings. In our comprehensive experimental evaluation, we demonstrate that FARE produces practical certificates that are tight and often even comparable with purely empirical results obtained by prior methods, which establishes the practical value of our approach.

**摘要:** 公平表示学习(FRL)是一种旨在通过数据预处理产生公平分类器的方法。最近的监管指令强调提供实用证书的FRL方法的必要性,即在预处理数据上训练的任何下游分类器的不公平上可证明的上限,直接在实际场景中提供保证。为了产生实用证书,我们开发和应用了一种统计程序,计算了基于FARE嵌入式训练的任何下游分类器的不公平性上的高信任上限有限样本。在我们的全面实验评价中,我们证明了FARE产生严格的实用证书,甚至与以往方法取得的纯经验结果相比较,从而确定了我们的方法的实用价值。

**[Paper URL](https://proceedings.mlr.press/v202/jovanovic23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jovanovic23a/jovanovic23a.pdf)** 

# Scaling of Class-wise Training Losses for Post-hoc Calibration
**题目:** 按班级进行校正后培训损失的计算

**作者:** Seungjin Jung, Seungmo Seo, Yonghyun Jeong, Jongwon Choi

**Abstract:** The class-wise training losses often diverge as a result of the various levels of intra-class and inter-class appearance variation, and we find that the diverging class-wise training losses cause the uncalibrated prediction with its reliability. To resolve the issue, we propose a new calibration method to synchronize the class-wise training losses. We design a new training loss to alleviate the variance of class-wise training losses by using multiple class-wise scaling factors. Since our framework can compensate the training losses of overfitted classes with those of under-fitted classes, the integrated training loss is preserved, preventing the performance drop even after the model calibration. Furthermore, our method can be easily employed in the post-hoc calibration methods, allowing us to use the pre-trained model as an initial model and reduce the additional computation for model calibration. We validate the proposed framework by employing it in the various post-hoc calibration methods, which generally improves calibration performance while preserving accuracy, and discover through the investigation that our approach performs well with unbalanced datasets and untuned hyperparameters.

**摘要:** 针对这一问题,我们提出了一种新的校准方法,以同步校准训练损失。我们设计了一种新的校准损失,以使用多种校准尺度因素来减轻校准训练损失的差异。由于我们的框架能够补偿校准过重类的训练损失和校准过低类的训练损失,因此整合训练损失得以保存,即使在校准模型后,也防止性能下降。此外,我们的方法也可以轻易地应用于日后校准方法,使我们能够使用预训练模型作为初始模型,减少模型校准的额外计算。我们通过采用各种后程校正方法验证了该方案的框架,这通常能提高校正性能,同时保持精度,并通过研究发现我们的方法在不平衡的数据集和不调谐的超参数方面表现良好。

**[Paper URL](https://proceedings.mlr.press/v202/jung23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jung23a/jung23a.pdf)** 

# Fighting Fire with Fire: Contrastive Debiasing without Bias-free Data via Generative Bias-transformation
**题目:** 与火作战:通过生成偏差变换,无偏差数据的反向偏差

**作者:** Yeonsung Jung, Hajin Shim, June Yong Yang, Eunho Yang

**Abstract:** Deep neural networks (DNNs), despite their ability to generalize with over-capacity networks, often rely heavily on the malignant bias as shortcuts instead of task-related information for discriminative tasks. This can lead to poor performance on real-world inputs, particularly when the majority of the sample is biased. To address the highly biased issue, recent studies either exploit auxiliary information which is rarely obtainable in practice or sift handful bias-free samples to emphasize them for debiasing. However, these methods are not always guaranteed to work due to unmet presumptions. In this paper, we propose Contrastive Debiasing via Generative Bias-transformation (CDvG) which is capable of operating without explicitly exploiting bias labels and bias-free samples. Motivated by our observation that not only discriminative models but also image translation models tend to focus on the malignant bias, CDvG employs an image translation model to transform the bias to another mode of bias while preserving task-relevant information. Through contrastive learning, the bias-transformed views are set against each other to learn bias-invariant representations. Our method shows a better debiasing effect when bias is more malignant as opposed to previous methods, and can also be integrated with the methods that focus on bias-free samples in a plug-and-play manner for further improvement. Experimental results on diverse datasets demonstrate that the proposed method outperforms the state-of-the-art, especially when bias-free samples are extremely scarce or absent.

**摘要:** 深层神经网络(DNNs)虽然具有超能力网络的通用性,但往往依靠恶性偏见作为短cut,而不是与任务有关的信息来进行歧视性任务。这可能导致真实输入的性能低下,特别是当多数样品偏见时。为了解决高偏见的问题,最近的研究要么利用在实践中很少获得的辅助信息,要么用手提偏见无偏见样品来强调偏见。然而,这些方法并不总是因为未满足的假设而得到保证。CDvG利用图像翻译模型将偏差转化为另一个偏差模式,同时保存任务相关信息。通过对比性学习,偏差变换的视角相互对立,学习偏差不变的表示。我们的方法在偏差比以前方法更恶性时具有较好的偏差效应,并且可以与基于偏差的样品进行进一步改进的方法结合起来。

**[Paper URL](https://proceedings.mlr.press/v202/jung23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jung23b/jung23b.pdf)** 

# Estimating Joint Treatment Effects by Combining Multiple Experiments
**题目:** 结合多种实验估计联合治疗效果

**作者:** Yonghan Jung, Jin Tian, Elias Bareinboim

**Abstract:** Estimating the effects of multi-dimensional treatments (i.e., joint treatment effects) is critical in many data-intensive domains, including genetics and drug evaluation. The main challenges for studying the joint treatment effects include the need for large sample sizes to explore different treatment combinations as well as potentially unsafe treatment interactions. In this paper, we develop machinery for estimating joint treatment effects by combining data from multiple experimental datasets. In particular, first, we develop new identification conditions for determining whether a joint treatment effect can be computed in terms of multiple interventional distributions under various scenarios. Further, we develop estimators with statistically appealing properties, including consistency and robustness to model misspecification and slow convergence. Finally, we perform simulation studies, which corroborate the effectiveness of the proposed methods.

**摘要:** 评价多维治疗(即联合治疗效应)在许多数据密集领域,包括遗传学和药物评价中具有关键意义。研究联合治疗效应的主要挑战包括需要大样本大小来研究不同的治疗组合以及潜在不安全的治疗相互作用。本文通过结合多个实验数据集的数据,开发联合治疗效应的机制。首先,我们开发新的识别条件,以确定联合治疗效应在不同场景下的多干预分布下是否可计算。此外,我们开发了具有统计学吸引力的估计器,包括对模型误区和缓慢收敛的一致性和鲁棒性。最后,我们进行了仿真研究,证实了拟议方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/jung23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jung23c/jung23c.pdf)** 

# The Catalog Problem: Clustering and Ordering Variable-Sized Sets
**题目:** 目录问题:集群和订购可变大小集

**作者:** Mateusz Maria Jurewicz, Graham W. Taylor, Leon Derczynski

**Abstract:** Prediction of a $\textbf{varying number}$ of $\textbf{ordered clusters}$ from sets of $\textbf{any cardinality}$ is a challenging task for neural networks, combining elements of set representation, clustering and learning to order. This task arises in many diverse areas, ranging from medical triage and early discharge, through machine part management and multi-channel signal analysis for petroleum exploration to product catalog structure prediction. This paper focuses on that last area, which exemplifies a number of challenges inherent to adaptive ordered clustering, referred to further as the eponymous $\textit{Catalog Problem}$. These include learning variable cluster constraints, exhibiting relational reasoning and managing combinatorial complexity. Despite progress in both neural clustering and set-to-sequence methods, no joint, fully differentiable model exists to-date. We develop such a modular architecture, referred to further as Neural Ordered Clusters (NOC), enhance it with a specific mechanism for learning cluster-level cardinality constraints, and provide a robust comparison of its performance in relation to alternative models. We test our method on three datasets, including synthetic catalog structures and PROCAT, a dataset of real-world catalogs consisting of over 1.5M products, achieving state-of-the-art results on a new, more challenging formulation of the underlying problem, which has not been addressed before. Additionally, we examine the network’s ability to learn higher-order interactions.

**摘要:** 从任何基数集合中预测$\textbf{变数}$$的$\textbf{有序集群}$是一个神经网络的挑战性任务,它结合集合表示、集群和学习的要素,在许多不同的领域出现,从医疗检索和早期放电,通过机械部件管理和石油勘探的多通道信号分析到产品目录结构预测。本文着重于最后一个领域,它说明了适应性有序集群所固有的一系列挑战,进一步称为同名的$\textit{Catalog Problem}$。这些挑战包括学习变量集群约束,展示关系推理和管理组合性复杂性。我们开发了这种模块化架构,进一步称作神经序列集群(NOC),以一种特定的学习集群级基准约束机制来增强它,并提供与替代模型的性能的可靠比较。我们测试了我们的方法,包括合成目录结构和PROCAT,一个由超过1.5M产品组成的实物目录的数据集,在新的、更挑战性的问题的拟定上取得了最先进的结果。

**[Paper URL](https://proceedings.mlr.press/v202/jurewicz23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/jurewicz23a/jurewicz23a.pdf)** 

# Equivariance with Learned Canonicalization Functions
**题目:** 与学到的 Canonicalization函数的等价性

**作者:** Sékou-Oumar Kaba, Arnab Kumar Mondal, Yan Zhang, Yoshua Bengio, Siamak Ravanbakhsh

**Abstract:** Symmetry-based neural networks often constrain the architecture in order to achieve invariance or equivariance to a group of transformations. In this paper, we propose an alternative that avoids this architectural constraint by learning to produce canonical representations of the data. These canonicalization functions can readily be plugged into non-equivariant backbone architectures. We offer explicit ways to implement them for some groups of interest. We show that this approach enjoys universality while providing interpretable insights. Our main hypothesis, supported by our empirical results, is that learning a small neural network to perform canonicalization is better than using predefined heuristics. Our experiments show that learning the canonicalization function is competitive with existing techniques for learning equivariant functions across many tasks, including image classification, $N$-body dynamics prediction, point cloud classification and part segmentation, while being faster across the board.

**摘要:** 基于对称性神经网络经常约束结构,以实现变换群的不变性或等变性。本文提出一种通过学习产生数据的 canonical 表示来避免这种结构约束的替代方案。这些 canonicalization函数可以轻易地插入非等变性后骨结构。我们提供了具体的实现方法,用于某些兴趣群体。我们证明,这种方法在提供可解释的洞察的同时具有普遍性。我们的实验表明,学习 canonicalization函数在许多任务中,包括图像分类、$N$-体动力学预测、点云分类和部件分割等,与现有技术相比具有竞争性。

**[Paper URL](https://proceedings.mlr.press/v202/kaba23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kaba23a/kaba23a.pdf)** 

# Biases in Evaluation of Molecular Optimization Methods and Bias Reduction Strategies
**题目:** 分子优化方法评价和偏见减少策略中的偏见

**作者:** Hiroshi Kajino, Kohei Miyaguchi, Takayuki Osogami

**Abstract:** We are interested in an evaluation methodology for molecular optimization. Given a sample of molecules and their properties of our interest, we wish not only to train a generator of molecules optimized with respect to a target property but also to evaluate its performance accurately. A common practice is to train a predictor of the target property using the sample and apply it to both training and evaluating the generator. However, little is known about its statistical properties, and thus, we are not certain about whether this performance estimate is reliable or not. We theoretically investigate this evaluation methodology and show that it potentially suffers from two biases; one is due to misspecification of the predictor and the other to reusing the same finite sample for training and evaluation. We discuss bias reduction methods for each of the biases, and empirically investigate their effectiveness.

**摘要:** 我们对分子优化的评价方法有兴趣。考虑到分子的样本及其特性,我们不仅希望训练一个针对目标特性优化的分子生成器,而且要准确地评价其性能。一个常见的做法是训练一个使用样本的目标特性的预测者,并将其应用于训练和评价生成器。然而,关于其统计性质的了解甚少,因此我们不确定该性能估计是否可靠。

**[Paper URL](https://proceedings.mlr.press/v202/kajino23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kajino23a/kajino23a.pdf)** 

# Statistical Indistinguishability of Learning Algorithms
**题目:** 学习算法的统计区分性

**作者:** Alkis Kalavasis, Amin Karbasi, Shay Moran, Grigoris Velegkas

**Abstract:** When two different parties use the same learning rule on their own data, how can we test whether the distributions of the two outcomes are similar? In this paper, we study the similarity of outcomes of learning rules through the lens of the Total Variation (TV) distance of distributions. We say that a learning rule is TV indistinguishable if the expected TV distance between the posterior distributions of its outputs, executed on two training data sets drawn independently from the same distribution, is small. We first investigate the learnability of hypothesis classes using TV indistinguishable learners. Our main results are information-theoretic equivalences between TV indistinguishability and existing algorithmic stability notions such as replicability and approximate differential privacy. Then, we provide statistical amplification and boosting algorithms for TV indistinguishable learners.

**摘要:** 当两个不同的当事人在自己的数据上使用相同的学习规则时,我们如何测试两个结果的分布是否相似?本文通过分布的总变量(TV)距离来研究学习规则的结果的相似性。我们说,如果从同一分布中独立抽取的两个训练数据集中执行其输出的后继分布之间的预期电视距离小,那么学习规则是电视不可分割的。我们首先研究了电视不可分割学习者使用假定类的可学习性。我们的主要结果是电视不可分割和现有的算法稳定性概念之间的信息理论等价,如可复制性和近似微分隐私。

**[Paper URL](https://proceedings.mlr.press/v202/kalavasis23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kalavasis23a/kalavasis23a.pdf)** 

# Identifying Interpretable Subspaces in Image Representations
**题目:** 在图像表示中识别可解释的子空间

**作者:** Neha Kalibhat, Shweta Bhardwaj, C. Bayan Bruss, Hamed Firooz, Maziar Sanjabi, Soheil Feizi

**Abstract:** We propose Automatic Feature Explanation using Contrasting Concepts (FALCON), an interpretability framework to explain features of image representations. For a target feature, FALCON captions its highly activating cropped images using a large captioning dataset (like LAION-400m) and a pre-trained vision-language model like CLIP. Each word among the captions is scored and ranked leading to a small number of shared, human-understandable concepts that closely describe the target feature. FALCON also applies contrastive interpretation using lowly activating (counterfactual) images, to eliminate spurious concepts. Although many existing approaches interpret features independently, we observe in state-of-the-art self-supervised and supervised models, that less than 20% of the representation space can be explained by individual features. We show that features in larger spaces become more interpretable when studied in groups and can be explained with high-order scoring concepts through FALCON. We discuss how extracted concepts can be used to explain and debug failures in downstream tasks. Finally, we present a technique to transfer concepts from one (explainable) representation space to another unseen representation space by learning a simple linear transformation.

**摘要:** 我们提出了使用对比概念的自动特征解释(FALCON),一种解释图像表现特征的可解框架。对于目标特征,FALCON标注使用大型标注数据集(如LAION-400m)和预训练的视觉语言模型(如CLIP)将其高度激活的剪切图像标注。每个标注中的单词被评分和排序,导致少数共享的、人能理解的概念能密切描述目标特征。FALCON还应用低激活(反事实)图像的对比解释,以消除伪造概念。通过FALCON,我们展示了在较大空间中的特征在群体研究时变得更易解释,并通过高阶评分概念来解释。我们讨论了如何利用提取的概念来解释和调试下游任务中的故障。最后,我们提出了一种通过学习简单的线性变换来将概念从一个(可解释的)表示空间转移到另一个未见的表示空间的技术。

**[Paper URL](https://proceedings.mlr.press/v202/kalibhat23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kalibhat23a/kalibhat23a.pdf)** 

# Nonlinear Causal Discovery with Latent Confounders
**题目:** 非线性因果发现与潜在混淆者

**作者:** David Kaltenpoth, Jilles Vreeken

**Abstract:** Causal discovery, the task of discovering the causal graph over a set of observed variables $X_1,\ldots,X_m$, is a challenging problem. One of the cornerstone assumptions is that of causal sufficiency: that all common causes of all measured variables have been observed. When it does not hold, causal discovery algorithms making this assumption return networks with many spurious edges. In this paper, we propose a nonlinear causal model involving hidden confounders. We show that it is identifiable from only the observed data and propose an efficient method for recovering this causal model. At the heart of our approach is a variational autoencoder which parametrizes both the causal interactions between observed variables as well as the influence of the unobserved confounders. Empirically we show that it outperforms other state-of-the-art methods for causal discovery under latent confounding on synthetic and real-world data.

**摘要:** 因果发现(英语:Causeal discovery)是发现因果图在观察变量集$X_1,\ldots,X_m$上的一个挑战性问题,其中一个基本假设是因果充足:所有测量变量的所有共同原因已经被观察到。当它不成立时,因果发现算法会使这个假设返回许多虚构边缘的网络。在本文中,我们提出了一种非线性因果模型,涉及隐藏的因果混淆者。我们证明它是仅从观察数据中识别的,并提出了一种有效的方法来恢复这个因果模型。

**[Paper URL](https://proceedings.mlr.press/v202/kaltenpoth23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kaltenpoth23a/kaltenpoth23a.pdf)** 

# Deep Generative Symbolic Regression with Monte-Carlo-Tree-Search
**题目:** Monte-Carlo-Tree-Search的深度生成符号回归

**作者:** Pierre-Alexandre Kamienny, Guillaume Lample, Sylvain Lamprier, Marco Virgolin

**Abstract:** Symbolic regression (SR) is the problem of learning a symbolic expression from numerical data. Recently, deep neural models trained on procedurally-generated synthetic datasets showed competitive performance compared to more classical Genetic Programming (GP) ones. Unlike their GP counterparts, these neural approaches are trained to generate expressions from datasets given as context. This allows them to produce accurate expressions in a single forward pass at test time. However, they usually do not benefit from search abilities, which result in low performance compared to GP on out-of-distribution datasets. In this paper, we propose a novel method which provides the best of both worlds, based on a Monte-Carlo Tree Search procedure using a context-aware neural mutation model, which is initially pre-trained to learn promising mutations, and further refined from successful experiences in an online fashion. The approach demonstrates state-of-the-art performance on the well-known SRBench benchmark.

**摘要:** 符号回归(英语:Symbolic regression,缩写:SR)是学习数字数据中的符号表达式的问题。最近,在程序生成的合成数据集上训练的深层神经模型,与较经典的遗传编程(GP)模型相比显示出竞争性性能。与其GP类别不同,这些神经方法被训练以生成数据集作为上下文的表达式。这使得它们能够在测试时在单个向前通行时产生准确的表达式。然而,它们通常不会从搜索能力中获益,这导致在离散数据集上与GP相比的性能低。该方法在众所周知的SRBench指标上显示了最先进的性能。

**[Paper URL](https://proceedings.mlr.press/v202/kamienny23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kamienny23a/kamienny23a.pdf)** 

# One-vs-the-Rest Loss to Focus on Important Samples in Adversarial Training
**题目:** 对敌方训练中重要的实例进行集中学习的“一比一”损失

**作者:** Sekitoshi Kanai, Shin’Ya Yamaguchi, Masanori Yamada, Hiroshi Takahashi, Kentaro Ohno, Yasutoshi Ida

**Abstract:** This paper proposes a new loss function for adversarial training. Since adversarial training has difficulties, e.g., necessity of high model capacity, focusing on important data points by weighting cross-entropy loss has attracted much attention. However, they are vulnerable to sophisticated attacks, e.g., Auto-Attack. This paper experimentally reveals that the cause of their vulnerability is their small margins between logits for the true label and the other labels. Since neural networks classify the data points based on the logits, logit margins should be large enough to avoid flipping the largest logit by the attacks. Importance-aware methods do not increase logit margins of important samples but decrease those of less-important samples compared with cross-entropy loss. To increase logit margins of important samples, we propose switching one-vs-the-rest loss (SOVR), which switches from cross-entropy to one-vs-the-rest loss for important samples that have small logit margins. We prove that one-vs-the-rest loss increases logit margins two times larger than the weighted cross-entropy loss for a simple problem. We experimentally confirm that SOVR increases logit margins of important samples unlike existing methods and achieves better robustness against Auto-Attack than importance-aware methods.

**摘要:** 由于敌对训练有困难,例如需要高模型容量,因此通过权重横向损失对重要数据点进行集中研究,引起了广泛的关注。然而,它们容易受到复杂的攻击,例如自动攻击。本文通过实验显示,其脆弱性的原因是其对真标签和其它标签的逻辑符号之间的小边界。由于神经网络基于逻辑符号分类数据点,逻辑符号的边界应该足够大,以避免攻击把最大逻辑符号转动。我们证明,一个-vs-the-rest损耗对于一个简单的问题增加的 logit边界比重的交叉熵损耗大两倍。我们实验证实,SOVR不同于现有方法,增加了重要的样品的 logit边界,并且在自动攻击方面比重视的方法具有更好的鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/kanai23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kanai23a/kanai23a.pdf)** 

# Large Language Models Struggle to Learn Long-Tail Knowledge
**题目:** 大型语言模型努力学习长尾知识

**作者:** Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, Colin Raffel

**Abstract:** The Internet contains a wealth of knowledge—from the birthdays of historical figures to tutorials on how to code—all of which may be learned by language models. However, while certain pieces of information are ubiquitous on the web, others appear extremely rarely. In this paper, we study the relationship between the knowledge memorized by large language models and the information in pre-training datasets scraped from the web. In particular, we show that a language model’s ability to answer a fact-based question relates to how many documents associated with that question were seen during pre-training. We identify these relevant documents by entity linking pre-training datasets and counting documents that contain the same entities as a given question-answer pair. Our results demonstrate strong correlational and causal relationships between accuracy and relevant document count for numerous question answering datasets (e.g., TriviaQA), pre-training corpora (e.g., ROOTS), and model sizes (e.g., 176B parameters). Moreover, while larger models are better at learning long-tail knowledge, we estimate that today’s models must be scaled by many orders of magnitude to reach competitive QA performance on questions with little support in the pre-training data. Finally, we show that retrieval-augmentation can reduce the dependence on relevant pre-training information, presenting a promising approach for capturing the long-tail.

**摘要:** 网络包含大量的知识,从历史数字的生日到如何编码的教程,这些都可由语言模型学习。然而,虽然某些信息在网络上普遍存在,但其他则非常罕见。本论文研究了由大型语言模型记载的知识与从网络 scraped的预培训数据集中的信息之间的关系。结果表明,对于许多问答数据集(例如TriviaQA)、预训练公司(例如ROOTS)和模型尺寸(例如176B参数)的准确性与相关文件数值之间有很强的关联和因果关系。此外,虽然较大的模型在学习长尾知识方面更好,但我们估计,今天的模型必须以许多数量级的尺度来衡量,以达到在预训练数据中很少支持的问题上的竞争性QA性能。

**[Paper URL](https://proceedings.mlr.press/v202/kandpal23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kandpal23a/kandpal23a.pdf)** 

# Git-Theta: A Git Extension for Collaborative Development of Machine Learning Models
**题目:** Git-Theta:计算机学习模型协作开发的Git扩展

**作者:** Nikhil Kandpal, Brian Lester, Mohammed Muqeeth, Anisha Mascarenhas, Monty Evans, Vishal Baskaran, Tenghao Huang, Haokun Liu, Colin Raffel

**Abstract:** Currently, most machine learning models are trained by centralized teams and are rarely updated. In contrast, open-source software development involves the iterative development of a shared artifact through distributed collaboration using a version control system. In the interest of enabling collaborative and continual improvement of machine learning models (Raffel, 2023), we introduce Git-Theta, a version control system for machine learning models. Git-Theta is an extension to Git, the most widely used version control software, that allows fine-grained tracking of changes to model parameters alongside code and other artifacts. Unlike existing version control systems that treat a model checkpoint as a blob of data, Git-Theta leverages the structure of checkpoints to support communication-efficient updates, automatic model merges, and meaningful reporting about the difference between two versions of a model. In addition, Git-Theta includes a plug-in system that enables users to easily add support for new functionality. In this paper, we introduce Git-Theta’s design and features and include an example use-case of Git-Theta where a pre-trained model is continually adapted and modified. We publicly release Git-Theta in hopes of kickstarting a new era of collaborative model development. https://github.com/r-three/git-theta/

**摘要:** 目前,大多数机器学习模型由集中团队训练,很少更新。相反,开放源代码软件开发涉及通过使用版本控制系统进行分布式协作来迭代开发共享成果。为了使机器学习模型进行协作和持续改进(Raffel, 2023),我们介绍了Git-Theta,一种机器学习模型的版本控制系统。Git-Theta是Git的扩展,最广泛使用的版本控制软件,它允许在代码和其他成果的同时,细微地跟踪模型参数的变化。与现有的版本控制系统不同,Git-Theta利用检查点的结构来支持通信效率的更新、自动模型合并和关于模型两版本之间的区别的有意义的报告。此外,Git-Theta还包括一个插件系统,让用户可以轻松添加新功能的支持。本论文介绍了Git-Theta的设计和功能,并包括了Git-Theta的预训练模型不断调整和修改的例子。我们公开发布Git-Theta,希望启动新的协作模型开发时代。

**[Paper URL](https://proceedings.mlr.press/v202/kandpal23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kandpal23b/kandpal23b.pdf)** 

# A Deep Conjugate Direction Method for Iteratively Solving Linear Systems
**题目:** 迭代求解线性系统深层共轭导引方法

**作者:** Ayano Kaneda, Osman Akar, Jingyu Chen, Victoria Alicia Trevino Kala, David Hyde, Joseph Teran

**Abstract:** We present a novel deep learning approach to approximate the solution of large, sparse, symmetric, positive-definite linear systems of equations. Motivated by the conjugate gradients algorithm that iteratively selects search directions for minimizing the matrix norm of the approximation error, we design an approach that utilizes a deep neural network to accelerate convergence via data-driven improvement of the search direction at each iteration. Our method leverages a carefully chosen convolutional network to approximate the action of the inverse of the linear operator up to an arbitrary constant. We demonstrate the efficacy of our approach on spatially discretized Poisson equations, which arise in computational fluid dynamics applications, with millions of degrees of freedom. Unlike state-of-the-art learning approaches, our algorithm is capable of reducing the linear system residual to a given tolerance in a small number of iterations, independent of the problem size. Moreover, our method generalizes effectively to various systems beyond those encountered during training.

**摘要:** 我们提出了一种新的深入学习方法,以求求近似方程的大型、稀疏、对称、正确定线性系统解决方案。我们通过迭代选择搜索方向来最小化近似误差矩阵规范的合并梯度算法,设计了一种利用深度神经网络通过数据驱动改进每次迭代的搜索方向来加速收敛的方法。我们的方法利用精心选择的进化网络,以求近似线性算子反向行动到任意常数。我们证明了我们在数百万自由度的计算流体动力学应用中出现的空间离散波森方程上的方法的有效性。而且,我们的方法能有效地推广到不同的系统,超越在训练过程中遇到的系统。

**[Paper URL](https://proceedings.mlr.press/v202/kaneda23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kaneda23a/kaneda23a.pdf)** 

# Leveraging Proxy of Training Data for Test-Time Adaptation
**题目:** 利用培训数据的代理来适应测试时间

**作者:** Juwon Kang, Nayeong Kim, Donghyeon Kwon, Jungseul Ok, Suha Kwak

**Abstract:** We consider test-time adaptation (TTA), the task of adapting a trained model to an arbitrary test domain using unlabeled input data on-the-fly during testing. A common practice of TTA is to disregard data used in training due to large memory demand and privacy leakage. However, the training data are the only source of supervision. This motivates us to investigate a proper way of using them while minimizing the side effects. To this end, we propose two lightweight yet informative proxies of the training data and a TTA method fully exploiting them. One of the proxies is composed of a small number of images synthesized (hence, less privacy-sensitive) by data condensation which minimizes their domain-specificity to capture a general underlying structure over a wide spectrum of domains. Then, in TTA, they are translated into labeled test data by stylizing them to match styles of unlabeled test samples. This enables virtually supervised test-time training. The other proxy is inter-class relations of training data, which are transferred to target model during TTA. On four public benchmarks, our method outperforms the state-of-the-art ones at remarkably less computation and memory.

**摘要:** 我们考虑测试时间适应(TTA),即在测试过程中使用非标记输入数据的任意测试域调整训练模型的任务。TTA的常见做法是由于大量内存需求和隐私泄漏而忽略在训练中使用的数据。然而,训练数据是监督的唯一来源。这促使我们研究在最小化副作用的同时使用它们的适当方法。为此,我们提出了两个轻量但信息性训练数据的代理和一个完全利用它们的TTA方法。其中一个代理是由由数据凝结合成的少量图像组成的,以最小化它们的领域特异性,在广泛的领域中捕捉一个基本结构。然后,在TTA中,它们被转换为标记测试数据,以使它们匹配非标记测试样品的风格。另一个代理是培训数据的类间关系,这些数据在TTA期间被转移到目标模型中。在四个公共基准上,我们的方法在计算和记忆方面比最先进的方法要低得多。

**[Paper URL](https://proceedings.mlr.press/v202/kang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kang23a/kang23a.pdf)** 

# Beyond Reward: Offline Preference-guided Policy Optimization
**题目:** Beyond Reward: Offline Preferences-guided Policy Optimization

**作者:** Yachen Kang, Diyuan Shi, Jinxin Liu, Li He, Donglin Wang

**Abstract:** This study focuses on the topic of offline preference-based reinforcement learning (PbRL), a variant of conventional reinforcement learning that dispenses with the need for online interaction or specification of reward functions. Instead, the agent is provided with fixed offline trajectories and human preferences between pairs of trajectories to extract the dynamics and task information, respectively. Since the dynamics and task information are orthogonal, a naive approach would involve using preference-based reward learning followed by an off-the-shelf offline RL algorithm. However, this requires the separate learning of a scalar reward function, which is assumed to be an information bottleneck of the learning process. To address this issue, we propose the offline preference-guided policy optimization (OPPO) paradigm, which models offline trajectories and preferences in a one-step process, eliminating the need for separately learning a reward function. OPPO achieves this by introducing an offline hindsight information matching objective for optimizing a contextual policy and a preference modeling objective for finding the optimal context. OPPO further integrates a well-performing decision policy by optimizing the two objectives iteratively. Our empirical results demonstrate that OPPO effectively models offline preferences and outperforms prior competing baselines, including offline RL algorithms performed over either true or pseudo reward function specifications. Our code is available on the project website: https://sites.google.com/view/oppo-icml-2023.

**摘要:** 本文主要讨论了基于网络的偏好强化学习(PbRL)的传统强化学习的变种,它不涉及在线交互或奖励函数的规范。相反,代理提供固定的网络轨迹和人类偏好,以分别提取动态和任务信息。由于动态和任务信息是正交的,一个单纯的方法将涉及使用基于偏好的奖励学习,然后采用 Off-the-shelf offline RL 算法。然而,这需要分开学习 scalar reward function,被认为是学习过程的一个信息瓶颈。OPPO通过引入非线性后视信息匹配目标来优化上下文政策和寻找最佳上下文的偏好建模目标来实现这一目标。 OPPO进一步通过迭代优化两个目标整合出良好的决策政策。我们的实证结果表明,OPPO有效建模了非线性偏好,并且超过了以前的竞争基线,包括在真实或伪奖励函数规范上执行的非线性RL算法。

**[Paper URL](https://proceedings.mlr.press/v202/kang23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kang23b/kang23b.pdf)** 

# Poisoning Generative Replay in Continual Learning to Promote Forgetting
**题目:** 持续学习中的毒性生成性重演促进遗忘

**作者:** Siteng Kang, Zhan Shi, Xinhua Zhang

**Abstract:** Generative models have grown into the workhorse of many state-of-the-art machine learning methods. However, their vulnerability under poisoning attacks has been largely understudied. In this work, we investigate this issue in the context of continual learning, where generative replayers are utilized to tackle catastrophic forgetting. By developing a novel customization of dirty-label input-aware backdoors to the online setting, our attacker manages to stealthily promote forgetting while retaining high accuracy at the current task and sustaining strong defenders. Our approach taps into an intriguing property of generative models, namely that they cannot well capture input-dependent triggers. Experiments on four standard datasets corroborate the poisoner’s effectiveness.

**摘要:** 生成型模型已经成长为许多最先进的机器学习方法的工作马匹。然而,它们在毒害攻击下的脆弱性被广泛忽视。在这项工作中,我们研究了这一问题在持续学习的上下文中,生成型重新播放器被用来解决灾难性遗忘。通过对在线设置的脏标签输入意识后门的新型定制,我们的攻击者设法隐秘地促进遗忘,同时在当前任务中保持高精度,并保持强大的防御者。

**[Paper URL](https://proceedings.mlr.press/v202/kang23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kang23c/kang23c.pdf)** 

# Node Embedding from Neural Hamiltonian Orbits in Graph Neural Networks
**题目:** 图形神经网络中神经汉密尔顿轨道节点的嵌入

**作者:** Qiyu Kang, Kai Zhao, Yang Song, Sijie Wang, Wee Peng Tay

**Abstract:** In the graph node embedding problem, embedding spaces can vary significantly for different data types, leading to the need for different GNN model types. In this paper, we model the embedding update of a node feature as a Hamiltonian orbit over time. Since the Hamiltonian orbits generalize the exponential maps, this approach allows us to learn the underlying manifold of the graph in training, in contrast to most of the existing literature that assumes a fixed graph embedding manifold with a closed exponential map solution. Our proposed node embedding strategy can automatically learn, without extensive tuning, the underlying geometry of any given graph dataset even if it has diverse geometries. We test Hamiltonian functions of different forms and verify the performance of our approach on two graph node embedding downstream tasks: node classification and link prediction. Numerical experiments demonstrate that our approach adapts better to different types of graph datasets than popular state-of-the-art graph node embedding GNNs. The code is available at https://github.com/zknus/Hamiltonian-GNN.

**摘要:** 在图节点嵌入问题中,嵌入空间对于不同的数据类型可能有很大变化,导致需要不同的GNN模型类型。本文,我们将一个节点特征的嵌入更新作为时间的哈密尔顿轨道模型。由于哈密尔顿轨道一般化指数图,这一方法让我们在训练中学习图的底层多变形,与大多数现有文献相比,它假设有封闭指数图解的固定图节点嵌入多变形。我们提出的节点嵌入策略可以自动学习任何给定的图数据集的底层几何,即使它具有各种几何。数值实验表明,我们的方法比嵌入GNN的流行最先进的图节点更适合不同类型的图数据集。该代码可于 https://github.com/zknus/Hamiltonian-GNN。

**[Paper URL](https://proceedings.mlr.press/v202/kang23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kang23d/kang23d.pdf)** 

# Understanding Gradient Regularization in Deep Learning: Efficient Finite-Difference Computation and Implicit Bias
**题目:** 深入学习中梯度调节的理解:高效的有限差计算和隐含偏见

**作者:** Ryo Karakida, Tomoumi Takase, Tomohiro Hayase, Kazuki Osawa

**Abstract:** Gradient regularization (GR) is a method that penalizes the gradient norm of the training loss during training. While some studies have reported that GR can improve generalization performance, little attention has been paid to it from the algorithmic perspective, that is, the algorithms of GR that efficiently improve the performance. In this study, we first reveal that a specific finite-difference computation, composed of both gradient ascent and descent steps, reduces the computational cost of GR. Next, we show that the finite-difference computation also works better in the sense of generalization performance. We theoretically analyze a solvable model, a diagonal linear network, and clarify that GR has a desirable implicit bias to so-called rich regime and finite-difference computation strengthens this bias. Furthermore, finite-difference GR is closely related to some other algorithms based on iterative ascent and descent steps for exploring flat minima. In particular, we reveal that the flooding method can perform finite-difference GR in an implicit way. Thus, this work broadens our understanding of GR for both practice and theory.

**摘要:** 梯度正则化(Gradient regularization,GR)是一种惩罚在训练过程中训练损失的梯度规范的方法,虽然一些研究报告说GR可以提高一般化性能,但从算法的角度却很少注意它,即提高性能的GR算法。在这项研究中,我们首先揭示了由梯度上升和下降两步组成的特定有限差数计算,降低了GR的计算成本。接下来,我们证明有限差数计算在一般化性能方面也更好。我们从理论上分析了可解模型、斜线网络,并澄清了GR对所谓的富裕制度有可望的隐性偏见,有限差数计算加强了这种偏见。特别是,我们揭示了水浸法可以隐含地实现有限差 GR,从而扩大了我们对 GR 的理解,既在实践中又在理论上。

**[Paper URL](https://proceedings.mlr.press/v202/karakida23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/karakida23a/karakida23a.pdf)** 

# Langevin Thompson Sampling with Logarithmic Communication: Bandits and Reinforcement Learning
**题目:** 朗格文·汤普森与逻辑通信的抽样: bandits and reinforcement learning

**作者:** Amin Karbasi, Nikki Lijing Kuang, Yian Ma, Siddharth Mitra

**Abstract:** Thompson sampling (TS) is widely used in sequential decision making due to its ease of use and appealing empirical performance. However, many existing analytical and empirical results for TS rely on restrictive assumptions on reward distributions, such as belonging to conjugate families, which limits their applicability in realistic scenarios. Moreover, sequential decision making problems are often carried out in a batched manner, either due to the inherent nature of the problem or to serve the purpose of reducing communication and computation costs. In this work, we jointly study these problems in two popular settings, namely, stochastic multi-armed bandits (MABs) and infinite-horizon reinforcement learning (RL), where TS is used to learn the unknown reward distributions and transition dynamics, respectively. We propose batched Langevin Thompson Sampling algorithms that leverage MCMC methods to sample from approximate posteriors with only logarithmic communication costs in terms of batches. Our algorithms are computationally efficient and maintain the same order-optimal regret guarantees of $\mathcal{O}(\log T)$ for stochastic MABs, and $\mathcal{O}(\sqrt{T})$ for RL. We complement our theoretical findings with experimental results.

**摘要:** 汤普森抽样法由于其易于使用和具有吸引力的实证性能,广泛应用于序列决策中。然而,许多现有的分析和实证结果都依赖于对奖赏分配的限制性假设,例如属于合并家族,这限制了它们在现实场景中的应用。此外,序列决策问题往往以批次的方式进行,要么是由于问题的固有性质,要么是为了减少通信和计算成本。本文提出了一种利用MCMC方法从近后端提取样本的批量拉根文·汤普森采样算法,仅用批量计算的代数通信成本。我们的算法具有计算效率,并保持了随机MAB的$\mathcal{O}(\log T)$和RL的$\mathcal{O}(\sqrt{T})$的顺序优化遗憾保证。

**[Paper URL](https://proceedings.mlr.press/v202/karbasi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/karbasi23a/karbasi23a.pdf)** 

# On the Relationship Between Explanation and Prediction: A Causal View
**题目:** 解释与预测之间的关系: 原因论

**作者:** Amir-Hossein Karimi, Krikamol Muandet, Simon Kornblith, Bernhard Schölkopf, Been Kim

**Abstract:** Being able to provide explanations for a model’s decision has become a central requirement for the development, deployment, and adoption of machine learning models. However, we are yet to understand what explanation methods can and cannot do. How do upstream factors such as data, model prediction, hyperparameters, and random initialization influence downstream explanations? While previous work raised concerns that explanations (E) may have little relationship with the prediction (Y), there is a lack of conclusive study to quantify this relationship. Our work borrows tools from causal inference to systematically assay this relationship. More specifically, we study the relationship between E and Y by measuring the treatment effect when intervening on their causal ancestors, i.e., on hyperparameters and inputs used to generate saliency-based Es or Ys. Our results suggest that the relationships between E and Y is far from ideal. In fact, the gap between ’ideal’ case only increase in higher-performing models — models that are likely to be deployed. Our work is a promising first step towards providing a quantitative measure of the relationship between E and Y, which could also inform the future development of methods for E with a quantitative metric.

**摘要:** 能够为模型的决策提供解释已成为机器学习模型的开发、部署和采用的中心要求。然而,我们仍未了解解释方法能够和不能做些什么。上游因素,如数据、模型预测、超参数和随机初始化如何影响下游解释?虽然以前的工作提出了解释(E)可能与预测(Y)没有关系的问题,但缺乏确定性研究来量化这一关系。我们的工作从因果推理借用工具系统地检验这一关系。事实上,“理想”案例之间的差距只在高性能模型 — — 可能被部署的模型 — — 中增加。我们的工作是向提供量化衡量E和Y之间的关系的有希望的第一步,这也将有助于今后用量化计量量来衡量E的方法的发展。

**[Paper URL](https://proceedings.mlr.press/v202/karimi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/karimi23a/karimi23a.pdf)** 

# Cocktail Party Attack: Breaking Aggregation-Based Privacy in Federated Learning Using Independent Component Analysis
**题目:** 鸡尾酒派对攻击:利用独立组件分析的联邦学习中基于集群隐私的突破

**作者:** Sanjay Kariyappa, Chuan Guo, Kiwan Maeng, Wenjie Xiong, G. Edward Suh, Moinuddin K Qureshi, Hsien-Hsin S. Lee

**Abstract:** Federated learning (FL) aims to perform privacy-preserving machine learning on distributed data held by multiple data owners. To this end, FL requires the data owners to perform training locally and share the gradients or weight updates (instead of the private inputs) with the central server, which are then securely aggregated over multiple data owners. Although aggregation by itself does not offer provable privacy protection, prior work suggested that if the batch size is sufficiently large the aggregation may be secure enough. In this paper, we propose the Cocktail Party Attack (CPA) that, contrary to prior belief, is able to recover the private inputs from gradients/weight updates aggregated over as many as 1024 samples. CPA leverages the crucial insight that aggregate gradients from a fully connected (FC) layer is a linear combination of its inputs, which allows us to frame gradient inversion as a blind source separation (BSS) problem. We adapt independent component analysis (ICA)—a classic solution to the BSS problem—to recover private inputs for FC and convolutional networks, and show that CPA significantly outperforms prior gradient inversion attacks, scales to ImageNet-sized inputs, and works on large batch sizes of up to 1024.

**摘要:** 联邦学习(FL)旨在在多个数据拥有者所持有的分布数据上进行机密保护的机器学习。为此目的,FL要求数据拥有者在本地进行培训并与中央服务器共享梯度或重量更新(而不是私人输入),然后在多个数据拥有者上安全地聚集。虽然自集并不提供可证明的隐私保护,但先前的工作建议如果批量大小足够大,集会足够安全。我们采用独立组件分析(ICA) — — 是BSS问题的经典解决方案 — — 来恢复FC和卷积网络的私人输入,并证明CPA明显超过了以前的梯度反演攻击,可扩展到ImageNet大小的输入,并且在最大1024批量大小的大型批量上工作。

**[Paper URL](https://proceedings.mlr.press/v202/kariyappa23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kariyappa23a/kariyappa23a.pdf)** 

# General Sequential Episodic Memory Model
**题目:** 一般序列 episodic 记忆模型

**作者:** Arjun Karuvally, Terrence Sejnowski, Hava T Siegelmann

**Abstract:** The state-of-the-art memory model is the General Associative Memory Model, a generalization of the classical Hopfield network. Like its ancestor, the general associative memory has a well-defined state-dependant energy surface, and its memories correlate with its fixed points. This is unlike human memories, which are commonly sequential rather than separated fixed points. In this paper, we introduce a class of General Sequential Episodic Memory Models (GSEMM) that, in the adiabatic limit, exhibit a dynamic energy surface, leading to a series of meta-stable states capable of encoding memory sequences. A multiple-timescale architecture enables the dynamic nature of the energy surface with newly introduced asymmetric synapses and signal propagation delays. We demonstrate its dense capacity under polynomial activation functions. GSEMM combines separate memories, short and long sequential episodic memories, under a unified theoretical framework, demonstrating how energy-based memory modeling can provide richer, human-like episodes.

**摘要:** 最先进的记忆模型是经典霍普菲尔德网络的一般关联记忆模型(General Associative Memory Model),与其前辈一样,一般关联记忆具有明确的状态依赖性能量表面,其记忆与其固定点相关。这与人类记忆不同,它们通常是序列而不是分离的固定点。本论文介绍了一种一般序列 episodic记忆模型(GSEMM)的类别,它在代数限界中显示出动态能量表面,导致一系列具有编码记忆序列的元稳定状态。GSEMM在统一的理论框架下结合了单独的记忆、短时间和长时间的连续 episodic memories,展示了基于能量的记忆建模如何提供更丰富的类似人类的片段。

**[Paper URL](https://proceedings.mlr.press/v202/karuvally23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/karuvally23a/karuvally23a.pdf)** 

# Regression with Sensor Data Containing Incomplete Observations
**题目:** 包含不完整的观测的传感器数据回归

**作者:** Takayuki Katsuki, Takayuki Osogami

**Abstract:** This paper addresses a regression problem in which output label values are the results of sensing the magnitude of a phenomenon. A low value of such labels can mean either that the actual magnitude of the phenomenon was low or that the sensor made an incomplete observation. This leads to a bias toward lower values in labels and the resultant learning because labels may have lower values due to incomplete observations, even if the actual magnitude of the phenomenon was high. Moreover, because an incomplete observation does not provide any tags indicating incompleteness, we cannot eliminate or impute them. To address this issue, we propose a learning algorithm that explicitly models incomplete observations corrupted with an asymmetric noise that always has a negative value. We show that our algorithm is unbiased as if it were learned from uncorrupted data that does not involve incomplete observations. We demonstrate the advantages of our algorithm through numerical experiments.

**摘要:** 本文针对一种回归问题,即输出标签的值是感知现象的大小的结果。低值的标签可能意味着该现象的实际大小是低的,或者感知器做了不完整的观察。这导致标签中的低值偏向和由此产生的学习,因为标签可能由于不完整的观察而有较低的值,即使该现象的实际大小是高。此外,由于不完整的观察不提供任何迹象显示不完整的标签,我们不能消除或推导它们。

**[Paper URL](https://proceedings.mlr.press/v202/katsuki23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/katsuki23a/katsuki23a.pdf)** 

# Data Representations’ Study of Latent Image Manifolds
**题目:** 数据代表研究隐形图像变形

**作者:** Ilya Kaufman, Omri Azencot

**Abstract:** Deep neural networks have been demonstrated to achieve phenomenal success in many domains, and yet their inner mechanisms are not well understood. In this paper, we investigate the curvature of image manifolds, i.e., the manifold deviation from being flat in its principal directions. We find that state-of-the-art trained convolutional neural networks for image classification have a characteristic curvature profile along layers: an initial steep increase, followed by a long phase of a plateau, and followed by another increase. In contrast, this behavior does not appear in untrained networks in which the curvature flattens. We also show that the curvature gap between the last two layers has a strong correlation with the generalization capability of the network. Moreover, we find that the intrinsic dimension of latent codes is not necessarily indicative of curvature. Finally, we observe that common regularization methods such as mixup yield flatter representations when compared to other methods. Our experiments show consistent results over a variety of deep learning architectures and multiple data sets.

**摘要:** 深层神经网络在许多领域取得了显著的成功,但其内在机制尚不清楚。本文研究了图像变形的变形,即变形偏差在其主要方向上是平的。我们发现,最先进的训练的变形神经网络在图像分类中具有沿层的特征变形特征:一个初始急剧增加,其次是高原的长相,然后是另一个增加。最后,我们观察到,与其他方法相比,混合等常规化方法能产生更平坦的图形。我们的实验显示,在多种深度学习架构和多个数据集中均有一致的结果。

**[Paper URL](https://proceedings.mlr.press/v202/kaufman23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kaufman23a/kaufman23a.pdf)** 

# Multi-Modal Classifiers for Open-Vocabulary Object Detection
**题目:** 开放语音对象检测的多模分类器

**作者:** Prannay Kaul, Weidi Xie, Andrew Zisserman

**Abstract:** The goal of this paper is open-vocabulary object detection (OVOD) — building a model that can detect objects beyond the set of categories seen at training, thus enabling the user to specify categories of interest at inference without the need for model retraining. We adopt a standard two- stage object detector architecture, and explore three ways for specifying novel categories: via language descriptions, via image exemplars, or via a combination of the two. We make three contributions: first, we prompt a large language model (LLM) to generate informative language descriptions for object classes, and construct powerful text-based classifiers; second, we employ a visual aggregator on image exemplars that can ingest any number of images as input, forming vision-based classifiers; and third, we provide a simple method to fuse information from language descriptions and image exemplars, yield- ing a multi-modal classifier. When evaluating on the challenging LVIS open-vocabulary bench- mark we demonstrate that: (i) our text-based classifiers outperform all previous OVOD works; (ii) our vision-based classifiers perform as well as text-based classifiers in prior work; (iii) using multi-modal classifiers perform better than either modality alone; and finally, (iv) our text-based and multi-modal classifiers yield better performance than a fully-supervised detector.

**摘要:** 本文的目的是建立一种能够检测在训练中看到的类别之外的对象的模型,从而使用户无需重新训练模型来指定感兴趣的类别。我们采用了一种标准的两级对象检测器架构,并探讨了通过语言描述、图像实例或两者的结合来指定新类别的三个方法。我们作出了三个贡献:首先,我们促使一个大型语言模型(LLM)为对象类生成信息性语言描述,并构建强大的基于文本的分类器;其次,我们使用了一个可输入任意数量图像的图像实例的视觉聚集器,形成基于视觉的分类器;第三,我们提供了一种简便的方法将语言描述和图像实例的信息结合起来,产生一种多模态分类器。当评估LVIS开放口语平台的挑战性时,我们证明: (i)我们的基于文本的分类器比以往的OVOD工作表现更好; (ii)我们的基于视觉的分类器在以前的工作表现得更好; (iii)使用多模态的分类器比单独的两种模式表现得更好; (iv)我们的基于文本的分类器和多模态的分类器比一个完全监督的检测器表现得更好。

**[Paper URL](https://proceedings.mlr.press/v202/kaul23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kaul23a/kaul23a.pdf)** 

# Learning Mixtures of Markov Chains and MDPs
**题目:** 马可夫链和MDP的学习混合物

**作者:** Chinmaya Kausik, Kevin Tan, Ambuj Tewari

**Abstract:** We present an algorithm for learning mixtures of Markov chains and Markov decision processes (MDPs) from short unlabeled trajectories. Specifically, our method handles mixtures of Markov chains with optional control input by going through a multi-step process, involving (1) a subspace estimation step, (2) spectral clustering of trajectories using "pairwise distance estimators," along with refinement using the EM algorithm, (3) a model estimation step, and (4) a classification step for predicting labels of new trajectories. We provide end-to-end performance guarantees, where we only explicitly require the length of trajectories to be linear in the number of states and the number of trajectories to be linear in a mixing time parameter. Experimental results support these guarantees, where we attain 96.6% average accuracy on a mixture of two MDPs in gridworld, outperforming the EM algorithm with random initialization (73.2% average accuracy). We also significantly outperform the EM algorithm on real data from the LastFM song dataset.

**摘要:** 我们提出了一种从短无标记轨迹中学习马可夫链和马可夫决策过程(MDP)混合物的算法。具体而言,我们的方法通过一个多步骤过程处理具有可选控制输入的马可夫链混合物,包括(一)分空间估计步骤、(二)使用“双向距离估计器”的轨迹光谱聚类、(三)使用EM算法的改进、(四)采用模型估计步骤和(四)预测新轨迹标签的分类步骤。我们提供了终到终的性能保证,其中我们仅明确要求轨迹的长度在状态数中线性,轨迹的数在混合时间参数中线性。实验结果支持这些保证,其中我们在网格世界中实现了两个MDP混合物的平均精度96.6%,超过了随机初始化(平均精度73.2%)的EM算法。我们也大大超过了EM算法在从LastFM歌曲数据集的实际数据上。

**[Paper URL](https://proceedings.mlr.press/v202/kausik23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kausik23a/kausik23a.pdf)** 

# Curious Replay for Model-based Adaptation
**题目:** 基于模型的适应性有趣的重演

**作者:** Isaac Kauvar, Chris Doyle, Linqi Zhou, Nick Haber

**Abstract:** Agents must be able to adapt quickly as an environment changes. We find that existing model-based reinforcement learning agents are unable to do this well, in part because of how they use past experiences to train their world model. Here, we present Curious Replay—a form of prioritized experience replay tailored to model-based agents through use of a curiosity-based priority signal. Agents using Curious Replay exhibit improved performance in an exploration paradigm inspired by animal behavior and on the Crafter benchmark. DreamerV3 with Curious Replay surpasses state-of-the-art performance on Crafter, achieving a mean score of 19.4 that substantially improves on the previous high score of 14.5 by DreamerV3 with uniform replay, while also maintaining similar performance on the Deepmind Control Suite. Code for Curious Replay is available at github.com/AutonomousAgentsLab/curiousreplay.

**摘要:** 代理人必须能够迅速适应环境的变化。我们发现现有基于模型的强化学习代理人无法做到这一点,部分原因是他们如何使用过去的经验来训练他们的世界模型。这里,我们介绍Curious Replay—一种基于模型的代理人通过使用一种基于好奇心的优先信号定制的优先经验重演形式。使用Curious Replay的代理人展示了由动物行为和Crafter基准启发的探索范式中改进的性能。DreamerV3与Curious Replay超越了Crafter上的最先进的性能,达到了19.4的平均分数,大大改善了DreamerV3与统一重演的14.5的之前的高分数,同时在Deepmind控制套件上保持类似的性能。

**[Paper URL](https://proceedings.mlr.press/v202/kauvar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kauvar23a/kauvar23a.pdf)** 

# How Does Information Bottleneck Help Deep Learning?
**题目:** 信息瓶颈如何帮助深入学习?

**作者:** Kenji Kawaguchi, Zhun Deng, Xu Ji, Jiaoyang Huang

**Abstract:** Numerous deep learning algorithms have been inspired by and understood via the notion of information bottleneck, where unnecessary information is (often implicitly) minimized while task-relevant information is maximized. However, a rigorous argument for justifying why it is desirable to control information bottlenecks has been elusive. In this paper, we provide the first rigorous learning theory for justifying the benefit of information bottleneck in deep learning by mathematically relating information bottleneck to generalization errors. Our theory proves that controlling information bottleneck is one way to control generalization errors in deep learning, although it is not the only or necessary way. We investigate the merit of our new mathematical findings with experiments across a range of architectures and learning settings. In many cases, generalization errors are shown to correlate with the degree of information bottleneck: i.e., the amount of the unnecessary information at hidden layers. This paper provides a theoretical foundation for current and future methods through the lens of information bottleneck. Our new generalization bounds scale with the degree of information bottleneck, unlike the previous bounds that scale with the number of parameters, VC dimension, Rademacher complexity, stability or robustness. Our code is publicly available at: https://github.com/xu-ji/information-bottleneck

**摘要:** 基于信息瓶颈的概念,许多深层学习算法被启发和理解,其中不必要的信息(往往隐含地)被最小化,而任务相关信息被最小化。然而,为什么控制信息瓶颈的合理论据是难以理解的。本文提供了通过数学关系信息瓶颈到一般化误差的第一个严格学习理论来证明深层学习中信息瓶颈的益处。我们的理论证明控制信息瓶颈是控制深层学习中的一般化误差的一种方法,尽管这不是唯一的或必要的方法。在许多情况下,一般化误差与信息瓶颈的程度相关:即隐藏层中不必要的信息的数量。本论文通过信息瓶颈的镜头为当前和未来方法提供理论基础。我们的新的一般化界限与信息瓶颈的程度相差,与以前的界限不同,这些界限与参数数、VC维度、Rademacher复杂度、稳定性或鲁棒性相差。我们的代码可于: https://github.com/xu-ji/information-bottleneck

**[Paper URL](https://proceedings.mlr.press/v202/kawaguchi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kawaguchi23a/kawaguchi23a.pdf)** 

# Instrumental Variable Estimation of Average Partial Causal Effects
**题目:** 平均部分原因影响的仪器变量估计

**作者:** Yuta Kawakami, Manabu Kuroki, Jin Tian

**Abstract:** Instrumental variable (IV) analysis is a powerful tool widely used to elucidate causal relationships. We study the problem of estimating the average partial causal effect (APCE) of a continuous treatment in an IV setting. Specifically, we develop new methods for estimating APCE based on a recent identification condition via an integral equation. We develop two families of methods, nonparametric and parametric - the former uses the Picard iteration to solve the integral equation; the latter parameterizes APCE using a linear basis function model. We analyze the statistical and computational properties of the proposed methods and illustrate them on synthetic and real data.

**摘要:** 仪器变量分析是一种广泛应用于解释因果关系的强有力工具。我们研究了在IV环境下持续治疗中估计平均部分因果效应(APCE)的问题。具体而言,我们通过积分方程,根据最近的识别条件,开发了新的估计 APCE的方法。我们开发了两种方法,非参数和参数:前一种使用Picard迭代来解决积分方程,后者用线性基函数模型参数化 APCE。我们分析了提议的方法的统计和计算特性,并对其在合成和实数据上进行了说明。

**[Paper URL](https://proceedings.mlr.press/v202/kawakami23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kawakami23a/kawakami23a.pdf)** 

# The Test of Tests: A Framework for Differentially Private Hypothesis Testing
**题目:** 测试的测试:不同程度的私有假设测试的框架

**作者:** Zeki Kazan, Kaiyan Shi, Adam Groce, Andrew P Bray

**Abstract:** We present a generic framework for creating differentially private versions of any hypothesis test in a black-box way. We analyze the resulting tests analytically and experimentally. Most crucially, we show good practical performance for small data sets, showing that at ε = 1 we only need 5-6 times as much data as in the fully public setting. We compare our work to the one existing framework of this type, as well as to several individually-designed private hypothesis tests. Our framework is higher power than other generic solutions and at least competitive with (and often better than) individually-designed tests.

**摘要:** 我们以黑箱的方式提供一种通用框架,以创建任何假设测试的差异性私人版本。我们分析结果的测试分析和实验。最重要的是,我们显示了小数据集的良好实际性能,表明在 ε = 1 时,我们只需要 5-6 倍的数据,如在完全公开环境中。我们比较我们的工作与这种类型的现有框架,以及几个单独设计的私人假设测试。我们的框架比其他通用解决方案强,并且至少与单独设计的测试具有竞争性。

**[Paper URL](https://proceedings.mlr.press/v202/kazan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kazan23a/kazan23a.pdf)** 

# Exact Inference in High-order Structured Prediction
**题目:** 高阶结构预测中的精确偏差

**作者:** Chuyang Ke, Jean Honorio

**Abstract:** In this paper, we study the problem of inference in high-order structured prediction tasks. In the context of Markov random fields, the goal of a high-order inference task is to maximize a score function on the space of labels, and the score function can be decomposed into sum of unary and high-order potentials. We apply a generative model approach to study the problem of high-order inference, and provide a two-stage convex optimization algorithm for exact label recovery. We also provide a new class of hypergraph structural properties related to hyperedge expansion that drives the success in general high-order inference problems. Finally, we connect the performance of our algorithm and the hyperedge expansion property using a novel hypergraph Cheeger-type inequality.

**摘要:** 本文研究了高阶结构预测任务的推导问题。在马可夫随机场中,高阶推导任务的目标是在标签空间上最大化分数函数,分数函数可以分解为单元和高阶势值的总数。我们应用生成模型方法研究高阶推导问题,并为准确标签恢复提供两个阶段凸优化算法。

**[Paper URL](https://proceedings.mlr.press/v202/ke23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ke23a/ke23a.pdf)** 

# Neural Wave Machines: Learning Spatiotemporally Structured Representations with Locally Coupled Oscillatory Recurrent Neural Networks
**题目:** 神经波机器:学习局部耦合振荡回流神经网络的时空结构表现

**作者:** T. Anderson Keller, Max Welling

**Abstract:** Traveling waves have been measured at a diversity of regions and scales in the brain, however a consensus as to their computational purpose has yet to be reached. An intriguing hypothesis is that traveling waves serve to structure neural representations both in space and time, thereby acting as an inductive bias towards natural data. In this work, we investigate this hypothesis by introducing the Neural Wave Machine (NWM) – a locally coupled oscillatory recurrent neural network capable of exhibiting traveling waves in its hidden state. After training on simple dynamic sequences, we show that this model indeed learns static spatial structure such as topographic organization, and further uses complex spatiotemporal structure such as traveling waves to encode observed transformations. To measure the computational implications of this structure, we use a suite of sequence classification and physical dynamics modeling tasks to show that the NWM is both more parameter efficient, and is able to forecast future trajectories of simple physical dynamical systems more accurately than existing state of the art counterparts.

**摘要:** 运动波在大脑的各个区域和尺度中被测量,但其计算目的尚未达成共识。一个引人注目的假设是,运动波可以在空间和时间中构造神经表现,从而作为对自然数据的诱导偏差。在本文中,我们通过引入神经波机器(NWM)来研究这一假设,一种能够在隐藏状态显示运动波的局部耦合振荡回流神经网络。为了测量该结构的计算影响,我们使用一系列序列分类和物理动力学建模任务来证明,NWM具有较高的参数效率,并且能够比现有的最先进的系统更准确地预测简单的物理动力学系统的未来轨迹。

**[Paper URL](https://proceedings.mlr.press/v202/keller23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/keller23a/keller23a.pdf)** 

# Homomorphism AutoEncoder -- Learning Group Structured Representations from Observed Transitions
**题目:** Homomorphism AutoEncoder -- 观察过渡的学习组结构表示

**作者:** Hamza Keurti, Hsiao-Ru Pan, Michel Besserve, Benjamin F Grewe, Bernhard Schölkopf

**Abstract:** How can agents learn internal models that veridically represent interactions with the real world is a largely open question. As machine learning is moving towards representations containing not just observational but also interventional knowledge, we study this problem using tools from representation learning and group theory. We propose methods enabling an agent acting upon the world to learn internal representations of sensory information that are consistent with actions that modify it. We use an autoencoder equipped with a group representation acting on its latent space, trained using an equivariance-derived loss in order to enforce a suitable homomorphism property on the group representation. In contrast to existing work, our approach does not require prior knowledge of the group and does not restrict the set of actions the agent can perform. We motivate our method theoretically, and show empirically that it can learn a group representation of the actions, thereby capturing the structure of the set of transformations applied to the environment. We further show that this allows agents to predict the effect of sequences of future actions with improved accuracy.

**摘要:** 代理人如何学习与现实世界相互作用的内部模型是一个主要的开放问题。由于机器学习正向包含不仅观察知识,而且干预知识的表述方向前进,我们利用表述学习和群论的工具研究这个问题。我们提出了使代理人在现实世界中学习与修改它的行为一致的感官信息的内部表述的方法。我们从理论上激励我们的方法,并从实例上证明它可以学习行动的群体表示,从而捕捉到环境所应用的一系列变换的结构。我们进一步证明,这使得代理人能够更准确地预测未来行动的序列的影响。

**[Paper URL](https://proceedings.mlr.press/v202/keurti23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/keurti23a/keurti23a.pdf)** 

# Rethinking Backdoor Attacks
**题目:** 重新思考后门攻击

**作者:** Alaa Khaddaj, Guillaume Leclerc, Aleksandar Makelov, Kristian Georgiev, Hadi Salman, Andrew Ilyas, Aleksander Madry

**Abstract:** In a backdoor attack, an adversary inserts maliciously constructed backdoor examples into a training set to make the resulting model vulnerable to manipulation. Defending against such attacks involves viewing inserted examples as outliers in the training set and using techniques from robust statistics to detect and remove them. In this work, we present a different approach to the backdoor attack problem. Specifically, we show that without structural information about the training data distribution, backdoor attacks are indistinguishable from naturally-occuring features in the data—and thus impossible to "detect" in a general sense. Then, guided by this observation, we revisit existing defenses against backdoor attacks and characterize the (often latent) assumptions they make, and on which they depend. Finally, we explore an alternative perspective on backdoor attacks: one that assumes these attacks correspond to the strongest feature in the training data. Under this assumption (which we make formal) we develop a new primitive for detecting backdoor attacks. Our primitive naturally gives rise to a detection algorithm that comes with theoretical guarantees, and is effective in practice.

**摘要:** 在后门攻击中,一个对手将恶意构造的后门实例插入到训练集合中,使结果模型易受操作。对此类攻击的防御包括将插入的实例视作训练集合中的异常,并使用鲁棒统计技术来检测和除去它们。在这个工作中,我们提出了对后门攻击问题的不同的方法。具体地说,我们表明,没有关于训练数据分布的结构信息,后门攻击与数据中的自然引人注目特征是不可区分的,因此在一般意义上是不可能“检测”的。在这一假设下(我们将其正式化)我们开发了一种用于检测后门攻击的新原始算法,我们的原始算法自然产生一种具有理论保障的检测算法,并且在实践中是有效的。

**[Paper URL](https://proceedings.mlr.press/v202/khaddaj23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/khaddaj23a/khaddaj23a.pdf)** 

# PAC Prediction Sets for Large Language Models of Code
**题目:** PAC预测组用于大型语言代码模型

**作者:** Adam Khakhar, Stephen Mell, Osbert Bastani

**Abstract:** Prediction sets have recently been shown to be a promising strategy for quantifying the uncertainty of deep neural networks in a way that provides theoretical guarantees. However, existing techniques have largely targeted settings where the space of labels is simple, so prediction sets can be arbitrary subsets of labels. For structured prediction problems where the space of labels is exponential in size, even prediction sets containing a small fraction of all labels can be exponentially large. In the context of code generation, we propose a solution that considers a restricted set of prediction sets that can compactly be represented as partial programs, which are programs with portions replaced with holes. Given a trained code generation model, our algorithm leverages a programming language’s abstract syntax tree to generate a set of programs such that the correct program is in the set with high-confidence. Valuable applications of our algorithm include a Codex-style code generator with holes in uncertain parts of the generated code, which provides a partial program with theoretical guarantees. We evaluate our approach on PICARD (a T5 model for SQL semantic parsing) and Codex (a GPT model for over a dozen programming languages, including Python), demonstrating that our approach generates compact PAC prediction sets. This is the first research contribution that generates PAC prediction sets for generative code models.

**摘要:** 预测集合最近被证明为一种具有理论保障的方法对深度神经网络不确定性的定量策略。然而,现有技术主要针对标签空间的设置,因此预测集合可以是任意的标签子集。 对于结构化预测问题,标签空间的指数性大小,甚至包含所有标签的一个小部分的预测集合也可以是指数性大的。我们对PICARD(SQL语义解析的T5模型)和Codex(包括Python在内的十多个编程语言的GPT模型)的方法进行了评估,证明我们的方法生成了小型PAC预测集。这是第一个为生成代码模型生成PAC预测集的研究贡献。

**[Paper URL](https://proceedings.mlr.press/v202/khakhar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/khakhar23a/khakhar23a.pdf)** 

# Accelerated Primal-Dual Methods for Convex-Strongly-Concave Saddle Point Problems
**题目:** 凸-强凹鞍点问题加速双重初始方法

**作者:** Mohammad Khalafi, Digvijay Boob

**Abstract:** We investigate a primal-dual (PD) method for the saddle point problem (SPP) that uses a linear approximation of the primal function instead of the standard proximal step, resulting in a linearized PD (LPD) method. For convex-strongly concave SPP, we observe that the LPD method has a suboptimal dependence on the Lipschitz constant of the primal function. To fix this issue, we combine features of Accelerated Gradient Descent with the LPD method resulting in a single-loop Accelerated Linearized Primal-Dual (ALPD) method. ALPD method achieves the optimal gradient complexity when the SPP has a semi-linear coupling function. We also present an inexact ALPD method for SPPs with a general nonlinear coupling function that maintains the optimal gradient evaluations of the primal parts and significantly improves the gradient evaluations of the coupling term compared to the ALPD method. We verify our findings with numerical experiments.

**摘要:** 研究了一种用于鞍点问题(SPP)的 primal-dual(PD)方法,该方法使用了初始函数的线性近似,而不是标准近阶步骤,从而产生一个线性PD(LPD)方法。对于凸凹凸凹凸SPP,我们观察到LPD方法对初始函数的 Lipschitz常数有亚最佳的依赖性。为了解决这个问题,我们结合加速梯度下降的特征与LPD方法,产生单环加速线性化初始-dual(ALPD)方法。ALPD方法在SPP具有半线性耦合函数时达到最佳梯度复杂性。

**[Paper URL](https://proceedings.mlr.press/v202/khalafi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/khalafi23a/khalafi23a.pdf)** 

# Loss Balancing for Fair Supervised Learning
**题目:** 公平监督学习的失衡

**作者:** Mohammad Mahdi Khalili, Xueru Zhang, Mahed Abroshan

**Abstract:** Supervised learning models have been used in various domains such as lending, college admission, face recognition, natural language processing, etc. However, they may inherit pre-existing biases from training data and exhibit discrimination against protected social groups. Various fairness notions have been proposed to address unfairness issues. In this work, we focus on Equalized Loss (EL), a fairness notion that requires the expected loss to be (approximately) equalized across different groups. Imposing EL on the learning process leads to a non-convex optimization problem even if the loss function is convex, and the existing fair learning algorithms cannot properly be adopted to find the fair predictor under the EL constraint. This paper introduces an algorithm that can leverage off-the-shelf convex programming tools (e.g., CVXPY (Diamond and Boyd, 2016; Agrawal et al., 2018)) to efficiently find the global optimum of this non-convex optimization. In particular, we propose the ELminimizer algorithm, which finds the optimal fair predictor under EL by reducing the non-convex optimization to a sequence of convex optimization problems. We theoretically prove that our algorithm finds the global optimal solution under certain conditions. Then, we support our theoretical results through several empirical studies

**摘要:** 监管型学习模型已经在各种领域使用,例如贷款、大学入学、面容识别、自然语言处理等。然而,它们可能继承从训练数据中存在的偏见,并表现出对受保护的社会群体的歧视。为了解决不公平问题,提出了不同的公平概念。本研究中,我们着重于均衡损失(EL)的概念,公平概念要求预期损失在不同群体中(大约)均等化。本文针对非凸优化问题,提出了一种优化算法,即以非凸优化为凸优化问题序列,在有限条件下求出最优的全球方案,并通过多项实证研究支持了该算法的理论结果。

**[Paper URL](https://proceedings.mlr.press/v202/khalili23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/khalili23a/khalili23a.pdf)** 

# Linearly Constrained Bilevel Optimization: A Smoothed Implicit Gradient Approach
**题目:** 线性约束双层优化: Smoothed implicit gradient approach

**作者:** Prashant Khanduri, Ioannis Tsaknakis, Yihua Zhang, Jia Liu, Sijia Liu, Jiawei Zhang, Mingyi Hong

**Abstract:** This work develops analysis and algorithms for solving a class of bilevel optimization problems where the lower-level (LL) problems have linear constraints. Most of the existing approaches for constrained bilevel problems rely on value function-based approximate reformulations, which suffer from issues such as non-convex and non-differentiable constraints. In contrast, in this work, we develop an implicit gradient-based approach, which is easy to implement, and is suitable for machine learning applications. We first provide an in-depth understanding of the problem, by showing that the implicit objective for such problems is in general non-differentiable. However, if we add some small (linear) perturbation to the LL objective, the resulting implicit objective becomes differentiable almost surely. This key observation opens the door for developing (deterministic and stochastic) gradient-based algorithms similar to the state-of-the-art ones for unconstrained bi-level problems. We show that when the implicit function is assumed to be strongly-convex, convex, and weakly-convex, the resulting algorithms converge with guaranteed rate. Finally, we experimentally corroborate the theoretical findings and evaluate the performance of the proposed framework on numerical and adversarial learning problems.

**摘要:** 本文研究了解决下层(LL)问题具有线性约束的双层优化问题类别的分析和算法。限制双层问题的现有方法大多依赖于值函数的近似改革,这些方法对非凸和非变异约束等问题产生影响。与此相反,本文开发了一个基于梯度的隐含方法,易于实现,适合于机器学习应用。我们首先提供问题的深入理解,表明此类问题的隐含目标一般是非变异的。然而,如果我们将一些小(线性)扰动添加到LL目标,结果的隐含目标几乎是可变异的。结果表明,当隐式函数假设是强凸、凸和弱凸,结果的算法与保证率趋同。最后,我们实验证实了理论结果,并评价了对数值和逆向学习问题提出的框架的性能。

**[Paper URL](https://proceedings.mlr.press/v202/khanduri23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/khanduri23a/khanduri23a.pdf)** 

# Emergent Asymmetry of Precision and Recall for Measuring Fidelity and Diversity of Generative Models in High Dimensions
**题目:** 高维生成模型的刚度与多样性测量的急剧不对称性与回顾

**作者:** Mahyar Khayatkhoei, Wael Abdalmageed

**Abstract:** Precision and Recall are two prominent metrics of generative performance, which were proposed to separately measure the fidelity and diversity of generative models. Given their central role in comparing and improving generative models, understanding their limitations are crucially important. To that end, in this work, we identify a critical flaw in the common approximation of these metrics using k-nearest-neighbors, namely, that the very interpretations of fidelity and diversity that are assigned to Precision and Recall can fail in high dimensions, resulting in very misleading conclusions. Specifically, we empirically and theoretically show that as the number of dimensions grows, two model distributions with supports at equal point-wise distance from the support of the real distribution, can have vastly different Precision and Recall regardless of their respective distributions, hence an emergent asymmetry in high dimensions. Based on our theoretical insights, we then provide simple yet effective modifications to these metrics to construct symmetric metrics regardless of the number of dimensions. Finally, we provide experiments on real-world datasets to illustrate that the identified flaw is not merely a pathological case, and that our proposed metrics are effective in alleviating its impact.

**摘要:** 精确和回想是两个重要的生成性能指标,它们被提议分别测量生成模型的忠实和多样性。由于它们在比较和改进生成模型中起着中心作用,理解其局限性是至关重要的。为此目的,我们在此研究中确定了利用k-nearest-neighbors对这些指标的共同近似中的一个关键缺陷,即精确和回想的忠实和多样性本身的解释在高维中可能失败,从而产生非常误导性的结论。最后,我们对实物数据集进行了实验,以说明识别的缺陷不仅仅是病理病例,而且我们提出的指标能有效减轻其影响。

**[Paper URL](https://proceedings.mlr.press/v202/khayatkhoei23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/khayatkhoei23a/khayatkhoei23a.pdf)** 

# Learning-augmented private algorithms for multiple quantile release
**题目:** 多量子释放学习增强的私人算法

**作者:** Mikhail Khodak, Kareem Amin, Travis Dick, Sergei Vassilvitskii

**Abstract:** When applying differential privacy to sensitive data, we can often improve performance using external information such as other sensitive data, public data, or human priors. We propose to use the learning-augmented algorithms (or algorithms with predictions) framework—previously applied largely to improve time complexity or competitive ratios—as a powerful way of designing and analyzing privacy-preserving methods that can take advantage of such external information to improve utility. This idea is instantiated on the important task of multiple quantile release, for which we derive error guarantees that scale with a natural measure of prediction quality while (almost) recovering state-of-the-art prediction-independent guarantees. Our analysis enjoys several advantages, including minimal assumptions about the data, a natural way of adding robustness, and the provision of useful surrogate losses for two novel ”meta” algorithms that learn predictions from other (potentially sensitive) data. We conclude with experiments on challenging tasks demonstrating that learning predictions across one or more instances can lead to large error reductions while preserving privacy.

**摘要:** 当对敏感数据应用微分隐私时,我们经常可以利用外部信息来提高性能,例如其他敏感数据、公共数据或人类预先数据。我们建议使用学习增强算法(或预测的算法)框架 — — 以前主要用于提高时间复杂度或竞争比率 — — 作为设计和分析利用这些外部信息来提高实用性的重要隐私保护方法的有力方法。我们的分析有几个优点,包括对数据的最小假设,一种自然增加鲁棒性的方法,以及提供两个新的“meta”算法的替代损失,这些算法可以从其他(潜在敏感)数据中学习预测。

**[Paper URL](https://proceedings.mlr.press/v202/khodak23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/khodak23a/khodak23a.pdf)** 

# CrossSplit: Mitigating Label Noise Memorization through Data Splitting
**题目:** CrossSplit:通过数据分割来减轻标签噪声记忆

**作者:** Jihye Kim, Aristide Baratin, Yan Zhang, Simon Lacoste-Julien

**Abstract:** We approach the problem of improving robustness of deep learning algorithms in the presence of label noise. Building upon existing label correction and co-teaching methods, we propose a novel training procedure to mitigate the memorization of noisy labels, called CrossSplit, which uses a pair of neural networks trained on two disjoint parts of the labeled dataset. CrossSplit combines two main ingredients: (i) Cross-split label correction. The idea is that, since the model trained on one part of the data cannot memorize example-label pairs from the other part, the training labels presented to each network can be smoothly adjusted by using the predictions of its peer network; (ii) Cross-split semi-supervised training. A network trained on one part of the data also uses the unlabeled inputs of the other part. Extensive experiments on CIFAR-10, CIFAR-100, Tiny-ImageNet and mini-WebVision datasets demonstrate that our method can outperform the current state-of-the-art in a wide range of noise ratios. The project page is at https://rlawlgul.github.io/.

**摘要:** 基于现有的标签校正和共教学方法,我们提出了一种新颖的训练方法来减轻噪声标签的记忆,称为CrossSplit,它使用了两个不同标签数据集的分离部分训练的神经网络。CrossSplit结合了两个主要成分: (i) Cross-split标签校正。对CIFAR-10、CIFAR-100、Tiny-ImageNet和Mini-WebVision数据集进行了广泛的实验,证明我们的方法在广泛的噪声比中能超越当前的最先进的方法。项目网页是://rlawlgul.github.io/。

**[Paper URL](https://proceedings.mlr.press/v202/kim23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23a/kim23a.pdf)** 

# Trainability, Expressivity and Interpretability in Gated Neural ODEs
**题目:** 门关神经元ODEs的训练性、表达性和解释性

**作者:** Timothy Doyeon Kim, Tankut Can, Kamesh Krishnamurthy

**Abstract:** Understanding how the dynamics in biological and artificial neural networks implement the computations required for a task is a salient open question in machine learning and neuroscience. In particular, computations requiring complex memory storage and retrieval pose a significant challenge for these networks to implement or learn. Recently, a family of models described by neural ordinary differential equations (nODEs) has emerged as powerful dynamical neural network models capable of capturing complex dynamics. Here, we extend nODEs by endowing them with adaptive timescales using gating interactions. We refer to these as gated neural ODEs (gnODEs). Using a task that requires memory of continuous quantities, we demonstrate the inductive bias of the gnODEs to learn (approximate) continuous attractors. We further show how reduced-dimensional gnODEs retain their modeling power while greatly improving interpretability, even allowing explicit visualization of the structure of learned attractors. We introduce a novel measure of expressivity which probes the capacity of a neural network to generate complex trajectories. Using this measure, we explore how the phase-space dimension of the nODEs and the complexity of the function modeling the flow field contribute to expressivity. We see that a more complex function for modeling the flow field allows a lower-dimensional nODE to capture a given target dynamics. Finally, we demonstrate the benefit of gating in nODEs on several real-world tasks.

**摘要:** 理解生物和人工神经网络中的动力学如何实现任务所需的计算是机器学习和神经科学的一个突出的开放问题。特别是,需要复杂的存储和检索的计算对这些网络实现或学习具有重大挑战。最近,由神经普通微分方程(nODEs)描述的模型家族 emerged as powerful dynamical neural network models capable of capturing complex dynamics。我们进一步展示了低维gnODEs如何保持其建模能力,同时极大地提高了可解释性,甚至允许明确的视觉化学习吸引器的结构。我们引入了一种新的表达能力测定神经网络生成复杂轨迹的能力测定方法。我们利用这个测定方法,探讨了nODEs的相空间维度和函数建模流域的复杂性如何促进表达性。我们发现,一个更复杂的函数建模流域允许一个低维nODE捕捉给定目标动态。

**[Paper URL](https://proceedings.mlr.press/v202/kim23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23b/kim23b.pdf)** 

# SAAL: Sharpness-Aware Active Learning
**题目:** SAAL:敏锐的主动学习

**作者:** Yoon-Yeong Kim, Youngjae Cho, Joonho Jang, Byeonghu Na, Yeongmin Kim, Kyungwoo Song, Wanmo Kang, Il-Chul Moon

**Abstract:** While deep neural networks play significant roles in many research areas, they are also prone to overfitting problems under limited data instances. To overcome overfitting, this paper introduces the first active learning method to incorporate the sharpness of loss space into the acquisition function. Specifically, our proposed method, Sharpness-Aware Active Learning (SAAL), constructs its acquisition function by selecting unlabeled instances whose perturbed loss becomes maximum. Unlike the Sharpness-Aware learning with fully-labeled datasets, we design a pseudo-labeling mechanism to anticipate the perturbed loss w.r.t. the ground-truth label, which we provide the theoretical bound for the optimization. We conduct experiments on various benchmark datasets for vision-based tasks in image classification, object detection, and domain adaptive semantic segmentation. The experimental results confirm that SAAL outperforms the baselines by selecting instances that have the potentially maximal perturbation on the loss. The code is available at https://github.com/YoonyeongKim/SAAL.

**摘要:** 深层神经网络在许多研究领域发挥着重要的作用,但它们在有限的数据实例下也容易发生过渡问题。为了克服过渡问题,本文介绍了将损失空间的敏锐性纳入获取函数的第一个主动学习方法。具体而言,我们提出的敏锐-敏锐主动学习法(英语:Sharpness-Aware Active Learning (SAAL))通过选择不标记的实例来构建其获取函数,其扰乱损失最大。与完全标记的敏锐-敏锐学习方法不同,我们设计了一个伪标记机制来预测扰乱损失,即地面-真实标记,为优化提供了理论约束。实验结果证实,SAAL通过选择具有潜在损失最大扰动的实例,超过了基线。代码可于 https://github.com/YoonyeongKim/SAAL。

**[Paper URL](https://proceedings.mlr.press/v202/kim23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23c/kim23c.pdf)** 

# Demonstration-free Autonomous Reinforcement Learning via Implicit and Bidirectional Curriculum
**题目:** 无演示的自主强化学习通过隐形和双向课程

**作者:** Jigang Kim, Daesol Cho, H. Jin Kim

**Abstract:** While reinforcement learning (RL) has achieved great success in acquiring complex skills solely from environmental interactions, it assumes that resets to the initial state are readily available at the end of each episode. Such an assumption hinders the autonomous learning of embodied agents due to the time-consuming and cumbersome workarounds for resetting in the physical world. Hence, there has been a growing interest in autonomous RL (ARL) methods that are capable of learning from non-episodic interactions. However, existing works on ARL are limited by their reliance on prior data and are unable to learn in environments where task-relevant interactions are sparse. In contrast, we propose a demonstration-free ARL algorithm via Implicit and Bi-directional Curriculum (IBC). With an auxiliary agent that is conditionally activated upon learning progress and a bidirectional goal curriculum based on optimal transport, our method outperforms previous methods, even the ones that leverage demonstrations.

**摘要:** 强化学习(英语:reinforcement learning,缩写为RL)是通过环境相互作用取得复杂的技能方面取得的巨大成功,但它假定在每一集的结尾都可以重新恢复到初始状态。这种假定阻碍了在物理世界中重置的主体的自主学习,因为需要花费大量时间和昂贵的工作方法。因此,人们对自主学习(英语:autonomous RL,缩写为ARL)方法越来越感兴趣,这些方法能够从非周期性相互作用中学习。然而,现有的ARL工作由于依赖于先前的数据而受到限制,无法在任务相关相互作用稀少的环境中学习。利用条件激活学习进度的辅助剂和基于最佳运输的双向目标课程,我们的方法超过了以往的方法,甚至超越了利用演示的方法。

**[Paper URL](https://proceedings.mlr.press/v202/kim23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23d/kim23d.pdf)** 

# Improved Algorithms for Multi-period Multi-class Packing Problems with Bandit Feedback
**题目:** 带子反馈的多周期多类包装问题改进算法

**作者:** Wonyoung Kim, Garud Iyengar, Assaf Zeevi

**Abstract:** We consider the linear contextual multi-class multi-period packing problem (LMMP) where the goal is to pack items such that the total vector of consumption is below a given budget vector and the total value is as large as possible. We consider the setting where the reward and the consumption vector associated with each action is a class-dependent linear function of the context, and the decision-maker receives bandit feedback. LMMP includes linear contextual bandits with knapsacks and online revenue management as special cases. We establish a new estimator which guarantees a faster convergence rate, and consequently, a lower regret in LMMP. We propose a bandit policy that is a closed-form function of said estimated parameters. When the contexts are non-degenerate, the regret of the proposed policy is sublinear in the context dimension, the number of classes, and the time horizon $T$ when the budget grows at least as $\sqrt{T}$. We also resolve an open problem posed in Agrawal & Devanur (2016) and extend the result to a multi-class setting. Our numerical experiments clearly demonstrate that the performance of our policy is superior to other benchmarks in the literature.

**摘要:** 我们考虑了线性上下文多类多周期包装问题(LMMP),其中目标是包装项目,使得消费的总向量低于给定的预算向量,且总值尽可能大。我们考虑了与每个行动相关的奖励和消费向量是上下文的类依赖的线性函数,决策者接受带子反馈。LMMP包括带子和在线收入管理的线性上下文带子作为特殊案例。我们建立了一个新的估计器,保证了更快的收敛率,从而降低了LMMP中的遗憾。我们提出了一种带子政策,它是上述估计参数的闭式函数。当上下文不退化时,提议的政策的遗憾是上下文维度、类数和时间范围$T$时,预算至少增长为$\sqrt{T}$。我们还解决了阿格拉瓦尔和德瓦努尔(2016年)提出的一个开放问题,并将其结果扩展到多类环境中。我们的数值实验清楚地表明,我们的政策表现优于文献中的其他指标。

**[Paper URL](https://proceedings.mlr.press/v202/kim23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23e/kim23e.pdf)** 

# Efficient Latency-Aware CNN Depth Compression via Two-Stage Dynamic Programming
**题目:** 通过双级动态编程实现高效的CNN深度压缩

**作者:** Jinuk Kim, Yeonwoo Jeong, Deokjae Lee, Hyun Oh Song

**Abstract:** Recent works on neural network pruning advocate that reducing the depth of the network is more effective in reducing run-time memory usage and accelerating inference latency than reducing the width of the network through channel pruning. In this regard, some recent works propose depth compression algorithms that merge convolution layers. However, the existing algorithms have a constricted search space and rely on human-engineered heuristics. In this paper, we propose a novel depth compression algorithm which targets general convolution operations. We propose a subset selection problem that replaces inefficient activation layers with identity functions and optimally merges consecutive convolution operations into shallow equivalent convolution operations for efficient end-to-end inference latency. Since the proposed subset selection problem is NP-hard, we formulate a surrogate optimization problem that can be solved exactly via two-stage dynamic programming within a few seconds. We evaluate our methods and baselines by TensorRT for a fair inference latency comparison. Our method outperforms the baseline method with higher accuracy and faster inference speed in MobileNetV2 on the ImageNet dataset. Specifically, we achieve $1.41\times$ speed-up with $0.11$%p accuracy gain in MobileNetV2-1.0 on the ImageNet.

**摘要:** 近年来对神经网络剪切的研究表明,减少网络的深度比通过剪切通道减少网络的宽度更有效减少运行时间内存的使用和加速推导延迟。在这方面,一些最近的研究提出了结合卷积层的深度压缩算法。然而,现有的算法具有有限的搜索空间,并依赖于人为设计的流理学。本文提出了一种针对一般卷积操作的新深度压缩算法。我们通过TensorRT对我们的方法和基线进行公平推导延迟比较。我们的方法超过了基于ImageNet数据集的MobileNetV2的基线方法,具有较高的准确性和更快的推导速度。

**[Paper URL](https://proceedings.mlr.press/v202/kim23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23f/kim23f.pdf)** 

# Probabilistic Concept Bottleneck Models
**题目:** 概率概念双臂模型

**作者:** Eunji Kim, Dahuin Jung, Sangha Park, Siwon Kim, Sungroh Yoon

**Abstract:** Interpretable models are designed to make decisions in a human-interpretable manner. Representatively, Concept Bottleneck Models (CBM) follow a two-step process of concept prediction and class prediction based on the predicted concepts. CBM provides explanations with high-level concepts derived from concept predictions; thus, reliable concept predictions are important for trustworthiness. In this study, we address the ambiguity issue that can harm reliability. While the existence of a concept can often be ambiguous in the data, CBM predicts concepts deterministically without considering this ambiguity. To provide a reliable interpretation against this ambiguity, we propose Probabilistic Concept Bottleneck Models (ProbCBM). By leveraging probabilistic concept embeddings, ProbCBM models uncertainty in concept prediction and provides explanations based on the concept and its corresponding uncertainty. This uncertainty enhances the reliability of the explanations. Furthermore, as class uncertainty is derived from concept uncertainty in ProbCBM, we can explain class uncertainty by means of concept uncertainty. Code is publicly available at https://github.com/ejkim47/prob-cbm.

**摘要:** 可解释模型设计为以人为本的方式作出决策。代表性地,概念角模型(CBM)遵循基于预测概念的概念预测和类预测的两步过程。CBM提供基于概念预测的高层次概念的解释,因此可靠的概念预测对于可靠性至关重要。本研究中,我们解决了可能损害可靠性的模糊问题。虽然一个概念的存在往往在数据中是模糊的,但CBM预测概念是确定性的,而不考虑这种模糊。为了对这种模糊提供可靠的解释,我们提出了概率性概念角模型(ProbCBM)。通过利用概率性概念嵌入,ProbCBM模型在概念预测中的不确定性和提供基于概念及其相应的不确定性的解释。这种不确定性提高了解释的可靠性。此外,由于在ProbCBM中,类不确定源自概念不确定,我们可以通过概念不确定来解释类不确定。代码可以在 https://github.com/ejkim47/prob-cbm上公开。

**[Paper URL](https://proceedings.mlr.press/v202/kim23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23g/kim23g.pdf)** 

# DevFormer: A Symmetric Transformer for Context-Aware Device Placement
**题目:** DevFormer:一个基于上下文的设备配置的统计变换器

**作者:** Haeyeon Kim, Minsu Kim, Federico Berto, Joungho Kim, Jinkyoo Park

**Abstract:** In this paper, we present DevFormer, a novel transformer-based architecture for addressing the complex and computationally demanding problem of hardware design optimization. Despite the demonstrated efficacy of transformers in domains including natural language processing and computer vision, their use in hardware design has been limited by the scarcity of offline data. Our approach addresses this limitation by introducing strong inductive biases such as relative positional embeddings and action-permutation symmetricity that effectively capture the hardware context and enable efficient design optimization with limited offline data. We apply DevFormer to the problem of decoupling capacitor placement and show that it outperforms state-of-the-art methods in both simulated and real hardware, leading to improved performances while reducing the number of components by more than 30%. Finally, we show that our approach achieves promising results in other offline contextual learning-based combinatorial optimization tasks.

**摘要:** 本文介绍了一种基于变换器的新型架构,用于解决硬件设计优化的复杂和计算上要求的问题。尽管变换器在包括自然语言处理和计算机视觉在内的领域具有显著的有效性,但其在硬件设计中的应用却由于网络数据的稀缺而受到限制。我们的方法通过引入相对位置嵌入和行动-变换对称性等强的诱导偏见来解决这一限制,从而有效地捕捉到硬件上下文,并通过有限的网络数据实现有效的设计优化。最后,我们证明了我们的方法在其他基于网络上下文学习的组合优化任务中取得了令人期待的结果。

**[Paper URL](https://proceedings.mlr.press/v202/kim23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23h/kim23h.pdf)** 

# Refining Generative Process with Discriminator Guidance in Score-based Diffusion Models
**题目:** 基于分数扩散模型中的歧视者指导的生成过程的改进

**作者:** Dongjun Kim, Yeongmin Kim, Se Jung Kwon, Wanmo Kang, Il-Chul Moon

**Abstract:** The proposed method, Discriminator Guidance, aims to improve sample generation of pre-trained diffusion models. The approach introduces a discriminator that gives explicit supervision to a denoising sample path whether it is realistic or not. Unlike GANs, our approach does not require joint training of score and discriminator networks. Instead, we train the discriminator after score training, making discriminator training stable and fast to converge. In sample generation, we add an auxiliary term to the pre-trained score to deceive the discriminator. This term corrects the model score to the data score at the optimal discriminator, which implies that the discriminator helps better score estimation in a complementary way. Using our algorithm, we achive state-of-the-art results on ImageNet 256x256 with FID 1.83 and recall 0.64, similar to the validation data’s FID (1.68) and recall (0.66). We release the code at https://github.com/alsdudrla10/DG.

**摘要:** 提议的方法,歧视者指导,旨在改进预训练的扩散模型的样品生成。该方法引入一种歧视者,它给予明确的监督,说明样品路径是否是现实的。与GAN不同,我们的方法不需要联合训练分数和歧视者网络。相反,我们训练分数训练之后的歧视者,使歧视者训练稳定和快速趋向。在样品生成中,我们添加了一个辅助词语,以欺骗歧视者。这个词语纠正了最佳歧视者的数据分数的模型分数,这意味着歧视者在互补的方式帮助更好的分数估算。使用我们的算法,我们取得图像网256x256的最新结果,与FID1.83和召回0.64类似,与验证数据FID1.68和召回0.66。

**[Paper URL](https://proceedings.mlr.press/v202/kim23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23i/kim23i.pdf)** 

# Robust Non-Linear Feedback Coding via Power-Constrained Deep Learning
**题目:** 基于电力约束的深入学习的鲁棒非线性反馈编码

**作者:** Junghoon Kim, Taejoon Kim, David Love, Christopher Brinton

**Abstract:** The design of codes for feedback-enabled communications has been a long-standing open problem. Recent research on non-linear, deep learning-based coding schemes have demonstrated significant improvements in communication reliability over linear codes, but are still vulnerable to the presence of forward and feedback noise over the channel. In this paper, we develop a new family of non-linear feedback codes that greatly enhance robustness to channel noise. Our autoencoder-based architecture is designed to learn codes based on consecutive blocks of bits, which obtains de-noising advantages over bit-by-bit processing to help overcome the physical separation between the encoder and decoder over a noisy channel. Moreover, we develop a power control layer at the encoder to explicitly incorporate hardware constraints into the learning optimization, and prove that the resulting average power constraint is satisfied asymptotically. Numerical experiments demonstrate that our scheme outperforms state-of-the-art feedback codes by wide margins over practical forward and feedback noise regimes, and provide information-theoretic insights on the behavior of our non-linear codes. Moreover, we observe that, in a long blocklength regime, canonical error correction codes are still preferable to feedback codes when the feedback noise becomes high. Our code is available at https://anonymous.4open.science/r/RCode1.

**摘要:** 基于反馈通信的代码设计是一个长期存在的开放问题。最近对非线性、深度学习的编码方案的研究显示了在线性代码上通信可靠性的显著改善,但仍易于在信道上存在前后反馈噪声。本文开发了一种新的非线性反馈代码家族,大大增强信道噪声的鲁棒性。数值实验表明,我们的方案在实际前后和反馈噪声机制上具有较大优势,并且提供了关于非线性代码的行为信息理论的洞察力。此外,我们观察到,在长块长度模式下,在反馈噪声高时,标准错误修正代码仍然比反馈代码更有利。

**[Paper URL](https://proceedings.mlr.press/v202/kim23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23j/kim23j.pdf)** 

# LESSON: Learning to Integrate Exploration Strategies for Reinforcement Learning via an Option Framework
**题目:** 教程:通过选择框架学习强化学习的探索策略集成

**作者:** Woojun Kim, Jeonghye Kim, Youngchul Sung

**Abstract:** In this paper, a unified framework for exploration in reinforcement learning (RL) is proposed based on an option-critic architecture. The proposed framework learns to integrate a set of diverse exploration strategies so that the agent can adaptively select the most effective exploration strategy to realize an effective exploration-exploitation trade-off for each given task. The effectiveness of the proposed exploration framework is demonstrated by various experiments in the MiniGrid and Atari environments.

**摘要:** 本文提出了一种基于选择-临界架构的增强学习勘探统一框架,该框架学习综合一系列不同的勘探策略,使探险人员能够自适应选择最有效的勘探策略,为每个任务实现有效的勘探-开发交换。

**[Paper URL](https://proceedings.mlr.press/v202/kim23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23k/kim23k.pdf)** 

# BPipe: Memory-Balanced Pipeline Parallelism for Training Large Language Models
**题目:** BPipe:训练大型语言模型的内存平衡管道平行

**作者:** Taebum Kim, Hyoungjoo Kim, Gyeong-In Yu, Byung-Gon Chun

**Abstract:** Pipeline parallelism is a key technique for training large language models within GPU clusters. However, it often leads to a memory imbalance problem, where certain GPUs face high memory pressure while others underutilize their capacity. This imbalance results in suboptimal training performance, even when the overall GPU memory capacity is sufficient for more efficient setups. To address this inefficiency, we propose BPipe, a novel approach for achieving memory balance in pipeline parallelism. BPipe employs an activation balancing method to transfer intermediate activations between GPUs during training, enabling all GPUs to utilize comparable amounts of memory. With balanced memory utilization, BPipe enhances the training efficiency of large language models like GPT-3 by eliminating redundant recomputations or increasing the micro-batch size. Our evaluation conducted on 48 A100 GPUs across six nodes interconnected with HDR InfiniBand shows that BPipe accelerates the training of GPT-3 96B and GPT-3 134B models by 1.25x-2.17x compared to Megatron-LM, a state-of-the-art framework for training large language models.

**摘要:** 在GPU集群内,管道平行是训练大型语言模型的一个关键技术,但它往往会导致记忆不平衡问题,其中某些GPU面临较高的内存压力,而其他则不充分利用其内存。这种不平衡的结果是训练性能低劣,即使整个GPU内存容量足够用于更高效的设置。为了解决这一不效率,我们提出了BPipe,一种实现管道平行中的内存平衡的新方法。BPipe采用了激活平衡方法,在训练期间将GPU间的中间激活转移到其他GPU之间,使所有GPU都能利用相等数量的内存。我们对48台与HDRInfiniBand连接的6节点的A100 GPU进行的评估显示,BPipe在GPT-3 96B和GPT-3 134B模型的训练速度比Megatron-LM(大型语言模型训练的最先进的框架)增加1.25x-2.17x。

**[Paper URL](https://proceedings.mlr.press/v202/kim23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23l/kim23l.pdf)** 

# Probabilistic Imputation for Time-series Classification with Missing Data
**题目:** 缺失数据时序分类的概率推理

**作者:** Seunghyun Kim, Hyunsu Kim, Eunggu Yun, Hwangrae Lee, Jaehun Lee, Juho Lee

**Abstract:** Multivariate time series data for real-world applications typically contain a significant amount of missing values. The dominant approach for classification with such missing values is to impute them heuristically with specific values (zero, mean, values of adjacent time-steps) or learnable parameters. However, these simple strategies do not take the data generative process into account, and more importantly, do not effectively capture the uncertainty in prediction due to the multiple possibilities for the missing values. In this paper, we propose a novel probabilistic framework for classification with multivariate time series data with missing values. Our model consists of two parts; a deep generative model for missing value imputation and a classifier. Extending the existing deep generative models to better capture structures of time-series data, our deep generative model part is trained to impute the missing values in multiple plausible ways, effectively modeling the uncertainty of the imputation. The classifier part takes the time series data along with the imputed missing values and classifies signals, and is trained to capture the predictive uncertainty due to the multiple possibilities of imputations. Importantly, we show that naïvely combining the generative model and the classifier could result in trivial solutions where the generative model does not produce meaningful imputations. To resolve this, we present a novel regularization technique that can promote the model to produce useful imputation values that help classification. Through extensive experiments on real-world time series data with missing values, we demonstrate the effectiveness of our method.

**摘要:** 实世界应用中多变量时间序列数据通常包含大量的丢失值。对这些丢失值进行分类的主导方法是用特定的值(零、平均、邻近时间步骤的值)或可学习的参数来推导它们。然而,这些简单的策略不考虑数据生成过程,更重要的是,由于丢失值的多种可能性,无法有效地捕捉预测中的不确定性。本文提出了一种新的概率框架,用于与丢失值的多变量时间序列数据分类。通过扩展现有的深层生成模型以更好地捕捉时间序列数据结构,我们的深层生成模型部分被训练以多种可信的方式推导缺失值,有效地建模归纳的不确定性。分类器部分将时间序列数据与归纳的缺失值结合起来分类信号,并被训练以捕捉归纳的多种可能性造成的预测不确定性。

**[Paper URL](https://proceedings.mlr.press/v202/kim23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23m/kim23m.pdf)** 

# Variational Curriculum Reinforcement Learning for Unsupervised Discovery of Skills
**题目:** 不同课程强化学习,无监督地发现技能

**作者:** Seongun Kim, Kyowoon Lee, Jaesik Choi

**Abstract:** Mutual information-based reinforcement learning (RL) has been proposed as a promising framework for retrieving complex skills autonomously without a task-oriented reward function through mutual information (MI) maximization or variational empowerment. However, learning complex skills is still challenging, due to the fact that the order of training skills can largely affect sample efficiency. Inspired by this, we recast variational empowerment as curriculum learning in goal-conditioned RL with an intrinsic reward function, which we name Variational Curriculum RL (VCRL). From this perspective, we propose a novel approach to unsupervised skill discovery based on information theory, called Value Uncertainty Variational Curriculum (VUVC). We prove that, under regularity conditions, VUVC accelerates the increase of entropy in the visited states compared to the uniform curriculum. We validate the effectiveness of our approach on complex navigation and robotic manipulation tasks in terms of sample efficiency and state coverage speed. We also demonstrate that the skills discovered by our method successfully complete a real-world robot navigation task in a zero-shot setup and that incorporating these skills with a global planner further increases the performance.

**摘要:** 基于相互信息的强化学习(英语:Mutual information-based reinforcement learning,简称RL)是通过相互信息(MI)最大化或变量赋权(英语:Varitional empowerment)自动获取复杂技能的有前途框架,但由于训练技能的顺序可能影响样品效率,学习复杂技能仍是一个挑战性课题。我们验证了我们对复杂导航和机器人操作任务的有效性,包括样品效率和状态覆盖速度。我们还证明了通过我们的方法发现的技能能够在零射击设置中成功完成一个真实机器人导航任务,并将这些技能结合到一个全球规划者进一步提高性能。

**[Paper URL](https://proceedings.mlr.press/v202/kim23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23n/kim23n.pdf)** 

# Margin-based Neural Network Watermarking
**题目:** 边缘神经网络水标记

**作者:** Byungjoo Kim, Suyoung Lee, Seanie Lee, Sooel Son, Sung Ju Hwang

**Abstract:** As Machine Learning as a Service (MLaaS) platforms become prevalent, deep neural network (DNN) watermarking techniques are gaining increasing attention, which enables one to verify the ownership of a target DNN model in a black-box scenario. Unfortunately, previous watermarking methods are vulnerable to functionality stealing attacks, thus allowing an adversary to falsely claim the ownership of a DNN model stolen from its original owner. In this work, we propose a novel margin-based DNN watermarking approach that is robust to the functionality stealing attacks based on model extraction and distillation. Specifically, during training, our method maximizes the margins of watermarked samples by using projected gradient ascent on them so that their predicted labels cannot change without compromising the accuracy of the model that the attacker tries to steal. We validate our method on multiple benchmarks and show that our watermarking method successfully defends against model extraction attacks, outperforming recent baselines.

**摘要:** 随着机器学习作为服务(MLaaS)平台的普及,深度神经网络(DNN)水标技术正日益受到关注,使得一个能够在黑箱场景中验证目标DNN模型的所有权。不幸的是,以前的水标方法易受功能盗窃攻击的侵害,从而使对手假称盗窃DNN模型的所有权。在这个工作中,我们提出了一种基于模型提取和蒸馏的新型边际DNN水标方法,以增强功能盗窃攻击的鲁棒性。通过多种指标验证了该方法,并证明了该水印法在模型提取攻击中具有较强的防护能力。

**[Paper URL](https://proceedings.mlr.press/v202/kim23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23o/kim23o.pdf)** 

# Regularizing Towards Soft Equivariance Under Mixed Symmetries
**题目:** 对混合交差下的软均衡进行调节

**作者:** Hyunsu Kim, Hyungi Lee, Hongseok Yang, Juho Lee

**Abstract:** Datasets often have their intrinsic symmetries, and particular deep-learning models called equivariant or invariant models have been developed to exploit these symmetries. However, if some or all of these symmetries are only approximate, which frequently happens in practice, these models may be suboptimal due to the architectural restrictions imposed on them. We tackle this issue of approximate symmetries in a setup where symmetries are mixed, i.e., they are symmetries of not single but multiple different types and the degree of approximation varies across these types. Instead of proposing a new architectural restriction as in most of the previous approaches, we present a regularizer-based method for building a model for a dataset with mixed approximate symmetries. The key component of our method is what we call equivariance regularizer for a given type of symmetries, which measures how much a model is equivariant with respect to the symmetries of the type. Our method is trained with these regularizers, one per each symmetry type, and the strength of the regularizers is automatically tuned during training, leading to the discovery of the approximation levels of some candidate symmetry types without explicit supervision. Using synthetic function approximation and motion forecasting tasks, we demonstrate that our method achieves better accuracy than prior approaches while discovering the approximate symmetry levels correctly.

**摘要:** 数据集经常有其内在的对称,并开发了被称为等式或不等式的深入学习模型来利用这些对称。然而,如果某些或所有这些对称只是近似,这经常在实践中发生,这些模型可能由于对它们施加的建筑限制而不理想。我们解决了对称对称问题在一个设置中,其中对称是混合的,即它们不是单一的,而是多种不同的类型的对称,并且近似程度在这些类型之间不同。通过对应函数近似和运动预测任务,证明了该方法在正确发现近似对称水平的同时,比以往方法更准确。

**[Paper URL](https://proceedings.mlr.press/v202/kim23p.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23p/kim23p.pdf)** 

# Model-based Offline Reinforcement Learning with Count-based Conservatism
**题目:** 基于模型的在线强化学习与基于数值的保守主义

**作者:** Byeongchan Kim, Min-Hwan Oh

**Abstract:** In this paper, we present a model-based offline reinforcement learning method that integrates count-based conservatism, named $\texttt{Count-MORL}$. Our method utilizes the count estimates of state-action pairs to quantify model estimation error, marking the first algorithm of demonstrating the efficacy of count-based conservatism in model-based offline deep RL to the best of our knowledge. For our proposed method, we first show that the estimation error is inversely proportional to the frequency of state-action pairs. Secondly, we demonstrate that the learned policy under the count-based conservative model offers near-optimality performance guarantees. Through extensive numerical experiments, we validate that $\texttt{Count-MORL}$ with hash code implementation significantly outperforms existing offline RL algorithms on the D4RL benchmark datasets. The code is accessible at https://github.com/oh-lab/Count-MORL.

**摘要:** 本文提出了一种基于模型的在线增强学习方法,该方法将基于数值的保守主义结合起来,命名为$\texttt{Count-MORL}$。该方法利用状态-行动对数值估计来定量模型估计误差,以显示基于数值的保守主义在 model-based offline deep RL中的有效性,这是我们最能知的第一个算法。针对我们提出的方法,我们首先表明估计误差与状态-行动对数的频率是逆比例的。

**[Paper URL](https://proceedings.mlr.press/v202/kim23q.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23q/kim23q.pdf)** 

# Transformer-based Stagewise Decomposition for Large-Scale Multistage Stochastic Optimization
**题目:** 基于变压器的大规模多级随机优化阶段分解

**作者:** Chanyeong Kim, Jongwoong Park, Hyunglip Bae, Woo Chang Kim

**Abstract:** Solving large-scale multistage stochastic programming (MSP) problems poses a significant challenge as commonly used stagewise decomposition algorithms, including stochastic dual dynamic programming (SDDP), face growing time complexity as the subproblem size and problem count increase. Traditional approaches approximate the value functions as piecewise linear convex functions by incrementally accumulating subgradient cutting planes from the primal and dual solutions of stagewise subproblems. Recognizing these limitations, we introduce TranSDDP, a novel Transformer-based stagewise decomposition algorithm. This innovative approach leverages the structural advantages of the Transformer model, implementing a sequential method for integrating subgradient cutting planes to approximate the value function. Through our numerical experiments, we affirm TranSDDP’s effectiveness in addressing MSP problems. It efficiently generates a piecewise linear approximation for the value function, significantly reducing computation time while preserving solution quality, thus marking a promising progression in the treatment of large-scale multistage stochastic programming problems.

**摘要:** 大规模多级随机编程(MSP)问题作为常用的分阶段分解算法,包括随机双动态编程(SDDP),面临着随着分问题大小和问题数增加的日益复杂的时间问题,提出了一个重大挑战。传统的方法通过从分阶段分问题的初始和双解累积分级切片来作为分段线性凸函数近似值函数。认识到这些局限性,我们介绍了一种新颖的变换器分阶段分解算法(Transformer-based stagewise decomposition algorithm)。该创新方法利用变换器模型的结构优势,实现了分级切片集成的顺序方法来近似值函数。它有效地生成值函数的分段线性近似,大大减少计算时间,同时保持解决方案质量,从而标志着大规模多级随机编程问题的处理有希望的进展。

**[Paper URL](https://proceedings.mlr.press/v202/kim23r.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23r/kim23r.pdf)** 

# SurProGenes: Survival Risk-Ordered Representation of Cancer Patients and Genes for the Identification of Prognostic Genes
**题目:** SurProGenes:癌症患者生存风险分类代表及诊断基因的基因

**作者:** Junetae Kim, Kyoungsuk Park, Hanseok Jeong, Youngwook Kim, Jeongseon Kim, Sun-Young Kim

**Abstract:** Identifying prognostic genes associated with patient survival is an important goal in cancer genomics, as this information could inform treatment approaches and improve patient outcomes. However, the identification of prognostic genes is complicated by the high dimensionality of genetic data, which makes their identification computationally intensive. Furthermore, most cancer genomics studies lack appropriate low-risk groups against which to compare. To address these issues, we present a framework that identifies candidate prognostic genes by integrating representation learning and statistical analysis approaches. Specifically, we propose a collaborative filtering-derived mechanism to represent patients in order of their survival risk, facilitating their dichotomization. We also propose a mechanism that allows embedded gene vectors to be polarized on the extremities of, or centered on, both reference axes to facilitate recommendations. Restricting our analysis to a few representative genes within each cluster allowed for the efficient identification of prognostic genes. Finally, we demonstrate the potential of this proposed framework for identifying prognostic genes.

**摘要:** 鉴别与患者生存有关的预后基因是癌症基因组学的重要目标,因为这些信息可以指导治疗方法和改善患者的结果。然而,预后基因的鉴别由于基因数据的高维度而复杂,使得其鉴别具有计算强度。此外,大多数癌症基因组学研究缺乏与比较的适当低风险群体。为了解决这些问题,我们提出了一种通过综合表现学习和统计分析方法来鉴别候选预后基因的框架。通过将分析限于每个集群中的少数代表性基因,能够有效地识别预后基因。最后,我们证明了该框架对预后基因的识别具有潜力。

**[Paper URL](https://proceedings.mlr.press/v202/kim23s.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23s/kim23s.pdf)** 

# Stable and Consistent Prediction of 3D Characteristic Orientation via Invariant Residual Learning
**题目:** 基于不变剩余学习的3D特征定位的稳定和一致预测

**作者:** Seungwook Kim, Chunghyun Park, Yoonwoo Jeong, Jaesik Park, Minsu Cho

**Abstract:** Learning to predict reliable characteristic orientations of 3D point clouds is an important yet challenging problem, as different point clouds of the same class may have largely varying appearances. In this work, we introduce a novel method to decouple the shape geometry and semantics of the input point cloud to achieve both stability and consistency. The proposed method integrates shape-geometry-based SO(3)-equivariant learning and shape-semantics-based SO(3)-invariant residual learning, where a final characteristic orientation is obtained by calibrating an SO(3)-equivariant orientation hypothesis using an SO(3)-invariant residual rotation. In experiments, the proposed method not only demonstrates superior stability and consistency but also exhibits state-of-the-art performances when applied to point cloud part segmentation, given randomly rotated inputs.

**摘要:** 基于形状几何的SO(3)等式学习和基于形状几何的SO(3)不等式残留学习相结合,通过校正一个SO(3)等式定位假设以SO(3)不等式残留回转实现最终的特征定位。在实验中,该方法不仅具有较高的稳定性和一致性,而且在随机回转输入时应用于点云部分分割时具有最先进的性能。

**[Paper URL](https://proceedings.mlr.press/v202/kim23t.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23t/kim23t.pdf)** 

# Prefer to Classify: Improving Text Classifiers via Auxiliary Preference Learning
**题目:** 优先分类:通过辅助偏好学习改进文本分类器

**作者:** Jaehyung Kim, Jinwoo Shin, Dongyeop Kang

**Abstract:** The development of largely human-annotated benchmarks has driven the success of deep neural networks in various NLP tasks. To enhance the effectiveness of existing benchmarks, collecting new additional input-output pairs is often too costly and challenging, particularly considering their marginal impact on improving the current model accuracy. Instead, additional or complementary annotations on the existing input texts in the benchmarks can be preferable as an efficient way to pay the additional human cost. In this paper, we investigate task-specific preferences between pairs of input texts as a new alternative way for such auxiliary data annotation. From pair-wise comparisons with respect to the task, the auxiliary preference learning enables the model to learn an additional informative training signal that cannot be captured with instance-wise task labels. To this end, we propose a novel multi-task learning framework, called prefer-to-classify (P2C), which can enjoy the cooperative effect of learning both the given classification task and the auxiliary preferences. Here, we provide three different ways to collect preference signals in practice: (a) implicitly extracting from annotation records (for free, but often unavailable), (b) collecting explicitly from crowd workers (high paid), or (c) pre-trained large language models such as GPT-3 (low paid). Given existing classification NLP benchmarks, we demonstrate that the proposed auxiliary preference learning via P2C on them is effective in improving text classifiers. Our codes are publicly available.

**摘要:** 基于人为注释的基准方法的开发,推动了深入神经网络在各种NLP任务中取得成功。为了提高现有基准的有效性,收集新的额外输入输出对往往太昂贵和挑战性,特别是考虑到它们对提高当前模型精度的边缘影响。相反,在基准中现有输入文本上的附加或补充注释可以作为支付额外人力成本的有效方法更佳。为此,我们提出了一种新的多任务学习框架,称为优先级分类(P2C),它可以享受学习给定的分类任务和辅助优先级的协同效应。在此,我们提供了三种在实践中收集优先级信号的方法: (a)隐含地从注释记录中提取(免费,但往往不可用), (b)隐含地从人群工人(高薪)提取,或 (c)预先训练的大型语言模型,如GPT-3(低薪)。

**[Paper URL](https://proceedings.mlr.press/v202/kim23u.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23u/kim23u.pdf)** 

# An Adaptive Entropy-Regularization Framework for Multi-Agent Reinforcement Learning
**题目:** 多干事强化学习的适应型内陆规则化框架

**作者:** Woojun Kim, Youngchul Sung

**Abstract:** In this paper, we propose an adaptive entropy-regularization framework (ADER) for multi-agent reinforcement learning (RL) to learn the adequate amount of exploration of each agent for entropy-based exploration. In order to derive a metric for the proper level of exploration entropy for each agent, we disentangle the soft value function into two types: one for pure return and the other for entropy. By applying multi-agent value factorization to the disentangled value function of pure return, we obtain a metric to determine the relevant level of exploration entropy for each agent, given by the partial derivative of the pure-return value function with respect to (w.r.t.) the policy entropy of each agent. Based on this metric, we propose the ADER algorithm based on maximum entropy RL, which controls the necessary level of exploration across agents over time by learning the proper target entropy for each agent. Experimental results show that the proposed scheme significantly outperforms current state-of-the-art multi-agent RL algorithms.

**摘要:** 本文提出了一种适应性熵调节框架(ADER)用于多元代理增强学习(RL),以学习每个代理的充分的探索量。为了导出每个代理的适当探索熵的度量,我们将软值函数分开为两个类型:一个用于纯返回和另一个用于熵。通过应用多元代理值因子化到纯返回的分离值函数,我们得到一个度量来确定每个代理的探索熵的适当水平,由纯返回值函数的偏导函数与(w.r.t.)每个代理的政策熵有关。基于此度量,我们提出了基于最大熵RL的ADER算法,该算法通过学习每个代理的适当目标熵,在时间上控制各个代理的必要探索水平。实验结果表明,该方案大大优于现行的多agentRL算法。

**[Paper URL](https://proceedings.mlr.press/v202/kim23v.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23v/kim23v.pdf)** 

# Practical and Matching Gradient Variance Bounds for Black-Box Variational Bayesian Inference
**题目:** 黑箱变量贝叶斯ference的实际和匹配梯度变量边界

**作者:** Kyurae Kim, Kaiwen Wu, Jisu Oh, Jacob R. Gardner

**Abstract:** Understanding the gradient variance of black-box variational inference (BBVI) is a crucial step for establishing its convergence and developing algorithmic improvements. However, existing studies have yet to show that the gradient variance of BBVI satisfies the conditions used to study the convergence of stochastic gradient descent (SGD), the workhorse of BBVI. In this work, we show that BBVI satisfies a matching bound corresponding to the ABC condition used in the SGD literature when applied to smooth and quadratically-growing log-likelihoods. Our results generalize to nonlinear covariance parameterizations widely used in the practice of BBVI. Furthermore, we show that the variance of the mean-field parameterization has provably superior dimensional dependence.

**摘要:** 了解黑箱变量推理的梯度变量是建立其收敛性和开发算法改进的关键步骤,但现有研究尚未证明BBVI的梯度变量满足了研究随机梯度下降(SGD)收敛条件的条件。本研究中,我们证明BBVI满足了在SGD文献中应用于平滑和二次增长的逻辑概率时使用ABC条件的匹配界限。

**[Paper URL](https://proceedings.mlr.press/v202/kim23w.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23w/kim23w.pdf)** 

# Learnability and Algorithm for Continual Learning
**题目:** 持续学习的可学习性和算法

**作者:** Gyuhak Kim, Changnan Xiao, Tatsuya Konishi, Bing Liu

**Abstract:** This paper studies the challenging continual learning (CL) setting of Class Incremental Learning (CIL). CIL learns a sequence of tasks consisting of disjoint sets of concepts or classes. At any time, a single model is built that can be applied to predict/classify test instances of any classes learned thus far without providing any task related information for each test instance. Although many techniques have been proposed for CIL, they are mostly empirical. It has been shown recently that a strong CIL system needs a strong within-task prediction (WP) and a strong out-of-distribution (OOD) detection for each task. However, it is still not known whether CIL is actually learnable. This paper shows that CIL is learnable. Based on the theory, a new CIL algorithm is also proposed. Experimental results demonstrate its effectiveness.

**摘要:** 本文研究了类累进学习(CIL)的挑战性持续学习(CL)设置。CIL学习的任务序列由不同概念或类组成。在任何时候,都建立一个单一模型,可用于预测/分类迄今所学习的任何类的测试实例,而不为每个测试实例提供任何任务相关信息。虽然为CIL提出了许多技术,但它们大多是经验性的。最近已经证明,一个强的CIL系统需要对每个任务进行强的内部任务预测(WP)和强的外部分配(OOD)检测。然而,目前还不清楚CIL是否确实可学习。本文表明CIL是可学习的。基于理论,提出了一种新的CIL算法。实验结果证明其有效性。

**[Paper URL](https://proceedings.mlr.press/v202/kim23x.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23x/kim23x.pdf)** 

# Unifying Nesterov’s Accelerated Gradient Methods for Convex and Strongly Convex Objective Functions
**题目:** 统一内斯特罗夫加速梯度方法对凸和强凸目标函数

**作者:** Jungbin Kim, Insoon Yang

**Abstract:** Although Nesterov’s accelerated gradient method (AGM) has been studied from various perspectives, it remains unclear why the most popular forms of AGMs must handle convex and strongly convex objective functions separately. To address this inconsistency, we propose a novel unified framework for Lagrangians, ordinary differential equation (ODE) models, and algorithms. As a special case, our new simple momentum algorithm, which we call the unified AGM, seamlessly bridges the gap between the two most popular forms of Nesterov’s AGM and has a superior convergence guarantee compared to existing algorithms for non-strongly convex objective functions. This property is beneficial in practice when considering ill-conditioned $\mu$-strongly convex objective functions (with small $\mu$). Furthermore, we generalize this algorithm and the corresponding ODE model to the higher-order non-Euclidean setting. Last but not least, our unified framework is used to construct the unified AGM-G ODE, a novel ODE model for minimizing the gradient norm of strongly convex functions.

**摘要:** 尽管纳斯特罗夫的加速度梯度方法(AGM)已经从不同角度研究,但仍不清楚为什么最受欢迎的AGM形式必须单独处理凸和强凸目标函数。为了解决这一不一致性,我们提出了一种新统一框架,用于拉格兰人、普通差分方程(ODE)模型和算法。作为特殊案例,我们称之为统一AGM的新简单动量算法,无缝地跨越了纳斯特罗夫的AGM两个最受欢迎形式之间的差距,与现有的非凸目标函数算法相比具有优越的收敛性保证。最后,我们统一的框架被用来构建统一的AGM-G ODE,一种新型的ODE模型,用于最小化强凸函数的梯度规范。

**[Paper URL](https://proceedings.mlr.press/v202/kim23y.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23y/kim23y.pdf)** 

# Denoising MCMC for Accelerating Diffusion-Based Generative Models
**题目:** 加速扩散型生成模型的称呼MCMC

**作者:** Beomsu Kim, Jong Chul Ye

**Abstract:** The sampling process of diffusion models can be interpreted as solving the reverse stochastic differential equation (SDE) or the ordinary differential equation (ODE) of the diffusion process, which often requires up to thousands of discretization steps to generate a single image. This has sparked a great interest in developing efficient integration techniques for reverse-S/ODEs. Here, we propose an orthogonal approach to accelerating score-based sampling: Denoising MCMC (DMCMC). DMCMC first uses MCMC to produce initialization points for reverse-S/ODE in the product space of data and diffusion time. Then, a reverse-S/ODE integrator is used to denoise the initialization points. Since MCMC traverses close to the data manifold, the cost of producing a clean sample for DMCMC is much less than that of producing a clean sample from noise. Denoising Langevin Gibbs, an instance of DMCMC, successfully accelerates all six reverse-S/ODE integrators considered in this work, and achieves state-of-the-art results: in the limited number of score function evaluation (NFE) setting on CIFAR10, we have $3.25$ FID with $\approx 10$ NFE and $2.49$ FID with $\approx 16$ NFE. On CelebA-HQ-256, we have $6.99$ FID with $\approx 160$ NFE, which beats the current best record of Kim et al. (2022) among score-based models, $7.16$ FID with $4000$ NFE. Code: https://github.com/1202kbs/DMCMC

**摘要:** 扩散模型的采样过程可以被解释为解决扩散过程的逆随机微分方程(SDE)或普通微分方程(ODE),通常需要数千个离散步骤来生成一个单一图像。这引发了对逆S/ODEs高效集成技术开发的极大兴趣。这里,我们提议加速分数based采样的正交方法: Denoising MCMC(DMCMC)。DMCMC首先使用MCMC来在数据和扩散时间的产物空间中产生逆S/ODE的初始点。DMCMC的一个实例,命名为兰格文·吉布斯,成功地加速了在这项工作中考虑的六种反向S/ODE集成器,并实现了最先进的结果:在CIFAR10的有限数值评分函数(NFE)设置中,我们有$3.25的FID和$10的FID和$2.49的FID和$16的FID。在CelebA-HQ-256上,我们有$6.99的FID和$160的FID,这打破了基姆等人(英语:Kim et al.)在基于评分模型中目前的最佳记录,$7.16的FID和$4000$的NFE。代码: https://github.com/1202kbs/DMCMC

**[Paper URL](https://proceedings.mlr.press/v202/kim23z.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23z/kim23z.pdf)** 

# Structure Learning of Latent Factors via Clique Search on Correlation Thresholded Graphs
**题目:** 按键查找相关性阻塞图的结构学习

**作者:** Dale Kim, Qing Zhou

**Abstract:** Despite the widespread application of latent factor analysis, existing methods suffer from the following weaknesses: requiring the number of factors to be known, lack of theoretical guarantees for learning the model structure, and nonidentifiability of the parameters due to rotation invariance properties of the likelihood. We address these concerns by proposing a fast correlation thresholding (CT) algorithm that simultaneously learns the number of latent factors and a rotationally identifiable model structure. Our novel approach translates this structure learning problem into the search for so-called independent maximal cliques in a thresholded correlation graph that can be easily constructed from the observed data. Our clique analysis technique scales well up to thousands of variables, while competing methods are not applicable in a reasonable amount of running time. We establish a finite-sample error bound and high-dimensional consistency for the structure learning of our method. Through a series of simulation studies and a real data example, we show that the CT algorithm is an accurate method for learning the structure of factor analysis models and is robust to violations of its assumptions.

**摘要:** 尽管延迟因子分析已广泛应用,现有方法仍存在以下缺陷: 需要知道因素数目,缺乏学习模型结构的理论保证,以及由于概率的旋转不变性特性,参数无法识别。我们通过提出快速相关阈值(CT)算法,同时学习延迟因子数目和可旋转识别模型结构,解决这些问题。通过一系列仿真研究和实数据实例,证明CT算法是学习因子分析模型结构的准确方法,对其假设的违反具有鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/kim23aa.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23aa/kim23aa.pdf)** 

# Fair and Robust Estimation of Heterogeneous Treatment Effects for Policy Learning
**题目:** 政策学习中异种治疗效果的公正可靠估计

**作者:** Kwangho Kim, Jose R Zubizarreta

**Abstract:** We propose a simple and general framework for nonparametric estimation of heterogeneous treatment effects under fairness constraints. Under standard regularity conditions, we show that the resulting estimators possess the double robustness property. We use this framework to characterize the trade-off between fairness and the maximum welfare achievable by the optimal policy. We evaluate the methods in a simulation study and illustrate them in a real-world case study.

**摘要:** 针对公平约束下的异质处理效应的非参数估计,提出了一种简单、通用的框架,在标准规律条件下,证明结果的估计者具有双重鲁棒性特性。我们利用这个框架,对公平与最优政策实现的最大福利之间的权衡特征进行了分析,并在仿真研究中对其进行了实例研究。

**[Paper URL](https://proceedings.mlr.press/v202/kim23ab.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kim23ab/kim23ab.pdf)** 

# Proper Losses for Discrete Generative Models
**题目:** 离散生成模型的适当损失

**作者:** Dhamma Kimpara, Rafael Frongillo, Bo Waggoner

**Abstract:** We initiate the study of proper losses for evaluating generative models in the discrete setting. Unlike traditional proper losses, we treat both the generative model and the target distribution as black-boxes, only assuming ability to draw i.i.d. samples. We define a loss to be black-box proper if the generative distribution that minimizes expected loss is equal to the target distribution. Using techniques from statistical estimation theory, we give a general construction and characterization of black-box proper losses: they must take a polynomial form, and the number of draws from the model and target distribution must exceed the degree of the polynomial. The characterization rules out a loss whose expectation is the cross-entropy between the target distribution and the model. By extending the construction to arbitrary sampling schemes such as Poisson sampling, however, we show that one can construct such a loss.

**摘要:** 在离散设置中对生成模型进行评估时,我们开始对适当损失进行研究。与传统的适当损失不同,我们把生成模型和目标分布当作黑箱,仅假设能够抽取即是样品。如果预期损失的生成分布等于目标分布,则定义损失为黑箱适当。使用统计估计理论的方法,我们给出了黑箱适当损失的一般构造和特征:它们必须采取多项式形式,从模型和目标分布中抽取的数目必须超过多项式的程度。

**[Paper URL](https://proceedings.mlr.press/v202/kimpara23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kimpara23a/kimpara23a.pdf)** 

# Controlling Posterior Collapse by an Inverse Lipschitz Constraint on the Decoder Network
**题目:** 逆利普希茨约束在除去器网络上的后倒塌控制

**作者:** Yuri Kinoshita, Kenta Oono, Kenji Fukumizu, Yuichi Yoshida, Shin-Ichi Maeda

**Abstract:** Variational autoencoders (VAEs) are one of the deep generative models that have experienced enormous success over the past decades. However, in practice, they suffer from a problem called posterior collapse, which occurs when the posterior distribution coincides, or collapses, with the prior taking no information from the latent structure of the input data into consideration. In this work, we introduce an inverse Lipschitz neural network into the decoder and, based on this architecture, provide a new method that can control in a simple and clear manner the degree of posterior collapse for a wide range of VAE models equipped with a concrete theoretical guarantee. We also illustrate the effectiveness of our method through several numerical experiments.

**摘要:** 变量自编码器(VAEs)是在过去几十年中经历了巨大的成功深层生成模型之一。然而,在实践中,它们存在一种叫做后退倒的问题,它发生在后退分布相符时或倒塌时,前者没有从输入数据的隐形结构中获取信息。在这一工作中,我们引入了逆利普希茨神经网络,并基于这种架构,提供了一种能够简单而清晰地控制后退倒度的新方法,用于具有具体的理论保证的广泛的VAE模型。

**[Paper URL](https://proceedings.mlr.press/v202/kinoshita23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kinoshita23a/kinoshita23a.pdf)** 

# A Watermark for Large Language Models
**题目:** 大型语言模型的水印

**作者:** John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, Tom Goldstein

**Abstract:** Potential harms of large language models can be mitigated by watermarking model output, i.e., embedding signals into generated text that are invisible to humans but algorithmically detectable from a short span of tokens. We propose a watermarking framework for proprietary language models. The watermark can be embedded with negligible impact on text quality, and can be detected using an efficient open-source algorithm without access to the language model API or parameters. The watermark works by selecting a randomized set of "green" tokens before a word is generated, and then softly promoting use of green tokens during sampling. We propose a statistical test for detecting the watermark with interpretable p-values, and derive an information-theoretic framework for analyzing the sensitivity of the watermark. We test the watermark using a multi-billion parameter model from the Open Pretrained Transformer (OPT) family, and discuss robustness and security.

**摘要:** 通过水标模型输出可以减轻大型语言模型的潜在危害,即将信号嵌入生成文本中,这些信号对人来说是看不见的,但从短范围的符号可以进行算法检测。我们提出了一种 proprietary language models的水标框架。水标可以嵌入到文本质量上,并且可以在没有访问语言模型API或参数的情况下使用高效的 open-source算法检测。水标通过选择一个字符生成前随机化的“绿色”符号集,然后在采样过程中轻轻地促进绿色符号的使用。我们提出了一种具有解释性p值的水标检测的统计测试,并推导了一个信息理论框架来分析水标的敏感性。我们测试水标使用来自Open Pretrained Transformer(OPT)家族的多亿参数模型,并讨论鲁棒性和安全性。

**[Paper URL](https://proceedings.mlr.press/v202/kirchenbauer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf)** 

# Probabilistic Contrastive Learning Recovers the Correct Aleatoric Uncertainty of Ambiguous Inputs
**题目:**  Probabilistic Contrastive Learning 纠正模糊输入的正确代数不确定性

**作者:** Michael Kirchhof, Enkelejda Kasneci, Seong Joon Oh

**Abstract:** Contrastively trained encoders have recently been proven to invert the data-generating process: they encode each input, e.g., an image, into the true latent vector that generated the image (Zimmermann et al., 2021). However, real-world observations often have inherent ambiguities. For instance, images may be blurred or only show a 2D view of a 3D object, so multiple latents could have generated them. This makes the true posterior for the latent vector probabilistic with heteroscedastic uncertainty. In this setup, we extend the common InfoNCE objective and encoders to predict latent distributions instead of points. We prove that these distributions recover the correct posteriors of the data-generating process, including its level of aleatoric uncertainty, up to a rotation of the latent space. In addition to providing calibrated uncertainty estimates, these posteriors allow the computation of credible intervals in image retrieval. They comprise images with the same latent as a given query, subject to its uncertainty. Code is at https://github.com/mkirchhof/Probabilistic_Contrastive_Learning .

**摘要:** 反向训练的编码器最近被证明可以逆转数据生成过程:它们将每个输入,例如图像,编码到生成图像的真潜向量(Zimmermann et al., 2021)。然而,实世界观察往往具有内在的含糊性。例如,图像可能模糊或只显示3D对象的2D视图,所以多个潜向可能产生它们。它们包含与指定查询相同的隐形图像,但其不确定。代码在 https://github.com/mkirchhof/Probabilistic_Contrative_Learning 。

**[Paper URL](https://proceedings.mlr.press/v202/kirchhof23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kirchhof23a/kirchhof23a.pdf)** 

# Training Normalizing Flows from Dependent Data
**题目:** 从依赖数据中规范流

**作者:** Matthias Kirchler, Christoph Lippert, Marius Kloft

**Abstract:** Normalizing flows are powerful non-parametric statistical models that function as a hybrid between density estimators and generative models. Current learning algorithms for normalizing flows assume that data points are sampled independently, an assumption that is frequently violated in practice, which may lead to erroneous density estimation and data generation. We propose a likelihood objective of normalizing flows incorporating dependencies between the data points, for which we derive a flexible and efficient learning algorithm suitable for different dependency structures. We show that respecting dependencies between observations can improve empirical results on both synthetic and real-world data, and leads to higher statistical power in a downstream application to genome-wide association studies.

**摘要:** 流的正常化是强有力的非参数统计模型,其功能是密度估计器与生成模型的混合体。当前的流的正常化学习算法假设数据点是独立抽样的,这一假设在实践中经常被违反,可能导致误差的密度估计和数据生成。我们提出了将数据点之间的依赖性纳入流的正常化概率目标,为此我们提出了一种适合不同依赖性结构的灵活有效的学习算法。

**[Paper URL](https://proceedings.mlr.press/v202/kirchler23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kirchler23a/kirchler23a.pdf)** 

# IncDSI: Incrementally Updatable Document Retrieval
**题目:** IncDSI:不断更新的文件检索

**作者:** Varsha Kishore, Chao Wan, Justin Lovelace, Yoav Artzi, Kilian Q Weinberger

**Abstract:** Differentiable Search Index is a recently proposed paradigm for document retrieval, that encodes information about a corpus of documents within the parameters of a neural network and directly maps queries to corresponding documents. These models have achieved state-of-the-art performances for document retrieval across many benchmarks. These kinds of models have a significant limitation: it is not easy to add new documents after a model is trained. We propose IncDSI, a method to add documents in real time (about 20-50ms per document), without retraining the model on the entire dataset (or even parts thereof). Instead we formulate the addition of documents as a constrained optimization problem that makes minimal changes to the network parameters. Although orders of magnitude faster, our approach is competitive with re-training the model on the whole dataset and enables the development of document retrieval systems that can be updated with new information in real-time. Our code for IncDSI is available at https://github.com/varshakishore/IncDSI.

**摘要:** 不同的搜索索引是最近提出的文件检索范式,它编码了神经网络参数内文件的文体信息,并直接映射到相应的文件的查询。这些模型在许多指标上实现了最先进的文件检索性能。这些类型的模型具有重要的局限性:在经过训练后添加新文件是不容易的。我们提出了IncDSI,一种在实时(每份文件约20-50ms)添加文件的方法,而不重新训练整个数据集(甚至部分)的模型。相反,我们将文件添加成限制优化问题,使得网络参数发生最小的变化。虽然数量的顺序更快,但我们的方法与整个数据集的模型重新训练具有竞争性,并使可更新新信息的文件检索系统得以发展。IncDSI的代码在 https://github.com/varshakishore/IncDSI.

**[Paper URL](https://proceedings.mlr.press/v202/kishore23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kishore23a/kishore23a.pdf)** 

# Regularization and Variance-Weighted Regression Achieves Minimax Optimality in Linear MDPs: Theory and Practice
**题目:** 规范化与变量重回归在线性MDP中实现最小优化:理论与实践

**作者:** Toshinori Kitamura, Tadashi Kozuno, Yunhao Tang, Nino Vieillard, Michal Valko, Wenhao Yang, Jincheng Mei, Pierre Menard, Mohammad Gheshlaghi Azar, Remi Munos, Olivier Pietquin, Matthieu Geist, Csaba Szepesvari, Wataru Kumagai, Yutaka Matsuo

**Abstract:** Mirror descent value iteration (MDVI), an abstraction of Kullback-Leibler (KL) and entropy-regularized reinforcement learning (RL), has served as the basis for recent high-performing practical RL algorithms. However, despite the use of function approximation in practice, the theoretical understanding of MDVI has been limited to tabular Markov decision processes (MDPs). We study MDVI with linear function approximation through its sample complexity required to identify an $\varepsilon$-optimal policy with probability $1-\delta$ under the settings of an infinite-horizon linear MDP, generative model, and G-optimal design. We demonstrate that least-squares regression weighted by the variance of an estimated optimal value function of the next state is crucial to achieving minimax optimality. Based on this observation, we present Variance-Weighted Least-Squares MDVI (VWLS-MDVI), the first theoretical algorithm that achieves nearly minimax optimal sample complexity for infinite-horizon linear MDPs. Furthermore, we propose a practical VWLS algorithm for value-based deep RL, Deep Variance Weighting (DVW). Our experiments demonstrate that DVW improves the performance of popular value-based deep RL algorithms on a set of MinAtar benchmarks.

**摘要:** 镜下降落值迭代(MDVI),是库尔巴克-莱布勒(KL)和熵-调节增强学习(RL)的抽象,为最近高性能的实际RL算法提供了基础。然而,尽管在实践中使用函数近似,MDVI的理论理解仅限于表式马可夫决策过程(MDPs)。我们研究MDVI的线性函数近似通过其所需的样本复杂性来识别一个$\varepsilon$-最佳策略,其概率为$1-\delta$在无限水平线性MDP、生成模型和G-最佳设计的设置下。在此基础上,提出了一种基于价值的深层RL的实用的VWLS算法,即深层变量权衡(DVW)。实验表明,DVW能提高基于价值的深层RL算法在一系列的MinAtar基准上性能。

**[Paper URL](https://proceedings.mlr.press/v202/kitamura23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kitamura23a/kitamura23a.pdf)** 

# Drug Discovery under Covariate Shift with Domain-Informed Prior Distributions over Functions
**题目:** 药物发现与功能上域名预先分配的协变转移下

**作者:** Leo Klarner, Tim G. J. Rudner, Michael Reutlinger, Torsten Schindler, Garrett M Morris, Charlotte Deane, Yee Whye Teh

**Abstract:** Accelerating the discovery of novel and more effective therapeutics is an important pharmaceutical problem in which deep learning is playing an increasingly significant role. However, real-world drug discovery tasks are often characterized by a scarcity of labeled data and significant covariate shift—a setting that poses a challenge to standard deep learning methods. In this paper, we present Q-SAVI, a probabilistic model able to address these challenges by encoding explicit prior knowledge of the data-generating process into a prior distribution over functions, presenting researchers with a transparent and probabilistically principled way to encode data-driven modeling preferences. Building on a novel, gold-standard bioactivity dataset that facilitates a meaningful comparison of models in an extrapolative regime, we explore different approaches to induce data shift and construct a challenging evaluation setup. We then demonstrate that using Q-SAVI to integrate contextualized prior knowledge of drug-like chemical space into the modeling process affords substantial gains in predictive accuracy and calibration, outperforming a broad range of state-of-the-art self-supervised pre-training and domain adaptation techniques.

**摘要:** 加速新有效的药物的发现是一个重要的药物问题,深入学习在其中扮演着越来越重要的角色。然而,现实药物发现任务往往被标记数据的稀缺和显著的可变性转变所 caracterizate — — 这种环境对标准的深入学习方法提出了挑战。本论文介绍Q-SAVI,一种能够解决这些挑战的概率模型,通过将数据生成过程的明示预先知识编码到功能上的预先分配中,以一种透明和概率原理的方式向研究人员提供编码数据驱动的建模偏好。然后,我们证明,使用Q-SAVI将药物类化学空间的上下文化知识集成到建模过程中,在预测精度和校准方面取得了显著的进步,超过了先进的自监督的预训练和领域适应技术。

**[Paper URL](https://proceedings.mlr.press/v202/klarner23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/klarner23a/klarner23a.pdf)** 

# Deep Laplacian-based Options for Temporally-Extended Exploration
**题目:** 基于深层拉普拉西亚的临时扩展勘探选项

**作者:** Martin Klissarov, Marlos C. Machado

**Abstract:** Selecting exploratory actions that generate a rich stream of experience for better learning is a fundamental challenge in reinforcement learning (RL). An approach to tackle this problem consists in selecting actions according to specific policies for an extended period of time, also known as options. A recent line of work to derive such exploratory options builds upon the eigenfunctions of the graph Laplacian. Importantly, until now these methods have been mostly limited to tabular domains where (1) the graph Laplacian matrix was either given or could be fully estimated, (2) performing eigendecomposition on this matrix was computationally tractable, and (3) value functions could be learned exactly. Additionally, these methods required a separate option discovery phase. These assumptions are fundamentally not scalable. In this paper we address these limitations and show how recent results for directly approximating the eigenfunctions of the Laplacian can be leveraged to truly scale up options-based exploration. To do so, we introduce a fully online deep RL algorithm for discovering Laplacian-based options and evaluate our approach on a variety of pixel-based tasks. We compare to several state-of-the-art exploration methods and show that our approach is effective, general, and especially promising in non-stationary settings.

**摘要:** 选择产生更好的学习经验的探索性行动是增强学习(RL)的一个基本挑战。解决这一问题的方法是根据特定政策选择长期的探索性行动,也被称为选择。最近的推导这些探索性选项的工作线建立在拉普拉西亚图的固有函数之上。重要的是,到目前为止,这些方法主要局限于表域,其中(1)拉普拉西亚图矩阵要么给出,要么可以完全估计,(2)在该矩阵上进行固有分解是可计算的,(3)值函数可以准确地学习。本文讨论了这些局限性,并展示了直接近似拉普拉西亚的特征函数的近期结果,如何有效提高基于选项的探索。为此,我们引入了基于拉普拉西亚的 Deep RL算法,对各种基于像素任务的探索方法进行了评估。

**[Paper URL](https://proceedings.mlr.press/v202/klissarov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/klissarov23a/klissarov23a.pdf)** 

# Generalized Reductions: Making any Hierarchical Clustering Fair and Balanced with Low Cost
**题目:** 一般化减低:让任何层次级集群公平和低成本平衡

**作者:** Marina Knittel, Max Springer, John P Dickerson, Mohammadtaghi Hajiaghayi

**Abstract:** Clustering is a fundamental building block of modern statistical analysis pipelines. Fair clustering has seen much attention from the machine learning community in recent years. We are some of the first to study fairness in the context of hierarchical clustering, after the results of Ahmadian et al. from NeurIPS in 2020. We evaluate our results using Dasgupta’s cost function, perhaps one of the most prevalent theoretical metrics for hierarchical clustering evaluation. Our work vastly improves the previous $O(n^{5/6}poly\log(n))$ fair approximation for cost to a near polylogarithmic $O(n^\delta poly\log(n))$ fair approximation for any constant $\delta\in(0,1)$. This result establishes a cost fairness tradeoff and extends to broader fairness constraints than the previous work. We also show how to alter existing hierarchical clusterings to guarantee fairness and cluster balance across any level in the hierarchy.

**摘要:** 聚类是现代统计分析管道的基本组成部分。公平聚类在近年来得到了机器学习社区的大量关注。我们是第一个在层次聚类中研究公平的对象,在2020年由NeurIPS的阿哈迈迪安等人取得的结果之后,我们利用Dasgupta的成本函数来评估我们的结果,也许是最普遍的层次聚类评价理论指标之一。我们的工作大大改善了以前的$O(n^{5/6}poly\log(n))$公平的成本近似值$O(n^\delta poly\log(n))$公平的成本近似值$\delta\in(0,1)$。

**[Paper URL](https://proceedings.mlr.press/v202/knittel23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/knittel23a/knittel23a.pdf)** 

# Can We Scale Transformers to Predict Parameters of Diverse ImageNet Models?
**题目:** 我们能将变换器进行尺度来预测各种ImageNet模型的参数 吗?

**作者:** Boris Knyazev, Doha Hwang, Simon Lacoste-Julien

**Abstract:** Pretraining a neural network on a large dataset is becoming a cornerstone in machine learning that is within the reach of only a few communities with large-resources. We aim at an ambitious goal of democratizing pretraining. Towards that goal, we train and release a single neural network that can predict high quality ImageNet parameters of other neural networks. By using predicted parameters for initialization we are able to boost training of diverse ImageNet models available in PyTorch. When transferred to other datasets, models initialized with predicted parameters also converge faster and reach competitive final performance.

**摘要:** 在大型数据集上,神经网络的预训练成为机器学习的一个基石,仅限于少数具有大量资源的社区。我们的目标是实现预训练的民主化。为了实现这一目标,我们训练和释放一个能够预测其他神经网络的高质量 ImageNet参数的单一神经网络。通过使用预先参数来初始化,我们能够提高在PyTorch中可用的各种 ImageNet模型的培训。

**[Paper URL](https://proceedings.mlr.press/v202/knyazev23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/knyazev23a/knyazev23a.pdf)** 

# Online Learning with Feedback Graphs: The True Shape of Regret
**题目:** 基于反馈图的在线学习:真正的遗憾

**作者:** Tomáš Kocák, Alexandra Carpentier

**Abstract:** Sequential learning with feedback graphs is a natural extension of the multi-armed bandit problem where the problem is equipped with an underlying graph structure that provides additional information - playing an action reveals the losses of all the neighbors of the action. This problem was introduced by Mannor & Shamir (2011) and received considerable attention in recent years. It is generally stated in the literature that the minimax regret rate for this problem is of order $\sqrt{\alpha T}$, where $\alpha$ is the independence number of the graph, and $T$ is the time horizon. However, this is proven only when the number of rounds $T$ is larger than $\alpha^3$, which poses a significant restriction for the usability of this result in large graphs. In this paper, we define a new quantity $R^*$, called the problem complexity, and prove that the minimax regret is proportional to $R^*$ for any graph and time horizon $T$. Introducing an intricate exploration strategy, we define the Exp3-EX algorithm that achieves the minimax optimal regret bound and becomes the first provably optimal algorithm for this setting, even if $T$ is smaller than $\alpha^3$.

**摘要:** 基于反馈图的序列学习是多军备的 bandit 问题的一个自然的扩展,该问题具有基本的图结构,提供额外的信息 - 播放一个动作显示所有行动的邻居的损失. 这个问题由Mannor & Shamir(2011)引入,并近年来得到相当的关注. 一般在文献中指出,该问题的最小遗憾率是 $\sqrt{\alpha T}$, 其中 $\alpha$ 是图的独立数目, $T$ 是时空数目. 然而,这只证明了当循环 $T$ 的数目比 $\alpha^3$ 更大, 这对于大图中这一结果的可用性构成了重大限制. 在本文中,我们定义了一个新的数量 $R^*$, 称为问题复杂性,并证明该最小遗憾率与任何图和时空引入了复杂的探索策略,我们定义了达到最小最优遗憾约束的exp3-EX算法,并且成为第一个可证明的最优算法,即使$T$比$\alpha^3$小。

**[Paper URL](https://proceedings.mlr.press/v202/kocak23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kocak23a/kocak23a.pdf)** 

# Grounding Language Models to Images for Multimodal Inputs and Outputs
**题目:** 基于多模态输入和输出的图像语言模型

**作者:** Jing Yu Koh, Ruslan Salakhutdinov, Daniel Fried

**Abstract:** We propose an efficient method to ground pretrained text-only language models to the visual domain, enabling them to process arbitrarily interleaved image-and-text data, and generate text interleaved with retrieved images. Our method leverages the abilities of language models learnt from large scale text-only pretraining, such as in-context learning and free-form text generation. We keep the language model frozen, and finetune input and output linear layers to enable cross-modality interactions. This allows our model to process arbitrarily interleaved image-and-text inputs, and generate free-form text interleaved with retrieved images. We achieve strong zero-shot performance on grounded tasks such as contextual image retrieval and multimodal dialogue, and showcase compelling interactive abilities. Our approach works with any off-the-shelf language model and paves the way towards an effective, general solution for leveraging pretrained language models in visually grounded settings.

**摘要:** 我们提出了一种有效的方法,将预处理的文本语言模型应用于视觉领域,使它们能够处理任意的图像和文本数据,并生成与检索图像的文本。我们的方法利用从大规模文本预训练中学习的语言模型的能力,例如在上下文学习和自由形式文本生成。我们将语言模型冻结,并调整输入和输出线性层,使交叉模态交互。这使得我们的模型能够处理任意的图像和文本输入,并生成与检索图像的自由形式文本。

**[Paper URL](https://proceedings.mlr.press/v202/koh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/koh23a/koh23a.pdf)** 

# Rigid Body Flows for Sampling Molecular Crystal Structures
**题目:** 分子晶体结构采样 Rigid Body Flows

**作者:** Jonas Köhler, Michele Invernizzi, Pim De Haan, Frank Noe

**Abstract:** Normalizing flows (NF) are a class of powerful generative models that have gained popularity in recent years due to their ability to model complex distributions with high flexibility and expressiveness. In this work, we introduce a new type of normalizing flow that is tailored for modeling positions and orientations of multiple objects in three-dimensional space, such as molecules in a crystal. Our approach is based on two key ideas: first, we define smooth and expressive flows on the group of unit quaternions, which allows us to capture the continuous rotational motion of rigid bodies; second, we use the double cover property of unit quaternions to define a proper density on the rotation group. This ensures that our model can be trained using standard likelihood-based methods or variational inference with respect to a thermodynamic target density. We evaluate the method by training Boltzmann generators for two molecular examples, namely the multi-modal density of a tetrahedral system in an external field and the ice XI phase in the TIP4P water model. Our flows can be combined with flows operating on the internal degrees of freedom of molecules and constitute an important step towards the modeling of distributions of many interacting molecules.

**摘要:** 规范流(英语:Normalizing flows,缩写NF)是近年来由于其具有高灵活性和表达性的复杂分布模型能力而得到广泛应用的一种强有力的生成模型。本文介绍了一种适合在三维空间中的多物体,如晶体中的分子,定位和定位的新型规范流。我们的方法基于两个关键思想:第一,我们定义单元四元体群的平滑和表达性流,使我们能够捕捉刚体的连续旋转运动;第二,我们使用单元四元体的双层覆盖特性来定义单元四元体群的适当密度。我们通过训练玻尔茨曼发电机对两个分子实例,即外场的四面体系统多模密度和TIP4P水模型中的冰十一相进行评价。我们的流动可以与分子内部自由度的流动结合,构成许多相互作用分子分布的建模的重要步骤。

**[Paper URL](https://proceedings.mlr.press/v202/kohler23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kohler23a/kohler23a.pdf)** 

# Enabling First-Order Gradient-Based Learning for Equilibrium Computation in Markets
**题目:** 为市场均衡计算提供基于初级梯度的学习

**作者:** Nils Kohring, Fabian Raoul Pieroth, Martin Bichler

**Abstract:** Understanding and analyzing markets is crucial, yet analytical equilibrium solutions remain largely infeasible. Recent breakthroughs in equilibrium computation rely on zeroth-order policy gradient estimation. These approaches commonly suffer from high variance and are computationally expensive. The use of fully differentiable simulators would enable more efficient gradient estimation. However, the discrete allocation of goods in economic simulations is a non-differentiable operation. This renders the first-order Monte Carlo gradient estimator inapplicable and the learning feedback systematically misleading. We propose a novel smoothing technique that creates a surrogate market game, in which first-order methods can be applied. We provide theoretical bounds on the resulting bias which justifies solving the smoothed game instead. These bounds also allow choosing the smoothing strength a priori such that the resulting estimate has low variance. Furthermore, we validate our approach via numerous empirical experiments. Our method theoretically and empirically outperforms zeroth-order methods in approximation quality and computational efficiency.

**摘要:** 市场理解和分析是至关重要的,但分析平衡解决方案仍然是无法实现的。平衡计算中最近的突破依赖于零阶政策梯度估计。这些方法通常受高变量影响,计算成本昂贵。完全可微分的模拟器的使用将使梯度估计更加有效。然而,经济模拟中的货物的离散分配是不可微分的操作。这使得第一阶蒙特卡罗梯度估计器不适用和学习反馈系统误导。通过大量的实证实验,验证了该方法在近似质量和计算效率方面在理论和实证上优于零阶方法。

**[Paper URL](https://proceedings.mlr.press/v202/kohring23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kohring23a/kohring23a.pdf)** 

# Revisiting Gradient Clipping: Stochastic bias and tight convergence guarantees
**题目:** 重置梯度剪切:随机偏差和紧密的收敛性保证

**作者:** Anastasia Koloskova, Hadrien Hendrikx, Sebastian U Stich

**Abstract:** Gradient clipping is a popular modification to standard (stochastic) gradient descent, at every iteration limiting the gradient norm to a certain value $c >0$. It is widely used for example for stabilizing the training of deep learning models (Goodfellow et al., 2016), or for enforcing differential privacy (Abadi et al., 2016). Despite popularity and simplicity of the clipping mechanism, its convergence guarantees often require specific values of $c$ and strong noise assumptions. In this paper, we give convergence guarantees that show precise dependence on arbitrary clipping thresholds $c$ and show that our guarantees are tight with both deterministic and stochastic gradients. In particular, we show that (i) for deterministic gradient descent, the clipping threshold only affects the higher-order terms of convergence, (ii) in the stochastic setting convergence to the true optimum cannot be guaranteed under the standard noise assumption, even under arbitrary small step-sizes. We give matching upper and lower bounds for convergence of the gradient norm when running clipped SGD, and illustrate these results with experiments.

**摘要:** 梯度剪切是标准(随机)梯度下降的一个流行的修改,在每个迭代中限制梯度标准为一定值$c>0$。 它广泛用于例如稳定深学习模型的训练(Goodfellow et al., 2016),或执行微分隐私(Abadi et al., 2016)。利用 clipped SGD 运行时对梯度规范的收敛性给出了匹配的上界和下界,并通过实验说明了这些结果。

**[Paper URL](https://proceedings.mlr.press/v202/koloskova23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/koloskova23a/koloskova23a.pdf)** 

# On Computing Optimal Tree Ensembles
**题目:** 计算最佳树集

**作者:** Christian Komusiewicz, Pascal Kunz, Frank Sommer, Manuel Sorge

**Abstract:** Random forests and, more generally, (decision-)tree ensembles are widely used methods for classification and regression. Recent algorithmic advances allow to compute decision trees that are optimal for various measures such as their size or depth. We are not aware of such research for tree ensembles and aim to contribute to this area. Mainly, we provide two novel algorithms and corresponding lower bounds. First, we are able to carry over and substantially improve on tractability results for decision trees, obtaining a $(6\delta D S)^S \cdot \mathrm{poly}$-time algorithm, where $S$ is the number of cuts in the tree ensemble, $D$ the largest domain size, and $\delta$ is the largest number of features in which two examples differ. To achieve this, we introduce the witness-tree technique which also seems promising for practice. Second, we show that dynamic programming, which has been successful for decision trees, may also be viable for tree ensembles, providing an $\ell^n \cdot \mathrm{poly}$-time algorithm, where $\ell$ is the number of trees and $n$ the number of examples. Finally, we compare the number of cuts necessary to classify training data sets for decision trees and tree ensembles, showing that ensembles may need exponentially fewer cuts for increasing number of trees.

**摘要:** 随机森林和更一般地说,(决策-)树群是广泛用于分类和回归的方法。最近的算法进步允许计算各种大小或深度的决策树。我们对树群的研究并不了解,并打算对这一领域作出贡献。主要,我们提供了两个新算法和相应的较低边界。首先,我们能够对决策树的易于处理结果进行重演和实质性改进,获得$(6\delta D S)^S \cdot \mathrm{poly}$-time算法,其中$S$是树群中的剪切数,$D$是最大域大小,$\delta$是两个不同例子的最大特征数。其次,我们证明了对于决策树的动态编程,对于树集的可行性,提供了$ell^n \cdot \mathrm{poly}$-time算法,其中$ell$是树的数目和$n$是例子的数目。最后,我们比较了用于分类决策树和树集的训练数据集所需的剪切数目,表明树集可能需要指数减少剪切,以增加树的数目。

**[Paper URL](https://proceedings.mlr.press/v202/komusiewicz23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/komusiewicz23a/komusiewicz23a.pdf)** 

# GOAT: A Global Transformer on Large-scale Graphs
**题目:** GOAT:大型图形上的全球变换器

**作者:** Kezhi Kong, Jiuhai Chen, John Kirchenbauer, Renkun Ni, C. Bayan Bruss, Tom Goldstein

**Abstract:** Graph transformers have been competitive on graph classification tasks, but they fail to outperform Graph Neural Networks (GNNs) on node classification, which is a common task performed on large-scale graphs for industrial applications. Meanwhile, existing GNN architectures are limited in their ability to perform equally well on both homophilious and heterophilious graphs as their inductive biases are generally tailored to only one setting. To address these issues, we propose GOAT, a scalable global graph transformer. In GOAT, each node conceptually attends to all the nodes in the graph and homophily/heterophily relationships can be learnt adaptively from the data. We provide theoretical justification for our approximate global self-attention scheme, and show it to be scalable to large-scale graphs. We demonstrate the competitiveness of GOAT on both heterophilious and homophilious graphs with millions of nodes.

**摘要:** 图形变换器在图形分类任务中具有竞争性,但它们不能超过图形神经网络(GNNs)在节点分类中的表现,这是工业应用中在大规模图形上执行的常见任务。同时,现有GNN架构在其性能上有限,因为它们的诱导偏见一般只适用于一个设置。为了解决这些问题,我们提出了 GOAT,一种可扩展的全球图形变换器。在 GOAT中,每个节点的概念上都关注图形中的所有节点,并且同性恋/异性恋关系可以从数据中学习。我们为我们的近似的全球自我关注方案提供了理论依据,并证明它可扩展到大规模图形。

**[Paper URL](https://proceedings.mlr.press/v202/kong23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kong23a/kong23a.pdf)** 

# Autoregressive Diffusion Model for Graph Generation
**题目:** 图形生成自动扩散模型

**作者:** Lingkai Kong, Jiaming Cui, Haotian Sun, Yuchen Zhuang, B. Aditya Prakash, Chao Zhang

**Abstract:** Diffusion-based graph generative models have recently obtained promising results for graph generation. However, existing diffusion-based graph generative models are mostly one-shot generative models that apply Gaussian diffusion in the dequantized adjacency matrix space. Such a strategy can suffer from difficulty in model training, slow sampling speed, and incapability of incorporating constraints. We propose an autoregressive diffusion model for graph generation. Unlike existing methods, we define a node-absorbing diffusion process that operates directly in the discrete graph space. For forward diffusion, we design a diffusion ordering network, which learns a data-dependent node absorbing ordering from graph topology. For reverse generation, we design a denoising network that uses the reverse node ordering to efficiently reconstruct the graph by predicting the node type of the new node and its edges with previously denoised nodes at a time. Based on the permutation invariance of graph, we show that the two networks can be jointly trained by optimizing a simple lower bound of data likelihood. Our experiments on six diverse generic graph datasets and two molecule datasets show that our model achieves better or comparable generation performance with previous state-of-the-art, and meanwhile enjoys fast generation speed.

**摘要:** 基于扩散的图形生成模型最近取得了对图形生成有希望的结果。然而,现有基于扩散的图形生成模型大多是应用高斯扩散在非定量邻接矩阵空间的一次射击生成模型。这种策略可能受到模型训练的困难、慢采样速度和包含约束的能力。我们提出了一种自回归扩散模型。与现有方法不同,我们定义了在离散图形空间中直接操作的节点吸收扩散过程。基于图的变换不变性,我们表明,通过优化一个简单的较低的数据概率,可以联合训练两个网络。我们对六种不同的通用图数据集和两个分子数据集的实验表明,我们的模型具有较好的或与前时最先进的生成性能,同时具有较快的生成速度。

**[Paper URL](https://proceedings.mlr.press/v202/kong23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kong23b/kong23b.pdf)** 

# End-to-End Full-Atom Antibody Design
**题目:** End-to-End全原子抗体设计

**作者:** Xiangzhe Kong, Wenbing Huang, Yang Liu

**Abstract:** Antibody design is an essential yet challenging task in various domains like therapeutics and biology. There are two major defects in current learning-based methods: 1) tackling only a certain subtask of the whole antibody design pipeline, making them suboptimal or resource-intensive. 2) omitting either the framework regions or side chains, thus incapable of capturing the full-atom geometry. To address these pitfalls, we propose dynamic Multi-channel Equivariant grAph Network (dyMEAN), an end-to-end full-atom model for E(3)-equivariant antibody design given the epitope and the incomplete sequence of the antibody. Specifically, we first explore structural initialization as a knowledgeable guess of the antibody structure and then propose shadow paratope to bridge the epitope-antibody connections. Both 1D sequences and 3D structures are updated via an adaptive multi-channel equivariant encoder that is able to process protein residues of variable sizes when considering full atoms. Finally, the updated antibody is docked to the epitope via the alignment of the shadow paratope. Experiments on epitope-binding CDR-H3 design, complex structure prediction, and affinity optimization demonstrate the superiority of our end-to-end framework and full-atom modeling.

**摘要:** 抗体设计是治疗和生物学等各个领域的重要任务,目前的基于学习的方法有两个主要缺陷:(一)只处理整个抗体设计管道的某个子任务,使它们不适宜或资源密集;(二)忽略框架区域或侧链,从而无法捕捉全原子几何;(三)针对这些漏洞,我们提出了动态多通道等变性格拉夫网络(dyMEAN),为E(3)等变性抗体设计提供全原子序列和不完整的全原子序列的全原子模型。最后,更新的抗体通过影子寄位体的整列连接到环状体上。环状体绑定CDR-H3的设计、复杂结构预测和亲和优化实验证明了我们的端到端框架和全原子建模的优越性。

**[Paper URL](https://proceedings.mlr.press/v202/kong23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kong23c/kong23c.pdf)** 

# Covariate balancing using the integral probability metric for causal inference
**题目:** 因果推理的积分概率度量对偶平衡

**作者:** Insung Kong, Yuha Park, Joonhyuk Jung, Kwonsang Lee, Yongdai Kim

**Abstract:** Weighting methods in causal inference have been widely used to achieve a desirable level of covariate balancing. However, the existing weighting methods have desirable theoretical properties only when a certain model, either the propensity score or outcome regression model, is correctly specified. In addition, the corresponding estimators do not behave well for finite samples due to large variance even when the model is correctly specified. In this paper, we consider to use the integral probability metric (IPM), which is a metric between two probability measures, for covariate balancing. Optimal weights are determined so that weighted empirical distributions for the treated and control groups have the smallest IPM value for a given set of discriminators. We prove that the corresponding estimator can be consistent without correctly specifying any model (neither the propensity score nor the outcome regression model). In addition, we empirically show that our proposed method outperforms existing weighting methods with large margins for finite samples.

**摘要:** 因果推理中的权重方法已广泛应用,以达到可望的共变平衡水平。然而,现有权重方法只有当某一模型,即倾向分数或结果回归模型,正确指定时,才具有可望的理论特性。此外,相应的估算符即使在模型正确指定时,也由于较大的变异而对有限样品不当行为。本论文中,我们考虑采用共变平衡的积分概率度量(IPM),即两个概率度量之间的度量。优化权重被确定,以使处理组和控制组的权重经验分布为给定的分离器最小IPM值。我们证明相应的估算符可以不正确指定任何模型(无论是倾向分数还是结果回归模型)。此外,我们通过实验证明,我们提出的方法优于现有的有限样品权衡方法,具有较大的余额。

**[Paper URL](https://proceedings.mlr.press/v202/kong23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kong23d/kong23d.pdf)** 

# Masked Bayesian Neural Networks : Theoretical Guarantee and its Posterior Inference
**题目:** 隐形贝叶斯神经网络:理论保证及其后向ference

**作者:** Insung Kong, Dongyoon Yang, Jongjin Lee, Ilsang Ohn, Gyuseung Baek, Yongdai Kim

**Abstract:** Bayesian approaches for learning deep neural networks (BNN) have been received much attention and successfully applied to various applications. Particularly, BNNs have the merit of having better generalization ability as well as better uncertainty quantification. For the success of BNN, search an appropriate architecture of the neural networks is an important task, and various algorithms to find good sparse neural networks have been proposed. In this paper, we propose a new node-sparse BNN model which has good theoretical properties and is computationally feasible. We prove that the posterior concentration rate to the true model is near minimax optimal and adaptive to the smoothness of the true model. In particular the adaptiveness is the first of its kind for node-sparse BNNs. In addition, we develop a novel MCMC algorithm which makes the Bayesian inference of the node-sparse BNN model feasible in practice.

**摘要:** 深神经网络学习的贝叶斯方法得到了广泛的关注,并成功应用于各种应用领域。特别是,深神经网络具有较好的一般化能力以及较好的不确定性定量。为深神经网络的成功,寻找适当的结构是一项重要的任务,并提出了各种算法,以寻找较好的稀疏神经网络。本文提出了一种具有较好的理论性质和可计算性的新型节点稀疏神经网络模型,证明对真模型的后向浓度率接近最小值,对真模型的平滑度具有适应性,特别是对节点稀疏神经网络的适应性是其第一类。

**[Paper URL](https://proceedings.mlr.press/v202/kong23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kong23e/kong23e.pdf)** 

# Parameter-Level Soft-Masking for Continual Learning
**题目:** 持续学习的参数级软面具

**作者:** Tatsuya Konishi, Mori Kurokawa, Chihiro Ono, Zixuan Ke, Gyuhak Kim, Bing Liu

**Abstract:** Existing research on task incremental learning in continual learning has primarily focused on preventing catastrophic forgetting (CF). Although several techniques have achieved learning with no CF, they attain it by letting each task monopolize a sub-network in a shared network, which seriously limits knowledge transfer (KT) and causes over-consumption of the network capacity, i.e., as more tasks are learned, the performance deteriorates. The goal of this paper is threefold: (1) overcoming CF, (2) encouraging KT, and (3) tackling the capacity problem. A novel technique (called SPG) is proposed that soft-masks (partially blocks) parameter updating in training based on the importance of each parameter to old tasks. Each task still uses the full network, i.e., no monopoly of any part of the network by any task, which enables maximum KT and reduction in capacity usage. To our knowledge, this is the first work that soft-masks a model at the parameter-level for continual learning. Extensive experiments demonstrate the effectiveness of SPG in achieving all three objectives. More notably, it attains significant transfer of knowledge not only among similar tasks (with shared knowledge) but also among dissimilar tasks (with little shared knowledge) while mitigating CF.

**摘要:** 当前在持续学习中的任务增量学习研究主要集中在防止灾难性遗忘(CF)方面。虽然没有CF技术实现学习,但通过让每个任务垄断共享网络中的子网络,严重限制知识转移(KT)和造成网络容量的过度消耗,即随着更多的任务学习,性能恶化。本文的目标是三fold:(一)克服CF,(二)鼓励 KT,(三)解决能力问题。提出了一种新技术(称为SPG),即软化(部分阻塞)在训练中根据每个参数对老任务的重要性进行参数更新。广泛的实验表明,SPG在实现上述三项目标方面具有有效性,特别是在相似任务(具有共享知识)中,在不同任务(缺乏共享知识)中取得重要的知识转移,同时缓解了CF问题。

**[Paper URL](https://proceedings.mlr.press/v202/konishi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/konishi23a/konishi23a.pdf)** 

# Pretraining Language Models with Human Preferences
**题目:** 人类偏好预训练语言模型

**作者:** Tomasz Korbak, Kejian Shi, Angelica Chen, Rasika Vinayak Bhalerao, Christopher Buckley, Jason Phang, Samuel R. Bowman, Ethan Perez

**Abstract:** Language models (LMs) are pretrained to imitate text from large and diverse datasets that contain content that would violate human preferences if generated by an LM: falsehoods, offensive comments, personally identifiable information, low-quality or buggy code, among others. Here, we explore alternative objectives for pretraining LMs in a way that also guides them to generate text aligned with human preferences. We benchmark five objectives for pretraining with human feedback across three tasks and study how they affect the alignment and capabilities of pretrained LMs. We find a Pareto-optimal and simple approach among those we explored: conditional training, or learning distribution over tokens conditional on their human preference scores. Conditional training reduces the rate of undesirable content by up to an order of magnitude, both when generating without a prompt and with an adversarially-chosen prompt. Moreover, conditional training maintains the downstream task performance of standard LM pretraining, both before and after task-specific finetuning. Pretraining with human feedback results in much better preference satisfaction than standard LM pretraining followed by finetuning with feedback, i.e., learning and then unlearning undesirable behavior. Our results suggest that we should move beyond imitation learning when pretraining LMs and incorporate human preferences from the start of training.

**摘要:** 语言模型(英语:Language models,简称:LMs)是用来模仿文本的大型和多种数据集,这些数据集包含内容,如果由LM生成,就会侵犯人类的喜好:伪造、攻击性评论、个人可识别的信息、低质量或笨拙代码等。这里,我们探索了以一种方式对LMs进行预训练的替代目标,并指导他们生成与人类的喜好相匹配的文本。我们 benchmark了三个任务中与人类反馈进行预训练的五个目标,并研究了它们如何影响预训练LMs的整合和能力。同时,条件训练保持了标准LM预训练的下游任务性能,既在任务特定调度前,又在任务特定调度后。采用人反馈的预训练结果比标准LM预训练的调度结果好得多,即学习后不再学习不良的行为。

**[Paper URL](https://proceedings.mlr.press/v202/korbak23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/korbak23a/korbak23a.pdf)** 

# Detecting Adversarial Directions in Deep Reinforcement Learning to Make Robust Decisions
**题目:** 发现敌对方向在深层强化中学习做出强有力的决策

**作者:** Ezgi Korkmaz, Jonah Brown-Cohen

**Abstract:** Learning in MDPs with highly complex state representations is currently possible due to multiple advancements in reinforcement learning algorithm design. However, this incline in complexity, and furthermore the increase in the dimensions of the observation came at the cost of volatility that can be taken advantage of via adversarial attacks (i.e. moving along worst-case directions in the observation space). To solve this policy instability problem we propose a novel method to detect the presence of these non-robust directions via local quadratic approximation of the deep neural policy loss. Our method provides a theoretical basis for the fundamental cut-off between safe observations and adversarial observations. Furthermore, our technique is computationally efficient, and does not depend on the methods used to produce the worst-case directions. We conduct extensive experiments in the Arcade Learning Environment with several different adversarial attack techniques. Most significantly, we demonstrate the effectiveness of our approach even in the setting where non-robust directions are explicitly optimized to circumvent our proposed method.

**摘要:** 由于增强学习算法设计的多方面的进步,目前具有高度复杂状态表示的MDP学习是可能的。然而,这种复杂度的倾斜,以及观察的维度的增加,是通过敌对攻击来利用的波动性成本(即沿观察空间的最坏情况方向移动)。为了解决这一政策不稳定问题,我们提出了一种新的方法来通过局部四维近似深度神经政策损失来检测这些非鲁棒方向的存在。我们的方法为安全观察和敌对观察的根本截断提供了理论基础。最重要的是,我们证明了我们的方法的有效性,即使在非刚性方向明确优化以绕过我们提出的方法的情况下。

**[Paper URL](https://proceedings.mlr.press/v202/korkmaz23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/korkmaz23a/korkmaz23a.pdf)** 

# Ewald-based Long-Range Message Passing for Molecular Graphs
**题目:** 基于Ewald的分子图的长距离消息传递

**作者:** Arthur Kosmala, Johannes Gasteiger, Nicholas Gao, Stephan Günnemann

**Abstract:** Neural architectures that learn potential energy surfaces from molecular data have undergone fast improvement in recent years. A key driver of this success is the Message Passing Neural Network (MPNN) paradigm. Its favorable scaling with system size partly relies upon a spatial distance limit on messages. While this focus on locality is a useful inductive bias, it also impedes the learning of long-range interactions such as electrostatics and van der Waals forces. To address this drawback, we propose Ewald message passing: a nonlocal Fourier space scheme which limits interactions via a cutoff on frequency instead of distance, and is theoretically well-founded in the Ewald summation method. It can serve as an augmentation on top of existing MPNN architectures as it is computationally inexpensive and agnostic to architectural details. We test the approach with four baseline models and two datasets containing diverse periodic (OC20) and aperiodic structures (OE62). Across all models and datasets, we observe robust improvements in energy mean absolute errors, averaging 10% on OC20 and 16% on OE62. Our analysis shows an outsize impact of these improvements on structures with high long-range contributions to the ground-truth energy.

**摘要:** 从分子数据中学习潜在能量表面的神经结构近年来经历了快速的改进。这一成功的关键驱动器是消息传递神经网络(MPNN)范式。其与系统大小的有利的规模化部分依赖于消息的空间距离限制。虽然这种定位是有益的诱导偏差,它也阻碍了电静力学和范德瓦尔力学等远程相互作用的学习。为了解决这一缺点,我们提出了Ewald消息传递:一种非本地傅立叶空间方案,通过切断频率来限制相互作用,并且在理论上是基于Ewald总结方法的。在所有模型和数据集中,我们观察到能量平均绝对误差的稳固改善,平均为OC20的10%和OE62的 16%。我们的分析显示,这些改进对具有高远距离贡献的结构对地质真理能量的超大影响。

**[Paper URL](https://proceedings.mlr.press/v202/kosmala23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kosmala23a/kosmala23a.pdf)** 

# TabDDPM: Modelling Tabular Data with Diffusion Models
**题目:** TabDDPM:用扩散模型建模表格数据

**作者:** Akim Kotelnikov, Dmitry Baranchuk, Ivan Rubachev, Artem Babenko

**Abstract:** Denoising diffusion probabilistic models are becoming the leading generative modeling paradigm for many important data modalities. Being the most prevalent in the computer vision community, diffusion models have recently gained some attention in other domains, including speech, NLP, and graph-like data. In this work, we investigate if the framework of diffusion models can be advantageous for general tabular problems, where data points are typically represented by vectors of heterogeneous features. The inherent heterogeneity of tabular data makes it quite challenging for accurate modeling since the individual features can be of a completely different nature, i.e., some of them can be continuous and some can be discrete. To address such data types, we introduce TabDDPM — a diffusion model that can be universally applied to any tabular dataset and handles any feature types. We extensively evaluate TabDDPM on a wide set of benchmarks and demonstrate its superiority over existing GAN/VAE alternatives, which is consistent with the advantage of diffusion models in other fields.

**摘要:** 描述扩散概率模型已成为许多重要的数据模式的主要生成模型范式。作为计算机视觉社区最普遍的扩散模型最近在其他领域得到了一些关注,包括语音、NLP和图形数据。在这个工作中,我们研究扩散模型的框架是否有利于一般表格问题,数据点通常由异质特征的向量代表。我们对 TabDDPM在广泛的基准上进行了广泛的评价,并证明它优于现有GAN/VAE替代品,这与其他领域扩散模型的优势一致。

**[Paper URL](https://proceedings.mlr.press/v202/kotelnikov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kotelnikov23a/kotelnikov23a.pdf)** 

# Randomized Schur Complement Views for Graph Contrastive Learning
**题目:** 图形对比学习的随机舒尔补充视图

**作者:** Vignesh Kothapalli

**Abstract:** We introduce a randomized topological augmentor based on Schur complements for Graph Contrastive Learning (GCL). Given a graph laplacian matrix, the technique generates unbiased approximations of its Schur complements and treats the corresponding graphs as augmented views. We discuss the benefits of our approach, provide theoretical justifications and present connections with graph diffusion. Unlike previous efforts, we study the empirical effectiveness of the augmentor in a controlled fashion by varying the design choices for subsequent GCL phases, such as encoding and contrasting. Extensive experiments on node and graph classification benchmarks demonstrate that our technique consistently outperforms pre-defined and adaptive augmentation approaches to achieve state-of-the-art results.

**摘要:** 我们介绍了基于舒尔补充的随机拓扑增强器,用于图形对比学习(GCL) 。 基于图形拉普拉斯基矩阵,该技术生成其舒尔补充的公正近似,并处理相应的图形为增强的视角。 我们讨论了我们方法的好处,提供理论依据和与图形扩散的联系。 与以往的努力不同,我们通过对后续GCL阶段的设计选择,例如编码和对比,以控制的方式研究了增强器的实证效果。

**[Paper URL](https://proceedings.mlr.press/v202/kothapalli23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kothapalli23a/kothapalli23a.pdf)** 

# Benign Overfitting in Two-layer ReLU Convolutional Neural Networks
**题目:** ReLU双层突变神经网络的优越性

**作者:** Yiwen Kou, Zixiang Chen, Yuanzhou Chen, Quanquan Gu

**Abstract:** Modern deep learning models with great expressive power can be trained to overfit the training data but still generalize well. This phenomenon is referred to as benign overfitting. Recently, a few studies have attempted to theoretically understand benign overfitting in neural networks. However, these works are either limited to neural networks with smooth activation functions or to the neural tangent kernel regime. How and when benign overfitting can occur in ReLU neural networks remains an open problem. In this work, we seek to answer this question by establishing algorithm-dependent risk bounds for learning two-layer ReLU convolutional neural networks with label-flipping noise. We show that, under mild conditions, the neural network trained by gradient descent can achieve near-zero training loss and Bayes optimal test risk. Our result also reveals a sharp transition between benign and harmful overfitting under different conditions on data distribution in terms of test risk. Experiments on synthetic data back up our theory.

**摘要:** 现代深层学习模型具有很强的表达能力,可以训练以适应训练数据,但仍能广义化。这一现象被称为良性过渡。最近,一些研究试图从理论上理解神经网络中的良性过渡。然而,这些工作要么局限于神经网络的平滑激活功能,要么局限于神经 Tangent 内核制度。良性过渡在ReLU神经网络中如何发生仍然是一个开放的问题。在这个研究中,我们试图通过建立基于算法的风险边界来回答这个问题。对合成数据的实验证明了我们的理论.

**[Paper URL](https://proceedings.mlr.press/v202/kou23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kou23a/kou23a.pdf)** 

# Variational Mixture of HyperGenerators for Learning Distributions over Functions
**题目:** 基于函数的学习分布 HyperGenerators的变量混合

**作者:** Batuhan Koyuncu, Pablo Sanchez Martin, Ignacio Peis, Pablo M. Olmos, Isabel Valera

**Abstract:** Recent approaches build on implicit neural representations (INRs) to propose generative models over function spaces. However, they are computationally costly when dealing with inference tasks, such as missing data imputation, or directly cannot tackle them. In this work, we propose a novel deep generative model, named VaMoH. VaMoH combines the capabilities of modeling continuous functions using INRs and the inference capabilities of Variational Autoencoders (VAEs). In addition, VaMoH relies on a normalizing flow to define the prior, and a mixture of hypernetworks to parametrize the data log-likelihood. This gives VaMoH a high expressive capability and interpretability. Through experiments on a diverse range of data types, such as images, voxels, and climate data, we show that VaMoH can effectively learn rich distributions over continuous functions. Furthermore, it can perform inference-related tasks, such as conditional super-resolution generation and in-painting, as well or better than previous approaches, while being less computationally demanding.

**摘要:** 近来的方法建立在隐性神经表示(INRs)之上,以提议在函数空间上建模模型。然而,在处理推导任务时,它们是计算上昂贵的,例如缺少数据归纳,或者直接无法解决它们。在这个工作中,我们提出了一种新颖的深层建模模型,命名为VaMoH。VaMoH结合了INRs和变量自动编码器(VAEs)的推导能力,以建模连续函数的能力。此外,VaMoH依赖于一个规范化流程来定义前者,以及一个混合的超网络来参数化数据日志可能性。此外,它可以执行与推理有关的任务,如条件超分辨率生成和内油漆,并且比以前的方法更好,同时具有较少的计算要求。

**[Paper URL](https://proceedings.mlr.press/v202/koyuncu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/koyuncu23a/koyuncu23a.pdf)** 

# Gradient Descent Monotonically Decreases the Sharpness of Gradient Flow Solutions in Scalar Networks and Beyond
**题目:** 梯度偏移单调地降低了梯度流解决方案的 Sharpness

**作者:** Itai Kreisler, Mor Shpigel Nacson, Daniel Soudry, Yair Carmon

**Abstract:** Recent research shows that when Gradient Descent (GD) is applied to neural networks, the loss almost never decreases monotonically. Instead, the loss oscillates as gradient descent converges to its “Edge of Stability” (EoS). Here, we find a quantity that does decrease monotonically throughout GD training: the sharpness attained by the gradient flow solution (GFS)—the solution that would be obtained if, from now until convergence, we train with an infinitesimal step size. Theoretically, we analyze scalar neural networks with the squared loss, perhaps the simplest setting where the EoS phenomena still occur. In this model, we prove that the GFS sharpness decreases monotonically. Using this result, we characterize settings where GD provably converges to the EoS in scalar networks. Empirically, we show that GD monotonically decreases the GFS sharpness in a squared regression model as well as practical neural network architectures.

**摘要:** 最近的研究表明,当梯度降落(GD)应用于神经网络时,损失几乎不会单调地减少。相反,损失在梯度降落的“稳定边缘”(EoS)上振荡。在这里,我们发现在 GD训练中单调地减少的数量:梯度流动解决方案(GFS)所取得的敏锐度—如果从现在到收敛,我们使用无穷小步骤大小进行训练,那么可以得到的解决办法。理论上,我们分析了平方损失的神经网络,也许是最简单的设置,其中EoS现象仍然发生。

**[Paper URL](https://proceedings.mlr.press/v202/kreisler23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kreisler23a/kreisler23a.pdf)** 

# Estimation Beyond Data Reweighting: Kernel Method of Moments
**题目:**  beyond data reweighting的估算:核心矩阵方法

**作者:** Heiner Kremer, Yassine Nemmour, Bernhard Schölkopf, Jia-Jie Zhu

**Abstract:** Moment restrictions and their conditional counterparts emerge in many areas of machine learning and statistics ranging from causal inference to reinforcement learning. Estimators for these tasks, generally called methods of moments, include the prominent generalized method of moments (GMM) which has recently gained attention in causal inference. GMM is a special case of the broader family of empirical likelihood estimators which are based on approximating a population distribution by means of minimizing a $\varphi$-divergence to an empirical distribution. However, the use of $\varphi$-divergences effectively limits the candidate distributions to reweightings of the data samples. We lift this long-standing limitation and provide a method of moments that goes beyond data reweighting. This is achieved by defining an empirical likelihood estimator based on maximum mean discrepancy which we term the kernel method of moments (KMM). We provide a variant of our estimator for conditional moment restrictions and show that it is asymptotically first-order optimal for such problems. Finally, we show that our method achieves competitive performance on several conditional moment restriction tasks.

**摘要:** 因果推导到增强学习的许多机器学习和统计领域中出现的矩阵限制及其条件性对照。这些任务的估计者,通常称为矩阵方法,包括最近在因果推导中引起注意的突出的矩阵一般化方法(GMM)。GMM是一个基于最小化$\varphi$-divergence到最小化$\varphi$-divergence的人口分布的广义经验概率估计者家族的特殊案例。然而,$\varphi$-divergences的使用实际上限制了数据样本的候选分布重权化。我们解除了这一长期的限制并提供了超越数据重权化的矩阵方法。给出了条件动量限制的估计器的变量,并证明该估计器在条件动量限制的几个任务中具有竞争性性能。

**[Paper URL](https://proceedings.mlr.press/v202/kremer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kremer23a/kremer23a.pdf)** 

# Multi-Task Differential Privacy Under Distribution Skew
**题目:** 多任务差异性私隐在分配下划分

**作者:** Walid Krichene, Prateek Jain, Shuang Song, Mukund Sundararajan, Abhradeep Guha Thakurta, Li Zhang

**Abstract:** We study the problem of multi-task learning under user-level differential privacy, in which n users contribute data to m tasks, each involving a subset of users. One important aspect of the problem, that can significantly impact quality, is the distribution skew among tasks. Tasks that have much fewer data samples than others are more susceptible to the noise added for privacy. It is natural to ask whether algorithms can adapt to this skew to improve the overall utility. We give a systematic analysis of the problem, by studying how to optimally allocate a user’s privacy budget among tasks. We propose a generic algorithm, based on an adaptive reweighting of the empirical loss, and show that in the presence of distribution skew, this gives a quantifiable improvement of excess empirical risk. Experimental studies on recommendation problems that exhibit a long tail of small tasks, demonstrate that our methods significantly improve utility, achieving the state of the art on two standard benchmarks.

**摘要:** 我们研究了多任务学习在用户层次的差异性隐私下的问题,其中 n 用户对 m 任务提供数据,每个任务涉及一个用户子集。一个问题的重要方面,可以显著影响质量,是任务间的分配偏差。比其他任务的数据样本少得多的任务对增加隐私的噪声更敏感。自然地问,算法是否能适应这一偏差来改善整体实用性。我们通过研究如何在任务间优化分配用户隐私预算,对这个问题进行了系统分析。实验研究表明,我们的方法大大提高了实用性,在两个标准指标上达到最先进的水平。

**[Paper URL](https://proceedings.mlr.press/v202/krichene23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/krichene23a/krichene23a.pdf)** 

# Towards Bridging the Gaps between the Right to Explanation and the Right to be Forgotten
**题目:** 解决解释权与被遗忘权之间的差距

**作者:** Satyapriya Krishna, Jiaqi Ma, Himabindu Lakkaraju

**Abstract:** The Right to Explanation and the Right to be Forgotten are two important principles outlined to regulate algorithmic decision making and data usage in real-world applications. While the right to explanation allows individuals to request an actionable explanation for an algorithmic decision, the right to be forgotten grants them the right to ask for their data to be deleted from all the databases and models of an organization. Intuitively, enforcing the right to be forgotten may trigger model updates which in turn invalidate previously provided explanations, thus violating the right to explanation. In this work, we investigate the technical implications arising due to the interference between the two aforementioned regulatory principles, and propose the first algorithmic framework to resolve the tension between them. To this end, we formulate a novel optimization problem to generate explanations that are robust to model updates due to the removal of training data instances by data deletion requests. We then derive an efficient approximation algorithm to handle the combinatorial complexity of this optimization problem. We theoretically demonstrate that our method generates explanations that are provably robust to worst-case data deletion requests with bounded costs in case of linear models and certain classes of non-linear models. Extensive experimentation with real-world datasets demonstrates the efficacy of the proposed framework.

**摘要:** 解释权和遗忘权是规范算法决策和数据应用的两个重要原则。解释权允许个人请求对算法决策进行有效的解释,而遗忘权赋予他们要求其数据被删除组织所有数据库和模型的权利。在直觉上,执行遗忘权可能触发模型更新,从而使先前提供的解释无效,从而违反解释权。本文研究了上述两个监管原则之间的干涉所产生的技术影响,并提出了解决它们之间的紧张关系的第一个算法框架。为此,我们制定了一种新的优化问题,以产生基于数据删除请求消除训练数据实例的模型更新的解释,然后推导出有效的近似算法来处理该优化问题的组合复杂性。我们从理论上证明,我们的方法能够证明在线性模型和非线性模型的某些类别情况下具有约束成本的最坏数据删除请求的解释。

**[Paper URL](https://proceedings.mlr.press/v202/krishna23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/krishna23a/krishna23a.pdf)** 

# Graph Neural Tangent Kernel: Convergence on Large Graphs
**题目:** 图 neural tangent kernel:大图的收敛性

**作者:** Sanjukta Krishnagopal, Luana Ruiz

**Abstract:** Graph neural networks (GNNs) achieve remarkable performance in graph machine learning tasks but can be hard to train on large-graph data, where their learning dynamics are not well understood. We investigate the training dynamics of large-graph GNNs using graph neural tangent kernels (GNTKs) and graphons. In the limit of large width, optimization of an overparametrized NN is equivalent to kernel regression on the NTK. Here, we investigate how the GNTK evolves as another independent dimension is varied: the graph size. We use graphons to define limit objects—graphon NNs for GNNs, and graphon NTKs for GNTKs—, and prove that, on a sequence of graphs, the GNTKs converge to the graphon NTK. We further prove that the spectrum of the GNTK, which is related to the problem’s learning directions, converges to the spectrum of the GNTK. This implies that in the large-graph limit, the GNTK fitted on a graph of moderate size can be used to solve the same task on the large graph, and to infer the learning dynamics of the large-graph GNN. These results are verified empirically on node regression and classification tasks.

**摘要:** 图形神经网络(GNN)在图形机器学习任务中取得显著的性能,但很难在大型图形数据上进行训练,其学习动力学并不很好理解。我们研究了使用图形神经 Tangent kernels(GNTKs)和graphons的大型图形GNN的训练动力学。在宽度的限制下,优化过参数化NN与NTK上的核回归等价。这意味着在大图限度中,适量大小图上安装的GNTK可以用于解决大图上相同的任务,并推导大图GNN的学习动力学。这些结果在节点回归和分类任务上进行了实验验证。

**[Paper URL](https://proceedings.mlr.press/v202/krishnagopal23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/krishnagopal23a/krishnagopal23a.pdf)** 

# Diffusion Models for Black-Box Optimization
**题目:** 黑箱优化扩散模型

**作者:** Siddarth Krishnamoorthy, Satvik Mehul Mashkaria, Aditya Grover

**Abstract:** The goal of offline black-box optimization (BBO) is to optimize an expensive black-box function using a fixed dataset of function evaluations. Prior works consider forward approaches that learn surrogates to the black-box function and inverse approaches that directly map function values to corresponding points in the input domain of the black-box function. These approaches are limited by the quality of the offline dataset and the difficulty in learning one-to-many mappings in high dimensions, respectively. We propose Denoising Diffusion Optimization Models (DDOM), a new inverse approach for offline black-box optimization based on diffusion models. Given an offline dataset, DDOM learns a conditional generative model over the domain of the black-box function conditioned on the function values. We investigate several design choices in DDOM, such as reweighting the dataset to focus on high function values and the use of classifier-free guidance at test-time to enable generalization to function values that can even exceed the dataset maxima. Empirically, we conduct experiments on the Design-Bench benchmark (Trabucco et al., 2022) and show that DDOM achieves results competitive with state-of-the-art baselines.

**摘要:** 非线性黑箱优化(BBO)的目标是利用函数评价的固定数据集优化一个昂贵的黑箱函数。前面的工作考虑学习黑箱函数的代用方法和直接映射黑箱函数输入域中的相应点的函数值的反向方法。这些方法由非线性数据集的质量和学习高维中的一到多映射的难度所限制。我们提出了一种基于扩散模型的非线性黑箱优化的新反向方法。我们研究了DDOM的一些设计选择,例如重权数据集以集中于高函数值,以及在测试时使用无分类器的指导,以便将函数值推广到甚至超过数据集最大值。

**[Paper URL](https://proceedings.mlr.press/v202/krishnamoorthy23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/krishnamoorthy23a/krishnamoorthy23a.pdf)** 

# Learning to Design Analog Circuits to Meet Threshold Specifications
**题目:** 学习设计模拟电路以满足阈值规范

**作者:** Dmitrii Krylov, Pooya Khajeh, Junhan Ouyang, Thomas Reeves, Tongkai Liu, Hiba Ajmal, Hamidreza Aghasi, Roy Fox

**Abstract:** Automated design of analog and radio-frequency circuits using supervised or reinforcement learning from simulation data has recently been studied as an alternative to manual expert design. It is straightforward for a design agent to learn an inverse function from desired performance metrics to circuit parameters. However, it is more common for a user to have threshold performance criteria rather than an exact target vector of feasible performance measures. In this work, we propose a method for generating from simulation data a dataset on which a system can be trained via supervised learning to design circuits to meet threshold specifications. We moreover perform the to-date most extensive evaluation of automated analog circuit design, including experimenting in a significantly more diverse set of circuits than in prior work, covering linear, nonlinear, and autonomous circuit configurations, and show that our method consistently reaches success rate better than 90% at 5% error margin, while also improving data efficiency by upward of an order of magnitude.

**摘要:** 基于仿真数据进行监控或增强学习的模拟和无线电频电路的自动化设计,作为一种替代手动专家设计的途径,最近被研究。对于设计代理人来说,从期望的性能指标学习到电路参数的逆函数是很容易的。然而,对于用户来说,拥有可行的性能指标的阈值性能标准比一个准确的目标向量更常见。此外,我们对自动化模拟电路设计进行了迄今为止最广泛的评价,包括在比以往的工作更广泛的线性、非线性和自主电路配置中进行实验,并表明,我们的方法在误差率5%的情况下始终达到90%以上的成功率,同时提高了数据效率以超过一个数量级。

**[Paper URL](https://proceedings.mlr.press/v202/krylov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/krylov23a/krylov23a.pdf)** 

# Variance Control for Distributional Reinforcement Learning
**题目:** 分布强化学习变量控制

**作者:** Qi Kuang, Zhoufan Zhu, Liwen Zhang, Fan Zhou

**Abstract:** Although distributional reinforcement learning (DRL) has been widely examined in the past few years, very few studies investigate the validity of the obtained Q-function estimator in the distributional setting. To fully understand how the approximation errors of the Q-function affect the whole training process, we do some error analysis and theoretically show how to reduce both the bias and the variance of the error terms. With this new understanding, we construct a new estimator Quantiled Expansion Mean (QEM) and introduce a new DRL algorithm (QEMRL) from the statistical perspective. We extensively evaluate our QEMRL algorithm on a variety of Atari and Mujoco benchmark tasks and demonstrate that QEMRL achieves significant improvement over baseline algorithms in terms of sample efficiency and convergence performance.

**摘要:** 尽管分布强化学习(DRL)在过去几年中被广泛研究,但很少有研究研究在分布环境中得到的Q-函数估计器的有效性。为了充分理解Q-函数的近似误差如何影响整个训练过程,我们进行了一些误差分析,并从理论上证明如何减少误差的偏差和变量。

**[Paper URL](https://proceedings.mlr.press/v202/kuang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kuang23a/kuang23a.pdf)** 

# Hierarchical Imitation Learning with Vector Quantized Models
**题目:** 矢量化模型的层次仿真学习

**作者:** Kalle Kujanpää, Joni Pajarinen, Alexander Ilin

**Abstract:** The ability to plan actions on multiple levels of abstraction enables intelligent agents to solve complex tasks effectively. However, learning the models for both low and high-level planning from demonstrations has proven challenging, especially with higher-dimensional inputs. To address this issue, we propose to use reinforcement learning to identify subgoals in expert trajectories by associating the magnitude of the rewards with the predictability of low-level actions given the state and the chosen subgoal. We build a vector-quantized generative model for the identified subgoals to perform subgoal-level planning. In experiments, the algorithm excels at solving complex, long-horizon decision-making problems outperforming state-of-the-art. Because of its ability to plan, our algorithm can find better trajectories than the ones in the training set.

**摘要:** 针对这一问题,我们建议利用强化学习来识别专家轨迹中的次目标,将奖励的大小与给定状态和选定次目标的次级行动的可预测性联系起来。我们为确定的次目标建立向量化生成模型,以执行次目标级规划。在实验中,该算法在解决复杂、长期决策问题方面优于最先进的算法。

**[Paper URL](https://proceedings.mlr.press/v202/kujanpaa23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kujanpaa23a/kujanpaa23a.pdf)** 

# SinDDM: A Single Image Denoising Diffusion Model
**题目:** SinDDM:一种单一图像噪声扩散模型

**作者:** Vladimir Kulikov, Shahar Yadin, Matan Kleiner, Tomer Michaeli

**Abstract:** Denoising diffusion models (DDMs) have led to staggering performance leaps in image generation, editing and restoration. However, existing DDMs use very large datasets for training. Here, we introduce a framework for training a DDM on a single image. Our method, which we coin SinDDM, learns the internal statistics of the training image by using a multi-scale diffusion process. To drive the reverse diffusion process, we use a fully-convolutional light-weight denoiser, which is conditioned on both the noise level and the scale. This architecture allows generating samples of arbitrary dimensions, in a coarse-to-fine manner. As we illustrate, SinDDM generates diverse high-quality samples, and is applicable in a wide array of tasks, including style transfer and harmonization. Furthermore, it can be easily guided by external supervision. Particularly, we demonstrate text-guided generation from a single image using a pre-trained CLIP model.

**摘要:** 描述扩散模型(DDMs)在图像生成、编辑和恢复中导致了惊人的性能跃迁。然而,现有DDM使用非常大的数据集进行培训。这里,我们引入了一个在单个图像上培训DDM的框架。我们的方法,即SinDDM,通过使用多维扩散过程学习培训图像的内部统计。为了驱动反向扩散过程,我们使用一个完全变形的轻量噪声调制器,该调制器在噪声水平和尺度上都有条件。该架构允许在粗糙到精细的方式生成任意尺寸的样品。

**[Paper URL](https://proceedings.mlr.press/v202/kulikov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kulikov23a/kulikov23a.pdf)** 

# Towards Explaining Distribution Shifts
**题目:** 向解释分配移位方向

**作者:** Sean Kulinski, David I. Inouye

**Abstract:** A distribution shift can have fundamental consequences such as signaling a change in the operating environment or significantly reducing the accuracy of downstream models. Thus, understanding distribution shifts is critical for examining and hopefully mitigating the effect of such a shift. Most prior work has focused on merely detecting if a shift has occurred and assumes any detected shift can be understood and handled appropriately by a human operator. We hope to aid in these manual mitigation tasks by explaining the distribution shift using interpretable transportation maps from the original distribution to the shifted one. We derive our interpretable mappings from a relaxation of the optimal transport problem, where the candidate mappings are restricted to a set of interpretable mappings. We then use a wide array of quintessential examples of distribution shift in real-world tabular, text, and image cases to showcase how our explanatory mappings provide a better balance between detail and interpretability than baseline explanations by both visual inspection and our PercentExplained metric.

**摘要:** 分布式变换可以产生基本后果,例如在操作环境中发出信号或大大降低下游模型的准确性。因此,理解分布式变换对于研究和希望减轻这种变换的影响至关重要。大多数以前的工作只集中在检测变换是否发生,并假设任何被检测的变换可以由人类操作者正确理解和处理。我们希望通过解释从原始分布到变换的可解释的运输地图来帮助这些手动减轻任务。然后,我们使用实世界表格、文本和图像案例中分布变化的一系列关键性例子,以展示我们的解释映射如何比视觉检查和我们的PercentExplained度量方法的基线解释提供更好的细节和可解释性之间的平衡。

**[Paper URL](https://proceedings.mlr.press/v202/kulinski23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kulinski23a/kulinski23a.pdf)** 

# Featured Graph Coarsening with Similarity Guarantees
**题目:** 具有相似性保证的特征图粗糙

**作者:** Manoj Kumar, Anurag Sharma, Shashwat Saxena, Sandeep Kumar

**Abstract:** Graph coarsening is a dimensionality reduction technique that aims to learn a smaller-tractable graph while preserving the properties of the original input graph. However, many real-world graphs also have features or contexts associated with each node. The existing graph coarsening methods do not consider the node features and rely solely on a graph matrix(e.g., adjacency and Laplacian) to coarsen graphs. However, some recent deep learning-based graph coarsening methods are designed for specific tasks considering both node features and graph matrix. In this paper, we introduce a novel optimization-based framework for graph coarsening that takes both the graph matrix and the node features as the input and jointly learns the coarsened graph matrix and the coarsened feature matrix while ensuring desired properties. To the best of our knowledge, this is the first work that guarantees that the learned coarsened graph is $\epsilon\in[0,1)$ similar to the original graph. Extensive experiments with both real and synthetic benchmark datasets elucidate the proposed framework’s efficacy and applicability for numerous graph-based applications, including graph clustering, node classification, stochastic block model identification, and graph summarization.

**摘要:** 图粗糙度是一种减少维度的技术,旨在学习较小可tractable图,同时保留原始输入图的属性。然而,许多实物图也有与每个节点关联的特征或上下文。现有的图粗糙度方法不考虑节点特征,只依靠图矩阵(例如邻接和拉普拉西亚)来粗糙图。然而,一些最近的基于深度学习的图粗糙度方法是用于考虑节点特征和图矩阵的特定任务设计的。对实际和合成的基准数据集进行广泛的实验,阐明了拟议的框架对于许多基于图的应用程序的有效性和适用性,包括图集、节点分类、随机块模型识别和图总结。

**[Paper URL](https://proceedings.mlr.press/v202/kumar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kumar23a/kumar23a.pdf)** 

# Modeling Dynamic Environments with Scene Graph Memory
**题目:** 用场景图记忆建模动态环境

**作者:** Andrey Kurenkov, Michael Lingelbach, Tanmay Agarwal, Emily Jin, Chengshu Li, Ruohan Zhang, Li Fei-Fei, Jiajun Wu, Silvio Savarese, Roberto Martı́n-Martı́n

**Abstract:** Embodied AI agents that search for objects in large environments such as households often need to make efficient decisions by predicting object locations based on partial information. We pose this as a new type of link prediction problem: link prediction on partially observable dynamic graphs Our graph is a representation of a scene in which rooms and objects are nodes, and their relationships are encoded in the edges; only parts of the changing graph are known to the agent at each timestep. This partial observability poses a challenge to existing link prediction approaches, which we address. We propose a novel state representation – Scene Graph Memory (SGM) – with captures the agent’s accumulated set of observations, as well as a neural net architecture called a Node Edge Predictor (NEP) that extracts information from the SGM to search efficiently. We evaluate our method in the Dynamic House Simulator, a new benchmark that creates diverse dynamic graphs following the semantic patterns typically seen at homes, and show that NEP can be trained to predict the locations of objects in a variety of environments with diverse object movement dynamics, outperforming baselines both in terms of new scene adaptability and overall accuracy. The codebase and more can be found www.scenegraphmemory.com.

**摘要:** 基于部分信息的对象定位预测是需要在大型环境,例如家庭中寻找对象的隐身AI代理人经常需要作出有效的决策。我们提出了一种新的链路预测问题:部分可观测的动态图形上的链路预测 Our graph is a representation of a scene in which rooms and objects are nodes, and their relationships are encoded in the edges; only parts of the changing graph are known to the agent at each timestep. This partial observability poses a challenge to existing link prediction approaches, which we address. We propose a novel state representation – Scene Graph Memory (SGM) – with captures the agent’s accumulated set of observations, as well as a neural net architecture called a Node Edge Predictor (NEP) that extracts information from the SGM to search efficiently.我们在动态住宅模拟器中评估了我们的方法,这是一个新的基准,它创建各种动态图形,遵循典型的家庭的语义模式,并表明,NEP可以训练在各种环境中预测对象的位置,具有不同的对象运动动力学,在新的场景适应性和整体准确性方面的表现超过了基准。

**[Paper URL](https://proceedings.mlr.press/v202/kurenkov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kurenkov23a/kurenkov23a.pdf)** 

# Tied-Augment: Controlling Representation Similarity Improves Data Augmentation
**题目:** Tied-Augment:控制表示相似性改善数据增强

**作者:** Emirhan Kurtuluş, Zichao Li, Yann Dauphin, Ekin Dogus Cubuk

**Abstract:** Data augmentation methods have played an important role in the recent advance of deep learning models, and have become an indispensable component of state-of-the-art models in semi-supervised, self-supervised, and supervised training for vision. Despite incurring no additional latency at test time, data augmentation often requires more epochs of training to be effective. For example, even the simple flips-and-crops augmentation requires training for more than 5 epochs to improve performance, whereas RandAugment requires more than 90 epochs. We propose a general framework called Tied-Augment, which improves the efficacy of data augmentation in a wide range of applications by adding a simple term to the loss that can control the similarity of representations under distortions. Tied-Augment can improve state-of-the-art methods from data augmentation (e.g. RandAugment, mixup), optimization (e.g. SAM), and semi-supervised learning (e.g. FixMatch). For example, Tied-RandAugment can outperform RandAugment by 2.0% on ImageNet. Notably, using Tied-Augment, data augmentation can be made to improve generalization even when training for a few epochs and when fine-tuning. We open source our code at https://github.com/ekurtulus/tied-augment/tree/main.

**摘要:** 数据增强方法在最近的深入学习模型的进步中发挥了重要作用,并且成为半监督、自我监督和视力监督训练中最先进的模型的不可缺少组成部分。尽管在测试时没有额外的延迟,数据增强通常需要更多的训练阶段才能发挥作用。例如,即使是简单的翻转和作物增强需要训练超过5个时期才能提高性能,而RandAugment则需要超过90个时期。我们提出了一种名为Tied-Augment的一般框架,它通过添加一个简单的术语来改善在各种应用中的数据增强的有效性,从而控制在扭曲下显示的相似性。例如,Tied-RandAugment可以在ImageNet上超过RandAugment的2.0%。 特别是,使用Tied-Augment,数据增强可以改善一般化,即使在训练几个时代和微调时。

**[Paper URL](https://proceedings.mlr.press/v202/kurtulus23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kurtulus23a/kurtulus23a.pdf)** 

# Cooperation in the Latent Space: The Benefits of Adding Mixture Components in Variational Autoencoders
**题目:** 间接空间合作:在变量自动编码器中添加混合组件的好处

**作者:** Oskar Kviman, Ricky Molén, Alexandra Hotti, Semih Kurt, Vı́ctor Elvira, Jens Lagergren

**Abstract:** In this paper, we show how the mixture components cooperate when they jointly adapt to maximize the ELBO. We build upon recent advances in the multiple and adaptive importance sampling literature. We then model the mixture components using separate encoder networks and show empirically that the ELBO is monotonically non-decreasing as a function of the number of mixture components. These results hold for a range of different VAE architectures on the MNIST, FashionMNIST, and CIFAR-10 datasets. In this work, we also demonstrate that increasing the number of mixture components improves the latent-representation capabilities of the VAE on both image and single-cell datasets. This cooperative behavior motivates that using Mixture VAEs should be considered a standard approach for obtaining more flexible variational approximations. Finally, Mixture VAEs are here, for the first time, compared and combined with normalizing flows, hierarchical models and/or the VampPrior in an extensive ablation study. Multiple of our Mixture VAEs achieve state-of-the-art log-likelihood results for VAE architectures on the MNIST and FashionMNIST datasets. The experiments are reproducible using our code, provided https://github.com/Lagergren-Lab/MixtureVAEs.

**摘要:** 本文研究了混合物组件在共同适应以最大化混合物组件时如何进行合作,并从多变量和适应性的重要采样文献中取得的最新进展。然后,我们利用单独的编码网络对混合物组件进行了建模,并实证表明混合物组件的数目是单调的,不减少的。这些结果适用于MNIST、 FashionMNIST和CIFAR-10数据集的多种混合物组件架构。最后,Mixture VAEs首次与正常化流程、层次模型和/或VampPrior在广泛的抽象研究中进行了比较和结合。我们的Mixture VAEs在MNIST和ModeMNIST数据集上为VAE架构取得最先进的 logi-likelihood结果。实验可用我们的代码,提供 https://github.com/Lagergren-Lab/MixtureVAEs。

**[Paper URL](https://proceedings.mlr.press/v202/kviman23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kviman23a/kviman23a.pdf)** 

# GeCoNeRF: Few-shot Neural Radiance Fields via Geometric Consistency
**题目:** GeCoNeRF:通过几何一致性的少数射击神经辐射场

**作者:** Min-Seop Kwak, Jiuhn Song, Seungryong Kim

**Abstract:** We present a novel framework to regularize Neural Radiance Field (NeRF) in a few-shot setting with a geometry-aware consistency regularization. The proposed approach leverages a rendered depth map at unobserved viewpoint to warp sparse input images to the unobserved viewpoint and impose them as pseudo ground truths to facilitate learning of NeRF. By encouraging such geometry-aware consistency at a feature-level instead of using pixel-level reconstruction loss, we regularize the NeRF at semantic and structural levels while allowing for modeling view dependent radiance to account for color variations across viewpoints. We also propose an effective method to filter out erroneous warped solutions, along with training strategies to stabilize training during optimization. We show that our model achieves competitive results compared to state-of-the-art few-shot NeRF models.

**摘要:** 提出了一种新颖的构架,以几何学知觉的一致性规范化来规范神经辐射场(NeRF)在少数射击设置中。该方法利用在未观察的视点绘制的深度图,将稀疏的输入图像向未观察的视点歪曲,并将其作为伪地面真实强加,以促进学习NeRF。通过鼓励这种几何学知觉的一致性,而不是使用像素级重建损失,我们在语义和结构层面规范NeRF while allowing for modeling view dependent radiance to account for color variations across viewpoints。我们还提出了一种有效的滤波错误歪曲解决方案的方法,以及训练策略以稳定训练在优化过程中。

**[Paper URL](https://proceedings.mlr.press/v202/kwak23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kwak23a/kwak23a.pdf)** 

# Rotation and Translation Invariant Representation Learning with Implicit Neural Representations
**题目:** 旋转和翻译非变形表示学习与隐形神经表示

**作者:** Sehyun Kwon, Joo Young Choi, Ernest K. Ryu

**Abstract:** In many computer vision applications, images are acquired with arbitrary or random rotations and translations, and in such setups, it is desirable to obtain semantic representations disentangled from the image orientation. Examples of such applications include semiconductor wafer defect inspection, plankton microscope images, and inference on single-particle cryo-electron microscopy (cryo-EM) micro-graphs. In this work, we propose Invariant Representation Learning with Implicit Neural Representation (IRL-INR), which uses an implicit neural representation (INR) with a hypernetwork to obtain semantic representations disentangled from the orientation of the image. We show that IRL-INR can effectively learn disentangled semantic representations on more complex images compared to those considered in prior works and show that these semantic representations synergize well with SCAN to produce state-of-the-art unsupervised clustering results.

**摘要:** 在许多计算机视觉应用中,图像是通过任意或随机旋转和翻译获得的,在这样的设置中,是可望 obtain semantic representations disentangled from the image orientation. Examples of such applications include semiconductor wafer defect inspection, plankton microscope images, and inference on single-particle cryo-electron microscopy (cryo-EM) micrographs. In this work, we propose Invariant Representation Learning with Implicit Neural Representation (IRL-INR), which uses an implicit neural representation (INR) with a hypernetwork to obtain semantic representations disentangled from the image orientation. We show that IRL-INR can effectively learn disentangled semantic representations on more complex images compared to those considered in previous works and show that these semantic representations synergize well with SCAN to produce

**[Paper URL](https://proceedings.mlr.press/v202/kwon23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kwon23a/kwon23a.pdf)** 

# Reward-Mixing MDPs with Few Latent Contexts are Learnable
**题目:** 少有潜在背景的奖励交换MDP可学习

**作者:** Jeongyeol Kwon, Yonathan Efroni, Constantine Caramanis, Shie Mannor

**Abstract:** We consider episodic reinforcement learning in reward-mixing Markov decision processes (RMMDPs): at the beginning of every episode nature randomly picks a latent reward model among $M$ candidates and an agent interacts with the MDP throughout the episode for $H$ time steps. Our goal is to learn a near-optimal policy that nearly maximizes the $H$ time-step cumulative rewards in such a model. Prior work established an upper bound for RMMDPs with $M=2$. In this work, we resolve several open questions for the general RMMDP setting. We consider an arbitrary $M\ge2$ and provide a sample-efficient algorithm–$EM^2$–that outputs an $\epsilon$-optimal policy using $O \left(\epsilon^{-2} \cdot S^d A^d \cdot \text{poly}(H, Z)^d \right)$ episodes, where $S, A$ are the number of states and actions respectively, $H$ is the time-horizon, $Z$ is the support size of reward distributions and $d=O(\min(M,H))$. We also provide a $(SA)^{\Omega(\sqrt{M})} / \epsilon^{2}$ lower bound, supporting that super-polynomial sample complexity in $M$ is necessary.

**摘要:** 我们考虑 reward-mixing Markov decision processes (RMMDPs)中的 episodic reinforcement learning: 在每个事件的开始时,自然会随机选择一个在$M$候选人之间潜在的奖励模型,并且一个代理人在$H$时间步骤中与MDP进行交互。我们的目标是学习 near-optimal policy that nearly maximizes the $H$ time-step cumulative rewards in such a model。我们还提供了$(SA)^{\Omega(\sqrt{M})} / \epsilon^{2}$下限,支持$M$中的超多项式样本复杂性是必要的。

**[Paper URL](https://proceedings.mlr.press/v202/kwon23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kwon23b/kwon23b.pdf)** 

# A Fully First-Order Method for Stochastic Bilevel Optimization
**题目:** 随机双层优化的完全先购方法

**作者:** Jeongyeol Kwon, Dohyun Kwon, Stephen Wright, Robert D Nowak

**Abstract:** We consider stochastic unconstrained bilevel optimization problems when only the first-order gradient oracles are available. While numerous optimization methods have been proposed for tackling bilevel problems, existing methods either tend to require possibly expensive calculations regarding Hessians of lower-level objectives, or lack rigorous finite-time performance guarantees. In this work, we propose a Fully First-order Stochastic Approximation (F2SA) method, and study its non-asymptotic convergence properties. Specifically, we show that F2SA converges to an $\epsilon$-stationary solution of the bilevel problem after $\epsilon^{-7/2}, \epsilon^{-5/2}$, and $\epsilon^{-3/2}$ iterations (each iteration using $O(1)$ samples) when stochastic noises are in both level objectives, only in the upper-level objective, and not present (deterministic settings), respectively. We further show that if we employ momentum-assisted gradient estimators, the iteration complexities can be improved to $\epsilon^{-5/2}, \epsilon^{-4/2}$, and $\epsilon^{-3/2}$, respectively. We demonstrate even superior practical performance of the proposed method over existing second-order based approaches on MNIST data-hypercleaning experiments.

**摘要:** 我们认为只有第一阶梯度词汇才能解决随机性无约束的双层优化问题。虽然为解决双层问题提出了许多优化方法,但现有的方法要么倾向于要求对下层目标的希斯sians进行可能昂贵的计算,要么缺乏严格的有限时间性能保证。我们进一步表明,如果使用动量辅助梯度估计器,迭代复杂度可以分别提高到$\epsilon^{-5/2}, \epsilon^{-4/2}$, 和$\epsilon^{-3/2}$。

**[Paper URL](https://proceedings.mlr.press/v202/kwon23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kwon23c/kwon23c.pdf)** 

# Complexity of Block Coordinate Descent with Proximal Regularization and Applications to Wasserstein CP-dictionary Learning
**题目:** 分块坐标起始的近似规范化及其应用于水德斯坦CP字典学习

**作者:** Dohyun Kwon, Hanbaek Lyu

**Abstract:** We consider the block coordinate descent methods of Gauss-Seidel type with proximal regularization (BCD-PR), which is a classical method of minimizing general nonconvex objectives under constraints that has a wide range of practical applications. We theoretically establish the worst-case complexity bound for this algorithm. Namely, we show that for general nonconvex smooth objectives with block-wise constraints, the classical BCD-PR algorithm converges to an epsilon-stationary point within O(1/epsilon) iterations. Under a mild condition, this result still holds even if the algorithm is executed inexactly in each step. As an application, we propose a provable and efficient algorithm for ‘Wasserstein CP-dictionary learning’, which seeks a set of elementary probability distributions that can well-approximate a given set of d-dimensional joint probability distributions. Our algorithm is a version of BCD-PR that operates in the dual space, where the primal problem is regularized both entropically and proximally.

**摘要:** 我们考虑了高斯-西德尔类型与近似正则化(BCD-PR)的块坐标降落方法,这是在约束下最小化一般非凸目标的经典方法,具有广泛的实际应用范围。我们从理论上建立该算法的最坏情况下的复杂性约束。我们的算法是BCD-PR的一个版本,它在双空间中运行,其中初始问题在内向和近向两方面均匀化。

**[Paper URL](https://proceedings.mlr.press/v202/kwon23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kwon23d/kwon23d.pdf)** 

# Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value
**题目:** Data-OOB:外包估算作为简单有效的数据值

**作者:** Yongchan Kwon, James Zou

**Abstract:** Data valuation is a powerful framework for providing statistical insights into which data are beneficial or detrimental to model training. Many Shapley-based data valuation methods have shown promising results in various downstream tasks, however, they are well known to be computationally challenging as it requires training a large number of models. As a result, it has been recognized as infeasible to apply to large datasets. To address this issue, we propose Data-OOB, a new data valuation method for a bagging model that utilizes the out-of-bag estimate. The proposed method is computationally efficient and can scale to millions of data by reusing trained weak learners. Specifically, Data-OOB takes less than $2.25$ hours on a single CPU processor when there are $10^6$ samples to evaluate and the input dimension is $100$. Furthermore, Data-OOB has solid theoretical interpretations in that it identifies the same important data point as the infinitesimal jackknife influence function when two different points are compared. We conduct comprehensive experiments using 12 classification datasets, each with thousands of sample sizes. We demonstrate that the proposed method significantly outperforms existing state-of-the-art data valuation methods in identifying mislabeled data and finding a set of helpful (or harmful) data points, highlighting the potential for applying data values in real-world applications.

**摘要:** 数据估价是提供数据对模型训练有好处或有害的统计洞察的强有力框架。许多基于Shapley的数据估价方法在下游任务中显示出有希望的结果,然而,它们是众所周知的计算挑战性,因为它需要训练大量的模型。结果,它被认为无法应用到大型数据集。为了解决这个问题,我们提出了Data-OOB,一种利用外包估计的新数据估价方法。此外,Data-OOB具有较强的理论解释,在比较两个不同点时,它能识别与无穷针影响函数相同的重要数据点。我们利用12个分类数据集,每个数据集有数千个样本大小进行综合实验,证明该方法在识别误标数据和发现一套有用的(或有害的)数据点方面大大超过现有的最先进的数据估算方法,突出了在实际应用中应用数据值的潜力。

**[Paper URL](https://proceedings.mlr.press/v202/kwon23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/kwon23e/kwon23e.pdf)** 

# Emergence of Adaptive Circadian Rhythms in Deep Reinforcement Learning
**题目:** 适应性圆形节奏在深层次强化学习中的应用

**作者:** Aqeel Labash, Florian Stelzer, Daniel Majoral, Raul Vicente Zafra

**Abstract:** Adapting to regularities of the environment is critical for biological organisms to anticipate events and plan. A prominent example is the circadian rhythm corresponding to the internalization by organisms of the $24$-hour period of the Earth’s rotation. In this work, we study the emergence of circadian-like rhythms in deep reinforcement learning agents. In particular, we deployed agents in an environment with a reliable periodic variation while solving a foraging task. We systematically characterize the agent’s behavior during learning and demonstrate the emergence of a rhythm that is endogenous and entrainable. Interestingly, the internal rhythm adapts to shifts in the phase of the environmental signal without any re-training. Furthermore, we show via bifurcation and phase response curve analyses how artificial neurons develop dynamics to support the internalization of the environmental rhythm. From a dynamical systems view, we demonstrate that the adaptation proceeds by the emergence of a stable periodic orbit in the neuron dynamics with a phase response that allows an optimal phase synchronisation between the agent’s dynamics and the environmental rhythm.

**摘要:** 适应环境规律是生物生物预测事件和计划的关键。一个突出的例子是地球转动周期24小时周期的生物内化与内化相符的周期节奏。在这个工作中,我们研究了深度增强学习代理中周期式节奏的出现。特别是,我们在解决搜索任务时部署在可靠周期性变化的环境中的代理。我们系统地描述了学习过程中代理的行为,并显示出一种内生和可进入的节奏的出现。有趣的是,内部节奏适应了环境信号在任何重新训练的情况下的变化。此外,我们通过分叉和相位响应曲线分析显示了人工神经元如何发展动力学来支持环境节奏内化。从动力学系统的角度,我们证明,适应过程通过神经元动力学中稳定周期轨道的出现而进行,其相响应允许剂量动力学与环境节奏之间进行最佳相同步。

**[Paper URL](https://proceedings.mlr.press/v202/labash23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/labash23a/labash23a.pdf)** 

# Synergies between Disentanglement and Sparsity: Generalization and Identifiability in Multi-Task Learning
**题目:** 分散与节约的协同效应:多任务学习中的一般化与可识别性

**作者:** Sebastien Lachapelle, Tristan Deleu, Divyat Mahajan, Ioannis Mitliagkas, Yoshua Bengio, Simon Lacoste-Julien, Quentin Bertrand

**Abstract:** Although disentangled representations are often said to be beneficial for downstream tasks, current empirical and theoretical understanding is limited. In this work, we provide evidence that disentangled representations coupled with sparse task-specific predictors improve generalization. In the context of multi-task learning, we prove a new identifiability result that provides conditions under which maximally sparse predictors yield disentangled representations. Motivated by this theoretical result, we propose a practical approach to learn disentangled representations based on a sparsity-promoting bi-level optimization problem. Finally, we explore a meta-learning version of this algorithm based on group Lasso multiclass SVM predictors, for which we derive a tractable dual formulation. It obtains competitive results on standard few-shot classification benchmarks, while each task is using only a fraction of the learned representations.

**摘要:** 在多任务学习中,我们证明了一种新的可识别性结果,它提供了最小限度的偏差预测器能产生偏差的表示。 基于这一理论结果,我们提出了一种基于偏差促进双级优化问题的实用方法来学习偏差的表示。 最后,我们探索了基于群拉索多类SVM预测器的该算法的元学习版本,由此得出可处理的双重公式。

**[Paper URL](https://proceedings.mlr.press/v202/lachapelle23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lachapelle23a/lachapelle23a.pdf)** 

# Nearly-Optimal Hierarchical Clustering for Well-Clustered Graphs
**题目:** 接近最佳的层次结构聚类图形

**作者:** Steinar Laenen, Bogdan Adrian Manghiuc, He Sun

**Abstract:** This paper presents two efficient hierarchical clustering (HC) algorithms with respect to Dasgupta’s cost function. For any input graph $G$ with a clear cluster-structure, our designed algorithms run in nearly-linear time in the input size of $G$, and return an $O(1)$-approximate HC tree with respect to Dasgupta’s cost function. We compare the performance of our algorithm against the previous state-of-the-art on synthetic and real-world datasets and show that our designed algorithm produces comparable or better HC trees with much lower running time.

**摘要:** 针对达斯古普塔的成本函数,提出了两个有效的层次聚类算法。对于任何具有清晰的聚类结构的输入图$G$,我们设计的算法在$G$的输入大小中运行近线性时间,并返回达斯古普塔的成本函数的$O(1)$-近似HC树。

**[Paper URL](https://proceedings.mlr.press/v202/laenen23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/laenen23a/laenen23a.pdf)** 

# Hybrid Energy Based Model in the Feature Space for Out-of-Distribution Detection
**题目:** 非分布检测功能空间中的混合动力模型

**作者:** Marc Lafon, Elias Ramzi, Clément Rambour, Nicolas Thome

**Abstract:** Out-of-distribution (OOD) detection is a critical requirement for the deployment of deep neural networks. This paper introduces the HEAT model, a new post-hoc OOD detection method estimating the density of in-distribution (ID) samples using hybrid energy-based models (EBM) in the feature space of a pre-trained backbone. HEAT complements prior density estimators of the ID density, e.g. parametric models like the Gaussian Mixture Model (GMM), to provide an accurate yet robust density estimation. A second contribution is to leverage the EBM framework to provide a unified density estimation and to compose several energy terms. Extensive experiments demonstrate the significance of the two contributions. HEAT sets new state-of-the-art OOD detection results on the CIFAR-10 / CIFAR-100 benchmark as well as on the large-scale Imagenet benchmark. The code is available at: https://github.com/MarcLafon/heatood.

**摘要:** 外分布检测(out-of-distribution,OOD)是 deep neural networks的部署的一个关键要求。本文介绍了HEAT模型,一种在预训练后后背骨的特征空间中使用混合能量模型(EBM)估计内分布(ID)样本的密度的新后置OOD检测方法。HEAT补充了ID密度的预先密度估计器,例如高斯混合模型(GMM)等参数模型,以提供准确但鲁棒的密度估计。

**[Paper URL](https://proceedings.mlr.press/v202/lafon23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lafon23a/lafon23a.pdf)** 

# A theory of continuous generative flow networks
**题目:** 连续生成流网络理论

**作者:** Salem Lahlou, Tristan Deleu, Pablo Lemos, Dinghuai Zhang, Alexandra Volokhova, Alex Hernández-Garcı́a, Lena Nehale Ezzine, Yoshua Bengio, Nikolay Malkin

**Abstract:** Generative flow networks (GFlowNets) are amortized variational inference algorithms that are trained to sample from unnormalized target distributions over compositional objects. A key limitation of GFlowNets until this time has been that they are restricted to discrete spaces. We present a theory for generalized GFlowNets, which encompasses both existing discrete GFlowNets and ones with continuous or hybrid state spaces, and perform experiments with two goals in mind. First, we illustrate critical points of the theory and the importance of various assumptions. Second, we empirically demonstrate how observations about discrete GFlowNets transfer to the continuous case and show strong results compared to non-GFlowNet baselines on several previously studied tasks. This work greatly widens the perspectives for the application of GFlowNets in probabilistic inference and various modeling settings.

**摘要:** 生成流网络(GFlowNets)是被训练从非正常目标分布上进行组合对象的变异推导算法,其关键限制是它们被限制在离散空间上。我们提出了通用GFlowNets的理论,包括既存在离散GFlowNets,又具有连续或混合状态空间的离散GFlowNets,并结合两个目标进行实验。首先,我们说明了理论的临界点和各种假设的重要性。

**[Paper URL](https://proceedings.mlr.press/v202/lahlou23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lahlou23a/lahlou23a.pdf)** 

# Automatically marginalized MCMC in probabilistic programming
**题目:** 概率规划中自动边缘化MCMC

**作者:** Jinlin Lai, Javier Burroni, Hui Guan, Daniel Sheldon

**Abstract:** Hamiltonian Monte Carlo (HMC) is a powerful algorithm to sample latent variables from Bayesian models. The advent of probabilistic programming languages (PPLs) frees users from writing inference algorithms and lets users focus on modeling. However, many models are difficult for HMC to solve directly, and often require tricks like model reparameterization. We are motivated by the fact that many of those models could be simplified by marginalization. We propose to use automatic marginalization as part of the sampling process using HMC in a graphical model extracted from a PPL, which substantially improves sampling from real-world hierarchical models.

**摘要:** 汉密尔顿蒙特卡罗(英语:Hamiltonian Monte Carlo,缩写HMC)是利用贝叶斯模型提取潜在变量的一个强大的算法。概率编程语言(PPL)的出现使用户免于编写推理算法,并使用户集中于建模。然而,许多模型很难直接解决,而且往往需要像模型校正(英语:Model reparameterization)这样的技巧。

**[Paper URL](https://proceedings.mlr.press/v202/lai23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lai23a/lai23a.pdf)** 

# DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation
**题目:** DS-1000:数据科学代码生成的自然可靠标准

**作者:** Yuhang Lai, Chengxi Li, Yiming Wang, Tianyi Zhang, Ruiqi Zhong, Luke Zettlemoyer, Wen-Tau Yih, Daniel Fried, Sida Wang, Tao Yu

**Abstract:** We introduce DS-1000, a code generation benchmark with a thousand data science problems spanning seven Python libraries, such as Numpy and Pandas. Compared to prior works, DS-1000 incorporates three core features. First, our problems reflect diverse, realistic, and practical use cases since we collected them from StackOverflow. Second, our automatic evaluation is highly specific (reliable) – across all Codex-002-predicted solutions that our evaluation accepts, only 1.8% of them are incorrect; we achieve this with multi-criteria metrics, checking both functional correctness by running test cases and surface-form constraints by restricting API usages or keywords. Finally, we proactively defend against memorization by slightly modifying our problems to be different from the original StackOverflow source; consequently, models cannot answer them correctly by memorizing the solutions from pre-training. The current best public system (Codex-002) achieves 43.3% accuracy, leaving ample room for improvement. We release our benchmark at https://ds1000-code-gen.github.io.

**摘要:** 我们引入DS-1000,一个代码生成基准,它包含了千个数据科学问题,包括七个 Python库,如Numpy和Pandas。 与以前的工作相比,DS-1000包含了三个核心功能。目前最好的公共系统(Codex-002)达到了43.3%的精度,留下大量改进空间。我们在 https://ds1000-code-gen.github.io上发布我们的基准。

**[Paper URL](https://proceedings.mlr.press/v202/lai23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lai23b/lai23b.pdf)** 

# ChiPFormer: Transferable Chip Placement via Offline Decision Transformer
**题目:** ChiPFormer:通过离线决策变换器进行可转让芯片配置

**作者:** Yao Lai, Jinxin Liu, Zhentao Tang, Bin Wang, Jianye Hao, Ping Luo

**Abstract:** Placement is a critical step in modern chip design, aiming to determine the positions of circuit modules on the chip canvas. Recent works have shown that reinforcement learning (RL) can improve human performance in chip placement. However, such an RL-based approach suffers from long training time and low transfer ability in unseen chip circuits. To resolve these challenges, we cast the chip placement as an offline RL formulation and present ChiPFormer that enables learning a transferable placement policy from fixed offline data. ChiPFormer has several advantages that prior arts do not have. First, ChiPFormer can exploit offline placement designs to learn transferable policies more efficiently in a multi-task setting. Second, ChiPFormer can promote effective finetuning for unseen chip circuits, reducing the placement runtime from hours to minutes. Third, extensive experiments on 32 chip circuits demonstrate that ChiPFormer achieves significantly better placement quality while reducing the runtime by 10x compared to recent state-of-the-art approaches in both public benchmarks and realistic industrial tasks. The deliverables are released at https://sites.google.com/view/chipformer/home.

**摘要:** 配置是现代芯片设计中的一个关键步骤,旨在确定芯片壁画上的电路模块的位置。最近的工作表明,增强学习(RL)可以提高芯片配置中的人类性能。然而,这种基于RL的方法在未见的芯片电路中受长期训练时间和低传输能力的影响。为了解决这些挑战,我们铸造了芯片配置为非线性RL公式,并展示了 ChiPFormer,它能够从固定的非线性数据中学习可转让配置政策。第三,在32个芯片电路上进行了广泛的实验,证明ChiPFormer在公共基准和现实的工业任务中,与最近的最先进的方法相比,在降低运行时间10倍的同时,实现了显著更好的配置质量。

**[Paper URL](https://proceedings.mlr.press/v202/lai23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lai23c/lai23c.pdf)** 

# FP-Diffusion: Improving Score-based Diffusion Models by Enforcing the Underlying Score Fokker-Planck Equation
**题目:** FP扩散:通过执行基础分数福克-普兰克方程改进基于分数扩散模型

**作者:** Chieh-Hsin Lai, Yuhta Takida, Naoki Murata, Toshimitsu Uesaka, Yuki Mitsufuji, Stefano Ermon

**Abstract:** Score-based generative models (SGMs) learn a family of noise-conditional score functions corresponding to the data density perturbed with increasingly large amounts of noise. These perturbed data densities are linked together by the Fokker-Planck equation (FPE), a partial differential equation (PDE) governing the spatial-temporal evolution of a density undergoing a diffusion process. In this work, we derive a corresponding equation called the score FPE that characterizes the noise-conditional scores of the perturbed data densities (i.e., their gradients). Surprisingly, despite the impressive empirical performance, we observe that scores learned through denoising score matching (DSM) fail to fulfill the underlying score FPE, which is an inherent self-consistency property of the ground truth score. We prove that satisfying the score FPE is desirable as it improves the likelihood and the degree of conservativity. Hence, we propose to regularize the DSM objective to enforce satisfaction of the score FPE, and we show the effectiveness of this approach across various datasets.

**摘要:** 基于分数的生成模型(SGMs)学习了噪声条件分数函数的家族,这些噪声条件分数与数据密度相符,这些噪声条件分数与 Fokker-Planck方程(FPE)相连,一个部分差分方程(PDE)控制了进行扩散过程的密度空间-时空演化。在这个研究中,我们导出了一种称为分数FPE的相符方程,它描述了噪声条件分数的扰动数据密度(即它们的梯度)。因此,我们建议对DSM目标进行规范化,以实现分数FPE的满意度,并表明该方法在不同数据集中具有有效性。

**[Paper URL](https://proceedings.mlr.press/v202/lai23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lai23d/lai23d.pdf)** 

# Private Statistical Estimation of Many Quantiles
**题目:** 多量子私人统计估计

**作者:** Clément Lalanne, Aurélien Garivier, Rémi Gribonval

**Abstract:** This work studies the estimation of many statistical quantiles under differential privacy. More precisely, given a distribution and access to i.i.d. samples from it, we study the estimation of the inverse of its cumulative distribution function (the quantile function) at specific points. For instance, this task is of key importance in private data generation. We present two different approaches. The first one consists in privately estimating the empirical quantiles of the samples and using this result as an estimator of the quantiles of the distribution. In particular, we study the statistical properties of the recently published algorithm introduced by (Kaplan et al., 2022) that privately estimates the quantiles recursively. The second approach is to use techniques of density estimation in order to uniformly estimate the quantile function on an interval. In particular, we show that there is a tradeoff between the two methods. When we want to estimate many quantiles, it is better to estimate the density rather than estimating the quantile function at specific points.

**摘要:** 本文研究了在微分私隐下对许多统计量子进行估算。更确切地说,考虑到其分布和从中获取的i.i.d.样品,我们在特定点研究了其累积分布函数(量子函数)反演的估算。例如,这项任务在私人数据生成中具有关键意义。我们提出了两个不同的方法。第一方法是私下估算样品的实证量子,并使用这个结果作为分配量子估算器。当我们想估计许多量子时,最好估计密度而不是在特定点估计量子函数。

**[Paper URL](https://proceedings.mlr.press/v202/lalanne23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lalanne23a/lalanne23a.pdf)** 

# Bootstrap in High Dimension with Low Computation
**题目:** 低计算量高维的脚踏陷阱

**作者:** Henry Lam, Zhenyuan Liu

**Abstract:** The bootstrap is a popular data-driven method to quantify statistical uncertainty, but for modern high-dimensional problems, it could suffer from huge computational costs due to the need to repeatedly generate resamples and refit models. We study the use of bootstraps in high-dimensional environments with a small number of resamples. In particular, we show that with a recent "cheap" bootstrap perspective, using a number of resamples as small as one could attain valid coverage even when the dimension grows closely with the sample size, thus strongly supporting the implementability of the bootstrap for large-scale problems. We validate our theoretical results and compare the performance of our approach with other benchmarks via a range of experiments.

**摘要:**  bootstrap是一种用于量化统计不确定性的流行数据驱动方法,但对于现代高维问题来说,由于需要反复生成再建模和修改模型,它可能承受巨大的计算成本。我们研究了在高维环境中使用少量再建模的方法。

**[Paper URL](https://proceedings.mlr.press/v202/lam23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lam23a/lam23a.pdf)** 

# LegendreTron: Uprising Proper Multiclass Loss Learning
**题目:** LegendreTron:反叛正确多类学习失败

**作者:** Kevin H Lam, Christian Walder, Spiridon Penev, Richard Nock

**Abstract:** Loss functions serve as the foundation of supervised learning and are often chosen prior to model development. To avoid potentially ad hoc choices of losses, statistical decision theory describes a desirable property for losses known as properness, which asserts that Bayes’ rule is optimal. Recent works have sought to learn losses and models jointly. Existing methods do this by fitting an inverse canonical link function which monotonically maps $\mathbb{R}$ to $[0,1]$ to estimate probabilities for binary problems. In this paper, we extend monotonicity to maps between $\mathbb{R}^{C-1}$ and the projected probability simplex $\tilde{\Delta}^{C-1}$ by using monotonicity of gradients of convex functions. We present LegendreTron as a novel and practical method that jointly learns proper canonical losses and probabilities for multiclass problems. Tested on a benchmark of domains with up to 1,000 classes, our experimental results show that our method consistently outperforms the natural multiclass baseline under a $t$-test at 99% significance on all datasets with greater than $10$ classes.

**摘要:** 损失函数作为监督学习的基础,并经常在模型开发之前选择。为了避免潜在的随机选择损失,统计决策理论描述了损失的理想属性,称为适当性,它证明贝斯规则是最佳的。最近的工作试图共同学习损失和模型。现有的方法通过调整一个反式 канон链函数,以单调地映射$\mathbb{R}$到$[0,1]$来估计二进制问题的概率。在本文中,我们通过使用凸函数梯度的单调性来将单调性扩展到$\mathbb{R}^{C-1}$和预测的概率 Simplex $\tilde{\Delta}^{C-1}$之间。在最大1000类域的基准测试中,我们的实验结果表明,我们的方法在所有超过10$类的数据集中,在$t$测试下,在99%重要度上始终超过了自然的多类基准。

**[Paper URL](https://proceedings.mlr.press/v202/lam23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lam23b/lam23b.pdf)** 

# Metagenomic Binning using Connectivity-constrained Variational Autoencoders
**题目:** 使用连接限制变量自动编码器的元基因组编码

**作者:** Andre Lamurias, Alessandro Tibo, Katja Hose, Mads Albertsen, Thomas Dyhre Nielsen

**Abstract:** Current state-of-the-art techniques for metagenomic binning only utilize local features for the individual DNA sequences (contigs), neglecting additional information such as the assembly graph, in which the contigs are connected according to overlapping reads, and gene markers identified in the contigs. In this paper, we propose the use of a Variational AutoEncoder (VAE) tailored to leverage auxiliary structural information about contig relations when learning contig representations for subsequent metagenomic binning. Our method, CCVAE, improves on previous work that used VAEs for learning latent representations of the individual contigs, by constraining these representations according to the connectivity information from the assembly graph. Additionally, we incorporate into the model additional information in the form of marker genes to better differentiate contigs from different genomes. Our experiments on both simulated and real-world datasets demonstrate that CCVAE outperforms current state-of-the-art techniques, thus providing a more effective method for metagenomic binning.

**摘要:** 本文提出了一种基于重叠读数和在卷轴中识别的基因标记的变量自动编码器(VAE),用于利用卷轴关系的辅助结构信息学习卷轴的卷轴表示,从而更好地区分卷轴与不同基因组的卷轴。我们对模拟和实物数据集的实验表明,CCVAE比目前的最先进的技术高,从而提供了一个更有效的元基因组分序方法。

**[Paper URL](https://proceedings.mlr.press/v202/lamurias23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lamurias23a/lamurias23a.pdf)** 

# Delay-Adapted Policy Optimization and Improved Regret for Adversarial MDP with Delayed Bandit Feedback
**题目:** 延迟适配政策优化与延迟盗版反馈对敌方MDP的改善遗憾

**作者:** Tal Lancewicki, Aviv Rosenberg, Dmitry Sotnikov

**Abstract:** Policy Optimization (PO) is one of the most popular methods in Reinforcement Learning (RL). Thus, theoretical guarantees for PO algorithms have become especially important to the RL community. In this paper, we study PO in adversarial MDPs with a challenge that arises in almost every real-world application – delayed bandit feedback. We give the first near-optimal regret bounds for PO in tabular MDPs, and may even surpass state-of-the-art (which uses less efficient methods). Our novel Delay-Adapted PO (DAPO) is easy to implement and to generalize, allowing us to extend our algorithm to: (i) infinite state space under the assumption of linear $Q$-function, proving the first regret bounds for delayed feedback with function approximation. (ii) deep RL, demonstrating its effectiveness in experiments on MuJoCo domains.

**摘要:** 策略优化(PO)是增强学习(RL)中最流行的方法之一。因此,PO算法的理论保证对于RL社区尤为重要。本论文研究了几乎在每一个实际应用中出现的挑战——延迟带式反馈——的敌对MDP中PO。我们给出了在表型MDP中PO的第一个接近最佳的遗憾界限,甚至可以超越最先进的(使用效率较低的)方法。我们的新Delay-AdaptedPO(DAPO)是易于实现和推广的,允许我们扩展我们的算法到: (i)线性$Q$-函数假设下的无限状态空间,证明了函数近似的延迟反馈的第一个遗憾界限。 (ii)深层RL,证明了它在MuJoCo域的实验中的效果。

**[Paper URL](https://proceedings.mlr.press/v202/lancewicki23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lancewicki23a/lancewicki23a.pdf)** 

# Lottery Tickets in Evolutionary Optimization: On Sparse Backpropagation-Free Trainability
**题目:** 进化优化中的抽奖券:基于备用备用备用备用训练能力

**作者:** Robert Tjarko Lange, Henning Sprekeler

**Abstract:** Is the lottery ticket phenomenon an idiosyncrasy of gradient-based training or does it generalize to evolutionary optimization? In this paper we establish the existence of highly sparse trainable initializations for evolution strategies (ES) and characterize qualitative differences compared to gradient descent (GD)-based sparse training. We introduce a novel signal-to-noise iterative pruning procedure, which incorporates loss curvature information into the network pruning step. This can enable the discovery of even sparser trainable network initializations when using black-box evolution as compared to GD-based optimization. Furthermore, we find that these initializations encode an inductive bias, which transfers across different ES, related tasks and even to GD-based training. Finally, we compare the local optima resulting from the different optimization paradigms and sparsity levels. In contrast to GD, ES explore diverse and flat local optima and do not preserve linear mode connectivity across sparsity levels and independent runs. The results highlight qualitative differences between evolution and gradient-based learning dynamics, which can be uncovered by the study of iterative pruning procedures.

**摘要:** 测验票现象是梯度基础训练的特异性,还是归纳为进化优化?本文建立了进化策略(ES)的高度稀疏训练性初始化的存在,并对梯度下降(GD)基础稀疏训练的质量差异进行了描述,介绍了一种新的信号到噪声迭代剪切程序,该程序将损失曲率信息纳入网络剪切步骤中,可使在使用黑箱进化时发现更稀疏的训练性网络初始化。此外,我们发现这些初始化编码了一个诱导性偏见,这种偏见通过不同的ES、相关任务甚至到GD基础训练。与GD相比,ES研究了多种平坦的局部优化,并不保留在稀疏水平和独立运行的线性模式连接。结果突出了进化与梯度基础学习动力学之间的质量差异,可以通过对迭代剪切过程的研究揭示。

**[Paper URL](https://proceedings.mlr.press/v202/lange23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lange23a/lange23a.pdf)** 

# On the Occupancy Measure of Non-Markovian Policies in Continuous MDPs
**题目:** 关于非马科维亚政策在持续的MDP中就业量

**作者:** Romain Laroche, Remi Tachet Des Combes

**Abstract:** The state-action occupancy measure of a policy is the expected (discounted or undiscounted) number of times a state-action couple is visited in a trajectory. For decades, RL books have been reporting the occupancy equivalence between Markovian and non-Markovian policies in countable state-action spaces under mild conditions. This equivalence states that the occupancy of any non-Markovian policy can be equivalently obtained by a Markovian policy, i.e. a memoryless probability distribution, conditioned only on its current state. While expected, for technical reasons, the translation of this result to continuous state space has resisted until now. Our main contribution is to fill this gap and to provide a general measure-theoretic treatment of the problem, permitting, in particular, its extension to continuous MDPs. Furthermore, we show that when the occupancy is infinite, we may encounter some non-trivial cases where the result does not hold anymore.

**摘要:** 一个政策的州-行动占用量是州-行动夫妇在轨迹中访问的预期(不计数或不计数)次数。几十年来,RL书籍在温和条件下在可计数的州-行动空间中报告了马科维亚和非马科维亚政策之间的占用等价性。这一等价性表示,任何非马科维亚政策的占用都可以通过马科维亚政策获得等价性,即无记忆概率分布,仅取决于其当前状态。虽然预期,由于技术原因,对连续州空间的这种结果的翻译一直存在阻力。我们的主要贡献是填补这一缺口,并提供对问题的一般计量理论处理,特别是允许其扩展到连续的MDP。此外,我们证明,当占用量无限时,我们可能遇到一些非平凡的案例,结果不再有效。

**[Paper URL](https://proceedings.mlr.press/v202/laroche23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/laroche23a/laroche23a.pdf)** 

# Minimalistic Predictions to Schedule Jobs with Online Precedence Constraints
**题目:** 基于在线先例约束的计划工作最小预测

**作者:** Alexandra Anna Lassota, Alexander Lindermayr, Nicole Megow, Jens Schlöter

**Abstract:** We consider non-clairvoyant scheduling with online precedence constraints, where an algorithm is oblivious to any job dependencies and learns about a job only if all of its predecessors have been completed. Given strong impossibility results in classical competitive analysis, we investigate the problem in a learning-augmented setting, where an algorithm has access to predictions without any quality guarantee. We discuss different prediction models: novel problem-specific models as well as general ones, which have been proposed in previous works. We present lower bounds and algorithmic upper bounds for different precedence topologies, and thereby give a structured overview on which and how additional (possibly erroneous) information helps for designing better algorithms. Along the way, we also improve bounds on traditional competitive ratios for existing algorithms.

**摘要:** 我们考虑使用在线优先约束的非线性调度,因为该算法对任何工作依赖性无知,只在所有它的先驱完成后才能了解工作。 鉴于经典竞争分析中的强烈不可能结果,我们在学习增强环境中研究问题,该算法在没有质量保证的情况下可以获得预测。 我们讨论不同的预测模型:新问题特有模型以及在以前的工作中提出的一般模型。 我们给出了不同优先拓扑的较低边界和算法上边界,从而为设计更好的算法提供了一个有结构的概览,说明哪些(可能错误的)额外信息如何帮助。

**[Paper URL](https://proceedings.mlr.press/v202/lassota23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lassota23a/lassota23a.pdf)** 

# Speeding Up Bellman Ford via Minimum Violation Permutations
**题目:** 通过最小违反变换加速贝尔曼福特

**作者:** Silvio Lattanzi, Ola Svensson, Sergei Vassilvitskii

**Abstract:** The Bellman-Ford algorithm is a basic primitive for computing single source shortest paths in graphs with negative weight edges. Its running time is governed by the order the algorithm examines vertices for iterative updates on the value of their shortest path. In this work we study this problem through the lens of ’Algorithms with predictions,’ and show how to leverage auxiliary information from similar instances to improve the running time. We do this by identifying the key problem of Minimum Violation Permutations, and give algorithms with strong approximation guarantees as well as formal lower bounds. We complement the theoretical analysis with an empirical evaluation, showing that this approach can lead to a significant speed up in practice.

**摘要:** 贝尔曼-福德算法是计算负重边形图中单源最短路径的基本原始算法,其运行时间由算法对最短路径的值进行迭代更新的顶点进行检验的顺序决定。本文通过“预测算法”的视角研究了这一问题,并展示了如何利用类似实例的辅助信息来改善运行时间。我们通过识别最小违背变换的关键问题,并给出了具有强近似保证和正式较低边界的算法。

**[Paper URL](https://proceedings.mlr.press/v202/lattanzi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lattanzi23a/lattanzi23a.pdf)** 

# Who Needs to Know? Minimal Knowledge for Optimal Coordination
**题目:** 谁需要知道?最佳协调的最小知识

**作者:** Niklas Lauffer, Ameesh Shah, Micah Carroll, Michael D Dennis, Stuart Russell

**Abstract:** To optimally coordinate with others in cooperative games, it is often crucial to have information about one’s collaborators: successful driving requires understanding which side of the road to drive on. However, not every feature of collaborators is strategically relevant: the fine-grained acceleration of drivers may be ignored while maintaining optimal coordination. We show that there is a well-defined dichotomy between strategically relevant and irrelevant information. Moreover, we show that, in dynamic games, this dichotomy has a compact representation that can be efficiently computed via a Bellman backup operator. We apply this algorithm to analyze the strategically relevant information for tasks in both a standard and a partially observable version of the Overcooked environment. Theoretical and empirical results show that our algorithms are significantly more efficient than baselines. Videos are available at https://minknowledge.github.io.

**摘要:** 为了在合作游戏中与他人进行最佳协调,经常必须有关于自己的合作者的信息:成功驾驶需要了解驾驶道路的哪一边。然而,合作者并非每个特征都具有战略意义:在保持最佳协调时,司机的细微加速度可能被忽略。我们显示,在战略意义和无关信息之间存在一个明确的二元关系。此外,我们显示,动态游戏中,这一二元关系具有一个简便的表示,可以通过贝尔曼备份操作器有效地计算。我们应用该算法来分析在标准和部分可观察的Overcooked环境中任务中的战略意义的信息。理论和经验结果表明,我们的算法比基线更有效。

**[Paper URL](https://proceedings.mlr.press/v202/lauffer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lauffer23a/lauffer23a.pdf)** 

# Target-based Surrogates for Stochastic Optimization
**题目:** 基于目标的随机优化替代品

**作者:** Jonathan Wilder Lavington, Sharan Vaswani, Reza Babanezhad Harikandeh, Mark Schmidt, Nicolas Le Roux

**Abstract:** We consider minimizing functions for which it is expensive to compute the (possibly stochastic) gradient. Such functions are prevalent in reinforcement learning, imitation learning and adversarial training. Our target optimization framework uses the (expensive) gradient computation to construct surrogate functions in a target space (e.g. the logits output by a linear model for classification) that can be minimized efficiently. This allows for multiple parameter updates to the model, amortizing the cost of gradient computation. In the full-batch setting, we prove that our surrogate is a global upper-bound on the loss, and can be (locally) minimized using a black-box optimization algorithm. We prove that the resulting majorization-minimization algorithm ensures convergence to a stationary point of the loss. Next, we instantiate our framework in the stochastic setting and propose the $SSO$ algorithm, which can be viewed as projected stochastic gradient descent in the target space. This connection enables us to prove theoretical guarantees for $SSO$ when minimizing convex functions. Our framework allows the use of standard stochastic optimization algorithms to construct surrogates which can be minimized by any deterministic optimization method. To evaluate our framework, we consider a suite of supervised learning and imitation learning problems. Our experiments indicate the benefits of target optimization and the effectiveness of $SSO$.

**摘要:** 我们考虑最小化函数,因为计算(可能随机)梯度是昂贵的。这些函数在增强学习、模仿学习和敌对训练中占主导地位。我们的目标优化框架使用(昂贵)梯度计算来构造在目标空间中替代函数(例如由线性分类模型输出的 logits),可以有效地最小化。这允许对模型进行多个参数更新, amortizing the cost of gradient computation。这个连接使我们能够在最小化凸函数时证明$SSO$的理论保证。我们的框架允许使用标准随机优化算法来构造替代品,以任何确定性优化方法来最小化。为了评价我们的框架,我们考虑了一系列的监督学习和模仿学习问题。我们的实验表明目标优化的好处和$SSO$的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/lavington23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lavington23a/lavington23a.pdf)** 

# Cluster Explanation via Polyhedral Descriptions
**题目:** 通过多面体描述的聚类解释

**作者:** Connor Lawless, Oktay Gunluk

**Abstract:** This paper focuses on the cluster description problem where, given a dataset and its partition into clusters, the task is to explain the clusters. We introduce a new approach to explain clusters by constructing a polyhedron around each cluster while minimizing either the complexity of the resulting polyhedra or the number of features used in the description. We formulate the cluster description problem as an integer program and present a column generation approach to search over an exponential number of candidate half-spaces that can be used to build the polyhedra. To deal with large datasets, we introduce a novel grouping scheme that first forms smaller groups of data points and then builds the polyhedra around the grouped data, a strategy which out-performs the common approach of sub-sampling data. Compared to state of the art cluster description algorithms, our approach is able to achieve competitive interpretability with improved description accuracy.

**摘要:** 本文着重讨论了数据集的描述问题,其任务是解释数据集。我们引入一种新的方法来解释数据集,通过在每个数据集周围构造一个多面体,同时尽量减少结果多面体的复杂性或描述中使用的特征数。我们将数据集描述问题定义为整数程序,并提出一种列生成方法,以搜索可用于构建多面体的候选半空间的指数数。为了处理大数据集,我们引入了一种新颖的聚类方案,首先形成较小的数据点群,然后在聚类数据周围构造多面体,这种策略超越了分样数据的一般方法。

**[Paper URL](https://proceedings.mlr.press/v202/lawless23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lawless23a/lawless23a.pdf)** 

# Pre-training for Speech Translation: CTC Meets Optimal Transport
**题目:** 英语口语翻译预习班:CTC迎合最佳运输

**作者:** Phuong-Hang Le, Hongyu Gong, Changhan Wang, Juan Pino, Benjamin Lecouteux, Didier Schwab

**Abstract:** The gap between speech and text modalities is a major challenge in speech-to-text translation (ST). Different methods have been proposed to reduce this gap, but most of them require architectural changes in ST training. In this work, we propose to mitigate this issue at the pre-training stage, requiring no change in the ST model. First, we show that the connectionist temporal classification (CTC) loss can reduce the modality gap by design. We provide a quantitative comparison with the more common cross-entropy loss, showing that pre-training with CTC consistently achieves better final ST accuracy. Nevertheless, CTC is only a partial solution and thus, in our second contribution, we propose a novel pre-training method combining CTC and optimal transport to further reduce this gap. Our method pre-trains a Siamese-like model composed of two encoders, one for acoustic inputs and the other for textual inputs, such that they produce representations that are close to each other in the Wasserstein space. Extensive experiments on the standard CoVoST-2 and MuST-C datasets show that our pre-training method applied to the vanilla encoder-decoder Transformer achieves state-of-the-art performance under the no-external-data setting, and performs on par with recent strong multi-task learning systems trained with external data. Finally, our method can also be applied on top of these multi-task systems, leading to further improvements for these models.

**摘要:** 语文翻译中,语文模式间的差距是语文翻译中的一个重大挑战。为了减少这种差距,提出了不同的方法,但大多数方法都要求在语文训练中进行结构性变化。在这项工作中,我们建议在预训练阶段缓解这一问题,不需要改变语文模式。首先,我们表明,连接主义时态分类(CTC)损失可以通过设计减少模式间的差距。我们提供了与更常见的跨跨热带损失的定量比较,表明预训练与CTC一致取得更好的最终语文精度。尽管如此,CTC只是一个部分解决方案,因此,在我们的第二个贡献中,我们提出了一种结合CTC和最佳运输的方法来进一步减少这种差距。我们的方法预训练一个由两个编码器组成的西亚米式模型,其中一个用于声学输入,另一个用于文本输入,使得它们在沃塞斯坦空间中产生相互接近的表示。对标准CoVoST-2和MuST-C数据集的广泛实验表明,我们的预训练方法适用于瓦尼拉编码器-编码器变换器,在没有外部数据设置下达到最先进的性能,并与最近由外部数据训练的强多任务学习系统相匹配。

**[Paper URL](https://proceedings.mlr.press/v202/le23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/le23a/le23a.pdf)** 

# Bootstrapped Representations in Reinforcement Learning
**题目:** 加强学习的 Bootstrapped代表

**作者:** Charline Le Lan, Stephen Tu, Mark Rowland, Anna Harutyunyan, Rishabh Agarwal, Marc G Bellemare, Will Dabney

**Abstract:** In reinforcement learning (RL), state representations are key to dealing with large or continuous state spaces. While one of the promises of deep learning algorithms is to automatically construct features well-tuned for the task they try to solve, such a representation might not emerge from end-to-end training of deep RL agents. To mitigate this issue, auxiliary objectives are often incorporated into the learning process and help shape the learnt state representation. Bootstrapping methods are today’s method of choice to make these additional predictions. Yet, it is unclear which features these algorithms capture and how they relate to those from other auxiliary-task-based approaches. In this paper, we address this gap and provide a theoretical characterization of the state representation learnt by temporal difference learning (Sutton, 1988). Surprisingly, we find that this representation differs from the features learned by Monte Carlo and residual gradient algorithms for most transition structures of the environment in the policy evaluation setting. We describe the efficacy of these representations for policy evaluation, and use our theoretical analysis to design new auxiliary learning rules. We complement our theoretical results with an empirical comparison of these learning rules for different cumulant functions on classic domains such as the four-room domain (Sutton et al, 1999) and Mountain Car (Moore, 1990).

**摘要:** 在强化学习(RL)中,状态表示是处理大型或连续状态空间的关键。虽然深度学习算法的承诺之一是自动构造适合他们解决任务的特征,但这种表示可能不会从深层RL代理的最终训练中产生。为了缓解这一问题,辅助目标经常被纳入学习过程,帮助塑造学习状态表示。令人惊讶的是,我们发现该模型不同于蒙特卡罗和在政策评价环境中大多数过渡结构的剩余梯度算法所学到的特征。我们描述了这些模型对政策评价的有效性,并利用我们的理论分析设计了新的辅助学习规则。我们补充了这些理论结果,用这些学习规则的实证比较来对经典领域中不同累积函数,例如四室领域(Sutton et al, 1999)和山车(Moore, 1990)。

**[Paper URL](https://proceedings.mlr.press/v202/le-lan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/le-lan23a/le-lan23a.pdf)** 

# Strategic Classification with Unknown User Manipulations
**题目:** 未知用户操作的策略分类

**作者:** Tosca Lechner, Ruth Urner, Shai Ben-David

**Abstract:** In many human-centric applications for Machine Learning instances will adapt to a classifier after its deployment. The field of strategic classification deals with this issue by aiming for a classifier that balances the trade-off between correctness and robustness to manipulation. This task is made harder if the underlying manipulation structure (i.e. the set of manipulations available at every instance) is unknown to the learner. We propose a novel batch-learning setting in which we use unlabeled data from previous rounds to estimate the manipulation structure. We show that in this batch-learning setting it is possible to learn a close-to-optimal classifier in terms of the strategic loss even without knowing the feasible manipulations beforehand. In line with recent advances in the strategic classification literature, we do not assume a best-response from agents but only require that observed manipulations are feasible.

**摘要:** 在许多机器学习的人类中心应用中,实例将在部署后适应分类器。战略分类领域通过针对一个分类器来处理这一问题,以平衡对操作的正确性和鲁棒性之间的交易。如果潜在的操作结构(即在每个实例中可用的操作的集合)对学习者不了解,则这项任务变得更加困难。我们提出了一种新颖的批量学习设置,在该设置中我们使用从以前的轮流中未标记的数据来估算操作结构。

**[Paper URL](https://proceedings.mlr.press/v202/lechner23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lechner23a/lechner23a.pdf)** 

# Learning in POMDPs is Sample-Efficient with Hindsight Observability
**题目:** POMDP中学习具有后视可视的实例效率

**作者:** Jonathan Lee, Alekh Agarwal, Christoph Dann, Tong Zhang

**Abstract:** POMDPs capture a broad class of decision making problems, but hardness results suggest that learning is intractable even in simple settings due to the inherent partial observability. However, in many realistic problems, more information is either revealed or can be computed during some point of the learning process. Motivated by diverse applications ranging from robotics to data center scheduling, we formulate a Hindsight Observable Markov Decision Process (HOMDP) as a POMDP where the latent states are revealed to the learner in hindsight and only during training. We introduce new algorithms for the tabular and function approximation settings that are provably sample-efficient with hindsight observability, even in POMDPs that would otherwise be statistically intractable. We give a lower bound showing that the tabular algorithm is optimal in its dependence on latent state and observation cardinalities.

**摘要:** POMDP包含了一个广泛的决策问题类别,但硬度结果表明学习即使在简单的设置中也是无法解决的,因为内在的局部可观察性。然而,在许多现实问题中,更多的信息要么被显示出来,要么可以在学习过程的某个点中计算出来。我们根据从机器人到数据中心调度的各种应用,制订了一个隐形可观察的马可夫决策过程(HOMDP)作为POMDP,其中隐形状态只在后视和训练中被显示出来。

**[Paper URL](https://proceedings.mlr.press/v202/lee23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23a/lee23a.pdf)** 

# Towards Deep Attention in Graph Neural Networks: Problems and Remedies
**题目:** 图神经网络的深入关注:问题与解决方法

**作者:** Soo Yong Lee, Fanchen Bu, Jaemin Yoo, Kijung Shin

**Abstract:** Graph neural networks (GNNs) learn the representation of graph-structured data, and their expressiveness can be further enhanced by inferring node relations for propagation. Attention-based GNNs infer neighbor importance to manipulate the weight of its propagation. Despite their popularity, the discussion on deep graph attention and its unique challenges has been limited. In this work, we investigate some problematic phenomena related to deep graph attention, including vulnerability to over-smoothed features and smooth cumulative attention. Through theoretical and empirical analyses, we show that various attention-based GNNs suffer from these problems. Motivated by our findings, we propose AERO-GNN, a novel GNN architecture designed for deep graph attention. AERO-GNN provably mitigates the proposed problems of deep graph attention, which is further empirically demonstrated with (a) its adaptive and less smooth attention functions and (b) higher performance at deep layers (up to 64). On 9 out of 12 node classification benchmarks, AERO-GNN outperforms the baseline GNNs, highlighting the advantages of deep graph attention. Our code is available at https://github.com/syleeheal/AERO-GNN.

**摘要:** 图形神经网络(GNN)学习图形结构数据的表示,并通过推导传播的节点关系进一步提高它们的表达性。基于注意力的GNN推导邻近的重要性来操纵其传播的重量。尽管它们很受欢迎,关于深度图形注意力及其独特的挑战的讨论已经有限。在这个工作中,我们研究了与深度图形注意力有关的一些问题现象,包括对过度卷曲特征和光滑累积注意力的脆弱性。通过理论和实证分析,我们表明基于注意力的GNN遭受这些问题。在12个节点分类基准中,AERO-GNN超过了基准GNN,突出了深度图关注的优势。我们的代码在 https://github.com/syleeheal/AERO-GNN。

**[Paper URL](https://proceedings.mlr.press/v202/lee23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23b/lee23b.pdf)** 

# InGram: Inductive Knowledge Graph Embedding via Relation Graphs
**题目:** InGram:基于关系图的诱导知识图嵌入

**作者:** Jaejun Lee, Chanyoung Chung, Joyce Jiyoung Whang

**Abstract:** Inductive knowledge graph completion has been considered as the task of predicting missing triplets between new entities that are not observed during training. While most inductive knowledge graph completion methods assume that all entities can be new, they do not allow new relations to appear at inference time. This restriction prohibits the existing methods from appropriately handling real-world knowledge graphs where new entities accompany new relations. In this paper, we propose an INductive knowledge GRAph eMbedding method, InGram, that can generate embeddings of new relations as well as new entities at inference time. Given a knowledge graph, we define a relation graph as a weighted graph consisting of relations and the affinity weights between them. Based on the relation graph and the original knowledge graph, InGram learns how to aggregate neighboring embeddings to generate relation and entity embeddings using an attention mechanism. Experimental results show that InGram outperforms 14 different state-of-the-art methods on varied inductive learning scenarios.

**摘要:** 诱导知识图的完成被认为是在训练过程中没有观察到的新实体之间缺少三重元的预测任务。虽然大多数诱导知识图的完成方法假设所有实体都可以是新的,但它们不允许新的关系在推理时出现。这一限制禁止现有的方法适当处理真实世界知识图,其中新的实体伴随新的关系。本论文提出了一种诱导知识图eMbedding方法,即InGram,它可以在推理时生成新关系的嵌入以及新的实体的嵌入。实验结果表明,InGram在不同的诱导学习场景中,超过了14种最先进的方法。

**[Paper URL](https://proceedings.mlr.press/v202/lee23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23c/lee23c.pdf)** 

# Optimality of Thompson Sampling with Noninformative Priors for Pareto Bandits
**题目:** 汤普森样本与非信息性前者对帕雷托强盗的优化

**作者:** Jongyeong Lee, Junya Honda, Chao-Kai Chiang, Masashi Sugiyama

**Abstract:** In the stochastic multi-armed bandit problem, a randomized probability matching policy called Thompson sampling (TS) has shown excellent performance in various reward models. In addition to the empirical performance, TS has been shown to achieve asymptotic problem-dependent lower bounds in several models. However, its optimality has been mainly addressed under light-tailed or one-parameter models that belong to exponential families. In this paper, we consider the optimality of TS for the Pareto model that has a heavy tail and is parameterized by two unknown parameters. Specifically, we discuss the optimality of TS with probability matching priors that include the Jeffreys prior and the reference priors. We first prove that TS with certain probability matching priors can achieve the optimal regret bound. Then, we show the suboptimality of TS with other priors, including the Jeffreys and the reference priors. Nevertheless, we find that TS with the Jeffreys and reference priors can achieve the asymptotic lower bound if one uses a truncation procedure. These results suggest carefully choosing noninformative priors to avoid suboptimality and show the effectiveness of truncation procedures in TS-based policies.

**摘要:** 在随机多武器 bandit 问题中,一个叫做汤普森抽样(TS)的随机概率匹配策略在各种奖励模型中表现出了良好的性能。除了经验性性能外,TS在多个模型中已经证明能够实现渐近性问题依赖的较低边界。然而,它的优越性主要是针对属于指数家族的光尾或单参数模型。本文考虑了具有重尾和由两个未知参数参数参数化的帕雷托模型的优越性。具体地,我们讨论了包括杰弗里斯前和参考前在内的概率匹配前模型的优越性。尽管如此,我们发现,使用切换过程的TS与 Jeffreys和参考前序可以达到无症状的较低界限。这些结果表明,选择非信息性前序是避免低效率的,并表明在TS-based政策中切换过程的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/lee23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23d/lee23d.pdf)** 

# Conditional Graph Information Bottleneck for Molecular Relational Learning
**题目:** 分子关系学习的条件图信息螺旋

**作者:** Namkyeong Lee, Dongmin Hyun, Gyoung S. Na, Sungwon Kim, Junseok Lee, Chanyoung Park

**Abstract:** Molecular relational learning, whose goal is to learn the interaction behavior between molecular pairs, got a surge of interest in molecular sciences due to its wide range of applications. Recently, graph neural networks have recently shown great success in molecular relational learning by modeling a molecule as a graph structure, and considering atom-level interactions between two molecules. Despite their success, existing molecular relational learning methods tend to overlook the nature of chemistry, i.e., a chemical compound is composed of multiple substructures such as functional groups that cause distinctive chemical reactions. In this work, we propose a novel relational learning framework, called CGIB, that predicts the interaction behavior between a pair of graphs by detecting core subgraphs therein. The main idea is, given a pair of graphs, to find a subgraph from a graph that contains the minimal sufficient information regarding the task at hand conditioned on the paired graph based on the principle of conditional graph information bottleneck. We argue that our proposed method mimics the nature of chemical reactions, i.e., the core substructure of a molecule varies depending on which other molecule it interacts with. Extensive experiments on various tasks with real-world datasets demonstrate the superiority of CGIB over state-of-the-art baselines. Our code is available at https://github.com/Namkyeong/CGIB.

**摘要:** 分子关系学习的目标是学习分子对之间的相互作用行为,由于其广泛的应用,分子科学引起了广泛的兴趣。最近,图神经网络通过将分子建模为图结构,并考虑两个分子之间的原子级相互作用,在分子关系学习中取得了巨大的成功。尽管它们取得了成功,现有的分子关系学习方法往往忽略了化学的性质,即化学化合物是由多种结构组成的,如功能组引起不同的化学反应。我们认为,我们提出的方法模仿化学反应的性质,即分子的核心结构在与它相互作用的其他分子之间有所不同。在实际数据集的各个任务上进行广泛的实验显示了CGIB在最先进的基线之上的优越性。我们的代码可于 https://github.com/Namkyeong/CGIB。

**[Paper URL](https://proceedings.mlr.press/v202/lee23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23e/lee23e.pdf)** 

# Exploring Chemical Space with Score-based Out-of-distribution Generation
**题目:** 基于分数的非分布生成的化学空间探索

**作者:** Seul Lee, Jaehyeong Jo, Sung Ju Hwang

**Abstract:** A well-known limitation of existing molecular generative models is that the generated molecules highly resemble those in the training set. To generate truly novel molecules that may have even better properties for de novo drug discovery, more powerful exploration in the chemical space is necessary. To this end, we propose Molecular Out-Of-distribution Diffusion(MOOD), a score-based diffusion scheme that incorporates out-of-distribution (OOD) control in the generative stochastic differential equation (SDE) with simple control of a hyperparameter, thus requires no additional costs. Since some novel molecules may not meet the basic requirements of real-world drugs, MOOD performs conditional generation by utilizing the gradients from a property predictor that guides the reverse-time diffusion process to high-scoring regions according to target properties such as protein-ligand interactions, drug-likeness, and synthesizability. This allows MOOD to search for novel and meaningful molecules rather than generating unseen yet trivial ones. We experimentally validate that MOOD is able to explore the chemical space beyond the training distribution, generating molecules that outscore ones found with existing methods, and even the top 0.01% of the original training pool. Our code is available at https://github.com/SeulLee05/MOOD.

**摘要:** 现存分子生成模型的一个众所周知的局限性是,生成的分子非常类似于训练集合中的分子。为了产生真正的新分子,可能为新药的发现具有更好的特性,需要在化学空间进行更强的探索。为此,我们提出了分子离散扩散(MOOD),一种基于分数的扩散方案,它将与高参数的简单控制相结合的离散(OOD)控制在生成随机微分方程(SDE)中,因此不需要额外的成本。这使得MOOD能够寻找新颖而有意义的分子,而不是产生未知而微不足道的分子。我们实验验证了MOOD能够在训练分配之外探索化学空间,产生那些与现有方法发现的分子,甚至是原始训练池的最高0.01%。我们的代码在 https://github.com/SeulLee05/MOOD。

**[Paper URL](https://proceedings.mlr.press/v202/lee23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23f/lee23f.pdf)** 

# Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding
**题目:** Pix2Struct:视觉语言理解的预备训练

**作者:** Kenton Lee, Mandar Joshi, Iulia Raluca Turc, Hexiang Hu, Fangyu Liu, Julian Martin Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova

**Abstract:** Visually-situated language is ubiquitous—sources range from textbooks with diagrams to web pages with images and tables, to mobile apps with buttons and forms. Perhaps due to this diversity, previous work has typically relied on domain-specific recipes with limited sharing of the underlying data, model architectures, and objectives. We present Pix2Struct, a pretrained image-to-text model for purely visual language understanding, which can be finetuned on tasks containing visually-situated language. Pix2Struct is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks. Intuitively, this objective subsumes common pretraining signals such as OCR, language modeling, and image captioning. In addition to the novel pretraining strategy, we introduce a variable-resolution input representation and a more flexible integration of language and vision inputs, where language prompts such as questions are rendered directly on top of the input image. For the first time, we show that a single pretrained model can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images.

**摘要:** 视觉定位语言是无处不在的—从图形的课本到图像和表格的网页,到按钮和表格的移动应用程序。也许由于这种多样性,以前的工作通常依赖于域特异的配方,与基本数据、模型架构和目标的有限共享。我们介绍Pix2Struct,一种纯视觉语言理解的预处理图像到文本模型,可以在包含视觉定位语言的任务上精细调整。Pix2Struct通过学习将网页的蒙蔽屏幕解析成简化HTML来预处理。除了新颖的预训练策略之外,我们引入了可变分辨率输入表示和更灵活的语言和视觉输入集成,即语言提示,如问题,直接在输入图像上显示。我们首次证明,单一预训练模型可以在四个领域:文件、插图、用户界面和自然图像的九个任务中取得最先进的结果。

**[Paper URL](https://proceedings.mlr.press/v202/lee23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23g/lee23g.pdf)** 

# FlexRound: Learnable Rounding based on Element-wise Division for Post-Training Quantization
**题目:** FlexRound:基于元素分区的可学习圆形化,用于训练后定量化

**作者:** Jung Hyun Lee, Jeonghoon Kim, Se Jung Kwon, Dongsoo Lee

**Abstract:** Post-training quantization (PTQ) has been gaining popularity for the deployment of deep neural networks on resource-limited devices since unlike quantization-aware training, neither a full training dataset nor end-to-end training is required at all. As PTQ schemes based on reconstructing each layer or block output turn out to be effective to enhance quantized model performance, recent works have developed algorithms to devise and learn a new weight-rounding scheme so as to better reconstruct each layer or block output. In this work, we propose a simple yet effective new weight-rounding mechanism for PTQ, coined FlexRound, based on element-wise division instead of typical element-wise addition such that FlexRound enables jointly learning a common quantization grid size as well as a different scale for each pre-trained weight. Thanks to the reciprocal rule of derivatives induced by element-wise division, FlexRound is inherently able to exploit pre-trained weights when updating their corresponding scales, and thus, flexibly quantize pre-trained weights depending on their magnitudes. We empirically validate the efficacy of FlexRound on a wide range of models and tasks. To the best of our knowledge, our work is the first to carry out comprehensive experiments on not only image classification and natural language understanding but also natural language generation, assuming a per-tensor uniform PTQ setting. Moreover, we demonstrate, for the first time, that large language models can be efficiently quantized, with only a negligible impact on performance compared to half-precision baselines, achieved by reconstructing the output in a block-by-block manner.

**摘要:** 训练后定量化(PTQ)在资源有限的设备上应用深层神经网络已经越来越流行,因为与定量化意识训练不同,完全的训练数据集和终到终训练都不需要。由于基于重建每个层或块输出的PTQ方案能够提高定量化模型性能,最近的工作已经开发了算法来设计和学习新的定量化方案,以便更好地重建每个层或块输出。FlexRound通过元素分化所诱导的衍生物的相互规则,能够在更新其相应的尺度时利用预训练的重量,从而根据其大小灵活量化预训练的重量。我们以实例验证了 FlexRound在广泛的模型和任务上的效果。为了更好地了解我们的工作,我们是第一个在不仅图像分类和自然语言理解,而且自然语言生成方面进行综合实验,假设每个传感器均匀的PTQ设置。

**[Paper URL](https://proceedings.mlr.press/v202/lee23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23h/lee23h.pdf)** 

# CoDi: Co-evolving Contrastive Diffusion Models for Mixed-type Tabular Synthesis
**题目:** CoDi:混合型表格合成的共演对比扩散模型

**作者:** Chaejeong Lee, Jayoung Kim, Noseong Park

**Abstract:** With growing attention to tabular data these days, the attempt to apply a synthetic table to various tasks has been expanded toward various scenarios. Owing to the recent advances in generative modeling, fake data generated by tabular data synthesis models become sophisticated and realistic. However, there still exists a difficulty in modeling discrete variables (columns) of tabular data. In this work, we propose to process continuous and discrete variables separately (but being conditioned on each other) by two diffusion models. The two diffusion models are co-evolved during training by reading conditions from each other. In order to further bind the diffusion models, moreover, we introduce a contrastive learning method with a negative sampling method. In our experiments with 11 real-world tabular datasets and 8 baseline methods, we prove the efficacy of the proposed method, called $\texttt{CoDi}$. Our code is available at https://github.com/ChaejeongLee/CoDi.

**摘要:** 由于目前对表数据的关注日益增加,对各种任务应用合成表的尝试已经扩大到各种场景。由于生成模型的近期进展,由表数据合成模型生成的假数据变得复杂和现实。然而,在建模表数据的离散变量(列)方面仍存在困难。在这个工作中,我们建议通过两个扩散模型分别处理连续和离散变量(但相互条件),两个扩散模型在训练过程中通过相互阅读条件共同演化。为了进一步结合扩散模型,我们引入了负采样法的对比性学习方法。在我们对11个真实世界表数据集和8个基线方法的实验中,我们证明了提议的方法的有效性,叫做$\texttt{CoDi}$。我们的代码在 https://github.com/ChaejeongLee/CoDi。

**[Paper URL](https://proceedings.mlr.press/v202/lee23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23i/lee23i.pdf)** 

# Minimizing Trajectory Curvature of ODE-based Generative Models
**题目:** 减少基于ODE的生成模型的推理曲线

**作者:** Sangyun Lee, Beomsu Kim, Jong Chul Ye

**Abstract:** Recent ODE/SDE-based generative models, such as diffusion models, rectified flows, and flow matching, define a generative process as a time reversal of a fixed forward process. Even though these models show impressive performance on large-scale datasets, numerical simulation requires multiple evaluations of a neural network, leading to a slow sampling speed. We attribute the reason to the high curvature of the learned generative trajectories, as it is directly related to the truncation error of a numerical solver. Based on the relationship between the forward process and the curvature, here we present an efficient method of training the forward process to minimize the curvature of generative trajectories without any ODE/SDE simulation. Experiments show that our method achieves a lower curvature than previous models and, therefore, decreased sampling costs while maintaining competitive performance. Code is available at https://github.com/sangyun884/fast-ode.

**摘要:** 最近的ODE/SDE基于生成模型,如扩散模型、修正流和流匹配,定义生成过程为固定的进度过程的时效逆转。尽管这些模型在大规模数据集上表现出令人印象深刻的性能,数值模拟需要神经网络的多个评估,导致采样速度缓慢。我们归因 learned generative trajectories的高曲率,因为它与数值求解器的缩短误差直接相关。基于进度过程和曲率之间的关系,我们在这里提出了一种有效的进度过程训练方法,以减少没有ODE/SDE模拟的 generative trajectories的曲率。实验表明,我们的方法比以前的模型低曲率,因此降低了采样成本 while maintaining competitive performance。代码可于 https://github.com/sangyun884/fast-ode。

**[Paper URL](https://proceedings.mlr.press/v202/lee23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23j/lee23j.pdf)** 

# H-Likelihood Approach to Deep Neural Networks with Temporal-Spatial Random Effects for High-Cardinality Categorical Features
**题目:** 高心率类别特征的临时空间随机效应对深度神经网络的H-概率研究

**作者:** Hangbin Lee, Youngjo Lee

**Abstract:** Deep Neural Networks (DNNs) are one of the most powerful tools for prediction, but many of them implicitly assume that the data are statistically independent. However, in the real world, it is common for large-scale data to be clustered with temporal-spatial correlation structures. Variational approaches and integrated likelihood approaches have been proposed to obtain approximate maximum likelihood estimators (MLEs) for correlated data. However, due to the large size of data, they cannot provide exact MLEs. In this study, we propose a new hierarchical likelihood approach to DNNs with correlated random effects for clustered data. By jointly optimizing the the negative h-likelihood loss, we can provide exact MLEs for both mean and dispersion parameters, as well as the best linear unbiased predictors for the random effects. Moreover, the hierarchical likelihood allows a computable procedure for restricted maximum likelihood estimators of dispersion parameters. The proposed two-step algorithm enables online learning for the neural networks, whereas the integrated likelihood cannot decompose like a widely-used loss function in DNNs. The proposed h-likelihood approach offers several advantages, which we demonstrate through numerical studies and real data analyses.

**摘要:** 深度神经网络(DNN)是预测最强的工具之一,但其中许多隐含假设数据是统计上独立的。然而,在现实世界中,大型数据与时空相关结构进行聚类是很常见的。变量方法和综合概率方法已提议为相关数据提供近似最大概率估计器(MLEs)。然而,由于数据的大小,它们不能提供准确的MLE。本研究中,我们提议为DNNs提供一种新的层次性概率方法,与聚类数据相关随机效应。通过联合优化负h-概率损失,我们可以为平均和分散参数提供准确的MLE,以及最佳的线性无偏见预测器为随机效应。提议的两步算法可为神经网络进行在线学习,而集成概率不能像在DNN中广泛使用的损失函数分解。提议的h-概率方法提供了几个优点,我们通过数值研究和实数据分析证明了这一点。

**[Paper URL](https://proceedings.mlr.press/v202/lee23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23k/lee23k.pdf)** 

# On the Importance of Feature Decorrelation for Unsupervised Representation Learning in Reinforcement Learning
**题目:** 非监督表现学习在增强学习中特征校正的重要性

**作者:** Hojoon Lee, Koanho Lee, Dongyoon Hwang, Hyunho Lee, Byungkun Lee, Jaegul Choo

**Abstract:** Recently, unsupervised representation learning (URL) has improved the sample efficiency of Reinforcement Learning (RL) by pretraining a model from a large unlabeled dataset. The underlying principle of these methods is to learn temporally predictive representations by predicting future states in the latent space. However, an important challenge of this approach is the representational collapse, where the subspace of the latent representations collapses into a low-dimensional manifold. To address this issue, we propose a novel URL framework that causally predicts future states while increasing the dimension of the latent manifold by decorrelating the features in the latent space. Through extensive empirical studies, we demonstrate that our framework effectively learns predictive representations without collapse, which significantly improves the sample efficiency of state-of-the-art URL methods on the Atari 100k benchmark. The code is available at https://github.com/dojeon-ai/SimTPR.

**摘要:** 最近,无监督的表示学习(URL)通过从一个不标记的数据集预训练模型提高增强学习(RL)的样本效率。这些方法的根本原理是通过预测潜在空间中的未来状态来学习临时预测表示。然而,这一方法的一个重要挑战是表示倒塌,其中潜在表示的子空间倒塌为低维多。为了解决这个问题,我们提出了一种新的URL框架,它可以因果地预测潜在空间中的特征,同时增加潜在多维多维度。通过广泛的实证研究,我们证明了我们的框架能够有效地学习没有倒塌的预测表示,这大大提高了Atari100k基准上最先进的URL方法样本效率。

**[Paper URL](https://proceedings.mlr.press/v202/lee23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23l/lee23l.pdf)** 

# HETAL: Efficient Privacy-preserving Transfer Learning with Homomorphic Encryption
**题目:** HETAL:高效的保密传输学习与同型加密

**作者:** Seewoo Lee, Garam Lee, Jung Woo Kim, Junbum Shin, Mun-Kyu Lee

**Abstract:** Transfer learning is a de facto standard method for efficiently training machine learning models for data-scarce problems by adding and fine-tuning new classification layers to a model pre-trained on large datasets. Although numerous previous studies proposed to use homomorphic encryption to resolve the data privacy issue in transfer learning in the machine learning as a service setting, most of them only focused on encrypted inference. In this study, we present HETAL, an efficient Homomorphic Encryption based Transfer Learning algorithm, that protects the client’s privacy in training tasks by encrypting the client data using the CKKS homomorphic encryption scheme. HETAL is the first practical scheme that strictly provides encrypted training, adopting validation-based early stopping and achieving the accuracy of nonencrypted training. We propose an efficient encrypted matrix multiplication algorithm, which is 1.8 to 323 times faster than prior methods, and a highly precise softmax approximation algorithm with increased coverage. The experimental results for five well-known benchmark datasets show total training times of 567–3442 seconds, which is less than an hour.

**摘要:** 传输学习是通过在大型数据集上预训练的模型中添加和微调新的分类层来有效训练机器学习模型的实例标准方法,解决数据私隐问题。虽然许多以前的研究提出使用同型加密来解决机器学习中的数据私隐问题,但其中大多数只集中在加密推理上。本研究中,我们介绍了一种基于同型加密的高效的传输学习算法HETAL,它通过使用CKKS同型加密方案加密客户数据来保护客户在培训任务中隐私。HETAL是第一个严格提供加密培训的实用方案,采用基于验证的早期停止和实现非加密培训的准确性。我们提出了一种比以前方法快1.8至323倍的高效加密矩阵乘法算法,并提出了一种高精度的软max近似算法,并增加了覆盖范围。

**[Paper URL](https://proceedings.mlr.press/v202/lee23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23m/lee23m.pdf)** 

# QASA: Advanced Question Answering on Scientific Articles
**题目:** QASA:科学文章 Advanced Question Answering

**作者:** Yoonjoo Lee, Kyungjae Lee, Sunghyun Park, Dasol Hwang, Jaehyeon Kim, Hong-In Lee, Moontae Lee

**Abstract:** Reasoning is the crux of intellectual thinking. While question answering (QA) tasks are prolific with various computational models and benchmark datasets, they mostly tackle factoid or shallow QA without asking deeper understanding. Dual process theory asserts that human reasoning consists of associative thinking to collect relevant pieces of knowledge and logical reasoning to consciously conclude grounding on evidential rationale. Based on our intensive think-aloud study that revealed the three types of questions: surface, testing, and deep questions, we first propose the QASA benchmark that consists of 1798 novel question answering pairs that require full-stack reasoning on scientific articles in AI and ML fields. Then we propose the QASA approach that tackles the full-stack reasoning with large language models via associative selection, evidential rationale-generation, and systematic composition. Our experimental results show that QASA’s full-stack inference outperforms the state-of-the-art InstructGPT by a big margin. We also find that rationale-generation is critical for the performance gain, claiming how we should rethink advanced question answering. The dataset is available at https://github.com/lgresearch/QASA.

**摘要:** 理性是智力思维的核心。虽然问答(QA)任务有多种计算模型和基准数据集,但它们大多不问深层次的理解,而是处理事实性或浅层次的QA问题。双过程理论认为,人类理性是由关联性思维来收集相关知识和逻辑推理,以自觉地结束基于证据理性的推理。基于我们深入的思考-倾听研究,揭示了三个问题类型:表面、测试和深层次问题,我们首先提出QASA基准,它由1798个新问题回答对组成,需要在AI和ML领域中科学文章上进行全面推理。我们的实验结果表明,QASA的全局推断比最新InstructGPT的大幅提高。我们还发现,理性生成对于性能提升至关重要,我们应该如何重新思考先进的问题回答。

**[Paper URL](https://proceedings.mlr.press/v202/lee23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23n/lee23n.pdf)** 

# Demystifying Disagreement-on-the-Line in High Dimensions
**题目:** 高维度在线分歧的解明

**作者:** Donghwan Lee, Behrad Moniri, Xinmeng Huang, Edgar Dobriban, Hamed Hassani

**Abstract:** Evaluating the performance of machine learning models under distribution shifts is challenging, especially when we only have unlabeled data from the shifted (target) domain, along with labeled data from the original (source) domain. Recent work suggests that the notion of disagreement, the degree to which two models trained with different randomness differ on the same input, is a key to tackling this problem. Experimentally, disagreement and prediction error have been shown to be strongly connected, which has been used to estimate model performance. Experiments have led to the discovery of the disagreement-on-the-line phenomenon, whereby the classification error under the target domain is often a linear function of the classification error under the source domain; and whenever this property holds, disagreement under the source and target domain follow the same linear relation. In this work, we develop a theoretical foundation for analyzing disagreement in high-dimensional random features regression; and study under what conditions the disagreement-on-the-line phenomenon occurs in our setting. Experiments on CIFAR-10-C, Tiny ImageNet-C, and Camelyon17 are consistent with our theory and support the universality of the theoretical findings.

**摘要:** 在分布变换下的机器学习模型的性能评价是挑战性的,尤其是当我们只有从变换的(目标)域中没有标记的数据,以及从原始(源)域中标记的数据时。最近的研究表明,不一致的概念,即两个与不同随机性训练的模型在同一输入上不同程度的程度,是解决这个问题的关键。本文为分析高维随机特征回归中的不一致性建立了理论基础,并研究在何种条件下在我们的环境中发生不一致性在线现象。CIFAR-10-C、Tiny ImageNet-C和Camelyon17的实验符合我们的理论,支持理论发现的普遍性。

**[Paper URL](https://proceedings.mlr.press/v202/lee23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23o/lee23o.pdf)** 

# On the Correctness of Automatic Differentiation for Neural Networks with Machine-Representable Parameters
**题目:** 基于机器可代表参数的神经网络自动区分的正确性

**作者:** Wonyeol Lee, Sejun Park, Alex Aiken

**Abstract:** Recent work has shown that forward- and reverse- mode automatic differentiation (AD) over the reals is almost always correct in a mathematically precise sense. However, actual programs work with machine-representable numbers (e.g., floating-point numbers), not reals. In this paper, we study the correctness of AD when the parameter space of a neural network consists solely of machine-representable numbers. In particular, we analyze two sets of parameters on which AD can be incorrect: the incorrect set on which the network is differentiable but AD does not compute its derivative, and the non-differentiable set on which the network is non-differentiable. For a neural network with bias parameters, we first prove that the incorrect set is always empty. We then prove a tight bound on the size of the non-differentiable set, which is linear in the number of non-differentiabilities in activation functions, and give a simple necessary and sufficient condition for a parameter to be in this set. We further prove that AD always computes a Clarke subderivative even on the non-differentiable set. We also extend these results to neural networks possibly without bias parameters.

**摘要:** 最近的研究表明,在实数上,前向和逆模式的自动分化(AD)在数学上几乎总是正确。然而,实际的程序与机器可表示数(例如浮点数),而不是实数进行工作。在本文中,我们研究了AD的正确性,当神经网络的参数空间仅由机器可表示数构成时。我们进一步证明,AD总是在不区分的集合上计算克拉克子代数,我们还将这些结果扩展到可能没有偏差参数的神经网络。

**[Paper URL](https://proceedings.mlr.press/v202/lee23p.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23p/lee23p.pdf)** 

# Implicit Jacobian regularization weighted with impurity of probability output
**题目:** 与概率输出不纯度加权的隐性雅各布定律化

**作者:** Sungyoon Lee, Jinseong Park, Jaewook Lee

**Abstract:** The success of deep learning is greatly attributed to stochastic gradient descent (SGD), yet it remains unclear how SGD finds well-generalized models. We demonstrate that SGD has an implicit regularization effect on the logit-weight Jacobian norm of neural networks. This regularization effect is weighted with the impurity of the probability output, and thus it is active in a certain phase of training. Moreover, based on these findings, we propose a novel optimization method that explicitly regularizes the Jacobian norm, which leads to similar performance as other state-of-the-art sharpness-aware optimization methods.

**摘要:** 深层学习的成功主要归因于随机梯度下降(SGD),但仍不清楚SGD如何发现广义模型。我们证明SGD对神经网络的 logit-weight雅各布规范具有隐含的调节效应,这种调节效应与概率输出的纯度相重,因此在某种训练阶段是活跃的。此外,基于这些发现,我们提出了一种明确调节雅各布规范的新优化方法,该方法与其他最先进的敏锐意识优化方法类似。

**[Paper URL](https://proceedings.mlr.press/v202/lee23q.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23q/lee23q.pdf)** 

# Unsupervised Skill Discovery for Learning Shared Structures across Changing Environments
**题目:** 无监督的学习技能发现在变化的环境中共享结构

**作者:** Sang-Hyun Lee, Seung-Woo Seo

**Abstract:** Learning shared structures across changing environments enables an agent to efficiently retain obtained knowledge and transfer it between environments. A skill is a promising concept to represent shared structures. Several recent works proposed unsupervised skill discovery algorithms that can discover useful skills without a reward function. However, they focused on discovering skills in stationary environments or assumed that a skill being trained is fixed within an episode, which is insufficient to learn and represent shared structures. In this paper, we introduce a new unsupervised skill discovery algorithm that discovers a set of skills that can represent shared structures across changing environments. Our algorithm trains incremental skills and encourages a new skill to expand state coverage obtained with compositions of previously learned skills. We also introduce a skill evaluation process to prevent our skills from containing redundant skills, a common issue in previous work. Our experimental results show that our algorithm acquires skills that represent shared structures across changing maze navigation and locomotion environments. Furthermore, we demonstrate that our skills are more useful than baselines on downstream tasks.

**摘要:** 在变化的环境中学习共享结构,使代理人能有效地保留所获得的知识并将其传递到环境中。一种技能是代表共享结构的有前途的概念。最近的几项研究提出了无监督的技能发现算法,可以在没有奖励函数的情况下发现有用的技能。然而,它们的重点在于在静态环境中发现技能,或者假设训练的技能在一集中固定,不足以学习和代表共享结构。本论文介绍了一种新的无监督的技能发现算法,该算法发现能够代表变化环境中共享结构的一系列技能。实验结果表明,我们的算法在不断变化的迷宫导航和运动环境中获取了代表共同结构的技能,而且,我们证明了我们的技能比下游任务的基线更有用。

**[Paper URL](https://proceedings.mlr.press/v202/lee23r.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lee23r/lee23r.pdf)** 

# Generalization Analysis for Contrastive Representation Learning
**题目:** 反向表示学习的一般化分析

**作者:** Yunwen Lei, Tianbao Yang, Yiming Ying, Ding-Xuan Zhou

**Abstract:** Recently, contrastive learning has found impressive success in advancing the state of the art in solving various machine learning tasks. However, the existing generalization analysis is very limited or even not meaningful. In particular, the existing generalization error bounds depend linearly on the number $k$ of negative examples while it was widely shown in practice that choosing a large $k$ is necessary to guarantee good generalization of contrastive learning in downstream tasks. In this paper, we establish novel generalization bounds for contrastive learning which do not depend on $k$, up to logarithmic terms. Our analysis uses structural results on empirical covering numbers and Rademacher complexities to exploit the Lipschitz continuity of loss functions. For self-bounding Lipschitz loss functions, we further improve our results by developing optimistic bounds which imply fast rates in a low noise condition. We apply our results to learning with both linear representation and nonlinear representation by deep neural networks, for both of which we derive Rademacher complexity bounds to get improved generalization bounds.

**摘要:** 近来,对比学习在解决各种机器学习任务方面取得了令人印象深刻的成功,但现有的一般化分析非常有限,甚至没有意义。特别是,现有的一般化误差边界线性地取决于负例$k$的数目,而在实践中广泛表明,选择一个大的$k$是保证下游任务中对比学习的良好一般化的必要条件。研究结果应用于深层神经网络的线性表示和非线性表示学习,两者都得到了拉德马切尔复杂度边界,从而得到改进的广义化边界。

**[Paper URL](https://proceedings.mlr.press/v202/lei23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lei23a/lei23a.pdf)** 

# Learning Control by Iterative Inversion
**题目:** 反演学习控制

**作者:** Gal Leibovich, Guy Jacob, Or Avner, Gal Novik, Aviv Tamar

**Abstract:** We propose iterative inversion - an algorithm for learning an inverse function without input-output pairs, but only with samples from the desired output distribution and access to the forward function. The key challenge is a distribution shift between the desired outputs and the outputs of an initial random guess, and we prove that iterative inversion can steer the learning correctly, under rather strict conditions on the function. We apply iterative inversion to learn control. Our input is a set of demonstrations of desired behavior, given as video embeddings of trajectories (without actions), and our method iteratively learns to imitate trajectories generated by the current policy, perturbed by random exploration noise. Our approach does not require rewards, and only employs supervised learning, which can be easily scaled to use state-of-the-art trajectory embedding techniques and policy representations. Indeed, with a VQ-VAE embedding, and a transformer-based policy, we demonstrate non-trivial continuous control on several tasks (videos available at https://sites.google.com/view/iter-inver). Further, we report an improved performance on imitating diverse behaviors compared to reward based methods.

**摘要:** 我们建议迭代反演--学习逆函数的算法,不使用输入输出对,但只使用希望输出分布的样品和访问向前函数。关键挑战是希望输出和初始随机推测的输出之间的分布转移,并证明迭代反演能够在函数的严格条件下正确引导学习。我们应用迭代反演学习控制。我们的输入是希望行为的演示集,给出为轨迹的视频嵌入(没有动作),我们的方法迭代学习模仿当前政策所生成的轨迹,被随机探索噪声扰乱。我们的方法不需要奖励,只使用监督学习,它可以轻易地扩展到使用最先进的轨迹嵌入技术和政策表示。事实上,通过VQ-VAE嵌入式和基于变换器的政策,我们展示了在多个任务上非平凡的连续控制(视频可于 https://sites.google.com/view/iter-inver) 。 此外,我们报告了与基于奖励的方法相比,在模仿各种行为方面的表现有所改善。

**[Paper URL](https://proceedings.mlr.press/v202/leibovich23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/leibovich23a/leibovich23a.pdf)** 

# Sampling-Based Accuracy Testing of Posterior Estimators for General Inference
**题目:** 基于样本的总干涉后估计器准确性测试

**作者:** Pablo Lemos, Adam Coogan, Yashar Hezaveh, Laurence Perreault-Levasseur

**Abstract:** Parameter inference, i.e. inferring the posterior distribution of the parameters of a statistical model given some data, is a central problem to many scientific disciplines. Posterior inference with generative models is an alternative to methods such as Markov Chain Monte Carlo, both for likelihood-based and simulation-based inference. However, assessing the accuracy of posteriors encoded in generative models is not straightforward. In this paper, we introduce "Tests of Accuracy with Random Points" (TARP) coverage testing as a method to estimate coverage probabilities of generative posterior estimators. Our method differs from previously-existing coverage-based methods, which require posterior evaluations. We prove that our approach is necessary and sufficient to show that a posterior estimator is accurate. We demonstrate the method on a variety of synthetic examples, and show that TARP can be used to test the results of posterior inference analyses in high-dimensional spaces. We also show that our method can detect inaccurate inferences in cases where existing methods fail.

**摘要:** 参数推导(parameter inference),即推导某数据统计模型参数的后方分布,是许多科学领域中的一个中心问题。基于模型的后方推导是基于概率和仿真推导的马可夫链蒙特卡罗(Markov Chain Monte Carlo)等方法的替代。然而,在生成模型中编码的后方的准确性评估并不简单。本文介绍了“随机点的准确性测试”(TARP)覆盖测试作为估计生成后方推算器覆盖概率的方法。我们还表明,在现有方法失败的情况下,我们的方法可以检测不准确的推理。

**[Paper URL](https://proceedings.mlr.press/v202/lemos23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lemos23a/lemos23a.pdf)** 

# Fast Inference from Transformers via Speculative Decoding
**题目:** 通过扩散解码从变换器中快速引诱

**作者:** Yaniv Leviathan, Matan Kalman, Yossi Matias

**Abstract:** Inference from large autoregressive models like Transformers is slow - decoding K tokens takes K serial runs of the model. In this work we introduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs, by computing several tokens in parallel. At the heart of our approach lie the observations that (1) hard language-modeling tasks often include easier subtasks that can be approximated well by more efficient models, and (2) using speculative execution and a novel sampling method, we can make exact decoding from the large models faster, by running them in parallel on the outputs of the approximation models, potentially generating several tokens concurrently, and without changing the distribution. Our method can accelerate existing off-the-shelf models without retraining or architecture changes. We demonstrate it on T5-XXL and show a 2X-3X acceleration compared to the standard T5X implementation, with identical outputs.

**摘要:** 例如Transformers等大型自回归模型的仿真是缓慢的--解码K符号需要模型的K序列运行。在这个工作中,我们引入了投机解码--一种算法,以计算并行多个符号来快速地从自回归模型中提取样本,而不改变输出的任何变化。我们的方法的核心是观察 (1) 硬语言建模任务通常包括容易的子任务,可以通过更高效的模型进行近似, (2) 使用投机执行和新样本方法,我们可以使大模型的精确解码更快,通过在近似模型的输出上并行运行它们,潜在地同时生成几个符号,而不改变分布。

**[Paper URL](https://proceedings.mlr.press/v202/leviathan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/leviathan23a/leviathan23a.pdf)** 

# Efficient Rate Optimal Regret for Adversarial Contextual MDPs Using Online Function Approximation
**题目:** 利用在线函数逼近对敌对上下文MDP的有效率最佳遗憾

**作者:** Orin Levy, Alon Cohen, Asaf Cassel, Yishay Mansour

**Abstract:** We present the OMG-CMDP! algorithm for regret minimization in adversarial Contextual MDPs. The algorithm operates under the minimal assumptions of realizable function class and access to online least squares and log loss regression oracles. Our algorithm is efficient (assuming efficient online regression oracles), simple and robust to approximation errors. It enjoys an $\widetilde{O}(H^{2.5} \sqrt{ T|S||A| ( \mathcal{R}_{TH}(\mathcal{O}) + H \log(\delta^{-1}) )})$ regret guarantee, with $T$ being the number of episodes, $S$ the state space, $A$ the action space, $H$ the horizon and $\mathcal{R}_{TH}(\mathcal{O}) = \mathcal{R}_{TH}(\mathcal{O}_{sq}^\mathcal{F}) + \mathcal{R}_{TH}(\mathcal{O}_{log}^\mathcal{P})$ is the sum of the square and log-loss regression oracles’ regret, used to approximate the context-dependent rewards and dynamics, respectively. To the best of our knowledge, our algorithm is the first efficient rate optimal regret minimization algorithm for adversarial CMDPs that operates under the minimal standard assumption of online function approximation.

**摘要:** 我们提出了OMG-CMDP!对敌对文脈MDP的遗憾最小化算法。该算法在可实现函数类的最小假设下运行,并获得在线最小方形和逻辑损失回归理论的访问。我们的算法是有效的(假设有效的在线回归理论),简单和鲁棒的近似错误。它享有$\widetilde{O}(H^{2.5} \sqrt{ T|S||A| ( \mathcal{R}_{TH}(\mathcal{O}) + H \log(\delta^{-1}) )})$遗憾保证,$T$是 эпизод数,$S$是州空间,$A$是行动空间,$H$是地平线和$\mathcal{R}_{TH}(\mathcal{O}) = \mathcal{R}本算法是基于在线函数近似的最小标准假设,为敌方CMDP提供最优遗憾最小化算法。

**[Paper URL](https://proceedings.mlr.press/v202/levy23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/levy23a/levy23a.pdf)** 

# GLOBE-CE: A Translation Based Approach for Global Counterfactual Explanations
**题目:**  GLOBE-CE:基于翻译的全球反事实解释

**作者:** Dan Ley, Saumitra Mishra, Daniele Magazzeni

**Abstract:** Counterfactual explanations have been widely studied in explainability, with a range of application dependent methods prominent in fairness, recourse and model understanding. The major shortcoming associated with these methods, however, is their inability to provide explanations beyond the local or instance-level. While many works touch upon the notion of a global explanation, typically suggesting to aggregate masses of local explanations in the hope of ascertaining global properties, few provide frameworks that are both reliable and computationally tractable. Meanwhile, practitioners are requesting more efficient and interactive explainability tools. We take this opportunity to propose Global & Efficient Counterfactual Explanations (GLOBE-CE), a flexible framework that tackles the reliability and scalability issues associated with current state-of-the-art, particularly on higher dimensional datasets and in the presence of continuous features. Furthermore, we provide a unique mathematical analysis of categorical feature translations, utilising it in our method. Experimental evaluation with publicly available datasets and user studies demonstrate that GLOBE-CE performs significantly better than the current state-of-the-art across multiple metrics (e.g., speed, reliability).

**摘要:** 反事实解释在解释性方面已得到广泛研究,在公平、诉求和模型理解中突出的一系列应用依赖方法。然而,与这些方法相关的主要缺陷是它们无法提供解释 beyond the local or instance-level。虽然许多作品涉及全球解释的概念,通常建议在确定全球属性的希望中聚集局部解释的大量,但很少提供可靠和可计算的框架。与此同时,实践者要求更有效的交互性解释工具。我们借此机会提出Global & Efficient Counterfactual Explanations(GLOBE-CE),一种灵活的框架,解决与最新技术有关的可靠性和可扩展性问题,特别是在高维数据集和连续特征的存在。此外,我们还提供一种独特的分类特征翻译的数学分析,并将其应用于我们的方法。利用公开的数据集和用户研究的实验评价表明, GLOBE-CE在多个指标(例如速度、可靠性)上的表现比目前的最先进的性能好得多。

**[Paper URL](https://proceedings.mlr.press/v202/ley23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ley23a/ley23a.pdf)** 

# TIPS: Topologically Important Path Sampling for Anytime Neural Networks
**题目:** 提示:任何时间神经网络的拓扑重要路径采样

**作者:** Guihong Li, Kartikeya Bhardwaj, Yuedong Yang, Radu Marculescu

**Abstract:** Anytime neural networks (AnytimeNNs) are a promising solution to adaptively adjust the model complexity at runtime under various hardware resource constraints. However, the manually-designed AnytimeNNs are biased by designers’ prior experience and thus provide sub-optimal solutions. To address the limitations of existing hand-crafted approaches, we first model the training process of AnytimeNNs as a discrete-time Markov chain (DTMC) and use it to identify the paths that contribute the most to the training of AnytimeNNs. Based on this new DTMC-based analysis, we further propose TIPS, a framework to automatically design AnytimeNNs under various hardware constraints. Our experimental results show that TIPS can improve the convergence rate and test accuracy of AnytimeNNs. Compared to the existing AnytimeNNs approaches, TIPS improves the accuracy by 2%-6.6% on multiple datasets and achieves SOTA accuracy-FLOPs tradeoffs.

**摘要:** 任何时间神经网络(AnytimeNNs)是适应不同硬件资源约束下的运行时模型复杂性调整的有前途的解决方案。然而,手动设计的任何时间NNs被设计者先前的经验偏向,因此提供亚最佳解决方案。为了解决现有手工设计方法的局限性,我们首先将任何时间NNs的训练过程建模为离散时间马可夫链(DTMC)并使用它来识别为任何时间NNs的训练最有贡献的路径。基于这一新的DTMC基础分析,我们进一步提议TPS,一种在不同硬件约束下自动设计任何时间NNs的框架。

**[Paper URL](https://proceedings.mlr.press/v202/li23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23a/li23a.pdf)** 

# MAHALO: Unifying Offline Reinforcement Learning and Imitation Learning from Observations
**题目:** 马哈洛:统一网络增强学习与仿真学习

**作者:** Anqi Li, Byron Boots, Ching-An Cheng

**Abstract:** We study a new paradigm for sequential decision making, called offline policy learning from observations (PLfO). Offline PLfO aims to learn policies using datasets with substandard qualities: 1) only a subset of trajectories is labeled with rewards, 2) labeled trajectories may not contain actions, 3) labeled trajectories may not be of high quality, and 4) the data may not have full coverage. Such imperfection is common in real-world learning scenarios, and offline PLfO encompasses many existing offline learning setups, including offline imitation learning (IL), offline IL from observations (ILfO), and offline reinforcement learning (RL). In this work, we present a generic approach to offline PLfO, called Modality-agnostic Adversarial Hypothesis Adaptation for Learning from Observations (MAHALO). Built upon the pessimism concept in offline RL, MAHALO optimizes the policy using a performance lower bound that accounts for uncertainty due to the dataset’s insufficient coverage. We implement this idea by adversarially training data-consistent critic and reward functions, which forces the learned policy to be robust to data deficiency. We show that MAHALO consistently outperforms or matches specialized algorithms across a variety of offline PLfO tasks in theory and experiments. Our code is available at https://github.com/AnqiLi/mahalo.

**摘要:** 我们研究了一种新的序列决策范式,即从观测中学习非线性策略(PLfO)。非线性PLfO旨在利用亚标准品质的数据集学习政策: 1)只有一个小路段被标记为奖励,2)标记的路段可能不包含行动,3)标记的路段可能不具有高质量,以及4)数据可能没有充分覆盖。这种不完善现象在现实学习场景中常见, offline PLfO包括许多现有的非线性学习设置,包括 offline模仿学习(IL), offline IL从观测中学习(ILfO), offline增强学习(RL)。我们通过对抗训练数据一致的批评和奖励函数来实现这个想法,这迫使学习的策略对数据短缺具有鲁棒性。我们证明,马哈洛在理论和实验中始终能超越或匹配各种非线性PLfO任务的专门算法。

**[Paper URL](https://proceedings.mlr.press/v202/li23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23b/li23b.pdf)** 

# Internet Explorer: Targeted Representation Learning on the Open Web
**题目:** Internet Explorer:基于开放网络的 Targeted Representation Learning

**作者:** Alexander Cong Li, Ellis Langham Brown, Alexei A Efros, Deepak Pathak

**Abstract:** Vision models typically rely on fine-tuning general-purpose models pre-trained on large, static datasets. These general-purpose models only capture the knowledge within their pre-training datasets, which are tiny, out-of-date snapshots of the Internet—where billions of images are uploaded each day. We suggest an alternate approach: rather than hoping our static datasets transfer to our desired tasks after large-scale pre-training, we propose dynamically utilizing the Internet to quickly train a small-scale model that does extremely well on a target dataset. Our approach, called Internet Explorer, explores the web in a self-supervised manner to progressively find relevant examples that improve performance on a desired target dataset. It cycles between searching for images on the Internet with text queries, self-supervised training on downloaded images, determining which images were useful, and prioritizing what to search for next. We evaluate Internet Explorer across several datasets and show that it outperforms or matches CLIP oracle performance using just a single GPU desktop to actively query the Internet for 30-40 hours.

**摘要:** 视觉模型通常依赖于在大型静态数据集上预训练的细微调制通用模型。这些通用模型只捕捉在其预训练数据集内的知识,这些数据集是互联网的微不足道、过时的缩影——每天有数十亿的图像被上传到互联网上。我们建议一种替代的方法:我们希望我们的静态数据集在大规模预训练后转移到我们所希望的任务,我们建议动态利用互联网快速训练一个小规模模型,它在目标数据集上表现非常出色。我们通过多个数据集评估Internet Explorer,并显示它在单一的GPU桌面上能超过或与CLIP Oracle性能相匹配,以积极查询互联网30—40小时。

**[Paper URL](https://proceedings.mlr.press/v202/li23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23c/li23c.pdf)** 

# Prototype-oriented unsupervised anomaly detection for multivariate time series
**题目:** 多变量时间序列的原型导向无监督异常检测

**作者:** Yuxin Li, Wenchao Chen, Bo Chen, Dongsheng Wang, Long Tian, Mingyuan Zhou

**Abstract:** Unsupervised anomaly detection (UAD) of multivariate time series (MTS) aims to learn robust representations of normal multivariate temporal patterns. Existing UAD methods try to learn a fixed set of mappings for each MTS, entailing expensive computation and limited model adaptation. To address this pivotal issue, we propose a prototype-oriented UAD (PUAD) method under a probabilistic framework. Specifically, instead of learning the mappings for each MTS, the proposed PUAD views multiple MTSs as the distribution over a group of prototypes, which are extracted to represent a diverse set of normal patterns. To learn and regulate the prototypes, PUAD introduces a reconstruction-based unsupervised anomaly detection approach, which incorporates a prototype-oriented optimal transport method into a Transformer-powered probabilistic dynamical generative framework. Leveraging meta-learned transferable prototypes, PUAD can achieve high model adaptation capacity for new MTSs. Experiments on five public MTS datasets all verify the effectiveness of the proposed UAD method.

**摘要:** 多变量时间序列(MTS)的无监督异常检测(UAD)旨在学习正常多变量时间模式的稳健表现。现有的UAD方法尝试学习每个MTS的固定映射集,包括昂贵的计算和有限的模型适应。为了解决这一关键问题,我们提出了基于概率框架的基于原型的UAD(PUAD)方法。具体地说,该方法不是为了学习每个MTS的映射集,而是将多变量MTS视作一种模型群的分布,这些模型被提取来代表各种不同类型的正常模式。对五个公共的MTS数据集进行了实验,验证了提议的UAD方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/li23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23d/li23d.pdf)** 

# Learning Preconditioners for Conjugate Gradient PDE Solvers
**题目:** 协和梯度PDE求解器学习预备条件

**作者:** Yichen Li, Peter Yichen Chen, Tao Du, Wojciech Matusik

**Abstract:** Efficient numerical solvers for partial differential equations empower science and engineering. One commonly employed numerical solver is the preconditioned conjugate gradient (PCG) algorithm, whose performance is largely affected by the preconditioner quality. However, designing high-performing preconditioner with traditional numerical methods is highly non-trivial, often requiring problem-specific knowledge and meticulous matrix operations. We present a new method that leverages learning-based approach to obtain an approximate matrix factorization to the system matrix to be used as a preconditioner in the context of PCG solvers. Our high-level intuition comes from the shared property between preconditioners and network-based PDE solvers that excels at obtaining approximate solutions at a low computational cost. Such observation motivates us to represent preconditioners as graph neural networks (GNNs). In addition, we propose a new loss function that rewrites traditional preconditioner metrics to incorporate inductive bias from PDE data distributions, enabling effective training of high-performing preconditioners. We conduct extensive experiments to demonstrate the efficacy and generalizability of our proposed approach on solving various 2D and 3D linear second-order PDEs.

**摘要:** 部分微分方程的有效数值求解器赋予科学和工程力量。一个常用的数值求解器是预先条件合并梯度(PCG)算法,其性能受到预先条件器质量的影响很大。然而,设计高性能预先条件器的传统数值方法非常不平凡,经常需要问题特有知识和精细的矩阵操作。我们提出了一种新的方法,利用学习基础的方法获得系统矩阵的近似矩阵因子化,以作为预先条件器在PCG求解器的上下文中使用。此外,我们提出了一种新的损失函数,将传统的预冷却器测度重新编写,将PDE数据分布的诱导偏差结合起来,使高性能预冷却器得到有效的训练。我们进行了广泛的实验,证明了我们提出的解决各种2D和3D线性二阶PDEs的方法的有效性和可推广性。

**[Paper URL](https://proceedings.mlr.press/v202/li23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23e/li23e.pdf)** 

# Parallel $Q$-Learning: Scaling Off-policy Reinforcement Learning under Massively Parallel Simulation
**题目:** 并行 $Q$-学习:在大规模并行仿真下从政策强化 learning中进行规模化

**作者:** Zechu Li, Tao Chen, Zhang-Wei Hong, Anurag Ajay, Pulkit Agrawal

**Abstract:** Reinforcement learning is time-consuming for complex tasks due to the need for large amounts of training data. Recent advances in GPU-based simulation, such as Isaac Gym, have sped up data collection thousands of times on a commodity GPU. Most prior works have used on-policy methods like PPO due to their simplicity and easy-to-scale nature. Off-policy methods are more sample-efficient, but challenging to scale, resulting in a longer wall-clock training time. This paper presents a novel Parallel Q-Learning (PQL) scheme that outperforms PPO in terms of wall-clock time and maintains superior sample efficiency. The driving force lies in the parallelization of data collection, policy function learning, and value function learning. Different from prior works on distributed off-policy learning, such as Apex, our scheme is designed specifically for massively parallel GPU-based simulation and optimized to work on a single workstation. In experiments, we demonstrate the capability of scaling up Q-learning methods to tens of thousands of parallel environments and investigate important factors that can affect learning speed, including the number of parallel environments, exploration strategies, batch size, GPU models, etc. The code is available at https://github.com/Improbable-AI/pql.

**摘要:** 强化学习是由于需要大量训练数据而耗费时间的复杂任务。最近的基于GPU的仿真,如伊萨克体育馆,在商品GPU上加速了数千次数据采集。大部分以前的工作都使用了基于PPO的策略方法,因为它们的简单性和易于规模化性质。非策略方法比样本效率高,但难以规模化,导致更长的墙时钟训练时间。本论文提出了一种新型的平行Q-学习(PQL)方案,它在墙时钟时间方面优于PPO,并保持了优越的样本效率。驱动力在于数据采集、政策函数学习和价值函数学习的平行化。在实验中,我们展示了将Q-学习方法扩展到数以万计的平行环境的能力,并研究了影响学习速度的重要因素,包括平行环境的数量、探索策略、批量大小、GPU模型等。

**[Paper URL](https://proceedings.mlr.press/v202/li23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23f/li23f.pdf)** 

# Minimum Width of Leaky-ReLU Neural Networks for Uniform Universal Approximation
**题目:** 统一通用近似神经网络的最小宽度

**作者:** Li’Ang Li, Yifei Duan, Guanghua Ji, Yongqiang Cai

**Abstract:** The study of universal approximation properties (UAP) for neural networks (NN) has a long history. When the network width is unlimited, only a single hidden layer is sufficient for UAP. In contrast, when the depth is unlimited, the width for UAP needs to be not less than the critical width $w^*_{\min}=\max(d_x,d_y)$, where $d_x$ and $d_y$ are the dimensions of the input and output, respectively. Recently, (Cai, 2022) shows that a leaky-ReLU NN with this critical width can achieve UAP for $L^p$ functions on a compact domain $\mathcal{K}$, i.e., the UAP for $L^p(\mathcal{K},\mathbb{R}^{d_y})$. This paper examines a uniform UAP for the function class $C(\mathcal{K},\mathbb{R}^{d_y})$ and gives the exact minimum width of the leaky-ReLU NN as $w_{\min}=\max(d_x+1,d_y)+1_{d_y=d_x+1}$, which involves the effects of the output dimensions. To obtain this result, we propose a novel lift-flow-discretization approach that shows that the uniform UAP has a deep connection with topological theory.

**摘要:** 神经网络的通用近似特性的研究具有悠久的历史。当网络宽度是无限时,仅一个隐藏层为UAP足够。与此相反,当深度是无限时,UAP的宽度必须不低于临界宽度$w^*_{\min}=\max(d_x,d_y)$,其中$d_x$和$d_y$分别是输入和输出的维度。最近,(Cai, 2022)表明,具有这一临界宽度的泄漏ReLUNN可以实现$L^p$函数在压缩域$\mathcal{K}$上,即$L^p(\mathcal{K},\mathbb{R}^{d_y})$的UAP。本文对函数类$C(\mathcal{K},\mathbb{R}^{d_y})

**[Paper URL](https://proceedings.mlr.press/v202/li23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23g/li23g.pdf)** 

# FAIRER: Fairness as Decision Rationale Alignment
**题目:** 公平:公平作为决策合理性平衡

**作者:** Tianlin Li, Qing Guo, Aishan Liu, Mengnan Du, Zhiming Li, Yang Liu

**Abstract:** Deep neural networks (DNNs) have made significant progress, but often suffer from fairness issues, as deep models typically show distinct accuracy differences among certain subgroups (e.g., males and females). Existing research addresses this critical issue by employing fairness-aware loss functions to constrain the last-layer outputs and directly regularize DNNs. Although the fairness of DNNs is improved, it is unclear how the trained network makes a fair prediction, which limits future fairness improvements. In this paper, we investigate fairness from the perspective of decision rationale and define the parameter parity score to characterize the fair decision process of networks by analyzing neuron influence in various subgroups. Extensive empirical studies show that the unfair issue could arise from the unaligned decision rationales of subgroups. Existing fairness regularization terms fail to achieve decision rationale alignment because they only constrain last-layer outputs while ignoring intermediate neuron alignment. To address the issue, we formulate the fairness as a new task, i.e., decision rationale alignment that requires DNNs’ neurons to have consistent responses on subgroups at both intermediate processes and the final prediction. To make this idea practical during optimization, we relax the naive objective function and propose gradient-guided parity alignment, which encourages gradient-weighted consistency of neurons across subgroups. Extensive experiments on a variety of datasets show that our method can significantly enhance fairness while sustaining a high level of accuracy and outperforming other approaches by a wide margin.

**摘要:** 深层神经网络(英语:Deep neural networks,缩写为DNN)已取得重大进展,但往往存在公平问题,因为深层模型通常显示某些子群间的准确性差异(例如男性和女性)。现有研究通过使用公平意识损失函数来约束最后层输出并直接规范DNN解决这一关键问题。虽然DNN的公平性得到了改善,但目前尚不清楚训练网络如何作出公平预测,从而限制未来公平性改进。现有的公平合理化术语无法实现决策合理化alignment,因为它们只限制最后层输出,而忽略中层神经元alignment。为了解决这个问题,我们将公平作为一项新任务,即需要DNN神经元在中层过程和最终预测中对分组作出一致响应的决策合理化alignment。

**[Paper URL](https://proceedings.mlr.press/v202/li23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23h/li23h.pdf)** 

# RACE: Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evolution
**题目:** RACE:以代表不对称和协作演化为基础,改进多代理强化学习

**作者:** Pengyi Li, Jianye Hao, Hongyao Tang, Yan Zheng, Xian Fu

**Abstract:** Multi-Agent Reinforcement Learning (MARL) has demonstrated its effectiveness in learning collaboration, but it often struggles with low-quality reward signals and high non-stationarity. In contrast, Evolutionary Algorithm (EA) has shown better convergence, robustness, and signal quality insensitivity. This paper introduces a hybrid framework, Representation Asymmetry and Collaboration Evolution (RACE), which combines EA and MARL for efficient collaboration. RACE maintains a MARL team and a population of EA teams. To enable efficient knowledge sharing and policy exploration, RACE decomposes the policies of different teams controlling the same agent into a shared nonlinear observation representation encoder and individual linear policy representations. To address the partial observation issue, we introduce Value-Aware Mutual Information Maximization to enhance the shared representation with useful information about superior global states. EA evolves the population using novel agent-level crossover and mutation operators, offering diverse experiences for MARL. Concurrently, MARL optimizes its policies and injects them into the population for evolution. The experiments on challenging continuous and discrete tasks demonstrate that RACE significantly improves the basic algorithms, consistently outperforming other algorithms. Our code is available at https://github.com/yeshenpy/RACE.

**摘要:** 多代理增强学习(英语:Multi-Agent Reinforcement Learning,缩写为MARL)在学习协作中已经证明了其有效性,但它经常与低质量的奖励信号和高非静态性作斗争。相比之下,进化算法(英语:Evolutionary Algorithm,缩写为EA)显示了更好的收敛性、鲁棒性和信号质量不敏感性。本论文介绍了一种混合框架,代表不对称和协作演化(英语:Representation Asymmetry and Collaboration Evolution,缩写为RACE),它结合了EA和MARL进行有效的协作。RACE维护了一个MARL团队和一个EA团队的人口。EA利用新的代理水平交叉和变异操作器来演化人口,为MARL提供多种经验。同时,MARL优化其政策,并将其注入进化人口中。挑战连续和离散任务的实验表明,RACE显著改善了基本算法,一致超过了其他算法。我们的代码可于 https://github.com/yeshenpy/RACE。

**[Paper URL](https://proceedings.mlr.press/v202/li23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23i/li23i.pdf)** 

# Adversarial Collaborative Learning on Non-IID Features
**题目:** 对非IID特征进行敌对协作学习

**作者:** Qinbin Li, Bingsheng He, Dawn Song

**Abstract:** Federated Learning (FL) has been a popular approach to enable collaborative learning on multiple parties without exchanging raw data. However, the model performance of FL may degrade a lot due to non-IID data. While many FL algorithms focus on non-IID labels, FL on non-IID features has largely been overlooked. Different from typical FL approaches, the paper proposes a new learning concept called ADCOL (Adversarial Collaborative Learning) for non-IID features. Instead of adopting the widely used model-averaging scheme, ADCOL conducts training in an adversarial way: the server aims to train a discriminator to distinguish the representations of the parties, while the parties aim to generate a common representation distribution. Our experiments show that ADCOL achieves better performance than state-of-the-art FL algorithms on non-IID features.

**摘要:** 联合学习(FL)是实现在多个方面进行协作学习的一种流行方法,但不能交换原始数据。然而,FL的模型性能可能因非IID数据而大幅下降。虽然许多非IID算法集中在非IID标签上,但非IID特性上的FL却被忽略了。不同于典型的FL方法,本文提出了一种新的学习概念,即非IID特性的ADCOL(Adversarial Collaborative Learning)。

**[Paper URL](https://proceedings.mlr.press/v202/li23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23j/li23j.pdf)** 

# Near-optimal Conservative Exploration in Reinforcement Learning under Episode-wise Constraints
**题目:** 在各章节约束下的强化学习中接近最佳的保守探索

**作者:** Donghao Li, Ruiquan Huang, Cong Shen, Jing Yang

**Abstract:** This paper investigates conservative exploration in reinforcement learning where the performance of the learning agent is guaranteed to be above a certain threshold throughout the learning process. It focuses on the tabular episodic Markov Decision Process (MDP) setting that has finite states and actions. With the knowledge of an existing safe baseline policy, an algorithms termed as StepMix is proposed to balance the exploitation and exploration while ensuring that the conservative constraint is never violated in each episode with high probability. StepMix features a unique design of a mixture policy that adaptively and smoothly interpolates between the baseline policy and the optimistic policy. Theoretical analysis shows that StepMix achieves near-optimal regret order as in the constraint-free setting, indicating that obeying the stringent episode-wise conservative constraint does not compromise the learning performance. Besides, a randomization based EpsMix algorithm is also proposed and shown the achieve the same performance as StepMix. The algorithm design and theoretical analysis are further extended to the setting where the baseline policy is not given a priori but must be learned from an offline dataset, and it is proved that similar conservative guarantee and regret can be achieved if the offline dataset is sufficiently large. Experiment results corroborate the theoretical analysis and demonstrate the effectiveness of the proposed conservative exploration strategies.

**摘要:** 本文研究了强化学习中的保守探索,其中学习代理的性能保证在整个学习过程中达到一定阈值以上。文章重点研究了具有有限状态和行动的表式周期性马可夫决策过程(MDP)设置。基于现有的安全基线政策的知识,提出了一种称为StepMix的算法,以平衡开发和探索,同时确保保守约束在每个周期中不会被违反。StepMix具有一种独特的混合政策设计,能够自适应和顺利地对基线政策和乐观政策进行插值。此外,提出了基于随机化的EpsMix算法,并表明该算法的性能与StepMix相同。该算法的设计和理论分析进一步扩展到基线政策不予先知,但必须从非线性数据集中学习的设置,并且证明如果非线性数据集足够大,可以实现类似的保守保证和遗憾。实验结果证实了该算法的理论分析,并证明了该算法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/li23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23k/li23k.pdf)** 

# Transformers as Algorithms: Generalization and Stability in In-context Learning
**题目:** 变换器作为算法:语境学习中的一般化与稳定性

**作者:** Yingcong Li, Muhammed Emrullah Ildiz, Dimitris Papailiopoulos, Samet Oymak

**Abstract:** In-context learning (ICL) is a type of prompting where a transformer model operates on a sequence of (input, output) examples and performs inference on-the-fly. In this work, we formalize in-context learning as an algorithm learning problem where a transformer model implicitly constructs a hypothesis function at inference-time. We first explore the statistical aspects of this abstraction through the lens of multitask learning: We obtain generalization bounds for ICL when the input prompt is (1) a sequence of i.i.d. (input, label) pairs or (2) a trajectory arising from a dynamical system. The crux of our analysis is relating the excess risk to the stability of the algorithm implemented by the transformer. We characterize when transformer/attention architecture provably obeys the stability condition and also provide empirical verification. For generalization on unseen tasks, we identify an inductive bias phenomenon in which the transfer learning risk is governed by the task complexity and the number of MTL tasks in a highly predictable manner. Finally, we provide numerical evaluations that (1) demonstrate transformers can indeed implement near-optimal algorithms on classical regression problems with i.i.d. and dynamic data, (2) provide insights on stability, and (3) verify our theoretical predictions.

**摘要:** 语境内学习(英语:In-context learning,缩写为ICL)是变换器模型在(输入、输出)实例的序列上操作并进行实时推导的一种推导类型。本文将语境内学习形式化为算法学习问题,其中变换器模型在推导时隐含构造假设函数。我们首先通过多任务学习的视角探讨了该抽象的统计方面:当输入推导是(一)i.i.d.(输入、标签)对的序列或(二)动态系统产生的轨迹时,我们得到ICL的一般化边界。为了对未知任务的一般化,我们确定了一个诱导偏差现象,其中传输学习风险由任务复杂度和MTL任务数值以高度可预测的方式控制。最后,我们提供数值评价,表明(1)变换器确实能够用i.i.d.和动态数据对经典回归问题实施 near-optimal算法,(2)提供稳定方面的洞察,以及(3)验证我们的理论预测。

**[Paper URL](https://proceedings.mlr.press/v202/li23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23l/li23l.pdf)** 

# Improving Hyperparameter Learning under Approximate Inference in Gaussian Process Models
**题目:** 高斯过程模型中近似ference下的超参数学习的改进

**作者:** Rui Li, S. T. John, Arno Solin

**Abstract:** Approximate inference in Gaussian process (GP) models with non-conjugate likelihoods gets entangled with the learning of the model hyperparameters. We improve hyperparameter learning in GP models and focus on the interplay between variational inference (VI) and the learning target. While VI’s lower bound to the marginal likelihood is a suitable objective for inferring the approximate posterior, we show that a direct approximation of the marginal likelihood as in Expectation Propagation (EP) is a better learning objective for hyperparameter optimization. We design a hybrid training procedure to bring the best of both worlds: it leverages conjugate-computation VI for inference and uses an EP-like marginal likelihood approximation for hyperparameter learning. We compare VI, EP, Laplace approximation, and our proposed training procedure and empirically demonstrate the effectiveness of our proposal across a wide range of data sets.

**摘要:** 在高斯过程(GP)模型中,与非共轭概率的近似推理与模型超参数的学习结合起来。我们改进GP模型中的超参数学习,并着重于变量推理(VI)与学习目标之间的相互作用。虽然VI与边缘概率的较低界限是推导近似后端的恰当目标,但我们表明,如 Expectation Propagation(EP)中的边缘概率的直接近似是优化超参数的更好的学习目标。我们设计了一个混合训练程序,使两个世界的最佳结果:它利用共轭计算VI进行推理,并使用EP类似的超参数学习的边缘概率近似。

**[Paper URL](https://proceedings.mlr.press/v202/li23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23m/li23m.pdf)** 

# Local Vertex Colouring Graph Neural Networks
**题目:** 局部顶点彩色图神经网络

**作者:** Shouheng Li, Dongwoo Kim, Qing Wang

**Abstract:** In recent years, there has been a significant amount of research focused on expanding the expressivity of Graph Neural Networks (GNNs) beyond the Weisfeiler-Lehman (1-WL) framework. While many of these studies have yielded advancements in expressivity, they have frequently come at the expense of decreased efficiency or have been restricted to specific types of graphs. In this study, we investigate the expressivity of GNNs from the perspective of graph search. Specifically, we propose a new vertex colouring scheme and demonstrate that classical search algorithms can efficiently compute graph representations that extend beyond the 1-WL. We show the colouring scheme inherits useful properties from graph search that can help solve problems like graph biconnectivity. Furthermore, we show that under certain conditions, the expressivity of GNNs increases hierarchically with the radius of the search neighbourhood. To further investigate the proposed scheme, we develop a new type of GNN based on two search strategies, breadth-first search and depth-first search, highlighting the graph properties they can capture on top of 1-WL. Our code is available at https://github.com/seanli3/lvc.

**摘要:** 近年来,对基于Weisfeiler-Lehman(1-WL)框架以外的图神经网络的表达能力进行了大量研究,其中许多研究都取得了表达能力的提高,但这些研究往往以效率降低为代价,或仅限于特定类型的图形。本研究中,我们从图形搜索的角度对GNN的表达能力进行了研究。具体地,我们提出了一种新的顶点颜色方案,并证明经典搜索算法能够有效地计算在1-WL以外的图形表现。我们展示了颜色方案继承了图形搜索中有用的特性,可以帮助解决像图形双联性这样的问题。为了进一步研究提议的方案,我们开发了一个基于两个搜索策略的新型GNN,即宽度搜索和深度搜索,突出他们能够在1-WL上捕捉的图形特性。

**[Paper URL](https://proceedings.mlr.press/v202/li23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23n/li23n.pdf)** 

# Analysis of Error Feedback in Federated Non-Convex Optimization with Biased Compression: Fast Convergence and Partial Participation
**题目:** 偏差压缩联合非凸优化误差反馈分析:快速收敛与部分参与

**作者:** Xiaoyun Li, Ping Li

**Abstract:** In practical federated learning (FL) systems, the communication cost between the clients and the central server can often be a bottleneck. In this paper, we focus on biased gradient compression in non-convex FL problems. In the classical distributed learning, the method of error feedback (EF) is a common technique to remedy the downsides of biased gradient compression, but the performance of EF in FL still lacks systematic investigation. In this work, we study a compressed FL scheme with error feedback, named Fed-EF, with two variants depending on the global model optimizer. While directly applying biased compression in FL leads to poor convergence, we show that Fed-EF is able to match the convergence rate of the full-precision FL counterpart with a linear speedup w.r.t. the number of clients. Experiments verify that Fed-EF achieves the same performance as the full-precision FL approach, at the substantially reduced communication cost. Moreover, we develop a new analysis of the EF under partial participation (PP), an important scenario in FL. Under PP, the convergence rate of Fed-EF exhibits an extra slow-down factor due to a so-called “stale error compensation” effect, which is also justified in our experiments. Our results provide insights on a theoretical limitation of EF, and possible directions for improvements.

**摘要:** 在实际联合学习(FL)系统中,客户与中央服务器之间的通信成本往往是瓶颈。本文着重于非凸的FL问题中的偏差梯度压缩。在经典分布式学习中,误差反馈(EF)是纠正偏差梯度压缩的常见技术,但EF在FL的性能仍缺乏系统性研究。本文研究了基于全球模型优化的两种变量,以Fed-EF为名,具有误差反馈的压缩FL方案。此外,我们还开发了FL的一个重要场景,即部分参与(PP)下的EF的新的分析。在PP下,美联储-EF的收敛率由于所谓的“停滞误差补偿”效应显示出额外的减速因子,这在我们的实验中也是合理的。我们的结果提供了对EF的理论限制以及改进的可能方向的洞察。

**[Paper URL](https://proceedings.mlr.press/v202/li23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23o/li23o.pdf)** 

# How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding
**题目:** 变换器如何学习主题结构:走向机械理解

**作者:** Yuchen Li, Yuanzhi Li, Andrej Risteski

**Abstract:** While the successes of transformers across many domains are indisputable, accurate understanding of the learning mechanics is still largely lacking. Their capabilities have been probed on benchmarks which include a variety of structured and reasoning tasks—but mathematical understanding is lagging substantially behind. Recent lines of work have begun studying representational aspects of this question: that is, the size/depth/complexity of attention-based networks to perform certain tasks. However, there is no guarantee the learning dynamics will converge to the constructions proposed. In our paper, we provide fine-grained mechanistic understanding of how transformers learn “semantic structure”, understood as capturing co-occurrence structure of words. Precisely, we show, through a combination of mathematical analysis and experiments on Wikipedia data and synthetic data modeled by Latent Dirichlet Allocation (LDA), that the embedding layer and the self-attention layer encode the topical structure. In the former case, this manifests as higher average inner product of embeddings between same-topic words. In the latter, it manifests as higher average pairwise attention between same-topic words. The mathematical results involve several assumptions to make the analysis tractable, which we verify on data, and might be of independent interest as well.

**摘要:** 尽管在许多领域中变换器的成功是不可争辩的,但学习力学的准确理解仍然十分缺乏。它们的能力已经在包括各种结构和推理任务的基准上进行测试,但数学的理解却远远落后。最近的工作开始研究这一问题的代表性方面:即,以注意力为基础的网络的大小/深度/复杂性来执行某些任务。然而,没有保证学习力学将趋于拟议的结构。通过由Latent Dirichlet Allocation(LDA)建模的维基百科数据和合成数据的数学分析和实验相结合,我们证明嵌入层和自注意层编码了主题结构。

**[Paper URL](https://proceedings.mlr.press/v202/li23p.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23p/li23p.pdf)** 

# BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models
**题目:** BLIP-2:用冻结图像编码器和大型语言模型启动语言-图像预训练

**作者:** Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi

**Abstract:** The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models. This paper proposes BLIP-2, a generic and efficient pre-training strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pre-trained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model’s emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.

**摘要:** 视觉和语言预训练的成本由于大规模模型的最终培训变得越来越低廉。本论文提出了一种通用和有效的预训练策略BLIP-2,它将从架空冻结的预训练图像编码器和冻结的大型语言模型中启动视觉语言预训练。BLIP-2通过一个轻量查询变换器,将预训练在两个阶段。第一阶段将从冻结的图像编码器 bootstraps视觉语言表现学习。第二阶段将从冻结的语言模型 bootstraps视觉语言生成学习。BLIP-2在不同视觉语言任务上取得最先进的性能,尽管有比现有方法更少的可训练参数。同时,我们还展示了该模型能够遵循自然语言指令的零拍图像到文本生成的新功能。

**[Paper URL](https://proceedings.mlr.press/v202/li23q.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23q/li23q.pdf)** 

# Nearly Optimal Algorithms with Sublinear Computational Complexity for Online Kernel Regression
**题目:** 基于次线性计算复杂度的近最佳算法用于在线核回归

**作者:** Junfan Li, Shizhong Liao

**Abstract:** The trade-off between regret and computational cost is a fundamental problem for online kernel regression, and previous algorithms worked on the trade-off can not keep optimal regret bounds at a sublinear computational complexity. In this paper, we propose two new algorithms, AOGD-ALD and NONS-ALD, which can keep nearly optimal regret bounds at a sublinear computational complexity, and give sufficient conditions under which our algorithms work. Both algorithms dynamically maintain a group of nearly orthogonal basis used to approximate the kernel mapping, and keep nearly optimal regret bounds by controlling the approximate error. The number of basis depends on the approximate error and the decay rate of eigenvalues of the kernel matrix. If the eigenvalues decay exponentially, then AOGD-ALD and NONS-ALD separately achieves a regret of $O(\sqrt{L(f)})$ and $O(\mathrm{d}_{\mathrm{eff}}(\mu)\ln{T})$ at a computational complexity in $O(\ln^2{T})$. If the eigenvalues decay polynomially with degree $p\geq 1$, then our algorithms keep the same regret bounds at a computational complexity in $o(T)$ in the case of $p>4$ and $p\geq 10$, respectively. $L(f)$ is the cumulative losses of $f$ and $\mathrm{d}_{\mathrm{eff}}(\mu)$ is the effective dimension of the problem. The two regret bounds are nearly optimal and are not comparable.

**摘要:** 遗憾与计算成本的权衡是在线内核回归的一个基本问题,以前的算法不能在次线性计算复杂度上保持最佳遗憾边界。本文提出了两个新的算法,AOGD-ALD和NOS-ALD,它们可以在次线性计算复杂度上保持接近最佳遗憾边界,并提供充分条件,使我们的算法工作。这两个算法动态地保持一个近正交基准用于近似内核映射的基准,并通过控制近似误差保持近似最佳遗憾边界。基准的数目取决于内核矩阵的近似误差和自值的衰减率。如果自值指数衰减,那么AOGD-ALD和NOS-ALD分别取得$O(\sqrt{L(f)})$和$O(\mathrm{d}_{\mathrm{eff如果 eigenvalues 具有 degree $p\geq 1$ 的多项式衰减,那么我们的算法在 $p>4$ 和 $p\geq 10$ 的计算复杂度下保持相同的遗憾边界。 $L(f)$ 是 $f$ 的累积损失, $\mathrm{d}_{\mathrm{eff}}(\mu)$ 是问题的有效维度。

**[Paper URL](https://proceedings.mlr.press/v202/li23r.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23r/li23r.pdf)** 

# Revisiting Weighted Aggregation in Federated Learning with Neural Networks
**题目:** 神经网络联合学习中的权重gregation的回顾

**作者:** Zexi Li, Tao Lin, Xinyi Shang, Chao Wu

**Abstract:** In federated learning (FL), weighted aggregation of local models is conducted to generate a global model, and the aggregation weights are normalized (the sum of weights is 1) and proportional to the local data sizes. In this paper, we revisit the weighted aggregation process and gain new insights into the training dynamics of FL. First, we find that the sum of weights can be smaller than 1, causing global weight shrinking effect (analogous to weight decay) and improving generalization. We explore how the optimal shrinking factor is affected by clients’ data heterogeneity and local epochs. Second, we dive into the relative aggregation weights among clients to depict the clients’ importance. We develop client coherence to study the learning dynamics and find a critical point that exists. Before entering the critical point, more coherent clients play more essential roles in generalization. Based on the above insights, we propose an effective method for Federated Learning with Learnable Aggregation Weights, named as FedLAW. Extensive experiments verify that our method can improve the generalization of the global model by a large margin on different datasets and models.

**摘要:** 在联合学习中,对局部模型进行权重聚合,以生成一个全球模型,并使聚合权重标准化(权重的总数为1),并与局部数据大小相称。本文回顾了权重聚合过程,并获得对FL训练动力学的新洞察。首先,我们发现权重的总数可以小于1,导致全球权重缩小效应(类似于权重衰变)和改进广义化。我们探讨了如何影响客户数据异质性和局部时代的最佳缩小因素。其次,我们深入客户间的相对聚合权重来描述客户的重要性。我们开发了客户一致性来研究学习动力学并找到存在的关键点。基于上述洞察,我们提出了一种有效的Federated Learning with Learnable Aggregation Weights(英语:Federated Learning with Learnable Aggregation Weights)方法,称为FedLAW(英语:Federated Learning with Learnable Aggregation Weights)。

**[Paper URL](https://proceedings.mlr.press/v202/li23s.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23s/li23s.pdf)** 

# Distribution-dependent McDiarmid-type Inequalities for Functions of Unbounded Interaction
**题目:** 无界相互作用函数的分布依赖性麦迪亚米德类型不等式

**作者:** Shaojie Li, Yong Liu

**Abstract:** The concentration of measure inequalities serves an essential role in statistics and machine learning. This paper gives unbounded analogues of the McDiarmid-type exponential inequalities for three popular classes of distributions, namely sub-Gaussian, sub-exponential and heavy-tailed distributions. The inequalities in the sub-Gaussian and sub-exponential cases are distribution-dependent compared with the recent results, and the inequalities in the heavy-tailed case are not available in the previous works. The usefulness of the inequalities is illustrated through applications to the sample mean, U-statistics and V-statistics.

**摘要:** 测量不平等的浓度在统计学和机器学习中起着重要的作用。本文给出了三类分布的麦克迪亚米式指数不平等的无界模拟,分别是次古斯分布、次指数分布和重尾分布。次古斯分布和次指数分布的不平等与最近的结果相比是分布依赖的,重尾分布的不平等与前作无关。

**[Paper URL](https://proceedings.mlr.press/v202/li23t.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23t/li23t.pdf)** 

# Optimal Convergence Rates for Agnostic Nyström Kernel Learning
**题目:** 最佳收敛速率,用于敏捷尼斯通核学习

**作者:** Jian Li, Yong Liu, Weiping Wang

**Abstract:** Nyström low-rank approximation has shown great potential in processing large-scale kernel matrix and neural networks. However, there lacks a unified analysis for Nyström approximation, and the asymptotical minimax optimality for Nyström methods usually require a strict condition, assuming that the target regression lies exactly in the hypothesis space. In this paper, to tackle these problems, we provide a refined generalization analysis for Nyström approximation in the agnostic setting, where the target regression may be out of the hypothesis space. Specifically, we show Nyström approximation can still achieve the capacity-dependent optimal rates in the agnostic setting. To this end, we first prove the capacity-dependent optimal guarantees of Nyström approximation with the standard uniform sampling, which covers both loss functions and applies to some agnostic settings. Then, using data-dependent sampling, for example, leverage scores sampling, we derive the capacity-dependent optimal rates that apply to the whole range of the agnostic setting. To our best knowledge, the capacity-dependent optimality for the whole range of the agnostic setting is first achieved and novel in Nyström approximation.

**摘要:** 尼斯通低级近似方法在处理大规模内核矩阵和神经网络方面具有巨大的潜力。然而,对于尼斯通近似方法缺乏统一的分析,而尼斯通方法的渐近最小值优化通常需要严格条件,假设目标回归完全位于假设空间中。为了解决这些问题,本文为尼斯通近似提供了精细的一般化分析,在 agnostic环境中,目标回归可能不在假设空间中。具体地,我们表明尼斯通近似方法在 agnostic环境中仍然能够达到容量依赖的最优率。为此目的,我们首先通过标准统一样本证明了尼斯通近似的容量依赖的最优保证,它涵盖了损失函数,并适用于某些 agnostic环境。然后,使用数据依赖的采样,例如杠杆分数采样,我们导出适用于整个 agnostic设置的容量依赖的最优率。我们最了解的是,整个 agnostic设置的容量依赖的最优率首先在Nyström近似中得到了实现。

**[Paper URL](https://proceedings.mlr.press/v202/li23u.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23u/li23u.pdf)** 

# Reconstructive Neuron Pruning for Backdoor Defense
**题目:** 后门防护重建神经 Pruning

**作者:** Yige Li, Xixiang Lyu, Xingjun Ma, Nodens Koren, Lingjuan Lyu, Bo Li, Yu-Gang Jiang

**Abstract:** Deep neural networks (DNNs) have been found to be vulnerable to backdoor attacks, raising security concerns about their deployment in mission-critical applications. While existing defense methods have demonstrated promising results, it is still not clear how to effectively remove backdoor-associated neurons in backdoored DNNs. In this paper, we propose a novel defense called Reconstructive Neuron Pruning (RNP) to expose and prune backdoor neurons via an unlearning and then recovering process. Specifically, RNP first unlearns the neurons by maximizing the model’s error on a small subset of clean samples and then recovers the neurons by minimizing the model’s error on the same data. In RNP, unlearning is operated at the neuron level while recovering is operated at the filter level, forming an asymmetric reconstructive learning procedure. We show that such an asymmetric process on only a few clean samples can effectively expose and prune the backdoor neurons implanted by a wide range of attacks, achieving a new state-of-the-art defense performance. Moreover, the unlearned model at the intermediate step of our RNP can be directly used to improve other backdoor defense tasks including backdoor removal, trigger recovery, backdoor label detection, and backdoor sample detection. Code is available at https://github.com/bboylyg/RNP.

**摘要:** 深层神经网络(DNNs)被发现易受后门攻击,对它们在任务关键应用中部署具有安全性问题。虽然现有的防护方法已显示出有前途的成果,但仍不清楚如何有效地消除后门关联神经元在后门DNNs中。本论文提出了一种新的防护方法,即重建神经元预 pruning(RNP),以暴露和剪切后门神经元,然后恢复过程。具体而言,RNP首先通过在清洁样品小部分上最大化模型误差,然后通过在相同数据上最小化模型误差,恢复神经元。我们证明,只有少数清洁的样品上,这样的不对称过程能够有效地暴露和剪切由广泛的攻击所植入的后门神经元,从而达到最先进的防护性能。此外,我们RNP的中间阶段的未学过的模型可以直接用于改进其他后门防护任务,包括后门除去、触发恢复、后门标签检测和后门样品检测。

**[Paper URL](https://proceedings.mlr.press/v202/li23v.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23v/li23v.pdf)** 

# Meta Learning of Interface Conditions for Multi-Domain Physics-Informed Neural Networks
**题目:** 多域物理学习神经网络的接口条件的元学习

**作者:** Shibo Li, Michael Penwarden, Yiming Xu, Conor Tillinghast, Akil Narayan, Mike Kirby, Shandian Zhe

**Abstract:** Physics-informed neural networks (PINNs) are emerging as popular mesh-free solvers for partial differential equations (PDEs). Recent extensions decompose the domain, apply different PINNs to solve the problem in each subdomain, and stitch the subdomains at the interface. Thereby, they can further alleviate the problem complexity, reduce the computational cost, and allow parallelization. However, the performance of multi-domain PINNs is sensitive to the choice of the interface conditions. While quite a few conditions have been proposed, there is no suggestion about how to select the conditions according to specific problems. To address this gap, we propose META Learning of Interface Conditions (METALIC), a simple, efficient yet powerful approach to dynamically determine appropriate interface conditions for solving a family of parametric PDEs. Specifically, we develop two contextual multi-arm bandit (MAB) models. The first one applies to the entire training course, and online updates a Gaussian process (GP) reward that given the PDE parameters and interface conditions predicts the performance. We prove a sub-linear regret bound for both UCB and Thompson sampling, which in theory guarantees the effectiveness of our MAB. The second one partitions the training into two stages, one is the stochastic phase and the other deterministic phase; we update a GP reward for each phase to enable different condition selections at the two stages to further bolster the flexibility and performance. We have shown the advantage of METALIC on four bench-mark PDE families.

**摘要:** 物理信息神经网络(PINNs)作为部分微分方程(PDEs)的流行网格自由解决方案正在出现。最近的扩展将域分解,应用不同的PINNs来解决每个子域的问题,并在接口上缝合子域。这样,它们可以进一步缓解问题复杂性,降低计算成本,并允许平行化。然而,多域PINNs的性能对接口条件的选择敏感。虽然已经提议了一些条件,但没有关于如何根据具体问题选择条件的建议。第一个应用于整个培训课程,并在线更新了高斯过程(GP)奖励,它根据PDE参数和界面条件预测性能。我们证明了对UCB和汤普森样本的非线性遗憾,理论上保证了我们的MAB的有效性。第二个将培训分为两个阶段,一个是随机阶段,另一个是确定阶段;我们更新了每个阶段的GP奖励,使两个阶段的条件选择能够进一步增强灵活性和性能。

**[Paper URL](https://proceedings.mlr.press/v202/li23w.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23w/li23w.pdf)** 

# Deep Anomaly Detection under Labeling Budget Constraints
**题目:** 标签预算限制下深度异常检测

**作者:** Aodong Li, Chen Qiu, Marius Kloft, Padhraic Smyth, Stephan Mandt, Maja Rudolph

**Abstract:** Selecting informative data points for expert feedback can significantly improve the performance of anomaly detection (AD) in various contexts, such as medical diagnostics or fraud detection. In this paper, we determine a set of theoretical conditions under which anomaly scores generalize from labeled queries to unlabeled data. Motivated by these results, we propose a data labeling strategy with optimal data coverage under labeling budget constraints. In addition, we propose a new learning framework for semi-supervised AD. Extensive experiments on image, tabular, and video data sets show that our approach results in state-of-the-art semi-supervised AD performance under labeling budget constraints.

**摘要:** 为专家反馈选择信息性数据点,可以显著提高异常检测(AD)在医学诊断或欺诈检测等各个方面的表现。本文确定了从标记查询到未标记数据的异常分数的理论条件,并根据这些结果,提出了一种在标记预算约束下最佳数据覆盖的数据标记策略。此外,我们提出了一种半监督AD的新学习框架。

**[Paper URL](https://proceedings.mlr.press/v202/li23x.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23x/li23x.pdf)** 

# On the Initialization of Graph Neural Networks
**题目:** 图神经网络的初始化

**作者:** Jiahang Li, Yakun Song, Xiang Song, David Wipf

**Abstract:** Graph Neural Networks (GNNs) have displayed considerable promise in graph representation learning across various applications. The core learning process requires the initialization of model weight matrices within each GNN layer, which is typically accomplished via classic initialization methods such as Xavier initialization. However, these methods were originally motivated to stabilize the variance of hidden embeddings and gradients across layers of Feedforward Neural Networks (FNNs) and Convolutional Neural Networks (CNNs) to avoid vanishing gradients and maintain steady information flow. In contrast, within the GNN context classical initializations disregard the impact of the input graph structure and message passing on variance. In this paper, we analyze the variance of forward and backward propagation across GNN layers and show that the variance instability of GNN initializations comes from the combined effect of the activation function, hidden dimension, graph structure and message passing. To better account for these influence factors, we propose a new initialization method for Variance Instability Reduction within GNN Optimization (Virgo), which naturally tends to equate forward and backward variances across successive layers. We conduct comprehensive experiments on 15 datasets to show that Virgo can lead to superior model performance and more stable variance at initialization on node classification, link prediction and graph classification tasks.

**摘要:** 图神经网络(GNNs)在不同应用中显示了图表示学习的显著前景。核心学习过程要求在每个GNN层内初始化模型重矩阵,通常通过经典初始化方法如Xavier初始化完成。然而,这些方法最初被动机化以稳定隐藏嵌入和梯度的变异在Feedforward神经网络(FNNs)和Convolutional神经网络(CNNs)各层之间,以避免消失梯度和保持稳定的信息流。本文分析了GNN层间前后传播的变量,并表明GNN初始化中变量不稳定是由于激活函数、隐藏维度、图结构和消息传递的综合作用而产生的。为了更好地考虑这些影响因素,我们提出了一种在GNN优化中变量不稳定性降低的新初始化方法(Virgo),它自然地倾向于在连续层间等同前后变量。

**[Paper URL](https://proceedings.mlr.press/v202/li23y.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23y/li23y.pdf)** 

# Federated Adversarial Learning: A Framework with Convergence Analysis
**题目:** 联合敌对学习:融合分析框架

**作者:** Xiaoxiao Li, Zhao Song, Jiaming Yang

**Abstract:** Federated learning (FL) is a trending training paradigm to utilize decentralized training data. FL allows clients to update model parameters locally for several epochs, then share them to a global model for aggregation. This training paradigm with multi-local step updating before aggregation exposes unique vulnerabilities to adversarial attacks. Adversarial training is a popular and effective method to improve the robustness of networks against adversaries. In this work, we formulate a general form of federated adversarial learning (FAL) that is adapted from adversarial learning in the centralized setting. On the client side of FL training, FAL has an inner loop to generate adversarial samples for adversarial training and an outer loop to update local model parameters. On the server side, FAL aggregates local model updates and broadcast the aggregated model. We design a global robust training loss and formulate FAL training as a min-max optimization problem. Unlike the convergence analysis in classical centralized training that relies on the gradient direction, it is significantly harder to analyze the convergence in FAL for three reasons: 1) the complexity of min-max optimization, 2) model not updating in the gradient direction due to the multi-local updates on the client-side before aggregation and 3) inter-client heterogeneity. We address these challenges by using appropriate gradient approximation and coupling techniques and present the convergence analysis in the over-parameterized regime. Our main result theoretically shows that the minimum loss under our algorithm can converge to $\epsilon$ small with chosen learning rate and communication rounds. It is noteworthy that our analysis is feasible for non-IID clients.

**摘要:** 联合学习(FL)是利用分散训练数据的趋势培训范式。FL允许客户为多个时代本地更新模型参数,然后将其分发给全球模型进行集群。在集群之前,该培训范式具有多个局部步骤的更新,暴露了对敌对攻击的独特脆弱性。敌对训练是提高网络对敌对的鲁棒性的一种流行有效的方法。在这个工作中,我们制订了从集中设置中适应敌对学习的联合敌对学习(FAL)的一般形式。在FL培训的客户方面,FAL有一个内环生成敌对训练样本和外部环更新本地模型参数。与基于梯度方向的经典集中训练中的收敛分析不同,FAL的收敛分析有三个原因:(一)最小最大优化的复杂性,(二)由于在集群前在客户端侧的多局域更新而没有在梯度方向更新的模型,以及(三)在客户端间的异质性。我们通过适当的梯度近似和耦合技术解决这些问题,并在超参数化模式中提出收敛分析。我们的主要理论结果表明,我们算法下的最小损失可以在选择学习率和通信周期下收敛到$\epsilon$小。

**[Paper URL](https://proceedings.mlr.press/v202/li23z.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23z/li23z.pdf)** 

# How Powerful are Shallow Neural Networks with Bandlimited Random Weights?
**题目:** 带限制随机重量的阴暗神经网络是多么强大的?

**作者:** Ming Li, Sho Sonoda, Feilong Cao, Yu Guang Wang, Jiye Liang

**Abstract:** We investigate the expressive power of depth-2 bandlimited random neural networks. A random net is a neural network where the hidden layer parameters are frozen with random assignment, and only the output layer parameters are trained by loss minimization. Using random weights for a hidden layer is an effective method to avoid non-convex optimization in standard gradient descent learning. It has also been adopted in recent deep learning theories. Despite the well-known fact that a neural network is a universal approximator, in this study, we mathematically show that when hidden parameters are distributed in a bounded domain, the network may not achieve zero approximation error. In particular, we derive a new nontrivial approximation error lower bound. The proof utilizes the technique of ridgelet analysis, a harmonic analysis method designed for neural networks. This method is inspired by fundamental principles in classical signal processing, specifically the idea that signals with limited bandwidth may not always be able to perfectly reconstruct the original signal. We corroborate our theoretical results with various simulation studies, and generally, two main take-home messages are offered: (i) Not any distribution for selecting random weights is feasible to build a universal approximator; (ii) A suitable assignment of random weights exists but to some degree is associated with the complexity of the target function.

**摘要:** 我们研究了深度-2带限制的随机神经网络的表达能力。随机网络是隐藏层参数与随机分配冻结的神经网络,只有输出层参数被训练以减少损失。使用隐藏层的随机权重是避免在标准梯度下降学习中非凸优化的有效方法。该方法以经典信号处理的基本原理为灵感,特别是带宽有限的信号可能不能完全重建原始信号的想法。我们通过各种仿真研究证实了我们的理论结果,并给出了两个主要的归纳信息: (i)在建立通用近似器时,选择随机权重的分配是不可能的; (ii)随机权重的适当分配存在,但在一定程度上与目标函数的复杂性有关。

**[Paper URL](https://proceedings.mlr.press/v202/li23aa.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23aa/li23aa.pdf)** 

# Efficient Quantum Algorithms for Quantum Optimal Control
**题目:** 量子优化控制的高效量子算法

**作者:** Xiantao Li, Chunhao Wang

**Abstract:** In this paper, we present efficient quantum algorithms that are exponentially faster than classical algorithms for solving the quantum optimal control problem. This problem involves finding the control variable that maximizes a physical quantity at time $T$, where the system is governed by a time-dependent Schrödinger equation. This type of control problem also has an intricate relation with machine learning. Our algorithms are based on a time-dependent Hamiltonian simulation method and a fast gradient-estimation algorithm. We also provide a comprehensive error analysis to quantify the total error from various steps, such as the finite-dimensional representation of the control function, the discretization of the Schrödinger equation, the numerical quadrature, and optimization. Our quantum algorithms require fault-tolerant quantum computers.

**摘要:** 本文给出了较经典算法快速解决量子优化控制问题的有效量子算法。该算法涉及在系统由时间依赖 Schrödinger方程控制时,最大化物理量子时$T$的控制变量。该类型的控制问题也与机器学习有着复杂的关系。我们的算法基于时间依赖汉密尔顿模拟方法和快速梯度估计算法。我们还提供了一个全面误差分析,以量化各个步骤的总误差,例如控制函数的有限维表示、Schrödinger方程的离散化、数二次和优化。

**[Paper URL](https://proceedings.mlr.press/v202/li23ab.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23ab/li23ab.pdf)** 

# Low-Switching Policy Gradient with Exploration via Online Sensitivity Sampling
**题目:** 通过在线敏感度样本进行探索的低调策略梯度

**作者:** Yunfan Li, Yiran Wang, Yu Cheng, Lin Yang

**Abstract:** Policy optimization methods are powerful algorithms in Reinforcement Learning (RL) for their flexibility to deal with policy parameterization and ability to handle model misspecification. However, these methods usually suffer from slow convergence rates and poor sample complexity. Hence it is important to design provably sample efficient algorithms for policy optimization. Yet, recent advances for this problems have only been successful in tabular and linear setting, whose benign structures cannot be generalized to non-linearly parameterized policies. In this paper, we address this problem by leveraging recent advances in value-based algorithms, including bounded eluder-dimension and online sensitivity sampling, to design a low-switching sample-efficient policy optimization algorithm, LPO, with general non-linear function approximation. We show that, our algorithm obtains an $\varepsilon$-optimal policy with only $\widetilde{O}(\frac{\text{poly}(d)}{\varepsilon^3})$ samples, where $\varepsilon$ is the suboptimality gap and $d$ is a complexity measure of the function class approximating the policy. This drastically improves previously best-known sample bound for policy optimization algorithms, $\widetilde{O}(\frac{\text{poly}(d)}{\varepsilon^8})$. Moreover, we empirically test our theory with deep neural nets to show the benefits of the theoretical inspiration.

**摘要:** 政策优化方法在增强学习中具有灵活性,可以处理政策参数化和处理模型误标的能力。然而,这些方法通常会受到慢收敛率和低样品复杂性的影响。因此,为政策优化设计可证明的有效样品算法是很重要的。然而,对于这一问题,最近的进展只在表格和线性设置中取得了成功,其良性结构不能推广到非线性参数化政策。我们证明,我们的算法只用$widetilde{O}(\frac{\text{poly}(d)}{\varepsilon^3})$样本获得$varepsilon$-optimal策略,其中$varepsilon$是次优差,$d$是函数类近似策略的复杂度测量。这大大改善了以前最著名的样本约束策略优化算法,$widetilde{O}(\frac{\text{poly}(d)}{\varepsilon^8})$。

**[Paper URL](https://proceedings.mlr.press/v202/li23ac.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23ac/li23ac.pdf)** 

# Hierarchical Diffusion for Offline Decision Making
**题目:** 网上决策的层次分化

**作者:** Wenhao Li, Xiangfeng Wang, Bo Jin, Hongyuan Zha

**Abstract:** Offline reinforcement learning typically introduces a hierarchical structure to solve the long-horizon problem so as to address its thorny issue of variance accumulation. Problems of deadly triad, limited data and reward sparsity, however, still remain, rendering the design of effective, hierarchical offline RL algorithms for general-purpose policy learning a formidable challenge. In this paper, we first formulate the problem of offline long-horizon decision-$\mathbf{M}$ak$\mathbf{I}$ng from the perspective of conditional generative modeling by incorporating goals into the control-as-inference graphic models. A $\mathbf{H}$ierarchical trajectory-level $\mathbf{D}$iffusion probabilistic model is then proposed with classifier-free guidance. HDMI employs a cascade framework that utilizes the reward-conditional goal diffuser for the subgoal discovery and the goal-conditional trajectory diffuser for generating the corresponding action sequence of subgoals. Planning-based subgoal extraction and transformer-based diffusion are employed to deal with the sub-optimal data pollution and long-range subgoal dependencies in the goal diffusion. Numerical experiments verify the advantages of HDMI on long-horizon decision-making compared to SOTA offline RL methods and conditional generative models.

**摘要:** 非线性强化学习通常引入层次结构来解决长期水平问题,以解决其变量累积的棘手问题。然而,致命的三角形、有限的数据和奖励稀缺问题仍然存在,使得对一般目的政策学习的有效、层次性非线性RL算法的设计是一个艰巨的挑战。本文首先从条件生成模型的视角对非线性长期水平决策-$\mathbf{M}$ak$\mathbf{I}$ng问题进行了公式,通过将目标纳入控制-as-inference图形模型,提出了一种非线性轨迹级$\mathbf{D}$扩散概率模型。基于规划的次目标提取和基于变压器的扩散是解决目标扩散中的次优数据污染和远距离次目标依赖的手段。数值实验验证了HDMI在长期决策方面的优势,与SOTA非线性RL方法和条件生成模型相比。

**[Paper URL](https://proceedings.mlr.press/v202/li23ad.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23ad/li23ad.pdf)** 

# Divide and Conquer Dynamic Programming: An Almost Linear Time Change Point Detection Methodology in High Dimensions
**题目:** 动态编程的分割与征服:高维时差点检测方法

**作者:** Wanshan Li, Daren Wang, Alessandro Rinaldo

**Abstract:** We develop a novel, general and computationally efficient framework, called Divide and Conquer Dynamic Programming (DCDP), for localizing change points in time series data with high-dimensional features. DCDP deploys a class of greedy algorithms that are applicable to a broad variety of high-dimensional statistical models and can enjoy almost linear computational complexity. We investigate the performance of DCDP in three commonly studied change point settings in high dimensions: the mean model, the Gaussian graphical model, and the linear regression model. In all three cases, we derive non-asymptotic bounds for the accuracy of the DCDP change point estimators. We demonstrate that the DCDP procedures consistently estimate the change points with sharp, and in some cases, optimal rates while incurring significantly smaller computational costs than the best available algorithms. Our findings are supported by extensive numerical experiments on both synthetic and real data.

**摘要:** 我们开发了一种新的、通用和计算效率高的框架,称为“分割和征服动态规划”(Divide and Conquer Dynamic Programming,DCDP),用于以高维特征定位时间序列数据中的变化点。DCDP部署了一种广泛应用于高维统计模型的贪婪算法,并且几乎具有线性计算复杂性。我们研究了高维中三个常被研究的变化点设置的DCDP性能:平均模型、高斯图形模型和线性回归模型。在所有三个情况下,我们得出DCDP变化点估计器的准确性非渐近边界。

**[Paper URL](https://proceedings.mlr.press/v202/li23ae.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23ae/li23ae.pdf)** 

# Architecture-Agnostic Masked Image Modeling -- From ViT back to CNN
**题目:** 建筑-神学蒙蔽图像建模--从ViT回到CNN

**作者:** Siyuan Li, Di Wu, Fang Wu, Zelin Zang, Stan Z. Li

**Abstract:** Masked image modeling, an emerging self-supervised pre-training method, has shown impressive success across numerous downstream vision tasks with Vision transformers. Its underlying idea is simple: a portion of the input image is masked out and then reconstructed via a pre-text task. However, the working principle behind MIM is not well explained, and previous studies insist that MIM primarily works for the Transformer family but is incompatible with CNNs. In this work, we observe that MIM essentially teaches the model to learn better middle-order interactions among patches for more generalized feature extraction. We then propose an Architecture-Agnostic Masked Image Modeling framework (A$^2$MIM), which is compatible with both Transformers and CNNs in a unified way. Extensive experiments on popular benchmarks show that A$^2$MIM learns better representations without explicit design and endows the backbone model with the stronger capability to transfer to various downstream tasks.

**摘要:** 隐形图像建模,一种新兴的自我监督预培训方法,在众多下游视图任务中显示出令人印象深刻的成功,其基本思想很简单:输入图像的部分被掩盖出来,然后通过预文本任务重建。然而,MIM背后的工作原理没有得到很好的解释,而以前的研究坚持,MIM主要用于变换器家族,但与CNN不兼容。在这个工作中,我们观察到MIM基本上教导模型学习更通用特征提取的补丁之间更好的中级交互。

**[Paper URL](https://proceedings.mlr.press/v202/li23af.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23af/li23af.pdf)** 

# Learning Antidote Data to Individual Unfairness
**题目:** 学习对个人不公平行为的抗药数据

**作者:** Peizhao Li, Ethan Xia, Hongfu Liu

**Abstract:** Fairness is essential for machine learning systems deployed in high-stake applications. Among all fairness notions, individual fairness, deriving from a consensus that ‘similar individuals should be treated similarly,’ is a vital notion to describe fair treatment for individual cases. Previous studies typically characterize individual fairness as a prediction-invariant problem when perturbing sensitive attributes on samples, and solve it by Distributionally Robust Optimization (DRO) paradigm. However, such adversarial perturbations along a direction covering sensitive information used in DRO do not consider the inherent feature correlations or innate data constraints, therefore could mislead the model to optimize at off-manifold and unrealistic samples. In light of this drawback, in this paper, we propose to learn and generate antidote data that approximately follows the data distribution to remedy individual unfairness. These generated on-manifold antidote data can be used through a generic optimization procedure along with original training data, resulting in a pure pre-processing approach to individual unfairness, or can also fit well with the in-processing DRO paradigm. Through extensive experiments on multiple tabular datasets, we demonstrate our method resists individual unfairness at a minimal or zero cost to predictive utility compared to baselines.

**摘要:** 公平是应用于高风险应用的机器学习系统中必不可少的。在所有公平概念中,个人公平是基于“相似的个体应被同等地对待”的共识的一个重要概念,以描述个别案例的公平处理。以往的研究通常将个人公平描述为在样品上扰动敏感属性时的预测不变问题,并通过分布性鲁棒优化(DRO)范式来解决这个问题。然而,在DRO中使用敏感信息的方向上,这种敌对扰动并不考虑固有特征相关性或天生的数据约束,因此可能误导模型在非多变性和不现实样品上优化。这些生成的多组抗药数据可通过通用优化程序与原始训练数据一起使用,从而实现对个人不公平行为的纯预处理方法,也可以很好地适应处理中的DRO范式。通过对多个表格数据集的广泛实验,我们证明了我们的方法能够对个人不公平行为产生最小或零成本的预测效用,与基线相比。

**[Paper URL](https://proceedings.mlr.press/v202/li23ag.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23ag/li23ag.pdf)** 

# Propensity Matters: Measuring and Enhancing Balancing for Recommendation
**题目:** 倾向问题:衡量和加强建议的平衡

**作者:** Haoxuan Li, Yanghao Xiao, Chunyuan Zheng, Peng Wu, Peng Cui

**Abstract:** Propensity-based weighting methods have been widely studied and demonstrated competitive performance in debiased recommendations. Nevertheless, there are still many questions to be addressed. How to estimate the propensity more conducive to debiasing performance? Which metric is more reasonable to measure the quality of the learned propensities? Is it better to make the cross-entropy loss as small as possible when learning propensities? In this paper, we first discuss the potential problems of the previously widely adopted metrics for learned propensities, and propose balanced-mean-squared-error (BMSE) metric for debiased recommendations. Based on BMSE, we propose IPS-V2 and DR-V2 as the estimators of unbiased loss, and theoretically show that IPS-V2 and DR-V2 have greater propensity balancing and smaller variance without sacrificing additional bias. We further propose a co-training method for learning balanced representation and unbiased prediction. Extensive experiments are conducted on three real-world datasets including a large industrial dataset, and the results show that our approach boosts the balancing property and results in enhanced debiasing performance.

**摘要:** 基于倾向的权重方法已经广泛研究并证明了偏见建议中的竞争性性能。然而,仍有许多问题需要解决。如何估计偏见建议的倾向更有利于偏见性能?在学习偏见时,哪个度量更合理测量学习偏见的质量?在学习偏见时,是否最好尽可能减少交叉熵损失?本文首先讨论了以前广泛采用的偏见指标的潜在问题,并提出了偏见建议的平衡平均误差(BMSE)度量。基于BMSE,我们提议 IPS-V2和 DR-V2作为偏见损失的估计者,并理论上表明 IPS-V2和 DR-V2具有更大的偏见平衡和较小的变异,而不牺牲额外偏见。对包括大型工业数据集在内的三个实物数据集进行了广泛实验,结果表明,我们的方法提高了平衡性能,提高了偏差性能。

**[Paper URL](https://proceedings.mlr.press/v202/li23ah.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23ah/li23ah.pdf)** 

# GraphCleaner: Detecting Mislabelled Samples in Popular Graph Learning Benchmarks
**题目:** GraphCleaner:在流行的图学习标记中检测误标样品

**作者:** Yuwen Li, Miao Xiong, Bryan Hooi

**Abstract:** Label errors have been found to be prevalent in popular text, vision, and audio datasets, which heavily influence the safe development and evaluation of machine learning algorithms. Despite increasing efforts towards improving the quality of generic data types, such as images and texts, the problem of mislabel detection in graph data remains underexplored. To bridge the gap, we explore mislabelling issues in popular real-world graph datasets and propose GraphCleaner, a post-hoc method to detect and correct these mislabelled nodes in graph datasets. GraphCleaner combines the novel ideas of 1) Synthetic Mislabel Dataset Generation, which seeks to generate realistic mislabels; and 2) Neighborhood-Aware Mislabel Detection, where neighborhood dependency is exploited in both labels and base classifier predictions. Empirical evaluations on 6 datasets and 6 experimental settings demonstrate that GraphCleaner outperforms the closest baseline, with an average improvement of $0.14$ in F1 score, and $0.16$ in MCC. On real-data case studies, GraphCleaner detects real and previously unknown mislabels in popular graph benchmarks: PubMed, Cora, CiteSeer and OGB-arxiv; we find that at least 6.91% of PubMed data is mislabelled or ambiguous, and simply removing these mislabelled data can boost evaluation performance from 86.71% to 89.11%.

**摘要:** 标签误差在流行文本、视觉和音频数据集中普遍存在,这严重影响了机器学习算法的安全开发和评价。尽管对改进图像和文本等通用数据类型的质量作出了越来越多的努力,但图形数据中的错误标签检测问题仍未得到充分探讨。为了弥补这一差距,我们探讨了流行真实世界图形数据集中的错误标签问题,并提出GraphCleaner,一种在图形数据集中检测和纠正这些错误标签节点的后置方法。6个数据集和6个实验设置的实证评价表明,GraphCleaner超过了最接近的基线,平均改善了F1分数$0.14$和MCC分数$0.16$。 在实数据案例研究中,GraphCleaner在流行图标基中检测到真实和以前未知的误标: PubMed、Cora、CiteSeer和OGB-arxiv;我们发现至少6.91%的 PubMed数据是误标或含糊的,而简单的删除这些误标数据可以从86.71%提高评价性能到89.11%。

**[Paper URL](https://proceedings.mlr.press/v202/li23ai.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23ai/li23ai.pdf)** 

# SMURF-THP: Score Matching-based UnceRtainty quantiFication for Transformer Hawkes Process
**题目:** SMURF-THP:基于 Score Matching UnceRtainty quantiFication for Transformer Hawkes Process

**作者:** Zichong Li, Yanbo Xu, Simiao Zuo, Haoming Jiang, Chao Zhang, Tuo Zhao, Hongyuan Zha

**Abstract:** Transformer Hawkes process models have shown to be successful in modeling event sequence data. However, most of the existing training methods rely on maximizing the likelihood of event sequences, which involves calculating some intractable integral. Moreover, the existing methods fail to provide uncertainty quantification for model predictions, e.g., confidence interval for the predicted event’s arrival time. To address these issues, we propose SMURF-THP, a score-based method for learning Transformer Hawkes process and quantifying prediction uncertainty. Specifically, SMURF-THP learns the score function of the event’s arrival time based on a score-matching objective that avoids the intractable computation. With such a learnt score function, we can sample arrival time of events from the predictive distribution. This naturally allows for the quantification of uncertainty by computing confidence intervals over the generated samples. We conduct extensive experiments in both event type prediction and uncertainty quantification on time of arrival. In all the experiments, SMURF-THP outperforms existing likelihood-based methods in confidence calibration while exhibiting comparable prediction accuracy.

**摘要:** 变换者霍克斯过程模型在建模事件序列数据方面已显示出成功。然而,大多数现有的训练方法依赖于最大化事件序列的概率,这涉及计算一些不可解积分。此外,现有的方法未能为模型预测提供不确定性的定量,例如,预测事件到达时间的信任间隔。为了解决这些问题,我们提出了变换者霍克斯过程学习和定量预测不确定性的基于分数的方法SMURF-THP。具体而言,SMURF-THP学习了基于分数匹配目标的事件到达时间的分数函数,以避免不可解计算。我们对事件类型预测和到达时间的不确定性定量进行了广泛的实验,在所有实验中,SMURF-THP在可靠校正中超越现有基于概率的方法,同时表现出可比的预测精度。

**[Paper URL](https://proceedings.mlr.press/v202/li23aj.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23aj/li23aj.pdf)** 

# Horizon-free Learning for Markov Decision Processes and Games: Stochastically Bounded Rewards and Improved Bounds
**题目:** 马可夫决策过程和游戏的水平自由学习:随机界定的奖励和改进的界限

**作者:** Shengshi Li, Lin Yang

**Abstract:** Horizon dependence is an important difference between reinforcement learning and other machine learning paradigms. Yet, existing results tackling the (exact) horizon dependence either assume that the reward is bounded per step, introducing unfair comparison, or assume strict total boundedness that requires the sum of rewards to be bounded almost surely – allowing only restricted noise on the reward observation. This paper addresses these limitations by introducing a new relaxation – expected boundedness on rewards, where we allow the reward to be stochastic with only boundedness on the expected sum – opening the door to study horizon-dependence with a much broader set of reward functions with noises. We establish a novel generic algorithm that achieves no-horizon dependence in terms of sample complexity for both Markov Decision Processes (MDP) and Games, via reduction to a good-conditioned auxiliary Markovian environment, in which only “important” state-action pairs are preserved. The algorithm takes only $\tilde{O}(\frac{S^2A}{\epsilon^2})$ episodes interacting with such an environment to achieve an $\epsilon$-optimal policy/strategy (with high probability), improving (zhang, 2022) (which only applies to MDPs with deterministic rewards). Here $S$ is the number of states and $A$ is the number of actions, and the bound is independent of the horizon $H$.

**摘要:** 水平依赖是增强学习和其他机器学习范式之间的重要区别。然而,解决(准确的)水平依赖的现有结果要么假设奖励是按步骤划分的,引入不公平的比较,要么假设严格的总划分,要求奖励的总数几乎确定地划分 — — 仅允许对奖励观察的有限噪声。算法只使用与这种环境相互作用的$tilde{O}(\frac{S^2A}{\epsilon^2})$事件实现$epsilon$-最佳政策/策略(具有很高的概率),改进(zhang, 2022)(只适用于具有确定性奖励的MDP)。

**[Paper URL](https://proceedings.mlr.press/v202/li23ak.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23ak/li23ak.pdf)** 

# Transcendental Idealism of Planner: Evaluating Perception from Planning Perspective for Autonomous Driving
**题目:** 规划者超越理想主义:从规划角度评价自主驾驶的观念

**作者:** Weixin Li, Xiaodong Yang

**Abstract:** Evaluating the performance of perception modules in autonomous driving is one of the most critical tasks in developing the complex intelligent system. While module-level unit test metrics adopted from traditional computer vision tasks are feasible to some extent, it remains far less explored to measure the impact of perceptual noise on the driving quality of autonomous vehicles in a consistent and holistic manner. In this work, we propose a principled framework that provides a coherent and systematic understanding of the impact an error in the perception module imposes on an autonomous agent’s planning that actually controls the vehicle. Specifically, the planning process is formulated as expected utility maximisation, where all input signals from upstream modules jointly provide a world state description, and the planner strives for the optimal action by maximising the expected utility determined by both world states and actions. We show that, under practical conditions, the objective function can be represented as an inner product between the world state description and the utility function in a Hilbert space. This geometric interpretation enables a novel way to analyse the impact of noise in world state estimation on planning and leads to a universal metric for evaluating perception. The whole framework resembles the idea of transcendental idealism in the classical philosophical literature, which gives the name to our approach.

**摘要:** 自主驾驶感知模块的性能评价是开发复杂智能系统中最关键的任务之一。虽然从传统的计算机视觉任务中采用的模块级单元测试度量在某种程度上是可行的,但仍远远没有研究以一致和整体的方式测量感知噪声对自主车辆驾驶质量的影响。在此工作中,我们提出了一种基于原则的框架,提供一个连贯和系统地理解感知模块误差对实际控制车辆的自主代理人的规划的影响。具体而言,规划过程是预期效用最大化,由上游模块的所有输入信号共同提供世界状态的描述,而规划者则通过最大化世界状态和行动确定的预期效用,谋求最佳行动。我们证明,在实际条件下,客观函数可以作为世界状态描述和希尔伯特空间中实用函数之间的内在产物表示。这种几何解释为分析世界状态估计噪声对规划的影响提供了一种新的方法,并导致了评价感知的通用度量。

**[Paper URL](https://proceedings.mlr.press/v202/li23al.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23al/li23al.pdf)** 

# Learning for Edge-Weighted Online Bipartite Matching with Robustness Guarantees
**题目:** 基于鲁棒性保证的边形在线双方匹配学习

**作者:** Pengfei Li, Jianyi Yang, Shaolei Ren

**Abstract:** Many problems, such as online ad display, can be formulated as online bipartite matching. The crucial challenge lies in the nature of sequentially-revealed online item information, based on which we make irreversible matching decisions at each step. While numerous expert online algorithms have been proposed with bounded worst-case competitive ratios, they may not offer satisfactory performance in average cases. On the other hand, reinforcement learning (RL) has been applied to improve the average performance, but it lacks robustness and can perform arbitrarily poorly. In this paper, we propose a novel RL-based approach to edge-weighted online bipartite matching with robustness guarantees (LOMAR), achieving both good average-case and worst-case performance. The key novelty of LOMAR is a new online switching operation which, based on a judicious condition to hedge against future uncertainties, decides whether to follow the expert’s decision or the RL decision for each online item. We prove that for any $\rho\in[0,1]$, LOMAR is $\rho$-competitive against any given expert online algorithm. To improve the average performance, we train the RL policy by explicitly considering the online switching operation. Finally, we run empirical experiments to demonstrate the advantages of LOMAR compared to existing baselines.

**摘要:** 许多问题,例如在线广告显示,可以作为在线双方匹配的格式化。关键的挑战在于逐次披露的在线项目信息的性质,基于此,我们在每个步骤中作出不可逆转的匹配决策。虽然有许多专家在线算法已经提出限制最坏情况的竞争比率,但它们可能在平均情况下不能提供令人满意的性能。另一方面,强化学习(RL)已经应用以提高平均性能,但缺乏鲁棒性,并且可以任意 perform poorly。在这个论文中,我们提出了一种基于RL的新方法,以边缘权衡的在线双方匹配与鲁棒性保证(LOMAR)实现好平均和最坏情况的性能。我们证明,对于任何 $\rho\in[0,1]$, LOMAR 是 $\rho$ 与任何特定专家在线算法竞争的。为了提高平均性能,我们通过明确考虑在线交换操作来训练RL政策。

**[Paper URL](https://proceedings.mlr.press/v202/li23am.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23am/li23am.pdf)** 

# FedVS: Straggler-Resilient and Privacy-Preserving Vertical Federated Learning for Split Models
**题目:** FedVS:对分割模型的垂直联合学习具有鲁棒性和保护隐私性

**作者:** Songze Li, Duanyi Yao, Jin Liu

**Abstract:** In a vertical federated learning (VFL) system consisting of a central server and many distributed clients, the training data are vertically partitioned such that different features are privately stored on different clients. The problem of split VFL is to train a model split between the server and the clients. This paper aims to address two major challenges in split VFL: 1) performance degradation due to straggling clients during training; and 2) data and model privacy leakage from clients’ uploaded data embeddings. We propose FedVS to simultaneously address these two challenges. The key idea of FedVS is to design secret sharing schemes for the local data and models, such that information-theoretical privacy against colluding clients and curious server is guaranteed, and the aggregation of all clients’ embeddings is reconstructed losslessly, via decrypting computation shares from the non-straggling clients. Extensive experiments on various types of VFL datasets (including tabular, CV, and multi-view) demonstrate the universal advantages of FedVS in straggler mitigation and privacy protection over baseline protocols.

**摘要:** 在垂直联合学习(VFL)系统中,由一个中央服务器和许多分布式客户端组成,培训数据是垂直分割的,使得不同的特征在不同的客户端上存储。分开VFL的问题是训练服务器和客户端之间的模型分开。本论文旨在解决分开VFL的两个主要挑战:(1)由于在培训过程中被阻挠的客户端的性能下降;和(2)从客户端上传的数据嵌入中的数据和模型隐私泄漏。我们建议FedVS同时解决这两个挑战。FedVS的关键思想是为本地数据和模型设计秘密共享方案,以确保与被阻挠的客户端和好奇服务器的信息理论隐私,并通过非阻挠的客户端的计算共享进行无损的重组。对不同类型的VFL数据集(包括表格、CV和多视图)进行了广泛的实验,证明了FedVS在缓冲干扰和隐私保护方面比基准协议具有普遍优势。

**[Paper URL](https://proceedings.mlr.press/v202/li23an.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23an/li23an.pdf)** 

# Achieving Hierarchy-Free Approximation for Bilevel Programs with Equilibrium Constraints
**题目:** 平衡约束下的双级程序实现无层次近似

**作者:** Jiayang Li, Jing Yu, Boyi Liu, Yu Nie, Zhaoran Wang

**Abstract:** In this paper, we develop an approximation scheme for solving bilevel programs with equilibrium constraints, which are generally difficult to solve. Among other things, calculating the first-order derivative in such a problem requires differentiation across the hierarchy, which is computationally intensive, if not prohibitive. To bypass the hierarchy, we propose to bound such bilevel programs, equivalent to multiple-followers Stackelberg games, with two new hierarchy-free problems: a $T$-step Cournot game and a $T$-step monopoly model. Since they are standard equilibrium or optimization problems, both can be efficiently solved via first-order methods. Importantly, we show that the bounds provided by these problems — the upper bound by the $T$-step Cournot game and the lower bound by the $T$-step monopoly model — can be made arbitrarily tight by increasing the step parameter $T$ for a wide range of problems. We prove that a small $T$ usually suffices under appropriate conditions to reach an approximation acceptable for most practical purposes. Eventually, the analytical insights are highlighted through numerical examples.

**摘要:** 为了绕过 hierarchy,我们提议将两个新的 hierarchy-free问题:$T$-step Cournot 和$T$-step monopoly 模型结合起来,等同于多个追随者 Stackelberg 游戏。 因为它们是标准的平衡或优化问题,两者都可以通过第一阶方法有效解决。我们证明,在适当的条件下,一个小$T$通常足以达到大多数实际用途的可接受的近似。最后,通过数值例子突出了分析的洞察。

**[Paper URL](https://proceedings.mlr.press/v202/li23ao.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23ao/li23ao.pdf)** 

# LoSparse: Structured Compression of Large Language Models based on Low-Rank and Sparse Approximation
**题目:** LoSparse:基于低Rank和 Sparse近似的大型语言模型结构压缩

**作者:** Yixiao Li, Yifan Yu, Qingru Zhang, Chen Liang, Pengcheng He, Weizhu Chen, Tuo Zhao

**Abstract:** Transformer models have achieved remarkable results in various natural language tasks, but they are often prohibitively large, requiring massive memories and computational resources. To re- duce the size and complexity of these models, we propose LoSparse (Low-Rank and Sparse ap- proximation), a novel model compression tech- nique that approximates a weight matrix by the sum of a low-rank matrix and a sparse matrix. Our method combines the advantages of both low- rank approximations and pruning, while avoid- ing their limitations. Low-rank approximation compresses the coherent and expressive parts in neurons, while pruning removes the incoherent and non-expressive parts in neurons. Pruning enhances the diversity of low-rank approxima- tions, and low-rank approximation prevents prun- ing from losing too many expressive neurons. We evaluate our method on natural language under- standing, question answering, and natural lan- guage generation tasks. We show that it signif- icantly outperforms existing compression meth- ods. Our code is publicly available at https: //github.com/yxli2123/LoSparse

**摘要:** 变换器模型在各种自然语言任务中取得了显著的成果,但它们往往非常庞大,需要大量的记忆和计算资源。为了重塑这些模型的大小和复杂性,我们提出了LoSparse(Low-Rank and Sparse ap- proximation),一种新颖的压缩技术,以低级矩阵和稀疏矩阵的总数来近似一个重量矩阵。我们的方法结合了低级近似和剪切的优点,同时避免了它们的局限性。低级近似压缩了神经元中的连贯和表达部分,而剪切则消除了神经元中的不连贯和非表达部分。剪切增强了低级近似的多样性,而低级近似则防止剪切失去太多表达神经元。我们表明,它显著超过现有压缩方法。我们的代码在 https: //github.com/yxli2123/LoSparse上公开

**[Paper URL](https://proceedings.mlr.press/v202/li23ap.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23ap/li23ap.pdf)** 

# Nesterov Meets Optimism: Rate-Optimal Separable Minimax Optimization
**题目:** Nesterov满足了优化:速度-最佳分离的最小优化

**作者:** Chris Junchi Li, Huizhuo Yuan, Gauthier Gidel, Quanquan Gu, Michael Jordan

**Abstract:** We propose a new first-order optimization algorithm — AcceleratedGradient-OptimisticGradient (AG-OG) Descent Ascent—for separable convex-concave minimax optimization. The main idea of our algorithm is to carefully leverage the structure of the minimax problem, performing Nesterov acceleration on the individual component and optimistic gradient on the coupling component. Equipped with proper restarting, we show that AG-OG achieves the optimal convergence rate (up to a constant) for a variety of settings, including bilinearly coupled strongly convex-strongly concave minimax optimization (bi-SC-SC), bilinearly coupled convex-strongly concave minimax optimization (bi-C-SC), and bilinear games. We also extend our algorithm to the stochastic setting and achieve the optimal convergence rate in both bi-SC-SC and bi-C-SC settings. AG-OG is the first single-call algorithm with optimal convergence rates in both deterministic and stochastic settings for bilinearly coupled minimax optimization problems.

**摘要:** 我们提出了一种新的第一阶优化算法 — AcceleratedGradient-OptimisticGradient (AG-OG) Descent Ascent — 用于可分开凸凹凸微型优化。我们算法的主要思想是仔细利用微型问题的结构,在单独组件上执行内斯特罗夫加速和耦合组件上的乐观梯度。经过适当的重新启动,我们证明AG-OG在各种设置中达到最佳收敛率(最大为一定),包括双向耦合强凸凹凸微型优化(bi-SC-SC),双向耦合凸凹凸微型优化(bi-C-SC),以及双向游戏。AG-OG是第一个具有确定性和随机设置的最佳收敛率的单调算法,用于双向耦合最小值优化问题。

**[Paper URL](https://proceedings.mlr.press/v202/li23aq.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23aq/li23aq.pdf)** 

# Alternating Local Enumeration (TnALE): Solving Tensor Network Structure Search with Fewer Evaluations
**题目:** 互换本地编号(TnALE):解决承载网络结构搜索与较少的评价

**作者:** Chao Li, Junhua Zeng, Chunmei Li, Cesar F Caiafa, Qibin Zhao

**Abstract:** Tensor network (TN) is a powerful framework in machine learning, but selecting a good TN model, known as TN structure search (TN-SS), is a challenging and computationally intensive task. The recent approach TNLS (Li et al., 2022) showed promising results for this task. However, its computational efficiency is still unaffordable, requiring too many evaluations of the objective function. We propose TnALE, a surprisingly simple algorithm that updates each structure-related variable alternately by local enumeration, greatly reducing the number of evaluations compared to TNLS. We theoretically investigate the descent steps for TNLS and TnALE, proving that both the algorithms can achieve linear convergence up to a constant if a sufficient reduction of the objective is reached in each neighborhood. We further compare the evaluation efficiency of TNLS and TnALE, revealing that $\Omega(2^K)$ evaluations are typically required in TNLS for reaching the objective reduction, while ideally $O(KR)$ evaluations are sufficient in TnALE, where $K$ denotes the dimension of search space and $R$ reflects the “low-rankness” of the neighborhood. Experimental results verify that TnALE can find practically good TN structures with vastly fewer evaluations than the state-of-the-art algorithms.

**摘要:** 特纳索网络(TN)是机器学习中的一个强大的框架,但选择一个好的TN模型,称为TN结构搜索(TN-SS),是一个具有挑战性和计算强度的任务。最近的TNLS(Li et al., 2022)方法显示了这一任务的有前途的结果。然而,它的计算效率仍然难以承受,需要对目标函数进行太多的评价。我们提出了TNALE,一个令人惊讶的简单算法,它通过局部排列更新每个结构相关变量,大大降低了与TNLS相比的评价数量。我们进一步比较了TNLS和TnALE的评价效率,发现TNLS通常需要$\Omega(2^K)$的评价才能达到目标减小,而理想的$O(KR)$的评价在TnALE中足够,$K$表示搜索空间的维度,$R$反映了邻近的“低级”。

**[Paper URL](https://proceedings.mlr.press/v202/li23ar.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23ar/li23ar.pdf)** 

# Understanding the Complexity Gains of Single-Task RL with a Curriculum
**题目:** 以课程为基础,理解单项任务的复杂性收益

**作者:** Qiyang Li, Yuexiang Zhai, Yi Ma, Sergey Levine

**Abstract:** Reinforcement learning (RL) problems can be challenging without well-shaped rewards. Prior work on provably efficient RL methods generally proposes to address this issue with dedicated exploration strategies. However, another way to tackle this challenge is to reformulate it as a multi-task RL problem, where the task space contains not only the challenging task of interest but also easier tasks that implicitly function as a curriculum. Such a reformulation opens up the possibility of running existing multi-task RL methods as a more efficient alternative to solving a single challenging task from scratch. In this work, we provide a theoretical framework that reformulates a single-task RL problem as a multi-task RL problem defined by a curriculum. Under mild regularity conditions on the curriculum, we show that sequentially solving each task in the multi-task RL problem is more computationally efficient than solving the original single-task problem, without any explicit exploration bonuses or other exploration strategies. We also show that our theoretical insights can be translated into an effective practical learning algorithm that can accelerate curriculum learning on simulated robotic tasks.

**摘要:** 强化学习(RL)问题是没有良好表现的奖励的挑战性问题。对可证明有效的RL方法的前期工作一般建议用专门的探索策略来解决这个问题。然而,解决这一挑战的另一个方法是将其改编为多任务RL问题,其中任务空间不仅包含有兴趣的挑战性任务,而且具有隐含功能的更简单的任务。这种改编打开了运行现有多任务RL方法的可能性,成为解决单任务从零的更有效的替代方案。在课程的温和规律条件下,我们证明在没有明确的探索奖金或其它探索策略的情况下,逐次解决多任务RL问题的每个任务比解决原先的单任务问题更具有计算效率。

**[Paper URL](https://proceedings.mlr.press/v202/li23as.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23as/li23as.pdf)** 

# Does a Neural Network Really Encode Symbolic Concepts?
**题目:** 神经网络真的编码符号概念 吗?

**作者:** Mingjie Li, Quanshi Zhang

**Abstract:** Recently, a series of studies have tried to extract interactions between input variables modeled by a DNN and define such interactions as concepts encoded by the DNN. However, strictly speaking, there still lacks a solid guarantee whether such interactions indeed represent meaningful concepts. Therefore, in this paper, we examine the trustworthiness of interaction concepts from four perspectives. Extensive empirical studies have verified that a well-trained DNN usually encodes sparse, transferable, and discriminative concepts, which is partially aligned with human intuition. The code is released at https://github.com/sjtu-xai-lab/interaction-concept.

**摘要:** 最近,一系列研究试图从DNN建模的输入变量间提取相互作用,并定义这些相互作用为DNN编码的概念。然而,严格地说,仍然缺乏可靠的保证,这些相互作用是否确实代表有意义的概念。因此,本文从四个角度来研究相互作用概念的可靠性。

**[Paper URL](https://proceedings.mlr.press/v202/li23at.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23at/li23at.pdf)** 

# Cooperative Open-ended Learning Framework for Zero-Shot Coordination
**题目:** 零射击协调合作开放学习框架

**作者:** Yang Li, Shao Zhang, Jichen Sun, Yali Du, Ying Wen, Xinbing Wang, Wei Pan

**Abstract:** Zero-shot coordination in cooperative artificial intelligence (AI) remains a significant challenge, which means effectively coordinating with a wide range of unseen partners. Previous algorithms have attempted to address this challenge by optimizing fixed objectives within a population to improve strategy or behaviour diversity. However, these approaches can result in a loss of learning and an inability to cooperate with certain strategies within the population, known as cooperative incompatibility. To address this issue, we propose the Cooperative Open-ended LEarning (COLE) framework, which constructs open-ended objectives in cooperative games with two players from the perspective of graph theory to assess and identify the cooperative ability of each strategy. We further specify the framework and propose a practical algorithm that leverages knowledge from game theory and graph theory. Furthermore, an analysis of the learning process of the algorithm shows that it can efficiently overcome cooperative incompatibility. The experimental results in the Overcooked game environment demonstrate that our method outperforms current state-of-the-art methods when coordinating with different-level partners. Our demo is available at https://sites.google.com/view/cole-2023.

**摘要:** 合作人工知能(AI)中的零射击协调仍然是一个重大的挑战,这意味着与广泛的未知伙伴进行有效协调。以前的算法试图通过在群体内优化固定目标来解决这一挑战,以改善策略或行为多样性。然而,这些方法可能导致学习的损失和群体内某些策略无法合作,称为合作不兼容性。为了解决这一问题,我们提出了合作开放学习(COLE)框架,从图论的角度对两个玩家在合作游戏中构建开放目标,以评估和识别每个策略的合作能力。此外,该算法的学习过程的分析表明,该算法能够有效地克服合作性不兼容性。Overcooked游戏环境的实验结果表明,我们的方法在与不同级别的合作伙伴进行协调时比现有的最先进的方法高。

**[Paper URL](https://proceedings.mlr.press/v202/li23au.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23au/li23au.pdf)** 

# Offline Reinforcement Learning with Closed-Form Policy Improvement Operators
**题目:** 与封闭式政策改善营办商进行网上强化学习

**作者:** Jiachen Li, Edwin Zhang, Ming Yin, Qinxun Bai, Yu-Xiang Wang, William Yang Wang

**Abstract:** Behavior constrained policy optimization has been demonstrated to be a successful paradigm for tackling Offline Reinforcement Learning. By exploiting historical transitions, a policy is trained to maximize a learned value function while constrained by the behavior policy to avoid a significant distributional shift. In this paper, we propose our closed-form policy improvement operators. We make a novel observation that the behavior constraint naturally motivates the use of first-order Taylor approximation, leading to a linear approximation of the policy objective. Additionally, as practical datasets are usually collected by heterogeneous policies, we model the behavior policies as a Gaussian Mixture and overcome the induced optimization difficulties by leveraging the LogSumExp’s lower bound and Jensen’s Inequality, giving rise to a closed-form policy improvement operator. We instantiate both one-step and iterative offline RL algorithms with our novel policy improvement operators and empirically demonstrate their effectiveness over state-of-the-art algorithms on the standard D4RL benchmark. Our code is available at https://cfpi-icml23.github.io/.

**摘要:** 行为约束政策优化是解决网络增强学习的有效范式,通过利用历史性转变,政策被训练以最大化学习值函数,同时被行为约束政策以避免重大分布性转变。本文提出了闭式政策改进算子。我们提出了一种新的观察,即行为约束自然地激励使用第一阶泰勒近似,导致政策目标的线性近似。我们通过新的政策改进操作器来实时化单步和迭代离线RL算法,并在标准D4RL基准上实证其在最先进的算法上的效果。我们的代码可浏览 https://cfpi-icml23.github.io/。

**[Paper URL](https://proceedings.mlr.press/v202/li23av.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23av/li23av.pdf)** 

# Optimal Arms Identification with Knapsacks
**题目:** 最优的武器识别与手提包

**作者:** Shaoang Li, Lan Zhang, Yingqi Yu, Xiangyang Li

**Abstract:** Best Arm Identification (BAI) is a general online pure exploration framework to identify optimal decisions among candidates via sequential interactions. We pioneer the Optimal Arms identification with Knapsacks (OAK) problem, which extends the BAI setting to model the resource consumption. We present a novel OAK algorithm and prove the upper bound of our algorithm by exploring the relationship between selecting optimal actions and the structure of the feasible region. Our analysis introduces a new complexity measure, which builds a bridge between the OAK setting and bandits with knapsacks problem. We establish the instance-dependent lower bound for the OAK problem based on the new complexity measure. Our results show that the proposed algorithm achieves a near-optimal probability bound for the OAK problem. In addition, we demonstrate that our algorithm recovers or improves the state-of-the-art upper bounds for several special cases, including the simple OAK setting and some classical pure exploration problems.

**摘要:** 最佳武器识别(英语:Best Arm Identification,简称BAI)是通过序列交互识别候选人的最佳决策的一般在线纯探索框架。我们为OAK问题(英语:Optimal Arms Identification with Knapsacks,缩写为OAK)提出了一种新的OAK算法,并通过探索选择最佳行动与可行的区域结构之间的关系,证明了OAK算法的上限。我们的分析引入了一种新的复杂度度量,建立了OAK设置与带袋问题之间的桥梁。我们根据新的复杂度量度建立了基于实例的OAK问题下限。此外,我们证明了我们的算法能恢复或改善一些特殊情况下最先进的上限,包括简单的OAK设置和一些经典的纯探索问题。

**[Paper URL](https://proceedings.mlr.press/v202/li23aw.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23aw/li23aw.pdf)** 

# Internally Rewarded Reinforcement Learning
**题目:** 内部奖励强化学习

**作者:** Mengdi Li, Xufeng Zhao, Jae Hee Lee, Cornelius Weber, Stefan Wermter

**Abstract:** We study a class of reinforcement learning problems where the reward signals for policy learning are generated by a discriminator that is dependent on and jointly optimized with the policy. This interdependence between the policy and the discriminator leads to an unstable learning process because reward signals from an immature discriminator are noisy and impede policy learning, and conversely, an under-optimized policy impedes discriminator learning. We call this learning setting $\textit{Internally Rewarded Reinforcement Learning}$ (IRRL) as the reward is not provided directly by the environment but $\textit{internally}$ by the discriminator. In this paper, we formally formulate IRRL and present a class of problems that belong to IRRL. We theoretically derive and empirically analyze the effect of the reward function in IRRL and based on these analyses propose the clipped linear reward function. Experimental results show that the proposed reward function can consistently stabilize the training process by reducing the impact of reward noise, which leads to faster convergence and higher performance compared with baselines in diverse tasks.

**摘要:** 我们研究了一种强化学习问题的类别,其中政策学习的奖励信号是由一个依赖于和与政策共同优化的鉴别器生成的。这种政策与鉴别器之间的相互依赖导致不稳定的学习过程,因为未成熟鉴别器的奖励信号是噪声的,阻碍政策学习,而相反,一个不优化的政策阻碍了鉴别器学习。我们称这种学习设置 $\textit{Internally Rewarded Reinforcement Learning}$ (IRRL),因为奖励不是由环境直接提供,而是由鉴别器$\textit{internally}$。实验结果表明,该建议的奖励函数能够通过减少奖励噪声影响稳定训练过程,从而使不同任务的协同工作速度更快和工作效率更高。

**[Paper URL](https://proceedings.mlr.press/v202/li23ax.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23ax/li23ax.pdf)** 

# Trustworthy Policy Learning under the Counterfactual No-Harm Criterion
**题目:** 基于反事实无害标准的可靠政策学习

**作者:** Haoxuan Li, Chunyuan Zheng, Yixiao Cao, Zhi Geng, Yue Liu, Peng Wu

**Abstract:** Trustworthy policy learning has significant importance in making reliable and harmless treatment decisions for individuals. Previous policy learning approaches aim at the well-being of subgroups by maximizing the utility function (e.g., conditional average causal effects, post-view click-through&conversion rate in recommendations), however, individual-level counterfactual no-harm criterion has rarely been discussed. In this paper, we first formalize the counterfactual no-harm criterion for policy learning from a principal stratification perspective. Next, we propose a novel upper bound for the fraction negatively affected by the policy and show the consistency and asymptotic normality of the estimator. Based on the estimators for the policy utility and harm upper bounds, we further propose a policy learning approach that satisfies the counterfactual no-harm criterion, and prove its consistency to the optimal policy reward for parametric and non-parametric policy classes, respectively. Extensive experiments are conducted to show the effectiveness of the proposed policy learning approach for satisfying the counterfactual no-harm criterion.

**摘要:** 可靠的政策学习对个人作出可靠无害处理决策具有重要意义。以往的政策学习方法以最大化效用函数(例如条件平均因果效应、建议中后视图点击through&转换率)为目标,旨在提高分组的福利。然而,个人层面的反事实无害标准很少被讨论。本文首先从主要分层观点形式化政策学习的反事实无害标准。其次,我们提出了一种新颖的上限,用于被政策影响的分组,并显示了估计器的一致性和渐近正常性。基于政策效用和伤害上限的估计器,我们进一步提出了一种符合反事实无害标准的政策学习方法,并证明其一致性为参数类和非参数类的最佳政策奖励。为 证明 拟议 的 政策 学习 方法 是否 有效, 进行 了 广泛 的 实验, 以 满足 反 事实 无害 标准 。

**[Paper URL](https://proceedings.mlr.press/v202/li23ay.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23ay/li23ay.pdf)** 

# Structured Cooperative Learning with Graphical Model Priors
**题目:** 基于图形模型的结构协作学习

**作者:** Shuangtong Li, Tianyi Zhou, Xinmei Tian, Dacheng Tao

**Abstract:** We study how to train personalized models for different tasks on decentralized devices with limited local data. We propose "Structured Cooperative Learning (SCooL)", in which a cooperation graph across devices is generated by a graphical model prior to automatically coordinate mutual learning between devices. By choosing graphical models enforcing different structures, we can derive a rich class of existing and novel decentralized learning algorithms via variational inference. In particular, we show three instantiations of SCooL that adopt Dirac distribution, stochastic block model (SBM), and attention as the prior generating cooperation graphs. These EM-type algorithms alternate between updating the cooperation graph and cooperative learning of local models. They can automatically capture the cross-task correlations among devices by only monitoring their model updating in order to optimize the cooperation graph. We evaluate SCooL and compare it with existing decentralized learning methods on an extensive set of benchmarks, on which SCooL always achieves the highest accuracy of personalized models and significantly outperforms other baselines on communication efficiency. Our code is available at https://github.com/ShuangtongLi/SCooL.

**摘要:** 我们研究如何在有限的本地数据下,在分散设备上训练不同任务的个性化模型。我们提出了“结构化合作学习(SCooL)”,在该模型中,通过图形模型生成设备间相互学习的协作图,然后自动协调相互学习。通过选择不同的结构的图形模型,我们可以通过变异推导导导出一种丰富的现有和新颖的分散学习算法。我们对SCooL进行评估,并与现有分散学习方法在广泛的基准中进行比较,在这些基准上SCooL总是达到个性化模型的最高精度,并且大大超过了其他通信效率的基准。

**[Paper URL](https://proceedings.mlr.press/v202/li23az.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/li23az/li23az.pdf)** 

# Low Complexity Homeomorphic Projection to Ensure Neural-Network Solution Feasibility for Optimization over (Non-)Convex Set
**题目:** 低复杂性同构投影以确保神经网络解决方案在(非)凸集上优化的可行性

**作者:** Enming Liang, Minghua Chen, Steven Low

**Abstract:** There has been growing interest in employing neural network (NN) to directly solve constrained optimization problems with low run-time complexity. However, it is non-trivial to ensure NN solutions strictly satisfying problem constraints due to inherent NN prediction errors. Existing feasibility-ensuring methods either are computationally expensive or lack performance guarantee. In this paper, we propose homeomorphic projection as a low-complexity scheme to guarantee NN solution feasibility for optimization over a general set homeomorphic to a unit ball, covering all compact convex sets and certain classes of nonconvex sets. The idea is to (i) learn a minimum distortion homeomorphic mapping between the constraint set and a unit ball using an invertible NN (INN), and then (ii) perform a simple bisection operation concerning the unit ball so that the INN-mapped final solution is feasible with respect to the constraint set with minor distortion-induced optimality loss. We prove the feasibility guarantee and bound the optimality loss under mild conditions. Simulation results, including those for non-convex AC-OPF problems in power grid operation, show that homeomorphic projection outperforms existing methods in solution feasibility and run-time complexity, while achieving similar optimality loss.

**摘要:** 利用神经网络直接解决低运行时间复杂性约束优化问题的兴趣日益增加,然而,由于固有的NN预测误差,很难确保NN解决方案严格满足约束问题。现有 feasibility-ensuring方法要么是计算成本昂贵,要么缺乏性能保证。本论文提出了一种低复杂性方案,以保证NN解决方案在单元球上优化的 feasibility over a general set homeomorphic to a unit ball, covering all compact convex sets and certain classes of nonconvex sets。在温和条件下证明了可行性保证,并约束了优化损失。模拟结果,包括在电力电网运行中非凸式AC-OPF问题中的结果,表明,仿真投影在解决可行性和运行时间复杂性方面优于现有方法,同时达到类似的优化损失。

**[Paper URL](https://proceedings.mlr.press/v202/liang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liang23a/liang23a.pdf)** 

# Consistency of Multiple Kernel Clustering
**题目:** 多核集群的一致性

**作者:** Weixuan Liang, Xinwang Liu, Yong Liu, Chuan Ma, Yunping Zhao, Zhe Liu, En Zhu

**Abstract:** Consistency plays an important role in learning theory. However, in multiple kernel clustering (MKC), the consistency of kernel weights has not been sufficiently investigated. In this work, we fill this gap with a non-asymptotic analysis on the consistency of kernel weights of a novel method termed SimpleMKKM. Under the assumptions of the eigenvalue gap, we give an infinity norm bound as $\widetilde{\mathcal{O}}(k/\sqrt{n})$, where $k$ is the number of clusters and $n$ is the number of samples. On this basis, we establish an upper bound for the excess clustering risk. Moreover, we study the difference of the kernel weights learned from $n$ samples and $r$ points sampled without replacement, and derive its upper bound as $\widetilde{\mathcal{O}}(k\cdot\sqrt{1/r-1/n})$. Based on the above results, we propose a novel strategy with Nyström method to enable SimpleMKKM to handle large-scale datasets with a theoretical learning guarantee. Finally, extensive experiments are conducted to verify the theoretical results and the effectiveness of the proposed large-scale strategy.

**摘要:** 一致性在学习理论中起着重要的作用。然而,在多核聚类(MKC)中,核重的一致性尚未得到充分研究。在这个工作中,我们用新方法 SimpleMKKM(英语:SimpleMKKM)的核重的一致性非渐近分析填补了这一缺口。在自值缺口的假设下,我们给出一个无限规范的bound as $\widetilde{\mathcal{O}}(k/\sqrt{n})$,其中$k$是群数和$n$是样品数。在此基础上,我们建立了额外聚类风险的上限。此外,我们研究了从$n$样品和$r$点抽取的核重的差异,并得出它的上限 as $\widetilde{\mathcal{O}}(k\cdot\sqrt{1/r-1/n}最后, 进行 了 广泛 的 实验, 验证 了 拟议 的 大规模 战略 的 理论 结果 和 有效性 。

**[Paper URL](https://proceedings.mlr.press/v202/liang23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liang23b/liang23b.pdf)** 

# A Distribution Optimization Framework for Confidence Bounds of Risk Measures
**题目:** 风险度量信任度的分布优化框架

**作者:** Hao Liang, Zhi-Quan Luo

**Abstract:** We present a distribution optimization framework that significantly improves confidence bounds for various risk measures compared to previous methods. Our framework encompasses popular risk measures such as the entropic risk measure, conditional value at risk (CVaR), spectral risk measure, distortion risk measure, equivalent certainty, and rank-dependent expected utility, which are well established in risk-sensitive decision-making literature. To achieve this, we introduce two estimation schemes based on concentration bounds derived from the empirical distribution, specifically using either the Wasserstein distance or the supremum distance. Unlike traditional approaches that add or subtract a confidence radius from the empirical risk measures, our proposed schemes evaluate a specific transformation of the empirical distribution based on the distance. Consequently, our confidence bounds consistently yield tighter results compared to previous methods. We further verify the efficacy of the proposed framework by providing tighter problem-dependent regret bound for the CVaR bandit.

**摘要:** 提出了一种与以往方法相比,对各种风险措施的信度极限的分布优化框架。该框架包括流行风险措施,如熵风险度量、风险条件值(CVaR)、光谱风险度量、扭曲风险度量、等效确定度、 rank-dependent预期效用等,这些都已在风险敏感决策文献中 well established。为此,我们引入了两个基于经验分布的浓度极限的估计方案,具体使用沃塞斯泰因距离或最长距离。与传统方法不同,这些方法从经验风险度量中增加或减去信度半径,我们提出的方案评价了基于距离的经验分布的特定变换。我们进一步验证了拟议的框架的有效性,为CVAR盗版提供更严格的受问题影响的约束的遗憾。

**[Paper URL](https://proceedings.mlr.press/v202/liang23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liang23c/liang23c.pdf)** 

# Accuracy on the Curve: On the Nonlinear Correlation of ML Performance Between Data Subpopulations
**题目:** 曲线的准确性:数据子群间ML性能的非线性相关性

**作者:** Weixin Liang, Yining Mao, Yongchan Kwon, Xinyu Yang, James Zou

**Abstract:** Understanding the performance of machine learning (ML) models across diverse data distributions is critically important for reliable applications. Despite recent empirical studies positing a near-perfect linear correlation between in-distribution (ID) and out-of-distribution (OOD) accuracies, we empirically demonstrate that this correlation is more nuanced under subpopulation shifts. Through rigorous experimentation and analysis across a variety of datasets, models, and training epochs, we demonstrate that OOD performance often has a nonlinear correlation with ID performance in subpopulation shifts. Our findings, which contrast previous studies that have posited a linear correlation in model performance during distribution shifts, reveal a "moon shape" correlation (parabolic uptrend curve) between the test performance on the majority subpopulation and the minority subpopulation. This non-trivial nonlinear correlation holds across model architectures, hyperparameters, training durations, and the imbalance between subpopulations. Furthermore, we found that the nonlinearity of this "moon shape" is causally influenced by the degree of spurious correlations in the training data. Our controlled experiments show that stronger spurious correlation in the training data creates more nonlinear performance correlation. We provide complementary experimental and theoretical analyses for this phenomenon, and discuss its implications for ML reliability and fairness. Our work highlights the importance of understanding the nonlinear effects of model improvement on performance in different subpopulations, and has the potential to inform the development of more equitable and responsible machine learning models.

**摘要:** 对不同数据分布的机器学习(ML)模型性能的理解对于可靠的应用至关重要。尽管最近的实证研究确定了内部分布(ID)和外部分布(OOD)精度之间的近完全线性相关性,但我们实证证明,这种相关性在分组迁移下更为微观。通过对各种数据集、模型和训练时代进行严格的实验和分析,我们证明了OOD性能在分组迁移中经常与ID性能有非线性相关性。我们发现,与先前研究确定在分组迁移期间模型性能有线性相关性,显示了多数分组和少数分组测试性能之间的“月形”相关性(双向趋势曲线)。该非平凡的非线性相关性在模型结构、超参数、训练时间和分群之间存在不平衡。此外,我们发现该“月形”的非线性是由训练数据中的虚构相关性程度引起的。我们的控制实验表明,训练数据中的更强的虚构相关性创造出更多的非线性性能相关性。我们为这一现象提供补充的实验和理论分析,并讨论其对ML可靠性和公平性的影响。

**[Paper URL](https://proceedings.mlr.press/v202/liang23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liang23d/liang23d.pdf)** 

# AdaptDiffuser: Diffusion Models as Adaptive Self-evolving Planners
**题目:** AdaptDiffuser:扩散模型作为适应性自演规划者

**作者:** Zhixuan Liang, Yao Mu, Mingyu Ding, Fei Ni, Masayoshi Tomizuka, Ping Luo

**Abstract:** Diffusion models have demonstrated their powerful generative capability in many tasks, with great potential to serve as a paradigm for offline reinforcement learning. However, the quality of the diffusion model is limited by the insufficient diversity of training data, which hinders the performance of planning and the generalizability to new tasks. This paper introduces AdaptDiffuser, an evolutionary planning method with diffusion that can self-evolve to improve the diffusion model hence a better planner, not only for seen tasks but can also adapt to unseen tasks. AdaptDiffuser enables the generation of rich synthetic expert data for goal-conditioned tasks using guidance from reward gradients. It then selects high-quality data via a discriminator to finetune the diffusion model, which improves the generalization ability to unseen tasks. Empirical experiments on two benchmark environments and two carefully designed unseen tasks in KUKA industrial robot arm and Maze2D environments demonstrate the effectiveness of AdaptDiffuser. For example, AdaptDiffuser not only outperforms the previous art Diffuser by 20.8% on Maze2D and 7.5% on MuJoCo locomotion, but also adapts better to new tasks, e.g., KUKA pick-and-place, by 27.9% without requiring additional expert data. More visualization results and demo videos could be found on our project page.

**摘要:** 扩散模型在许多任务中表现出其强大的生成能力,具有巨大的潜力,可以作为 offline增强学习的范式。然而,扩散模型的质量受到训练数据的不足多样性限制,这阻碍了规划的性能和对新任务的通用性。本论文介绍了扩散的演化规划方法AdaptDiffuser,它可以自演来改进扩散模型,从而成为一个更好的规划者,不仅适用于已见的任务,而且可以适应未见的任务。AdaptDiffuser允许生成rich synthetic expert data for goal-conditioned tasks using guidance from reward gradients。在KUKA工业机器人臂和Maze2D环境中,两个基准环境和两个精心设计的未知任务的实证实验证明了AdaptDiffuser的有效性。例如,AdaptDiffuser不仅在Maze2D和MuJoCo运动上比以前的Art Diffuser有20.8%和7.5%,而且在不需要额外的专家数据的情况下更适合新的任务,例如KUKA pick-and-place的27.9%。

**[Paper URL](https://proceedings.mlr.press/v202/liang23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liang23e/liang23e.pdf)** 

# Learning Compiler Pass Orders using Coreset and Normalized Value Prediction
**题目:** 使用核心集和标准化值预测学习编译器传递命令

**作者:** Youwei Liang, Kevin Stone, Ali Shameli, Chris Cummins, Mostafa Elhoushi, Jiadong Guo, Benoit Steiner, Xiaomeng Yang, Pengtao Xie, Hugh James Leather, Yuandong Tian

**Abstract:** Finding the optimal pass sequence of compilation can lead to a significant reduction in program size. Prior works on compilation pass ordering have two major drawbacks. They either require an excessive budget (in terms of the number of compilation passes) at compile time or fail to generalize to unseen programs. In this work, instead of predicting passes sequentially, we directly learn a policy on the pass sequence space, which outperforms the default -Oz flag by an average of 4.5% over a large collection (4683) of unseen code repositories from diverse domains across 14 datasets. To achieve this, we first identify a small set (termed coreset) of pass sequences that generally optimize the size of most programs. Then, a policy is learned to pick the optimal sequences by predicting the normalized values of the pass sequences in the coreset. Our results demonstrate that existing human-designed compiler passes can be improved with a simple yet effective technique that leverages pass sequence space which contains dense rewards, while approaches operating on the individual pass space may suffer from issues of sparse reward, and do not generalize well to held-out programs from different domains. Website: https://rlcompopt.github.io.

**摘要:** 寻找编译的最佳密码序列可导致程序大小的大幅减少。编译密码序列上以前的工作有两个主要缺点。它们要么在编译时需要过多的预算(包括编译密码的数量)或不能将程序推广到未见的程序。在这个工作中,我们直接学习了密码序列空间上的策略,它比默认的-Oz标志平均4.5%高,从14个数据集中从不同领域收集到大量未见的代码存储器。我们的结果表明,现有由人类设计的编译器通行可以通过一种简单而有效的技术改进,它利用包含密集奖励的通行序列空间,而操作在单独的通行空间的办法可能受到稀有奖励的问题,并不能很好地推广到不同域的保持程序。

**[Paper URL](https://proceedings.mlr.press/v202/liang23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liang23f/liang23f.pdf)** 

# Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples
**题目:** 敌对的例子有好处:通过敌对的例子防止从扩散模型中模仿绘画

**作者:** Chumeng Liang, Xiaoyu Wu, Yang Hua, Jiaru Zhang, Yiming Xue, Tao Song, Zhengui Xue, Ruhui Ma, Haibing Guan

**Abstract:** Recently, Diffusion Models (DMs) boost a wave in AI for Art yet raise new copyright concerns, where infringers benefit from using unauthorized paintings to train DMs and generate novel paintings in a similar style. To address these emerging copyright violations, in this paper, we are the first to explore and propose to utilize adversarial examples for DMs to protect human-created artworks. Specifically, we first build a theoretical framework to define and evaluate the adversarial examples for DMs. Then, based on this framework, we design a novel algorithm to generate these adversarial examples, named AdvDM, which exploits a Monte-Carlo estimation of adversarial examples for DMs by optimizing upon different latent variables sampled from the reverse process of DMs. Extensive experiments show that the generated adversarial examples can effectively hinder DMs from extracting their features. Therefore, our method can be a powerful tool for human artists to protect their copyright against infringers equipped with DM-based AI-for-Art applications. The code of our method is available on GitHub: https://github.com/mist-project/mist.git.

**摘要:** 为了解决这些新兴的版权侵犯问题,我们是第一个探索和提出利用对策的例子来保护人创造的艺术作品。具体地说,我们首先构建了一个定义和评价对策的例子的理论框架。然后,基于这个框架,我们设计了一个基于对策的算法,命名为AdvDM,该算法利用对策的 Monte-Carlo估计,以优化从对策过程中采样的不同隐形变量。因此,我们的方法可以为人类艺术家提供一种强大的工具来保护他们的著作权,防止使用基于DM的AI-for-Art应用程序的侵犯者。我们的方法的代码可以在GitHub上找到: https://github.com/mist-project/mist.git。

**[Paper URL](https://proceedings.mlr.press/v202/liang23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liang23g/liang23g.pdf)** 

# CLUSTSEG: Clustering for Universal Segmentation
**题目:** CLUSTSEG:通用分区集群

**作者:** James Chenhao Liang, Tianfei Zhou, Dongfang Liu, Wenguan Wang

**Abstract:** We present CLUSTSEG, a general, transformer-based framework that tackles different image segmentation tasks ($i.e.,$ superpixel, semantic, instance, and panoptic) through a unified, neural clustering scheme. Regarding queries as cluster centers, CLUSTSEG is innovative in two aspects: 1) cluster centers are initialized in heterogeneous ways so as to pointedly address task-specific demands ($e.g.,$ instance- or category-level distinctiveness), yet without modifying the architecture; and 2) pixel-cluster assignment, formalized in a cross-attention fashion, is alternated with cluster center update, yet without learning additional parameters. These innovations closely link CLUSTSEG to EM clustering and make it a transparent and powerful framework that yields superior results across the above segmentation tasks.

**摘要:** 我们介绍CLUSTSEG,一种基于变换器的通用框架,它通过统一的神经集群计划处理不同的图像分割任务($i.e.,$ superpixel, semantic, instance, and panoptic)。

**[Paper URL](https://proceedings.mlr.press/v202/liang23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liang23h/liang23h.pdf)** 

# Conformal Inference is (almost) Free for Neural Networks Trained with Early Stopping
**题目:** 与早期停止训练的神经网络的一致性干扰是(几乎)免费的

**作者:** Ziyi Liang, Yanfei Zhou, Matteo Sesia

**Abstract:** Early stopping based on hold-out data is a popular regularization technique designed to mitigate overfitting and increase the predictive accuracy of neural networks. Models trained with early stopping often provide relatively accurate predictions, but they generally still lack precise statistical guarantees unless they are further calibrated using independent hold-out data. This paper addresses the above limitation with conformalized early stopping: a novel method that combines early stopping with conformal calibration while efficiently recycling the same hold-out data. This leads to models that are both accurate and able to provide exact predictive inferences without multiple data splits nor overly conservative adjustments. Practical implementations are developed for different learning tasks—outlier detection, multi-class classification, regression—and their competitive performance is demonstrated on real data.

**摘要:** 基于停顿数据的早期停顿是旨在减轻超标和提高神经网络的预测准确性的一种流行的调节技术。使用早期停顿训练的模型通常提供相对准确的预测,但它们通常仍缺乏准确的统计保证,除非使用独立停顿数据进行进一步校正。本论文讨论了上述限制的标准化早期停顿:一种新方法,它将早期停顿与校正结合,同时有效地回收相同的停顿数据。这导致模型既准确又能够提供准确的预测推断,而不需要多数据分割或过度保守的调整。

**[Paper URL](https://proceedings.mlr.press/v202/liang23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liang23i/liang23i.pdf)** 

# Less is More: Task-aware Layer-wise Distillation for Language Model Compression
**题目:** 少是多:语言模型压缩的基于任务层级蒸馏

**作者:** Chen Liang, Simiao Zuo, Qingru Zhang, Pengcheng He, Weizhu Chen, Tuo Zhao

**Abstract:** Layer-wise distillation is a powerful tool to compress large models (i.e. teacher models) into small ones (i.e., student models). The student distills knowledge from the teacher by mimicking the hidden representations of the teacher at every intermediate layer. However, layer-wise distillation is difficult. Since the student has a smaller model capacity than the teacher, it is often under-fitted. Furthermore, the hidden representations of the teacher contain redundant information that the student does not necessarily need for the target task’s learning. To address these challenges, we propose a novel Task-aware layEr-wise Distillation (TED). TED designs task-aware filters to align the hidden representations of the student and the teacher at each layer. The filters select the knowledge that is useful for the target task from the hidden representations. As such, TED reduces the knowledge gap between the two models and helps the student to fit better on the target task. We evaluate TED in two scenarios: continual pre-training and fine-tuning. TED demonstrates significant and consistent improvements over existing distillation methods in both scenarios. Code is available at https://github.com/cliang1453/task-aware-distillation.

**摘要:** 层级蒸馏是压缩大型模型(例如教师模型)到较小的模型(例如学生模型)的强有力工具。学生通过模仿教师在每个中间层的隐藏表示来蒸馏教师的知识。然而,层级蒸馏是困难的。因为学生比教师的模型能力较小,所以经常不足。此外,教师的隐藏表示包含了学生不一定需要学习的目标任务的信息。为了解决这些问题,我们提出了一种新颖的任务意识层级蒸馏(英语:Task-aware distillation)。我们评估TED在两个场景中:持续的预训练和微调。 TED在这两个场景中对现有的蒸馏方法进行了显著和一致的改进。代码可于 https://github.com/cliang1453/task-aware-distillation。

**[Paper URL](https://proceedings.mlr.press/v202/liang23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liang23j/liang23j.pdf)** 

# Statistical Inference and A/B Testing for First-Price Pacing Equilibria
**题目:** 统计ference和A/B测试第一价配额均衡

**作者:** Luofeng Liao, Christian Kroer

**Abstract:** We initiate the study of statistical inference and A/B testing for first-price pacing equilibria (FPPE). The FPPE model captures the dynamics resulting from large-scale first-price auction markets where buyers use pacing-based budget management. Such markets arise in the context of internet advertising, where budgets are prevalent. We propose a statistical framework for the FPPE model, in which a limit FPPE with a continuum of items models the long-run steady-state behavior of the auction platform, and an observable FPPE consisting of a finite number of items provides the data to estimate primitives of the limit FPPE, such as revenue, Nash social welfare (a fair metric of efficiency), and other parameters of interest. We develop central limit theorems and asymptotically valid confidence intervals. Furthermore, we establish the asymptotic local minimax optimality of our estimators. We then show that the theory can be used for conducting statistically valid A/B testing on auction platforms. Numerical simulations verify our central limit theorems, and empirical coverage rates for our confidence intervals agree with our theory.

**摘要:** 本文首先对第一价铺设均衡(FPPE)的统计推导和A/B测试进行了研究。FPPE模型捕捉了买家使用铺设基础预算管理的大规模第一价拍卖市场产生的动态。这些市场在互联网广告中出现,预算占主导地位。我们为FPPE模型提出了一个统计框架,其中以项目模型的连续体为限度FPPE,拍卖平台的长期稳定状态行为,以及由有限个项目组成的可观测的FPPE提供数据来估计限度FPPE的初始特征,如收入、纳什社会福利(公平的效率度量)和其他参数。通过数值仿真验证了我们的中心限度定理,并证明了我们对信用间隔的实证覆盖率与理论一致。

**[Paper URL](https://proceedings.mlr.press/v202/liao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liao23a/liao23a.pdf)** 

# Supervised Metric Learning to Rank for Retrieval via Contextual Similarity Optimization
**题目:** 通过对上下文相似性优化来检索等级的监控度量学习

**作者:** Christopher Liao, Theodoros Tsiligkaridis, Brian Kulis

**Abstract:** There is extensive interest in metric learning methods for image retrieval. Many metric learning loss functions focus on learning a correct ranking of training samples, but strongly overfit semantically inconsistent labels and require a large amount of data. To address these shortcomings, we propose a new metric learning method, called contextual loss, which optimizes contextual similarity in addition to cosine similarity. Our contextual loss implicitly enforces semantic consistency among neighbors while converging to the correct ranking. We empirically show that the proposed loss is more robust to label noise, and is less prone to overfitting even when a large portion of train data is withheld. Extensive experiments demonstrate that our method achieves a new state-of-the-art across four image retrieval benchmarks and multiple different evaluation settings. Code is available at: https://github.com/Chris210634/metric-learning-using-contextual-similarity

**摘要:** 对图像检索的计量学习方法有广泛的兴趣。许多计量学习损失函数的重点是学习训练样品的正确排名,但强烈超过语义不一致的标签,需要大量数据。为了解决这些缺陷,我们提出了一种新的计量学习方法,即语义损失,它除了同位素相似性外,优化语义相似性。我们的语义损失隐含地强制邻舍之间的语义一致性,同时收敛到正确的排名。

**[Paper URL](https://proceedings.mlr.press/v202/liao23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liao23b/liao23b.pdf)** 

# Revisiting Domain Randomization via Relaxed State-Adversarial Policy Optimization
**题目:** 通过放松的国家敌对政策优化重覆域名随机化

**作者:** Yun-Hsuan Lien, Ping-Chun Hsieh, Yu-Shuen Wang

**Abstract:** Domain randomization (DR) is widely used in reinforcement learning (RL) to bridge the gap between simulation and reality by maximizing its average returns under the perturbation of environmental parameters. However, even the most complex simulators cannot capture all details in reality due to finite domain parameters and simplified physical models. Additionally, the existing methods often assume that the distribution of domain parameters belongs to a specific family of probability functions, such as normal distributions, which may not be correct. To overcome these limitations, we propose a new approach to DR by rethinking it from the perspective of adversarial state perturbation, without the need for reconfiguring the simulator or relying on prior knowledge about the environment. We also address the issue of over-conservatism that can occur when perturbing agents to the worst states during training by introducing a Relaxed State-Adversarial Algorithm that simultaneously maximizes the average-case and worst-case returns. We evaluate our method by comparing it to state-of-the-art methods, providing experimental results and theoretical proofs to verify its effectiveness. Our source code and appendix are available at https://github.com/sophialien/RAPPO.

**摘要:** 域随机化(DR)广泛应用于增强学习(RL)中,通过在环境参数的扰动下最大化其平均回报来填补模拟与现实之间的差距。然而,即使最复杂的模拟器也无法通过有限域参数和简化物理模型捕捉到现实中的所有细节。此外,现有的方法往往假定域参数的分布属于特定概率函数家族,如正常分布,可能不正确。我们还通过引入一个放松状态-敌方算法,同时最大化平均和最糟糕的回报,解决了在训练期间影响最坏状态的代理人时可能出现的过度保守主义问题。我们通过与最先进的方法进行比较,提供实验结果和理论证明来验证其有效性。

**[Paper URL](https://proceedings.mlr.press/v202/lien23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lien23a/lien23a.pdf)** 

# Variational Open-Domain Question Answering
**题目:** 变量开放域名问题解答

**作者:** Valentin Liévin, Andreas Geert Motzfeldt, Ida Riis Jensen, Ole Winther

**Abstract:** Retrieval-augmented models have proven to be effective in natural language processing tasks, yet there remains a lack of research on their optimization using variational inference. We introduce the Variational Open-Domain (VOD) framework for end-to-end training and evaluation of retrieval-augmented models, focusing on open-domain question answering and language modelling. The VOD objective, a self-normalized estimate of the Rényi variational bound, approximates the task marginal likelihood and is evaluated under samples drawn from an auxiliary sampling distribution (cached retriever and/or approximate posterior). It remains tractable, even for retriever distributions defined on large corpora. We demonstrate VOD’s versatility by training reader-retriever BERT-sized models on multiple-choice medical exam questions. On the MedMCQA dataset, we outperform the domain-tuned Med-PaLM by +5.3% despite using 2.500$\times$ fewer parameters. Our retrieval-augmented BioLinkBERT model scored 62.9% on the MedMCQA and 55.0% on the MedQA-USMLE. Last, we show the effectiveness of our learned retriever component in the context of medical semantic search.

**摘要:** 在自然语言处理任务中,检索增强模型已经证明有效,但仍缺乏利用变异推理进行优化的研究。我们引入变异开放域(VOD)框架,以最终培训和评价检索增强模型,重点放在开放域问题回答和语言建模上。VOD的目标,是雷尼变异边界自正常化估计,近似任务边缘概率,并根据从辅助抽样分布(缓存检索和/或近似后继)提取的样本进行评估。基于检索增强的BioLinkBERT模型获得 MedMCQA的62.9%和 MedQA-USMLE的55.0%。最后,我们展示了我们学习检索组件在医学语义搜索中的作用。

**[Paper URL](https://proceedings.mlr.press/v202/lievin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lievin23a/lievin23a.pdf)** 

# Generating Novel, Designable, and Diverse Protein Structures by Equivariantly Diffusing Oriented Residue Clouds
**题目:** 以均匀扩散方向的残留云生成新型、可设计和多样的蛋白质结构

**作者:** Yeqing Lin, Mohammed Alquraishi

**Abstract:** Proteins power a vast array of functional processes in living cells. The capability to create new proteins with designed structures and functions would thus enable the engineering of cellular behavior and development of protein-based therapeutics and materials. Structure-based protein design aims to find structures that are designable (can be realized by a protein sequence), novel (have dissimilar geometry from natural proteins), and diverse (span a wide range of geometries). While advances in protein structure prediction have made it possible to predict structures of novel protein sequences, the combinatorially large space of sequences and structures limits the practicality of search-based methods. Generative models provide a compelling alternative, by implicitly learning the low-dimensional structure of complex data distributions. Here, we leverage recent advances in denoising diffusion probabilistic models and equivariant neural networks to develop Genie, a generative model of protein structures that performs discrete-time diffusion using a cloud of oriented reference frames in 3D space. Through in silico evaluations, we demonstrate that Genie generates protein backbones that are more designable, novel, and diverse than existing models. This indicates that Genie is capturing key aspects of the distribution of protein structure space and facilitates protein design with high success rates. Code for generating new proteins and training new versions of Genie is available at https://github.com/aqlaboratory/genie.

**摘要:** 蛋白质是生物细胞中广泛的功能过程的动力。通过设计的结构和功能,能够创造新的蛋白质,从而使细胞行为和蛋白质基础的治疗和材料的开发得以实现。基于结构的蛋白质设计旨在找到可设计的结构(可以通过蛋白质序列实现),新颖的(具有与自然蛋白质不同的几何)和多样的(跨越广泛的几何)。虽然蛋白质结构预测的进步使预测新颖的蛋白质序列的结构成为可能,但组合性大的序列和结构空间限制了基于搜索的方法的实用性。在此,我们利用最近的演化扩散概率模型和等价神经网络来开发Genie,一种在3D空间中利用面向参考框架的云进行离散时间扩散的蛋白质结构的生成模型。通过Silico评估,我们证明Genie产生比现有模型更可设计、新颖、多样的蛋白质后骨。这表明Genie正在捕捉蛋白质结构空间的分配关键方面,并促进蛋白质设计的高成功率。

**[Paper URL](https://proceedings.mlr.press/v202/lin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23a/lin23a.pdf)** 

# Hyperbolic Diffusion Embedding and Distance for Hierarchical Representation Learning
**题目:** 层次表示学习的超波扩散嵌入与距离

**作者:** Ya-Wei Eileen Lin, Ronald R. Coifman, Gal Mishne, Ronen Talmon

**Abstract:** Finding meaningful representations and distances of hierarchical data is important in many fields. This paper presents a new method for hierarchical data embedding and distance. Our method relies on combining diffusion geometry, a central approach to manifold learning, and hyperbolic geometry. Specifically, using diffusion geometry, we build multi-scale densities on the data, aimed to reveal their hierarchical structure, and then embed them into a product of hyperbolic spaces. We show theoretically that our embedding and distance recover the underlying hierarchical structure. In addition, we demonstrate the efficacy of the proposed method and its advantages compared to existing methods on graph embedding benchmarks and hierarchical datasets.

**摘要:** 本文提出了一种新的层次数据嵌入和距离的方法,它结合扩散几何、多变量学习的中心方法和高分子几何。具体应用扩散几何,我们在数据上建立多尺度密度,以揭示其层次结构,并将其嵌入高分子空间的产物。我们理论上表明,我们的嵌入和距离可以恢复基本层次结构。

**[Paper URL](https://proceedings.mlr.press/v202/lin23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23b/lin23b.pdf)** 

# Simplifying Momentum-based Positive-definite Submanifold Optimization with Applications to Deep Learning
**题目:** 基于动量 Positive-definite 子多变量优化的简化应用于深层学习

**作者:** Wu Lin, Valentin Duruisseaux, Melvin Leok, Frank Nielsen, Mohammad Emtiyaz Khan, Mark Schmidt

**Abstract:** Riemannian submanifold optimization with momentum is computationally challenging because, to ensure that the iterates remain on the submanifold, we often need to solve difficult differential equations. Here, we simplify such difficulties for a class of structured symmetric positive-definite matrices with the affine-invariant metric. We do so by proposing a generalized version of the Riemannian normal coordinates that dynamically orthonormalizes the metric and locally converts the problem into an unconstrained problem in the Euclidean space. We use our approach to simplify existing approaches for structured covariances and develop matrix-inverse-free $2^\text{nd}$-order optimizers for deep learning in low precision settings.

**摘要:** 以动量为 Riemann 子变量优化是计算上的挑战,因为为了确保子变量在子变量上保持不变,我们经常需要解决困难的微分方程。这里,我们简化了以非微变量度量为类结构的对称正确定矩阵的这种困难。我们这样做是通过提议一个一般化版本的 Riemann 的正常坐标,以动态正则化度量并局部转换问题为欧几里德空间中的无约束问题。

**[Paper URL](https://proceedings.mlr.press/v202/lin23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23c/lin23c.pdf)** 

# Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise
**题目:** 扩散语言模型的文本生成:基于持续段落的预训练方法

**作者:** Zhenghao Lin, Yeyun Gong, Yelong Shen, Tong Wu, Zhihao Fan, Chen Lin, Nan Duan, Weizhu Chen

**Abstract:** In this paper, we introduce a novel dIffusion language modEl pre-training framework for text generation, which we call GENIE. GENIE is a large-scale pre-trained diffusion language model that consists of an encoder and a diffusion-based decoder, which can generate text by gradually transforming a random noise sequence into a coherent text sequence. To pre-train GENIE on a large-scale language corpus, we design a new continuous paragraph denoise objective, which encourages the diffusion-decoder to reconstruct a clean text paragraph from a corrupted version, while preserving the semantic and syntactic coherence. We evaluate GENIE on four downstream text generation benchmarks, namely XSum, CNN/DailyMail, Gigaword, and CommonGen. Our experimental results show that GENIE achieves comparable performance with the state-of-the-art autoregressive models on these benchmarks, and generates more diverse text samples. The code and models of GENIE are available at https://github.com/microsoft/ProphetNet/tree/master/GENIE.

**摘要:** 本文介绍了一种新型的文本生成预训练框架,即GENIE。GENIE是一个由编码器和基于扩散的解码器组成的大规模预训练扩散语言模型,通过逐步将随机噪声序列转化为一致的文本序列来生成文本。为了在大规模语言库上预训练GENIE,我们设计了一个新的连续段落密度目标,鼓励扩散解码器从破译版本重建一个干净的段落,同时保持语义和语法的一致性。我们对GENIE在四个下游文本生成基准,即XSum、CNN/DailyMail、Gigaword和CommonGen进行了评估。GENIE的代码和模型可以在 https://github.com/microsoft/ProphetNet/tree/master/GENIE上找到。

**[Paper URL](https://proceedings.mlr.press/v202/lin23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23d/lin23d.pdf)** 

# Self-supervised Neural Factor Analysis for Disentangling Utterance-level Speech Representations
**题目:** 自我监督神经因子分析语文表达障碍

**作者:** Weiwei Lin, Chenhang He, Man-Wai Mak, Youzhi Tu

**Abstract:** Self-supervised learning (SSL) speech models such as wav2vec and HuBERT have demonstrated state-of-the-art performance on automatic speech recognition (ASR) and proved to be extremely useful in low label-resource settings. However, the success of SSL models has yet to transfer to utterance-level tasks such as speaker, emotion, and language recognition, which still require supervised fine-tuning of the SSL models to obtain good performance. We argue that the problem is caused by the lack of disentangled representations and an utterance-level learning objective for these tasks. Inspired by how HuBERT uses clustering to discover hidden acoustic units, we formulate a factor analysis (FA) model that uses the discovered hidden acoustic units to align the SSL features. The underlying utterance-level representations are disentangled using probabilistic inference on the aligned features. Furthermore, the variational lower bound derived from the FA model provides an utterance-level objective, allowing error gradients to be backpropagated to the Transformer layers to learn highly discriminative acoustic units. When used in conjunction with HuBERT’s masked prediction training, our models outperform the current best model, WavLM, on all utterance-level non-semantic tasks on the SUPERB benchmark with only 20% of labeled data.

**摘要:** 自我监督学习(SSL)语言模型,如wav2vec和HuBERT已经证明了自动语音识别(ASR)的最先进的性能,并且证明在低标记资源设置中非常有用。然而,SSL模型的成功仍需转移到口头、情感和语言识别等口头级任务,这些任务仍需要对SSL模型进行监督细微调制,以获得良好的性能。我们认为,问题是由于缺乏分开的表示和这些任务的口头级学习目标而引起的。此外,由FA模型导出的变量下限提供了口语级目标,允许误差梯度在变形层上反弹,以便学习高分辨率的音频单元。当使用HuBERT的掩盖预测训练时,我们的模型在所有口语级非语义任务上超过目前最好的模型WavLM,只有20%的标记数据。

**[Paper URL](https://proceedings.mlr.press/v202/lin23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23e/lin23e.pdf)** 

# Theory on Forgetting and Generalization of Continual Learning
**题目:** 持续学习的遗忘与一般化理论

**作者:** Sen Lin, Peizhong Ju, Yingbin Liang, Ness Shroff

**Abstract:** Continual learning (CL), which aims to learn a sequence of tasks, has attracted significant recent attention. However, most work has focused on the experimental performance of CL, and theoretical studies of CL are still limited. In particular, there is a lack of understanding on what factors are important and how they affect "catastrophic forgetting" and generalization performance. To fill this gap, our theoretical analysis, under overparameterized linear models, provides the first-known explicit form of the expected forgetting and generalization error for a general CL setup with an arbitrary number of tasks. Further analysis of such a key result yields a number of theoretical explanations about how overparameterization, task similarity, and task ordering affect both forgetting and generalization error of CL. More interestingly, by conducting experiments on real datasets using deep neural networks (DNNs), we show that some of these insights even go beyond the linear models and can be carried over to practical setups. In particular, we use concrete examples to show that our results not only explain some interesting empirical observations in recent studies, but also motivate better practical algorithm designs of CL.

**摘要:** 持续学习(CL),旨在学习任务序列,最近引起了大量关注。然而,大多数工作都集中在Cl的实验性能上,Cl的理论研究仍然有限。特别是,人们缺乏了解哪些因素是重要的,以及它们如何影响“灾难性遗忘”和一般化性能。为了填补这一空白,我们的理论分析,在过参数化线性模型下,为一般Cl设置提供了一个任意数量的任务的预期遗忘和一般化错误的第一个已知的明确形式。更有趣的是,通过对使用深度神经网络(DNN)的实物数据集进行实验,我们发现这些洞察甚至超出了线性模型,并可以被应用到实际的设置中。

**[Paper URL](https://proceedings.mlr.press/v202/lin23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23f/lin23f.pdf)** 

# Accelerated Cyclic Coordinate Dual Averaging with Extrapolation for Composite Convex Optimization
**题目:** 复合凸优化的加速度循环坐标双重平均法

**作者:** Cheuk Yin Lin, Chaobing Song, Jelena Diakonikolas

**Abstract:** Exploiting partial first-order information in a cyclic way is arguably the most natural strategy to obtain scalable first-order methods. However, despite their wide use in practice, cyclic schemes are far less understood from a theoretical perspective than their randomized counterparts. Motivated by a recent success in analyzing an extrapolated cyclic scheme for generalized variational inequalities, we propose an Accelerated Cyclic Coordinate Dual Averaging with Extrapolation (A-CODER) method for composite convex optimization, where the objective function can be expressed as the sum of a smooth convex function accessible via a gradient oracle and a convex, possibly nonsmooth, function accessible via a proximal oracle. We show that A-CODER attains the optimal convergence rate with improved dependence on the number of blocks compared to prior work. Furthermore, for the setting where the smooth component of the objective function is expressible in a finite sum form, we introduce a variance-reduced variant of A-CODER, VR-A-CODER, with state-of-the-art complexity guarantees. Finally, we demonstrate the effectiveness of our algorithms through numerical experiments.

**摘要:** 利用循环方式的局部序列信息是获得可扩展序列方法的最自然的策略。然而,尽管在实践中广泛应用,循环方案从理论角度比随机化对称方案更少被理解。由于最近成功地分析了广义变异性不平等的推导循环方案,我们提出了一种复合凸优化的加速循环坐标双比推导(A-CODER)方法,其中目标函数可以表示为通过梯度环和通过近距离环可访问的滑凸函数和凸函数的总数。此外,对于目标函数的平滑成分可以表达于有限总数形式的设置,我们引入了最先进的复杂度保证的A-CODER变量,VR-A-CODER变量。最后,我们通过数值实验证明了我们的算法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/lin23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23g/lin23g.pdf)** 

# Safe Offline Reinforcement Learning with Real-Time Budget Constraints
**题目:** 基于实时预算约束的网上安全强化学习

**作者:** Qian Lin, Bo Tang, Zifan Wu, Chao Yu, Shangqin Mao, Qianlong Xie, Xingxing Wang, Dong Wang

**Abstract:** Aiming at promoting the safe real-world deployment of Reinforcement Learning (RL), research on safe RL has made significant progress in recent years. However, most existing works in the literature still focus on the online setting where risky violations of the safety budget are likely to be incurred during training. Besides, in many realworld applications, the learned policy is required to respond to dynamically determined safety budgets (i.e., constraint threshold) in real time. In this paper, we target at the above real-time budget constraint problem under the offline setting, and propose Trajectory-based REal-time Budget Inference (TREBI) as a novel solution that approaches this problem from the perspective of trajectory distribution. Theoretically, we prove an error bound of the estimation on the episodic reward and cost under the offline setting and thus provide a performance guarantee for TREBI. Empirical results on a wide range of simulation tasks and a real-world large-scale advertising application demonstrate the capability of TREBI in solving real-time budget constraint problems under offline settings.

**摘要:** 为了促进强化学习(RL)的安全现实应用,安全RL的研究近年来取得了重大进展。然而,文献中大多数现有的工作仍集中在安全预算的危险违反在培训过程中发生的在线设置上。此外,在许多现实应用中,学习的政策需要在实时响应动态确定的安全预算(即约束阈值)。本论文针对上述在离线设置下的实时预算约束问题,并提出基于轨迹分配的观点来解决这一问题的新方案,即基于轨迹预算讨论(TREBI)。理论上,我们证明在离线设置下的 episodic reward and cost的估计有误差,从而为TREBI提供性能保证。对广泛的仿真任务和实世界大规模广告应用的实证结果表明了 TREBI在离线设置下解决实时预算约束问题的能力。

**[Paper URL](https://proceedings.mlr.press/v202/lin23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23h/lin23h.pdf)** 

# Probabilistic Unrolling: Scalable, Inverse-Free Maximum Likelihood Estimation for Latent Gaussian Models
**题目:**  Probabilistic Unrolling: Scalable, Inverse-Free Maximum Likelihood Estimation for Latent Gaussian Models

**作者:** Alexander Lin, Bahareh Tolooshams, Yves Atchade, Demba E. Ba

**Abstract:** Latent Gaussian models have a rich history in statistics and machine learning, with applications ranging from factor analysis to compressed sensing to time series analysis. The classical method for maximizing the likelihood of these models is the expectation-maximization (EM) algorithm. For problems with high-dimensional latent variables and large datasets, EM scales poorly because it needs to invert as many large covariance matrices as the number of data points. We introduce probabilistic unrolling, a method that combines Monte Carlo sampling with iterative linear solvers to circumvent matrix inversion. Our theoretical analyses reveal that unrolling and backpropagation through the iterations of the solver can accelerate gradient estimation for maximum likelihood estimation. In experiments on simulated and real data, we demonstrate that probabilistic unrolling learns latent Gaussian models up to an order of magnitude faster than gradient EM, with minimal losses in model performance.

**摘要:** 隐形高斯模型在统计学和机器学习中具有丰富的历史,其应用范围从因子分析到压缩感知到时间序列分析。这些模型的概率最大化经典方法是期望最大化(EM)算法。对于高维隐形变量和大数据集的问题,EM scales poorly because it needs to invert as many large covariance matrices as the number of data points。我们引入了概率展开,一种将蒙特卡罗样本与迭代线性求解器相结合的方法,以绕过矩阵逆转。我们的理论分析显示,通过求解器的迭代展开和逆转可以加速最大概率估计的梯度估计。

**[Paper URL](https://proceedings.mlr.press/v202/lin23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23i/lin23i.pdf)** 

# Fast Online Value-Maximizing Prediction Sets with Conformal Cost Control
**题目:** 符合成本控制的快速在线价值最大化预测集

**作者:** Zhen Lin, Shubhendu Trivedi, Cao Xiao, Jimeng Sun

**Abstract:** Many real-world multi-label prediction problems involve set-valued predictions that must satisfy specific requirements dictated by downstream usage. We focus on a typical scenario where such requirements, separately encoding value and cost, compete with each other. For instance, a hospital might expect a smart diagnosis system to capture as many severe, often co-morbid, diseases as possible (the value), while maintaining strict control over incorrect predictions (the cost). We present a general pipeline, dubbed as FavMac, to maximize the value while controlling the cost in such scenarios. FavMac can be combined with almost any multi-label classifier, affording distribution-free theoretical guarantees on cost control. Moreover, unlike prior works, FavMac can handle real-world large-scale applications via a carefully designed online update mechanism, which is of independent interest. Our methodological and theoretical contributions are supported by experiments on several healthcare tasks and synthetic datasets - FavMac furnishes higher value compared with several variants and baselines while maintaining strict cost control.

**摘要:** 许多实世界多标签预测问题涉及设置值的预测,必须满足下游使用规定的具体要求。我们关注一个典型的场景,这些要求,分别编码值和成本,互相竞争。例如,一家医院可能会期望智能诊断系统捕捉到尽可能多的严重、经常共致病、疾病(价值),同时保持严格控制错误的预测(成本)。我们提出了一种通用管道,称为FavMac,在控制这些场景中的成本的同时,最大化值。我们的方法论和理论贡献是通过对几个医疗任务和合成数据集的实验支持的 - FavMac提供与几个变量和基线相比更高的价值,同时保持严格的成本控制。

**[Paper URL](https://proceedings.mlr.press/v202/lin23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23j/lin23j.pdf)** 

# Unveiling The Mask of Position-Information Pattern Through the Mist of Image Features
**题目:** 通过图像特征的雾气揭示位置信息模式的面具

**作者:** Chieh Hubert Lin, Hung-Yu Tseng, Hsin-Ying Lee, Maneesh Kumar Singh, Ming-Hsuan Yang

**Abstract:** Recent studies have shown that paddings in convolutional neural networks encode absolute position information which can negatively affect the model performance for certain tasks. However, existing metrics for quantifying the strength of positional information remain unreliable and frequently lead to erroneous results. To address this issue, we propose novel metrics for measuring and visualizing the encoded positional information. We formally define the encoded information as Position-information Pattern from Padding (PPP) and conduct a series of experiments to study its properties as well as its formation. The proposed metrics measure the presence of positional information more reliably than the existing metrics based on PosENet and tests in F-Conv. We also demonstrate that for any extant (and proposed) padding schemes, PPP is primarily a learning artifact and is less dependent on the characteristics of the underlying padding schemes.

**摘要:** 近来的研究表明,带状神经网络中的带状神经网络可编码绝对位置信息,从而对某些任务的模型性能产生负面影响。然而,现有测定带状信息强度的测定指标仍然不可靠,往往会导致错误的结果。为了解决这个问题,我们提出了新的测定指标来测量带状信息的可视化。我们正式定义带状信息为带状信息模式(PPP),并进行了一系列实验研究其特性及其形成。

**[Paper URL](https://proceedings.mlr.press/v202/lin23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23k/lin23k.pdf)** 

# Fair yet Asymptotically Equal Collaborative Learning
**题目:** 公平,但同感性平等的协作学习

**作者:** Xiaoqiang Lin, Xinyi Xu, See-Kiong Ng, Chuan-Sheng Foo, Bryan Kian Hsiang Low

**Abstract:** In collaborative learning with streaming data, nodes (e.g., organizations) jointly and continuously learn a machine learning (ML) model by sharing the latest model updates computed from their latest streaming data. For the more resourceful nodes to be willing to share their model updates, they need to be fairly incentivized. This paper explores an incentive design that guarantees fairness so that nodes receive rewards commensurate to their contributions. Our approach leverages an explore-then-exploit formulation to estimate the nodes’ contributions (i.e., exploration) for realizing our theoretically guaranteed fair incentives (i.e., exploitation). However, we observe a "rich get richer" phenomenon arising from the existing approaches to guarantee fairness and it discourages the participation of the less resourceful nodes. To remedy this, we additionally preserve asymptotic equality, i.e., less resourceful nodes achieve equal performance eventually to the more resourceful/“rich” nodes. We empirically demonstrate in two settings with real-world streaming data: federated online incremental learning and federated reinforcement learning, that our proposed approach outperforms existing baselines in fairness and learning performance while remaining competitive in preserving equality.

**摘要:** 在协同学习中,节点(例如组织)共同和持续学习机器学习(ML)模型,通过共享从其最新流域数据计算的最新模型更新。为了使更有资源的节点愿意共享其模型更新,它们需要得到公平的激励。本文探讨了保证公平的激励设计,以使节点获得与其贡献相等的奖励。我们的方法利用探索--然后--开发公式来估计节点的贡献(即探索)实现我们理论上保证的公平激励(即剥削)。我们通过实时流数据的两个环境实证表明:联合在线渐进学习和联合强化学习,我们提出的方法在公平和学习成绩方面超越现有的基线,同时在维护平等方面保持竞争力。

**[Paper URL](https://proceedings.mlr.press/v202/lin23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23l/lin23l.pdf)** 

# Efficient Approximations of Complete Interatomic Potentials for Crystal Property Prediction
**题目:** 晶体性质预测的完整原子间势的有效近似

**作者:** Yuchao Lin, Keqiang Yan, Youzhi Luo, Yi Liu, Xiaoning Qian, Shuiwang Ji

**Abstract:** We study property prediction for crystal materials. A crystal structure consists of a minimal unit cell that is repeated infinitely in 3D space. How to accurately represent such repetitive structures in machine learning models remains unresolved. Current methods construct graphs by establishing edges only between nearby nodes, thereby failing to faithfully capture infinite repeating patterns and distant interatomic interactions. In this work, we propose several innovations to overcome these limitations. First, we propose to model physics-principled interatomic potentials directly instead of only using distances as in many existing methods. These potentials include the Coulomb potential, London dispersion potential, and Pauli repulsion potential. Second, we model the complete set of potentials among all atoms, instead of only between nearby atoms as in existing methods. This is enabled by our approximations of infinite potential summations with provable error bounds. We further develop efficient algorithms to compute the approximations. Finally, we propose to incorporate our computations of complete interatomic potentials into message passing neural networks for representation learning. We perform experiments on the JARVIS and Materials Project benchmarks for evaluation. Results show that the use of interatomic potentials and complete interatomic potentials leads to consistent performance improvements with reasonable computational costs. Our code is publicly available as part of the AIRS library (https://github.com/divelab/AIRS).

**摘要:** 我们研究了晶体材料的性质预测。晶体结构由微小单元细胞组成,在3D空间中重复无穷。如何准确地代表机器学习模型中的这种重复结构仍未得到解决。目前的方法通过在附近的节点之间建立边缘来构造图形,从而不能忠实地捕捉无穷重复模式和遥远的原子间相互作用。在这个工作中,我们提出了克服这些局限性的若干创新。我们进一步开发了有效的算法来计算近似值。最后,我们建议将我们完全的原子能计算纳入信息传递神经网络中,用于表示学习。我们对JARVIS和材料项目的评判指标进行了实验。结果表明,使用原子能和完全的原子能会导致持续的性能改进,计算成本合理。我们的代码已作为AIRS库的一部分公开(https://github.com/divelab/AIRS)。

**[Paper URL](https://proceedings.mlr.press/v202/lin23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23m/lin23m.pdf)** 

# Continuation Path Learning for Homotopy Optimization
**题目:** 同位素优化的持续路径学习

**作者:** Xi Lin, Zhiyuan Yang, Xiaoyuan Zhang, Qingfu Zhang

**Abstract:** Homotopy optimization is a traditional method to deal with a complicated optimization problem by solving a sequence of easy-to-hard surrogate subproblems. However, this method can be very sensitive to the continuation schedule design and might lead to a suboptimal solution to the original problem. In addition, the intermediate solutions, often ignored by classic homotopy optimization, could be useful for many real-world applications. In this work, we propose a novel model-based approach to learn the whole continuation path for homotopy optimization, which contains infinite intermediate solutions for any surrogate subproblems. Rather than the classic unidirectional easy-to-hard optimization, our method can simultaneously optimize the original problem and all surrogate subproblems in a collaborative manner. The proposed model also supports the real-time generation of any intermediate solution, which could be desirable for many applications. Experimental studies on different problems show that our proposed method can significantly improve the performance of homotopy optimization and provide extra helpful information to support better decision-making.

**摘要:** 同位素优化是一种传统的处理复杂优化问题的方法,通过解决易于重置子问题的序列。然而,这种方法对持续时间表设计非常敏感,可能导致初始问题的次优解。此外,传统的同位素优化经常忽略的中间解决方案,对于许多实世界应用有用。本研究中,我们提出了一种新的基于模型的方法来学习同位素优化的整个持续路径,该路径包含任何代位子子问题的无限中间解决方案。对不同问题的实验研究表明,我们提出的方法可以大大提高同位素优化的性能,并提供较有帮助的信息,以支持更好的决策。

**[Paper URL](https://proceedings.mlr.press/v202/lin23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lin23n/lin23n.pdf)** 

# Speed-Oblivious Online Scheduling: Knowing (Precise) Speeds is not Necessary
**题目:** 快速可知的在线计划:知道(准确)的速度是不需要的

**作者:** Alexander Lindermayr, Nicole Megow, Martin Rapp

**Abstract:** We consider online scheduling on unrelated (heterogeneous) machines in a speed-oblivious setting, where an algorithm is unaware of the exact job-dependent processing speeds. We show strong impossibility results for clairvoyant and non-clairvoyant algorithms and overcome them in models inspired by practical settings: (i) we provide competitive learning-augmented algorithms, assuming that (possibly erroneous) predictions on the speeds are given, and (ii) we provide competitive algorithms for the speed-ordered model, where a single global order of machines according to their unknown job-dependent speeds is known. We prove strong theoretical guarantees and evaluate our findings on a representative heterogeneous multi-core processor. These seem to be the first empirical results for scheduling algorithms with predictions that are evaluated in a non-synthetic hardware environment.

**摘要:** 我们考虑在无关联的(异质)机器上进行在线调度,在速度可知的设置中,算法不了解工作依赖的处理速度。我们对透明和非透明算法显示强的不可能结果,并在实际设置启发的模型中克服它们: (i)我们提供竞争性学习增强算法,假设速度上的预测(可能是错误的)是给出的, (ii)我们提供竞争性算法用于速度顺序模型,其中根据它们未知的工作依赖速度的单一全球顺序是已知的。

**[Paper URL](https://proceedings.mlr.press/v202/lindermayr23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lindermayr23a/lindermayr23a.pdf)** 

# Graph Mixup with Soft Alignments
**题目:**  Graph Mixup 与软整列

**作者:** Hongyi Ling, Zhimeng Jiang, Meng Liu, Shuiwang Ji, Na Zou

**Abstract:** We study graph data augmentation by mixup, which has been used successfully on images. A key operation of mixup is to compute a convex combination of a pair of inputs. This operation is straightforward for grid-like data, such as images, but challenging for graph data. The key difficulty lies in the fact that different graphs typically have different numbers of nodes, and thus there lacks a node-level correspondence between graphs. In this work, we propose S-Mixup, a simple yet effective mixup method for graph classification by soft alignments. Specifically, given a pair of graphs, we explicitly obtain node-level correspondence via computing a soft assignment matrix to match the nodes between two graphs. Based on the soft assignments, we transform the adjacency and node feature matrices of one graph, so that the transformed graph is aligned with the other graph. In this way, any pair of graphs can be mixed directly to generate an augmented graph. We conduct systematic experiments to show that S-Mixup can improve the performance and generalization of graph neural networks (GNNs) on various graph classification tasks. In addition, we show that S-Mixup can increase the robustness of GNNs against noisy labels. Our code is publicly available as part of the DIG package (https://github.com/divelab/DIG).

**摘要:** 我们研究了通过混合来增加图形数据,并将其成功地应用于图形上。混合的关键操作是计算一对输入的凸组合。该操作是直接用于网格式数据,如图形,但对图形数据具有挑战性。关键困难在于不同的图形通常有不同的节点数,因此缺乏不同图形之间的节点级相符。在这个工作中,我们提议S-Mixup,一种简单但有效的混合方法,通过软配位来分类图形。具体而言,给给一对图形,我们通过计算软配位矩阵来明确地获得两个图形之间的节点的相符。基于软配位,我们将一个图形的相邻和节点特征矩阵变换成一个图形,使变换的图形与另一个图形相符。我们进行了系统性实验,证明S-Mixup可以在不同图类别任务上提高图神经网络的性能和推广。此外,我们还表明S-Mixup可以提高GNN的鲁棒性,抵御噪声标签。我们的代码作为DIG软件包的一部分是公开的(https://github.com/divelab/DIG)。

**[Paper URL](https://proceedings.mlr.press/v202/ling23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ling23a/ling23a.pdf)** 

# Deep Graph Representation Learning and Optimization for Influence Maximization
**题目:** 深度图表表示学习和影响最大化优化

**作者:** Chen Ling, Junji Jiang, Junxiang Wang, My T. Thai, Renhao Xue, James Song, Meikang Qiu, Liang Zhao

**Abstract:** Influence maximization (IM) is formulated as selecting a set of initial users from a social network to maximize the expected number of influenced users. Researchers have made great progresses to design various traditional methods, yet both theoretical design and performance gain are close to their limits. In the past few years, learning-based IM methods have emerged to achieve stronger generalization ability to unknown graphs than traditional ones. However, the development of learning-based IM methods is still limited by fundamental obstacles, including 1) the difficulty of effectively solving the objective function; 2) the difficulty of characterizing the diversified and underlying diffusion patterns; and 3) the difficulty of adapting the solution under various node-centrality-constrained IM variants. To cope with the above challenges, we design a novel framework DeepIM to generatively characterize the latent representation of seed sets, and we propose to learn the diversified information diffusion pattern in a data-driven and end-to-end manner. Finally, we design a novel objective function to infer optimal seed sets under flexible node-centrality-based budget constraints. Extensive analyses are conducted over both synthetic and real-world datasets to demonstrate the overall performance of DeepIM.

**摘要:** 影响最大化(英语:Influence maximization,缩写:IM)是通过从社交网络中选择一系列初始用户来最大化预期的受影响用户数量来制定的,研究者在设计各种传统方法方面取得了巨大的进展,但理论设计和性能提升都接近其局限性。在过去几年中,基于学习的IM方法已经出现,以实现未知图形的更强的一般化能力。然而,基于学习的IM方法的发展仍然受到基本障碍的限制,包括 1)有效解决目标函数的困难; 2)对多样化和基础扩散模式的特征的困难; 3)在不同节点中心约束的IM变异下调整解决方案的困难。为了应付上述挑战,我们设计了一种新的 DeepIM框架,以生成性地描述种子集的潜在表现,并提出以数据驱动和end-to-end的方式学习多样化的信息扩散模式。最后,我们设计了一种新的目标函数,以根据灵活的节点中心性预算约束推导最佳种子集。

**[Paper URL](https://proceedings.mlr.press/v202/ling23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ling23b/ling23b.pdf)** 

# Emergent Agentic Transformer from Chain of Hindsight Experience
**题目:** 脉冲远视经验中的紧急代理变换器

**作者:** Hao Liu, Pieter Abbeel

**Abstract:** Large transformer models powered by diverse data and model scale have dominated natural language modeling and computer vision and pushed the frontier of multiple AI areas. In reinforcement learning (RL), despite many efforts into transformer-based policies, a key limitation, however, is that current transformer-based policies cannot learn by directly combining information from multiple sub-optimal trials. In this work, we address this issue using recently proposed chain of hindsight to relabel experience, where we train a transformer on a sequence of trajectory experience ascending sorted according to their total rewards. Our method consists of relabelling target return of each trajectory to the maximum total reward among in sequence of trajectories and training an autoregressive model to predict actions conditioning on past states, actions, rewards, target returns, and task completion tokens, the resulting model, Agentic Transformer (AT), can learn to improve upon itself both at training and test time. As we show on D4RL and ExoRL benchmarks, to the best our knowledge, this is the first time that a simple transformer-based model performs competitively with both temporal-difference and imitation-learning-based approaches, even from sub-optimal data. Our Agentic Transformer also shows a promising scaling trend that bigger models consistently improve results.

**摘要:** 基于多数据和模型规模的大型变换器模型主导了自然语言建模和计算机视觉, pushed the frontier of multiple AI areas. 在增强学习(RL)中,尽管在基于变换器的政策方面作出了大量努力,但一个关键的限制是,当前基于变换器的政策不能通过直接结合多个次优试验的信息来学习。我们的方法 consists of relabelling target return of each trajectory to the maximum total reward among in sequence of trajectories and training an autogressive model to predict actions conditioning on past states, actions, rewards, target returns, and task completion tokens, the resulting model, Agentic Transformer (AT), can learn to improve upon itself both at training and test time. As we show on D4RL and ExoRL benchmarks, to the best our knowledge, this is the first time that a simple transformer-based model performs competitively with both temporal-difference and imitation-learning-based approaches, even from sub-optimal data. Our Agentic Transformer also shows a promising scaling trend that bigger models consistently improve results.

**[Paper URL](https://proceedings.mlr.press/v202/liu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23a/liu23a.pdf)** 

# Shapley Based Residual Decomposition for Instance Analysis
**题目:** 基于形状的残留分解法实例分析

**作者:** Tommy Liu, Amanda S Barnard

**Abstract:** In this paper, we introduce the idea of decomposing the residuals of regression with respect to the data instances instead of features. This allows us to determine the effects of each individual instance on the model and each other, and in doing so makes for a model-agnostic method of identifying instances of interest. In doing so, we can also determine the appropriateness of the model and data in the wider context of a given study. The paper focuses on the possible applications that such a framework brings to the relatively unexplored field of instance analysis in the context of Explainable AI tasks.

**摘要:** 本文介绍了关于数据实例而非特征的回归残余分解的概念,可以确定每个个体实例对模型和彼此的影响,并以此为确定感兴趣的实例的模型 agnostic方法。在此基础上,我们还可以确定该模型和数据在特定研究的更广泛范围内是否适宜。本文着重讨论了这种框架在解释性人工智能任务的实例分析领域中所带来的可能应用。

**[Paper URL](https://proceedings.mlr.press/v202/liu23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23b/liu23b.pdf)** 

# Learning Representations without Compositional Assumptions
**题目:** 无成分假设的学习表现

**作者:** Tennison Liu, Jeroen Berrevoets, Zhaozhi Qian, Mihaela Van Der Schaar

**Abstract:** This paper addresses unsupervised representation learning on tabular data containing multiple views generated by distinct sources of measurement. Traditional methods, which tackle this problem using the multi-view framework, are constrained by predefined assumptions that assume feature sets share the same information and representations should learn globally shared factors. However, this assumption is not always valid for real-world tabular datasets with complex dependencies between feature sets, resulting in localized information that is harder to learn. To overcome this limitation, we propose a data-driven approach that learns feature set dependencies by representing feature sets as graph nodes and their relationships as learnable edges. Furthermore, we introduce $\texttt{LEGATO}$, a novel hierarchical graph autoencoder that learns a smaller, latent graph to aggregate information from multiple views dynamically. This approach results in latent graph components that specialize in capturing localized information from different regions of the input, leading to superior downstream performance.

**摘要:** 本文讨论了由不同测量源生成的多视图的表数据上不受监督的表示学习问题。传统的方法,以多视图框架来解决这一问题,受到假设特征集共享相同的信息和表示应该学习全球共享因素的预先定义假设的约束。然而,这种假设并不总是适用于具有特征集间复杂依赖性的实世界表数据集,从而导致难以学习的本地化信息。为了克服这一限制,我们提出了一种基于数据的方法,以表示特征集为图节点和其关系为可学习边缘来学习特征集依赖性。这种方法的结果是潜在的图组成部分专门捕捉来自输入的不同区域的本地化信息,导致了优越的下游性能。

**[Paper URL](https://proceedings.mlr.press/v202/liu23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23c/liu23c.pdf)** 

# Byzantine-Robust Learning on Heterogeneous Data via Gradient Splitting
**题目:** 通过梯度分割对异质数据的拜占庭-罗布斯特学习

**作者:** Yuchen Liu, Chen Chen, Lingjuan Lyu, Fangzhao Wu, Sai Wu, Gang Chen

**Abstract:** Federated learning has exhibited vulnerabilities to Byzantine attacks, where the Byzantine attackers can send arbitrary gradients to a central server to destroy the convergence and performance of the global model. A wealth of robust AGgregation Rules (AGRs) have been proposed to defend against Byzantine attacks. However, Byzantine clients can still circumvent robust AGRs when data is non-Identically and Independently Distributed (non-IID). In this paper, we first reveal the root causes of performance degradation of current robust AGRs in non-IID settings: the curse of dimensionality and gradient heterogeneity. In order to address this issue, we propose GAS, a GrAdient Splitting approach that can successfully adapt existing robust AGRs to non-IID settings. We also provide a detailed convergence analysis when the existing robust AGRs are combined with GAS. Experiments on various real-world datasets verify the efficacy of our proposed GAS. The implementation code is provided in https://github.com/YuchenLiu-a/byzantine-gas.

**摘要:** 联合学习已经显示出对拜占庭攻击的脆弱性,拜占庭攻击者可以向中央服务器发送任意梯度来破坏全球模型的收敛性和性能。为了防卫拜占庭攻击,提出了大量强格gregation Rules(AGRs)。然而,拜占庭客户仍然可以绕过数据非身份和独立分布(non-IID)时的强格gregation Rules(AGRs)。本论文首先揭示了非IID设置中的当前强格gregation Rules(AGRs)性能下降的根本原因:维度和梯度异构的诅咒。为了解决这一问题,我们提出了GAS,一种可以成功地调整现有强格格gregation Rules(AGRs)到非IID设置的GrAdient Splitting方法。实现代码为 https://github.com/YuchenLiu-a/byzantine-gas。

**[Paper URL](https://proceedings.mlr.press/v202/liu23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23d/liu23d.pdf)** 

# Towards Constituting Mathematical Structures for Learning to Optimize
**题目:** 构建优化学习的数学结构

**作者:** Jialin Liu, Xiaohan Chen, Zhangyang Wang, Wotao Yin, Hanqin Cai

**Abstract:** Learning to Optimize (L2O), a technique that utilizes machine learning to learn an optimization algorithm automatically from data, has gained arising attention in recent years. A generic L2O approach parameterizes the iterative update rule and learns the update direction as a black-box network. While the generic approach is widely applicable, the learned model can overfit and may not generalize well to out-of-distribution test sets. In this paper, we derive the basic mathematical conditions that successful update rules commonly satisfy. Consequently, we propose a novel L2O model with a mathematics-inspired structure that is broadly applicable and generalized well to out-of-distribution problems. Numerical simulations validate our theoretical findings and demonstrate the superior empirical performance of the proposed L2O model.

**摘要:** 优化学习(英语:Learning to Optimize,简称L2O)是利用机器学习来自动从数据中学习优化算法的一种技术,近年来引起了人们的关注。一种通用的L2O方法对迭代更新规则进行参数化,并学习更新方向作为黑箱网络。虽然通用的方法广泛适用,但学习的模型可能超过,并不能对非分布测试集进行一般化。本文给出了成功更新规则普遍满足的基本数学条件,因此提出了一种具有数学启发结构的新型L2O模型,适用于非分布问题。

**[Paper URL](https://proceedings.mlr.press/v202/liu23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23e/liu23e.pdf)** 

# AudioLDM: Text-to-Audio Generation with Latent Diffusion Models
**题目:** AudioLDM:基于潜在扩散模型的文本到音频生成

**作者:** Haohe Liu, Zehua Chen, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, Mark D Plumbley

**Abstract:** Text-to-audio (TTA) systems have recently gained attention for their ability to synthesize general audio based on text descriptions. However, previous studies in TTA have limited generation quality with high computational costs. In this study, we propose AudioLDM, a TTA system that is built on a latent space to learn continuous audio representations from contrastive language-audio pretraining (CLAP) embeddings. The pretrained CLAP models enable us to train LDMs with audio embeddings while providing text embeddings as the condition during sampling. By learning the latent representations of audio signals without modelling the cross-modal relationship, AudioLDM improves both generation quality and computational efficiency. Trained on AudioCaps with a single GPU, AudioLDM achieves state-of-the-art TTA performance compared to other open-sourced systems, measured by both objective and subjective metrics. AudioLDM is also the first TTA system that enables various text-guided audio manipulations (e.g., style transfer) in a zero-shot fashion. Our implementation and demos are available at https://audioldm.github.io.

**摘要:** Text-to-audio(TTA)系统最近因其基于文本描述的通用音频合成能力而引起关注。然而,TTA的先前研究具有有限的生成质量和高计算成本。在本研究中,我们提议AudioLDM,一种基于潜在空间的TTA系统,以学习对比语言-音频预训练(CLAP)嵌入式连续的音频表示。预处理的CLAP模型使我们能够训练LDM与音频嵌入式同时提供文本嵌入式作为采样条件。通过学习音频信号的潜在表示而不建模交叉模态关系,AudioLDM提高了生成质量和计算效率。AudioLDM也是第一个以零射击方式实现各种文本驱动的音频操作(例如风格转换)的TTA系统。我们的实现和试演可于 https://audioldm.github.io。

**[Paper URL](https://proceedings.mlr.press/v202/liu23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23f/liu23f.pdf)** 

# Identifiability of Label Noise Transition Matrix
**题目:** 标签噪声过渡矩阵的识别性

**作者:** Yang Liu, Hao Cheng, Kun Zhang

**Abstract:** The noise transition matrix plays a central role in the problem of learning with noisy labels. Among many other reasons, a large number of existing solutions rely on the knowledge of it. Identifying and estimating the transition matrix without ground truth labels is a critical and challenging task. When label noise transition depends on each instance, the problem of identifying the instance-dependent noise transition matrix becomes substantially more challenging. Despite recently proposed solutions for learning from instance-dependent noisy labels, the literature lacks a unified understanding of when such a problem remains identifiable. The goal of this paper is to characterize the identifiability of the label noise transition matrix. Building on Kruskal’s identifiability results, we are able to show the necessity of multiple noisy labels in identifying the noise transition matrix at the instance level. We further instantiate the results to explain the successes of the state-of-the-art solutions and how additional assumptions alleviated the requirement of multiple noisy labels. Our result reveals that disentangled features improve identification. This discovery led us to an approach that improves the estimation of the transition matrix using properly disentangled features. Code is available at https://github.com/UCSC-REAL/Identifiability.

**摘要:** 噪声变换矩阵在学习噪声变换矩阵中起着中心作用。在许多其他原因中,很多现有的解决方案都依赖于它的知识。识别和估计没有地面真实标签的变换矩阵是一个关键和挑战性的任务。当标签噪声变换依赖于每个实例时,识别依赖于实例的噪声变换矩阵的难题变得更加艰巨。尽管最近提出了从依赖于实例的噪声变换矩阵学习的解决方案,但文献缺乏一个统一的理解,当这样的问题仍然可识别时。本论文的目标是对标签噪声变换矩阵的识别性进行特征化。我们进一步的实证结果,解释了最先进的解决方案的成功,以及额外的假设如何减轻多个噪声标签的要求。我们的结果显示,异构特征改善识别。这一发现导致我们采用适当异构特征来改进过渡矩阵的估计方法。代码在 https://github.com/UCSC-REAL/Identifiability 上。

**[Paper URL](https://proceedings.mlr.press/v202/liu23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23g/liu23g.pdf)** 

# A Group Symmetric Stochastic Differential Equation Model for Molecule Multi-modal Pretraining
**题目:** 分子多模预训练的群交称随机微分方程模型

**作者:** Shengchao Liu, Weitao Du, Zhi-Ming Ma, Hongyu Guo, Jian Tang

**Abstract:** Molecule pretraining has quickly become the go-to schema to boost the performance of AI-based drug discovery. Naturally, molecules can be represented as 2D topological graphs or 3D geometric point clouds. Although most existing pertaining methods focus on merely the single modality, recent research has shown that maximizing the mutual information (MI) between such two modalities enhances the molecule representation ability. Meanwhile, existing molecule multi-modal pretraining approaches approximate MI based on the representation space encoded from the topology and geometry, thus resulting in the loss of critical structural information of molecules. To address this issue, we propose MoleculeSDE. MoleculeSDE leverages group symmetric (e.g., SE(3)-equivariant and reflection-antisymmetric) stochastic differential equation models to generate the 3D geometries from 2D topologies, and vice versa, directly in the input space. It not only obtains tighter MI bound but also enables prosperous downstream tasks than the previous work. By comparing with 17 pretraining baselines, we empirically verify that MoleculeSDE can learn an expressive representation with state-of-the-art performance on 26 out of 32 downstream tasks.

**摘要:** 分子预训练已经迅速成为提高基于人工智能的药物发现性能的模式。当然,分子可以作为2D拓扑图形或3D几何点云表示。虽然大多数现有的相关方法只关注单一模式,但最近的研究表明,在两种模式之间最大化相互信息(MI)增强了分子的表示能力。与此同时,现有的分子多模式预训练方法基于拓扑和几何编码的表示空间近似MI,从而导致分子的关键结构信息丢失。通过与17个预训练基线的比较,我们实验验证了MoleculeSDE可以在32个下游任务中26个中学习最先进的表现。

**[Paper URL](https://proceedings.mlr.press/v202/liu23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23h/liu23h.pdf)** 

# Using Perturbation to Improve Goodness-of-Fit Tests based on Kernelized Stein Discrepancy
**题目:** 基于核化石异质的扰动改善适度测试

**作者:** Xing Liu, Andrew B. Duncan, Axel Gandy

**Abstract:** Kernelized Stein discrepancy (KSD) is a score-based discrepancy widely used in goodness-of-fit tests. It can be applied even when the target distribution has an unknown normalising factor, such as in Bayesian analysis. We show theoretically and empirically that the KSD test can suffer from low power when the target and the alternative distributions have the same well-separated modes but differ in mixing proportions. We propose to perturb the observed sample via Markov transition kernels, with respect to which the target distribution is invariant. This allows us to then employ the KSD test on the perturbed sample. We provide numerical evidence that with suitably chosen transition kernels the proposed approach can lead to substantially higher power than the KSD test.

**摘要:** 核化施泰因相差(英语:Kernelized Stein discrepancy,KSD)是一种基于分数的相差,广泛应用于适度测试中。它甚至可以在目标分布有未知的正常化因子时应用,例如在贝叶斯分析中。我们从理论上和经验上表明,当目标和替代分布有相同的分离模式,但混合比例不同时,KSD测试可能受到低功率的影响。我们建议通过马可夫过渡核扰动观察到的样品,以致目标分布不变。这允许我们在扰动样品上使用KSD测试。

**[Paper URL](https://proceedings.mlr.press/v202/liu23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23i/liu23i.pdf)** 

# Cones: Concept Neurons in Diffusion Models for Customized Generation
**题目:** 锥形:定制生成扩散模型中的概念神经元

**作者:** Zhiheng Liu, Ruili Feng, Kai Zhu, Yifei Zhang, Kecheng Zheng, Yu Liu, Deli Zhao, Jingren Zhou, Yang Cao

**Abstract:** Human brains respond to semantic features of presented stimuli with different neurons. This raises the question of whether deep neural networks admit a similar behavior pattern. To investigate this phenomenon, this paper identifies a small cluster of neurons associated with a specific subject in a diffusion model. We call those neurons the concept neurons. They can be identified by statistics of network gradients to a stimulation connected with the given subject. The concept neurons demonstrate magnetic properties in interpreting and manipulating generation results. Shutting them can directly yield the related subject contextualized in different scenes. Concatenating multiple clusters of concept neurons can vividly generate all related concepts in a single image. Our method attains impressive performance for multi-subject customization, even four or more subjects. For large-scale applications, the concept neurons are environmentally friendly as we only need to store a sparse cluster of int index instead of dense float32 parameter values, reducing storage consumption by 90% compared with previous customized generation methods. Extensive qualitative and quantitative studies on diverse scenarios show the superiority of our method in interpreting and manipulating diffusion models.

**摘要:** 人类大脑与不同的神经元对提示刺激的语义特征作出反应,这引发了深层神经网络是否承认类似的行为模式的问题。为了研究这一现象,本文在扩散模型中识别了与特定对象相关的小神经元集群。我们称这些神经元为概念神经元。它们可以通过网络梯度的统计来识别与特定对象关联的刺激。概念神经元在解释和操作生成结果中显示出磁性特性。关闭它们可以直接产生不同场景中的关联对象的上下文。在大型应用中,概念神经元是环保的,因为我们只需要存储一个稀疏的int指数群,而不是密集的 float32参数值,比以前的定制生成方法减少存储消耗的90%。

**[Paper URL](https://proceedings.mlr.press/v202/liu23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23j/liu23j.pdf)** 

# Opponent-Limited Online Search for Imperfect Information Games
**题目:** 不完美信息游戏的对手限定在线搜索

**作者:** Weiming Liu, Haobo Fu, Qiang Fu, Yang Wei

**Abstract:** In recent years, online search has been playing an increasingly important role in imperfect information games (IIGs). Previous online search is known as common-knowledge subgame solving, which has to consider all the states in a common-knowledge closure. This is only computationally tolerable for medium size games, such as poker. To handle larger games, order-1 Knowledge-Limited Subgame Solving (1-KLSS) only considers the states in a knowledge-limited closure, which results in a much smaller subgame. However, 1-KLSS is unsafe. In this paper, we first extend 1-KLSS to Safe-1-KLSS and prove its safeness. To make Safe-1-KLSS applicable to even larger games, we propose Opponent-Limited Subgame Solving (OLSS) to limit how the opponent reaches a subgame and how it acts in the subgame. Limiting the opponent’s strategy dramatically reduces the subgame size and improves the efficiency of subgame solving while still preserving some safety in the limit. Experiments in medium size poker show that Safe-1-KLSS and OLSS are orders of magnitude faster than previous common-knowledge subgame solving. Also, OLSS significantly improves the online performance in a two-player Mahjong game, whose game size prohibits the use of previous common-knowledge subgame-solving methods.

**摘要:** 近年来,在线搜索在不完备的信息游戏(IIGs)中发挥着越来越重要的作用。以前的在线搜索被称为普通知识子游戏解决,它必须考虑在普通知识关卡中的所有状态。这仅在计算上可容纳中等大小游戏,例如扑克。为了处理较大的游戏,命令-1知识有限子游戏解决(1-KLSS)只考虑在知识有限关卡中的所有状态,从而导致一个较小的子游戏。然而,1-KLSS是不安全的。中型扑克的实验表明,Safe-1-KLSS和OLSS比以前的普通知识子游戏解决速度快得多,而且,OLSS大大提高了两个玩家 Mahjong游戏的在线性能,其游戏大小禁止使用以前的普通知识子游戏解决方法。

**[Paper URL](https://proceedings.mlr.press/v202/liu23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23k/liu23k.pdf)** 

# Towards Robust and Safe Reinforcement Learning with Benign Off-policy Data
**题目:** 基于非政策数据的稳健和安全强化学习

**作者:** Zuxin Liu, Zijian Guo, Zhepeng Cen, Huan Zhang, Yihang Yao, Hanjiang Hu, Ding Zhao

**Abstract:** Previous work demonstrates that the optimal safe reinforcement learning policy in a noise-free environment is vulnerable and could be unsafe under observational attacks. While adversarial training effectively improves robustness and safety, collecting samples by attacking the behavior agent online could be expensive or prohibitively dangerous in many applications. We propose the robuSt vAriational ofF-policy lEaRning (SAFER) approach, which only requires benign training data without attacking the agent. SAFER obtains an optimal non-parametric variational policy distribution via convex optimization and then uses it to improve the parameterized policy robustly via supervised learning. The two-stage policy optimization facilitates robust training, and extensive experiments on multiple robot platforms show the efficiency of SAFER in learning a robust and safe policy: achieving the same reward with much fewer constraint violations during training than on-policy baselines.

**摘要:** 以往的研究表明,在无噪环境中,最佳安全强化学习策略是脆弱的,在观察攻击下可能不安全。敌对训练有效提高鲁棒性和安全性,通过攻击行为代理在线收集样本可能在许多应用中很昂贵或极危险。我们建议采用鲁棒vAriational的F-policy lEaRning(SAFER)方法,仅需要无害训练数据而不攻击代理。SAFER通过凸优化获得最佳非参数变量政策分配,然后通过监督学习改进参数化政策。

**[Paper URL](https://proceedings.mlr.press/v202/liu23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23l/liu23l.pdf)** 

# Constrained Decision Transformer for Offline Safe Reinforcement Learning
**题目:** 网上安全强化学习约束决策转换器

**作者:** Zuxin Liu, Zijian Guo, Yihang Yao, Zhepeng Cen, Wenhao Yu, Tingnan Zhang, Ding Zhao

**Abstract:** Safe reinforcement learning (RL) trains a constraint satisfaction policy by interacting with the environment. We aim to tackle a more challenging problem: learning a safe policy from an offline dataset. We study the offline safe RL problem from a novel multi-objective optimization perspective and propose the $\epsilon$-reducible concept to characterize problem difficulties. The inherent trade-offs between safety and task performance inspire us to propose the constrained decision transformer (CDT) approach, which can dynamically adjust the trade-offs during deployment. Extensive experiments show the advantages of the proposed method in learning an adaptive, safe, robust, and high-reward policy. CDT outperforms its variants and strong offline safe RL baselines by a large margin with the same hyperparameters across all tasks, while keeping the zero-shot adaptation capability to different constraint thresholds, making our approach more suitable for real-world RL under constraints.

**摘要:** 安全强化学习(英语:Safe reinforcement learning,简称RL)是通过与环境互动来培养约束满意政策。我们的目标是解决一个更加挑战性的问题:从一个非线性数据集学习安全政策。我们从一种新颖的多目标优化视角研究非线性安全RL问题,并提出$\epsilon$-可缩减的概念来描述问题困难。安全和任务性能之间的内在交易激励我们提出约束决策变换器(CDT)方法,它可以动态调整部署期间的交易权限。

**[Paper URL](https://proceedings.mlr.press/v202/liu23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23m/liu23m.pdf)** 

# Understanding and Defending Patched-based Adversarial Attacks for Vision Transformer
**题目:** 理解和防御基于 Patched的视觉变换器的敌对攻击

**作者:** Liang Liu, Yanan Guo, Youtao Zhang, Jun Yang

**Abstract:** Vision Transformer (ViT) is an attention-based model architecture that has demonstrated superior performance on many computer vision tasks. However, its security properties, in particular, the robustness against adversarial attacks, are yet to be thoroughly studied. Recent works have shown that ViT is vulnerable to attention-based adversarial patch attacks, which cover 1-3% area of the input image using adversarial patches and degrades the model accuracy to 0%. This work provides a generic study targeting the attention-based patch attack. First, we experimentally observe that adversarial patches only activate in a few layers and become lazy during attention updating. According to experiments, we study the theory of how a small adversarial patch perturbates the whole model. Based on understanding adversarial patch attacks, we propose a simple but efficient defense that correctly detects more than 95% of adversarial patches.

**摘要:** 视觉变换器(ViT)是一种基于注意力的模型架构,它在许多计算机视觉任务中表现出了优越的性能。然而,它的安全性特性,特别是对敌对攻击的鲁棒性,尚待深入研究。最近的研究表明ViT易于基于注意力的敌对补丁攻击,以敌对补丁的方式覆盖输入图像的1-3%区域,并降低模型精度到0%。这项研究提供了针对敌对补丁攻击的一般性研究。

**[Paper URL](https://proceedings.mlr.press/v202/liu23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23n/liu23n.pdf)** 

# NUNO: A General Framework for Learning Parametric PDEs with Non-Uniform Data
**题目:** NUNO:非统一数据学习参数数据的通用框架

**作者:** Songming Liu, Zhongkai Hao, Chengyang Ying, Hang Su, Ze Cheng, Jun Zhu

**Abstract:** The neural operator has emerged as a powerful tool in learning mappings between function spaces in PDEs. However, when faced with real-world physical data, which are often highly non-uniformly distributed, it is challenging to use mesh-based techniques such as the FFT. To address this, we introduce the Non-Uniform Neural Operator (NUNO), a comprehensive framework designed for efficient operator learning with non-uniform data. Leveraging a K-D tree-based domain decomposition, we transform non-uniform data into uniform grids while effectively controlling interpolation error, thereby paralleling the speed and accuracy of learning from non-uniform data. We conduct extensive experiments on 2D elasticity, (2+1)D channel flow, and a 3D multi-physics heatsink, which, to our knowledge, marks a novel exploration into 3D PDE problems with complex geometries. Our framework has reduced error rates by up to 60% and enhanced training speeds by 2x to 30x. The code is now available at https://github.com/thu-ml/NUNO .

**摘要:** 神经运算器已成为PDEs中功能空间之间的学习映射的有力工具。然而,当面对经常高度不均匀分布的实物数据时,使用网格技术,如FFT是挑战性的。为了解决这个问题,我们引入了非均匀神经运算器(NUNO),为非均匀数据的有效运算器学习设计的综合框架。利用K-D树基域分解,我们将非均匀数据转化为均匀网格,同时有效地控制插值误差,从而平行非均匀数据学习的速度和精度。代码现在可以在 https://github.com/thu-ml/NUNO 上找到。

**[Paper URL](https://proceedings.mlr.press/v202/liu23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23o/liu23o.pdf)** 

# Hierarchical Programmatic Reinforcement Learning via Learning to Compose Programs
**题目:** 通过学习编写程序的层次性方案强化学习

**作者:** Guan-Ting Liu, En-Pei Hu, Pu-Jen Cheng, Hung-Yi Lee, Shao-Hua Sun

**Abstract:** Aiming to produce reinforcement learning (RL) policies that are human-interpretable and can generalize better to novel scenarios, Trivedi et al. (2021) present a method (LEAPS) that first learns a program embedding space to continuously parameterize diverse programs from a pre-generated program dataset, and then searches for a task-solving program in the learned program embedding space when given a task. Despite the encouraging results, the program policies that LEAPS can produce are limited by the distribution of the program dataset. Furthermore, during searching, LEAPS evaluates each candidate program solely based on its return, failing to precisely reward correct parts of programs and penalize incorrect parts. To address these issues, we propose to learn a meta-policy that composes a series of programs sampled from the learned program embedding space. By learning to compose programs, our proposed hierarchical programmatic reinforcement learning (HPRL) framework can produce program policies that describe out-of-distributionally complex behaviors and directly assign credits to programs that induce desired behaviors. The experimental results in the Karel domain show that our proposed framework outperforms baselines. The ablation studies confirm the limitations of LEAPS and justify our design choices.

**摘要:** 特里维迪等人(英语:Trivedi et al.,2021)提出了一种方法(LEAPS):首先学习一个程序嵌入空间,从预生成的程序数据集中连续参数化各种程序,然后在给一个任务时,在学习程序嵌入空间中搜索一个任务解决程序。尽管这些结果令人鼓舞,LEAPS能够生成的程序政策是由于程序数据集的分布而限制的。此外,在搜索过程中,LEAPS只根据其回报评估每个候选程序,未能准确地奖励正确部分和惩罚错误部分。通过学习编写程序,我们提出的层次级方案增强学习(HPRL)框架能够产生描述非分配性复杂行为的方案政策,并直接分配奖励给诱导欲望行为的程序。Karel领域实验结果表明,我们提出的框架优于标准。ablation研究证实了LEAPS的局限性并证明了我们的设计选择。

**[Paper URL](https://proceedings.mlr.press/v202/liu23p.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23p/liu23p.pdf)** 

# Online Local Differential Private Quantile Inference via Self-normalization
**题目:** 通过自正常化在线局部差价私人量子ference

**作者:** Yi Liu, Qirui Hu, Lei Ding, Linglong Kong

**Abstract:** Based on binary inquiries, we developed an algorithm to estimate population quantiles under Local Differential Privacy (LDP). By self-normalizing, our algorithm provides asymptotically normal estimation with valid inference, resulting in tight confidence intervals without the need for nuisance parameters to be estimated. Our proposed method can be conducted fully online, leading to high computational efficiency and minimal storage requirements with $\mathcal{O}(1)$ space. We also proved an optimality result by an elegant application of one central limit theorem of Gaussian Differential Privacy (GDP) when targeting the frequently encountered median estimation problem. With mathematical proof and extensive numerical testing, we demonstrate the validity of our algorithm both theoretically and experimentally.

**摘要:** 基于二进制查询,我们开发了一个基于本地差分私隐(LDP)的人口量值估计算法。通过自正化,我们的算法提供与有效推理相近的正常估计,从而不需要对扰动参数进行估计,从而产生紧闭的信任间隔。我们提出的方法可以完全在线进行,并以$\mathcal{O}(1)$空间实现高计算效率和最小存储要求。

**[Paper URL](https://proceedings.mlr.press/v202/liu23q.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23q/liu23q.pdf)** 

# GFlowOut: Dropout with Generative Flow Networks
**题目:** GFlowOut:基于生成流网络的脱落

**作者:** Dianbo Liu, Moksh Jain, Bonaventure F. P. Dossou, Qianli Shen, Salem Lahlou, Anirudh Goyal, Nikolay Malkin, Chris Chinenye Emezue, Dinghuai Zhang, Nadhir Hassen, Xu Ji, Kenji Kawaguchi, Yoshua Bengio

**Abstract:** Bayesian inference offers principled tools to tackle many critical problems with modern neural networks such as poor calibration and generalization, and data inefficiency. However, scaling Bayesian inference to large architectures is challenging and requires restrictive approximations. Monte Carlo Dropout has been widely used as a relatively cheap way to approximate inference and estimate uncertainty with deep neural networks. Traditionally, the dropout mask is sampled independently from a fixed distribution. Recent research shows that the dropout mask can be seen as a latent variable, which can be inferred with variational inference. These methods face two important challenges: (a) the posterior distribution over masks can be highly multi-modal which can be difficult to approximate with standard variational inference and (b) it is not trivial to fully utilize sample-dependent information and correlation among dropout masks to improve posterior estimation. In this work, we propose GFlowOut to address these issues. GFlowOut leverages the recently proposed probabilistic framework of Generative Flow Networks (GFlowNets) to learn the posterior distribution over dropout masks. We empirically demonstrate that GFlowOut results in predictive distributions that generalize better to out-of-distribution data and provide uncertainty estimates which lead to better performance in downstream tasks.

**摘要:** 贝叶斯推导提供了解决现代神经网络中的许多关键问题的基本工具,例如低校正和一般化,以及数据效率低下。然而,将贝叶斯推导扩展到大型架构是挑战性的,需要限制性的近似。蒙特卡罗推导已被广泛使用,作为近似推导和评估深层神经网络的不确定性的相对廉价方法。传统上,推导面具是独立于固定分布的样品。最近的研究表明,推导面具可以被视为潜在变量,可以与变量推导推导。在这一工作中,我们提出了GFlowOut来解决这些问题。GFlowOut利用最近提议的生成流网(GFlowNets)概率框架学习后继分布在脱落面罩上。我们以实例证明GFlowOut在预测分布中产生结果,能够更好地推广到非分布数据,并提供不确定估计,从而在下游任务中提高性能。

**[Paper URL](https://proceedings.mlr.press/v202/liu23r.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23r/liu23r.pdf)** 

# 2D-Shapley: A Framework for Fragmented Data Valuation
**题目:** 2D-Shapley:断片数据评价的框架

**作者:** Zhihong Liu, Hoang Anh Just, Xiangyu Chang, Xi Chen, Ruoxi Jia

**Abstract:** Data valuation—quantifying the contribution of individual data sources to certain predictive behaviors of a model—is of great importance to enhancing the transparency of machine learning and designing incentive systems for data sharing. Existing work has focused on evaluating data sources with the shared feature or sample space. How to valuate fragmented data sources of which each only contains partial features and samples remains an open question. We start by presenting a method to calculate the counterfactual of removing a fragment from the aggregated data matrix. Based on the counterfactual calculation, we further propose 2D-Shapley, a theoretical framework for fragmented data valuation that uniquely satisfies some appealing axioms in the fragmented data context. 2D-Shapley empowers a range of new use cases, such as selecting useful data fragments, providing interpretation for sample-wise data values, and fine-grained data issue diagnosis.

**摘要:** 数据估价—量化个别数据源对模型的某些预测行为的贡献—对于提高机器学习的透明度和设计数据共享激励系统具有重要意义。现有的工作重点是评估数据源的共享特征或样品空间。如何估价每个包含部分特征和样品的断片数据源仍然是一个开放的问题。我们首先提出一种方法来计算从集群数据矩阵中删除断片的反事实。基于反事实计算,我们进一步提议2D-Shapley,一种用于断片数据估价的理论框架,它独特的满足了断片数据上下文中的一些引人注目的公理。2D-Shapley赋予了一系列新的使用案例,例如选择有用的断片数据,提供对样品数据值的解释,以及细微数据问题诊断。

**[Paper URL](https://proceedings.mlr.press/v202/liu23s.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23s/liu23s.pdf)** 

# Causal Structure Learning for Latent Intervened Non-stationary Data
**题目:** 随机干预非静态数据的诱因结构学习

**作者:** Chenxi Liu, Kun Kuang

**Abstract:** Causal structure learning can reveal the causal mechanism behind natural systems. It is well studied that the multiple domain data consisting of observational and interventional samples benefit causal identifiability. However, for non-stationary time series data, domain indexes are often unavailable, making it difficult to distinguish observational samples from interventional samples. To address these issues, we propose a novel Latent Intervened Non-stationary learning (LIN) method to make the domain indexes recovery process and the causal structure learning process mutually promote each other. We characterize and justify a possible faithfulness condition to guarantee the identifiability of the proposed LIN method. Extensive experiments on both synthetic and real-world datasets demonstrate that our method outperforms the baselines on causal structure learning for latent intervened non-stationary data.

**摘要:** 因果结构学习可以揭示自然系统背后的因果机制。研究表明,由观察和干预样本组成的多域数据有利于因果识别性。然而,对于非静态时间序列数据,域索引往往没有可用,使得观察样本与干预样本难以区分。为了解决这些问题,我们提出了一种新颖的隐性干预非静态学习(LIN)方法,使域索引的恢复过程和因果结构学习过程相互促进。

**[Paper URL](https://proceedings.mlr.press/v202/liu23t.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23t/liu23t.pdf)** 

# Structural Re-weighting Improves Graph Domain Adaptation
**题目:** 结构重权改善图域适应

**作者:** Shikun Liu, Tianchun Li, Yongbin Feng, Nhan Tran, Han Zhao, Qiang Qiu, Pan Li

**Abstract:** In many real-world applications, graph-structured data used for training and testing have differences in distribution, such as in high energy physics (HEP) where simulation data used for training may not match real experiments. Graph domain adaptation (GDA) is a method used to address these differences. However, current GDA primarily works by aligning the distributions of node representations output by a single graph neural network encoder shared across the training and testing domains, which may often yield sub-optimal solutions. This work examines different impacts of distribution shifts caused by either graph structure or node attributes and identifies a new type of shift, named conditional structure shift (CSS), which current GDA approaches are provably sub-optimal to deal with. A novel approach, called structural reweighting (StruRW), is proposed to address this issue and is tested on synthetic graphs, four benchmark datasets, and a new application in HEP. StruRW has shown significant performance improvement over the baselines in the settings with large graph structure shifts, and reasonable performance improvement when node attribute shift dominates.

**摘要:** 在许多实际应用中,用于训练和测试的图形结构数据有分布上的差异,例如在高能量物理学(HEP)中,用于训练的仿真数据可能与实际实验不相符。图形域适应(GDA)是解决这些差异的一种方法。然而,当前GDA主要通过由一个单一图形神经网络编码器在训练和测试领域中共享的节点表示输出的分布进行协调工作,这往往可以产生亚最佳解决方案。StruRW在大图结构变换的设置中显示了比基准值显著的性能改善,在节点属性变换占主导地位时也显示了合理的性能改善。

**[Paper URL](https://proceedings.mlr.press/v202/liu23u.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23u/liu23u.pdf)** 

# Dink-Net: Neural Clustering on Large Graphs
**题目:** Dink-Net:大型图形上神经集群

**作者:** Yue Liu, Ke Liang, Jun Xia, Sihang Zhou, Xihong Yang, Xinwang Liu, Stan Z. Li

**Abstract:** Deep graph clustering, which aims to group the nodes of a graph into disjoint clusters with deep neural networks, has achieved promising progress in recent years. However, the existing methods fail to scale to the large graph with million nodes. To solve this problem, a scalable deep graph clustering method (Dink-Net) is proposed with the idea of dilation and shrink. Firstly, by discriminating nodes, whether being corrupted by augmentations, representations are learned in a self-supervised manner. Meanwhile, the cluster centers are initialized as learnable neural parameters. Subsequently, the clustering distribution is optimized by minimizing the proposed cluster dilation loss and cluster shrink loss in an adversarial manner. By these settings, we unify the two-step clustering, i.e., representation learning and clustering optimization, into an end-to-end framework, guiding the network to learn clustering-friendly features. Besides, Dink-Net scales well to large graphs since the designed loss functions adopt the mini-batch data to optimize the clustering distribution even without performance drops. Both experimental results and theoretical analyses demonstrate the superiority of our method. Compared to the runner-up, Dink-Net achieves $9.62%$ NMI improvement on the ogbn-papers100M dataset with 111 million nodes and 1.6 billion edges. The source code is released: https://github.com/yueliu1999/Dink-Net. Besides, a collection (papers, codes, and datasets) of deep graph clustering is shared on GitHub https://github.com/yueliu1999/Awesome-Deep-Graph-Clustering.

**摘要:** 深度图集群,旨在将图的节点群化为与深度神经网络分离的集群,近年来取得了令人期待的进展。然而,现有的方法无法以百万节点的大型图进行规模化。为了解决这个问题,提出了可扩展的深度图集群方法(Dink-Net)以扩散和缩小的概念。首先,通过区分节点,不论是受增量破坏的还是受自我监督的方式,表示 learned in a self-supervised manner。同时, cluster centers are initialized as learnable neural parameters。此外,Dink-Net在设计损耗函数中采用小批量数据来优化集群分布,即使没有性能下降。实验结果和理论分析都证明了我们方法的优越性。与runner-up相比,Dink-Net在Ogbn-papers100M数据集中取得了9.62%的NMI改善,包含111亿节点和1.6亿边缘。

**[Paper URL](https://proceedings.mlr.press/v202/liu23v.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23v/liu23v.pdf)** 

# Oscillation-free Quantization for Low-bit Vision Transformers
**题目:** 低位视觉变换器无振量化

**作者:** Shih-Yang Liu, Zechun Liu, Kwang-Ting Cheng

**Abstract:** Weight oscillation is a by-product of quantization-aware training, in which quantized weights frequently jump between two quantized levels, resulting in training instability and a sub-optimal final model. We discover that the learnable scaling factor, a widely-used $\textit{de facto}$ setting in quantization aggravates weight oscillation. In this work, we investigate the connection between learnable scaling factor and quantized weight oscillation using ViT, and we additionally find that the interdependence between quantized weights in $\textit{query}$ and $\textit{key}$ of a self-attention layer also makes ViT vulnerable to oscillation. We propose three techniques correspondingly: statistical weight quantization ($\rm StatsQ$) to improve quantization robustness compared to the prevalent learnable-scale-based method; confidence-guided annealing ($\rm CGA$) that freezes the weights with $\textit{high confidence}$ and calms the oscillating weights; and $\textit{query}$-$\textit{key}$ reparameterization ($\rm QKR$) to resolve the query-key intertwined oscillation and mitigate the resulting gradient misestimation. Extensive experiments demonstrate that our algorithms successfully abate weight oscillation and consistently achieve substantial accuracy improvement on ImageNet. Specifically, our 2-bit DeiT-T/DeiT-S surpass the previous state-of-the-art by 9.8% and 7.7%, respectively. The code is included in the supplementary material and will be released.

**摘要:** 重量振荡是量化意识训练的一个副产物,量化重量经常在两个量化水平之间跳跃,导致训练不稳定性和亚最佳的最终模型。我们发现量化中广泛使用的可学习尺度因子($\textit{de facto}$ setting)加剧了重量振荡。在这个研究中,我们研究了可学习尺度因子($\textit{de facto}$ setting)和使用ViT的量化重量振荡之间的联系,并进一步发现自注意层的$\textit{query}$和$\textit{key}$中的量化重量之间的相互依存性也使得ViT易受振荡。我们提出了三个相应的技术:统计量化量化($\rm StatsQ$)以提高量化鲁棒性,与普遍的可学习尺度方法相比;基于信任的凝固($\rm CGA$)以冻结重量和稳定振荡重量;和$\textit{query}$-$\textit{key}$修复度量化($\rm QKR$)以解决查询键相互关联振荡和减轻由此产生的梯度误估。

**[Paper URL](https://proceedings.mlr.press/v202/liu23w.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23w/liu23w.pdf)** 

# Understanding the Distillation Process from Deep Generative Models to Tractable Probabilistic Circuits
**题目:** 从深层生成模型到可推导概率电路的蒸馏过程的理解

**作者:** Xuejie Liu, Anji Liu, Guy Van Den Broeck, Yitao Liang

**Abstract:** Probabilistic Circuits (PCs) are a general and unified computational framework for tractable probabilistic models that support efficient computation of various inference tasks (e.g., computing marginal probabilities). Towards enabling such reasoning capabilities in complex real-world tasks, Liu et al. (2022) propose to distill knowledge (through latent variable assignments) from less tractable but more expressive deep generative models. However, it is still unclear what factors make this distillation work well. In this paper, we theoretically and empirically discover that the performance of a PC can exceed that of its teacher model. Therefore, instead of performing distillation from the most expressive deep generative model, we study what properties the teacher model and the PC should have in order to achieve good distillation performance. This leads to a generic algorithmic improvement as well as other data-type-specific ones over the existing latent variable distillation pipeline. Empirically, we outperform SoTA TPMs by a large margin on challenging image modeling benchmarks. In particular, on ImageNet32, PCs achieve 4.06 bits-per-dimension, which is only 0.34 behind variational diffusion models (Kingma et al., 2021).

**摘要:** 概率电路(PCs)是可操作的概率模型的通用统一计算框架,支持各种推理任务(例如计算边际概率)的有效计算。为了在复杂的现实任务中实现这种推理能力,刘等人(2022)建议从较易操作但更具表达性的深层生成模型中提取知识(通过隐形变量分配)。然而,目前仍不清楚哪些因素使这种提取工作正常。本文从理论和经验上发现,一个PC的性能可以超过其教师模型的性能。因此,我们不再从最具有表达性的深层生成模型提取知识,而是研究教师模型和个人电脑应该具备哪些特性,以达到良好的提取性能。在图像建模的挑战性指标上,我们明显超过了SoTA TPM,特别是在ImageNet32上,PC的每维比特达4.06位,仅0.34位(Kingma et al., 2021)。

**[Paper URL](https://proceedings.mlr.press/v202/liu23x.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23x/liu23x.pdf)** 

# Averaged Method of Multipliers for Bi-Level Optimization without Lower-Level Strong Convexity
**题目:** 无低级强凸的双级优化倍数平均方法

**作者:** Risheng Liu, Yaohua Liu, Wei Yao, Shangzhi Zeng, Jin Zhang

**Abstract:** Gradient methods have become mainstream techniques for Bi-Level Optimization (BLO) in learning fields. The validity of existing works heavily rely on either a restrictive Lower- Level Strong Convexity (LLSC) condition or on solving a series of approximation subproblems with high accuracy or both. In this work, by averaging the upper and lower level objectives, we propose a single loop Bi-level Averaged Method of Multipliers (sl-BAMM) for BLO that is simple yet efficient for large-scale BLO and gets rid of the limited LLSC restriction. We further provide non-asymptotic convergence analysis of sl-BAMM towards KKT stationary points, and the comparative advantage of our analysis lies in the absence of strong gradient boundedness assumption, which is always required by others. Thus our theory safely captures a wider variety of applications in deep learning, especially where the upper-level objective is quadratic w.r.t. the lower-level variable. Experimental results demonstrate the superiority of our method.

**摘要:** 梯度方法已成为学习领域中双级优化(BLO)的主流技术。现有工作的有效性很大程度上取决于限制性低级强凸条件(LLSC)或以高精度解决一系列近似子问题。在这个工作中,通过对上层和下层目标的平均化,我们提出了一个单环BLO的双级平均方法(sl-BAMM),该方法对于大尺度BLO来说是简单而有效的,并且消除了有限LLSC限制。实验结果证明了该方法的优越性.

**[Paper URL](https://proceedings.mlr.press/v202/liu23y.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23y/liu23y.pdf)** 

# Graph Switching Dynamical Systems
**题目:** 图转换动态系统

**作者:** Yongtuo Liu, Sara Magliacane, Miltiadis Kofinas, Efstratios Gavves

**Abstract:** Dynamical systems with complex behaviours, e.g. immune system cells interacting with a pathogen, are commonly modelled by splitting the behaviour in different regimes, or modes, each with simpler dynamics, and then learn the switching behaviour from one mode to another. To achieve this, Switching Dynamical Systems (SDS) are a powerful tool that automatically discovers these modes and mode-switching behaviour from time series data. While effective, these methods focus on independent objects, where the modes of one object are independent of the modes of the other objects. In this paper, we focus on the more general interacting object setting for switching dynamical systems, where the per-object dynamics also depend on an unknown and dynamically changing subset of other objects and their modes. To this end, we propose a novel graph-based approach for switching dynamical systems, GRAph Switching dynamical Systems (GRASS), in which we use a dynamic graph to characterize interactions between objects and learn both intra-object and inter-object mode-switching behaviour. For benchmarking, we create two new datasets, a synthesized ODE-driven particles dataset and a real-world Salsa-couple dancing dataset. Experiments show that GRASS can consistently outperforms previous state-of-the-art methods. We will release code and data after acceptance.

**摘要:** 具有复杂行为的动态系统,例如免疫系统细胞与病原体相互作用,通常通过分开行为在不同的模式或模式中进行建模,然后从一个模式学习到另一个模式的转换行为。为此,动态系统转换(SDS)是自动从时间序列数据中发现这些模式和模式转换行为的有力工具。虽然这些方法有效,但它们的重点在于独立对象,其中一个对象的模式与其他对象的模式不相干。为此,我们提出了一种基于图的动态系统转换的新方法,即动态系统转换图(Graph Switching dynamical Systems,GRASS),利用动态图来描述对象之间的相互作用,并学习对象内部和对象间模式转换行为。为测试,我们创建了两个新的数据集,一个由ODE驱动的粒子数据集和一个真实世界萨尔萨夫妇舞蹈数据集。

**[Paper URL](https://proceedings.mlr.press/v202/liu23z.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23z/liu23z.pdf)** 

# High Probability Convergence of Stochastic Gradient Methods
**题目:** 随机梯度方法的高概率收敛

**作者:** Zijian Liu, Ta Duy Nguyen, Thien Hang Nguyen, Alina Ene, Huy Nguyen

**Abstract:** In this work, we describe a generic approach to show convergence with high probability for both stochastic convex and non-convex optimization with sub-Gaussian noise. In previous works for convex optimization, either the convergence is only in expectation or the bound depends on the diameter of the domain. Instead, we show high probability convergence with bounds depending on the initial distance to the optimal solution. The algorithms use step sizes analogous to the standard settings and are universal to Lipschitz functions, smooth functions, and their linear combinations. The method can be applied to the non-convex case. We demonstrate an $O((1+\sigma^{2}\log(1/\delta))/T+\sigma/\sqrt{T})$ convergence rate when the number of iterations $T$ is known and an $O((1+\sigma^{2}\log(T/\delta))/\sqrt{T})$ convergence rate when $T$ is unknown for SGD, where $1-\delta$ is the desired success probability. These bounds improve over existing bounds in the literature. We also revisit AdaGrad-Norm (Ward et al., 2019) and show a new analysis to obtain a high probability bound that does not require the bounded gradient assumption made in previous works. The full version of our paper contains results for the standard per-coordinate AdaGrad.

**摘要:** 在该工作中,我们描述了一种一般方法,以显示具有高概率的随机凸和非凸优化与子-高斯噪声的凸。在以前的凸优化工作中,要么凸只是在预期中,要么边界取决于域的直径。相反,我们以边界取决于最优解的初始距离来显示高概率的凸。这些算法使用与标准设置类似的步骤大小,并且适用于利普希茨函数、滑函数和它们的线性组合。该方法可以应用于非凸例。我们证明了$O((1+\sigma^{2}\log(1/\delta))/T+\sigma/\sqrt{T})$的凸率,当迭代数$T$已知时,以及$O((1+\sigma^{2}\log(T/\delta))/\我们还回顾了AdaGrad-Norm(Ward et al., 2019)并给出了一个新的分析,以获得一个不需要在以前的工作中所作的边界梯度假设的高概率边界。

**[Paper URL](https://proceedings.mlr.press/v202/liu23aa.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23aa/liu23aa.pdf)** 

# OMS-DPM: Optimizing the Model Schedule for Diffusion Probabilistic Models
**题目:** OMS-DPM:优化扩散概率模型的模型时间表

**作者:** Enshu Liu, Xuefei Ning, Zinan Lin, Huazhong Yang, Yu Wang

**Abstract:** Diffusion probabilistic models (DPMs) are a new class of generative models that have achieved state-of-the-art generation quality in various domains. Despite the promise, one major drawback of DPMs is the slow generation speed due to the large number of neural network evaluations required in the generation process. In this paper, we reveal an overlooked dimension—model schedule—for optimizing the trade-off between generation quality and speed. More specifically, we observe that small models, though having worse generation quality when used alone, could outperform large models in certain generation steps. Therefore, unlike the traditional way of using a single model, using different models in different generation steps in a carefully designed model schedule could potentially improve generation quality and speed simultaneously. We design OMS-DPM, a predictor-based search algorithm, to determine the optimal model schedule given an arbitrary generation time budget and a set of pre-trained models. We demonstrate that OMS-DPM can find model schedules that improve generation quality and speed than prior state-of-the-art methods across CIFAR-10, CelebA, ImageNet, and LSUN datasets. When applied to the public checkpoints of the Stable Diffusion model, we are able to accelerate the sampling by 2x while maintaining the generation quality.

**摘要:** 扩散概率模型(英语:Disffusion probabilistic models,缩写为DPM)是一种新型的生成模型,在各个领域都实现了最先进的生成质量。尽管具有这种前景,但DPM的一个主要缺点是由于生成过程中需要大量的神经网络评估,因此产生速度很慢。本文揭示了一个被忽视的维度——模型时间表——以优化生成质量和速度之间的交换。具体地说,我们观察到小模型虽然在单独使用时具有较差的生成质量,但在某些生成步骤中却能胜过大型模型。我们设计了一种基于预测器的搜索算法OMS-DPM,以确定基于任意的生成时间预算和预训练模型的优化模型日程表。我们证明OMS-DPM可以在CIFAR-10、CelebA、ImageNet和LSUN数据集中找到改进生成质量和速度的模型日程表。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ab.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ab/liu23ab.pdf)** 

# Lazy Agents: A New Perspective on Solving Sparse Reward Problem in Multi-agent Reinforcement Learning
**题目:** 懒散代理人:在多代理强化学习中解决 Sparse Reward问题的新视角

**作者:** Boyin Liu, Zhiqiang Pu, Yi Pan, Jianqiang Yi, Yanyan Liang, D. Zhang

**Abstract:** Sparse reward remains a valuable and challenging problem in multi-agent reinforcement learning (MARL). This paper addresses this issue from a new perspective, i.e., lazy agents. We empirically illustrate how lazy agents damage learning from both exploration and exploitation. Then, we propose a novel MARL framework called Lazy Agents Avoidance through Influencing External States (LAIES). Firstly, we examine the causes and types of lazy agents in MARL using a causal graph of the interaction between agents and their environment. Then, we mathematically define the concept of fully lazy agents and teams by calculating the causal effect of their actions on external states using the do-calculus process. Based on definitions, we provide two intrinsic rewards to motivate agents, i.e., individual diligence intrinsic motivation (IDI) and collaborative diligence intrinsic motivation (CDI). IDI and CDI employ counterfactual reasoning based on the external states transition model (ESTM) we developed. Empirical results demonstrate that our proposed method achieves state-of-the-art performance on various tasks, including the sparse-reward version of StarCraft multi-agent challenge (SMAC) and Google Research Football (GRF). Our code is open-source and available at https://github.com/liuboyin/LAIES.

**摘要:** 节余奖励在多代理强化学习(MARL)中仍然是一个具有价值和挑战性的问题。本文从一个新的角度探讨了这一问题,即懒惰代理。我们以实证的方式说明了懒惰代理在探索和开发学习中如何损害学习。然后,我们提出了一种新的MARL框架,即通过影响外部状态来避免懒惰代理(LAIES)。首先,我们利用代理与其环境之间的相互作用的因果图分析了MARL中的懒惰代理的原因和类型。然后,我们用do-calculus过程计算了其行为对外部状态的因果效应,从而数学地定义了完全懒惰代理和团队的概念。IDI和CDI使用基于我们开发的外部状态转换模型(ESTM)的反事实推理。实验结果表明,我们提出的方法在各种任务中达到最先进的性能,包括StarCraft多代理挑战(SMAC)和Google研究足球(GRF)的低回报版本。我们的代码是开放源代码,可于 https://github.com/liuboyin/LAIES下载。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ac.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ac/liu23ac.pdf)** 

# RSC: Accelerate Graph Neural Networks Training via Randomized Sparse Computations
**题目:** RSC:通过随机备用计算加速图形神经网络培训

**作者:** Zirui Liu, Chen Shengyuan, Kaixiong Zhou, Daochen Zha, Xiao Huang, Xia Hu

**Abstract:** Training graph neural networks (GNNs) is extremely time consuming because sparse graph-based operations are hard to be accelerated by community hardware. Prior art successfully reduces the computation cost of dense matrix based operations (e.g., convolution and linear) via sampling-based approximation. However, unlike dense matrices, sparse matrices are stored in the irregular data format such that each row/column may have different number of non-zero entries. Thus, compared to the dense counterpart, approximating sparse operations has two unique challenges (1) we cannot directly control the efficiency of approximated sparse operation since the computation is only executed on non-zero entries; (2) sampling sparse matrices is much more inefficient due to the irregular data format. To address the issues, our key idea is to control the accuracy-efficiency trade off by optimizing computation resource allocation layer-wisely and epoch-wisely. For the first challenge, we customize the computation resource to different sparse operations, while limit the total used resource below a certain budget. For the second challenge, we cache previous sampled sparse matrices to reduce the epoch-wise sampling overhead. Finally, we propose a switching mechanisms to improve the generalization of GNNs trained with approximated operations. To this end, we propose Randomized Sparse Computation. In practice, rsc can achieve up to 11.6X speedup for a single sparse operation and 1.6X end-to-end wall-clock time speedup with almost no accuracy drop.

**摘要:** 训练图神经网络(GNNs)是非常耗时的,因为基于稀疏图的操作很难通过社区硬件加速。先驱技术通过采样的近似方法成功地降低了基于稀疏矩阵的操作的计算成本。然而,与稀疏矩阵不同,稀疏矩阵存储在不规则数据格式中,使得每个行/列可能有不同数量的非零项。因此,与稀疏操作相比,近似稀疏操作有两个独特的挑战(一)我们不能直接控制近似稀疏操作的效率,因为计算只在非零项上执行;(二)采样稀疏矩阵由于不规则数据格式造成的效率更低。针对第一个挑战,我们将计算资源定制到不同的稀疏操作,同时限制使用资源的总数在一定预算以下。对于第二个挑战,我们缓存以前的稀疏矩阵以减少时段wise采样的额外费用。最后,我们提出了一种交换机制,以改进训练与近似操作的GNN的一般化。为此目的,我们提出了随机稀疏计算。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ad.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ad/liu23ad.pdf)** 

# Algorithms for bounding contribution for histogram estimation under user-level privacy
**题目:** 在用户层面隐私下对图形估计的缓冲贡献算法

**作者:** Yuhan Liu, Ananda Theertha Suresh, Wennan Zhu, Peter Kairouz, Marco Gruteser

**Abstract:** We study the problem of histogram estimation under user-level differential privacy, where the goal is to preserve the privacy of all entries of any single user. We consider the heterogeneous scenario where the quantity of data can be different for each user. In this scenario, the amount of noise injected into the histogram to obtain differential privacy is proportional to the maximum user contribution, which can be amplified by few outliers. One approach to circumvent this would be to bound (or limit) the contribution of each user to the histogram. However, if users are limited to small contributions, a significant amount of data will be discarded. In this work, we propose algorithms to choose the best user contribution bound for histogram estimation under both bounded and unbounded domain settings. When the size of the domain is bounded, we propose a user contribution bounding strategy that almost achieves a two-approximation with respect to the best contribution bound in hindsight. For unbounded domain histogram estimation, we propose an algorithm that is logarithmic-approximation with respect to the best contribution bound in hindsight. This result holds without any distribution assumptions on the data. Experiments on both real and synthetic datasets verify our theoretical findings and demonstrate the effectiveness of our algorithms. We also show that clipping bias introduced by bounding user contribution may be reduced under mild distribution assumptions, which can be of independent interest.

**摘要:** 我们研究了在用户级别的差异性隐私下对histogram的估计问题,目标是保护任何单个用户的所有输入的隐私。我们考虑了一个异构的场景,其中数据的数量可以为每个用户不同。在这个场景中,向histogram注入的噪音量以获得差异性隐私是与最大用户贡献相称的,可以由少数异常放大的。绕过这一问题的一个方法是将每个用户对histogram的贡献绑定(或限制)。然而,如果用户仅限于小贡献,则将丢弃大量数据。为无界域图估计,提出了一种基于后视最优贡献约束的逻辑近似算法,该算法在数据上没有分布假设的情况下有效。实数据和合成数据的实验验证了我们的理论发现,并证明了我们的算法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ae.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ae/liu23ae.pdf)** 

# Simple Embodied Language Learning as a Byproduct of Meta-Reinforcement Learning
**题目:** 简单的代谢语言学习作为元增强学习的副产物

**作者:** Evan Zheran Liu, Sahaana Suri, Tong Mu, Allan Zhou, Chelsea Finn

**Abstract:** Whereas machine learning models typically learn language by directly training on language tasks (e.g., next-word prediction), language emerges in human children as a byproduct of solving non-language tasks (e.g., acquiring food). Motivated by this observation, we ask: can embodied reinforcement learning (RL) agents also indirectly learn language from non-language tasks? Learning to associate language with its meaning requires a dynamic environment with varied language. Therefore, we investigate this question in a multi-task environment with language that varies across the different tasks. Specifically, we design an office navigation environment, where the agent’s goal is to find a particular office, and office locations differ in different buildings (i.e., tasks). Each building includes a floor plan with a simple language description of the goal office’s location, which can be visually read as an RGB image when visited. We find RL agents indeed are able to indirectly learn language. Agents trained with current meta-RL algorithms successfully generalize to reading floor plans with held-out layouts and language phrases, and quickly navigate to the correct office, despite receiving no direct language supervision.

**摘要:** 尽管机器学习模型通常通过直接训练语言任务(例如下一个词的预测)来学习语言,但语言在人类儿童中 emerges as a byproduct of solving non-language tasks (e.g., acquiring food). 基于这一观察,我们提出以下问题: Can embodied reinforcement learning (RL) agents also indirectly learn language from non-language tasks? Learning to associate language with its meaning requires a dynamic environment with varied language. Therefore, we investigate this question in a multi-task environment with language that varies across the different tasks. Specifically, we design a office navigation environment, where the agent’s goal is to find a particular office, and office locations differ in different buildings (i.e., tasks). 每个建筑包括一个楼层计划,其中有一个简单的目标办公室位置的语言描述,在访问时可视化为使用当前的Meta-RL算法训练的代理人成功地推广使用保留布局和语言语句阅读楼层计划,并且快速地进入正确的办公室,尽管没有得到直接语言监督。

**[Paper URL](https://proceedings.mlr.press/v202/liu23af.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23af/liu23af.pdf)** 

# Generating Private Synthetic Data with Genetic Algorithms
**题目:** 利用遗传算法生成私人合成数据

**作者:** Terrance Liu, Jingwu Tang, Giuseppe Vietri, Steven Wu

**Abstract:** We study the problem of efficiently generating differentially private synthetic data that approximate the statistical properties of an underlying sensitive dataset. In recent years, there has been a growing line of work that approaches this problem using first-order optimization techniques. However, such techniques are restricted to optimizing differentiable objectives only, severely limiting the types of analyses that can be conducted. For example, first-order mechanisms have been primarily successful in approximating statistical queries only in the form of marginals for discrete data domains. In some cases, one can circumvent such issues by relaxing the task’s objective to maintain differentiability. However, even when possible, these approaches impose a fundamental limitation in which modifications to the minimization problem become additional sources of error. Therefore, we propose Private-GSD, a private genetic algorithm based on zeroth-order optimization heuristics that do not require modifying the original objective; thus, it avoids the aforementioned limitations of first-order optimization. We demonstrate empirically that on data with both discrete and real-valued attributes, Private-GSD outperforms the state-of-the-art methods on non-differential queries while matching accuracy in approximating differentiable ones.

**摘要:** 我们研究了有效地生成基本敏感数据集的统计属性的微分私有合成数据的问题。近年来,出现了一种以第一阶优化技术来解决这一问题的不断增长的工作线。然而,这些技术仅限于优化可微分目标,严重限制可以进行的分析类型。例如,第一阶机制主要成功地通过微分数据域的边界形式来近似统计查询。在某些情况下,可以通过放松任务目标来绕过这些问题来保持微分性。因此,我们提出了一种基于零阶优化算法的私人遗传算法Private-GSD,它不需要修改原始目标,从而避免了上述第一阶优化的局限性。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ag.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ag/liu23ag.pdf)** 

# FusionRetro: Molecule Representation Fusion via In-Context Learning for Retrosynthetic Planning
**题目:** FusionRetro:分子的代表 Fusion通过内文学习进行 Retrosynthetic规划

**作者:** Songtao Liu, Zhengkai Tu, Minkai Xu, Zuobai Zhang, Lu Lin, Rex Ying, Jian Tang, Peilin Zhao, Dinghao Wu

**Abstract:** Retrosynthetic planning aims to devise a complete multi-step synthetic route from starting materials to a target molecule. Current strategies use a decoupled approach of single-step retrosynthesis models and search algorithms, taking only the product as the input to predict the reactants for each planning step and ignoring valuable context information along the synthetic route. In this work, we propose a novel framework that utilizes context information for improved retrosynthetic planning. We view synthetic routes as reaction graphs and propose to incorporate context through three principled steps: encode molecules into embeddings, aggregate information over routes, and readout to predict reactants. Our approach is the first attempt to utilize in-context learning for retrosynthesis prediction in retrosynthetic planning. The entire framework can be efficiently optimized in an end-to-end fashion and produce more practical and accurate predictions. Comprehensive experiments demonstrate that by fusing in the context information over routes, our model significantly improves the performance of retrosynthetic planning over baselines that are not context-aware, especially for long synthetic routes. Code is available at https://github.com/SongtaoLiu0823/FusionRetro.

**摘要:** 回顾性规划的目的在于从原料到目标分子之间设计一个完整的多步骤的合成路线。目前的策略采用单步的回顾性模型和搜索算法的分离方法,只将产品作为预测规划步骤的反应物的输入,并忽略合成路线沿线的宝贵的语境信息。本文提出了一种新的框架,利用语境信息改进的回顾性规划。我们把合成路线看作反应图,并建议通过三个基本步骤结合语境:将分子编入嵌入,在路径上汇集信息,并读取预测反应物。我们的方法是第一个尝试在回顾性规划中利用语境学习进行回顾性预测。综合实验表明,通过在路径上融合上下文信息,我们的模型显著改善了在没有上下文意识的基线上进行反合成规划的性能,特别是在长合成路径上。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ah.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ah/liu23ah.pdf)** 

# I$^2$SB: Image-to-Image Schrödinger Bridge
**题目:** I$^2$SB: Image-to-Image Schrödinger Bridge

**作者:** Guan-Horng Liu, Arash Vahdat, De-An Huang, Evangelos Theodorou, Weili Nie, Anima Anandkumar

**Abstract:** We propose Image-to-Image Schrödinger Bridge (I$^2$SB), a new class of conditional diffusion models that directly learn the nonlinear diffusion processes between two given distributions. These diffusion bridges are particularly useful for image restoration, as the degraded images are structurally informative priors for reconstructing the clean images. I$^2$SB belongs to a tractable class of Schrödinger bridge, the nonlinear extension to score-based models, whose marginal distributions can be computed analytically given boundary pairs. This results in a simulation-free framework for nonlinear diffusions, where the I$^2$SB training becomes scalable by adopting practical techniques used in standard diffusion models. We validate I$^2$SB in solving various image restoration tasks, including inpainting, super-resolution, deblurring, and JPEG restoration on ImageNet 256$\times$256 and show that I$^2$SB surpasses standard conditional diffusion models with more interpretable generative processes. Moreover, I$^2$SB matches the performance of inverse methods that additionally require the knowledge of the corruption operators. Our work opens up new algorithmic opportunities for developing efficient nonlinear diffusion models on a large scale. Project page and codes: https://i2sb.github.io/

**摘要:** 我们提出了Image-to-Image Schrödinger Bridge(I$^2$SB),一种直接学习两个分布之间的非线性扩散过程的条件扩散模型的新类别。这些扩散桥特别有用于图像恢复,因为被降级的图像是重建干净图像的结构性信息的先驱。I$^2$SB属于Schrödinger桥的可操作类别,是基于分数的非线性扩散模型的扩展,其边界扩散可以通过分析计算给边界对数。我们验证了I$^2$SB在ImageNet256$\times$256上解决各种图像恢复任务,包括油漆、超分辨率、 deblurring和JPEG恢复,并证明I$^2$SB超过了标准条件扩散模型,具有更可解释的生成过程。此外,I$^2$SB匹配了反向方法的性能,额外需要对腐蚀操作者的知识。我们的工作打开了大规模开发高效非线性扩散模型的新算法机会。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ai.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ai/liu23ai.pdf)** 

# What can online reinforcement learning with function approximation benefit from general coverage conditions?
**题目:** 基于功能近似的在线强化学习能从总体覆盖条件中获益甚么?

**作者:** Fanghui Liu, Luca Viano, Volkan Cevher

**Abstract:** In online reinforcement learning (RL), instead of employing standard structural assumptions on Markov decision processes (MDPs), using a certain coverage condition (original from offline RL) is enough to ensure sample-efficient guarantees (Xie et al. 2023). In this work, we focus on this new direction by digging more possible and general coverage conditions, and study the potential and the utility of them in efficient online RL. We identify more concepts, including the $L^p$ variant of concentrability, the density ratio realizability, and trade-off on the partial/rest coverage condition, that can be also beneficial to sample-efficient online RL, achieving improved regret bound. Furthermore, if exploratory offline data are used, under our coverage conditions, both statistically and computationally efficient guarantees can be achieved for online RL. Besides, even though the MDP structure is given, e.g., linear MDP, we elucidate that, good coverage conditions are still beneficial to obtain faster regret bound beyond $\widetilde{\mathcal{O}}(\sqrt{T})$ and even a logarithmic order regret. These results provide a good justification for the usage of general coverage conditions in efficient online RL.

**摘要:** 在在线强化学习(RL)中,使用某种覆盖条件(源自offline RL)代替使用标准结构假设的马可夫决策过程(MDP)是保证样本有效的保证(Xie et al. 2023)。在这项工作中,我们通过挖掘更多可能和一般覆盖条件,研究有效在线RL中它们的潜力和实用性。我们确定了更多的概念,包括$L^p$的集中性变量、密度比可实现性、和部分/rest覆盖条件上的交易权,这些概念也有利于提高样本有效的在线RL,从而实现改进的遗憾约束。此外,尽管给出了线性MPD结构,但我们证明,良好的覆盖条件仍然有利于获得比$\widetilde{\mathcal{O}}(\sqrt{T})$更快的约束 regret,甚至可以得到一个数值顺序 regret。这些结果为有效在线RL中使用一般覆盖条件提供了很好的理由。

**[Paper URL](https://proceedings.mlr.press/v202/liu23aj.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23aj/liu23aj.pdf)** 

# TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation
**题目:** TR0N:0-Shot插件和播放条件生成的转换器网络

**作者:** Zhaoyan Liu, Noël Vouitsis, Satya Krishna Gorti, Jimmy Ba, Gabriel Loaiza-Ganem

**Abstract:** We propose TR0N, a highly general framework to turn pre-trained unconditional generative models, such as GANs and VAEs, into conditional models. The conditioning can be highly arbitrary, and requires only a pre-trained auxiliary model. For example, we show how to turn unconditional models into class-conditional ones with the help of a classifier, and also into text-to-image models by leveraging CLIP. TR0N learns a lightweight stochastic mapping which "translates’" between the space of conditions and the latent space of the generative model, in such a way that the generated latent corresponds to a data sample satisfying the desired condition. The translated latent samples are then further improved upon through Langevin dynamics, enabling us to obtain higher-quality data samples. TR0N requires no training data nor fine-tuning, yet can achieve a zero-shot FID of 10.9 on MS-COCO, outperforming competing alternatives not only on this metric, but also in sampling speed – all while retaining a much higher level of generality. Our code is available at https://github.com/layer6ai-labs/tr0n.

**摘要:** 我们提出了一种高度通用的框架,以将预训练的无条件生成模型,例如GAN和VAEs,转变为条件模型。条件化可以非常任意,只需要预训练的辅助模型。例如,我们展示了如何用分类器将无条件模型转变为类条件模型,并利用CLIP来转换成文本到图像模型。 TR0N学习了一种轻量随机映射,它将条件空间与生成模型的潜在空间之间“翻译”,使生成的潜在空间与满足要求条件的数据样本相符。TR0N不需要任何训练数据或微调,但可以在MS-COCO上达到10.9的零射击FID,不仅在这个度量上,而且在采样速度上也超越了其他竞争的替代方案,同时保持了较高的一般性水平。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ak.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ak/liu23ak.pdf)** 

# Global Optimization with Parametric Function Approximation
**题目:** 参数函数近似的全球优化

**作者:** Chong Liu, Yu-Xiang Wang

**Abstract:** We consider the problem of global optimization with noisy zeroth order oracles — a well-motivated problem useful for various applications ranging from hyper-parameter tuning for deep learning to new material design. Existing work relies on Gaussian processes or other non-parametric family, which suffers from the curse of dimensionality. In this paper, we propose a new algorithm GO-UCB that leverages a parametric family of functions (e.g., neural networks) instead. Under a realizable assumption and a few other mild geometric conditions, we show that GO-UCB achieves a cumulative regret of $\tilde{O}(\sqrt{T})$ where $T$ is the time horizon. At the core of GO-UCB is a carefully designed uncertainty set over parameters based on gradients that allows optimistic exploration. Synthetic and real-world experiments illustrate GO-UCB works better than popular Bayesian optimization approaches, even if the model is misspecified.

**摘要:** 本文提出了一种新的算法GO-UCB,该算法利用函数的参数家族(例如神经网络)代替。在可实现的假设下和少数其他温和几何条件下,我们表明 GO-UCB实现$\tilde{O}(\sqrt{T})$的累积遗憾,其中$T$是时空。 GO-UCB的核心是基于梯度的参数 carefully designed uncertainty set over parameters that allows optimistic exploration。 Synthetic and real-world experiments illustrate GO-UCB works better than popular Bayesian optimization approaches, even if the model is misspecified。

**[Paper URL](https://proceedings.mlr.press/v202/liu23al.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23al/liu23al.pdf)** 

# Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time
**题目:** Deja Vu:影响时间的高效LLM的上下文节余

**作者:** Zichang Liu, Jue Wang, Tri Dao, Tianyi Zhou, Binhang Yuan, Zhao Song, Anshumali Shrivastava, Ce Zhang, Yuandong Tian, Christopher Re, Beidi Chen

**Abstract:** Large language models (LLMs) with hundreds of billions of parameters have sparked a new wave of exciting AI applications. However, they are computationally expensive at inference time. Sparsity is a natural approach to reduce this cost, but existing methods either require costly retraining, have to forgo LLM’s in-context learning ability, or do not yield wall-clock time speedup on modern hardware. We hypothesize that contextual sparsity, which are small, input-dependent sets of attention heads and MLP parameters that yield approximately the same output as the dense model for a given input, can address these issues. We show that contextual sparsity exists, that it can be accurately predicted, and that we can exploit it to speed up LLM inference in wall-clock time without compromising LLM’s quality or in-context learning ability. Based on these insights, we propose DejaVu, a system that uses a low-cost algorithm to predict contextual sparsity on the fly given inputs to each layer, along with an asynchronous and hardware-aware implementation that speeds up LLM inference. We validate that DejaVu can reduce the inference latency of OPT-175B by over 2$\times$ compared to the state-of-the-art FasterTransformer, and over 6$\times$ compared to the widely used Hugging Face implementation, without compromising model quality. The code is available at https://github.com/FMInference/DejaVu.

**摘要:** 具有数十亿参数的大型语言模型(LLM)引发了令人兴奋的人工智能应用的新浪潮,但它们在推导时间计算成本昂贵。节率是降低成本的自然途径,但现有的方法要么需要昂贵的重新训练,要么必须放弃LLM的上下文学习能力,要么不能在现代硬件上提高墙时钟速度。我们假设,上下文节率是小、依赖输入的注意力头和MLP参数的集合,它们与给定输入的密集模型的输出大致相同,可以解决这些问题。基于这些洞察,我们提出了DejaVu,一种使用低成本算法来预测每个层的上下文稀疏,同时使用非同步和硬件意识的实现来加速LLM推导。我们验证了DejaVu能够降低OPT-175B的推导延迟,比最先进的 FasterTransformer更低2$\times$,比广泛使用的Hugging Face实现更低6$\times$,而不影响模型质量。该代码可于 https://github.com/FMInference/DejaVu。

**[Paper URL](https://proceedings.mlr.press/v202/liu23am.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23am/liu23am.pdf)** 

# Trapdoor Normalization with Irreversible Ownership Verification
**题目:** 不可逆所有权验证的陷阱规范化

**作者:** Hanwen Liu, Zhenyu Weng, Yuesheng Zhu, Yadong Mu

**Abstract:** This paper introduces a deep model watermark with an irreversible ownership verification scheme: Trapdoor Normalization (TdN), inspired by the trapdoor function in traditional cryptography. To protect intellectual property within deep models, the proposed method is able to embed ownership information into normalization layers during training. We argue and empirically validate that relevant methods are vulnerable to ambiguity attacks, where the forged watermarks can cast ambiguity over the ownership verification. The primary trait that distinguishes this work from previous ones, is its design of a bidirectional connection between watermarks and deep models. Thereby, TdN enables an irreversible ownership verification scheme that is difficult for the adversary to compromise. In this way, the proposed TdN can effectively defeat ambiguity attacks. Extensive experiments demonstrate that the proposed method is not only superior to previous state-of-the-art methods in robustness, but also has better efficiency.

**摘要:** 本文介绍了一种具有不可逆性所有权验证方案的深层模型水印:传统密码学中的网格门功能启发的网格门规范化(TdN)。为保护深层模型中的知识产权,本文提出的方法能够在训练过程中将所有权信息嵌入规范化层中。我们论证和实验验证了相关方法易受模糊攻击的脆弱性,伪造的水印可以在所有权验证上造成模糊。广泛的实验表明,该方法不仅具有较强的鲁棒性,而且具有较好的效率。

**[Paper URL](https://proceedings.mlr.press/v202/liu23an.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23an/liu23an.pdf)** 

# Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models
**题目:** 同样的预培训损失,更好的下游:语言模型的隐性偏见重要

**作者:** Hong Liu, Sang Michael Xie, Zhiyuan Li, Tengyu Ma

**Abstract:** Language modeling on large-scale datasets improves performance of various downstream tasks. The validation pre-training loss is often used as the evaluation metric for language models since the pre-training loss tends to be well-correlated with downstream performance (which is itself hard to evaluate comprehensively). Contrary to the conventional wisdom, this paper shows that 1) pre-training loss cannot fully explain downstream performance and 2) flatness of the model is well-correlated with downstream performance where pre-training loss is not. We identify three ways to produce models with the same pre-training loss but different downstream performance: continue pre-training after convergence, increasing the model size, and changing the pre-training algorithms. These experiments demonstrate the existence of implicit bias of pre-training algorithms—among models with the same minimal pre-training loss, they implicitly prefer more transferable ones. Toward understanding this implicit bias, we prove that SGD with standard mini-batch noise implicitly prefers flatter minima of pre-training loss in language models, and empirically observe a strong correlation between flatness (measured by the trace of Hessian) and downstream performance among models with the same pre-training loss. We also prove in a synthetic language setting that among models with the minimal pre-training loss, the flattest model transfers to downstream tasks.

**摘要:** 语言建模在大规模数据集中提高了各个下游任务的性能。 validation pre-training loss常被用来作为语言模型的评价度量,因为pre-training loss往往与下游性能有很好的关联(本身很难综合评价)。与传统智慧相反,本论文显示 1) pre-training loss不能充分解释下游性能,2) model flatness与下游性能有很好的关联,在pre-training loss没有的情况下,我们确定了三个方法来生成与同样的pre-training loss但不同的下游性能的模型:在融合后继续pre-training,增加模型大小,并改变pre-training算法。这些实验证明了pre-training算法的隐性偏见的存在——在同一个最小 pre-training loss的模型中,它们隐性偏爱更易转移的模型。为了理解这种隐性偏见,我们证明了标准小批量噪声的SGD在语言模型中隐性偏好预训练损耗的更平坦的最小值,并从经验上观察到同一个预训练损耗模型之间平坦度(由希斯sian的迹象测定)和下游性能之间的强相关性。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ao.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ao/liu23ao.pdf)** 

# Taxonomy-Structured Domain Adaptation
**题目:** 分类结构域适应

**作者:** Tianyi Liu, Zihao Xu, Hao He, Guang-Yuan Hao, Guang-He Lee, Hao Wang

**Abstract:** Domain adaptation aims to mitigate distribution shifts among different domains. However, traditional formulations are mostly limited to categorical domains, greatly simplifying nuanced domain relationships in the real world. In this work, we tackle a generalization with taxonomy-structured domains, which formalizes domains with nested, hierarchical similarity structures such as animal species and product catalogs. We build on the classic adversarial framework and introduce a novel taxonomist, which competes with the adversarial discriminator to preserve the taxonomy information. The equilibrium recovers the classic adversarial domain adaptation’s solution if given a non-informative domain taxonomy (e.g., a flat taxonomy where all leaf nodes connect to the root node) while yielding non-trivial results with other taxonomies. Empirically, our method achieves state-of-the-art performance on both synthetic and real-world datasets with successful adaptation.

**摘要:** 域适应旨在减轻不同域间的分布变化,但传统的公式大多局限于分类域,大大简化了现实世界中的微观域关系。在这项工作中,我们处理了与分类结构域的一般化,它将与动物种类和产品目录等嵌入的层次相似结构的域形式化。我们构建了经典的敌对框架,并引入了新的分类学家,他与敌对歧视者竞争,以保持分类信息。平衡恢复了经典敌对域适应的解决方案,如果给予非信息性领域分类(例如,所有叶节点连接根节点的平坦分类),同时与其他分类产生非平凡的结果。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ap.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ap/liu23ap.pdf)** 

# Dropout Reduces Underfitting
**题目:** 放学减少不合时宜

**作者:** Zhuang Liu, Zhiqiu Xu, Joseph Jin, Zhiqiang Shen, Trevor Darrell

**Abstract:** Introduced by Hinton et al. in 2012, dropout has stood the test of time as a regularizer for preventing overfitting in neural networks. In this study, we demonstrate that dropout can also mitigate underfitting when used at the start of training. During the early phase, we find dropout reduces the directional variance of gradients across mini-batches and helps align the mini-batch gradients with the entire dataset’s gradient. This helps counteract the stochasticity of SGD and limit the influence of individual batches on model training. Our findings lead us to a solution for improving performance in underfitting models - early dropout: dropout is applied only during the initial phases of training, and turned off afterwards. Models equipped with early dropout achieve lower final training loss compared to their counterparts without dropout. Additionally, we explore a symmetric technique for regularizing overfitting models - late dropout, where dropout is not used in the early iterations and is only activated later in training. Experiments on ImageNet and various vision tasks demonstrate that our methods consistently improve generalization accuracy. Our results encourage more research on understanding regularization in deep learning and our methods can be useful tools for future neural network training, especially in the era of large data. Code is available at https://github.com/facebookresearch/dropout.

**摘要:** 在2012年由Hinton等人引入的“脱落”是防止神经网络上过度匹配的调节器。本研究中,我们证明脱落在训练开始时也能够减轻不足匹配。在早期阶段,我们发现脱落减少了小批对小批梯度的方向变异,并帮助将小批梯度与整个数据集的梯度匹配。这有助于对应SGD的随机性并限制个体批对模型训练的影响。此外,我们探索了一种对称技术来规范匹配的模型——晚期退缩,在早期迭代中不使用退缩,并且在训练中仅被激活。ImageNet和各种视觉任务的实验表明,我们的方法能持续提高一般化精度。我们的结果鼓励深入学习中理解正规化,我们的方法可以成为未来神经网络训练的有用工具,特别是在大型数据时代。

**[Paper URL](https://proceedings.mlr.press/v202/liu23aq.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23aq/liu23aq.pdf)** 

# Revisiting Pseudo-Label for Single-Positive Multi-Label Learning
**题目:** 对单位多字体学习的伪字体进行检讨

**作者:** Biao Liu, Ning Xu, Jiaqi Lv, Xin Geng

**Abstract:** To deal with the challenge of high cost of annotating all relevant labels for each example in multi-label learning, single-positive multi-label learning (SPMLL) has been studied in recent years, where each example is annotated with only one positive label. By adopting pseudo-label generation, i.e., assigning pseudo-label to each example by various strategies, existing methods have empirically validated that SPMLL would significantly reduce the amount of supervision with a tolerable damage in classification performance. However, there is no existing method that can provide a theoretical guarantee for learning from pseudo-label on SPMLL. In this paper, the conditions of the effectiveness of learning from pseudo-label for SPMLL are shown and the learnability of pseudo-label-based methods is proven. Furthermore, based on the theoretical guarantee of pseudo-label for SPMLL, we propose a novel SPMLL method named MIME, i.e., Mutual label enhancement for sIngle-positive Multi-label lEarning and prove that the generated pseudo-label by MIME approximately converges to the fully-supervised case. Experiments on four image datasets and five MLL datasets show the effectiveness of our methods over several existing SPMLL approaches.

**摘要:** 为了解决多标签学习中对每个实例标注所有相关标记的高成本的挑战,近年来研究了单正多标签学习(SPMLL),其中每个实例标注只有一个正标记。通过采用伪标记生成,即通过不同的策略对每个实例标注伪标记,现有方法已实证证明,SPMLL将显著减少监督量,对分类性能造成可容忍的损害。然而,目前尚没有一种可以提供伪标记在SPMLL上学习的理论保证的现有方法。此外,基于SPMLL的伪标签理论保证,提出了一种名为MIME的新型SPMLL方法,即 sIngle-positive Multi-label lEarning的相互标签增强,并证明MIME生成的伪标签近似了完全监视的案例。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ar.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ar/liu23ar.pdf)** 

# Retrosynthetic Planning with Dual Value Networks
**题目:** 双值网络的 Retrosynthetic规划

**作者:** Guoqing Liu, Di Xue, Shufang Xie, Yingce Xia, Austin Tripp, Krzysztof Maziarz, Marwin Segler, Tao Qin, Zongzhang Zhang, Tie-Yan Liu

**Abstract:** Retrosynthesis, which aims to find a route to synthesize a target molecule from commercially available starting materials, is a critical task in drug discovery and materials design. Recently, the combination of ML-based single-step reaction predictors with multi-step planners has led to promising results. However, the single-step predictors are mostly trained offline to optimize the single-step accuracy, without considering complete routes. Here, we leverage reinforcement learning (RL) to improve the single-step predictor, by using a tree-shaped MDP to optimize complete routes. Specifically, we propose a novel online training algorithm, called Planning with Dual Value Networks (PDVN), which alternates between the planning phase and updating phase. In PDVN, we construct two separate value networks to predict the synthesizability and cost of molecules, respectively. To maintain the single-step accuracy, we design a two-branch network structure for the single-step predictor. On the widely-used USPTO dataset, our PDVN algorithm improves the search success rate of existing multi-step planners (e.g., increasing the success rate from 85.79% to 98.95% for Retro$^{\ast}$, and reducing the number of model calls by half while solving 99.47% molecules for RetroGraph). Additionally, PDVN helps find shorter synthesis routes (e.g., reducing the average route length from 5.76 to 4.83 for Retro$^{\ast}$, and from 5.63 to 4.78 for RetroGraph).

**摘要:** 回顾性合成(英语:Retrosynthesis)是药物发现和材料设计中的一个关键任务。最近,ML-based single-step reaction predictors(英语:ML-based single-step reaction predictors)与多步规划者相结合,取得了令人期待的成果。然而,单步预测者大多是在线训练的,以优化单步的准确性,而不考虑完整的路径。在广泛使用的USPTO数据集上,我们的PDVN算法提高了现有多步规划器的搜索成功率(例如,在Retro$^{\ast}$中,成功率从85.79 %提高到98.95 %,在RetroGraph中,求解99.47 %的分子时,减少模型调用数量一半)。此外,PDVN还帮助找到更短的合成路径(例如,在Retro$^{\ast}$中,平均路径长度从5.76 %降低到4.83 %,在RetroGraph中从5.63 %降低到4.78 %)。

**[Paper URL](https://proceedings.mlr.press/v202/liu23as.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23as/liu23as.pdf)** 

# Online Nonstochastic Control with Adversarial and Static Constraints
**题目:** 基于敌对和静态约束的在线非随机控制

**作者:** Xin Liu, Zixian Yang, Lei Ying

**Abstract:** This paper studies online nonstochastic control problems with adversarial and static constraints. We propose online nonstochastic control algorithms that achieve both sublinear regret and sublinear adversarial constraint violation while keeping static constraint violation minimal against the optimal constrained linear control policy in hindsight. To establish the results, we introduce an online convex optimization with memory framework under adversarial and static constraints, which serves as a subroutine for the constrained online nonstochastic control algorithms. This subroutine also achieves the state-of-the-art regret and constraint violation bounds for constrained online convex optimization problems, which is of independent interest. Our experiments demonstrate the proposed control algorithms are adaptive to adversarial constraints and achieve smaller cumulative costs and violations. Moreover, our algorithms are less conservative and achieve significantly smaller cumulative costs than the state-of-the-art algorithm.

**摘要:** 本文研究了对敌对和静态约束的在线非随机控制问题,提出了实现双线性遗憾和双线性敌对约束的在线非随机控制算法,同时保持静态约束约束约束的约束约束约束最小限度,以实现双线性遗憾和约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束约束而且,我们的算法比最先进的算法更少保守,并实现的累积成本较小。

**[Paper URL](https://proceedings.mlr.press/v202/liu23at.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23at/liu23at.pdf)** 

# Optimization for Amortized Inverse Problems
**题目:**  Amortized逆问题优化

**作者:** Tianci Liu, Tong Yang, Quan Zhang, Qi Lei

**Abstract:** Incorporating a deep generative model as the prior distribution in inverse problems has established substantial success in reconstructing images from corrupted observations. Notwithstanding, the existing optimization approaches use gradient descent largely without adapting to the non-convex nature of the problem and can be sensitive to initial values, impeding further performance improvement. In this paper, we propose an efficient amortized optimization scheme for inverse problems with a deep generative prior. Specifically, the optimization task with high degrees of difficulty is decomposed into optimizing a sequence of much easier ones. We provide a theoretical guarantee of the proposed algorithm and empirically validate it on different inverse problems. As a result, our approach outperforms baseline methods qualitatively and quantitatively by a large margin.

**摘要:** 在逆问题中引入深层生成模型作为预先分布,在重建图像时取得了相当大的成功。尽管如此,现有的优化方法在很大程度上不适应问题非凸性质的情况下使用梯度下降,并且对初始值有敏感性,从而阻碍了进一步的性能改进。本文提出了一种具有深层生成序列的逆问题有效的 amortized optimization scheme。具体而言,具有较高难度的优化任务被分解为一种较容易的优化序列。

**[Paper URL](https://proceedings.mlr.press/v202/liu23au.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23au/liu23au.pdf)** 

# Active Policy Improvement from Multiple Black-box Oracles
**题目:** 多个黑箱Oracle中的主动政策改进

**作者:** Xuefeng Liu, Takuma Yoneda, Chaoqi Wang, Matthew Walter, Yuxin Chen

**Abstract:** Reinforcement learning (RL) has made significant strides in various complex domains. However, identifying an effective policy via RL often necessitates extensive exploration. Imitation learning aims to mitigate this issue by using expert demonstrations to guide exploration. In real-world scenarios, one often has access to multiple suboptimal black-box experts, rather than a single optimal oracle. These experts do not universally outperform each other across all states, presenting a challenge in actively deciding which oracle to use and in which state. We introduce MAPS and MAPS-SE, a class of policy improvement algorithms that perform imitation learning from multiple suboptimal oracles. In particular, MAPS actively selects which of the oracles to imitate and improve their value function estimates, and MAPS-SE additionally leverages an active state exploration criterion to determine which states one should explore. We provide a comprehensive theoretical analysis and demonstrate that MAPS and MAPS-SE enjoy sample efficiency advantage over the state-of-the-art policy improvement algorithms. Empirical results show that MAPS-SE significantly accelerates policy optimization via state-wise imitation learning from multiple oracles across a broad spectrum of control tasks in the DeepMind Control Suite.

**摘要:** 强化学习(RL)在各个复杂领域取得了重大进展。然而,通过RL识别有效的政策往往需要进行广泛的探索。仿真学习旨在通过专家的演示来缓解这一问题,指导探索。在现实世界中,人们经常有访问多个次优的黑箱专家,而不是单个最优的 Oracle。这些专家并不普遍在所有州中互相超越,在积极决定使用哪个 Oracle和在哪个州中提出挑战。我们引入MAPS和MAPS-SE,一种政策改进算法,从多个次优的 Oracle中进行仿真学习。我们提供了一个全面的理论分析,并证明了MAPS和MAPS-SE在最先进的政策改进算法上享有样本效率优势。经验结果表明,MAPS-SE在 DeepMind控制套件的广泛控制任务中,通过从多个 Oracle 中进行状态模拟学习,大大加快了政策优化。

**[Paper URL](https://proceedings.mlr.press/v202/liu23av.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23av/liu23av.pdf)** 

# Gradient-based Wang-Landau Algorithm: A Novel Sampler for Output Distribution of Neural Networks over the Input Space
**题目:** 基于梯度 Wang-Landau算法:输入空间内神经网络输出分布的新样本

**作者:** Weitang Liu, Yi-Zhuang You, Ying Wai Li, Jingbo Shang

**Abstract:** The output distribution of a neural network (NN) over the entire input space captures the complete input-output mapping relationship, offering in- sights toward a more comprehensive NN under- standing. Exhaustive enumeration or traditional Monte Carlo methods for the entire input space can exhibit impractical sampling time, especially for high-dimensional inputs. To make such difficult sampling computationally feasible, in this paper, we propose a novel Gradient-based Wang-Landau (GWL) sampler. We first draw the connection between the output distribution of a NN and the density of states (DOS) of a physical system. Then, we renovate the classic sampler for the DOS problem, Wang-Landau algorithm, by re-placing its random proposals with gradient-based Monte Carlo proposals. This way, our GWL sampler investigates the under-explored subsets of the input space much more efficiently. Extensive experiments have verified the accuracy of the output distribution generated by GWL and also showcased several interesting findings - for example, in a binary image classification task, both CNN and ResNet mapped the majority of human unrecognizable images to very negative logit values.

**摘要:** 整个输入空间中神经网络的输出分布能捕捉到完整的输入输出映射关系,从而提供更全面的NN下层空间。对整个输入空间的综合计数或传统的蒙特卡罗方法可能显示出不实用的采样时间,特别是对于高维输入。为了使这种难于计算的采样可行,本文提出了一种新型基于梯度 Wang-Landau (GWL)采样器。我们首先描绘了一种NN的输出分布与物理系统的密度(DOS)之间的关系,然后重新设计了DOS问题的经典采样器,即 Wang-Landau算法,用梯度基于蒙特卡罗的采样方案取代其随机提议。广泛的实验验证了GWL生成的输出分布的准确性,并展示了一些有趣的发现 - 例如,在二进制图像分类任务中,CNN和ResNet都将大多数人无法识别图像映射到非常负的 logit值。

**[Paper URL](https://proceedings.mlr.press/v202/liu23aw.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23aw/liu23aw.pdf)** 

# VectorMapNet: End-to-end Vectorized HD Map Learning
**题目:** VectorMapNet:端到端向量化HD地图学习

**作者:** Yicheng Liu, Tianyuan Yuan, Yue Wang, Yilun Wang, Hang Zhao

**Abstract:** Autonomous driving systems require High-Definition (HD) semantic maps to navigate around urban roads. Existing solutions approach the semantic mapping problem by offline manual annotation, which suffers from serious scalability issues. Recent learning-based methods produce dense rasterized segmentation predictions to construct maps. However, these predictions do not include instance information of individual map elements and require heuristic post-processing to obtain vectorized maps. To tackle these challenges, we introduce an end-to-end vectorized HD map learning pipeline, termed VectorMapNet. VectorMapNet takes onboard sensor observations and predicts a sparse set of polylines in the bird’s-eye view. This pipeline can explicitly model the spatial relation between map elements and generate vectorized maps that are friendly to downstream autonomous driving tasks. Extensive experiments show that VectorMapNet achieve strong map learning performance on both nuScenes and Argoverse2 dataset, surpassing previous state-of-the-art methods by 14.2 mAP and 14.6mAP. Qualitatively, VectorMapNet is capable of generating comprehensive maps and capturing fine-grained details of road geometry. To the best of our knowledge, VectorMapNet is the first work designed towards end-to-end vectorized map learning from onboard observations.

**摘要:** 自动驾驶系统需要高定义(HD)语义地图,以导航城市道路。现有的解决方案通过非线性手动注释来解决语义映射问题,造成严重的可扩展性问题。最近的基于学习的方法产生密集的分段预测来构建地图。然而,这些预测不包括个别地图元素的实例信息,并需要启发式后处理以获得向量化地图。为了解决这些挑战,我们引入了一个向量化HD地图学习管道,称为VectorMapNet。VectorMapNet采用传感器观测并预测鸟眼视图中稀少的多线。广泛的实验表明,VectorMapNet在 nuScenes 和 Argoverse2 数据集上取得了较强的地图学习性能,超过了以往的最先进的方法 14.2 mAP 和 14.6mAP 。 在质量上,VectorMapNet能够生成全面的地图并捕捉道路几何的细微细节。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ax.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ax/liu23ax.pdf)** 

# Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing
**题目:** 部分可观察的多agentRL(四元)效率:信息共享的光辉

**作者:** Xiangyu Liu, Kaiqing Zhang

**Abstract:** We study provable multi-agent reinforcement learning (MARL) in the general framework of partially observable stochastic games (POSGs). To circumvent the known hardness results and the use of computationally intractable oracles, we propose to leverage the potential information-sharing among agents, a standard practice in empirical MARL and a common model for multi-agent control systems with communications. We first establish several computation complexity results to justify the necessity of information-sharing, as well as the observability assumption that has enabled quasi-efficient single-agent RL with partial observations, for computational efficiency in solving POSGs. We then propose to further approximate the shared common information to construct an approximate model of the POSG, in which planning an approximate equilibrium (in terms of solving the original POSG) can be quasi-efficient, i.e., of quasi-polynomial-time, under the aforementioned assumptions. Furthermore, we develop a partially observable MARL algorithm that is both statistically and computationally quasi-efficient. We hope our study can open up the possibilities of leveraging and even designing different information structures, for developing both sample- and computation-efficient partially observable MARL.

**摘要:** 在部分可观测随机游戏的一般框架中,我们研究了可证明的多代理增强学习(MARL)方法。为了绕过已知的硬度结果和计算上不可解的方言的使用,我们建议利用代理间的潜在信息共享,这是经验的MARL的标准实践和通信的多代理控制系统的一个共同模型。我们首先建立几个计算复杂性结果,以证明信息共享的必要性,以及通过部分观察实现准有效单代理RL的可观测性假设,以求求求解POSG的计算效率。此外,我们还开发了一种统计和计算的准效率的局部可观测MARL算法,希望我们的研究能打开利用甚至设计不同信息结构的可能性,以开发具有样品和计算效率的局部可观测MARL。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ay.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ay/liu23ay.pdf)** 

# Prometheus: Taming Sample and Communication Complexities in Constrained Decentralized Stochastic Bilevel Learning
**题目:** Prometheus:抑制分散随机双层学习中的实例与通信复杂性

**作者:** Zhuqing Liu, Xin Zhang, Prashant Khanduri, Songtao Lu, Jia Liu

**Abstract:** In recent years, decentralized bilevel optimization has gained significant attention thanks to its versatility in modeling a wide range of multi-agent learning problems, such as multi-agent reinforcement learning and multi-agent meta-learning. However, one unexplored and fundamental problem in this area is how to solve decentralized stochastic bilevel optimization problems with domain constraints while achieving low sample and communication complexities. This problem often arises from multi-agent learning problems with safety constraints. As shown in this paper, constrained decentralized bilevel optimization is far more challenging than its unconstrained counterpart due to the complex coupling structure, which necessitates new algorithm design and analysis techniques. Toward this end, we investigate a class of constrained decentralized bilevel optimization problems, where multiple agents collectively solve a nonconvex-strongly-convex bilevel problem with constraints in the upper-level variables. We propose an algorithm called Prometheus (proximal tracked stochastic recursive estimator) that achieves the first $\mathcal{O}(\epsilon^{-1})$ results in both sample and communication complexities for constrained decentralized bilevel optimization, where $\epsilon>0$ is a desired stationarity error. Collectively, the results in this work contribute to a theoretical foundation for low sample- and communication-complexity constrained decentralized bilevel learning.

**摘要:** 近年来,分散二级优化技术在建模多层次学习问题,如多层次增强学习和多层次元学习方面具有广泛的应用价值。然而,在这一领域,一个尚未探索的根本问题是如何解决具有域约束的分散随机二级优化问题,同时实现低样品和通信复杂性。这一问题往往来自具有安全约束的多层次学习问题。为此目的,我们研究了一种约束分散二级优化问题的类别,其中多个代理人共同解决了非凸强凸二级问题,其上层变量有约束。我们提出了一种叫做Prometheus的算法(近似跟踪随机递归估计器),该算法在约束分散二级优化的样品和通信复杂性上取得第一个$\mathcal{O}(\epsilon^{-1})$结果,其中$\epsilon>0$是理想的静态误差。

**[Paper URL](https://proceedings.mlr.press/v202/liu23az.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23az/liu23az.pdf)** 

# D2Match: Leveraging Deep Learning and Degeneracy for Subgraph Matching
**题目:** D2Match:利用深度学习和退化为子图匹配

**作者:** Xuanzhou Liu, Lin Zhang, Jiaqi Sun, Yujiu Yang, Haiqin Yang

**Abstract:** Subgraph matching is a fundamental building block for graph-based applications and is challenging due to its high-order combinatorial nature. Existing studies usually tackle it by combinatorial optimization or learning-based methods. However, they suffer from exponential computational costs or searching the matching without theoretical guarantees. In this paper, we develop $D^2$Match by leveraging the efficiency of Deep learning and Degeneracy for subgraph matching. More specifically, we first prove that subgraph matching can degenerate to subtree matching, and subsequently is equivalent to finding a perfect matching on a bipartite graph. We can then yield an implementation of linear time complexity by the built-in tree-structured aggregation mechanism on graph neural networks. Moreover, circle structures and node attributes can be easily incorporated in $D^2$Match to boost the matching performance. Finally, we conduct extensive experiments to show the superior performance of our $D^2$Match and confirm that our $D^2$Match indeed exploits the subtrees and differs from existing GNNs-based subgraph matching methods that depend on memorizing the data distribution divergence.

**摘要:** 子图匹配是基于图的应用程序的一个基本构件,由于其高阶组合性而具有挑战性。现有的研究通常通过组合优化或基于学习的方法来解决它。然而,它们会遭受指数计算成本或没有理论保证的匹配搜索。本论文通过利用深度学习和退化对子图匹配的效率来开发$D^2$Match。具体地说,我们首先证明子图匹配可以退化到子树匹配,并随后相当于在双边图上找到完美的匹配。最后,我们进行了广泛的实验,证明了$D^2$Match的优越性能,并证实了$D^2$Match的确利用子树,与现有基于GNN的子图匹配方法不同,这取决于记忆数据分布差异。

**[Paper URL](https://proceedings.mlr.press/v202/liu23ba.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23ba/liu23ba.pdf)** 

# Image Shortcut Squeezing: Countering Perturbative Availability Poisons with Compression
**题目:** 图像短cut压缩:对应压缩的有害毒物

**作者:** Zhuoran Liu, Zhengyu Zhao, Martha Larson

**Abstract:** Perturbative availability poisoning (PAP) adds small changes to images to prevent their use for model training. Current research adopts the belief that practical and effective approaches to countering such poisons do not exist. In this paper, we argue that it is time to abandon this belief. We present extensive experiments showing that 12 state-of-the-art PAP methods are vulnerable to Image Shortcut Squeezing (ISS), which is based on simple compression. For example, on average, ISS restores the CIFAR-10 model accuracy to 81.73%, surpassing the previous best preprocessing-based countermeasures by 37.97% absolute. ISS also (slightly) outperforms adversarial training and has higher generalizability to unseen perturbation norms and also higher efficiency. Our investigation reveals that the property of PAP perturbations depends on the type of surrogate model used for poison generation, and it explains why a specific ISS compression yields the best performance for a specific type of PAP perturbation. We further test stronger, adaptive poisoning, and show it falls short of being an ideal defense against ISS. Overall, our results demonstrate the importance of considering various (simple) countermeasures to ensure the meaningfulness of analysis carried out during the development of availability poisons.

**摘要:** 扰动可用性毒化(英语:Perturbative availability poisoning,PAP)是对图像进行小变化,以防止它们用于模型训练的使用。目前的研究认为,对抗这种毒素的实际和有效的方法并不存在。我们认为,现在是放弃这种信念的时候了。我们提出了12个最新 PAP方法对基于简单的压缩的Image Shortcut Squeezing(ISS)具有脆弱性,例如,ISS平均恢复CIFAR-10模型的准确率为81.73%,超过了以前最好的预处理基础的对抗措施的37.97%。研究表明,PAP扰动的性质取决于毒素生成中使用的替代模型类型,并解释了为什么某一特定的ISS压缩机对某一特定类型的PAP扰动产生最佳性能。我们进一步测试了更强的适应性毒素,并证明它不足为理想的防护。总体而言,我们的结果表明考虑各种(简单的)对策的重要性,以确保在开发可用毒素时进行的分析有意义。

**[Paper URL](https://proceedings.mlr.press/v202/liu23bb.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23bb/liu23bb.pdf)** 

# Which Invariance Should We Transfer? A Causal Minimax Learning Approach
**题目:** 我们应该转移哪种不变性? 预防性最小学习方法

**作者:** Mingzhou Liu, Xiangyu Zheng, Xinwei Sun, Fang Fang, Yizhou Wang

**Abstract:** A major barrier to deploying current machine learning models lies in their non-reliability to dataset shifts. To resolve this problem, most existing studies attempted to transfer stable information to unseen environments. Particularly, independent causal mechanisms-based methods proposed to remove mutable causal mechanisms via the do-operator. Compared to previous methods, the obtained stable predictors are more effective in identifying stable information. However, a key question remains: which subset of this whole stable information should the model transfer, in order to achieve optimal generalization ability? To answer this question, we present a comprehensive minimax analysis from a causal perspective. Specifically, we first provide a graphical condition for the whole stable set to be optimal. When this condition fails, we surprisingly find with an example that this whole stable set, although can fully exploit stable information, is not the optimal one to transfer. To identify the optimal subset under this case, we propose to estimate the worst-case risk with a novel optimization scheme over the intervention functions on mutable causal mechanisms. We then propose an efficient algorithm to search for the subset with minimal worst-case risk, based on a newly defined equivalence relation between stable subsets. Compared to the exponential cost of exhaustively searching over all subsets, our searching strategy enjoys a polynomial complexity. The effectiveness and efficiency of our methods are demonstrated on synthetic data and the diagnosis of Alzheimer’s disease.

**摘要:** 当前机器学习模型的部署的一个主要障碍在于其对数据集变换的不可靠性。为了解决这个问题,大多数现有的研究都试图将稳定信息转移到未见的环境中。特别是,基于独立的因果机制的方法提议通过做操作者去除变态因果机制。与以前的方法相比,获得的稳定预测器在识别稳定信息方面更有效。然而,一个关键问题仍然存在:该整个稳定信息的哪个子集应该由模型转移,以达到最佳的一般化能力?为了回答这个问题,我们从因果角度给出了全面微分分析。具体地说,我们首先为整个稳定集合提供一个图形条件,使整个稳定集合成为最优。为了确定该案例下的最优子集,我们提出了一种基于稳定子集之间新界定的等价关系的最小最小风险子集搜索的高效算法,并提出了一种基于变态因果机制的干预函数的新优化方案来估计最小风险子集。与所有子集全面搜索的指数成本相比,我们的搜索策略具有多项式复杂性。

**[Paper URL](https://proceedings.mlr.press/v202/liu23bc.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23bc/liu23bc.pdf)** 

# Unsupervised Out-of-Distribution Detection with Diffusion Inpainting
**题目:** 不经监督的外散检测与扩散油漆

**作者:** Zhenzhen Liu, Jin Peng Zhou, Yufan Wang, Kilian Q Weinberger

**Abstract:** Unsupervised out-of-distribution detection (OOD) seeks to identify out-of-domain data by learning only from unlabeled in-domain data. We present a novel approach for this task – Lift, Map, Detect (LMD) – that leverages recent advancement in diffusion models. Diffusion models are one type of generative models. At their core, they learn an iterative denoising process that gradually maps a noisy image closer to their training manifolds. LMD leverages this intuition for OOD detection. Specifically, LMD lifts an image off its original manifold by corrupting it, and maps it towards the in-domain manifold with a diffusion model. For an OOD image, the mapped image would have a large distance away from its original manifold, and LMD would identify it as OOD accordingly. We show through extensive experiments that LMD achieves competitive performance across a broad variety of datasets. Code can be found at https://github.com/zhenzhel/lift_map_detect.

**摘要:** 非监督的外分布检测(OOD)旨在通过学习非标记内域数据来识别外域数据。我们为这一任务提出了一种新方法--提取、映射、检测(LMD)--它利用扩散模型的最新进展。扩散模型是产生模型的一种类型。在其核心中,他们学习一种迭代代名词化过程,逐渐将噪音的图像映射到他们训练的多边形。LMD利用这种直觉来检测OOD。具体地说,LMD通过破坏其原始多边形而提取一个图像,并将其映射到内域多边形的扩散模型。

**[Paper URL](https://proceedings.mlr.press/v202/liu23bd.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23bd/liu23bd.pdf)** 

# N$\text{A}^{\text{2}}$Q: Neural Attention Additive Model for Interpretable Multi-Agent Q-Learning
**题目:** N$\text{A}^{\text{2}}$Q:解释性多代理Q-学习的神经注意力辅助模型

**作者:** Zichuan Liu, Yuanyang Zhu, Chunlin Chen

**Abstract:** Value decomposition is widely used in cooperative multi-agent reinforcement learning, however, its implicit credit assignment mechanism is not yet fully understood due to black-box networks. In this work, we study an interpretable value decomposition framework via the family of generalized additive models. We present a novel method, named Neural Attention Additive Q-learning (N$\text{A}^\text{2}$Q), providing inherent intelligibility of collaboration behavior. N$\text{A}^\text{2}$Q can explicitly factorize the optimal joint policy induced by enriching shape functions to model all possible coalition of agents into individual policies. Moreover, we construct the identity semantics to promote estimating credits together with the global state and individual value functions, where local semantic masks help us diagnose whether each agent captures the relevant-task information. Extensive experiments show that N$\text{A}^\text{2}$Q consistently achieves superior performance compared to different state-of-the-art methods on all challenging tasks, while yielding human-like interpretability.

**摘要:** 价值分解在合作多agent增强学习中广泛应用,但由于黑箱网络,其隐性信用分配机制尚未得到充分理解。本文通过广义附加模型研究了一个可解释的价值分解框架。我们提出了一种新的方法,叫做神经 Attention Additive Q-learning(N$\text{A}^\text{2}$Q),提供协作行为的内在可理解性。N$\text{A}^\text{2}$Q可以明确考虑通过riching shape functions诱导的优化联合政策,将所有可能的代理组合模型化为单独的政策。广泛的实验表明,N$\text{A}^\text{2}$Q在所有挑战性任务中,与不同的最先进的方法相比,始终能取得更高的性能,同时提供类似人类的解释能力。

**[Paper URL](https://proceedings.mlr.press/v202/liu23be.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23be/liu23be.pdf)** 

# Contextual Combinatorial Bandits with Probabilistically Triggered Arms
**题目:** 具有可能触动武器的背景组合强盗

**作者:** Xutong Liu, Jinhang Zuo, Siwei Wang, John C.S. Lui, Mohammad Hajiesmaili, Adam Wierman, Wei Chen

**Abstract:** We study contextual combinatorial bandits with probabilistically triggered arms (C$^2$MAB-T) under a variety of smoothness conditions that capture a wide range of applications, such as contextual cascading bandits and contextual influence maximization bandits. Under the triggering probability modulated (TPM) condition, we devise the C$^2$-UCB-T algorithm and propose a novel analysis that achieves an $\tilde{O}(d\sqrt{KT})$ regret bound, removing a potentially exponentially large factor $O(1/p_{\min})$, where $d$ is the dimension of contexts, $p_{\min}$ is the minimum positive probability that any arm can be triggered, and batch-size $K$ is the maximum number of arms that can be triggered per round. Under the variance modulated (VM) or triggering probability and variance modulated (TPVM) conditions, we propose a new variance-adaptive algorithm VAC$^2$-UCB and derive a regret bound $\tilde{O}(d\sqrt{T})$, which is independent of the batch-size $K$. As a valuable by-product, our analysis technique and variance-adaptive algorithm can be applied to the CMAB-T and C$^2$MAB setting, improving existing results there as well. We also include experiments that demonstrate the improved performance of our algorithms compared with benchmark algorithms on synthetic and real-world datasets.

**摘要:** 我们研究了基于概率触发的上下文组合带子(C$^2$MAB-T)在各种滑度条件下,包括上下文 cascading带子(C$^2$MAB-T)和上下文影响最大化带子(C$^2$MAB-T)。在触发概率调制(TPM)条件下,我们设计了C$^2$-UCB-T算法,并提出了一种新的分析,实现$\tilde{O}(d\sqrt{KT})$ regret bound,除去潜在指数大因子$O(1/p_{\min})$,其中$d$是上下文的维度,$p_{\min}$是任何手臂可以触发的最小正概率,而批量大小$K$是每轮可以触发的 arms 的最大数量。在作为一种有价值的副产品,我们分析技术和变异适应算法可以应用于CMAB-T和C$^2$MAB设置,改善现有的结果。我们还包括实验,证明了我们算法在合成和现实数据集的基准算法上的表现。

**[Paper URL](https://proceedings.mlr.press/v202/liu23bf.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/liu23bf/liu23bf.pdf)** 

# Flipping Coins to Estimate Pseudocounts for Exploration in Reinforcement Learning
**题目:** 旋转硬币估算增强学习中的伪数

**作者:** Sam Lobel, Akhil Bagaria, George Konidaris

**Abstract:** We propose a new method for count-based exploration in high-dimensional state spaces. Unlike previous work which relies on density models, we show that counts can be derived by averaging samples from the Rademacher distribution (or coin flips). This insight is used to set up a simple supervised learning objective which, when optimized, yields a state’s visitation count. We show that our method is significantly more effective at deducing ground-truth visitation counts than previous work; when used as an exploration bonus for a model-free reinforcement learning algorithm, it outperforms existing approaches on most of 9 challenging exploration tasks, including the Atari game Montezuma’s Revenge.

**摘要:** 我们提出了一种基于计数的高维状态空间勘探的新方法。与以往基于密度模型的工作不同,我们表明,计数可以通过平均从拉德马切尔分布(或硬币翻转)的样品导出。这一洞察被用来建立一个简单的监督学习目标,当优化后,产生一个国家访问数。我们表明,我们的方法比以往的工作更有效地推导地面事实访问数;当用作一个无模型增强学习算法的勘探奖金时,它超过了在9个挑战性勘探任务中现有的方法,包括阿塔里游戏蒙特苏马复仇。

**[Paper URL](https://proceedings.mlr.press/v202/lobel23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lobel23a/lobel23a.pdf)** 

# Multi-Symmetry Ensembles: Improving Diversity and Generalization via Opposing Symmetries
**题目:** 多对称集:通过反对称改进多样性和推广

**作者:** Charlotte Loh, Seungwook Han, Shivchander Sudalairaj, Rumen Dangovski, Kai Xu, Florian Wenzel, Marin Soljacic, Akash Srivastava

**Abstract:** Deep ensembles (DE) have been successful in improving model performance by learning diverse members via the stochasticity of random initialization. While recent works have attempted to promote further diversity in DE via hyperparameters or regularizing loss functions, these methods primarily still rely on a stochastic approach to explore the hypothesis space. In this work, we present Multi-Symmetry Ensembles (MSE), a framework for constructing diverse ensembles by capturing the multiplicity of hypotheses along symmetry axes, which explore the hypothesis space beyond stochastic perturbations of model weights and hyperparameters. We leverage recent advances in contrastive representation learning to create models that separately capture opposing hypotheses of invariant and equivariant functional classes and present a simple ensembling approach to efficiently combine appropriate hypotheses for a given task. We show that MSE effectively captures the multiplicity of conflicting hypotheses that is often required in large, diverse datasets like ImageNet. As a result of their inherent diversity, MSE improves classification performance, uncertainty quantification, and generalization across a series of transfer tasks. Our code is available at https://github.com/clott3/multi-sym-ensem

**摘要:** 深组件通过随机初始化的随机性学习,成功地提高了模型性能。虽然最近的研究试图通过高参数或调整损失函数来促进DE的进一步多样性,但这些方法仍主要依靠随机性的方法来探索假设空间。本研究中,我们提出了多相称组件(MSE),一种通过在对称轴上捕捉假设的多重性来构造不同的组件的框架,这些框架可以超越模型重量和高参数的随机性扰动来探索假设空间。我们证明,MSE有效捕捉了像ImageNet这样的大型、多样性数据集中经常需要的冲突假设的多重性。由于它们的固有多样性,MSE提高了分类性能、不确定性量化和在一系列的传输任务中推广。

**[Paper URL](https://proceedings.mlr.press/v202/loh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/loh23a/loh23a.pdf)** 

# The Flan Collection: Designing Data and Methods for Effective Instruction Tuning
**题目:** Flan收集:设计有效的教学调教数据和方法

**作者:** Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, Adam Roberts

**Abstract:** We study the design decision of publicly available instruction tuning methods, by reproducing and breaking down the development of Flan 2022 (Chung et al., 2022). Through careful ablation studies on the Flan Collection of tasks and methods, we tease apart the effect of design decisions which enable Flan-T5 to outperform prior work by 3-17% across evaluation settings. We find task balancing and enrichment techniques are overlooked but critical to effective instruction tuning, and in particular, training with mixed prompt settings (zero-shot, few-shot, chain-of-thought) actually yields equivalent or stronger (2%) performance in all settings. In further experiments we show Flan-T5 requires less finetuning to converge higher and faster than T5 on single downstream tasks – motivating instruction-tuned models as more computationally-efficient starting checkpoints for new tasks. Finally, to accelerate research on instruction tuning, we make the Flan 2022 collection of datasets, templates, and methods publicly available.

**摘要:** 我们研究了公开的指令调制方法的设计决策,通过复制和分解Flan 2022的开发过程(Chung et al., 2022)。通过对Flan收集任务和方法的仔细研究,我们分开设计决策的影响,使得Flan-T5在评价设置中比以前的工作表现高3-17%。我们发现任务平衡和richment技术被忽略,但对于有效的指令调制至关重要,特别是,混合快速设置的训练(零射击、少射击、思考链)实际上在所有设置中产生等效或更强(2%)的性能。最后,为了加速教学调制的研究,我们公开了Flan 2022数据集、模板和方法的收集。

**[Paper URL](https://proceedings.mlr.press/v202/longpre23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/longpre23a/longpre23a.pdf)** 

# Dataset Distillation with Convexified Implicit Gradients
**题目:** 凸形隐形梯度数据集蒸馏

**作者:** Noel Loo, Ramin Hasani, Mathias Lechner, Daniela Rus

**Abstract:** We propose a new dataset distillation algorithm using reparameterization and convexification of implicit gradients (RCIG), that substantially improves the state-of-the-art. To this end, we first formulate dataset distillation as a bi-level optimization problem. Then, we show how implicit gradients can be effectively used to compute meta-gradient updates. We further equip the algorithm with a convexified approximation that corresponds to learning on top of a frozen finite-width neural tangent kernel. Finally, we improve bias in implicit gradients by parameterizing the neural network to enable analytical computation of final-layer parameters given the body parameters. RCIG establishes the new state-of-the-art on a diverse series of dataset distillation tasks. Notably, with one image per class, on resized ImageNet, RCIG sees on average a 108% improvement over the previous state-of-the-art distillation algorithm. Similarly, we observed a 66% gain over SOTA on Tiny-ImageNet and 37% on CIFAR-100.

**摘要:** 本文提出了一种新的隐形梯度校正和凸化(RCIG)算法,大大改善了隐形梯度的性能。为此,首先将隐形梯度定义为双级优化问题,然后说明隐形梯度如何有效用于计算元梯度更新。我们进一步装配了凸化近似算法,与冻结的有限宽度神经 Tangent 内核上学习相符。最后,通过参数化神经网络来改善隐形梯度的偏差,使给身体参数的最终层参数的分析计算得以实现。同样,我们观察到在Tiny-ImageNet上的SOA比SOTA增长66%,在CIFAR-100上的SOA增长37%。

**[Paper URL](https://proceedings.mlr.press/v202/loo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/loo23a/loo23a.pdf)** 

# Reflected Diffusion Models
**题目:** 反射扩散模型

**作者:** Aaron Lou, Stefano Ermon

**Abstract:** Score-based diffusion models learn to reverse a stochastic differential equation that maps data to noise. However, for complex tasks, numerical error can compound and result in highly unnatural samples. Previous work mitigates this drift with thresholding, which projects to the natural data domain (such as pixel space for images) after each diffusion step, but this leads to a mismatch between the training and generative processes. To incorporate data constraints in a principled manner, we present Reflected Diffusion Models, which instead reverse a reflected stochastic differential equation evolving on the support of the data. Our approach learns the perturbed score function through a generalized score matching loss and extends key components of standard diffusion models including diffusion guidance, likelihood-based training, and ODE sampling. We also bridge the theoretical gap with thresholding: such schemes are just discretizations of reflected SDEs. On standard image benchmarks, our method is competitive with or surpasses the state of the art without architectural modifications and, for classifier-free guidance, our approach enables fast exact sampling with ODEs and produces more faithful samples under high guidance weight.

**摘要:** 基于分数的扩散模型学习将数据映射成噪声的随机微分方程逆转。然而,对于复杂的任务,数值误差可以复杂化并产生非常不自然的样品。以前的工作通过阈值减缓了这种漂移,它在每次扩散步骤后将投影到自然数据领域(例如像素空间)中,但这会导致训练和生成过程之间的不匹配。为了在原则上结合数据约束,我们提出了反射扩散模型,它相反地逆转了反映随机微分方程在数据支持上演变。我们的方法通过推广分数匹配损失来学习扰动分数函数,并扩展了标准扩散模型的关键组成部分,包括扩散指导、基于概率的训练和ODE样本。在标准图像基准上,我们的方法与或超越了无建筑修改的最先进的技术,并且对于无分类指导,我们的方法能够快速准确地与ODEs提取样品,并且在高指导重量下产生更忠实的样品。

**[Paper URL](https://proceedings.mlr.press/v202/lou23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lou23a/lou23a.pdf)** 

# Never mind the metrics---what about the uncertainty? Visualising binary confusion matrix metric distributions to put performance in perspective
**题目:** 不考虑度量---不确定度如何? 可视化二进制混淆矩阵度量分布,将性能置于视角

**作者:** David Lovell, Dimity Miller, Jaiden Capra, Andrew P. Bradley

**Abstract:** There are strong incentives to build classification systems that show outstanding performance on various datasets and benchmarks. This can encourage a narrow focus on models and the performance metrics used to evaluate and compare them—resulting in a growing body of literature to evaluate and compare metrics. This paper strives for a more balanced perspective on binary classifier performance metrics by showing how uncertainty in these metrics can easily eclipse differences in empirical performance. We emphasise the discrete nature of confusion matrices and show how they can be well represented in a 3D lattice whose cross-sections form the space of receiver operating characteristic (ROC) curves. We develop novel interactive visualisations of performance metric contours within (and beyond) ROC space, showing the discrete probability mass functions of true and false positive rates and how these relate to performance metric distributions. We aim to raise awareness of the substantial uncertainty in performance metric estimates that can arise when classifiers are evaluated on empirical datasets and benchmarks, and that performance claims should be tempered by this understanding.

**摘要:** 建立基于不同数据集和基准的分类系统具有很强的激励作用。这可以鼓励对模型和用于评价和比较的性能指标进行狭窄的关注 — — 从而使越来越多的文献对性能指标进行评价和比较。本论文试图在二进制分类器性能指标上建立更平衡的视角,以显示这些指标中的不确定性如何轻易地掩盖经验性能上的差异。我们强调混淆矩阵的离散性质,并表明它们如何在3D网格中得到很好的表现,其截面构成接收器操作特性曲线的空间。我们开发了新的交互式可视化性能度量曲线在ROC空间内(以及在ROC空间之外),显示真实和假正率的离散概率质量函数以及它们如何与性能度量分布有关。我们 旨在 提高 人们 对 在 评价 分类 器 的 经验 数据 集 和 基准 时 可能 产生 的 业绩 统计 估计 中 的 重大 不确定性 的 认识, 并 希望 通过 这种 了解 来 缓和 业绩 要求 。

**[Paper URL](https://proceedings.mlr.press/v202/lovell23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lovell23a/lovell23a.pdf)** 

# Bilevel Optimization with Coupled Decision-Dependent Distributions
**题目:** 双层优化与耦合决策依赖分布

**作者:** Songtao Lu

**Abstract:** Bilevel optimization has gained significant popularity in recent years due to its ability to formulate various machine learning problems. For instance, in meta-learning, the upper-level (UL) problem offers a good initialization for the lower-level (LL) model to facilitate adaptation. However, the decision variables can impact data features and outcomes, leading to the phenomenon known as performativity. In this work, we investigate the inclusion of decision-dependent distributions in bilevel optimization. Specifically, we consider the scenarios where the UL data distribution depends on the LL optimization variable, and the LL data distribution also depends on the UL decision variable. We first establish sufficient conditions for the existence of performatively stable (PS) solutions in this class of bilevel problems. Also, we propose efficient stochastic algorithms to find the PS point with theoretical convergence rate analysis and discuss the theoretical optimality of the obtained solution. Our theoretical analysis is corroborated through a series of numerical experiments, wherein we evaluate the performance of the bilevel performative prediction algorithms alongside non-performative counterparts in the context of meta strategic learning problems.

**摘要:** 双层优化近年来由于能够制订各种机器学习问题而获得显著的 popularity。例如,在元学习中,上层(UL)问题为下层(LL)模型提供良好的初始化,以促进适应。然而,决策变量可以影响数据特征和结果,从而导致表现性现象。在这个工作中,我们研究了决策依赖分布在双层优化中的应用。具体地说,我们考虑了UL数据分布依赖于LL优化变量的情况,而LL数据分布也依赖于UL决策变量。同时,提出了有效的随机算法,通过理论收敛率分析找到PS点,探讨得到的解决方案的理论优越性,通过一系列数值实验证明了理论分析的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/lu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lu23a/lu23a.pdf)** 

# Two-Scale Gradient Descent Ascent Dynamics Finds Mixed Nash Equilibria of Continuous Games: A Mean-Field Perspective
**题目:** 双尺度梯度上升动力学发现连续游戏的混合纳什均衡:一个中场视角

**作者:** Yulong Lu

**Abstract:** Finding the mixed Nash equilibria (MNE) of a two-player zero sum continuous game is an important and challenging problem in machine learning. A canonical algorithm to finding the MNE is the noisy gradient descent ascent method which in the infinite particle limit gives rise to the Mean-Field Gradient Descent Ascent (GDA) dynamics on the space of probability measures. In this paper, we first study the convergence of a two-scale Mean-Field GDA dynamics for finding the MNE of the entropy-regularized objective. More precisely we show that for each finite temperature (or regularization parameter), the two-scale Mean-Field GDA with a suitable finite scale ratio converges exponentially to the unique MNE without assuming the convexity or concavity of the interaction potential. The key ingredient of our proof lies in the construction of new Lyapunov functions that dissipate exponentially along the Mean-Field GDA. We further study the simulated annealing of the Mean-Field GDA dynamics. We show that with a temperature schedule that decays logarithmically in time the annealed Mean-Field GDA converges to the MNE of the original unregularized objective.

**摘要:** 本文首先研究了两个尺度中尺度GDA动力学的收敛性,以求找到熵调节目标中尺度的MNE。更确切地说,对于每个有限温度(或调节参数)中,两个尺度中尺度GDA具有适当的有限尺度比的收敛性,不假设相互作用潜力的凸凹性或凸凹性,从而使单一的MNE具有指数收敛性。我们证明的关键成分在于构造新的拉普诺夫函数,这些函数在中尺度GDA中指数散逸。我们进一步研究了中尺度GDA动力学的模拟收敛。我们证明,在温度表随时间递减的逻辑下, annealed Mean-Field GDA与原来的非调节目标的MNE相吻合。

**[Paper URL](https://proceedings.mlr.press/v202/lu23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lu23b/lu23b.pdf)** 

# STEP: Learning N:M Structured Sparsity Masks from Scratch with Precondition
**题目:** 步骤:学习N:M结构的零散面具从零开始,预备条件

**作者:** Yucheng Lu, Shivani Agrawal, Suvinay Subramanian, Oleg Rybakov, Christopher De Sa, Amir Yazdanbakhsh

**Abstract:** Recent innovations on hardware (e.g. Nvidia A100) have motivated learning N:M structured sparsity masks from scratch for fast model inference. However, state-of-the-art learning recipes in this regime (e.g. SR-STE) are proposed for non-adaptive optimizers like momentum SGD, while incurring non-trivial accuracy drop for Adam-trained models like attention-based LLMs. In this paper, we first demonstrate such gap origins from poorly estimated second moment (i.e. variance) in Adam states given by the masked weights. We conjecture that learning N:M masks with Adam should take the critical regime of variance estimation into account. In light of this, we propose STEP, an Adam-aware recipe that learns N:M masks with two phases: first, STEP calculates a reliable variance estimate (precondition phase) and subsequently, the variance remains fixed and is used as a precondition to learn N:M masks (mask-learning phase). STEP automatically identifies the switching point of two phases by dynamically sampling variance changes over the training trajectory and testing the sample concentration. Empirically, we evaluate STEP and other baselines such as ASP and SR-STE on multiple tasks including CIFAR classification, machine translation and LLM fine-tuning (BERT-Base, GPT-2). We show STEP mitigates the accuracy drop of baseline recipes and is robust to aggressive structured sparsity ratios.

**摘要:** 在硬件上,最近的创新(例如Nvidia A100)为快速模型推导提供了动力学习N:M结构的稀疏面具从零开始。然而,在这种模式中,最先进的学习配方(例如SR-STE)被提议用于不适应的优化器,如 momentum SGD,同时对阿达姆训练模型(如注意力型LLM)造成非平凡的精度下降。STEP自动识别两个阶段的交换点,通过动态采样训练轨迹上的变异变化和测试样品浓度。 STEP和其它基本线,如 ASP和SR-STE,在包括CIFAR分类、机器翻译和LLM微调(BERT-Base、GPT-2)在内的多个任务中,以实证的方式评估。

**[Paper URL](https://proceedings.mlr.press/v202/lu23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lu23c/lu23c.pdf)** 

# Contrastive Energy Prediction for Exact Energy-Guided Diffusion Sampling in Offline Reinforcement Learning
**题目:** 在线强化学习中的准确能量导向扩散采样的对比性能量预测

**作者:** Cheng Lu, Huayu Chen, Jianfei Chen, Hang Su, Chongxuan Li, Jun Zhu

**Abstract:** Guided sampling is a vital approach for applying diffusion models in real-world tasks that embeds human-defined guidance during the sampling procedure. This paper considers a general setting where the guidance is defined by an (unnormalized) energy function. The main challenge for this setting is that the intermediate guidance during the diffusion sampling procedure, which is jointly defined by the sampling distribution and the energy function, is unknown and is hard to estimate. To address this challenge, we propose an exact formulation of the intermediate guidance as well as a novel training objective named contrastive energy prediction (CEP) to learn the exact guidance. Our method is guaranteed to converge to the exact guidance under unlimited model capacity and data samples, while previous methods can not. We demonstrate the effectiveness of our method by applying it to offline reinforcement learning (RL). Extensive experiments on D4RL benchmarks demonstrate that our method outperforms existing state-of-the-art algorithms. We also provide some examples of applying CEP for image synthesis to demonstrate the scalability of CEP on high-dimensional data.

**摘要:** 导引采样是应用扩散模型在实际任务中的一个重要方法,它在采样过程中嵌入了人类定义的导引。本文考虑了导引由一个(非正常化的)能量函数定义的一般设置。该设置的主要挑战是,扩散采样过程中由采样分布和能量函数共同定义的中间导引是未知的,很难估计的。为了解决这一挑战,我们提出了一种准确的中间导引的公式以及一个名为对比能量预测(CEP)的新训练目标,以学习准确导引。对D4RL基准的广泛实验表明,我们的方法优于现有的最先进的算法。我们还提供了CEP在图像合成中的应用实例,以证明CEP在高维数据上具有可扩展性。

**[Paper URL](https://proceedings.mlr.press/v202/lu23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lu23d/lu23d.pdf)** 

# Exploring the Limits of Model-Targeted Indiscriminate Data Poisoning Attacks
**题目:** 探索基于模型的非歧视性数据中毒攻击的局限性

**作者:** Yiwei Lu, Gautam Kamath, Yaoliang Yu

**Abstract:** Indiscriminate data poisoning attacks aim to decrease a model’s test accuracy by injecting a small amount of corrupted training data. Despite significant interest, existing attacks remain relatively ineffective against modern machine learning (ML) architectures. In this work, we introduce the notion of model poisoning reachability as a technical tool to explore the intrinsic limits of data poisoning attacks towards target parameters (i.e., model-targeted attacks). We derive an easily computable threshold to establish and quantify a surprising phase transition phenomenon among popular ML models: data poisoning attacks can achieve certain target parameters only when the poisoning ratio exceeds our threshold. Building on existing parameter corruption attacks and refining the Gradient Canceling attack, we perform extensive experiments to confirm our theoretical findings, test the predictability of our transition threshold, and significantly improve existing indiscriminate data poisoning baselines over a range of datasets and models. Our work highlights the critical role played by the poisoning ratio, and sheds new insights on existing empirical results, attacks and mitigation strategies in data poisoning.

**摘要:** 非歧视性数据中毒攻击旨在通过注射少量受损训练数据降低模型的测试精度。尽管存在着重大的兴趣,现有的攻击仍然对现代机器学习(ML)架构相对无效。在这个工作中,我们引入了模型中毒的可达性的概念,作为一种技术工具来探索数据中毒攻击的内在局限性,以达到目标参数(即模型目标攻击)。基于现有参数腐蚀攻击和改进梯度取消攻击,我们进行了广泛的实验,证实了我们的理论发现,测试了我们过渡阈值的预测性,并在数据集和模型中大幅改善现有的无差别数据中毒基线。我们的工作突出了毒素比率所起的关键作用,并对数据中毒中的现有经验结果、攻击和缓解策略提供了新的洞察。

**[Paper URL](https://proceedings.mlr.press/v202/lu23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lu23e/lu23e.pdf)** 

# QAS-Bench: Rethinking Quantum Architecture Search and A Benchmark
**题目:** QAS-Bench:重新思考量子架构搜索和一个基准

**作者:** Xudong Lu, Kaisen Pan, Ge Yan, Jiaming Shan, Wenjie Wu, Junchi Yan

**Abstract:** Automatic quantum architecture search (QAS) has been widely studied across disciplines with different implications. In this paper, beyond a particular domain, we formulate the QAS problem into two basic (and relatively even ideal) tasks: i) arbitrary quantum circuit (QC) regeneration given a target QC; ii) approximating an arbitrary unitary (oracle). The latter can be connected to the setting of various quantum machine learning tasks and other QAS applications. Based on these two tasks, we generate a public QAS benchmark including 900 random QCs and 400 random unitary matrices which is still missing in the literature. We evaluate six baseline algorithms including brute force search, simulated annealing, genetic algorithm, reinforcement learning, hybrid algorithm, and differentiable algorithm as part of our benchmark. One characteristic of our proposed evaluation protocol on the basic tasks is that it deprives the domain-specific designs and techniques as used in existing QAS literature, making a unified evaluation possible and focusing on the vanilla search methods themselves without coupling with domain prior. In fact, the unitary approximation task could be algorithmically more difficult than the specific problems as it needs to explore the whole matrix space to fit the unitary. While specific tasks often only need to fit a partial observation of the unitary as the objective for search. Data and code are available at https://github.com/Lucky-Lance/QAS-Bench.

**摘要:** 自动量子架构搜索(英语:Automatic quantum architecture search,缩写:QAS)在不同领域广泛研究,具有不同的影响。本文在特定领域以外,将量子架构问题归纳为两个基本(甚至相对理想的)任务:(i)任意量子电路(QC)再生给目标QC;(ii)近似任意单元(oracle),后者可与各种量子机器学习任务和其他量子架构应用的设置联系起来。基于这两个任务,我们生成了一个包括900个随机量子电路和400个随机单元矩阵在内的公共量子架构基准。在基本任务上,我们提出的评估协议的一个特征是它剥夺了现有QAS文档中使用的领域特有的设计和技术,使统一的评估成为可能,并且集中于与领域相连的瓦尼拉搜索方法本身。事实上,单元近似任务可能比具体问题更困难,因为它需要探索整个矩阵空间来适应单元。

**[Paper URL](https://proceedings.mlr.press/v202/lu23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lu23f/lu23f.pdf)** 

# Learning Dense Correspondences between Photos and Sketches
**题目:** 学习照片与图画之间的紧密相连

**作者:** Xuanchen Lu, Xiaolong Wang, Judith E Fan

**Abstract:** Humans effortlessly grasp the connection between sketches and real-world objects, even when these sketches are far from realistic. Moreover, human sketch understanding goes beyond categorization – critically, it also entails understanding how individual elements within a sketch correspond to parts of the physical world it represents. What are the computational ingredients needed to support this ability? Towards answering this question, we make two contributions: first, we introduce a new sketch-photo correspondence benchmark, PSC6k, containing 150K annotations of 6250 sketch-photo pairs across 125 object categories, augmenting the existing Sketchy dataset with fine-grained correspondence metadata. Second, we propose a self-supervised method for learning dense correspondences between sketch-photo pairs, building upon recent advances in correspondence learning for pairs of photos. Our model uses a spatial transformer network to estimate the warp flow between latent representations of a sketch and photo extracted by a contrastive learning-based ConvNet backbone. We found that this approach outperformed several strong baselines and produced predictions that were quantitatively consistent with other warp-based methods. However, our benchmark also revealed systematic differences between predictions of the suite of models we tested and those of humans. Taken together, our work suggests a promising path towards developing artificial systems that achieve more human-like understanding of visual images at different levels of abstraction. Project page: https://photo-sketch-correspondence.github.io

**摘要:** 人类 effortlessly grasp the connection between sketches and real-world objects, even when these sketches are far from realistic. Moreover, human sketch understanding goes beyond categorization – critically, it also entails understanding how individual elements within a sketch correspond to parts of the physical world it represents. What are the computational ingredients needed to support this ability? Towards answering this question, we make two contributions: first, we introduce a new sketch-photo correspondence benchmark, PSC6k, containing 150K annotations of 6250 sketch-photo pairs across 125 object categories, augmenting the existing Sketchy dataset with fine-grained correspondence metadata. Second, we propose a self-supervised method for learning dense correspondences between sketch-photo pairs, building on recent advances in correspondence learning for pairs of photos.我们的模型使用空间变换器网络来估计基于对比学习的康文网后骨的草图和照片的隐形表现之间的 warp流。我们发现,这种方法超过了几个强的基线,并产生与其他基于 warp的方法的定量一致的预测。然而,我们的基准还显示了我们测试的模型组合和人类的预测之间的系统性差异。结合起来,我们的工作提出了一种在不同抽象水平上实现视觉图像更像人类的理解的人工系统开发方面有前景的道路。

**[Paper URL](https://proceedings.mlr.press/v202/lu23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lu23g/lu23g.pdf)** 

# Adversarial Cheap Talk
**题目:** 敌方廉价谈话

**作者:** Chris Lu, Timon Willi, Alistair Letcher, Jakob Nicolaus Foerster

**Abstract:** Adversarial attacks in reinforcement learning (RL) often assume highly-privileged access to the victim’s parameters, environment, or data. Instead, this paper proposes a novel adversarial setting called a Cheap Talk MDP in which an Adversary can merely append deterministic messages to the Victim’s observation, resulting in a minimal range of influence. The Adversary cannot occlude ground truth, influence underlying environment dynamics or reward signals, introduce non-stationarity, add stochasticity, see the Victim’s actions, or access their parameters. Additionally, we present a simple meta-learning algorithm called Adversarial Cheap Talk (ACT) to train Adversaries in this setting. We demonstrate that an Adversary trained with ACT can still significantly influence the Victim’s training and testing performance, despite the highly constrained setting. Affecting train-time performance reveals a new attack vector and provides insight into the success and failure modes of existing RL algorithms. More specifically, we show that an ACT Adversary is capable of harming performance by interfering with the learner’s function approximation, or instead helping the Victim’s performance by outputting useful features. Finally, we show that an ACT Adversary can manipulate messages during train-time to directly and arbitrarily control the Victim at test-time.

**摘要:** 在强化学习中,敌对攻击往往采取高度特权的访问受害者参数、环境或数据。相反,本文提出了一种名为“廉价对话”的新型敌对设置,在该设置中,敌对只能将确定性信息添加到受害者的观察中,从而产生最小范围的影响。敌对不能掩盖地面事实,影响环境动力学或奖励信号,引入非静态性,增加随机性,查看受害者的行为,或访问其参数。影响 tren-time性能,揭示了一个新的攻击向量,并提供对现有RL算法的成功和失败模式的洞察。具体地说,我们展示了ACT攻击者能够干扰学习者的函数近似,或者通过输出有用的特性来帮助受害者的性能。

**[Paper URL](https://proceedings.mlr.press/v202/lu23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lu23h/lu23h.pdf)** 

# Federated Conformal Predictors for Distributed Uncertainty Quantification
**题目:** 分布不确定度量化联邦一致预测器

**作者:** Charles Lu, Yaodong Yu, Sai Praneeth Karimireddy, Michael Jordan, Ramesh Raskar

**Abstract:** Conformal prediction is emerging as a popular paradigm for providing rigorous uncertainty quantification in machine learning since it can be easily applied as a post-processing step to already trained models. In this paper, we extend conformal prediction to the federated learning setting. The main challenge we face is data heterogeneity across the clients — this violates the fundamental tenet of exchangeability required for conformal prediction. We propose a weaker notion of partial exchangeability, better suited to the FL setting, and use it to develop the Federated Conformal Prediction (FCP) framework. We show FCP enjoys rigorous theoretical guarantees and excellent empirical performance on several computer vision and medical imaging datasets. Our results demonstrate a practical approach to incorporating meaningful uncertainty quantification in distributed and heterogeneous environments. We provide code used in our experiments https://github.com/clu5/federated-conformal.

**摘要:** 一致预测是提供机器学习中严格的不确定性定量的一个流行范式,因为它可以轻易地应用于已经训练的模型的后处理步骤。本论文中,我们将一致预测扩展到联邦学习环境。我们面临的主要挑战是客户间的数据异质性 — 这违反了对一致预测所需的交换性的基本原则。我们提出了一种较弱的部分交换性概念,更适合FL环境,并使用它来开发联邦一致预测(FCP)框架。

**[Paper URL](https://proceedings.mlr.press/v202/lu23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lu23i/lu23i.pdf)** 

# Mechanistic Mode Connectivity
**题目:** 机械模式连接

**作者:** Ekdeep Singh Lubana, Eric J Bigelow, Robert P. Dick, David Krueger, Hidenori Tanaka

**Abstract:** We study neural network loss landscapes through the lens of mode connectivity, the observation that minimizers of neural networks retrieved via training on a dataset are connected via simple paths of low loss. Specifically, we ask the following question: are minimizers that rely on different mechanisms for making their predictions connected via simple paths of low loss? We provide a definition of mechanistic similarity as shared invariances to input transformations and demonstrate that lack of linear connectivity between two models implies they use dissimilar mechanisms for making their predictions. Relevant to practice, this result helps us demonstrate that naive fine-tuning on a downstream dataset can fail to alter a model’s mechanisms, e.g., fine-tuning can fail to eliminate a model’s reliance on spurious attributes. Our analysis also motivates a method for targeted alteration of a model’s mechanisms, named connectivity-based fine-tuning (CBFT), which we analyze using several synthetic datasets for the task of reducing a model’s reliance on spurious attributes.

**摘要:** 我们通过模式连接的镜头研究神经网络损失景观,观察通过数据集训练获取的神经网络最小化者通过低损失的简单路径连接起来。具体地,我们提出以下问题: 利用不同的机制来预测的最小化者是否通过低损失的简单路径连接起来? 我们给出了输入变换的共享不变性的机械相似性定义,并证明两个模型之间缺乏线性连接意味着它们使用不同的机制来预测。我们的分析还动机了一种基于连接的微调(CBFT)的模型机制目标修改方法,我们用几个合成数据集分析该方法,以减少模型的依赖于假属性。

**[Paper URL](https://proceedings.mlr.press/v202/lubana23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lubana23a/lubana23a.pdf)** 

# A Unifying Framework to the Analysis of Interaction Methods using Synergy Functions
**题目:** 基于协同函数的交互方法分析的统一框架

**作者:** Daniel Lundstrom, Meisam Razaviyayn

**Abstract:** Deep learning has revolutionized many areas of machine learning, from computer vision to natural language processing, but these high-performance models are generally “black box." Explaining such models would improve transparency and trust in AI-powered decision making and is necessary for understanding other practical needs such as robustness and fairness. A popular means of enhancing model transparency is to quantify how individual inputs contribute to model outputs (called attributions) and the magnitude of interactions between groups of inputs. A growing number of these methods import concepts and results from game theory to produce attributions and interactions. This work presents a unifying framework for game-theory-inspired attribution and $k^\text{th}$-order interaction methods. We show that, given modest assumptions, a unique full account of interactions between features, called synergies, is possible in the continuous input setting. We identify how various methods are characterized by their policy of distributing synergies. We establish that gradient-based methods are characterized by their actions on monomials, a type of synergy function, and introduce unique gradient-based methods. We show that the combination of various criteria uniquely defines the attribution/interaction methods. Thus, the community needs to identify goals and contexts when developing and employing attribution and interaction methods.

**摘要:** 深入学习已经革命化了机器学习的许多领域,从计算机视觉到自然语言处理,但这些高性能模型一般是“黑箱”。解释这些模型将提高透明度和对AI驱动决策的信任,并且对于理解其他实际需要,如鲁棒性和公平性,是必要的。提高模型透明度的一个普遍的方法是量化个体输入如何对模型输出(称为属性)和输入群之间的相互作用的大小作出贡献。越来越多的这些方法从游戏理论中导入概念和结果来产生属性和相互作用。确定了不同方法的协同分配策略的特点,确定了基于梯度的方法的单调作用是协同作用的一种类型,并引入了独特的基于梯度的方法,说明了不同标准的结合对归因/相互作用方法具有独特的定义,因此,在开发和使用归因/相互作用方法时,社区需要确定目标和上下文。

**[Paper URL](https://proceedings.mlr.press/v202/lundstrom23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lundstrom23a/lundstrom23a.pdf)** 

# SegCLIP: Patch Aggregation with Learnable Centers for Open-Vocabulary Semantic Segmentation
**题目:** SegCLIP:基于开放口语语义分段的可学习中心的补丁集

**作者:** Huaishao Luo, Junwei Bao, Youzheng Wu, Xiaodong He, Tianrui Li

**Abstract:** Recently, the contrastive language-image pre-training, e.g., CLIP, has demonstrated promising results on various downstream tasks. The pre-trained model can capture enriched visual concepts for images by learning from a large scale of text-image data. However, transferring the learned visual knowledge to open-vocabulary semantic segmentation is still under-explored. In this paper, we propose a CLIP-based model named SegCLIP for the topic of open-vocabulary segmentation in an annotation-free manner. The SegCLIP achieves segmentation based on ViT and the main idea is to gather patches with learnable centers to semantic regions through training on text-image pairs. The gathering operation can dynamically capture the semantic groups, which can be used to generate the final segmentation results. We further propose a reconstruction loss on masked patches and a superpixel-based KL loss with pseudo-labels to enhance the visual representation. Experimental results show that our model achieves comparable or superior segmentation accuracy on the PASCAL VOC 2012 (+0.3% mIoU), PASCAL Context (+2.3% mIoU), and COCO (+2.2% mIoU) compared with baselines. We release the code at https://github.com/ArrowLuo/SegCLIP.

**摘要:** 近年来,对比性语言图像预训练,例如CLIP,在各个下游任务中表现出了良好的效果。预训练模型可以从大量文本图像数据中学习图像的丰富视觉概念。然而,将学习的视觉知识转移到开放语音语义分割仍未得到充分研究。本文提出了一种基于CLIP的模型,名为 SegCLIP,以无注释的方式讨论开放语音语义分割的主题。实验结果表明,我们的模型在与基线相比,在PASCAL VOC 2012 (+0.3% mIoU) 、 PASCAL Context (+2.3% mIoU) 和 COCO (+2.2% mIoU) 的 segmentation精度上达到可比或更高。

**[Paper URL](https://proceedings.mlr.press/v202/luo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/luo23a/luo23a.pdf)** 

# Image Restoration with Mean-Reverting Stochastic Differential Equations
**题目:** 平均逆随机差分方程的图像恢复

**作者:** Ziwei Luo, Fredrik K. Gustafsson, Zheng Zhao, Jens Sjölund, Thomas B. Schön

**Abstract:** This paper presents a stochastic differential equation (SDE) approach for general-purpose image restoration. The key construction consists in a mean-reverting SDE that transforms a high-quality image into a degraded counterpart as a mean state with fixed Gaussian noise. Then, by simulating the corresponding reverse-time SDE, we are able to restore the origin of the low-quality image without relying on any task-specific prior knowledge. Crucially, the proposed mean-reverting SDE has a closed-form solution, allowing us to compute the ground truth time-dependent score and learn it with a neural network. Moreover, we propose a maximum likelihood objective to learn an optimal reverse trajectory that stabilizes the training and improves the restoration results. The experiments show that our proposed method achieves highly competitive performance in quantitative comparisons on image deraining, deblurring, and denoising, setting a new state-of-the-art on two deraining datasets. Finally, the general applicability of our approach is further demonstrated via qualitative results on image super-resolution, inpainting, and dehazing. Code is available at https://github.com/Algolzw/image-restoration-sde.

**摘要:** 本文提出了一种随机微分方程(SDE)方法,用于一般目的图像恢复。关键构造是将高质量图像转化为高质量图像,作为高斯噪声固定的平均状态。然后,通过仿真相应的反时SDE,我们能够恢复低质量图像的源头,而不依赖任何特定任务的预先知识。关键是,拟议的反时SDE具有封闭式解决方案,允许我们计算地面真实时间依赖性分数,并用神经网络学习。此外,我们提出了学习最佳反轨迹的目标,稳定训练并提高恢复结果。实验表明,我们拟议的方法在图像提取、 deblurring和 denoising的定量比较中具有很高的竞争力。最后,通过图像超分辨率、油漆和脱hazing的质量结果进一步证明了我们方法的通用性。代码可于 https://github.com/Algolzw/image-restoration-sde。

**[Paper URL](https://proceedings.mlr.press/v202/luo23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/luo23b/luo23b.pdf)** 

# Dimensionality Reduction for General KDE Mode Finding
**题目:** 一般KDE模式查找的尺寸减小

**作者:** Xinyu Luo, Christopher Musco, Cas Widdershoven

**Abstract:** Finding the mode of a high dimensional probability distribution $\mathcal{D}$ is a fundamental algorithmic problem in statistics and data analysis. There has been particular interest in efficient methods for solving the problem when $\mathcal{D}$ is represented as a mixture model or kernel density estimate, although few algorithmic results with worst-case approximation and runtime guarantees are known. In this work, we significantly generalize a result of (LeeLiMusco:2021) on mode approximation for Gaussian mixture models. We develop randomized dimensionality reduction methods for mixtures involving a broader class of kernels, including the popular logistic, sigmoid, and generalized Gaussian kernels. As in Lee et al.’s work, our dimensionality reduction results yield quasi-polynomial algorithms for mode finding with multiplicative accuracy $(1-\epsilon)$ for any $\epsilon > 0$. Moreover, when combined with gradient descent, they yield efficient practical heuristics for the problem. In addition to our positive results, we prove a hardness result for box kernels, showing that there is no polynomial time algorithm for finding the mode of a kernel density estimate, unless $\mathit{P} = \mathit{NP}$. Obtaining similar hardness results for kernels used in practice (like Gaussian or logistic kernels) is an interesting future direction.

**摘要:** 寻找高维概率分布模式$\mathcal{D}$是统计和数据分析中一个基本的算法问题。当$\mathcal{D}$被作为混合模型或核密度估计表示时,对于解决这个问题的有效方法有特别的兴趣,尽管已知很少有最坏情况下的近似和运行时间保证的算法结果。在这个工作中,我们对高斯混合模型的模式近似(LeeLiMusco:2021)的结果进行了显着的一般化。我们开发了涉及更广泛的核类混合物的随机化尺寸减少方法,包括流行的物流、 sigmoid和广义化高斯核。除了我们的积极结果外,我们证明了箱子核的硬度结果,证明没有多项式时间算法来找到核密度估计模式,除非$\mathit{P} = \mathit{NP}$。在实际应用中(如高斯或物流核)的核的相似硬度结果是有趣的未来方向。

**[Paper URL](https://proceedings.mlr.press/v202/luo23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/luo23c/luo23c.pdf)** 

# Iterative Approximate Cross-Validation
**题目:** 迭代近似交叉验证

**作者:** Yuetian Luo, Zhimei Ren, Rina Barber

**Abstract:** Cross-validation (CV) is one of the most popular tools for assessing and selecting predictive models. However, standard CV suffers from high computational cost when the number of folds is large. Recently, under the empirical risk minimization (ERM) framework, a line of works proposed efficient methods to approximate CV based on the solution of the ERM problem trained on the full dataset. However, in large-scale problems, it can be hard to obtain the exact solution of the ERM problem, either due to limited computational resources or due to early stopping as a way of preventing overfitting. In this paper, we propose a new paradigm to efficiently approximate CV when the ERM problem is solved via an iterative first-order algorithm, without running until convergence. Our new method extends existing guarantees for CV approximation to hold along the whole trajectory of the algorithm, including at convergence, thus generalizing existing CV approximation methods. Finally, we illustrate the accuracy and computational efficiency of our method through a range of empirical studies.

**摘要:** 交叉验证是评价和选择预测模型的最常用的工具之一,然而,标准CV在折叠数大时会承受很高的计算成本。最近,在经验风险最小化(ERM)框架下,一连串工作提出了基于全数据集训练的ERM问题解决方案的有效方法来近似CV。然而,在大规模问题中,由于有限的计算资源或早期停止以防止过度匹配,很难得到ERM问题的准确解决。最后通过一系列实证研究,说明了该方法的准确性和计算效率。

**[Paper URL](https://proceedings.mlr.press/v202/luo23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/luo23d/luo23d.pdf)** 

# A Closer Look at Few-shot Classification Again
**题目:** 再次对少数镜头分类进行更深入的分析

**作者:** Xu Luo, Hao Wu, Ji Zhang, Lianli Gao, Jing Xu, Jingkuan Song

**Abstract:** Few-shot classification consists of a training phase where a model is learned on a relatively large dataset and an adaptation phase where the learned model is adapted to previously-unseen tasks with limited labeled samples. In this paper, we empirically prove that the training algorithm and the adaptation algorithm can be completely disentangled, which allows algorithm analysis and design to be done individually for each phase. Our meta-analysis for each phase reveals several interesting insights that may help better understand key aspects of few-shot classification and connections with other fields such as visual representation learning and transfer learning. We hope the insights and research challenges revealed in this paper can inspire future work in related directions. Code and pre-trained models (in PyTorch) are available at https://github.com/Frankluox/CloserLookAgainFewShot.

**摘要:** Few-shot分类包括一个训练阶段,其中一个模型在相对大的数据集上学习,一个适应阶段,其中学习的模型被适应于先前未见的任务,带有有限的标记样品。本文,我们以实证证明训练算法和适应算法可以完全分割,使得算法分析和设计可以为每个阶段单独进行。

**[Paper URL](https://proceedings.mlr.press/v202/luo23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/luo23e/luo23e.pdf)** 

# HOPE: High-order Graph ODE For Modeling Interacting Dynamics
**题目:** 目的:高阶图形ODE用于建模交互动力学

**作者:** Xiao Luo, Jingyang Yuan, Zijie Huang, Huiyu Jiang, Yifang Qin, Wei Ju, Ming Zhang, Yizhou Sun

**Abstract:** Leading graph ordinary differential equation (ODE) models have offered generalized strategies to model interacting multi-agent dynamical systems in a data-driven approach. They typically consist of a temporal graph encoder to get the initial states and a neural ODE-based generative model to model the evolution of dynamical systems. However, existing methods have severe deficiencies in capacity and efficiency due to the failure to model high-order correlations in long-term temporal trends. To tackle this, in this paper, we propose a novel model named High-order graph ODE (HOPE) for learning from dynamic interaction data, which can be naturally represented as a graph. It first adopts a twin graph encoder to initialize the latent state representations of nodes and edges, which consists of two branches to capture spatio-temporal correlations in complementary manners. More importantly, our HOPE utilizes a second-order graph ODE function which models the dynamics for both nodes and edges in the latent space respectively, which enables efficient learning of long-term dependencies from complex dynamical systems. Experiment results on a variety of datasets demonstrate both the effectiveness and efficiency of our proposed method.

**摘要:** 主要的图 ordinary differential equation (ODE)模型提供了一种基于数据的模型策略,以模拟相互作用的多代理动态系统。它们通常由一个时间图编码器来获取初始状态和一个基于ODE的神经元生成模型来模拟动态系统的进化。然而,现有的方法在能力和效率方面存在严重缺陷,因为无法在长期时间趋势中模拟高阶相关关系。为了解决这一问题,我们提出了一种名为高阶图ODE(HOPE)的新模型,用于从动态交互数据中学习,该模型可以自然地作为图形表示。更重要的是,我们的HOPE利用了一种二阶图ODE函数,分别建模了 latent空间中的节点和边缘的动力学,从而能够有效地学习复杂动态系统长期的依赖性。

**[Paper URL](https://proceedings.mlr.press/v202/luo23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/luo23f/luo23f.pdf)** 

# Stabilizing GANs’ Training with Brownian Motion Controller
**题目:** 通过布朗运动控制器稳定GAN的训练

**作者:** Tianjiao Luo, Ziyu Zhu, Jianfei Chen, Jun Zhu

**Abstract:** The training process of generative adversarial networks (GANs) is unstable and does not converge globally. In this paper, we examine the stability of GANs from the perspective of control theory and propose a universal higher-order noise-based controller called Brownian Motion Controller (BMC). Starting with the prototypical case of Dirac-GANs, we design a BMC to retrieve precisely the same but reachable optimal equilibrium. We theoretically prove that the training process of DiracGANs-BMC is globally exponential stable and derive bounds on the rate of convergence. Then we extend our BMC to normal GANs and provide implementation instructions on GANs-BMC. Our experiments show that our GANs-BMC effectively stabilizes GANs’ training under StyleGANv2-ada frameworks with a faster rate of convergence, a smaller range of oscillation, and better performance in terms of FID score.

**摘要:** 生成敌对网络(GAN)的训练过程不稳定,并不能在全球一致。本文从控制理论的角度对GAN的稳定性进行了研究,并提出了一种基于高阶噪声的通用控制器,称为布朗运动控制器(BMC)。从Dirack-GAN的原型案例开始,我们设计了一种BMC,以取得精确的相同,但可达到的最优平衡。我们从理论上证明DirackGANs-BMC的训练过程是全球指数稳定,并推导了收敛速度上的边界。

**[Paper URL](https://proceedings.mlr.press/v202/luo23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/luo23g/luo23g.pdf)** 

# OCD: Learning to Overfit with Conditional Diffusion Models
**题目:** OCD:学习适应条件扩散模型

**作者:** Shahar Lutati, Lior Wolf

**Abstract:** We present a dynamic model in which the weights are conditioned on an input sample x and are learned to match those that would be obtained by finetuning a base model on x and its label y. This mapping between an input sample and network weights is approximated by a denoising diffusion model. The diffusion model we employ focuses on modifying a single layer of the base model and is conditioned on the input, activations, and output of this layer. Since the diffusion model is stochastic in nature, multiple initializations generate different networks, forming an ensemble, which leads to further improvements. Our experiments demonstrate the wide applicability of the method for image classification, 3D reconstruction, tabular data, speech separation, and natural language processing.

**摘要:** 本文提出了一种动态模型,在该模型中对输入样本x的权重进行调节,并学习通过对x及其标签y的基模型进行微调来匹配。该模型将输入样本和网络权重的映射近似为分化扩散模型。我们所采用的扩散模型集中于修改基模型的一个单层,并根据该层的输入、激活和输出进行调节。由于扩散模型的性质是随机性,多个初始化生成不同的网络,形成一个组合,从而进一步改进。

**[Paper URL](https://proceedings.mlr.press/v202/lutati23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lutati23a/lutati23a.pdf)** 

# DiscoBAX: Discovery of optimal intervention sets in genomic experiment design
**题目:** DiscoBAX:基因组实验设计中最佳干预集的发现

**作者:** Clare Lyle, Arash Mehrjou, Pascal Notin, Andrew Jesson, Stefan Bauer, Yarin Gal, Patrick Schwab

**Abstract:** The discovery of therapeutics to treat genetically-driven pathologies relies on identifying genes involved in the underlying disease mechanism. Existing approaches search over the billions of potential interventions to maximize the expected influence on the target phenotype. However, to reduce the risk of failure in future stages of trials, practical experiment design aims to find a set of interventions that maximally change a target phenotype via diverse mechanisms. We propose DiscoBAX - a sample-efficient method for maximizing the rate of significant discoveries per experiment while simultaneously probing for a wide range of diverse mechanisms during a genomic experiment campaign. We provide theoretical guarantees of optimality under standard assumptions, and conduct a comprehensive experimental evaluation covering both synthetic as well as real-world experimental design tasks. DiscoBAX outperforms existing state-of-the-art methods for experimental design, selecting effective and diverse perturbations in biological systems.

**摘要:** 基因驱动病理的治疗方法的发现依赖于在病理机制中所涉及的基因的识别。现有的方法搜索了数十亿个潜在的干预措施,以最大化对目标模式的预期影响。然而,为了减少今后的试验阶段的失败风险,实际实验设计的目标是通过多种机制找到能够最大改变目标模式的干预措施。我们建议采用样本效率的方法,在基因组实验活动中同时探测各种不同的机制,以最大化每个实验中重大发现的速度。我们根据标准假设提供最佳的理论保证,并进行综合实验评价,包括合成和实际实验设计任务。DiscoBAX超越现有的最先进的实验设计方法,选择生物系统中的有效和多样性扰动。

**[Paper URL](https://proceedings.mlr.press/v202/lyle23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lyle23a/lyle23a.pdf)** 

# Understanding Plasticity in Neural Networks
**题目:** 神经网络的塑性理解

**作者:** Clare Lyle, Zeyu Zheng, Evgenii Nikishin, Bernardo Avila Pires, Razvan Pascanu, Will Dabney

**Abstract:** Plasticity, the ability of a neural network to quickly change its predictions in response to new information, is essential for the adaptability and robustness of deep reinforcement learning systems. Deep neural networks are known to lose plasticity over the course of training even in relatively simple learning problems, but the mechanisms driving this phenomenon are still poorly understood. This paper conducts a systematic empirical analysis into plasticity loss, with the goal of understanding the phenomenon mechanistically in order to guide the future development of targeted solutions. We find that loss of plasticity is deeply connected to changes in the curvature of the loss landscape, but that it often occurs in the absence of saturated units. Based on this insight, we identify a number of parameterization and optimization design choices which enable networks to better preserve plasticity over the course of training. We validate the utility of these findings on larger-scale RL benchmarks in the Arcade Learning Environment.

**摘要:** 神经网络的可塑性,即神经网络在响应新信息时快速改变其预测的能力,对于深度增强学习系统适应性和鲁棒性是至关重要的。深层神经网络在训练过程中会失去可塑性,即使在相对简单的学习问题上,但驱动这一现象的机制仍未得到充分理解。本文对可塑性损失进行了系统实证分析,目的在于机械化地理解这一现象,以指导目标解决方案的未来发展。我们发现可塑性损失与损失景观曲线的变化密切相关,但往往在缺乏饱和单位的情况下发生。我们验证了这些发现在 Arcade Learning Environment 中具有较大规模的RL标准的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/lyle23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lyle23b/lyle23b.pdf)** 

# Bandits with Knapsacks: Advice on Time-Varying Demands
**题目:** 带手提包的强盗:关于时间变化的需求的建议

**作者:** Lixing Lyu, Wang Chi Cheung

**Abstract:** We consider a non-stationary Bandits with Knapsack problem. The outcome distribution at each time is scaled by a non-stationary quantity that signifies changing demand volumes. Instead of studying settings with limited non-stationarity, we investigate how online predictions on the total demand volume $Q$ allows us to improve our performance guarantees. We show that, without any prediction, any online algorithm incurs a linear-in-$T$ regret. In contrast, with online predictions on $Q$, we propose an online algorithm that judiciously incorporates the predictions, and achieve regret bounds that depends on the accuracy of the predictions. These bounds are shown to be tight in settings when prediction accuracy improves across time. Our theoretical results are corroborated by our numerical findings.

**摘要:** 我们考虑了一个与Knapsack有关的非静态Bandits问题。每次的结果分布都是以非静态数量来衡量,这表明需求量的变化。我们没有研究与非静态性有限的设置,而是研究如何在总需求量$Q$上在线预测能够改善我们的性能保证。我们显示,没有任何预测,任何在线算法都会产生线性$T$的遗憾。与此相反,与$Q$上的在线预测相比,我们提出了一种合理地结合预测的在线算法,并在预测的准确性上达成遗憾的边界。

**[Paper URL](https://proceedings.mlr.press/v202/lyu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lyu23a/lyu23a.pdf)** 

# Pairwise Ranking Losses of Click-Through Rates Prediction for Welfare Maximization in Ad Auctions
**题目:** 按点击率的分级排名损失预测在广告拍卖中提高福利水平

**作者:** Boxiang Lyu, Zhe Feng, Zachary Robertson, Sanmi Koyejo

**Abstract:** We study the design of loss functions for click-through rates (CTR) to optimize (social) welfare in advertising auctions. Existing works either only focus on CTR predictions without consideration of business objectives (e.g., welfare) in auctions or assume that the distribution over the participants’ expected cost-per-impression (eCPM) is known a priori, then use various additional assumptions on the parametric form of the distribution to derive loss functions for predicting CTRs. In this work, we bring back the welfare objectives of ad auctions into CTR predictions and propose a novel weighted rankloss to train the CTR model. Compared to existing literature, our approach provides a provable guarantee on welfare but without assumptions on the eCPMs’ distribution while also avoiding the intractability of naively applying existing learning-to-rank methods. Further, we propose a theoretically justifiable technique for calibrating the losses using labels generated from a teacher network, only assuming that the teacher network has bounded $\ell_2$ generalization error. Finally, we demonstrate the advantages of the proposed loss on synthetic and real-world data.

**摘要:** 在广告拍卖中,我们研究了点击率(CTR)损失函数的设计,以优化(社会)福利。现有的工作 either focus on CTR predictions without consideration of business objectives (e.g., welfare) in auctions or assume that the distribution over the participants’ expected cost-per-impression (eCPM) is known a priori, then use various additional assumptions on the parametric form of the distribution to derive loss functions for predicting CTRs。最后,我们提出了一种从教师网络生成的标签来校准损失的理论合理方法,仅假设教师网络有界定$\ell_2$一般化误差。

**[Paper URL](https://proceedings.mlr.press/v202/lyu23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lyu23b/lyu23b.pdf)** 

# Which Tricks are Important for Learning to Rank?
**题目:** 哪些技巧对于提高等级很重要?

**作者:** Ivan Lyzhin, Aleksei Ustimenko, Andrey Gulin, Liudmila Prokhorenkova

**Abstract:** Nowadays, state-of-the-art learning-to-rank methods are based on gradient-boosted decision trees (GBDT). The most well-known algorithm is LambdaMART which was proposed more than a decade ago. Recently, several other GBDT-based ranking algorithms were proposed. In this paper, we thoroughly analyze these methods in a unified setup. In particular, we address the following questions. Is direct optimization of a smoothed ranking loss preferable over optimizing a convex surrogate? How to properly construct and smooth surrogate ranking losses? To address these questions, we compare LambdaMART with YetiRank and StochasticRank methods and their modifications. We also propose a simple improvement of the YetiRank approach that allows for optimizing specific ranking loss functions. As a result, we gain insights into learning-to-rank techniques and obtain a new state-of-the-art algorithm.

**摘要:** 当前,最先进的学习到排序方法是基于梯度缓冲决策树(GBDT)的,最著名的算法是十年前提出的LambdaMART。最近,提出了其他基于GBDT的排序算法。在本文中,我们深入分析了这些方法在统一的设置中。我们特别针对以下问题。平滑排序损失的直接优化是否比优化凸代理更有利?如何正确构造和平滑代理排序损失?为了解决这些问题,我们比较了LambdaMART与YetiRank和StochasticRank方法及其修改。我们还提出了YetiRank方法的简单改进,允许优化特定排序损失函数。

**[Paper URL](https://proceedings.mlr.press/v202/lyzhin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/lyzhin23a/lyzhin23a.pdf)** 

# Learning Neural Constitutive Laws from Motion Observations for Generalizable PDE Dynamics
**题目:** 从运动观测中学习神经构成规律,用于通用的PDE动力学

**作者:** Pingchuan Ma, Peter Yichen Chen, Bolei Deng, Joshua B. Tenenbaum, Tao Du, Chuang Gan, Wojciech Matusik

**Abstract:** We propose a hybrid neural network (NN) and PDE approach for learning generalizable PDE dynamics from motion observations. Many NN approaches learn an end-to-end model that implicitly models both the governing PDE and constitutive models (or material models). Without explicit PDE knowledge, these approaches cannot guarantee physical correctness and have limited generalizability. We argue that the governing PDEs are often well-known and should be explicitly enforced rather than learned. Instead, constitutive models are particularly suitable for learning due to their data-fitting nature. To this end, we introduce a new framework termed "Neural Constitutive Laws" (NCLaw), which utilizes a network architecture that strictly guarantees standard constitutive priors, including rotation equivariance and undeformed state equilibrium. We embed this network inside a differentiable simulation and train the model by minimizing a loss function based on the difference between the simulation and the motion observation. We validate NCLaw on various large-deformation dynamical systems, ranging from solids to fluids. After training on a single motion trajectory, our method generalizes to new geometries, initial/boundary conditions, temporal ranges, and even multi-physics systems. On these extremely out-of-distribution generalization tasks, NCLaw is orders-of-magnitude more accurate than previous NN approaches. Real-world experiments demonstrate our method’s ability to learn constitutive laws from videos.

**摘要:** 我们提出了一种混合神经网络(NN)和PDE方法来从运动观察中学习可推广的PDE动力学。许多NN方法学习一个 implicitly modeling both the governing PDE and constitutive models (or material models). Without explicit PDE knowledge, these approaches cannot guarantee physical correctness and have limited generalizability. We argue that the governing PDEs are often well-known and should be explicitly enforced rather than learned. Instead, constitutive models are particularly suitable for learning due to their data-fitting nature. To this end, we introduce a new framework called "Neural Constitutive Laws" (NCLaw), which utilizes a network architecture that strictly guarantees standard constitutive priors, including rotation equivariance and undeformed state equilibrium.我们将该网络嵌入在可微分模拟中,并根据模拟和运动观察之间的差异,通过最小化损失函数来训练模型。我们对各种大型变形动力学系统,从固体到流体,验证了NCLaw。在单一运动轨迹的训练后,我们的方法将推广到新的几何、初始/边界条件、时间范围,甚至多维物理系统。

**[Paper URL](https://proceedings.mlr.press/v202/ma23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ma23a/ma23a.pdf)** 

# LIV: Language-Image Representations and Rewards for Robotic Control
**题目:** LIV:语言-图像表现和机器人控制奖励

**作者:** Yecheng Jason Ma, Vikash Kumar, Amy Zhang, Osbert Bastani, Dinesh Jayaraman

**Abstract:** We present Language-Image Value learning (LIV), a unified objective for vision-language representation and reward learning from action-free videos with text annotations. Exploiting a novel connection between dual reinforcement learning and mutual information contrastive learning, the LIV objective trains a multi-modal representation that implicitly encodes a universal value function for tasks specified as language or image goals. We use LIV to pre-train the first control-centric vision-language representation from large human video datasets such as EpicKitchen. Given only a language or image goal, the pre-trained LIV model can assign dense rewards to each frame in videos of unseen robots or humans attempting that task in unseen environments. Further, when some target domain-specific data is available, the same objective can be used to fine-tune and improve LIV and even other pre-trained representations for robotic control and reward specification in that domain. In our experiments on several simulated and real-world robot environments, LIV models consistently outperform the best prior input state representations for imitation learning, as well as reward specification methods for policy synthesis. Our results validate the advantages of joint vision-language representation and reward learning within the unified, compact LIV framework.

**摘要:** 语言-图像价值学习(英语:Language-Image Value learning,简称LIV)是一种基于文本注释的视觉语言表示和奖励学习的统一目标。利用双重增强学习与相互信息对比学习之间的新联系,LIV目标训练了一个多模态的表示, implicitly encodes a universal value function for tasks specified as language or image goals。我们使用LIV来预训练第一组大型人类视频数据集的控制中心视觉语言表示,例如EpicKitchen。仅给出一个语言或图像目标,预训练的LIV模型可以给视频中未见机器人或人类在未见环境中尝试这项任务的每个帧分配密集奖励。在多个模拟和现实机器人环境的实验中,LIV模型始终超过了仿真学习的最佳输入状态表示,以及政策合成的奖励规范方法。我们的结果验证了联合视觉语言表示和奖励学习在统一、紧凑的LIV框架内的优势。

**[Paper URL](https://proceedings.mlr.press/v202/ma23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ma23b/ma23b.pdf)** 

# Graph Inductive Biases in Transformers without Message Passing
**题目:** 无消息传递的变换器图诱导偏差

**作者:** Liheng Ma, Chen Lin, Derek Lim, Adriana Romero-Soriano, Puneet K. Dokania, Mark Coates, Philip Torr, Ser-Nam Lim

**Abstract:** Transformers for graph data are increasingly widely studied and successful in numerous learning tasks. Graph inductive biases are crucial for Graph Transformers, and previous works incorporate them using message-passing modules and/or positional encodings. However, Graph Transformers that use message-passing inherit known issues of message-passing, and differ significantly from Transformers used in other domains, thus making transfer of research advances more difficult. On the other hand, Graph Transformers without message-passing often perform poorly on smaller datasets, where inductive biases are more crucial. To bridge this gap, we propose the Graph Inductive bias Transformer (GRIT) — a new Graph Transformer that incorporates graph inductive biases without using message passing. GRIT is based on several architectural changes that are each theoretically and empirically justified, including: learned relative positional encodings initialized with random walk probabilities, a flexible attention mechanism that updates node and node-pair representations, and injection of degree information in each layer. We prove that GRIT is expressive — it can express shortest path distances and various graph propagation matrices. GRIT achieves state-of-the-art empirical performance across a variety of graph datasets, thus showing the power that Graph Transformers without message-passing can deliver.

**摘要:** 图形数据的变换器越来越广泛地研究并在众多学习任务中取得成功。图形诱导偏差对于图形变换器至关重要,而以前的工作都采用了消息传递模块和/或位置编码。然而,使用消息传递的图形变换器继承了消息传递的已知问题,与其他领域使用的变换器有很大区别,从而使得研究进展的转移变得更加困难。GRIT基于几个理论和经验上的建筑变化,包括:基于随机步行概率的学习相对定位编码,更新节点和节点对映射的灵活注意机制,以及在每个层中注入学位信息。我们证明GRIT具有表达性 — 它可以表达最短的路径距离和各种图形传播矩阵。GRIT在各种图形数据集中实现了最先进的经验性能,从而显示了 Graph Transformers 没有消息传递的能提供的力量。

**[Paper URL](https://proceedings.mlr.press/v202/ma23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ma23c/ma23c.pdf)** 

# Learning Signed Distance Functions from Noisy 3D Point Clouds via Noise to Noise Mapping
**题目:** 从噪声到噪声映射的噪声3D点云学符号距离函数

**作者:** Baorui Ma, Yu-Shen Liu, Zhizhong Han

**Abstract:** Learning signed distance functions (SDFs) from 3D point clouds is an important task in 3D computer vision. However, without ground truth signed distances, point normals or clean point clouds, current methods still struggle from learning SDFs from noisy point clouds. To overcome this challenge, we propose to learn SDFs via a noise to noise mapping, which does not require any clean point cloud or ground truth supervision for training. Our novelty lies in the noise to noise mapping which can infer a highly accurate SDF of a single object or scene from its multiple or even single noisy point cloud observations. Our novel learning manner is supported by modern Lidar systems which capture multiple noisy observations per second. We achieve this by a novel loss which enables statistical reasoning on point clouds and maintains geometric consistency although point clouds are irregular, unordered and have no point correspondence among noisy observations. Our evaluation under the widely used benchmarks demonstrates our superiority over the state-of-the-art methods in surface reconstruction, point cloud denoising and upsampling. Our code, data, and pre-trained models are available at https://github.com/mabaorui/Noise2NoiseMapping/ .

**摘要:** 从3D点云中学习符号距离函数(SDFs)是3D计算机视觉中的一个重要任务。然而,没有地面真实符号距离、点正常或清洁点云,当前的方法仍无法从噪声点云中学习SDFs。为了克服这一挑战,我们建议通过噪声到噪声映射学习SDFs,这不需要任何清洁点云或地面真实监督来训练。我们的新颖之处在于噪声到噪声映射,它可以推导出一个单一对象或场景的高精度SDF从其多个或甚至单一的噪声点云观测中。在广泛使用的基准下,我们的评估显示了我们在表面重建、点云调制和采样方面的最先进的方法之上的优越性。我们的代码、数据和预训练模型可以在 https://github.com/mabaorui/Noise2NoiseMapping/ 上找到。

**[Paper URL](https://proceedings.mlr.press/v202/ma23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ma23d/ma23d.pdf)** 

# Learning Intuitive Policies Using Action Features
**题目:** 使用动作特征学习直观政策

**作者:** Mingwei Ma, Jizhou Liu, Samuel Sokota, Max Kleiman-Weiner, Jakob Nicolaus Foerster

**Abstract:** An unaddressed challenge in multi-agent coordination is to enable AI agents to exploit the semantic relationships between the features of actions and the features of observations. Humans take advantage of these relationships in highly intuitive ways. For instance, in the absence of a shared language, we might point to the object we desire or hold up our fingers to indicate how many objects we want. To address this challenge, we investigate the effect of network architecture on the propensity of learning algorithms to exploit these semantic relationships. Across a procedurally generated coordination task, we find that attention-based architectures that jointly process a featurized representation of observations and actions have a better inductive bias for learning intuitive policies. Through fine-grained evaluation and scenario analysis, we show that the resulting policies are human-interpretable. Moreover, such agents coordinate with people without training on any human data.

**摘要:** 在多代理协调中,一个未解决的挑战是使AI代理利用行为特征与观察特征之间的语义关系。人类以高度直观的方式利用这些关系。例如,在没有共享语言的情况下,我们可能指向我们想要的对象或举起手指来指示我们想要多少对象。为了解决这一挑战,我们研究网络架构对学习算法利用这些语义关系的倾向的影响。在程序生成的协调任务中,我们发现,以注意力为基础的架构共同处理观察和行动的典型表现具有较好的直观政策学习的诱导性偏见。通过细微的评价和场景分析,我们显示结果的政策是人可解释的。

**[Paper URL](https://proceedings.mlr.press/v202/ma23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ma23e/ma23e.pdf)** 

# Over-parametrization via Lifting for Low-rank Matrix Sensing: Conversion of Spurious Solutions to Strict Saddle Points
**题目:** 低级矩阵感知的升降过分参数化:变换痕量解决方案为严格的鞍点

**作者:** Ziye Ma, Igor Molybog, Javad Lavaei, Somayeh Sojoudi

**Abstract:** This paper studies the role of over-parametrization in solving non-convex optimization problems. The focus is on the important class of low-rank matrix sensing, where we propose an infinite hierarchy of non-convex problems via the lifting technique and the Burer-Monteiro factorization. This contrasts with the existing over-parametrization technique where the search rank is limited by the dimension of the matrix and it does not allow a rich over-parametrization of an arbitrary degree. We show that although the spurious solutions of the problem remain stationary points through the hierarchy, they will be transformed into strict saddle points (under some technical conditions) and can be escaped via local search methods. This is the first result in the literature showing that over-parametrization creates a negative curvature for escaping spurious solutions. We also derive a bound on how much over-parametrization is requited to enable the elimination of spurious solutions.

**摘要:** 本文研究了超参数化在解决非凸优化问题中的作用。重点是低级矩阵感知的重要类别,提出了通过提升技术和Burer-Monteiro因子化对非凸问题的无限层次结构,与现有的超参数化技术有对比,其中搜索等级由矩阵的维度限制,不允许任意程度的丰富超参数化。

**[Paper URL](https://proceedings.mlr.press/v202/ma23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ma23f/ma23f.pdf)** 

# Buying Information for Stochastic Optimization
**题目:** 随机优化采购信息

**作者:** Mingchen Ma, Christos Tzamos

**Abstract:** Stochastic optimization is one of the central problems in Machine Learning and Theoretical Computer Science. In the standard model, the algorithm is given a fixed distribution known in advance. In practice though, one may acquire at a cost extra information to make better decisions. In this paper, we study how to buy information for stochastic optimization and formulate this question as an online learning problem. Assuming the learner has an oracle for the original optimization problem, we design a $2$-competitive deterministic algorithm and a $e/(e-1)$-competitive randomized algorithm for buying information. We show that this ratio is tight as the problem is equivalent to a robust generalization of the ski-rental problem, which we call super-martingale stopping. We also consider an adaptive setting where the learner can choose to buy information after taking some actions for the underlying optimization problem. We focus on the classic optimization problem, Min-Sum Set Cover, where the goal is to quickly find an action that covers a given request drawn from a known distribution. We provide an $8$-competitive algorithm running in polynomial time that chooses actions and decides when to buy information about the underlying request.

**摘要:** 随机优化是机器学习和理论计算机科学中的核心问题之一。在标准模型中,算法给出了一个预先知道的固定分布。然而,在实践中,人们可以以额外的成本获取信息来做出更好的决策。本文研究了随机优化的信息购买方法,并将这一问题定为在线学习问题。假设学习者为原始优化问题有口号,我们设计了一个$2的竞争性确定性算法和一个$e/(e-1)的竞争性随机化算法来购买信息。我们专注于经典优化问题,Min-Sum Set Cover,目标是快速找到从一个已知的分布中提取的特定请求的行动。我们提供一个在多项式时间运行的$8$竞争算法,它选择行动并决定什么时候购买有关潜在请求的信息。

**[Paper URL](https://proceedings.mlr.press/v202/ma23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ma23g/ma23g.pdf)** 

# Generated Graph Detection
**题目:** 生成图形检测

**作者:** Yihan Ma, Zhikun Zhang, Ning Yu, Xinlei He, Michael Backes, Yun Shen, Yang Zhang

**Abstract:** Graph generative models become increasingly effective for data distribution approximation and data augmentation. While they have aroused public concerns about their malicious misuses or misinformation broadcasts, just as what Deepfake visual and auditory media has been delivering to society. Hence it is essential to regulate the prevalence of generated graphs. To tackle this problem, we pioneer the formulation of the generated graph detection problem to distinguish generated graphs from real ones. We propose the first framework to systematically investigate a set of sophisticated models and their performance in four classification scenarios. Each scenario switches between seen and unseen datasets/generators during testing to get closer to real-world settings and progressively challenge the classifiers. Extensive experiments evidence that all the models are qualified for generated graph detection, with specific models having advantages in specific scenarios. Resulting from the validated generality and oblivion of the classifiers to unseen datasets/generators, we draw a safe conclusion that our solution can sustain for a decent while to curb generated graph misuses.

**摘要:** 图形生成模型对于数据分布的近似和数据增加变得越来越有效。虽然它们已经引起公众对它们的恶意滥用或误导信息广播的关注,正如 Deepfake视觉和听觉媒体向社会提供的信息一样。因此,调节生成图形的普及至关重要。为了解决这一问题,我们率先制定生成图形检测问题,以区分生成图形与实际图形。我们提出了第一个框架,以系统地研究一套复杂的图形和它们在四个分类场景中的表现。通过验证的一般性和把分类器遗忘在未见的数据集/生成器上,我们得出一个安全结论:我们的解决方案能够维持相当长的时间来抑制生成图的误用。

**[Paper URL](https://proceedings.mlr.press/v202/ma23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ma23h/ma23h.pdf)** 

# Calibrating Multimodal Learning
**题目:** 校正多模学习

**作者:** Huan Ma, Qingyang Zhang, Changqing Zhang, Bingzhe Wu, Huazhu Fu, Joey Tianyi Zhou, Qinghua Hu

**Abstract:** Multimodal machine learning has achieved remarkable progress in a wide range of scenarios. However, the reliability of multimodal learning remains largely unexplored. In this paper, through extensive empirical studies, we identify current multimodal classification methods suffer from unreliable predictive confidence that tend to rely on partial modalities when estimating confidence. Specifically, we find that the confidence estimated by current models could even increase when some modalities are corrupted. To address the issue, we introduce an intuitive principle for multimodal learning, i.e., the confidence should not increase when one modality is removed. Accordingly, we propose a novel regularization technique, i.e., Calibrating Multimodal Learning (CML) regularization, to calibrate the predictive confidence of previous methods. This technique could be flexibly equipped by existing models and improve the performance in terms of confidence calibration, classification accuracy, and model robustness.

**摘要:** 本文通过广泛的实证研究,指出当前的多型分类方法在估计信任时往往依赖部分模式的预测性信任。具体而言,我们发现当前模型估计的信任甚至可能在某些模式被损坏时增加。为了解决这个问题,我们引入了多型学习的直观原则,即当一个模式被删除时信任不应增加。该技术可由现有模型灵活装配,提高可靠性校正、分类精度和模型鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/ma23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ma23i/ma23i.pdf)** 

# AutoCoreset: An Automatic Practical Coreset Construction Framework
**题目:** AutoCoreset:一种自动实用核心集建构框架

**作者:** Alaa Maalouf, Murad Tukan, Vladimir Braverman, Daniela Rus

**Abstract:** A coreset is a small weighted subset of an input set that approximates its loss function, for a given set of queries. Coresets became prevalent in machine learning as they have shown to be advantageous for many applications. Unfortunately, coresets are constructed in a problem-dependent manner, where for each problem, a new coreset construction algorithm is suggested, taking years to prove its correctness. Even the generic frameworks require additional (problem-dependent) computations or proofs to be done by the user. Besides, many problems do not have (provable) small coresets, limiting their applicability. To this end, we suggest an automatic practical framework for constructing coresets, which requires (only) the input data and the desired cost function from the user, without the need for any other task-related computation to be done by the user. To do so, we reduce the problem of approximating a loss function to an instance of vector summation approximation, where the vectors we aim to sum are loss vectors of a specific subset of the queries, such that we aim to approximate the image of the function on this subset. We show that while this set is limited, the coreset is quite general. An extensive experimental study on various machine learning applications is also conducted. Finally, we provide a “plug and play" style implementation, proposing a user-friendly system that can be easily used to apply coresets for many problems. We believe that these contributions enable future research and easier use and applications of coresets.

**摘要:** 核心集是一个给定的查询集的输入集的微量子集,其损失函数近似。核心集在机器学习中变得普遍,因为它们已经证明为许多应用程序具有优势。不幸的是,核心集在依赖问题的方式构建,每个问题都有新的核心集构造算法,需要花费数年来证明其正确性。即使是通用框架也需要用户做额外的(依赖问题)计算或证明。此外,许多问题没有(可证明的)小核心集,限制其适用性。为此,我们建议建立一个自动的实用框架,它需要(仅)用户提供输入数据和所需的成本函数,而不需要用户做任何其他与任务有关的计算。为此,我们将丢失函数的近似问题减少到向量总结近似的一个实例,其中我们的目标是将查询的一个特定子集的丢失向量归纳为向量,从而使我们的目标是近似该子集的函数的图像。我们显示,虽然这个子集有限,但核心集非常一般。我们还进行了关于各种机器学习应用的广泛实验研究。最后,我们提供了“插件和玩”风格的实现,提出了一种易于使用和应用于许多问题的核心集的用户友好系统。我们相信,这些贡献能够使核心集的未来研究和更易于使用和应用。

**[Paper URL](https://proceedings.mlr.press/v202/maalouf23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/maalouf23a/maalouf23a.pdf)** 

# Learning GFlowNets From Partial Episodes For Improved Convergence And Stability
**题目:** 从部分事件中学习GFlowNets,提高收敛性和稳定性

**作者:** Kanika Madan, Jarrid Rector-Brooks, Maksym Korablyov, Emmanuel Bengio, Moksh Jain, Andrei Cristian Nica, Tom Bosc, Yoshua Bengio, Nikolay Malkin

**Abstract:** Generative flow networks (GFlowNets) are a family of algorithms for training a sequential sampler of discrete objects under an unnormalized target density and have been successfully used for various probabilistic modeling tasks. Existing training objectives for GFlowNets are either local to states or transitions, or propagate a reward signal over an entire sampling trajectory. We argue that these alternatives represent opposite ends of a gradient bias-variance tradeoff and propose a way to exploit this tradeoff to mitigate its harmful effects. Inspired by the TD($\lambda$) algorithm in reinforcement learning, we introduce subtrajectory balance or SubTB($\lambda$), a GFlowNet training objective that can learn from partial action subsequences of varying lengths. We show that SubTB($\lambda$) accelerates sampler convergence in previously studied and new environments and enables training GFlowNets in environments with longer action sequences and sparser reward landscapes than what was possible before. We also perform a comparative analysis of stochastic gradient dynamics, shedding light on the bias-variance tradeoff in GFlowNet training and the advantages of subtrajectory balance.

**摘要:** 生成流网络(GFlowNets)是训练一个不正常目标密度下的离散对象序列样本器的算法,并成功地用于各种概率建模任务。GFlowNets现有的训练目标要么是局部状态或过渡,要么是在整个采样轨迹上传播奖励信号。我们认为这些替代方案代表梯度偏差交换的相反端,并提出一种利用这种交换来减轻其有害影响的方法。研究表明,SubTB($\lambda$)在先前研究和新的环境中加速样品收敛,使GFlowNet在较长动作序列和较稀少奖励景观的环境中进行训练。我们还对随机梯度动力学进行了比较分析,揭示了GFlowNet训练中的偏差-变量交换和子推理平衡的优点。

**[Paper URL](https://proceedings.mlr.press/v202/madan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/madan23a/madan23a.pdf)** 

# Applied Online Algorithms with Heterogeneous Predictors
**题目:** 基于异构预测的在线算法

**作者:** Jessica Maghakian, Russell Lee, Mohammad Hajiesmaili, Jian Li, Ramesh Sitaraman, Zhenhua Liu

**Abstract:** For many application domains, the integration of machine learning (ML) models into decision making is hindered by the poor explainability and theoretical guarantees of black box models. Although the emerging area of algorithms with predictions offers a way to leverage ML while enjoying worst-case guarantees, existing work usually assumes access to only one predictor. We demonstrate how to more effectively utilize historical datasets and application domain knowledge by intentionally using predictors of different quantities. By leveraging the heterogeneity in our predictors, we are able to achieve improved performance, explainability and computational efficiency over predictor-agnostic methods. Theoretical results are supplemented by large-scale empirical evaluations with production data demonstrating the success of our methods on optimization problems occurring in large distributed computing systems.

**摘要:** 对于许多应用领域,机器学习(ML)模型的整合在决策中受到黑箱模型的 poor explainability和理论保证的阻碍。虽然具有预测的算法的新兴领域提供了一种利用ML的途径,同时享受最坏情况的保证,现有的工作通常只接受一个预测器的访问。我们展示了如何更有效地利用历史数据集和应用领域知识,意图使用不同数量的预测器。通过利用预测器中的异质性,我们能够在预测器-预测方法上提高性能、解释性和计算效率。

**[Paper URL](https://proceedings.mlr.press/v202/maghakian23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/maghakian23a/maghakian23a.pdf)** 

# CSP: Self-Supervised Contrastive Spatial Pre-Training for Geospatial-Visual Representations
**题目:** CSP: Geospatial-Visual Representations的自我监督反向空间预训练

**作者:** Gengchen Mai, Ni Lao, Yutong He, Jiaming Song, Stefano Ermon

**Abstract:** Geo-tagged images are publicly available in large quantities, whereas labels such as object classes are rather scarce and expensive to collect. Meanwhile, contrastive learning has achieved tremendous success in various natural image and language tasks with limited labeled data. However, existing methods fail to fully leverage geospatial information, which can be paramount to distinguishing objects that are visually similar. To directly leverage the abundant geospatial information associated with images in pre-training, fine-tuning, and inference stages, we present Contrastive Spatial Pre-Training (CSP), a self-supervised learning framework for geo-tagged images. We use a dual-encoder to separately encode the images and their corresponding geo-locations, and use contrastive objectives to learn effective location representations from images, which can be transferred to downstream supervised tasks such as image classification. Experiments show that CSP can improve model performance on both iNat2018 and fMoW datasets. Especially, on iNat2018, CSP significantly boosts the model performance with 10-34% relative improvement with various labeled training data sampling ratios.

**摘要:** 地理标记图像是大量公开的,而像对象类这样的标记则比较稀少和昂贵的收集。同时,对比性学习在有限标记数据的自然图像和语言任务中取得了巨大的成功。然而,现有的方法无法充分利用地理空间信息,这对于区分有视觉相似的对象是至关重要的。为了直接利用与图像相关的丰富的地理空间信息在预训练、微调和推导阶段,我们提出了对比性空间预训练(CSP)——对地理标记图像进行自我监督的学习框架。实验表明,CSP可以在iNat2018和fMoW数据集中提高模型性能,特别是在iNat2018中,CSP能显著提高模型性能,以10-34%的相对改进率与各种标记训练数据采样率。

**[Paper URL](https://proceedings.mlr.press/v202/mai23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mai23a/mai23a.pdf)** 

# Vertical Federated Graph Neural Network for Recommender System
**题目:** 推荐系统垂直联合图神经网络

**作者:** Peihua Mai, Yan Pang

**Abstract:** Conventional recommender systems are required to train the recommendation model using a centralized database. However, due to data privacy concerns, this is often impractical when multi-parties are involved in recommender system training. Federated learning appears as an excellent solution to the data isolation and privacy problem. Recently, Graph neural network (GNN) is becoming a promising approach for federated recommender systems. However, a key challenge is to conduct embedding propagation while preserving the privacy of the graph structure. Few studies have been conducted on the federated GNN-based recommender system. Our study proposes the first vertical federated GNN-based recommender system, called VerFedGNN. We design a framework to transmit: (i) the summation of neighbor embeddings using random projection, and (ii) gradients of public parameter perturbed by ternary quantization mechanism. Empirical studies show that VerFedGNN has competitive prediction accuracy with existing privacy preserving GNN frameworks while enhanced privacy protection for users’ interaction information.

**摘要:** 传统的推荐系统需要使用集中数据库来培训推荐模型。然而,由于数据隐私问题,当多方参与推荐系统培训时,这往往是不现实的。联合学习似乎是一个很好的解决数据隔离和隐私问题。最近,图神经网络(GNN)正成为联合推荐系统的一个有前途的途径。然而,关键的挑战是在维护图结构的隐私的同时进行嵌入传播。实证研究表明,VerFedGNN具有与现有的GNN框架保持隐私的竞争性预测精度,同时增强了用户交互信息的隐私保护。

**[Paper URL](https://proceedings.mlr.press/v202/mai23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mai23b/mai23b.pdf)** 

# Can Neural Network Memorization Be Localized?
**题目:** 神经网络记忆是否可局部化?

**作者:** Pratyush Maini, Michael Curtis Mozer, Hanie Sedghi, Zachary Chase Lipton, J Zico Kolter, Chiyuan Zhang

**Abstract:** Recent efforts at explaining the interplay of memorization and generalization in deep overparametrized networks have posited that neural networks memorize “hard” examples in the final few layers of the model. Memorization refers to the ability to correctly predict on atypical examples of the training set. In this work, we show that rather than being confined to individual layers, memorization is a phenomenon confined to a small set of neurons in various layers of the model. First, via three experimental sources of converging evidence, we find that most layers are redundant for the memorization of examples and the layers that contribute to example memorization are, in general, not the final layers. The three sources are gradient accounting (measuring the contribution to the gradient norms from memorized and clean examples), layer rewinding (replacing specific model weights of a converged model with previous training checkpoints), and retraining (training rewound layers only on clean examples). Second, we ask a more generic question: can memorization be localized anywhere in a model? We discover that memorization is often confined to a small number of neurons or channels (around 5) of the model. Based on these insights we propose a new form of dropout—example-tied dropout that enables us to direct the memorization of examples to an aprior determined set of neurons. By dropping out these neurons, we are able to reduce the accuracy on memorized examples from 100% to 3%, while also reducing the generalization gap.

**摘要:** 最近在解释深度超参数化网络中的记忆和一般化相互作用方面,研究表明神经网络在模型的最后几个层中记忆“硬”的例子。记忆是指在训练集合的非典型例子上正确预测的能力。在这项研究中,我们表明,记忆不是局限于单个层,而是局限于模型的各个层中的一个小组神经元。三个来源是梯度会计(测量从记忆和纯实例中对梯度规范的贡献)、层重叠(用以前的训练检查点替换统一模型的特定模型重量)和重新训练(只在纯实例上训练重叠层)。其次,我们提出一个更一般的问题:在模型中,是否可以定位记忆?我们发现记忆往往局限于模型的少数神经元或通道(大约5个)。

**[Paper URL](https://proceedings.mlr.press/v202/maini23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/maini23a/maini23a.pdf)** 

# Fundamental Tradeoffs in Learning with Prior Information
**题目:** 事先资料学习的基本折衷

**作者:** Anirudha Majumdar

**Abstract:** We seek to understand fundamental tradeoffs between the accuracy of prior information that a learner has on a given problem and its learning performance. We introduce the notion of prioritized risk, which differs from traditional notions of minimax and Bayes risk by allowing us to study such fundamental tradeoffs in settings where reality does not necessarily conform to the learner’s prior. We present a general reduction-based approach for extending classical minimax lower-bound techniques in order to lower bound the prioritized risk for statistical estimation problems. We also introduce a novel generalization of Fano’s inequality (which may be of independent interest) for lower bounding the prioritized risk in more general settings involving unbounded losses. We illustrate the ability of our framework to provide insights into tradeoffs between prior information and learning performance for problems in estimation, regression, and reinforcement learning.

**摘要:** 我们试图理解学习者对某一问题的信息准确性与学习成绩之间的基本折衷。我们引入了优先风险的概念,与传统微分和贝斯风险的概念不同,允许我们在现实不一定符合学习者的优先情况的情况下研究这些基本折衷。我们提出了一种基于减少的一般方法,以扩展经典微分低限技术,以降低统计估计问题优先风险。我们还引入了法诺不平等(可能具有独立利益)的新一般化,以便在涉及无限损失的一般环境下降低优先风险的折衷。我们说明了我们的框架能够提供对估计、回归和增强学习问题之间的折衷的洞察。

**[Paper URL](https://proceedings.mlr.press/v202/majumdar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/majumdar23a/majumdar23a.pdf)** 

# Additive Causal Bandits with Unknown Graph
**题目:** 未知图形的诱导性强奸犯

**作者:** Alan Malek, Virginia Aglietti, Silvia Chiappa

**Abstract:** We explore algorithms to select actions in the causal bandit setting where the learner can choose to intervene on a set of random variables related by a causal graph, and the learner sequentially chooses interventions and observes a sample from the interventional distribution. The learner’s goal is to quickly find the intervention, among all interventions on observable variables, that maximizes the expectation of an outcome variable. We depart from previous literature by assuming no knowledge of the causal graph except that latent confounders between the outcome and its ancestors are not present. We first show that the unknown graph problem can be exponentially hard in the parents of the outcome. To remedy this, we adopt an additional additive assumption on the outcome which allows us to solve the problem by casting it as an additive combinatorial linear bandit problem with full-bandit feedback. We propose a novel action-elimination algorithm for this setting, show how to apply this algorithm to the causal bandit problem, provide sample complexity bounds, and empirically validate our findings on a suite of randomly generated causal models, effectively showing that one does not need to explicitly learn the parents of the outcome to identify the best intervention.

**摘要:** 我们研究了因果带子设置中选择行为的算法,学习者可以选择在因果图关联的随机变量集中干预,学习者可以顺序选择干预并观察干预分布的样品。学习者的目标是迅速找到在可观察变量的所有干预中,能最大化结果变量预期的干预。我们为此设置提出了一种新颖的行动排斥算法,展示了该算法如何应用于因果性盗窃问题,提供样品复杂度边界,并通过实验验证了我们对随机生成的因果模型的一系列发现,有效地显示了人们不需要明确学习结果的父母来确定最佳干预方法。

**[Paper URL](https://proceedings.mlr.press/v202/malek23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/malek23a/malek23a.pdf)** 

# Weighted Tallying Bandits: Overcoming Intractability via Repeated Exposure Optimality
**题目:** 重压高压带子:通过重复暴露优化克服阻塞性

**作者:** Dhruv Malik, Conor Igoe, Yuanzhi Li, Aarti Singh

**Abstract:** In human-interactive applications of online learning, a human’s preferences or abilities are often a function of the algorithm’s recent actions. Motivated by this, a significant line of work has formalized settings where an action’s loss is a function of the number of times it was played in the prior $m$ timesteps, where $m$ corresponds to a bound on human memory capacity. To more faithfully capture decay of human memory with time, we introduce the Weighted Tallying Bandit (WTB), which generalizes this setting by requiring that an action’s loss is a function of a weighted summation of the number of times it was played in the last $m$ timesteps. WTB is intractable without further assumption. So we study it under Repeated Exposure Optimality (REO), a condition requiring the existence of an action that when repetitively played will eventually yield smaller loss than any other action sequence. We study the minimization of complete policy regret (CPR), which is the strongest notion of regret, in WTB under REO. Since $m$ is often unknown, we only assume access to an upper bound $M$ on $m$. We show that for problems with $K$ actions and horizon $T$, a simple modification of the successive elimination algorithm has $\mathcal{O} \left( \sqrt{KT} + (m+M)K \right)$ CPR. Upto an additive (in lieu of mutliplicative) factor in $(m+M)K$, this recovers the classical guarantee for the far simpler stochastic multi-armed bandit with traditional regret. We additionally show that in our setting, any algorithm will suffer additive CPR of $\Omega \left( mK + M \right)$, demonstrating our result is near optimal. Our method is computationally efficient, and we experimentally demonstrate its practicality and superiority over various baselines.

**摘要:** 在在线学习的人类交互应用中,人类的偏好或能力往往是算法最近的行动的函数。受此动机,一个重要的工作线已形成设置,其中一个行动的损失是它在以前的$m$时间步骤中被播放的数次的函数,其中$m$与人类记忆能力的约束相符。为了更忠实地捕捉时间的人类记忆的衰变,我们引入了权重提振 Bandit(WTB),它通过要求行动的损失是它在最后的$m$时间步骤中被播放的数次的权重总结的函数来概括这一设置。我们研究了在REO下WTB中最强的策略遗憾(CPR)的最小化。由于$m$经常未知,我们只假设在$m$上获得上限$M$。我们证明,对于$K$行动和水平$T$的问题,连续消除算法的简单修改具有$\mathcal{O} \left(\sqrt{KT} + (m+M)K \right)$ CPR。

**[Paper URL](https://proceedings.mlr.press/v202/malik23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/malik23a/malik23a.pdf)** 

# A Kernel-Based View of Language Model Fine-Tuning
**题目:** 基于内核的语言模型微调视图

**作者:** Sadhika Malladi, Alexander Wettig, Dingli Yu, Danqi Chen, Sanjeev Arora

**Abstract:** It has become standard to solve NLP tasks by fine-tuning pre-trained language models (LMs), especially in low-data settings. There is minimal theoretical understanding of empirical success, e.g., why fine-tuning a model with $10^8$ or more parameters on a couple dozen training points does not result in overfitting. We investigate whether the Neural Tangent Kernel (NTK)—which originated as a model to study the gradient descent dynamics of infinitely wide networks with suitable random initialization—describes fine-tuning of pre-trained LMs. This study was inspired by the decent performance of NTK for computer vision tasks (Wei et al., 2022). We extend the NTK formalism to Adam and use Tensor Programs (Yang, 2020) to characterize conditions under which the NTK lens may describe fine-tuning updates to pre-trained language models. Extensive experiments on 14 NLP tasks validate our theory and show that formulating the downstream task as a masked word prediction problem through prompting often induces kernel-based dynamics during fine-tuning. Finally, we use this kernel view to propose an explanation for the success of parameter-efficient subspace-based fine-tuning methods.

**摘要:** 通过微调预训练语言模型(LMs)来解决NLP任务已成为标准,特别是在低数据设置中。 经验成功的理论理解是最低限度的,例如,为什么用10^8$或更多的参数微调模型在一对数十个训练点上不会造成过度匹配的问题。 我们研究了神经 Tangent Kernel(NTK)—它起源于研究无穷宽网络梯度下降动力学的模型,以适当的随机初始化来描述预训练LMs的微调。 这项研究被NTK对计算机视觉任务的良好性能所激发(Wei et al., 2022)。对14个NLP任务进行了广泛的实验验证了我们的理论,并表明,通过提示将下游任务作为隐形词预测问题,在微调过程中经常诱导内核动力学。最后,我们使用这个内核视图,提出参数效率低的子空间微调方法的成功解释。

**[Paper URL](https://proceedings.mlr.press/v202/malladi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/malladi23a/malladi23a.pdf)** 

# Performative Reinforcement Learning
**题目:** 表演强化学习

**作者:** Debmalya Mandal, Stelios Triantafyllou, Goran Radanovic

**Abstract:** We introduce the framework of performative reinforcement learning where the policy chosen by the learner affects the underlying reward and transition dynamics of the environment. Following the recent literature on performative prediction (Perdomo et al., 2020), we introduce the concept of performatively stable policy. We then consider a regularized version of the reinforcement learning problem and show that repeatedly optimizing this objective converges to a performatively stable policy under reasonable assumptions on the transition dynamics. Our proof utilizes the dual perspective of the reinforcement learning problem and may be of independent interest in analyzing the convergence of other algorithms with decision-dependent environments. We then extend our results for the setting where the learner just performs gradient ascent steps instead of fully optimizing the objective, and for the setting where the learner has access to a finite number of trajectories from the changed environment. For both the settings, we leverage the dual formulation of performative reinforcement learning, and establish convergence to a stable solution. Finally, through extensive experiments on a grid-world environment, we demonstrate the dependence of convergence on various parameters e.g. regularization, smoothness, and the number of samples.

**摘要:** 本文介绍了基于学习者选择的策略对环境下的回报和过渡动力学的影响的 performative reinforcement learning框架,并根据最近关于 performative prediction的文献(Perdomo et al., 2020),提出了 performatively stable policy的概念,然后考虑了强化学习问题的规范化版本,并表明,反复优化这一目标在合理假设下的过渡动力学下会趋向到 performatively stable policy。我们的证明采用了强化学习问题的双重视角,对分析其他算法与决策环境的趋向具有独立的兴趣。最后,通过对网格世界环境的广泛实验,证明了对各种参数的依赖性,例如规则化、平滑度和样品数等。

**[Paper URL](https://proceedings.mlr.press/v202/mandal23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mandal23a/mandal23a.pdf)** 

# Differential Privacy has Bounded Impact on Fairness in Classification
**题目:** 差异性隐私对分类公平的影响有限

**作者:** Paul Mangold, Michaël Perrot, Aurélien Bellet, Marc Tommasi

**Abstract:** We theoretically study the impact of differential privacy on fairness in classification. We prove that, given a class of models, popular group fairness measures are pointwise Lipschitz-continuous with respect to the parameters of the model. This result is a consequence of a more general statement on accuracy conditioned on an arbitrary event (such as membership to a sensitive group), which may be of independent interest. We use this Lipschitz property to prove a non-asymptotic bound showing that, as the number of samples increases, the fairness level of private models gets closer to the one of their non-private counterparts. This bound also highlights the importance of the confidence margin of a model on the disparate impact of differential privacy.

**摘要:** 我们从理论上研究了微分私隐对分类公平的影响。我们证明,给定一类模型,大众群体公平措施与模型的参数相对于是点wise Lipschitz-continuous。这一结果是基于任意事件(例如对敏感群体的成员)的更一般性声明的结果,可能具有独立利益。我们使用这一 Lipschitz属性来证明一个非渐近的约束,表明随着样品数量的增加,私人模型的公平程度会更接近其非私人对照者之一。这一约束也突出了模型对微分私隐的差异影响的信任边际的重要性。

**[Paper URL](https://proceedings.mlr.press/v202/mangold23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mangold23a/mangold23a.pdf)** 

# Random Classification Noise does not defeat All Convex Potential Boosters Irrespective of Model Choice
**题目:** 随机分类噪声不影响模型选择的所有凸势增强器

**作者:** Yishay Mansour, Richard Nock, Robert Williamson

**Abstract:** A landmark negative result of Long and Servedio has had a considerable impact on research and development in boosting algorithms, around the now famous tagline that "noise defeats all convex boosters". In this paper, we appeal to the half-century+ founding theory of losses for class probability estimation, an extension of Long and Servedio’s results and a new general convex booster to demonstrate that the source of their negative result is in fact the model class, linear separators. Losses or algorithms are neither to blame. This leads us to a discussion on an otherwise praised aspect of ML, parameterisation.

**摘要:**  Long 和 Servedio 的标志性负结果对提高算法的研究和开发产生了重大影响,这与现在著名的“噪声击败了所有凸增量器”有关。本文,我们呼吁半个世纪+ 的分类概率估计损失理论,以及 Long 和 Servedio 的结果的扩展和一种新的一般凸增量器,以证明其负结果的来源实际上是模型类,线性分离器。

**[Paper URL](https://proceedings.mlr.press/v202/mansour23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mansour23a/mansour23a.pdf)** 

# $H$-Consistency Bounds for Pairwise Misranking Loss Surrogates
**题目:** $H$-对双级差额损失替代品的一致性上限

**作者:** Anqi Mao, Mehryar Mohri, Yutao Zhong

**Abstract:** We present a detailed study of $H$-consistency bounds for score-based ranking. These are upper bounds on the target loss estimation error of a predictor in a hypothesis set $H$, expressed in terms of the surrogate loss estimation error of that predictor. We will show that both in the general pairwise ranking scenario and in the bipartite ranking scenario, there are no meaningful $H$-consistency bounds for most hypothesis sets used in practice including the family of linear models and that of the neural networks, which satisfy the equicontinuous property with respect to the input. To come up with ranking surrogate losses with theoretical guarantees, we show that a natural solution consists of resorting to a pairwise abstention loss in the general pairwise ranking scenario, and similarly, a bipartite abstention loss in the bipartite ranking scenario, to abstain from making predictions at some limited cost $c$. For surrogate losses of these abstention loss functions, we give a series of $H$-consistency bounds for both the family of linear functions and that of neural networks with one hidden-layer. Our experimental results illustrate the effectiveness of ranking with abstention.

**摘要:** 我们对基于分数的排名的$H$-一致性边界进行了详细研究,这些是预测器在假设集合$H$中目标损失估计误差的上限,表达为预测器的替代损失估计误差。我们将显示,在一般双向排名场景和双向排名场景中,几乎没有意义的$H$-一致性边界,包括线性模型的家族和神经网络,它们满足对输入的一致性属性。针对这些弃权失效函数的替代损失,我们给出了一系列的$H$-一致性界限,适用于线性函数和一个隐藏层的神经网络。

**[Paper URL](https://proceedings.mlr.press/v202/mao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mao23a/mao23a.pdf)** 

# Cross-Entropy Loss Functions: Theoretical Analysis and Applications
**题目:** 跨熵失效函数:理论分析与应用

**作者:** Anqi Mao, Mehryar Mohri, Yutao Zhong

**Abstract:** Cross-entropy is a widely used loss function in applications. It coincides with the logistic loss applied to the outputs of a neural network, when the softmax is used. But, what guarantees can we rely on when using cross-entropy as a surrogate loss? We present a theoretical analysis of a broad family of loss functions, comp-sum losses, that includes cross-entropy (or logistic loss), generalized cross-entropy, the mean absolute error and other cross-entropy-like loss functions. We give the first $H$-consistency bounds for these loss functions. These are non-asymptotic guarantees that upper bound the zero-one loss estimation error in terms of the estimation error of a surrogate loss, for the specific hypothesis set $H$ used. We further show that our bounds are tight. These bounds depend on quantities called minimizability gaps. To make them more explicit, we give a specific analysis of these gaps for comp-sum losses. We also introduce a new family of loss functions, smooth adversarial comp-sum losses, that are derived from their comp-sum counterparts by adding in a related smooth term. We show that these loss functions are beneficial in the adversarial setting by proving that they admit $H$-consistency bounds. This leads to new adversarial robustness algorithms that consist of minimizing a regularized smooth adversarial comp-sum loss. While our main purpose is a theoretical analysis, we also present an extensive empirical analysis comparing comp-sum losses. We further report the results of a series of experiments demonstrating that our adversarial robustness algorithms outperform the current state-of-the-art, while also achieving a superior non-adversarial accuracy.

**摘要:** 交叉熵是广泛应用于应用程序中的损失函数。当使用软最大时,它与应用于神经网络输出的物流损失相一致。但是,当使用交叉熵作为替代损失时,我们能得到哪些保证?我们给出了广泛的损失函数的理论分析,包括交叉熵(或物流损失),一般化交叉熵,平均绝对误差和其他交叉熵类似损失函数。我们给出了这些损失函数的第一个$H$-一致性边界。我们还引入了一种新的损失函数家族,即平滑的敌对计算sum损失,通过添加相关的平滑术语来推导其计算sum对照者。我们证明,这些损失函数在敌对设置中是有益的,因为它们承认$H$-一致性边界。这导致新的敌对鲁棒性算法,包括最小化平滑的敌对计算sum损失。虽然我们的主要目的是理论分析,我们还提出了比较计算sum损失的广泛的实证分析。

**[Paper URL](https://proceedings.mlr.press/v202/mao23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mao23b/mao23b.pdf)** 

# Supported Trust Region Optimization for Offline Reinforcement Learning
**题目:** 支持信任区域优化 offline增强学习

**作者:** Yixiu Mao, Hongchang Zhang, Chen Chen, Yi Xu, Xiangyang Ji

**Abstract:** Offline reinforcement learning suffers from the out-of-distribution issue and extrapolation error. Most policy constraint methods regularize the density of the trained policy towards the behavior policy, which is too restrictive in most cases. We propose Supported Trust Region optimization (STR) which performs trust region policy optimization with the policy constrained within the support of the behavior policy, enjoying the less restrictive support constraint. We show that, when assuming no approximation and sampling error, STR guarantees strict policy improvement until convergence to the optimal support-constrained policy in the dataset. Further with both errors incorporated, STR still guarantees safe policy improvement for each step. Empirical results validate the theory of STR and demonstrate its state-of-the-art performance on MuJoCo locomotion domains and much more challenging AntMaze domains.

**摘要:** 我们建议支持信任区域优化(Supported Trust Region optimization,STR),以支持行为策略的约束政策进行信任区域优化,享受较少的约束支持约束。我们表明,在假设没有近似和抽样错误时,Supported Trust区域优化(Supported Trust Region optimization,STR)保证严格的政策改进,直到数据集的优化支持约束政策的收敛。

**[Paper URL](https://proceedings.mlr.press/v202/mao23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mao23c/mao23c.pdf)** 

# Robust Perception through Equivariance
**题目:** 通过等价感知的鲁棒理解

**作者:** Chengzhi Mao, Lingyu Zhang, Abhishek Vaibhav Joshi, Junfeng Yang, Hao Wang, Carl Vondrick

**Abstract:** Deep networks for computer vision are not reliable when they encounter adversarial examples. In this paper, we introduce a framework that uses the dense intrinsic constraints in natural images to robustify inference. By introducing constraints at inference time, we can shift the burden of robustness from training to testing, thereby allowing the model to dynamically adjust to each individual image’s unique and potentially novel characteristics at inference time. Our theoretical results show the importance of having dense constraints at inference time. In contrast to existing single-constraint methods, we propose to use equivariance, which naturally allows dense constraints at a fine-grained level in the feature space. Our empirical experiments show that restoring feature equivariance at inference time defends against worst-case adversarial perturbations. The method obtains improved adversarial robustness on four datasets (ImageNet, Cityscapes, PASCAL VOC, and MS-COCO) on image recognition, semantic segmentation, and instance segmentation tasks.

**摘要:** 计算机视觉深层网络在遇到敌对实例时并不可靠。本文介绍了一种利用自然图像中的密集内在约束来强化推理的框架。通过引入推理时的约束,我们可以从训练转变为测试,从而使模型在推理时能动态调整到每个图像的独特和潜在的新特征。该方法提高了图像识别、语义分割和实例分割任务的四个数据集(ImageNet、Cityscapes、PASCAL VOC和MS-COCO)的敌对鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/mao23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mao23d/mao23d.pdf)** 

# Reliable Measures of Spread in High Dimensional Latent Spaces
**题目:** 高维拉特空间扩散的可靠测量

**作者:** Anna Marbut, Katy Mckinney-Bock, Travis Wheeler

**Abstract:** Understanding geometric properties of the latent spaces of natural language processing models allows the manipulation of these properties for improved performance on downstream tasks. One such property is the amount of data spread in a model’s latent space, or how fully the available latent space is being used. We demonstrate that the commonly used measures of data spread, average cosine similarity and a partition function min/max ratio I(V), do not provide reliable metrics to compare the use of latent space across data distributions. We propose and examine six alternative measures of data spread, all of which improve over these current metrics when applied to seven synthetic data distributions. Of our proposed measures, we recommend one principal component-based measure and one entropy-based measure that provide reliable, relative measures of spread and can be used to compare models of different sizes and dimensionalities.

**摘要:** 理解自然语言处理模型的延迟空间的几何特性允许对这些特性进行操作,以提高下游任务的性能。其中一种属性是模型的延迟空间中的数据扩散量,或者利用的可用延迟空间的充分程度。我们证明,常用的数据扩散量、平均共数相似性和分区函数最大/最小比 ratio I(V)不提供可靠度量来比较数据分布中延迟空间的使用。我们建议和检查数据扩散的六种替代度量,这些都改善了这些现有度量,当应用于七种合成数据分布时。我们建议一个主要的组件基础度量和一个熵基础度量提供可靠、相对的扩散度量,并可用于比较不同尺寸和维度的模型。

**[Paper URL](https://proceedings.mlr.press/v202/marbut23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/marbut23a/marbut23a.pdf)** 

# SRATTA: Sample Re-ATTribution Attack of Secure Aggregation in Federated Learning.
**题目:** SRATTA:  Federated Learning 中 安全 集群 的 再分配 攻击 实例 。

**作者:** Tanguy Marchand, Regis Loeb, Ulysse Marteau-Ferey, Jean Ogier Du Terrail, Arthur Pignet

**Abstract:** We consider a federated learning (FL) setting where a machine learning model with a fully connected first layer is trained between different clients and a central server using FedAvg, and where the aggregation step can be performed with secure aggregation (SA). We present SRATTA an attack relying only on aggregated models which, under realistic assumptions, (i) recovers data samples from the different clients, and (ii) groups data samples coming from the same client together. While sample recovery has already been explored in an FL setting, the ability to group samples per client, despite the use of SA, is novel. This poses a significant unforeseen security threat to FL and effectively breaks SA. We show that SRATTA is both theoretically grounded and can be used in practice on realistic models and datasets. We also propose counter-measures, and claim that clients should play an active role to guarantee their privacy during training.

**摘要:** 我们考虑一个联邦学习(FL)设置,其中一个与完全联接的第一个层的机器学习模型在不同客户端和使用FedAvg的中央服务器之间进行培训,并使用安全聚合(SA)进行聚合步骤。我们提出了SRATTA攻击,仅依靠聚合模型,在现实假设下,(i)从不同客户端恢复数据样本,和(ii)从同一客户端一起收集数据样本。

**[Paper URL](https://proceedings.mlr.press/v202/marchand23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/marchand23a/marchand23a.pdf)** 

# Neuro-Symbolic Continual Learning: Knowledge, Reasoning Shortcuts and Concept Rehearsal
**题目:** 神经-象征性持续学习:知识、理智捷径和概念练习

**作者:** Emanuele Marconato, Gianpaolo Bontempo, Elisa Ficarra, Simone Calderara, Andrea Passerini, Stefano Teso

**Abstract:** We introduce Neuro-Symbolic Continual Learning, where a model has to solve a sequence of neuro-symbolic tasks, that is, it has to map sub-symbolic inputs to high-level concepts and compute predictions by reasoning consistently with prior knowledge. Our key observation is that neuro-symbolic tasks, although different, often share concepts whose semantics remains stable over time. Traditional approaches fall short: existing continual strategies ignore knowledge altogether, while stock neuro-symbolic architectures suffer from catastrophic forgetting. We show that leveraging prior knowledge by combining neuro-symbolic architectures with continual strategies does help avoid catastrophic forgetting, but also that doing so can yield models affected by reasoning shortcuts. These undermine the semantics of the acquired concepts, even when detailed prior knowledge is provided upfront and inference is exact, and in turn continual performance. To overcome these issues, we introduce COOL, a COncept-level cOntinual Learning strategy tailored for neuro-symbolic continual problems that acquires high-quality concepts and remembers them over time. Our experiments on three novel benchmarks highlights how COOL attains sustained high performance on neuro-symbolic continual learning tasks in which other strategies fail.

**摘要:** 我们引入了神经符号持续学习,模型必须解决神经符号任务的序列,即必须将次符号输入映射到高层次概念,并通过与先前知识一致的推理计算预测。我们的主要观察是,神经符号任务虽然不同,但往往共享概念,其语义在时间上保持稳定。传统的方法不足:现有的持续策略完全忽略知识,而库存的神经符号架构则遭受灾难性遗忘。我们证明,通过将神经符号架构和持续策略结合起来利用先前知识有助于避免灾难性遗忘,但这样做也能产生因推理捷径影响的模型。为了克服这些问题,我们引入了COOL,一种基于神经符号的持续学习策略,它获取高质量的概念并在时间上记住它们。我们对三个新标准的实验突出了COOL如何在其他策略失败的神经符号的持续学习任务中取得持续的高性能。

**[Paper URL](https://proceedings.mlr.press/v202/marconato23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/marconato23a/marconato23a.pdf)** 

# Evaluating Unsupervised Denoising Requires Unsupervised Metrics
**题目:** 评价未经监督的臭氧要求未经监督的计量

**作者:** Adria Marcos Morales, Matan Leibovich, Sreyas Mohan, Joshua Lawrence Vincent, Piyush Haluai, Mai Tan, Peter Crozier, Carlos Fernandez-Granda

**Abstract:** Unsupervised denoising is a crucial challenge in real-world imaging applications. Unsupervised deep-learning methods have demonstrated impressive performance on benchmarks based on synthetic noise. However, no metrics exist to evaluate these methods in an unsupervised fashion. This is highly problematic for the many practical applications where ground-truth clean images are not available. In this work, we propose two novel metrics: the unsupervised mean squared error (MSE) and the unsupervised peak signal-to-noise ratio (PSNR), which are computed using only noisy data. We provide a theoretical analysis of these metrics, showing that they are asymptotically consistent estimators of the supervised MSE and PSNR. Controlled numerical experiments with synthetic noise confirm that they provide accurate approximations in practice. We validate our approach on real-world data from two imaging modalities: videos in raw format and transmission electron microscopy. Our results demonstrate that the proposed metrics enable unsupervised evaluation of denoising methods based exclusively on noisy data.

**摘要:** 无监督噪声是现实图像应用中一个关键的挑战。无监督深度学习方法在基于合成噪声的基准上表现出了令人印象深刻的性能。然而,没有统计方法来评估这些方法的无监督方式。这对于许多实际应用来说是十分困难的,因为地面真实清洁图像没有可用。在这个工作中,我们提出了两个新统计方法:无监督平均平方误差(MSE)和无监督峰值信号噪声比(PSNR),这些数据只使用噪声数据计算。我们提供了这些统计方法的理论分析,表明它们是无监督的MSE和PSNR的渐近一致估计者。实验结果表明,该方法能够对基于噪声数据的噪声检测方法进行无监督的评价。

**[Paper URL](https://proceedings.mlr.press/v202/marcos-morales23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/marcos-morales23a/marcos-morales23a.pdf)** 

# Regions of Reliability in the Evaluation of Multivariate Probabilistic Forecasts
**题目:** 评价多变概率预测的可靠性区域

**作者:** Étienne Marcotte, Valentina Zantedeschi, Alexandre Drouin, Nicolas Chapados

**Abstract:** Multivariate probabilistic time series forecasts are commonly evaluated via proper scoring rules, i.e., functions that are minimal in expectation for the ground-truth distribution. However, this property is not sufficient to guarantee good discrimination in the non-asymptotic regime. In this paper, we provide the first systematic finite-sample study of proper scoring rules for time series forecasting evaluation. Through a power analysis, we identify the “region of reliability” of a scoring rule, i.e., the set of practical conditions where it can be relied on to identify forecasting errors. We carry out our analysis on a comprehensive synthetic benchmark, specifically designed to test several key discrepancies between ground-truth and forecast distributions, and we gauge the generalizability of our findings to real-world tasks with an application to an electricity production problem. Our results reveal critical shortcomings in the evaluation of multivariate probabilistic forecasts as commonly performed in the literature.

**摘要:** 多变概率时间序列预测通常通过适当评分规则进行评估,即为地面真实分布预期的最小函数。然而,这一特性不足以保证在非渐近条件下进行良好区分。本论文首先为时间序列预测评估提供系统有限样本研究的适当评分规则。通过功率分析,我们确定了评分规则的“可靠性区域”,即可以依赖于确定预测误差的实际条件。结果表明,在评价文献中常见的多变概率预测中存在着关键性缺陷。

**[Paper URL](https://proceedings.mlr.press/v202/marcotte23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/marcotte23a/marcotte23a.pdf)** 

# Analyzing Diffusion as Serial Reproduction
**题目:** 作为序列复制的扩散分析

**作者:** Raja Marjieh, Ilia Sucholutsky, Thomas A Langlois, Nori Jacoby, Thomas L. Griffiths

**Abstract:** Diffusion models are a class of generative models that learn to synthesize samples by inverting a diffusion process that gradually maps data into noise. While these models have enjoyed great success recently, a full theoretical understanding of their observed properties is still lacking, in particular, their weak sensitivity to the choice of noise family and the role of adequate scheduling of noise levels for good synthesis. By identifying a correspondence between diffusion models and a well-known paradigm in cognitive science known as serial reproduction, whereby human agents iteratively observe and reproduce stimuli from memory, we show how the aforementioned properties of diffusion models can be explained as a natural consequence of this correspondence. We then complement our theoretical analysis with simulations that exhibit these key features. Our work highlights how classic paradigms in cognitive science can shed light on state-of-the-art machine learning problems.

**摘要:** 扩散模型是一种通过将数据逐渐映射成噪声的扩散过程逆转来合成样品的生成模型。虽然这些模型最近取得了巨大的成功,但它们所观察到的特性仍缺乏充分的理论理解,特别是对于选择噪声家族的敏感性以及对良好合成的噪声水平的适当调度的作用。通过识别扩散模型与认知科学中的众所周知的“序列复制”范式之间的相关性,通过人间代理人迭代观察和从记忆中复制刺激,我们展示了扩散模型的上述特性如何解释为这种关联的自然后果。

**[Paper URL](https://proceedings.mlr.press/v202/marjieh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/marjieh23a/marjieh23a.pdf)** 

# Quantized Distributed Training of Large Models with Convergence Guarantees
**题目:** 具有收敛性保证的大型模型量化分布式培训

**作者:** Ilia Markov, Adrian Vladu, Qi Guo, Dan Alistarh

**Abstract:** Communication-reduction techniques are a popular way to improve scalability in data-parallel training of deep neural networks (DNNs). The recent emergence of large language models such as GPT has created the need for new approaches to exploit data-parallelism. Among these, fully-sharded data parallel (FSDP) training is highly popular, yet it still encounters scalability bottlenecks. One reason is that applying compression techniques to FSDP is challenging: as the vast majority of the communication involves the model’s weights, direct compression alters convergence and leads to accuracy loss. We present QSDP, a variant of FSDP which supports both gradient and weight quantization with theoretical guarantees, is simple to implement and has essentially no overheads. To derive QSDP we prove that a natural modification of SGD achieves convergence even when we only maintain quantized weights, and thus the domain over which we train consists of quantized points and is, therefore, highly non-convex. We validate this approach by training GPT-family models with up to 1.3 billion parameters on a multi-node cluster. Experiments show that QSDP preserves model accuracy, while completely removing the communication bottlenecks of FSDP, providing end-to-end speedups of up to 2.2x.

**摘要:** 通信减少技术是提高深度神经网络(DNN)数据平行训练的可扩展性的一种流行方法。GPT等大型语言模型最近出现,使得开发数据平行需要新的方法。其中,完全硬化数据平行(FSDP)训练非常流行,但仍面临可扩展性瓶颈。为了推导QSDP,我们证明了SGD的自然修改能够实现收敛性,即使我们只保持量化重量,因此我们训练的领域由量化点组成,因此非常非凸。我们通过在多节点集群上训练GPT家族模型来验证这一方法,同时完全消除FSDP的通信瓶颈,提供最大2.2x的端到端速度提升。

**[Paper URL](https://proceedings.mlr.press/v202/markov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/markov23a/markov23a.pdf)** 

# Efficient Transformed Gaussian Processes for Non-Stationary Dependent Multi-class Classification
**题目:** 非静态依赖多类分类的高效变形高斯过程

**作者:** Juan Maroñas, Daniel Hernández-Lobato

**Abstract:** This work introduces the Efficient Transformed Gaussian Process (ETGP), a new way of creating $C$ stochastic processes characterized by: 1) the $C$ processes are non-stationary, 2) the $C$ processes are dependent by construction without needing a mixing matrix, 3) training and making predictions is very efficient since the number of Gaussian Processes (GP) operations (e.g. inverting the inducing point’s covariance matrix) do not depend on the number of processes. This makes the ETGP particularly suited for multi-class problems with a very large number of classes, which are the problems studied in this work. ETGP exploits the recently proposed Transformed Gaussian Process (TGP), a stochastic process specified by transforming a Gaussian Process using an invertible transformation. However, unlike TGP, ETGP is constructed by transforming a single sample from a GP using $C$ invertible transformations. We derive an efficient sparse variational inference algorithm for the proposed model and demonstrate its utility in 5 classification tasks which include low/medium/large datasets and a different number of classes, ranging from just a few to hundreds. Our results show that ETGP, in general, outperforms state-of-the-art methods for multi-class classification based on GPs, and has a lower computational cost (around one order of magnitude smaller).

**摘要:** 本文介绍了高效变形高斯过程(英语:Efficient Transformed Gaussian Process)(ETGP),一种由以下特征组成的$C$随机过程的新方法: 1)$C$过程是非静态的,2)$C$过程是不需要混合矩阵的构造而依赖的,3)训练和预测是非常有效的,因为高斯过程(GP)操作的数目(例如将诱导点的共变矩阵反转)并不取决于过程的数目,这使得ETGP特别适合于具有大量类数的多类问题,这是本文研究的问题。研究结果表明,ETGP一般比基于GP的多类分类的最先进的方法更优,计算成本更低(约一等大小)。

**[Paper URL](https://proceedings.mlr.press/v202/maronas23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/maronas23a/maronas23a.pdf)** 

# Computational Asymmetries in Robust Classification
**题目:** 鲁棒分类中的计算不对称

**作者:** Samuele Marro, Michele Lombardi

**Abstract:** In the context of adversarial robustness, we make three strongly related contributions. First, we prove that while attacking ReLU classifiers is $\mathit{NP}$-hard, ensuring their robustness at training time is $\Sigma^2_P$-hard (even on a single example). This asymmetry provides a rationale for the fact that robust classifications approaches are frequently fooled in the literature. Second, we show that inference-time robustness certificates are not affected by this asymmetry, by introducing a proof-of-concept approach named Counter-Attack (CA). Indeed, CA displays a reversed asymmetry: running the defense is $\mathit{NP}$-hard, while attacking it is $\Sigma_2^P$-hard. Finally, motivated by our previous result, we argue that adversarial attacks can be used in the context of robustness certification, and provide an empirical evaluation of their effectiveness. As a byproduct of this process, we also release UG100, a benchmark dataset for adversarial attacks.

**摘要:** 首先,我们证明在攻击ReLU分类器时的鲁棒性是$\mathit{NP}$-hard,在训练时的鲁棒性是$\Sigma^2_P$-hard(甚至在单个例子中)。这一不对称提供了鲁棒分类方法在文献中经常被误导的理由。其次,我们证明推断时间鲁棒性证书不受这种不对称的影响,通过引入一个名为反攻击(CA)的概念证明方法。事实上,CA显示了逆不对称:运行防御是$\mathit{NP}$-hard,而攻击是$\Sigma_2^P$-hard。最后,我们以我们的先前结果为动机,认为鲁棒性认证的范围内可以使用鲁棒性攻击,并提供他们的有效性的经验评估。作为这一过程的副产物,我们还发布了UG100,一个对鲁棒性攻击

**[Paper URL](https://proceedings.mlr.press/v202/marro23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/marro23a/marro23a.pdf)** 

# Neural Network Approximations of PDEs Beyond Linearity: A Representational Perspective
**题目:** 非线性神经网络的近似:一种代表性的视角

**作者:** Tanya Marwah, Zachary Chase Lipton, Jianfeng Lu, Andrej Risteski

**Abstract:** A burgeoning line of research has developed deep neural networks capable of approximating the solutions to high dimensional PDEs, opening related lines of theoretical inquiry focused on explaining how it is that these models appear to evade the curse of dimensionality. However, most theoretical analyses thus far have been limited to linear PDEs. In this work, we take a step towards studying the representational power of neural networks for approximating solutions to nonlinear PDEs. We focus on a class of PDEs known as nonlinear elliptic variational PDEs, whose solutions minimize an Euler-Lagrange energy functional $\mathcal{E}(u) = \int_\Omega L(x, u(x), \nabla u(x)) - f(x) u(x)dx$. We show that if composing a function with Barron norm $b$ with partial derivatives of $L$ produces a function of Barron norm at most $B_L b^p$, the solution to the PDE can be $\epsilon$-approximated in the $L^2$ sense by a function with Barron norm $O\left(\left(dB_L\right)^{\max\{p \log(1/ \epsilon), p^{\log(1/\epsilon)}\}}\right)$. By a classical result due to Barron (1993), this correspondingly bounds the size of a 2-layer neural network needed to approximate the solution. Treating $p, \epsilon, B_L$ as constants, this quantity is polynomial in dimension, thus showing neural networks can evade the curse of dimensionality. Our proof technique involves neurally simulating (preconditioned) gradient in an appropriate Hilbert space, which converges exponentially fast to the solution of the PDE, and such that we can bound the increase of the Barron norm at each iterate. Our results subsume and substantially generalize analogous prior results for linear elliptic PDEs over a unit hypercube.

**摘要:** 一个新兴的研究领域已经开发了深度神经网络,能够近似高维PDEs的解决方案,开辟了相关的理论研究领域,重点在于解释这些模型是如何逃避维度的诅咒。然而,迄今为止,大多数理论分析都局限于线性PDEs。在这个工作中,我们迈向研究神经网络对近似非线性PDEs的表示力的研究。我们证明,如果编写一个与巴伦规范 $b$ 的函数,与$L$ 的部分导数产生最多 $B_L b^p$ 的巴伦规范函数,那么对PDE 的解可以为 $\epsilon$ 的函数 $O\left(\left(dB_L\right)^{\max\{p \log(1/ \epsilon), p^{\log(1/\epsilon)}\}}\right)$ 在$L^2$ 意义下与巴伦规范函数 $O\left(\left(dB_L\right)^{\max\{p \log(1/ \epsilon), p^{\log(1/\epsilon)}\}}\right)$ 相近。

**[Paper URL](https://proceedings.mlr.press/v202/marwah23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/marwah23a/marwah23a.pdf)** 

# Generative Pretraining for Black-Box Optimization
**题目:** 黑箱优化的生成预训练

**作者:** Satvik Mehul Mashkaria, Siddarth Krishnamoorthy, Aditya Grover

**Abstract:** Many problems in science and engineering involve optimizing an expensive black-box function over a high-dimensional space. In the offline model-based optimization (MBO) setting, we assume access to a fixed, offline dataset for pretraining and a small budget for online function evaluations. Prior approaches seek to utilize the offline data to approximate the function or its inverse but are not sufficiently accurate far from the data distribution. We propose BONET, a generative framework for pretraining a novel model-based optimizer using offline datasets. In BONET, we train an autoregressive model on fixed-length trajectories derived from an offline dataset. We design a sampling strategy to synthesize trajectories from offline data using a simple heuristic of rolling out monotonic transitions from low-fidelity to high-fidelity samples. Empirically, we instantiate BONET using a causally masked Transformer (Radford et al., 2019) and evaluate it on Design-Bench (Trabucco et al., 2022), where we rank the best on average, outperforming state-of-the-art baselines.

**摘要:** 在科学和工程中有许多问题涉及在高维空间上优化一个昂贵的黑箱函数。在非线性模型优化(MBO)设置中,我们假定可以访问一个固定的非线性数据集,用于预训练和在线功能评估的少预算。以前的方法试图利用非线性数据来近似功能或其逆向,但与数据分布不十分精确。我们提出了BONET,一种基于非线性数据集的新型模型优化者预训练的生成框架。用因果掩盖的变形器(Radford et al., 2019)来实证 BONET,并在Design-Bench(Trabucco et al., 2022)上评估它,其中我们平均排名最佳,超过了最先进的基线。

**[Paper URL](https://proceedings.mlr.press/v202/mashkaria23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mashkaria23a/mashkaria23a.pdf)** 

# Improved Policy Evaluation for Randomized Trials of Algorithmic Resource Allocation
**题目:** 改进算法资源分配随机试验政策评价

**作者:** Aditya Mate, Bryan Wilder, Aparna Taneja, Milind Tambe

**Abstract:** We consider the task of evaluating policies of algorithmic resource allocation through randomized controlled trials (RCTs). Such policies are tasked with optimizing the utilization of limited intervention resources, with the goal of maximizing the benefits derived. Evaluation of such allocation policies through RCTs proves difficult, notwithstanding the scale of the trial, because the individuals’ outcomes are inextricably interlinked through resource constraints controlling the policy decisions. Our key contribution is to present a new estimator leveraging our proposed novel concept, that involves retrospective reshuffling of participants across experimental arms at the end of an RCT. We identify conditions under which such reassignments are permissible and can be leveraged to construct counterfactual trials, whose outcomes can be accurately ascertained, for free. We prove theoretically that such an estimator is more accurate than common estimators based on sample means – we show that it returns an unbiased estimate and simultaneously reduces variance. We demonstrate the value of our approach through empirical experiments on synthetic, semisynthetic as well as real case study data and show improved estimation accuracy across the board.

**摘要:** 我们考虑通过随机控制试验评估算法资源分配政策的任务。这些政策的任务是优化有限的干预资源的利用,以期最大化所获得的利益。尽管试验规模大,但通过控制试验评估这些资源分配政策是困难的,因为个人的成果是通过资源限制控制政策决策的不可分割地相互关联的。我们的主要贡献是提出一种新的估算器,利用我们提出的新概念,包括在试验结束时对参与者进行回顾性重新调整。我们从理论上证明,这种估算器比基于样品方法的一般估算器更准确 — — 我们证明它能返回不偏见的估算并同时减少变异。 我们通过对合成、半合成和实例研究数据的实证实验证明了我们的方法的价值,并全面显示了改进的估算精度。

**[Paper URL](https://proceedings.mlr.press/v202/mate23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mate23a/mate23a.pdf)** 

# Multi-Fidelity Covariance Estimation in the Log-Euclidean Geometry
**题目:** 逻辑欧几何中多实度协变估计

**作者:** Aimee Maurais, Terrence Alsup, Benjamin Peherstorfer, Youssef Marzouk

**Abstract:** We introduce a multi-fidelity estimator of covariance matrices that employs the log-Euclidean geometry of the symmetric positive-definite manifold. The estimator fuses samples from a hierarchy of data sources of differing fidelities and costs for variance reduction while guaranteeing definiteness, in contrast with previous approaches. The new estimator makes covariance estimation tractable in applications where simulation or data collection is expensive; to that end, we develop an optimal sample allocation scheme that minimizes the mean-squared error of the estimator given a fixed budget. Guaranteed definiteness is crucial to metric learning, data assimilation, and other downstream tasks. Evaluations of our approach using data from physical applications (heat conduction, fluid dynamics) demonstrate more accurate metric learning and speedups of more than one order of magnitude compared to benchmarks.

**摘要:** 本文介绍了一种采用对称正确定多边形的逻辑欧几里达几何的共变矩阵多可信度估计器。该估计器将不同可信度和减少共变成本的数据源层次结构中的样品结合起来,同时与以往方法相比,保证确定性。该新的估计器使共变估计在仿真或数据收集成本昂贵的应用程序中易于处理;为此,我们开发了一个优化的样品分配方案,以减少给定预算的估计器平均平方误差。保证的确定性对于计量学习、数据同化和其他下游任务至关重要。

**[Paper URL](https://proceedings.mlr.press/v202/maurais23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/maurais23a/maurais23a.pdf)** 

# Communication-Constrained Bandits under Additive Gaussian Noise
**题目:** 加热高斯噪声下通信受限制的 bandits

**作者:** Prathamesh Mayekar, Jonathan Scarlett, Vincent Y. F. Tan

**Abstract:** We study a distributed stochastic multi-armed bandit where a client supplies the learner with communication-constrained feedback based on the rewards for the corresponding arm pulls. In our setup, the client must encode the rewards such that the second moment of the encoded rewards is no more than $P$, and this encoded reward is further corrupted by additive Gaussian noise of variance $\sigma^2$; the learner only has access to this corrupted reward. For this setting, we derive an information-theoretic lower bound of $\Omega\left(\sqrt{\frac{KT}{\mathtt{SNR} \wedge1}} \right)$ on the minimax regret of any scheme, where $\mathtt{SNR}\coloneqq \frac{P}{\sigma^2}$, and $K$ and $T$ are the number of arms and time horizon, respectively. Furthermore, we propose a multi-phase bandit algorithm, $\mathtt{UE}\text{-}\mathtt{UCB}\text{++}$, which matches this lower bound to a minor additive factor. $\mathtt{UE}\text{-}\mathtt{UCB}\text{++}$ performs uniform exploration in its initial phases and then utilizes the upper confidence bound (UCB) bandit algorithm in its final phase. An interesting feature of $\mathtt{UE}\text{-}\mathtt{UCB}\text{++}$ is that the coarser estimates of the mean rewards formed during a uniform exploration phase help to refine the encoding protocol in the next phase, leading to more accurate mean estimates of the rewards in the subsequent phase. This positive reinforcement cycle is critical to reducing the number of uniform exploration rounds and closely matching our lower bound.

**摘要:** 我们研究了分布式随机多武器带子,其中一个客户端为学习者提供基于相应的手臂拉动的奖励的通信约束反馈。在我们的设置中,客户端必须编码奖励,使得编码奖励的第二个时刻不超过$P$,并且这种编码奖励进一步受加法加法的 variance $\sigma^2$的 Gaussian噪声破坏;学习者只能访问这种破坏的奖励。为此设置,我们从任何方案的最小遗憾上导出$\Omega\left(\sqrt{\frac{KT}{\mathtt{SNR} \wedge1}} \right)$信息理论下限,其中$\mathtt{SNR}\coloneqq \frac{P}{\sigma^2}$和$K$和$T$分别是武器和时空的数目。$\mathtt{UE}\text{-}\mathtt{UCB}\text{++}$在其初始阶段进行均匀探索,然后在其最后阶段使用上级信托边界(UCB)带子算法。$\mathtt{UE}\text{-}\mathtt{UCB}\text{++}$的一个有趣的特征是,在均匀探索阶段形成的平均奖励的粗糙估计有助于在下一个阶段改进编码协议,导致下一个阶段的奖励的平均估计更加准确。

**[Paper URL](https://proceedings.mlr.press/v202/mayekar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mayekar23a/mayekar23a.pdf)** 

# Nonparametric Density Estimation under Distribution Drift
**题目:** 分布漂流下的非参数密度估计

**作者:** Alessio Mazzetto, Eli Upfal

**Abstract:** We study nonparametric density estimation in non-stationary drift settings. Given a sequence of independent samples taken from a distribution that gradually changes in time, the goal is to compute the best estimate for the current distribution. We prove tight minimax risk bounds for both discrete and continuous smooth densities, where the minimum is over all possible estimates and the maximum is over all possible distributions that satisfy the drift constraints. Our technique handles a broad class of drift models and generalizes previous results on agnostic learning under drift.

**摘要:** 我们研究非参数密度估计在非静态漂移设置中。考虑到从一个随时间变化的分布中取出的独立样本的序列,目的是计算当前分布的最佳估计。我们证明了严格的最小风险边界,适用于离散和连续的平滑密度,其中最小值是所有可能估计的,最大值是满足漂移约束的所有可能分布的。

**[Paper URL](https://proceedings.mlr.press/v202/mazzetto23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mazzetto23a/mazzetto23a.pdf)** 

# PAC-Bayesian Generalization Bounds for Adversarial Generative Models
**题目:** 反向生成模型PAC-Bayesian一般化界限

**作者:** Sokhna Diarra Mbacke, Florence Clerc, Pascal Germain

**Abstract:** We extend PAC-Bayesian theory to generative models and develop generalization bounds for models based on the Wasserstein distance and the total variation distance. Our first result on the Wasserstein distance assumes the instance space is bounded, while our second result takes advantage of dimensionality reduction. Our results naturally apply to Wasserstein GANs and Energy-Based GANs, and our bounds provide new training objectives for these two. Although our work is mainly theoretical, we perform numerical experiments showing non-vacuous generalization bounds for Wasserstein GANs on synthetic datasets.

**摘要:** 我们将PAC-Bayesian理论扩展到生成模型,并为基于水星距离和总变异距离的模型开发一般化边界。我们的第一项水星距离的结果假设实例空间是有限的,而第二项结果则利用维度减少。我们的结果自然适用于水星GAN和基于能量的GAN,而我们的边界为这两者提供了新的训练目标。虽然我们的工作主要是理论的,我们在合成数据集上进行了数值实验,显示了水星GAN的非空的一般化边界。

**[Paper URL](https://proceedings.mlr.press/v202/mbacke23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mbacke23a/mbacke23a.pdf)** 

# Robustness in Multimodal Learning under Train-Test Modality Mismatch
**题目:**  tren-test模式不匹配下的多模式学习的鲁棒性

**作者:** Brandon Mckinzie, Vaishaal Shankar, Joseph Yitan Cheng, Yinfei Yang, Jonathon Shlens, Alexander T Toshev

**Abstract:** Multimodal learning is defined as learning over multiple heterogeneous input modalities such as video, audio, and text. In this work, we are concerned with understanding how models behave as the type of modalities differ between training and deployment, a situation that naturally arises in many applications of multimodal learning to hardware platforms. We present a multimodal robustness framework to provide a systematic analysis of common multimodal representation learning methods. Further, we identify robustness short-comings of these approaches and propose two intervention techniques leading to $1.5\times$-$4\times$ robustness improvements on three datasets, AudioSet, Kinetics-400 and ImageNet-Captions. Finally, we demonstrate that these interventions better utilize additional modalities, if present, to achieve competitive results of $44.2$ mAP on AudioSet 20K.

**摘要:** 多模学习定义为视频、音频和文本等多种异质输入模式的学习。在这项工作中,我们关注如何理解模型的行为模式类型在训练和部署之间不同,这是一个在许多硬件平台的多模学习应用中自然产生的情况。我们提出了一种多模鲁棒性框架,为提供共同多模表示学习方法的系统分析。此外,我们确定了这些方法的鲁棒性缺点,并提出了两个干预技术,导致3个数据集、AudioSet、Kinetics-400和ImageNet-Captions的鲁棒性改进。

**[Paper URL](https://proceedings.mlr.press/v202/mckinzie23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mckinzie23a/mckinzie23a.pdf)** 

# A Model-free Closeness-of-influence Test for Features in Supervised Learning
**题目:** 监督学习中特征的无模型影响程度测试

**作者:** Mohammad Mehrabi, Ryan A. Rossi

**Abstract:** Understanding the effect of a feature vector $x\in \mathbb{R}^d$ on the response value (label) $y\in \mathbb{R}$ is the cornerstone of many statistical learning problems. Ideally, it is desired to understand how a set of collected features combine together and influence the response value, but this problem is notoriously difficult, due to the high-dimensionality of data and limited number of labeled data points, among many others. In this work, we take a new perspective on this problem, and we study the question of assessing the difference of influence that the two given features have on the response value. We first propose a notion of closeness for the influence of features, and show that our definition recovers the familiar notion of the magnitude of coefficients in the parametric model. We then propose a novel method to test for the closeness of influence in general model-free supervised learning problems. Our proposed test can be used with finite number of samples with control on type I error rate, no matter the ground truth conditional law $\mathcal{L}(Y|X)$. We analyze the power of our test for two general learning problems i) linear regression, and ii) binary classification under mixture of Gaussian models, and show that under the proper choice of score function, an internal component of our test, with sufficient number of samples will achieve full statistical power. We evaluate our findings through extensive numerical simulations, specifically we adopt the datamodel framework (Ilyas, et al., 2022) for CIFAR-10 dataset to identify pairs of training samples with different influence on the trained model via optional black box training mechanisms.

**摘要:** 理解特征向量$x\in \mathbb{R}^d$对响应值(标签)的影响$y\in \mathbb{R}$是许多统计学学习问题的基石。理想情况下,人们希望了解收集到的特征如何结合并影响响应值,但由于数据的高维度和标记数据点的数量有限,这一问题在许多其他方面都十分困难。在这个工作中,我们对这一问题采取了新的视角,并研究了评估两个特征对响应值的影响差异的问题。我们首先提出了特征影响的近似概念,并证明了我们的定义恢复了参数模型中有关系数的大小的概念。我们分析了两个一般学习问题(i)线性回归和(ii)加索模型混合下的二进制分类的测试的有效性,并表明在适当选择分数函数下,我们测试的一个内部组成部分,具有足够数量的样品,将达到充分的统计力。我们通过广泛的数值模拟评估了我们的发现,具体采用了CIFAR-10数据集的数据模型框架(Ilyas, et al., 2022)来通过任意的黑盒训练机制识别不同影响训练模型的训练样品。

**[Paper URL](https://proceedings.mlr.press/v202/mehrabi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mehrabi23a/mehrabi23a.pdf)** 

# Stochastic Gradient Succeeds for Bandits
**题目:** 强盗的随机梯度成功

**作者:** Jincheng Mei, Zixin Zhong, Bo Dai, Alekh Agarwal, Csaba Szepesvari, Dale Schuurmans

**Abstract:** We show that the stochastic gradient bandit algorithm converges to a globally optimal policy at an $O(1/t)$ rate, even with a constant step size. Remarkably, global convergence of the stochastic gradient bandit algorithm has not been previously established, even though it is an old algorithm known to be applicable to bandits. The new result is achieved by establishing two novel technical findings: first, the noise of the stochastic updates in the gradient bandit algorithm satisfies a strong “growth condition” property, where the variance diminishes whenever progress becomes small, implying that additional noise control via diminishing step sizes is unnecessary; second, a form of “weak exploration” is automatically achieved through the stochastic gradient updates, since they prevent the action probabilities from decaying faster than $O(1/t)$, thus ensuring that every action is sampled infinitely often with probability $1$. These two findings can be used to show that the stochastic gradient update is already “sufficient” for bandits in the sense that exploration versus exploitation is automatically balanced in a manner that ensures almost sure convergence to a global optimum. These novel theoretical findings are further verified by experimental results.

**摘要:** 我们证明,随机梯度带子算法在$O(1/t)$率下达到全球最佳策略,即使具有一定步骤大小。 值得注意的是,随机梯度带子算法的全球收敛性尚未建立,尽管它是一个已知适用于带子的旧算法。 新的结果是建立两个新技术发现:首先,随机梯度带子算法中的随机更新的噪声满足了强的“增长条件”属性,在进度变小时变小,意味着通过减少步骤大小的额外的噪声控制是不必要的;其次,随机梯度更新自动实现“弱探索”的形式,因为它们防止行动概率比$O(1/t)$快衰变,从而确保每个行动都随机随机采样。这两个发现可以用来证明,随机梯度更新对 bandits已经“足够”,即探索与剥削是自动平衡的,以确保几乎确定的趋同到全球最佳。这些新理论发现还通过实验结果进一步验证。

**[Paper URL](https://proceedings.mlr.press/v202/mei23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mei23a/mei23a.pdf)** 

# Normalizing Flows for Interventional Density Estimation
**题目:** 干预密度估计的正常化流量

**作者:** Valentyn Melnychuk, Dennis Frauen, Stefan Feuerriegel

**Abstract:** Existing machine learning methods for causal inference usually estimate quantities expressed via the mean of potential outcomes (e.g., average treatment effect). However, such quantities do not capture the full information about the distribution of potential outcomes. In this work, we estimate the density of potential outcomes after interventions from observational data. For this, we propose a novel, fully-parametric deep learning method called Interventional Normalizing Flows. Specifically, we combine two normalizing flows, namely (i) a nuisance flow for estimating nuisance parameters and (ii) a target flow for parametric estimation of the density of potential outcomes. We further develop a tractable optimization objective based on a one-step bias correction for efficient and doubly robust estimation of the target flow parameters. As a result, our Interventional Normalizing Flows offer a properly normalized density estimator. Across various experiments, we demonstrate that our Interventional Normalizing Flows are expressive and highly effective, and scale well with both sample size and high-dimensional confounding. To the best of our knowledge, our Interventional Normalizing Flows are the first proper fully-parametric, deep learning method for density estimation of potential outcomes.

**摘要:** 因果推理现有的机器学习方法通常估计通过潜在结果的平均值表达的数量(例如平均治疗效果)。然而,这些数量不能获取关于潜在结果的分布的完整信息。在这项工作中,我们从观察数据中进行干预后估计潜在结果的密度。为此,我们提出了一种全新的,完全参数化的深入学习方法,即干预正常化流。具体而言,我们结合了两个正常化流,即(i)对估计参数的干扰流和(ii)对潜在结果的密度参数的参数估计目标流。通过各种实验,我们证明了我们的干预正常化流具有表达性和高效率,并且在样品大小和高维混淆条件下具有良好的尺度。根据我们所知,我们的干预正常化流是潜在结果密度估计的第一个适当的全参数、深度学习方法。

**[Paper URL](https://proceedings.mlr.press/v202/melnychuk23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/melnychuk23a/melnychuk23a.pdf)** 

# Reprogramming Pretrained Language Models for Antibody Sequence Infilling
**题目:** 反体序列填充的预设语言模型重编程

**作者:** Igor Melnyk, Vijil Chenthamarakshan, Pin-Yu Chen, Payel Das, Amit Dhurandhar, Inkit Padhi, Devleena Das

**Abstract:** Antibodies comprise the most versatile class of binding molecules, with numerous applications in biomedicine. Computational design of antibodies involves generating novel and diverse sequences, while maintaining structural consistency. Unique to antibodies, designing the complementarity-determining region (CDR), which determines the antigen binding affinity and specificity, creates its own unique challenges. Recent deep learning models have shown impressive results, however the limited number of known antibody sequence/structure pairs frequently leads to degraded performance, particularly lacking diversity in the generated sequences. In our work we address this challenge by leveraging Model Reprogramming (MR), which repurposes pretrained models on a source language to adapt to the tasks that are in a different language and have scarce data - where it may be difficult to train a high-performing model from scratch or effectively fine-tune an existing pre-trained model on the specific task. Specifically, we introduce ReprogBert in which a pretrained English language model is repurposed for protein sequence infilling - thus considers cross-language adaptation using less data. Results on antibody design benchmarks show that our model on low-resourced antibody sequence dataset provides highly diverse CDR sequences, up to more than a two-fold increase of diversity over the baselines, without losing structural integrity and naturalness. The generated sequences also demonstrate enhanced antigen binding specificity and virus neutralization ability. Code is available at https://github.com/IBM/ReprogBERT

**摘要:** 抗体是生物医学中应用最为广泛的结合分子类别,具有多种用途。抗体的计算设计涉及生成新颖和多样的序列,同时保持结构的一致性。抗体独特,设计决定抗原结合亲和性和特异性的互补性区域(CDR)是其独特的挑战。最近的深入学习模型显示出令人印象深刻的结果,然而,已知的抗体序列/结构对数有限往往导致性能下降,特别是在生成序列中缺乏多样性。在我们的工作中,我们利用模型重编程(MR)来解决这一挑战,它重新利用源语言的预处理模型来适应不同语言的任务,并具有较少的数据--在这些情况下,很难从零开始训练高性能模型,或者在特定任务上有效地调整现有预训练模型。具体地说,我们引入ReprogBert,其中预处理的英语语言模型被重新用于蛋白质序列填充 - - 从而考虑使用较少的数据进行跨语言的适应。抗体设计基准的结果表明,低资源抗体序列数据集的我们的模型提供了非常多样的CDR序列,在基准上增加了多倍的多样性,而不失去结构完整和自然性。生成的序列还显示了增强的抗原结合特异性和病毒中立能力。代码在 https://github.com/IBM/ReprogBERT

**[Paper URL](https://proceedings.mlr.press/v202/melnyk23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/melnyk23a/melnyk23a.pdf)** 

# Superhuman Fairness
**题目:** 超人公平

**作者:** Omid Memarrast, Linh Vu, Brian D Ziebart

**Abstract:** The fairness of machine learning-based decisions has become an increasingly important focus in the design of supervised machine learning methods. Most fairness approaches optimize a specified trade-off between performance measure(s) (e.g., accuracy, log loss, or AUC) and fairness metric(s) (e.g., demographic parity, equalized odds). This begs the question: are the right performance-fairness trade-offs being specified? We instead re-cast fair machine learning as an imitation learning task by introducing superhuman fairness, which seeks to simultaneously outperform human decisions on multiple predictive performance and fairness measures. We demonstrate the benefits of this approach given suboptimal decisions.

**摘要:** 基于机器学习的公平决策已成为监控机器学习方法设计中日益重要的焦点。大多数公平方法优化了性能指标(例如准确度、逻辑损失或AUC)和公平度量(例如人口平价、均衡概率)之间的特定交易权衡。这引发了以下问题:是否指定了正确的性能公平交易权衡?我们通过引入超人公平的方法重新cast公平机器学习作为模仿学习任务,以同时超越人类在多个预测性能和公平度量上做出的决定。

**[Paper URL](https://proceedings.mlr.press/v202/memarrast23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/memarrast23a/memarrast23a.pdf)** 

# A Model-Based Method for Minimizing CVaR and Beyond
**题目:** 一种基于模型的方法来最小化CVaR及 beyond

**作者:** Si Yi Meng, Robert M. Gower

**Abstract:** We develop a variant of the stochastic prox-linear method for minimizing the Conditional Value-at-Risk (CVaR) objective. CVaR is a risk measure focused on minimizing worst-case performance, defined as the average of the top quantile of the losses. In machine learning, such a risk measure is useful to train more robust models. Although the stochastic subgradient method (SGM) is a natural choice for minimizing the CVaR objective, we show that our stochastic prox-linear (SPL+) algorithm can better exploit the structure of the objective, while still providing a convenient closed form update. Our SPL+ method also adapts to the scaling of the loss function, which allows for easier tuning. We then specialize a general convergence theorem for SPL+ to our setting, and show that it allows for a wider selection of step sizes compared to SGM. We support this theoretical finding experimentally.

**摘要:** 我们开发了一种变异的随机近线性方法来最小化条件值在风险目标(CVaR)。CVaR是一个基于最小化最坏情况性能的风险度量,定义为损失的最高量值的平均值。在机器学习中,这种风险度量对于训练更强的模型有用。虽然随机降级方法(SGM)是最小化CVaR目标的自然选择,但我们证明我们的随机近线性(SPL+)算法能够更好地利用目标的结构,同时提供方便的闭式更新。

**[Paper URL](https://proceedings.mlr.press/v202/meng23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/meng23a/meng23a.pdf)** 

# Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
**题目:** 训练语言模型作为增强增强小步学习的训练数据生成器

**作者:** Yu Meng, Martin Michalski, Jiaxin Huang, Yu Zhang, Tarek Abdelzaher, Jiawei Han

**Abstract:** Recent studies have revealed the intriguing few-shot learning ability of pretrained language models (PLMs): They can quickly adapt to a new task when fine-tuned on a small amount of labeled data formulated as prompts, without requiring abundant task-specific annotations. Despite their promising performance, most existing few-shot approaches that only learn from the small training set still underperform fully supervised training by nontrivial margins. In this work, we study few-shot learning with PLMs from a different perspective: We first tune an autoregressive PLM on the few-shot samples and then use it as a generator to synthesize a large amount of novel training samples which augment the original training set. To encourage the generator to produce label-discriminative samples, we train it via weighted maximum likelihood where the weight of each token is automatically adjusted based on a discriminative meta-learning objective. A classification PLM can then be fine-tuned on both the few-shot and the synthetic samples with regularization for better generalization and stability. Our approach FewGen achieves an overall better result across seven classification tasks of the GLUE benchmark than existing few-shot learning methods, improving no-augmentation methods by 5+ average points, and outperforming augmentation methods by 3+ average points.

**摘要:** 最近的研究显示了预留语言模型(PLMs)的极具吸引力的少数射击学习能力:它们可以快速适应新的任务,在少量标记数据作为提示调制时,不需要大量的任务特有注释。尽管它们具有良好的性能,但大多数现有的少数射击方法只从小训练集合中学习,但仍不能通过非微不足道的边界完成完全监督训练。然后,一个分类PLM可以在少数射击和合成样品上进行精细调整,并进行校正,以提高一般化和稳定性。我们的方法 FewGen在GLUE基准的七项分类任务中比现有的少数射击学习方法取得较好的结果,提高了5+平均点的无增量方法和3+平均点的提高方法。

**[Paper URL](https://proceedings.mlr.press/v202/meng23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/meng23b/meng23b.pdf)** 

# On Preemption and Learning in Stochastic Scheduling
**题目:** 关于随机安排的预防与学习

**作者:** Nadav Merlis, Hugo Richard, Flore Sentenac, Corentin Odic, Mathieu Molina, Vianney Perchet

**Abstract:** We study single-machine scheduling of jobs, each belonging to a job type that determines its duration distribution. We start by analyzing the scenario where the type characteristics are known and then move to two learning scenarios where the types are unknown: non-preemptive problems, where each started job must be completed before moving to another job; and preemptive problems, where job execution can be paused in the favor of moving to a different job. In both cases, we design algorithms that achieve sublinear excess cost, compared to the performance with known types, and prove lower bounds for the non-preemptive case. Notably, we demonstrate, both theoretically and through simulations, how preemptive algorithms can greatly outperform non-preemptive ones when the durations of different job types are far from one another, a phenomenon that does not occur when the type durations are known.

**摘要:** 我们研究了单机调度工作,每个工作属于一个工作类型,决定其时间分布。我们首先分析了类型特征的场景,然后移动到两个未知类型的学习场景:非预防性问题,其中每个开始的工作必须完成,然后移动到另一个工作;以及预防性问题,其中工作执行可以被停顿以有利于移动到另一个工作。

**[Paper URL](https://proceedings.mlr.press/v202/merlis23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/merlis23a/merlis23a.pdf)** 

# Quantile Credit Assignment
**题目:** 量子信用分配

**作者:** Thomas Mesnard, Wenqi Chen, Alaa Saade, Yunhao Tang, Mark Rowland, Theophane Weber, Clare Lyle, Audrunas Gruslys, Michal Valko, Will Dabney, Georg Ostrovski, Eric Moulines, Remi Munos

**Abstract:** In reinforcement learning, the credit assignment problem is to distinguish luck from skill, that is, separate the inherent randomness in the environment from the controllable effects of the agent’s actions. This paper proposes two novel algorithms, Quantile Credit Assignment (QCA) and Hindsight QCA (HQCA), which incorporate distributional value estimation to perform credit assignment. QCA uses a network that predicts the quantiles of the return distribution, whereas HQCA additionally incorporates information about the future. Both QCA and HQCA have the appealing interpretation of leveraging an estimate of the quantile level of the return (interpreted as the level of "luck") in order to derive a "luck-dependent" baseline for policy gradient methods. We show theoretically that this approach gives an unbiased policy gradient estimate that can yield significant variance reductions over a standard value estimate baseline. QCA and HQCA significantly outperform prior state-of-the-art methods on a range of extremely difficult credit assignment problems.

**摘要:** 在强化学习中,信用分配问题是把运气与技能区分开来,即把环境中的随机性与代理行为的可控效应分开来。本文提出了两个新算法,量化信用分配(QCA)和隐性信用分配(HQCA),这些算法包含分配值估计来执行信用分配。QCA使用了一个预测回报分配的网络,而HQCA还包括关于未来的信息。QCA和HQCA都有利用返回量化水平的估计(解释为“运气”水平)来推导策略梯度方法的“运气依赖”基线的引人注目的解释。QCA和HQCA在一系列极为困难的信贷分配问题上大大超过了以往的最先进的方法。

**[Paper URL](https://proceedings.mlr.press/v202/mesnard23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mesnard23a/mesnard23a.pdf)** 

# Is Consensus Acceleration Possible in Decentralized Optimization over Slowly Time-Varying Networks?
**题目:** 在缓慢时间变化的网络上进行分散优化时,是否可以加快协商一致?

**作者:** Dmitry Metelev, Alexander Rogozin, Dmitry Kovalev, Alexander Gasnikov

**Abstract:** We consider decentralized optimization problems where one aims to minimize a sum of convex smooth objective functions distributed between nodes in the network. The links in the network can change from time to time. For the setting when the amount of changes is arbitrary, lower complexity bounds and corresponding optimal algorithms are known, and the consensus acceleration is not possible. However, in practice the magnitude of network changes may be limited. We derive lower complexity bounds for several regimes of velocity of networks changes. Moreover, we show how to obtain accelerated communication rates for a certain class of time-varying graphs using a specific consensus algorithm.

**摘要:** 我们考虑了分散优化问题,其中一个目标是尽量减少网络中节点间分布的凸滑目标函数的总数。网络中的链接可以随时间变化。在设置时,变化量是任意的,较低的复杂度边界和相应的优化算法是已知的,并且协商加速是不可能的。然而,在实践中,网络变化的幅度可能有限。

**[Paper URL](https://proceedings.mlr.press/v202/metelev23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/metelev23a/metelev23a.pdf)** 

# Towards Theoretical Understanding of Inverse Reinforcement Learning
**题目:** 逆强化学习的理论理解

**作者:** Alberto Maria Metelli, Filippo Lazzati, Marcello Restelli

**Abstract:** Inverse reinforcement learning (IRL) denotes a powerful family of algorithms for recovering a reward function justifying the behavior demonstrated by an expert agent. A well-known limitation of IRL is the ambiguity in the choice of the reward function, due to the existence of multiple rewards that explain the observed behavior. This limitation has been recently circumvented by formulating IRL as the problem of estimating the feasible reward set, i.e., the region of the rewards compatible with the expert’s behavior. In this paper, we make a step towards closing the theory gap of IRL in the case of finite-horizon problems with a generative model. We start by formally introducing the problem of estimating the feasible reward set, the corresponding PAC requirement, and discussing the properties of particular classes of rewards. Then, we provide the first minimax lower bound on the sample complexity for the problem of estimating the feasible reward set of order ${\Omega}\left( \frac{H^3SA}{\epsilon^2} \left( \log \left(\frac{1}{\delta}\right) + S \right)\right)$, being $S$ and $A$ the number of states and actions respectively, $H$ the horizon, $\epsilon$ the desired accuracy, and $\delta$ the confidence. We analyze the sample complexity of a uniform sampling strategy (US-IRL), proving a matching upper bound up to logarithmic factors. Finally, we outline several open questions in IRL and propose future research directions.

**摘要:** 逆强化学习(IRL)指一种用于恢复专家代理所表现的行为的奖励函数的强有力算法家族。IRL的一个众所周知的局限性是奖励函数的选择的模糊性,因为存在多个奖励,解释了观察到的行为。这一局限性最近通过IRL作为估计可行的奖励集的问题,即与专家行为相容的奖励区域,加以回避。然后,为估计可行的奖励集合的顺序 ${\Omega}\left( \frac{H^3SA}{\epsilon^2} \left( \log \left(\frac{1}{\delta}\right) + S \right)\right)$ 的样品复杂度提供第一个最小限度,分别是 $S$ 和 $A$ 的状态和行动数, $H$ 的水平, $\epsilon$ 的期望精度, 和 $\delta$ 的信心。

**[Paper URL](https://proceedings.mlr.press/v202/metelli23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/metelli23a/metelli23a.pdf)** 

# Quantum Policy Gradient Algorithm with Optimized Action Decoding
**题目:** 优化动作解码的量子策略梯度算法

**作者:** Nico Meyer, Daniel Scherer, Axel Plinge, Christopher Mutschler, Michael Hartmann

**Abstract:** Quantum machine learning implemented by variational quantum circuits (VQCs) is considered a promising concept for the noisy intermediate-scale quantum computing era. Focusing on applications in quantum reinforcement learning, we propose an action decoding procedure for a quantum policy gradient approach. We introduce a quality measure that enables us to optimize the classical post-processing required for action selection, inspired by local and global quantum measurements. The resulting algorithm demonstrates a significant performance improvement in several benchmark environments. With this technique, we successfully execute a full training routine on a 5-qubit hardware device. Our method introduces only negligible classical overhead and has the potential to improve VQC-based algorithms beyond the field of quantum reinforcement learning.

**摘要:** 变量量量子电路(VQCs)实现的量子机器学习被认为是噪声中级量子计算时代的一个有前途的概念。我们着重于量子增强学习的应用,提出了一种量子政策梯度方法的动作解码程序。我们引入了一种质量措施,使我们能够优化由局部和全球量子测量所启发的动作选择所需的经典后处理。由此产生的算法在多个基准环境中显示了显著的性能改进。

**[Paper URL](https://proceedings.mlr.press/v202/meyer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/meyer23a/meyer23a.pdf)** 

# Training Deep Surrogate Models with Large Scale Online Learning
**题目:** 大规模在线学习的 Deep Surrogate Models培训

**作者:** Lucas Thibaut Meyer, Marc Schouler, Robert Alexander Caulk, Alejandro Ribes, Bruno Raffin

**Abstract:** The spatiotemporal resolution of Partial Differential Equations (PDEs) plays important roles in the mathematical description of the world’s physical phenomena. In general, scientists and engineers solve PDEs numerically by the use of computationally demanding solvers. Recently, deep learning algorithms have emerged as a viable alternative for obtaining fast solutions for PDEs. Models are usually trained on synthetic data generated by solvers, stored on disk and read back for training. This paper advocates that relying on a traditional static dataset to train these models does not allow the full benefit of the solver to be used as a data generator. It proposes an open source online training framework for deep surrogate models. The framework implements several levels of parallelism focused on simultaneously generating numerical simulations and training deep neural networks. This approach suppresses the I/O and storage bottleneck associated with disk-loaded datasets, and opens the way to training on significantly larger datasets. Experiments compare the offline and online training of four surrogate models, including state-of-the-art architectures. Results indicate that exposing deep surrogate models to more dataset diversity, up to hundreds of GB, can increase model generalization capabilities. Fully connected neural networks, Fourier Neural Operator (FNO), and Message Passing PDE Solver prediction accuracy is improved by 68%, 16% and 7%, respectively.

**摘要:** 局部差分方程的时空分辨率在世界物理现象的数学描述中起着重要的作用。一般来说,科学家和工程师通过计算要求的求解者来数值求解PDEs。最近,深入学习算法已成为获得快速求解PDEs的可行的替代方案。模型通常是通过求解者生成的合成数据进行训练,存储在磁盘上并读回训练。本文主张,依靠传统的静态数据集来训练这些模型不能使求解者成为数据生成器的全部收益。该方法抑制了与磁盘载入的数据集有关的I/O和存储瓶颈,并打开了大量更大的数据集的培训之路。实验比较了四个替代模型的在线和非在线培训,包括最新架构。结果表明,对数据集多样性最大数百GB的深度替代模型的曝光,可以增加模型的通用化能力。

**[Paper URL](https://proceedings.mlr.press/v202/meyer23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/meyer23b/meyer23b.pdf)** 

# MANSA: Learning Fast and Slow in Multi-Agent Systems
**题目:** MANSA:多代理系统中的快速和缓慢学习

**作者:** David Henry Mguni, Haojun Chen, Taher Jafferjee, Jianhong Wang, Longfei Yue, Xidong Feng, Stephen Marcus Mcaleer, Feifei Tong, Jun Wang, Yaodong Yang

**Abstract:** In multi-agent reinforcement learning (MARL), independent learning (IL) often shows remarkable performance and easily scales with the number of agents. Yet, using IL can be inefficient and runs the risk of failing to successfully train, particularly in scenarios that require agents to coordinate their actions. Using centralised learning (CL) enables MARL agents to quickly learn how to coordinate their behaviour but employing CL everywhere is often prohibitively expensive in real-world applications. Besides, using CL in value-based methods often needs strong representational constraints (e.g. individual-global-max condition) that can lead to poor performance if violated. In this paper, we introduce a novel plug & play IL framework named Multi-Agent Network Selection Algorithm (MANSA) which selectively employs CL only at states that require coordination. At its core, MANSA has an additional agent that uses switching controls to quickly learn the best states to activate CL during training, using CL only where necessary and vastly reducing the computational burden of CL. Our theory proves MANSA preserves cooperative MARL convergence properties, boosts IL performance and can optimally make use of a fixed budget on the number CL calls. We show empirically in Level-based Foraging (LBF) and StarCraft Multi-agent Challenge (SMAC) that MANSA achieves fast, superior and more reliable performance while making 40% fewer CL calls in SMAC and using CL at only 1% CL calls in LBF.

**摘要:** 在多代理强化学习(MARL)中,独立学习(IL)经常表现出显著的性能,并易于与代理数量进行校正。然而,使用IL是效率低下的,并可能无法成功训练,特别是在需要代理协调其行动的场景中。使用集中学习(CL)使MARL代理能够快速学习如何协调其行为,但在现实应用中,使用CL在任何地方都往往非常昂贵。此外,在基于价值的方法中使用CL经常需要强的表示约束(例如个人-全球-最大条件),如果违反这些约束,则会导致性能低下。我们的理论证明,MANSA保留了协同的MARL收敛特性,增强了IL性能,并能够在数量的CL调用上最优化地利用固定预算。在Level-based Foraging(LBF)和StarCraft Multi-agent Challenge(SMAC)中,我们实验证明,MANSA在 SMAC中减少40%的CL调用的同时,实现快速、优越和更可靠的性能,而在LBF中只使用1%的CL调用。

**[Paper URL](https://proceedings.mlr.press/v202/mguni23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mguni23a/mguni23a.pdf)** 

# Representation Learning with Multi-Step Inverse Kinematics: An Efficient and Optimal Approach to Rich-Observation RL
**题目:** 多步逆动力学表现学习:rich-Observation RL的高效优化方法

**作者:** Zakaria Mhammedi, Dylan J Foster, Alexander Rakhlin

**Abstract:** We study the design of sample-efficient algorithms for reinforcement learning in the presence of rich, high-dimensional observations, formalized via the Block MDP problem. Existing algorithms suffer from either 1) computational intractability, 2) strong statistical assumptions that are not necessarily satisfied in practice, or 3) suboptimal sample complexity. We address these issues by providing the first computationally efficient algorithm that attains rate-optimal sample complexity with respect to the desired accuracy level, with minimal statistical assumptions. Our algorithm, MusIK, combines exploration with representation learning based on multi-step inverse kinematics, a learning objective in which the aim is to predict the current action from the current observation and observations in the (potentially distant) future. MusIK is simple and flexible, and can efficiently take advantage of general-purpose function approximation. Our analysis of MusIK leverages several new techniques tailored to non-optimistic algorithms for reward-free exploration, which we anticipate will find broader use.

**摘要:** 我们研究了通过 Block MDP问题形式化的丰富、高维观测的增强学习样本效率算法的设计。现有的算法 either 1) 具有计算的内在性, 2) 具有很强的统计假设,但不一定在实践中得到满足, 3) 具有低精度样本复杂性。我们通过提供第一个具有计算效率的算法来解决这些问题,以达到期望精度水平的率-最佳样本复杂性,并提供最小统计假设。我们对MusIK的分析利用了针对无奖赏探索的非优化算法的几种新技术,我们预计这些技术将得到更广泛的应用。

**[Paper URL](https://proceedings.mlr.press/v202/mhammedi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mhammedi23a/mhammedi23a.pdf)** 

# Single Point-Based Distributed Zeroth-Order Optimization with a Non-Convex Stochastic Objective Function
**题目:** 非凸随机目标函数的单点分布零序优化

**作者:** Elissa Mhanna, Mohamad Assaad

**Abstract:** Zero-order (ZO) optimization is a powerful tool for dealing with realistic constraints. On the other hand, the gradient-tracking (GT) technique proved to be an efficient method for distributed optimization aiming to achieve consensus. However, it is a first-order (FO) method that requires knowledge of the gradient, which is not always possible in practice. In this work, we introduce a zero-order distributed optimization method based on a one-point estimate of the gradient tracking technique. We prove that this new technique converges with a single noisy function query at a time in the non-convex setting. We then establish a convergence rate of $O(\frac{1}{\sqrt[3]{K}})$ after a number of iterations K, which competes with that of $O(\frac{1}{\sqrt[4]{K}})$ of its centralized counterparts. Finally, a numerical example validates our theoretical results.

**摘要:** 零阶优化是处理现实约束的强有力工具。另一方面,梯度跟踪技术证明是实现协商一致的分布优化的有效方法。然而,它是第一个阶(FO)方法,需要知识梯度,这在实践中并不总是可能。在这个工作中,我们介绍了基于梯度跟踪技术的一个点估计的零阶分布优化方法。

**[Paper URL](https://proceedings.mlr.press/v202/mhanna23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mhanna23a/mhanna23a.pdf)** 

# Learning Instance-Specific Augmentations by Capturing Local Invariances
**题目:** 通过捕捉局部变量来学习实例特定增强

**作者:** Ning Miao, Tom Rainforth, Emile Mathieu, Yann Dubois, Yee Whye Teh, Adam Foster, Hyunjik Kim

**Abstract:** We introduce InstaAug, a method for automatically learning input-specific augmentations from data. Previous methods for learning augmentations have typically assumed independence between the original input and the transformation applied to that input. This can be highly restrictive, as the invariances we hope our augmentation will capture are themselves often highly input dependent. InstaAug instead introduces a learnable invariance module that maps from inputs to tailored transformation parameters, allowing local invariances to be captured. This can be simultaneously trained alongside the downstream model in a fully end-to-end manner, or separately learned for a pre-trained model. We empirically demonstrate that InstaAug learns meaningful input-dependent augmentations for a wide range of transformation classes, which in turn provides better performance on both supervised and self-supervised tasks.

**摘要:** 我们介绍了InstaAug,一种自动从数据中学习输入特定增量的方法。以往学习增量的方法通常假设了原始输入和对该输入的转换之间的独立性。这可非常限制性,因为我们希望我们的增量能够捕捉的变量往往是高度的输入依赖性。InstaAug则引入了一个可学习的变量模块,它将从输入映射到定制的变量参数,允许本地变量被捕捉。

**[Paper URL](https://proceedings.mlr.press/v202/miao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/miao23a/miao23a.pdf)** 

# Path Neural Networks: Expressive and Accurate Graph Neural Networks
**题目:** 路径神经网络:表达式和准确的图形神经网络

**作者:** Gaspard Michel, Giannis Nikolentzos, Johannes F. Lutzeyer, Michalis Vazirgiannis

**Abstract:** Graph neural networks (GNNs) have recently become the standard approach for learning with graph-structured data. Prior work has shed light into their potential, but also their limitations. Unfortunately, it was shown that standard GNNs are limited in their expressive power. These models are no more powerful than the 1-dimensional Weisfeiler-Leman (1-WL) algorithm in terms of distinguishing non-isomorphic graphs. In this paper, we propose Path Neural Networks (PathNNs), a model that updates node representations by aggregating paths emanating from nodes. We derive three different variants of the PathNN model that aggregate single shortest paths, all shortest paths and all simple paths of length up to K. We prove that two of these variants are strictly more powerful than the 1-WL algorithm, and we experimentally validate our theoretical results. We find that PathNNs can distinguish pairs of non-isomorphic graphs that are indistinguishable by 1-WL, while our most expressive PathNN variant can even distinguish between 3-WL indistinguishable graphs. The different PathNN variants are also evaluated on graph classification and graph regression datasets, where in most cases, they outperform the baseline methods.

**摘要:** 图形神经网络(GNN)最近成为图形结构数据学习的标准方法。以前的工作已经把光线投射到它们的潜力中,同时也显示了它们的局限性。不幸的是,标准GNN在表达能力上有限。这些模型在区分非同型图形方面没有比1-维Weisfeiler-Leman(1-WL)算法更强大。我们发现,PathNN可以区分1WL无法区分的非同型图的两对,而我们最明显的PathNN变量甚至可以区分3WL无法区分的图。不同的PathNN变量也在图分类和图回归数据集中进行评估,其中在大多数情况下,它们超过了基线方法。

**[Paper URL](https://proceedings.mlr.press/v202/michel23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/michel23a/michel23a.pdf)** 

# Learning to acquire novel cognitive tasks with evolution, plasticity and meta-meta-learning
**题目:** 学习以进化、塑性和元元元学习来获取新的认知任务

**作者:** Thomas Miconi

**Abstract:** A hallmark of intelligence is the ability to autonomously learn new flexible, cognitive behaviors - that is, behaviors where the appropriate action depends not just on immediate stimuli (as in simple reflexive stimulus-response associations), but on contextual information that must be adequately acquired, stored and processed. While many meta-learning algorithms can design agents that autonomously learn new tasks, cognitive tasks adds another level of learning and memory to typical “learning-to-learn” problems. Here we evolve neural networks, endowed with plastic connections and neuromodulation, over a sizable set of simple cognitive tasks adapted from a computational neuroscience framework. The resulting evolved networks can automatically modify their own connectivity to acquire a novel simple cognitive task, never seen during evolution, from stimuli and rewards alone, through the spontaneous operation of their evolved neural organization and plasticity system. Our results emphasize the importance of carefully considering the multiple learning loops involved in the emergence of intelligent behavior.

**摘要:** 智力的一个特征是能够自主学习新的灵活的认知行为,即行为的适当行为不仅取决于直接的刺激(如简单的反射性刺激-响应关联),而且取决于必须获得、储存和处理的上下文信息。虽然许多元学习算法能够设计能够自主学习新任务的代理,但认知任务将增加学习和记忆的另一个水平到典型的“学习到学习”问题。研究结果表明,在智能行为的产生过程中,必须仔细考虑多方面的学习循环。

**[Paper URL](https://proceedings.mlr.press/v202/miconi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/miconi23a/miconi23a.pdf)** 

# Generative Decoding of Visual Stimuli
**题目:** 视觉刺激的生成解码

**作者:** Eleni Miliotou, Panagiotis Kyriakis, Jason D Hinman, Andrei Irimia, Paul Bogdan

**Abstract:** Reconstructing natural images from fMRI recordings is a challenging task of great importance in neuroscience. The current architectures are bottlenecked because they fail to effectively capture the hierarchical processing of visual stimuli that takes place in the human brain. Motivated by that fact, we introduce a novel neural network architecture for the problem of neural decoding. Our architecture uses Hierarchical Variational Autoencoders (HVAEs) to learn meaningful representations of natural images and leverages their latent space hierarchy to learn voxel-to-image mappings. By mapping the early stages of the visual pathway to the first set of latent variables and the higher visual cortex areas to the deeper layers in the latent hierarchy, we are able to construct a latent variable neural decoding model that replicates the hierarchical visual information processing. Our model achieves better reconstructions compared to the state of the art and our ablation study indicates that the hierarchical structure of the latent space is responsible for that performance.

**摘要:** 从fMRI记录中重建自然图像是神经科学中非常重要的挑战性任务。目前的架构因无法有效地捕捉在人类大脑中发生的视觉刺激的层次处理而陷入瓶颈。基于这一事实,我们引入了一种新的神经网络架构来解决神经解码问题。我们的架构使用层次变异自动编码器(HVAEs)学习自然图像的有意义表现,并利用它们的潜在空间层次结构来学习 voxel-to-image映射。我们的模型与现时的工艺相比具有较好的重建效果,而我们的研究表明,潜伏空间的层次结构是这一表现的依据。

**[Paper URL](https://proceedings.mlr.press/v202/miliotou23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/miliotou23a/miliotou23a.pdf)** 

# Cooperative Multi-Agent Reinforcement Learning: Asynchronous Communication and Linear Function Approximation
**题目:** 合作多代理强化学习:非同步通信与线性函数近似

**作者:** Yifei Min, Jiafan He, Tianhao Wang, Quanquan Gu

**Abstract:** We study multi-agent reinforcement learning in the setting of episodic Markov decision processes, where many agents cooperate via communication through a central server. We propose a provably efficient algorithm based on value iteration that can simultaneously allow asynchronous communication and guarantee the benefit of cooperation with low communication complexity. Under linear function approximation, we prove that our algorithm enjoys a $\tilde{\mathcal{O}}(d^{3/2}H^2\sqrt{K})$ regret upper bound with $\tilde{\mathcal{O}}(dHM^2)$ communication complexity, where $d$ is the feature dimension, $H$ is the horizon length, $M$ is the total number of agents, and $K$ is the total number of episodes. We also provide a lower bound showing that an $\Omega(dM)$ communication complexity is necessary to improve the performance through collaboration.

**摘要:** 我们研究了基于值迭代的可证明有效的算法,可以同时允许异步通信,并保证与低通信复杂度的合作收益。在线性函数近似下,我们证明了我们的算法具有:$\tilde{\mathcal{O}}(d^{3/2}H^2\sqrt{K})$ regret upper bound with $\tilde{\mathcal{O}}(dHM^2)$ communication complexity, where $d$ is the feature dimension, $H$ is the horizon length, $M$ is the total number of agents, and $K$ is the total number of episodes。

**[Paper URL](https://proceedings.mlr.press/v202/min23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/min23a/min23a.pdf)** 

# Directed Chain Generative Adversarial Networks
**题目:** 直接链生成敌对网络

**作者:** Ming Min, Ruimeng Hu, Tomoyuki Ichiba

**Abstract:** Real-world data can be multimodal distributed, e.g., data describing the opinion divergence in a community, the interspike interval distribution of neurons, and the oscillators natural frequencies. Generating multimodal distributed real-world data has become a challenge to existing generative adversarial networks (GANs). For example, it is often observed that Neural SDEs have only demonstrated successfully performance mainly in generating unimodal time series datasets. In this paper, we propose a novel time series generator, named directed chain GANs (DC-GANs), which inserts a time series dataset (called a neighborhood process of the directed chain or input) into the drift and diffusion coefficients of the directed chain SDEs with distributional constraints. DC-GANs can generate new time series of the same distribution as the neighborhood process, and the neighborhood process will provide the key step in learning and generating multimodal distributed time series. The proposed DC-GANs are examined on four datasets, including two stochastic models from social sciences and computational neuroscience, and two real-world datasets on stock prices and energy consumption. To our best knowledge, DC-GANs are the first work that can generate multimodal time series data and consistently outperforms state-of-the-art benchmarks with respect to measures of distribution, data similarity, and predictive ability.

**摘要:** 实物数据可以多模分布,例如描述社区意见差异、神经元间隔分布和振荡器自然频率的数据。多模分布实物数据的生成已成为现有的生成敌对网络(GANs)的挑战。例如,人们经常观察到神经元DSEs只有在生成单模时间序列数据集方面成功表现。研究了四个数据集,包括两个社会科学和计算神经科学的随机模型,以及两个股票价格和能源消耗的现实数据集。根据我们所知,DC-GAN是能够产生多模时间序列数据的第一个工作,并且在分布、数据相似性和预测能力方面始终超过了最先进的基准。

**[Paper URL](https://proceedings.mlr.press/v202/min23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/min23b/min23b.pdf)** 

# An Information-Theoretic Analysis of Nonstationary Bandit Learning
**题目:** 非静态强盗学习信息理论分析

**作者:** Seungki Min, Daniel Russo

**Abstract:** In nonstationary bandit learning problems, the decision-maker must continually gather information and adapt their action selection as the latent state of the environment evolves. In each time period, some latent optimal action maximizes expected reward under the environment state. We view the optimal action sequence as a stochastic process, and take an information-theoretic approach to analyze attainable performance. We bound per-period regret in terms of the entropy rate of the optimal action process. The bound applies to a wide array of problems studied in the literature and reflects the problem’s information structure through its information-ratio.

**摘要:** 在非静态 bandit学习问题中,决策者必须不断收集信息并随着环境 latent状态的演变而调整其行动选择。在每个时间段中,某些 latent最佳行动在环境状态下最大化预期的回报。我们把最佳行动序列看作随机过程,并采取信息理论的方法来分析可实现的性能。

**[Paper URL](https://proceedings.mlr.press/v202/min23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/min23c/min23c.pdf)** 

# On the Convergence of Gradient Flow on Multi-layer Linear Models
**题目:** 多层线性模型梯度流的趋同问题

**作者:** Hancheng Min, Rene Vidal, Enrique Mallada

**Abstract:** In this paper, we analyze the convergence of gradient flow on a multi-layer linear model with a loss function of the form $f(W_1W_2\cdots W_L)$. We show that when $f$ satisfies the gradient dominance property, proper weight initialization leads to exponential convergence of the gradient flow to a global minimum of the loss. Moreover, the convergence rate depends on two trajectory-specific quantities that are controlled by the weight initialization: the imbalance matrices, which measure the difference between the weights of adjacent layers, and the least singular value of the weight product $W=W_1W_2\cdots W_L$. Our analysis exploits the fact that the gradient of the overparameterized loss can be written as the composition of the non-overparametrized gradient with a time-varying (weight-dependent) linear operator whose smallest eigenvalue controls the convergence rate. The key challenge we address is to derive a uniform lower bound for this time-varying eigenvalue that lead to improved rates for several multi-layer network models studied in the literature.

**摘要:** 本文分析了一种多层线性模型的梯度流的收敛性,其损失函数为$f(W_1W_2\cdots W_L)$。我们证明,当$f$满足梯度主导性属性时,适当的重量初始化导致梯度流的指数收敛到损失的全球最小值。此外,收敛率取决于由重量初始化控制的两个轨迹特定量:相邻层的重量之间的差异和重量产物的最小单一值:不平衡矩阵。解决的关键挑战是为这一时间变化的固有值求出一个统一的较低的界限,从而提高文献中研究的若干多层网络模型的速率。

**[Paper URL](https://proceedings.mlr.press/v202/min23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/min23d/min23d.pdf)** 

# Optimal Sets and Solution Paths of ReLU Networks
**题目:** ReLU网络的最佳设置和解决方案路径

**作者:** Aaron Mishkin, Mert Pilanci

**Abstract:** We develop an analytical framework to characterize the set of optimal ReLU neural networks by reformulating the non-convex training problem as a convex program. We show that the global optima of the convex parameterization are given by a polyhedral set and then extend this characterization to the optimal set of the non-convex training objective. Since all stationary points of the ReLU training problem can be represented as optima of sub-sampled convex programs, our work provide a general expression for all critical points of the non-convex objective. We then leverage our results to provide an optimal pruning algorithm for computing minimal networks, establish conditions for the regularization path of ReLU networks to be continuous, and develop sensitivity results for minimal ReLU networks.

**摘要:** 通过将非凸训练问题归纳为凸程序,开发了一种分析框架来描述最佳的ReLU神经网络。我们表明,凸参数化的全球优化是由多面体集合给出的,然后将其扩展到非凸训练目标的优化集合。由于ReLU训练问题的所有静态点可以作为分样凸程序的优化,我们的工作为非凸目标的所有关键点提供了一般表达式。然后,我们利用我们的结果,为计算最小网络提供最优剪切算法,为ReLU网络的正常化路径建立条件,并开发最小ReLU网络的敏感性结果。

**[Paper URL](https://proceedings.mlr.press/v202/mishkin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mishkin23a/mishkin23a.pdf)** 

# The Numerical Stability of Hyperbolic Representation Learning
**题目:** 超位表示学习的数值稳定性

**作者:** Gal Mishne, Zhengchao Wan, Yusu Wang, Sheng Yang

**Abstract:** The hyperbolic space is widely used for representing hierarchical datasets due to its ability to embed trees with small distortion. However, this property comes at a price of numerical instability such that training hyperbolic learning models will sometimes lead to catastrophic NaN problems, encountering unrepresentable values in floating point arithmetic. In this work, we analyze the limitations of two popular models for the hyperbolic space, namely, the Poincaré ball and the Lorentz model. We find that, under the 64-bit arithmetic system, the Poincaré ball has a relatively larger capacity than the Lorentz model for correctly representing points. However, the Lorentz model is superior to the Poincaré ball from the perspective of optimization, which we theoretically validate. To address these limitations, we identify one Euclidean parametrization of the hyperbolic space which can alleviate these issues. We further extend this Euclidean parametrization to hyperbolic hyperplanes and demonstrate its effectiveness in improving the performance of hyperbolic SVM.

**摘要:** 高分子空间被广泛用于表述层次数据集,因为它能够嵌入小扭曲的树木。然而,这种特性的代价是数值不稳定,例如,训练高分子学习模型有时会导致灾难性NaN问题,在浮点算术中会遇到无法表述的值。在这个工作中,我们分析了高分子空间的两个流行模型的局限性,即Poincaré球和Lorentz模型。我们发现,在64位数系统下,Poincaré球比Lorentz模型具有较好的正确表示点的能力。然而,Lorentz模型在优化方面优于Poincaré球,我们对此进行了理论验证。进一步将欧几里达参数化扩展到高分子超平面,并证明其在提高高分子VM性能方面的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/mishne23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mishne23a/mishne23a.pdf)** 

# DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature
**题目:** DetectGPT:使用概率曲线的零射机生成文本检测

**作者:** Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D Manning, Chelsea Finn

**Abstract:** The increasing fluency and widespread usage of large language models (LLMs) highlight the desirability of corresponding tools aiding detection of LLM-generated text. In this paper, we identify a property of the structure of an LLM’s probability function that is useful for such detection. Specifically, we demonstrate that text sampled from an LLM tends to occupy negative curvature regions of the model’s log probability function. Leveraging this observation, we then define a new curvature-based criterion for judging if a passage is generated from a given LLM. This approach, which we call DetectGPT, does not require training a separate classifier, collecting a dataset of real or generated passages, or explicitly watermarking generated text. It uses only log probabilities computed by the model of interest and random perturbations of the passage from another generic pre-trained language model (e.g., T5). We find DetectGPT is more discriminative than existing zero-shot methods for model sample detection, notably improving detection of fake news articles generated by 20B parameter GPT-NeoX from 0.81 AUROC for the strongest zero-shot baseline to 0.95 AUROC for DetectGPT.

**摘要:** 大型语言模型(LLM)的灵活性和广泛使用突出了对LLM生成文本的检测提供相应的工具的必要性。本论文中,我们确定了LLM概率函数结构的属性,对于这种检测有用。具体地说,我们证明从LLM抽取的文本倾向于占有模型的逻辑概率函数的负曲率区域。利用这一观察,我们定义了判断是否从给定的LLM生成一段的曲率基准的新标准。我们发现,检测GPT比现有的零射程检测方法更具有歧视性,特别是改进了由20B参数GPT-NeoX生成的假新闻文章的检测,从最强的零射程基线的0.81 AUROC到检测GPT的0.95 AUROC。

**[Paper URL](https://proceedings.mlr.press/v202/mitchell23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mitchell23a/mitchell23a.pdf)** 

# Diffusion Based Representation Learning
**题目:** 基于扩散的代表学习

**作者:** Sarthak Mittal, Korbinian Abstreiter, Stefan Bauer, Bernhard Schölkopf, Arash Mehrjou

**Abstract:** Diffusion-based methods, represented as stochastic differential equations on a continuous-time domain, have recently proven successful as non-adversarial generative models. Training such models relies on denoising score matching, which can be seen as multi-scale denoising autoencoders. Here, we augment the denoising score matching framework to enable representation learning without any supervised signal. GANs and VAEs learn representations by directly transforming latent codes to data samples. In contrast, the introduced diffusion-based representation learning relies on a new formulation of the denoising score matching objective and thus encodes the information needed for denoising. We illustrate how this difference allows for manual control of the level of details encoded in the representation. Using the same approach, we propose to learn an infinite-dimensional latent code that achieves improvements on state-of-the-art models on semi-supervised image classification. We also compare the quality of learned representations of diffusion score matching with other methods like autoencoder and contrastively trained systems through their performances on downstream tasks. Finally, we also ablate with a different SDE formulation for diffusion models and show that the benefits on downstream tasks are still present on changing the underlying differential equation.

**摘要:** 基于扩散的方法,在连续时间域中表现为随机微分方程,最近证明了作为非敌对的生成模型的成功。训练这些模型依赖于扩散分数匹配,可视作多尺度的扩散自动编码器。在这里,我们增加了扩散分数匹配框架,使无监督信号的表示学习得以实现。GAN和VAEs通过直接转换延迟代码到数据样本学习表示。通过对下游任务的性能进行比较,还比较了分布分数匹配的学习表现与自动编码器和对比训练系统等其他方法的质量。最后,还给出了不同SDE公式的分布模型,表明下游任务的收益仍然存在于改变基本的微分方程。

**[Paper URL](https://proceedings.mlr.press/v202/mittal23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mittal23a/mittal23a.pdf)** 

# Disentangled Multiplex Graph Representation Learning
**题目:** 分散多重图表表示学习

**作者:** Yujie Mo, Yajie Lei, Jialie Shen, Xiaoshuang Shi, Heng Tao Shen, Xiaofeng Zhu

**Abstract:** Unsupervised multiplex graph representation learning (UMGRL) has received increasing interest, but few works simultaneously focused on the common and private information extraction. In this paper, we argue that it is essential for conducting effective and robust UMGRL to extract complete and clean common information, as well as more-complementarity and less-noise private information. To achieve this, we first investigate disentangled representation learning for the multiplex graph to capture complete and clean common information, as well as design a contrastive constraint to preserve the complementarity and remove the noise in the private information. Moreover, we theoretically analyze that the common and private representations learned by our method are provably disentangled and contain more task-relevant and less task-irrelevant information to benefit downstream tasks. Extensive experiments verify the superiority of the proposed method in terms of different downstream tasks.

**摘要:** 无监督的多维图表表示学习(UMGRL)得到了越来越多的兴趣,但少数工作同时集中于共同和私人信息提取。本论文认为,进行有效的鲁棒UMGRL来提取完整的和清洁的共同信息,以及更完整的和较少噪声的私人信息是必不可少的。为此,我们首先研究了多维图的分离表示学习,以捕捉完整的和清洁的共同信息,并设计了保持互补性并消除私人信息中的噪声的对比约束。此外,我们从理论上分析了通过我们的方法学习的共同和私人表示具有可证明的分离性,并包含更多与任务相关的和较少与任务相关的信息,以有利于下游任务。

**[Paper URL](https://proceedings.mlr.press/v202/mo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mo23a/mo23a.pdf)** 

# A Unified Audio-Visual Learning Framework for Localization, Separation, and Recognition
**题目:** 统一的视听学习框架,用于定位、分离和识别

**作者:** Shentong Mo, Pedro Morgado

**Abstract:** The ability to accurately recognize, localize and separate sound sources is fundamental to any audio-visual perception task. Historically, these abilities were tackled separately, with several methods developed independently for each task. However, given the interconnected nature of source localization, separation, and recognition, independent models are likely to yield suboptimal performance as they fail to capture the interdependence between these tasks. To address this problem, we propose a unified audio-visual learning framework (dubbed OneAVM) that integrates audio and visual cues for joint localization, separation, and recognition. OneAVM comprises a shared audio-visual encoder and task-specific decoders trained with three objectives. The first objective aligns audio and visual representations through a localized audio-visual correspondence loss. The second tackles visual source separation using a traditional mix-and-separate framework. Finally, the third objective reinforces visual feature separation and localization by mixing images in pixel space and aligning their representations with those of all corresponding sound sources. Extensive experiments on MUSIC, VGG-Instruments, VGG-Music, and VGGSound datasets demonstrate the effectiveness of OneAVM for all three tasks, audio-visual source localization, separation, and nearest neighbor recognition, and empirically demonstrate a strong positive transfer between them.

**摘要:** 准确识别、定位和分离声源的能力对于任何音频视觉感知任务是至关重要的。从历史上看,这些能力被单独处理,每个任务都有几个独立开发的方法。然而,由于源定位、分离和识别的相互关联性,独立的模型可能产生亚最佳性能,因为它们无法捕捉这些任务之间的相互依存性。为了解决这个问题,我们提出了一种统一的音频视觉学习框架(双重 OneAVM),它将集成音频和视觉信号来共同定位、分离和识别。 OneAVM包括一个共享的音频视觉编码器和三个目标训练的特定任务编码器。最后,第三个目标通过在像素空间中混合图像并将它们的表示与所有相应的音源的表示相匹配,加强视觉特征分离和定位。在MUSIC、VGG-Instruments、VGG-Music和VGGSound数据集上进行了广泛的实验,证明OneAVM在三个任务,音频-视觉源定位、分离和最接近的邻居识别中具有有效性,并通过实验证明它们之间具有很强的正向传输。

**[Paper URL](https://proceedings.mlr.press/v202/mo23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mo23b/mo23b.pdf)** 

# Pruning via Sparsity-indexed ODE: a Continuous Sparsity Viewpoint
**题目:** 通过节余指数的ODE Pruning:一个持续的节余视角

**作者:** Zhanfeng Mo, Haosen Shi, Sinno Jialin Pan

**Abstract:** Neural pruning, which involves identifying the optimal sparse subnetwork, is a key technique for reducing the complexity and improving the efficiency of deep neural networks. To address the challenge of solving neural pruning at a specific sparsity level directly, we investigate the evolution of optimal subnetworks with continuously increasing sparsity, which can provide insight into how to transform an unpruned dense model into an optimal subnetwork with any desired level of sparsity. In this paper, we proposed a novel pruning framework, coined Sparsity-indexed ODE (SpODE) that provides explicit guidance on how to best preserve model performance while ensuring an infinitesimal increase in model sparsity. On top of this, we develop a pruning algorithm, termed Pruning via Sparsity-indexed ODE (PSO), that enables effective pruning via traveling along the SpODE path. Empirical experiments show that PSO achieves either better or comparable performance compared to state-of-the-art baselines across various pruning settings.

**摘要:** 神经剪切(英语:Neural pruning)是识别最优稀疏子网络的关键技术,以减少复杂性和提高深度神经网络的效率。为了解决在特定稀疏水平解决神经剪切的挑战,我们对不断增加稀疏的最优子网络的演化进行了研究,可以提供对如何将不稀疏的密集模型转化为任意的稀疏水平的最优子网络的洞察。实证实验表明,PSO在不同剪切环境中具有较好的或可比的性能,与最先进的基线相比。

**[Paper URL](https://proceedings.mlr.press/v202/mo23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mo23c/mo23c.pdf)** 

# Text-To-Concept (and Back) via Cross-Model Alignment
**题目:** Text-To-Concept (和Back) 通过交叉模型排列

**作者:** Mazda Moayeri, Keivan Rezaei, Maziar Sanjabi, Soheil Feizi

**Abstract:** We observe that the mapping between an image’s representation in one model to its representation in another can be learned surprisingly well with just a linear layer, even across diverse models. Building on this observation, we propose text-to-concept, where features from a fixed pretrained model are aligned linearly to the CLIP space, so that text embeddings from CLIP’s text encoder become directly comparable to the aligned features. With text-to-concept, we convert fixed off-the-shelf vision encoders to surprisingly strong zero-shot classifiers for free, with accuracy at times even surpassing that of CLIP, despite being much smaller models and trained on a small fraction of the data compared to CLIP. We show other immediate use-cases of text-to-concept, like building concept bottleneck models with no concept supervision, diagnosing distribution shifts in terms of human concepts, and retrieving images satisfying a set of text-based constraints. Lastly, we demonstrate the feasibility of concept-to-text, where vectors in a model’s feature space are decoded by first aligning to the CLIP before being fed to a GPT-based generative model. Our work suggests existing deep models, with presumably diverse architectures and training, represent input samples relatively similarly, and a two-way communication across model representation spaces and to humans (through language) is viable.

**摘要:** 我们观察到,一个模型中的图像的映射与另一个模型中的图像的映射之间的映射,即使在不同模型之间,只要使用线性层就能令人惊奇地很好地学习。基于这一观察,我们提出了文本到概念,由固定预先模型的特征线性地排列到CLIP空间中,使CLIP的文本编码器中的文本嵌入成为直接与排列特征相比较。最后,我们证明了概念到文本的可行性,在模型特征空间中的向量首先通过对CLIP进行排列,然后被输入到基于GPT的生成模型中去解码。我们的研究表明,现有的深层模型,具有可能多样的架构和训练,代表输入样本相对相似,并且在模型表示空间和人类之间(通过语言)的双向通信是可行的。

**[Paper URL](https://proceedings.mlr.press/v202/moayeri23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/moayeri23a/moayeri23a.pdf)** 

# A Fast, Well-Founded Approximation to the Empirical Neural Tangent Kernel
**题目:** 快速、良好的近似经验神经 Tangent 核

**作者:** Mohamad Amin Mohamadi, Wonho Bae, Danica J. Sutherland

**Abstract:** Empirical neural tangent kernels (eNTKs) can provide a good understanding of a given network’s representation: they are often far less expensive to compute and applicable more broadly than infinite-width NTKs. For networks with $O$ output units (e.g. an $O$-class classifier), however, the eNTK on $N$ inputs is of size $NO \times NO$, taking $\mathcal O\big( (N O)^2\big)$ memory and up to $\mathcal O\big( (N O)^3 \big)$ computation to use. Most existing applications have therefore used one of a handful of approximations yielding $N \times N$ kernel matrices, saving orders of magnitude of computation, but with limited to no justification. We prove that one such approximation, which we call "sum of logits," converges to the true eNTK at initialization. Our experiments demonstrate the quality of this approximation for various uses across a range of settings.

**摘要:** 对于具有$O$输出单元(例如$O$类分类器)的网络,然而,eNTK在$N$输入的大小是$NO \times NO$,以$\mathcal O\big((N O)^2\big)$内存和最大$\mathcal O\big((N O)^3 \big)$计算为使用。因此,大多数现有的应用程序都使用了少数的近似,产生$N \times N$内核矩阵,节省计算规模的顺序,但没有理由。我们证明,一个这样的近似,我们称之为" logits 的总数",在初始化时会与真正的eNTK相一致。我们的实验证明了这种近似在各种设置中的应用质量。

**[Paper URL](https://proceedings.mlr.press/v202/mohamadi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mohamadi23a/mohamadi23a.pdf)** 

# Special Properties of Gradient Descent with Large Learning Rates
**题目:** 高学习率梯度下降的特殊特性

**作者:** Amirkeivan Mohtashami, Martin Jaggi, Sebastian U Stich

**Abstract:** When training neural networks, it has been widely observed that a large step size is essential in stochastic gradient descent (SGD) for obtaining superior models. However, the effect of large step sizes on the success of SGD is not well understood theoretically. Several previous works have attributed this success to the stochastic noise present in SGD. However, we show through a novel set of experiments that the stochastic noise is not sufficient to explain good non-convex training, and that instead the effect of a large learning rate itself is essential for obtaining best performance.We demonstrate the same effects also in the noise-less case, i.e. for full-batch GD. We formally prove that GD with large step size —on certain non-convex function classes — follows a different trajectory than GD with a small step size, which can lead to convergence to a global minimum instead of a local one. Our settings provide a framework for future analysis which allows comparing algorithms based on behaviors that can not be observed in the traditional settings.

**摘要:** 在训练神经网络时,人们广泛观察到大步大小对于获得优越模型的随机梯度下降(SGD)是必不可少的,然而,大步大小对SGD的成功的影响在理论上并不十分清楚。我们的设置为未来分析提供了框架,允许基于不能在传统的设置中观察的行为的算法进行比较。

**[Paper URL](https://proceedings.mlr.press/v202/mohtashami23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mohtashami23a/mohtashami23a.pdf)** 

# Neural Inverse Operators for Solving PDE Inverse Problems
**题目:** 神经逆运算器解决PDE逆问题

**作者:** Roberto Molinaro, Yunan Yang, Björn Engquist, Siddhartha Mishra

**Abstract:** A large class of inverse problems for PDEs are only well-defined as mappings from operators to functions. Existing operator learning frameworks map functions to functions and need to be modified to learn inverse maps from data. We propose a novel architecture termed Neural Inverse Operators (NIOs) to solve these PDE inverse problems. Motivated by the underlying mathematical structure, NIO is based on a suitable composition of DeepONets and FNOs to approximate mappings from operators to functions. A variety of experiments are presented to demonstrate that NIOs significantly outperform baselines and solve PDE inverse problems robustly, accurately and are several orders of magnitude faster than existing direct and PDE-constrained optimization methods.

**摘要:** 对PDEs的反向问题的一大类只定义为从算子到函数的映射。现有的算子学习框架将函数映射到函数,需要修改才能从数据中学习反向映射。我们提出了一种新的结构,称为神经反向算子(NIOs)来解决这些PDE反向问题。

**[Paper URL](https://proceedings.mlr.press/v202/molinaro23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/molinaro23a/molinaro23a.pdf)** 

# Input uncertainty propagation through trained neural networks
**题目:** 通过训练神经网络传播输入不确定性

**作者:** Paul Monchot, Loic Coquelin, Sébastien Julien Petit, Sébastien Marmin, Erwan Le Pennec, Nicolas Fischer

**Abstract:** When physical sensors are involved, such as image sensors, the uncertainty over the input data is often a major component of the output uncertainty of machine learning models. In this work, we address the problem of input uncertainty propagation through trained neural networks. We do not rely on a Gaussian distribution assumption of the output or of any intermediate layer. We propagate instead a Gaussian Mixture Model (GMM) that offers much more flexibility, using the Split&Merge algorithm. This paper’s main contribution is the computation of a Wasserstein criterion to control the Gaussian splitting procedure for which theoretical guarantees of convergence on the output distribution estimates are derived. The methodology is tested against a wide range of datasets and networks. It shows robustness, and genericity and offers highly accurate output probability density function estimation while maintaining a reasonable computational cost compared with the standard Monte Carlo (MC) approach.

**摘要:** 当物理传感器(如图像传感器)参与时,输入数据上的不确定性往往是机器学习模型输出不确定性的主要组成部分。本文针对通过训练神经网络传播输入不确定性问题。我们不依赖输出或任何中间层的高斯分布假设,而是采用分割和合并算法传播高斯混合模型(GMM),它提供了更大的灵活性。本文的主要贡献是计算一个沃斯泰因标准来控制高斯分离过程,从而得到对输出分布估计的理论保证。该方法在广泛的数据集和网络上进行测试。它显示了鲁棒性和通用性,并提供高精度的输出概率密度函数估计,同时与标准蒙特卡罗(MC)方法相比保持合理的计算成本。

**[Paper URL](https://proceedings.mlr.press/v202/monchot23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/monchot23a/monchot23a.pdf)** 

# Compressing Tabular Data via Latent Variable Estimation
**题目:** 通过潜在变量估计压缩表格数据

**作者:** Andrea Montanari, Eric Weiner

**Abstract:** Data used for analytics and machine learning often take the form of tables with categorical entries. We introduce a family of lossless compression algorithms for such data that proceed in four steps: (i) Estimate latent variables associated to rows and columns; (ii) Partition the table in blocks according to the row/column latents; (iii) Apply a sequential (e.g. Lempel-Ziv) coder to each of the blocks; (iv) Append a compressed encoding of the latents. We evaluate this approach on several benchmark datasets, and study optimal compression in a probabilistic model for tabular data, whereby latent values are independent and table entries are conditionally independent given the latent values. We prove that the model has a well defined entropy rate and satisfies an asymptotic equipartition property. We also prove that classical compression schemes such as Lempel-Ziv and finite-state encoders do not achieve this rate. On the other hand, the latent estimation strategy outlined above achieves the optimal rate.

**摘要:** 用于分析和机器学习的数据通常以类别输入的表格的形式出现。我们引入了以四个步骤进行的无损压缩算法的家族: (i)估计与行和列关联的延迟变量; (ii)根据行/列延迟分隔表; (iii)对各块应用序列(例如Lempel-Ziv)编码器; (iv)添加延迟的压缩编码。我们对几个基准数据集进行了评估,并研究了用于表数据的概率模型中的最佳压缩,其中延迟值是独立的,而表输入是基于延迟值的条件独立的。另一方面, 上述潜伏估计策略达到最佳速度.

**[Paper URL](https://proceedings.mlr.press/v202/montanari23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/montanari23a/montanari23a.pdf)** 

# An SDE for Modeling SAM: Theory and Insights
**题目:** SAM建模的SDE:理论和洞察

**作者:** Enea Monzio Compagnoni, Luca Biggio, Antonio Orvieto, Frank Norbert Proske, Hans Kersting, Aurelien Lucchi

**Abstract:** We study the SAM (Sharpness-Aware Minimization) optimizer which has recently attracted a lot of interest due to its increased performance over more classical variants of stochastic gradient descent. Our main contribution is the derivation of continuous-time models (in the form of SDEs) for SAM and two of its variants, both for the full-batch and mini-batch settings. We demonstrate that these SDEs are rigorous approximations of the real discrete-time algorithms (in a weak sense, scaling linearly with the learning rate). Using these models, we then offer an explanation of why SAM prefers flat minima over sharp ones – by showing that it minimizes an implicitly regularized loss with a Hessian-dependent noise structure. Finally, we prove that SAM is attracted to saddle points under some realistic conditions. Our theoretical results are supported by detailed experiments.

**摘要:** 我们研究了SAM(Sharpness-Aware Minimization)优化器,该优化器最近因其在更经典的梯度下降变形上提高性能而引起大量兴趣。我们的主要贡献是为SAM及其两个变形的连续时间模型(SDEs形式)的导引, both for the full-batch and mini-batch settings。

**[Paper URL](https://proceedings.mlr.press/v202/monzio-compagnoni23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/monzio-compagnoni23a/monzio-compagnoni23a.pdf)** 

# Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic
**题目:** 基于形式逻辑的综合体学习推理推理

**作者:** Terufumi Morishita, Gaku Morio, Atsuki Yamaguchi, Yasuhiro Sogawa

**Abstract:** We study a synthetic corpus based approach for language models (LMs) to acquire logical deductive reasoning ability. The previous studies generated deduction examples using specific sets of deduction rules. However, these rules were limited or otherwise arbitrary. This can limit the generalizability of acquired deductive reasoning ability. We rethink this and adopt a well-grounded set of deduction rules based on formal logic theory, which can derive any other deduction rules when combined in a multistep way. We empirically verify that LMs trained on the proposed corpora, which we name $\textbf{FLD}$ ($\textbf{F}$ormal $\textbf{L}$ogic $\textbf{D}$eduction), acquire more generalizable deductive reasoning ability. Furthermore, we identify the aspects of deductive reasoning ability on which deduction corpora can enhance LMs and those on which they cannot. Finally, on the basis of these results, we discuss the future directions for applying deduction corpora or other approaches for each aspect. We release the code, data, and models.

**摘要:** 我们研究了一种基于语言模型的综合体法来获取逻辑推理推理能力的语言模型(LMs)。以前的研究使用特定推理规则生成了推理例子。然而,这些规则是有限或任意的。这可以限制获得的推理推理能力的普遍性。我们重新思考并采用基于形式逻辑理论的推理规则的良好基础,在多种步骤中结合时可以导出其他推理规则。我们通过实证验证了LMs在拟议的结构上训练,我们称之为$\textbf{FLD}$($\textbf{F}$ormal $\textbf{L}$ogic $\textbf{D}$eduction),从而获得更普遍的推理能力。此外,我们确定了推理结构可以增强LMs的推理能力的各个方面以及不能增强LMs的方面。最后,以这些结果为基础,讨论了各方面应用减记 corpora或其他方法的未来方向,并发布代码、数据和模型。

**[Paper URL](https://proceedings.mlr.press/v202/morishita23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/morishita23a/morishita23a.pdf)** 

# WL meet VC
**题目:** WL与VC会面

**作者:** Christopher Morris, Floris Geerts, Jan Tönshoff, Martin Grohe

**Abstract:** Recently, many works studied the expressive power of graph neural networks (GNNs) by linking it to the $1$-dimensional Weisfeiler-Leman algorithm ($1\text{-}\mathsf{WL}$). Here, the $1\text{-}\mathsf{WL}$ is a well-studied heuristic for the graph isomorphism problem, which iteratively colors or partitions a graph’s vertex set. While this connection has led to significant advances in understanding and enhancing GNNs’ expressive power, it does not provide insights into their generalization performance, i.e., their ability to make meaningful predictions beyond the training set. In this paper, we study GNNs’ generalization ability through the lens of Vapnik-Chervonenkis (VC) dimension theory in two settings, focusing on graph-level predictions. First, when no upper bound on the graphs’ order is known, we show that the bitlength of GNNs’ weights tightly bounds their VC dimension. Further, we derive an upper bound for GNNs’ VC dimension using the number of colors produced by the $1\text{-}\mathsf{WL}$. Secondly, when an upper bound on the graphs’ order is known, we show a tight connection between the number of graphs distinguishable by the $1\text{-}\mathsf{WL}$ and GNNs’ VC dimension. Our empirical study confirms the validity of our theoretical findings.

**摘要:** 最近,许多研究了图神经网络(GNNs)的表达能力,通过将其与$1维Weisfeiler-Leman算法($1\text{-}\mathsf{WL}$)连接起来。这里,$1\text{-}\mathsf{WL}$是对图同构问题进行较好的启发性研究,它迭代颜色或分割图顶集合。虽然这一联系导致了GNNs的表达能力的理解和提高的重要进展,但它并不提供对它们的一般化性能的洞察,即它们能够在训练集合之外作出有意义的预测的能力。其次,当在图序上的上界线已知时,我们显示了由 $1\text{-}\mathsf{WL}$和GNN的VC维度区分的图数之间的紧密联系。我们的实证研究证实了我们的理论发现的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/morris23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/morris23a/morris23a.pdf)** 

# ReLOAD: Reinforcement Learning with Optimistic Ascent-Descent for Last-Iterate Convergence in Constrained MDPs
**题目:** ReLOAD:在约束的MDP中实现最后迭代收敛的优化提升学习

**作者:** Ted Moskovitz, Brendan O’Donoghue, Vivek Veeriah, Sebastian Flennerhag, Satinder Singh, Tom Zahavy

**Abstract:** In recent years, reinforcement learning (RL) has been applied to real-world problems with increasing success. Such applications often require to put constraints on the agent’s behavior. Existing algorithms for constrained RL (CRL) rely on gradient descent-ascent, but this approach comes with a caveat. While these algorithms are guaranteed to converge on average, they do not guarantee last-iterate convergence, i.e., the current policy of the agent may never converge to the optimal solution. In practice, it is often observed that the policy alternates between satisfying the constraints and maximizing the reward, rarely accomplishing both objectives simultaneously. Here, we address this problem by introducing Reinforcement Learning with Optimistic Ascent-Descent (ReLOAD), a principled CRL method with guaranteed last-iterate convergence. We demonstrate its empirical effectiveness on a wide variety of CRL problems including discrete MDPs and continuous control. In the process we establish a benchmark of challenging CRL problems.

**摘要:** 近年来,强化学习(RL)已经应用于日益成功的现实问题。此类应用往往要求对代理人的行为施加约束。约束RL(CRL)的现有算法依赖梯度下降-上升,但这种方法带有警告。虽然这些算法保证平均收敛,但它们并不保证最后定量收敛,即代理人的当前政策永远不会收敛到最佳解决方案。在实践中,经常观察到该政策在满足约束和最大化报酬之间变化,很少同时实现两个目标。在此过程中,我们确定了挑战CRL问题的基准.

**[Paper URL](https://proceedings.mlr.press/v202/moskovitz23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/moskovitz23a/moskovitz23a.pdf)** 

# Optimistic Planning by Regularized Dynamic Programming
**题目:** 基于规范动态规划的优化规划

**作者:** Antoine Moulin, Gergely Neu

**Abstract:** We propose a new method for optimistic planning in infinite-horizon discounted Markov decision processes based on the idea of adding regularization to the updates of an otherwise standard approximate value iteration procedure. This technique allows us to avoid contraction and monotonicity arguments typically required by existing analyses of approximate dynamic programming methods, and in particular to use approximate transition functions estimated via least-squares procedures in MDPs with linear function approximation. We use our method to recover known guarantees in tabular MDPs and to provide a computationally efficient algorithm for learning near-optimal policies in discounted linear mixture MDPs from a single stream of experience, and show it achieves near-optimal statistical guarantees.

**摘要:** 本文提出了一种基于在其他标准的近似值迭代程序更新中添加正则化的概念的无穷水平偏差马可夫决策过程的乐观规划新方法。该方法可避免近似动态编程方法的现有分析所要求的收缩和单调性参数,特别是通过线性函数近似的最小方程程序估计的近似过渡函数。我们利用该方法在表式近似方案中恢复已知的保证,并为从一个经验流中学习近似线性混合物近似方案提供计算效率的算法,并证明它达到近似最佳的统计保证。

**[Paper URL](https://proceedings.mlr.press/v202/moulin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/moulin23a/moulin23a.pdf)** 

# Neural signature kernels as infinite-width-depth-limits of controlled ResNets
**题目:** 神经签名核作为控制的ResNets无限宽度深度限制

**作者:** Nicola Muca Cirone, Maud Lemercier, Cristopher Salvi

**Abstract:** Motivated by the paradigm of reservoir computing, we consider randomly initialized controlled ResNets defined as Euler-discretizations of neural controlled differential equations (Neural CDEs), a unified architecture which enconpasses both RNNs and ResNets. We show that in the infinite-width-depth limit and under proper scaling, these architectures converge weakly to Gaussian processes indexed on some spaces of continuous paths and with kernels satisfying certain partial differential equations (PDEs) varying according to the choice of activation function $\varphi$, extending the results of Hayou (2022); Hayou & Yang (2023) to the controlled and homogeneous case. In the special, homogeneous, case where $\varphi$ is the identity, we show that the equation reduces to a linear PDE and the limiting kernel agrees with the signature kernel of Salvi et al. (2021a). We name this new family of limiting kernels neural signature kernels. Finally, we show that in the infinite-depth regime, finite-width controlled ResNets converge in distribution to Neural CDEs with random vector fields which, depending on whether the weights are shared across layers, are either time-independent and Gaussian or behave like a matrix-valued Brownian motion.

**摘要:** 基于储层计算的范式,我们考虑随机初始化控制的ResNets定义为神经控制微分方程(神经CDEs)的欧勒分离,一个包含RNN和ResNets的统一架构。我们表明,在无限宽度深度限制下和适当的尺度下,这些架构在某些连续路径空间上的加索过程和满足某些部分微分方程(PDEs)的内核上弱收敛,根据激活函数$\varphi$的选择变化,扩展海奥(2022);海奥和杨(2023)的结果到控制和均匀的案例。最后,我们证明,在无限深度模式下,有限宽度控制的ResNets在分布上趋向到随机向量场的神经CDEs,这些向量场取决于重量是否在层间共享,要么是时间独立的,要么是高斯运动,要么是基于矩阵值的布朗运动。

**[Paper URL](https://proceedings.mlr.press/v202/muca-cirone23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/muca-cirone23a/muca-cirone23a.pdf)** 

# Improving Statistical Fidelity for Neural Image Compression with Implicit Local Likelihood Models
**题目:** 基于隐形局部概率模型对神经图像压缩的统计信合性提高

**作者:** Matthew J. Muckley, Alaaeldin El-Nouby, Karen Ullrich, Herve Jegou, Jakob Verbeek

**Abstract:** Lossy image compression aims to represent images in as few bits as possible while maintaining fidelity to the original. Theoretical results indicate that optimizing distortion metrics such as PSNR or MS-SSIM necessarily leads to a discrepancy in the statistics of original images from those of reconstructions, in particular at low bitrates, often manifested by the blurring of the compressed images. Previous work has leveraged adversarial discriminators to improve statistical fidelity. Yet these binary discriminators adopted from generative modeling tasks may not be ideal for image compression. In this paper, we introduce a non-binary discriminator that is conditioned on quantized local image representations obtained via VQ-VAE autoencoders. Our evaluations on the CLIC2020, DIV2K and Kodak datasets show that our discriminator is more effective for jointly optimizing distortion (e.g., PSNR) and statistical fidelity (e.g., FID) than the PatchGAN of the state-of-the-art HiFiC model. On CLIC2020, we obtain the same FID as HiFiC with 30-40% fewer bits.

**摘要:** 丢失图像压缩的目标是尽可能少的位数显示图像,同时保持对原始图像的忠实性。理论结果表明,优化歪曲度量,如PSNR或MS-SSIM,必然导致原始图像的统计与重建数据的差异,特别是在低位数,往往表现为压缩图像的模糊。以前的工作利用敌对分离器来提高统计忠实性。然而,这些从生成模型任务中采用的二进制分离器可能不适合图像压缩。在CLIC2020中,我们得到与HiFiC相同的FID,但比特少 30-40%。

**[Paper URL](https://proceedings.mlr.press/v202/muckley23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/muckley23a/muckley23a.pdf)** 

# PFNs4BO: In-Context Learning for Bayesian Optimization
**题目:** PFNs4BO:贝叶斯优化的内 context learning

**作者:** Samuel Müller, Matthias Feurer, Noah Hollmann, Frank Hutter

**Abstract:** In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible surrogate for Bayesian Optimization (BO). PFNs are neural processes that are trained to approximate the posterior predictive distribution (PPD) through in-context learning on any prior distribution that can be efficiently sampled from. We describe how this flexibility can be exploited for surrogate modeling in BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and a Bayesian Neural Network (BNN). In addition, we show how to incorporate further information into the prior, such as allowing hints about the position of optima (user priors), ignoring irrelevant dimensions, and performing non-myopic BO by learning the acquisition function. The flexibility underlying these extensions opens up vast possibilities for using PFNs for BO. We demonstrate the usefulness of PFNs for BO in a large-scale evaluation on artificial GP samples and three different hyperparameter optimization testbeds: HPO-B, Bayesmark, and PD1. We publish code alongside trained models at https://github.com/automl/PFNs4BO.

**摘要:** 在本文中,我们使用前数据匹配网络(PFNs)作为贝叶斯优化(BO)的灵活替代品。PFNs是通过在上下文学习上对任何可以有效采样的预后分布进行近似后预测分布(PPD)的神经过程。我们描述了如何利用这一灵活性在BO中的替代模型。我们使用PFNs以模仿一个 naiv Gaussian process(GP) 、 an advanced GP 、 and a Bayesian Neural Network (BNN) 。此外,我们还展示了如何将进一步的信息纳入预先,例如允许关于优化(用户预先)的位置的提示、忽略不相关的维度和通过学习获取函数执行非线性BO。我们在人工GP样本和三个不同的高参数优化测试床:HPO-B、Bayesmark和PD1中展示了PFN对BO的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/muller23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/muller23a/muller23a.pdf)** 

# Achieving High Accuracy with PINNs via Energy Natural Gradient Descent
**题目:** 通过能量自然梯度偏移获得高精度的PINN

**作者:** Johannes Müller, Marius Zeinhofer

**Abstract:** We propose energy natural gradient descent, a natural gradient method with respect to a Hessian-induced Riemannian metric as an optimization algorithm for physics-informed neural networks (PINNs) and the deep Ritz method. As a main motivation we show that the update direction in function space resulting from the energy natural gradient corresponds to the Newton direction modulo an orthogonal projection on the model’s tangent space. We demonstrate experimentally that energy natural gradient descent yields highly accurate solutions with errors several orders of magnitude smaller than what is obtained when training PINNs with standard optimizers like gradient descent or Adam, even when those are allowed significantly more computation time.

**摘要:** 本文提出了一种基于希斯sian推导的黎曼度法的自然梯度方法,即能量自然梯度下降,作为物理信息神经网络(PINN)的优化算法和深度里兹方法。我们主要的动机是,从能量自然梯度产生函数空间中的更新方向与牛顿方向模态对模型的 Tangent空间的正交投影相符。

**[Paper URL](https://proceedings.mlr.press/v202/muller23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/muller23b/muller23b.pdf)** 

# Uncertain Evidence in Probabilistic Models and Stochastic Simulators
**题目:** 概率模型和随机模拟器中不确定证据

**作者:** Andreas Munk, Alexander Mead, Frank Wood

**Abstract:** We consider the problem of performing Bayesian inference in probabilistic models where observations are accompanied by uncertainty, referred to as "uncertain evidence.” We explore how to interpret uncertain evidence, and by extension the importance of proper interpretation as it pertains to inference about latent variables. We consider a recently-proposed method "distributional evidence” as well as revisit two older methods: Jeffrey’s rule and virtual evidence. We devise guidelines on how to account for uncertain evidence and we provide new insights, particularly regarding consistency. To showcase the impact of different interpretations of the same uncertain evidence, we carry out experiments in which one interpretation is defined as "correct.” We then compare inference results from each different interpretation illustrating the importance of careful consideration of uncertain evidence.

**摘要:** 我们考虑了在概率模型中执行贝叶斯推理的问题,即观察伴随不确定,称为“不确定证据”。我们探讨了如何解释不确定证据,并进一步探讨了正确的解释的重要性,因为它涉及关于隐形变量推理。我们考虑了最近提出的“分配证据”方法,并重新回顾了两个较旧的方法:杰弗里规则和虚拟证据。我们制定了如何解释不确定证据的准则,并提供了新的洞察,特别是关于一致性。为了展示同一不确定证据的不同解释的影响,我们进行了一个解释被定义为“正确的”的实验。

**[Paper URL](https://proceedings.mlr.press/v202/munk23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/munk23a/munk23a.pdf)** 

# GibbsDDRM: A Partially Collapsed Gibbs Sampler for Solving Blind Inverse Problems with Denoising Diffusion Restoration
**题目:** GibbsDDRM:一种部分倒塌的吉布斯样品,用于解决隐性扩散恢复的盲逆问题

**作者:** Naoki Murata, Koichi Saito, Chieh-Hsin Lai, Yuhta Takida, Toshimitsu Uesaka, Yuki Mitsufuji, Stefano Ermon

**Abstract:** Pre-trained diffusion models have been successfully used as priors in a variety of linear inverse problems, where the goal is to reconstruct a signal from noisy linear measurements. However, existing approaches require knowledge of the linear operator. In this paper, we propose GibbsDDRM, an extension of Denoising Diffusion Restoration Models (DDRM) to a blind setting in which the linear measurement operator is unknown. GibbsDDRM constructs a joint distribution of the data, measurements, and linear operator by using a pre-trained diffusion model for the data prior, and it solves the problem by posterior sampling with an efficient variant of a Gibbs sampler. The proposed method is problem-agnostic, meaning that a pre-trained diffusion model can be applied to various inverse problems without fine-tuning. In experiments, it achieved high performance on both blind image deblurring and vocal dereverberation tasks, despite the use of simple generic priors for the underlying linear operators.

**摘要:** 本文提出了GibbsDDRM(英语:GibbsDDRM)的扩展,即Denoising Diffusion Restoration Models(英语:Denoising Diffusion Restoration Models)(DDRM)的扩展,用于盲设置,其中线性测量算子是未知的。GibbsDDRM通过使用预先训练的扩散模型来构造数据、测量和线性算子的联合分布,并用Gibbs样本器的有效变量后采样解决了问题。该方法是问题无误的,这意味着预先训练的扩散模型可以在不精确调整的情况下应用于各种逆问题。

**[Paper URL](https://proceedings.mlr.press/v202/murata23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/murata23a/murata23a.pdf)** 

# DIFF2: Differential Private Optimization via Gradient Differences for Nonconvex Distributed Learning
**题目:** DIFF2:非凸分布式学习用梯度差异进行微分私人优化

**作者:** Tomoya Murata, Taiji Suzuki

**Abstract:** Differential private optimization for nonconvex smooth objective is considered. In the previous work, the best known utility bound is $\widetilde O(\sqrt{d}/(n\varepsilon_\mathrm{DP}))$ in terms of the squared full gradient norm, which is achieved by Differential Private Gradient Descent (DP-GD) as an instance, where $n$ is the sample size, $d$ is the problem dimensionality and $\varepsilon_\mathrm{DP}$ is the differential privacy parameter. To improve the best known utility bound, we propose a new differential private optimization framework called DIFF2 (DIFFerential private optimization via gradient DIFFerences) that constructs a differential private global gradient estimator with possibly quite small variance based on communicated gradient differences rather than gradients themselves. It is shown that DIFF2 with a gradient descent subroutine achieves the utility of $\widetilde O(d^{2/3}/(n\varepsilon_\mathrm{DP})^{4/3})$, which can be significantly better than the previous one in terms of the dependence on the sample size $n$. To the best of our knowledge, this is the first fundamental result to improve the standard utility $\widetilde O(\sqrt{d}/(n\varepsilon_\mathrm{DP}))$ for nonconvex objectives. Additionally, a more computational and communication efficient subroutine is combined with DIFF2 and its theoretical analysis is also given. Numerical experiments are conducted to validate the superiority of DIFF2 framework.

**摘要:** 考虑了非凸平滑目标的微分私人优化。在前面的工作中,最著名的实用函数边界是 $\widetilde O(\sqrt{d}/(n\varepsilon_\mathrm{DP}))$ 的平方完全梯度规范,由微分私人梯度降落(DP-GD)作为实例实现,其中 $n$ 是样品大小, $d$ 是问题维度, $\varepsilon_\mathrm{DP}$ 是微分私人参数。结果表明,具有梯度下降子程序的DIFF2实现了$\widetilde O(d^{2/3}/(n\varepsilon_\mathrm{DP})^{4/3})$的实用性,对于样品尺寸$n$的依赖性而言,可以比前一种显著提高。根据我们所知,这是改进非凸目标标准实用性$\widetilde O(\sqrt{d}/(n\varepsilon_\mathrm{DP}))$的第一个基本结果。

**[Paper URL](https://proceedings.mlr.press/v202/murata23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/murata23b/murata23b.pdf)** 

# Efficiently predicting high resolution mass spectra with graph neural networks
**题目:** 用图神经网络预测高分辨率质量谱

**作者:** Michael Murphy, Stefanie Jegelka, Ernest Fraenkel, Tobias Kind, David Healey, Thomas Butler

**Abstract:** Identifying a small molecule from its mass spectrum is the primary open problem in computational metabolomics. This is typically cast as information retrieval: an unknown spectrum is matched against spectra predicted computationally from a large database of chemical structures. However, current approaches to spectrum prediction model the output space in ways that force a tradeoff between capturing high resolution mass information and tractable learning. We resolve this tradeoff by casting spectrum prediction as a mapping from an input molecular graph to a probability distribution over chemical formulas. We further discover that a large corpus of mass spectra can be closely approximated using a fixed vocabulary constituting only 2% of all observed formulas. This enables efficient spectrum prediction using an architecture similar to graph classification - GrAFF-MS - achieving significantly lower prediction error and greater retrieval accuracy than previous approaches.

**摘要:** 识别其质量谱中的小分子是计算代谢学中主要的开放问题。这通常被用作信息检索:一个未知的谱与从大量化学结构的数据库中进行计算预测的谱匹配。然而,目前的谱预测方法在获取高分辨率的质量信息和易于处理的学习之间强制出力输出空间。我们通过从输入分子图向化学公式上的概率分布绘制谱预测来解决这一问题。我们进一步发现,大量谱的大型体积可以用固定词汇来接近,仅占观察公式的2%。

**[Paper URL](https://proceedings.mlr.press/v202/murphy23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/murphy23a/murphy23a.pdf)** 

# Dynamical Linear Bandits
**题目:** 动态线性 Bandits

**作者:** Marco Mussi, Alberto Maria Metelli, Marcello Restelli

**Abstract:** In many real-world sequential decision-making problems, an action does not immediately reflect on the feedback and spreads its effects over a long time frame. For instance, in online advertising, investing in a platform produces an instantaneous increase of awareness, but the actual reward, i.e., a conversion, might occur far in the future. Furthermore, whether a conversion takes place depends on: how fast the awareness grows, its vanishing effects, and the synergy or interference with other advertising platforms. Previous work has investigated the Multi-Armed Bandit framework with the possibility of delayed and aggregated feedback, without a particular structure on how an action propagates in the future, disregarding possible dynamical effects. In this paper, we introduce a novel setting, the Dynamical Linear Bandits (DLB), an extension of the linear bandits characterized by a hidden state. When an action is performed, the learner observes a noisy reward whose mean is a linear function of the hidden state and of the action. Then, the hidden state evolves according to linear dynamics, affected by the performed action too. We start by introducing the setting, discussing the notion of optimal policy, and deriving an expected regret lower bound. Then, we provide an optimistic regret minimization algorithm, Dynamical Linear Upper Confidence Bound (DynLin-UCB), that suffers an expected regret of order $\widetilde{\mathcal{O}} \Big( \frac{d \sqrt{T}}{(1-\overline{\rho})^{3/2}} \Big)$, where $\overline{\rho}$ is a measure of the stability of the system, and $d$ is the dimension of the action vector. Finally, we conduct a numerical validation on a synthetic environment and on real-world data to show the effectiveness of DynLin-UCB in comparison with several baselines.

**摘要:** 例如,在在线广告中,在平台上投资产生意识的瞬时增长,但实际的回报,即转换,可能在将来发生。 此外,转换是否发生取决于:意识的增长速度、消亡效应以及与其他广告平台的协同或干涉。当一个动作执行时,学习者会观察一个噪声的奖励,其平均值是隐藏状态和动作的线性函数。然后,隐藏状态根据线性动力学演化,也受到执行的动作的影响。我们首先引入设置,讨论最佳政策的概念,并推导预期的遗憾下限。然后,我们提供一种乐观的遗憾最小化算法,动态线性上限(DynLin-UCB),它 suffers a expected regret of order $\widetilde{\mathcal{O}} \Big(\frac{d \sqrt{T}}{(1-\overline{\rho})^{3/2}} \Big)$, where $\overline{\rho}$ is a measure of the stability of the system, and $d$ is the dimension of the action vector。最后,我们对合成环境和实

**[Paper URL](https://proceedings.mlr.press/v202/mussi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/mussi23a/mussi23a.pdf)** 

# Representation-Driven Reinforcement Learning
**题目:** 代表驱动强化学习

**作者:** Ofir Nabati, Guy Tennenholtz, Shie Mannor

**Abstract:** We present a representation-driven framework for reinforcement learning. By representing policies as estimates of their expected values, we leverage techniques from contextual bandits to guide exploration and exploitation. Particularly, embedding a policy network into a linear feature space allows us to reframe the exploration-exploitation problem as a representation-exploitation problem, where good policy representations enable optimal exploration. We demonstrate the effectiveness of this framework through its application to evolutionary and policy gradient-based approaches, leading to significantly improved performance compared to traditional methods. Our framework provides a new perspective on reinforcement learning, highlighting the importance of policy representation in determining optimal exploration-exploitation strategies.

**摘要:** 本文提出了一种基于表征的强化学习框架,以表征政策为预期值的估计方法,利用上下文带子技术指导探索和开发。具体而言,将政策网络嵌入线性特征空间,使我们能够将探索-开发问题重新构造为表征-开发问题,其中良好的政策表征可实现最佳探索。我们通过应用进化和政策梯度方法来证明该框架的有效性,从而大大提高了与传统方法相比的性能。本框架为强化学习提供了新的视角,突出了政策表征在确定最佳探索-开发战略中的重要性。

**[Paper URL](https://proceedings.mlr.press/v202/nabati23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nabati23a/nabati23a.pdf)** 

# DADAO: Decoupled Accelerated Decentralized Asynchronous Optimization
**题目:** DADAO:解耦加速分散异步优化

**作者:** Adel Nabli, Edouard Oyallon

**Abstract:** This work introduces DADAO: the first decentralized, accelerated, asynchronous, primal, first-order algorithm to minimize a sum of $L$-smooth and $\mu$-strongly convex functions distributed over a given network of size $n$. Our key insight is based on modeling the local gradient updates and gossip communication procedures with separate independent Poisson Point Processes. This allows us to decouple the computation and communication steps, which can be run in parallel, while making the whole approach completely asynchronous. This leads to communication acceleration compared to synchronous approaches. Our new method employs primal gradients and does not use a multi-consensus inner loop nor other ad-hoc mechanisms such as Error Feedback, Gradient Tracking, or a Proximal operator. By relating the inverse of the smallest positive eigenvalue of the Laplacian matrix $\chi_1$ and the maximal resistance $\chi_2\leq \chi_1$ of the graph to a sufficient minimal communication rate between the nodes of the network, we show that our algorithm requires $\mathcal{O}(n\sqrt{\frac{L}{\mu}}\log(\frac{1}{\epsilon}))$ local gradients and only $\mathcal{O}(n\sqrt{\chi_1\chi_2}\sqrt{\frac{L}{\mu}}\log(\frac{1}{\epsilon}))$ communications to reach a precision $\epsilon$, up to logarithmic terms. Thus, we simultaneously obtain an accelerated rate for both computations and communications, leading to an improvement over state-of-the-art works, our simulations further validating the strength of our relatively unconstrained method.

**摘要:** 本文介绍了DADAO:第一个分散、加速、非同步、初级、第一阶算法,以最小限度地将$L$- Smooth 和 $\mu$-strongly 凸函数分布在给定的 $n$ 大小网络上。我们的关键洞察是基于单独独立的 Poisson Point 过程对局部梯度更新和流言通信程序的建模。这允许我们将计算和通信步骤分开,并可同时运行,同时使整个方法完全非同步。这导致与同步方法相比的通信加速。通过将拉普拉西亚矩阵$\chi_1$的最小正值和最大阻力$\chi_2\leq \chi_1$与网络节点间的足够最小通信速率的逆关系,我们表明,我们的算法需要$\mathcal{O}(n\sqrt{\frac{L}{\mu}}\log(\frac{1}{\epsilon}))$局部梯度和只有$\mathcal{O}(n\sqrt{\chi_1\chi_2}\sqrt{\frac{L}{\mu}}\log(\frac{1}{\epsilon}))$通信才能达到精度$\epsilon$,从而同时获得计算和通信的加速度,从而使计算和通信比最先进的工作有所提高,我们的仿真进一步验证了我们

**[Paper URL](https://proceedings.mlr.press/v202/nabli23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nabli23a/nabli23a.pdf)** 

# Multi-User Reinforcement Learning with Low Rank Rewards
**题目:** 低等级奖励的多用户强化学习

**作者:** Dheeraj Mysore Nagaraj, Suhas S Kowshik, Naman Agarwal, Praneeth Netrapalli, Prateek Jain

**Abstract:** We consider collaborative multi-user reinforcement learning, where multiple users have the same state-action space and transition probabilities but different rewards. Under the assumption that the reward matrix of the $N$ users has a low-rank structure – a standard and practically successful assumption in the collaborative filtering setting – we design algorithms with significantly lower sample complexity compared to the ones that learn the MDP individually for each user. Our main contribution is an algorithm which explores rewards collaboratively with $N$ user-specific MDPs and can learn rewards efficiently in two key settings: tabular MDPs and linear MDPs. When $N$ is large and the rank is constant, the sample complexity per MDP depends logarithmically over the size of the state-space, which represents an exponential reduction (in the state-space size) when compared to the standard “non-collaborative” algorithms. Our main technical contribution is a method to construct policies which obtain data such that low rank matrix completion is possible (without a generative model). This goes beyond the regular RL framework and is closely related to mean field limits of multi-agent RL.

**摘要:** 基于$N$用户奖励矩阵具有低级结构的假设 — — 在协作滤波设置中的一个标准和实际成功假设 — — 我们设计了与每个用户单独学习MDP的算法相比,具有显著较低的样品复杂度的算法。我们的主要贡献是,一种与$N$用户特定的MDP合作探索奖励的算法,并能够在两个关键设置中有效地学习奖励:表型MDP和线性MDP。我们的主要技术贡献是建立能够取得低级矩阵完成(没有生成模型)的数据政策的方法,它超出了常规的RL框架,并且与多代理RL的平均场限密切相关。

**[Paper URL](https://proceedings.mlr.press/v202/nagaraj23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nagaraj23a/nagaraj23a.pdf)** 

# Statistical Foundations of Prior-Data Fitted Networks
**题目:** 前数据匹配网络的统计基础

**作者:** Thomas Nagler

**Abstract:** Prior-data fitted networks (PFNs) were recently proposed as a new paradigm for machine learning. Instead of training the network to an observed training set, a fixed model is pre-trained offline on small, simulated training sets from a variety of tasks. The pre-trained model is then used to infer class probabilities in-context on fresh training sets with arbitrary size and distribution. Empirically, PFNs achieve state-of-the-art performance on tasks with similar size to the ones used in pre-training. Surprisingly, their accuracy further improves when passed larger data sets during inference. This article establishes a theoretical foundation for PFNs and illuminates the statistical mechanisms governing their behavior. While PFNs are motivated by Bayesian ideas, a purely frequentistic interpretation of PFNs as pre-tuned, but untrained predictors explains their behavior. A predictor’s variance vanishes if its sensitivity to individual training samples does and the bias vanishes only if it is appropriately localized around the test feature. The transformer architecture used in current PFN implementations ensures only the former. These findings shall prove useful for designing architectures with favorable empirical behavior.

**摘要:** 前数据装配网络(PFNs)最近被提出为机器学习的新范式。在训练网络为观察训练集时,一个固定模型在不同任务的小型模拟训练集上进行预训练,然后用预训练模型推导在随机大小和分布的新鲜训练集的类概率。 Empirically, PFNs achieve state-of-the-art performance on tasks with similar size to those used in pre-training. Surprisingly, their accuracy further improves when passed larger data sets during inference. This article establishes a theoretical foundation for PFNs and illuminates the statistical mechanisms governing their behavior. While PFNs are motivated by Bayesian ideas, a purely frequentistic interpretation of PFNs as pre-tuned, but untrained predictors explains their behavior.如果对个别训练样品的敏感性消失,则预测器的变异消失,并且偏见只消失,如果它在测试特征周围适当地定位。在当前PFN实现中使用的变换器架构只确保前者。这些发现将证明为设计具有有利的实证行为的架构有用。

**[Paper URL](https://proceedings.mlr.press/v202/nagler23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nagler23a/nagler23a.pdf)** 

# Do Machine Learning Models Learn Statistical Rules Inferred from Data?
**题目:** 机器学习模型能从数据中学习统计规则 吗?

**作者:** Aaditya Naik, Yinjun Wu, Mayur Naik, Eric Wong

**Abstract:** Machine learning models can make critical errors that are easily hidden within vast amounts of data. Such errors often run counter to rules based on human intuition. However, rules based on human knowledge are challenging to scale or to even formalize. We thereby seek to infer statistical rules from the data and quantify the extent to which a model has learned them. We propose a framework SQRL that integrates logic-based methods with statistical inference to derive these rules from a model’s training data without supervision. We further show how to adapt models at test time to reduce rule violations and produce more coherent predictions. SQRL generates up to 300K rules over datasets from vision, tabular, and language settings. We uncover up to 158K violations of those rules by state-of-the-art models for classification, object detection, and data imputation. Test-time adaptation reduces these violations by up to 68.7% with relative performance improvement up to 32%. SQRL is available at https://github.com/DebugML/sqrl.

**摘要:** 机器学习模型可以很容易隐藏在大量数据中产生关键性错误,这些错误往往与基于人类直觉的规则相抵触。然而,基于人类知识的规则对于规模化或甚至形式化具有挑战性。因此,我们试图从数据中推断统计规则,并定量化模型学习的程度。我们提出了一个框架SQRL,它将与统计推断相结合的逻辑方法从模型训练数据中导出这些规则。我们进一步展示了如何在测试时调整模型来减少规则违反和产生更一致的预测。SQRL生成到300K规则从视觉、表格和语言设置的数据集上。SQRL可以在 https://github.com/DebugML/sqrl 上找到。

**[Paper URL](https://proceedings.mlr.press/v202/naik23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/naik23a/naik23a.pdf)** 

# Sample and Predict Your Latent: Modality-free Sequential Disentanglement via Contrastive Estimation
**题目:** 实例和预测你的意图:通过对比估算无模态的序列混淆

**作者:** Ilan Naiman, Nimrod Berman, Omri Azencot

**Abstract:** Unsupervised disentanglement is a long-standing challenge in representation learning. Recently, self-supervised techniques achieved impressive results in the sequential setting, where data is time-dependent. However, the latter methods employ modality-based data augmentations and random sampling or solve auxiliary tasks. In this work, we propose to avoid that by generating, sampling, and comparing empirical distributions from the underlying variational model. Unlike existing work, we introduce a self-supervised sequential disentanglement framework based on contrastive estimation with no external signals, while using common batch sizes and samples from the latent space itself. In practice, we propose a unified, efficient, and easy-to-code sampling strategy for semantically similar and dissimilar views of the data. We evaluate our approach on video, audio, and time series benchmarks. Our method presents state-of-the-art results in comparison to existing techniques. The code is available at https://github.com/azencot-group/SPYL.

**摘要:** 非监督分离是表示学习中的长期挑战。最近,自监督技术在分离设置中取得了令人印象深刻的结果,其中数据是时间依赖的。然而,后者方法采用基于模式的数据增量和随机抽样或解决辅助任务。在这个工作中,我们提议通过生成、抽样和从基本变量模型中比较经验分布来避免这种现象。与现有的工作不同,我们引入基于没有外部信号的对比估计的自监督分离框架,同时使用共同批量大小和潜在空间本身的样品。代码可以在 https://github.com/azencot-group/SPYL 上找到。

**[Paper URL](https://proceedings.mlr.press/v202/naiman23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/naiman23a/naiman23a.pdf)** 

# Effectively Using Public Data in Privacy Preserving Machine Learning
**题目:** 有效利用公共数据保护隐私的机器学习

**作者:** Milad Nasr, Saeed Mahloujifar, Xinyu Tang, Prateek Mittal, Amir Houmansadr

**Abstract:** Differentially private (DP) machine learning techniques are notorious for their degradation of model utility (e.g., they degrade classification accuracy). A recent line of work has demonstrated that leveraging public data can improve the trade-off between privacy and utility when training models with DP guaranteed. In this work, we further explore the potential of using public data in DP models, showing that utility gains can in fact be significantly higher than what shown in prior works. Specifically, we introduce DOPE-SGD, a modified DP-SGD algorithm that leverages public data during its training. DOPE-SGD uses public data in two complementary ways: (1) it uses advance augmentation techniques that leverages public data to generate synthetic data that is effectively embedded in multiple steps of the training pipeline; (2) it uses a modified gradient clipping mechanism (which is a standard technique in DP training) to change the origin of gradient vectors using the information inferred from available public and synthetic data, therefore boosting utility. We also introduce a technique to ensemble intermediate DP models by leveraging the post processing property of differential privacy to further improve the accuracy of the predictions. Our experimental results demonstrate the effectiveness of our approach in improving the state-of-the-art in DP machine learning across multiple datasets, network architectures, and application domains. For instance, assuming access to $2,000$ public images, and for a privacy budget of $\varepsilon=2,\delta=10^{-5}$, our technique achieves an accuracy of $75.1%$ on CIFAR10, significantly higher than $68.1%$ achieved by the state of the art.

**摘要:** 不同类型的私人(DP)机器学习技术因其降级模型实用性而闻名(例如,它们降低分类精度) 。最近的一系列研究表明,利用公共数据可以改善培训模型时的私隐与实用性之间的交易权衡。在这项研究中,我们进一步探讨了在DP模型中使用公共数据的潜力,表明实用性收益实际上比以往的工作要高得多。DOPE-SGD利用公共数据的两个互补方式:(一)利用利用公共数据的先进增强技术生成综合数据,有效地嵌入培训管道的多个步骤;(二)使用修改的梯度剪切机制(这是DP培训中的标准技术)来改变利用可用公共和综合数据推导的梯度向量来源,从而提高实用性。我们还引入了利用差分隐私的后处理特性来综合中级DP模型的技术,进一步提高预测的准确性。例如,假定获得2,000$的公众图像,以及$\varepsilon=2,\delta=10^{-5}$的私隐预算,我们的技术在CIFAR10中达到$75.1%的准确率,远远高于当时的$68.1%。

**[Paper URL](https://proceedings.mlr.press/v202/nasr23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nasr23a/nasr23a.pdf)** 

# Counterfactual Identifiability of Bijective Causal Models
**题目:** 双向因果模型的反事实辨识性

**作者:** Arash Nasr-Esfahany, Mohammad Alizadeh, Devavrat Shah

**Abstract:** We study counterfactual identifiability in causal models with bijective generation mechanisms (BGM), a class that generalizes several widely-used causal models in the literature. We establish their counterfactual identifiability for three common causal structures with unobserved confounding, and propose a practical learning method that casts learning a BGM as structured generative modeling. Learned BGMs enable efficient counterfactual estimation and can be obtained using a variety of deep conditional generative models. We evaluate our techniques in a visual task and demonstrate its application in a real-world video streaming simulation task.

**摘要:** 本文研究了双向生成机理(BGM)对因果模型的反因果识别性,是广义化文献中几种广泛应用的因果模型的一个类别。我们建立了三种共同的因果结构的反因果识别性,并提出了一种基于结构性生成模型的实用学习方法。

**[Paper URL](https://proceedings.mlr.press/v202/nasr-esfahany23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nasr-esfahany23a/nasr-esfahany23a.pdf)** 

# Discovering Object-Centric Generalized Value Functions From Pixels
**题目:** 从像素中发现对象中心的一般化值函数

**作者:** Somjit Nath, Gopeshh Subbaraj, Khimya Khetarpal, Samira Ebrahimi Kahou

**Abstract:** Deep Reinforcement Learning has shown significant progress in extracting useful representations from high-dimensional inputs albeit using hand-crafted auxiliary tasks and pseudo rewards. Automatically learning such representations in an object-centric manner geared towards control and fast adaptation remains an open research problem. In this paper, we introduce a method that tries to discover meaningful features from objects, translating them to temporally coherent ‘question’ functions and leveraging the subsequent learned general value functions for control. We compare our approach with state-of-the-art techniques alongside other ablations and show competitive performance in both stationary and non-stationary settings. Finally, we also investigate the discovered general value functions and through qualitative analysis show that the learned representations are not only interpretable but also, centered around objects that are invariant to changes across tasks facilitating fast adaptation.

**摘要:** 深层强化学习在利用手工制作辅助任务和伪奖励来从高维输入中提取有用的图象方面取得了显著的进展。自动以面向控制和快速适应的对象中心方式学习这些图象仍然是一个开放的研究问题。本文介绍一种方法,该方法试图从对象中发现有意义的特征,将其转换为时间相连的“问题”函数,并利用随后学习的一般价值函数来控制。最后,我们还对发现的一般值函数进行了研究,通过定性分析表明,学习的表述不仅可解释,而且围绕在任务间变化不变的对象,从而促进快速适应。

**[Paper URL](https://proceedings.mlr.press/v202/nath23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nath23a/nath23a.pdf)** 

# On Many-Actions Policy Gradient
**题目:** 多行动政策梯度

**作者:** Michal Nauman, Marek Cygan

**Abstract:** We study the variance of stochastic policy gradients (SPGs) with many action samples per state. We derive a many-actions optimality condition, which determines when many-actions SPG yields lower variance as compared to a single-action agent with proportionally extended trajectory. We propose Model-Based Many-Actions (MBMA), an approach leveraging dynamics models for many-actions sampling in the context of SPG. MBMA addresses issues associated with existing implementations of many-actions SPG and yields lower bias and comparable variance to SPG estimated from states in model-simulated rollouts. We find that MBMA bias and variance structure matches that predicted by theory. As a result, MBMA achieves improved sample efficiency and higher returns on a range of continuous action environments as compared to model-free, many-actions, and model-based on-policy SPG baselines.

**摘要:** 我们研究了随机政策梯度(SPGs)与每个状态的多个行动样本的差异性。我们得出一个多行动优化条件,该条件决定了多行动SPG在与比例扩展轨道的单行动代理相比产生较低的差异性。我们提出了基于模型的多行动(MBMA),一种在SPG上下文中的多行动采样的动力学模型利用方法。 MBMA解决了与多行动SPG现有实现有关的问题,并给出了从模型模拟滚动中状态估计的多行动SPG的低偏差和比较的差异性。我们发现MBMA偏差和差异性结构符合理论预测。

**[Paper URL](https://proceedings.mlr.press/v202/nauman23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nauman23a/nauman23a.pdf)** 

# Equivariant Architectures for Learning in Deep Weight Spaces
**题目:** 深重空间学习的等价结构

**作者:** Aviv Navon, Aviv Shamsian, Idan Achituve, Ethan Fetaya, Gal Chechik, Haggai Maron

**Abstract:** Designing machine learning architectures for processing neural networks in their raw weight matrix form is a newly introduced research direction. Unfortunately, the unique symmetry structure of deep weight spaces makes this design very challenging. If successful, such architectures would be capable of performing a wide range of intriguing tasks, from adapting a pre-trained network to a new domain to editing objects represented as functions (INRs or NeRFs). As a first step towards this goal, we present here a novel network architecture for learning in deep weight spaces. It takes as input a concatenation of weights and biases of a pre-trained MLP and processes it using a composition of layers that are equivariant to the natural permutation symmetry of the MLP’s weights: Changing the order of neurons in intermediate layers of the MLP does not affect the function it represents. We provide a full characterization of all affine equivariant and invariant layers for these symmetries and show how these layers can be implemented using three basic operations: pooling, broadcasting, and fully connected layers applied to the input in an appropriate manner. We demonstrate the effectiveness of our architecture and its advantages over natural baselines in a variety of learning tasks.

**摘要:** 设计机器学习架构以处理神经网络的原始重量矩阵形式是一项新引入的研究方向。不幸的是,深重空间的独特对称结构使得这一设计非常具有挑战性。如果成功,这些架构将能够执行广泛的有趣的任务,从适应预训练网络到一个新的领域到编辑作为函数的对象(INR或NeRF)。作为迈向这一目标的第一步,我们在这里提出了一种新的深重空间学习网络架构。我们为这些对称提供所有精细等价和不等价层的完整描述,并展示如何使用三个基本操作实现这些层:合并、广播和充分连接的层,以适当的方式应用到输入。我们在各种学习任务中证明了我们的架构的有效性及其优越于自然基线。

**[Paper URL](https://proceedings.mlr.press/v202/navon23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/navon23a/navon23a.pdf)** 

# Scalable Multi-Agent Reinforcement Learning through Intelligent Information Aggregation
**题目:** 基于智能信息集群的可扩展多代理强化学习

**作者:** Siddharth Nayak, Kenneth Choi, Wenqi Ding, Sydney Dolan, Karthik Gopalakrishnan, Hamsa Balakrishnan

**Abstract:** We consider the problem of multi-agent navigation and collision avoidance when observations are limited to the local neighborhood of each agent. We propose InforMARL, a novel architecture for multi-agent reinforcement learning (MARL) which uses local information intelligently to compute paths for all the agents in a decentralized manner. Specifically, InforMARL aggregates information about the local neighborhood of agents for both the actor and the critic using a graph neural network and can be used in conjunction with any standard MARL algorithm. We show that (1) in training, InforMARL has better sample efficiency and performance than baseline approaches, despite using less information, and (2) in testing, it scales well to environments with arbitrary numbers of agents and obstacles. We illustrate these results using four task environments, including one with predetermined goals for each agent, and one in which the agents collectively try to cover all goals.

**摘要:** 我们考虑了当观察仅限于每个代理人的本地社区时,多代理导航和碰撞避免的问题。我们提出了多代理增强学习的新架构InforMARL(英语:InforMARL),该架构以分散的方式使用本地信息来计算所有代理人的路径。InforMARL具体地集聚了代理人的本地社区信息,以图神经网络为主体和批评者,并可与任何标准的MARL算法结合起来使用。我们证明(1)在训练中,InforMARL比基线方法具有更好的样本效率和性能,尽管使用较少的信息,(2)在测试中,它可以很好地扩展到任意代理和障碍的环境。

**[Paper URL](https://proceedings.mlr.press/v202/nayak23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nayak23a/nayak23a.pdf)** 

# Geometric Autoencoders - What You See is What You Decode
**题目:** 几何自动编码器-你看到的是你解码的

**作者:** Philipp Nazari, Sebastian Damrich, Fred A Hamprecht

**Abstract:** Visualization is a crucial step in exploratory data analysis. One possible approach is to train an autoencoder with low-dimensional latent space. Large network depth and width can help unfolding the data. However, such expressive networks can achieve low reconstruction error even when the latent representation is distorted. To avoid such misleading visualizations, we propose first a differential geometric perspective on the decoder, leading to insightful diagnostics for an embedding’s distortion, and second a new regularizer mitigating such distortion. Our “Geometric Autoencoder” avoids stretching the embedding spuriously, so that the visualization captures the data structure more faithfully. It also flags areas where little distortion could not be achieved, thus guarding against misinterpretation.

**摘要:** 可视化是探索数据分析的一个关键步骤。一种可能的方法是训练一个具有低维潜空间的自动编码器。大的网络深度和宽度可以帮助解开数据。然而,这种表达式网络甚至在潜伏表示被扭曲时也能实现低重建误差。为了避免这种误导的可视化,我们首先提出了一种对解码器的微分几何视角,从而为嵌入的扭曲进行洞察性诊断,其次提出了一种新的调节器来减轻这种扭曲。我们的“几何自动编码器”避免将嵌入伸展,使可视化更忠实地捕捉到数据结构。

**[Paper URL](https://proceedings.mlr.press/v202/nazari23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nazari23a/nazari23a.pdf)** 

# Action Matching: Learning Stochastic Dynamics from Samples
**题目:** 动作匹配:从实例中学习随机动力学

**作者:** Kirill Neklyudov, Rob Brekelmans, Daniel Severo, Alireza Makhzani

**Abstract:** Learning the continuous dynamics of a system from snapshots of its temporal marginals is a problem which appears throughout natural sciences and machine learning, including in quantum systems, single-cell biological data, and generative modeling. In these settings, we assume access to cross-sectional samples that are uncorrelated over time, rather than full trajectories of samples. In order to better understand the systems under observation, we would like to learn a model of the underlying process that allows us to propagate samples in time and thereby simulate entire individual trajectories. In this work, we propose Action Matching, a method for learning a rich family of dynamics using only independent samples from its time evolution. We derive a tractable training objective, which does not rely on explicit assumptions about the underlying dynamics and does not require back-propagation through differential equations or optimal transport solvers. Inspired by connections with optimal transport, we derive extensions of Action Matching to learn stochastic differential equations and dynamics involving creation and destruction of probability mass. Finally, we showcase applications of Action Matching by achieving competitive performance in a diverse set of experiments from biology, physics, and generative modeling.

**摘要:** 在自然科学和机器学习中,包括量子系统、单细胞生物数据和生成建模中,学习系统从其时限边缘 snapshots中获得连续动力学是一个问题。在这些设置中,我们假定可以访问与时间无关的跨sectional样品,而不是样品的全轨迹。为了更好地理解观察中的系统,我们希望学习一个能够在时间中传播样品并从而模拟整个个体轨迹的底层过程模型。通过对最佳运输的关联,我们推导了Action Matching的扩展,以学习随机微分方程和涉及创造和破坏概率质量的动力学。最后,我们展示了Action Matching在生物学、物理学和生成模型方面的一系列实验中实现竞争性性能的应用。

**[Paper URL](https://proceedings.mlr.press/v202/neklyudov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/neklyudov23a/neklyudov23a.pdf)** 

# Extending Conformal Prediction to Hidden Markov Models with Exact Validity via de Finetti’s Theorem for Markov Chains
**题目:** 用费内提的马可夫链定理扩展一致预测到隐形马可夫模型的准确有效性

**作者:** Buddhika Nettasinghe, Samrat Chatterjee, Ramakrishna Tipireddy, Mahantesh M Halappanavar

**Abstract:** Conformal prediction is a widely used method to quantify the uncertainty of a classifier under the assumption of exchangeability (e.g., IID data). We generalize conformal prediction to the Hidden Markov Model (HMM) framework where the assumption of exchangeability is not valid. The key idea of the proposed method is to partition the non-exchangeable Markovian data from the HMM into exchangeable blocks by exploiting the de Finetti’s Theorem for Markov Chains discovered by Diaconis and Freedman (1980). The permutations of the exchangeable blocks are viewed as randomizations of the observed Markovian data from the HMM. The proposed method provably retains all desirable theoretical guarantees offered by the classical conformal prediction framework in both exchangeable and Markovian settings. In particular, while the lack of exchangeability introduced by Markovian samples constitutes a violation of a crucial assumption for classical conformal prediction, the proposed method views it as an advantage that can be exploited to improve the performance further. Detailed numerical and empirical results that complement the theoretical conclusions are provided to illustrate the practical feasibility of the proposed method.

**摘要:** 正则预测是一种广泛应用的方法,用来定量在交换性假设下分类器的不确定性(例如IID数据)。我们将正则预测归纳为隐藏马尔科夫模型(HMM)框架,其中交换性假设并不有效。该方法的关键思想是将HMM中不可交换的马尔科夫数据分割为可交换的块,利用迪芬蒂在1980年发现的马尔科夫链的定理(Diaconis and Freedman 1980)。特别是,虽然马可维亚样品引入的交换性不足违反了经典 konform 预测的一个关键假设,但提出的方法认为它是一个可以进一步提高性能的优点。详细的数值和实证结果补充了理论结论,以说明该方法的实际可行性。

**[Paper URL](https://proceedings.mlr.press/v202/nettasinghe23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nettasinghe23a/nettasinghe23a.pdf)** 

# ClimaX: A foundation model for weather and climate
**题目:** 气候X:气候和气候的基础模型

**作者:** Tung Nguyen, Johannes Brandstetter, Ashish Kapoor, Jayesh K Gupta, Aditya Grover

**Abstract:** Recent data-driven approaches based on machine learning aim to directly solve a downstream forecasting or projection task by learning a data-driven functional mapping using deep neural networks. However, these networks are trained using curated and homogeneous climate datasets for specific spatiotemporal tasks, and thus lack the generality of currently used computationally intensive physics-informed numerical models for weather and climate modeling. We develop and demonstrate ClimaX, a flexible and generalizable deep learning model for weather and climate science that can be trained using heterogeneous datasets spanning different variables, spatio-temporal coverage, and physical groundings. ClimaX extends the Transformer architecture with novel encoding and aggregation blocks that allow effective use of available compute and data while maintaining general utility. ClimaX is pretrained with a self-supervised learning objective on climate datasets derived from CMIP6. The pretrained ClimaX can then be fine-tuned to address a breadth of climate and weather tasks, including those that involve atmospheric variables and spatio-temporal scales unseen during pretraining. Compared to existing data-driven baselines, we show that this generality in ClimaX results in superior performance on benchmarks for weather forecasting and climate projections, even when pretrained at lower resolutions and compute budgets. Our source code is available at https://github.com/microsoft/ClimaX.

**摘要:** 基于机器学习的最新数据驱动方法旨在通过学习利用深层神经网络进行数据驱动的功能映射直接解决下游预测或预测任务。然而,这些网络被训练为特定时空任务使用 curated and homogeneous climate datasets,因此缺乏当前用于计算密集的物理信息的气候和气候建模的数值模型的普遍性。我们开发和展示 ClimaX,一种可用于气候和气候科学的灵活和通用的深层学习模型,可以使用不同变量、时空覆盖和物理基础的异性数据集进行训练。预处理的ClimaX可以精确调整,以解决气候和气候任务的范围,包括在预训练中未见的大气变量和空间时空尺度。与现有数据驱动的基线相比,我们显示ClimaX的这种普遍性在天气预报和气候预测的基准上表现优越,即使预处理在较低的分辨率和计算预算中。

**[Paper URL](https://proceedings.mlr.press/v202/nguyen23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nguyen23a/nguyen23a.pdf)** 

# Provable Reset-free Reinforcement Learning by No-Regret Reduction
**题目:** 可提供无重新设置的强化学习,减少重复

**作者:** Hoai-An Nguyen, Ching-An Cheng

**Abstract:** Reinforcement learning (RL) so far has limited real-world applications. One key challenge is that typical RL algorithms heavily rely on a reset mechanism to sample proper initial states; these reset mechanisms, in practice, are expensive to implement due to the need for human intervention or heavily engineered environments. To make learning more practical, we propose a generic no-regret reduction to systematically design reset-free RL algorithms. Our reduction turns the reset-free RL problem into a two-player game. We show that achieving sublinear regret in this two-player game would imply learning a policy that has both sublinear performance regret and sublinear total number of resets in the original RL problem. This means that the agent eventually learns to perform optimally and avoid resets. To demonstrate the effectiveness of this reduction, we design an instantiation for linear Markov decision processes, which is the first provably correct reset-free RL algorithm.

**摘要:** 增强学习(RL)迄今为止只限于实世界应用。一个关键挑战是典型的RL算法严重依赖重置机制,以采样适当的初始状态;这些重置机制在实践中,由于人类干预或严重工程环境的需要而难以实现。为了使学习更加实用,我们提出了一种通用的无重置减少,以系统地设计重置自由RL算法。我们的减少将重置自由RL问题转变为两人游戏。我们表明,在这一两人游戏中实现次线性遗憾将意味着学习一个政策,它既具有次线性性能遗憾,又具有在原始RL问题中重置的次线性总数。这意味着代理最终学会进行最优并避免重置。

**[Paper URL](https://proceedings.mlr.press/v202/nguyen23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nguyen23b/nguyen23b.pdf)** 

# Revisiting Over-smoothing and Over-squashing Using Ollivier-Ricci Curvature
**题目:** 使用奥利维尔-里奇曲线重申过多吸烟和过多流洗

**作者:** Khang Nguyen, Nong Minh Hieu, Vinh Duc Nguyen, Nhat Ho, Stanley Osher, Tan Minh Nguyen

**Abstract:** Graph Neural Networks (GNNs) had been demonstrated to be inherently susceptible to the problems of over-smoothing and over-squashing. These issues prohibit the ability of GNNs to model complex graph interactions by limiting their effectiveness in taking into account distant information. Our study reveals the key connection between the local graph geometry and the occurrence of both of these issues, thereby providing a unified framework for studying them at a local scale using the Ollivier-Ricci curvature. Specifically, we demonstrate that over-smoothing is linked to positive graph curvature while over-squashing is linked to negative graph curvature. Based on our theory, we propose the Batch Ollivier-Ricci Flow, a novel rewiring algorithm capable of simultaneously addressing both over-smoothing and over-squashing.

**摘要:** 图神经网络(GNNs)已经被证明易于过度吸烟和过度挥霍的问题。这些问题禁止GNNs通过限制它们在考虑遥远信息的有效性来建模复杂的图相互作用。我们的研究揭示了本地图几何和这两个问题的发生之间的关键联系,从而为使用奥利维尔-里奇曲率研究它们在局部尺度提供统一框架。具体地说,我们证明了过度吸烟与正图曲率有联系,而过度挥霍与负图曲率有联系。

**[Paper URL](https://proceedings.mlr.press/v202/nguyen23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nguyen23c/nguyen23c.pdf)** 

# Deep Clustering with Incomplete Noisy Pairwise Annotations: A Geometric Regularization Approach
**题目:** 不完整的噪声对称注释的深 clustering:一种地质调节方法

**作者:** Tri Nguyen, Shahana Ibrahim, Xiao Fu

**Abstract:** The recent integration of deep learning and pairwise similarity annotation-based constrained clustering—i.e., deep constrained clustering (DCC)—has proven effective for incorporating weak supervision into massive data clustering: Less than 1% of pair similarity annotations can often substantially enhance the clustering accuracy. However, beyond empirical successes, there is a lack of understanding of DCC. In addition, many DCC paradigms are sensitive to annotation noise, but performance-guaranteed noisy DCC methods have been largely elusive. This work first takes a deep look into a recently emerged logistic loss function of DCC, and characterizes its theoretical properties. Our result shows that the logistic DCC loss ensures the identifiability of data membership under reasonable conditions, which may shed light on its effectiveness in practice. Building upon this understanding, a new loss function based on geometric factor analysis is proposed to fend against noisy annotations. It is shown that even under unknown annotation confusions, the data membership can still be provably identified under our proposed learning criterion. The proposed approach is tested over multiple datasets to validate our claims.

**摘要:** 基于深度学习和双对相似性注释的约束集群(即深度约束集群)最近的整合已经证明,在大规模数据集群中引入弱监管是有效的:对偶相似性注释的1%以下往往能够大大提高集群精度。然而,超越经验的成功,存在对DCC的理解不足。此外,许多DCC范式对注释噪声敏感,但性能保证的噪声DCC方法在很大程度上难以理解。结果表明,即使在未知注释混淆的情况下,我们提出的学习标准仍可证明数据成员身份。我们提出的方法在多个数据集上测试,以验证我们的要求。

**[Paper URL](https://proceedings.mlr.press/v202/nguyen23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nguyen23d/nguyen23d.pdf)** 

# Self-Attention Amortized Distributional Projection Optimization for Sliced Wasserstein Point-Cloud Reconstruction
**题目:** 自控减损分布预测优化,用于斜面水石点云重建

**作者:** Khai Nguyen, Dang Nguyen, Nhat Ho

**Abstract:** Max sliced Wasserstein (Max-SW) distance has been widely known as a solution for less discriminative projections of sliced Wasserstein (SW) distance. In applications that have various independent pairs of probability measures, amortized projection optimization is utilized to predict the “max" projecting directions given two input measures instead of using projected gradient ascent multiple times. Despite being efficient, Max-SW and its amortized version cannot guarantee metricity property due to the sub-optimality of the projected gradient ascent and the amortization gap. Therefore, we propose to replace Max-SW with distributional sliced Wasserstein distance with von Mises-Fisher (vMF) projecting distribution (v-DSW). Since v-DSW is a metric with any non-degenerate vMF distribution, its amortized version can guarantee the metricity when performing amortization. Furthermore, current amortized models are not permutation invariant and symmetric. To address the issue, we design amortized models based on self-attention architecture. In particular, we adopt efficient self-attention architectures to make the computation linear in the number of supports. With the two improvements, we derive self-attention amortized distributional projection optimization and show its appealing performance in point-cloud reconstruction and its downstream applications

**摘要:** Max-SW距离已广为人知,是一种较少分离的施瓦茨泰因(SW)距离投影的解决方案。在具有各种独立的概率计数对的应用程序中,采用 amortized projection optimization来预测“max”投影方向,给出两个输入计数,而不是多次使用投影梯度上升。尽管如此,Max-SW及其 amortized版本不能保证测量特性,因为投影梯度上升的次优性和 amortization gap。因此,我们建议用VMF投影分布(v-DSW)代替Max-SW的分布式施瓦茨泰因距离。v-DSW是任何非退化VMF分布的度量,因此它的 amortized版本可以保证测量特性在进行 amortization。为了解决这个问题,我们设计了基于自注意架构的 amortized模型,特别是采用有效的自注意架构,使支持数的计算线性化。通过这两个改进,我们得到了自注意 amortized分布预测的优化,并在点云重建和下游应用中表现出其吸引力

**[Paper URL](https://proceedings.mlr.press/v202/nguyen23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nguyen23e/nguyen23e.pdf)** 

# Building Neural Networks on Matrix Manifolds: A Gyrovector Space Approach
**题目:** 基于矩阵模型的神经网络构建:一种陀螺空间方法

**作者:** Xuan Son Nguyen, Shuo Yang

**Abstract:** Matrix manifolds, such as manifolds of Symmetric Positive Definite (SPD) matrices and Grassmann manifolds, appear in many applications. Recently, by applying the theory of gyrogroups and gyrovector spaces that is a powerful framework for studying hyperbolic geometry, some works have attempted to build principled generalizations of Euclidean neural networks on matrix manifolds. However, due to the lack of many concepts in gyrovector spaces for the considered manifolds, e.g., the inner product and gyroangles, techniques and mathematical tools provided by these works are still limited compared to those developed for studying hyperbolic geometry. In this paper, we generalize some notions in gyrovector spaces for SPD and Grassmann manifolds, and propose new models and layers for building neural networks on these manifolds. We show the effectiveness of our approach in two applications, i.e., human action recognition and knowledge graph completion.

**摘要:** 矩阵多边形,如对称正确定矩阵的多边形和格拉斯曼多边形,在许多应用中出现。最近,通过应用高压几何学研究的一个有力框架的陀螺群和陀螺空间理论,一些研究尝试在矩阵多边形上建立欧几里德神经网络的原理一般化。然而,由于考虑的多边形的陀螺空间缺乏许多概念,例如内积和陀螺角,这些研究所提供的技术和数学工具与研究高压几何学的理论相比仍然有限。

**[Paper URL](https://proceedings.mlr.press/v202/nguyen23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nguyen23f/nguyen23f.pdf)** 

# Simple Disentanglement of Style and Content in Visual Representations
**题目:** 视觉表示中的风格和内容的简单解散

**作者:** Lilian Ngweta, Subha Maity, Alex Gittens, Yuekai Sun, Mikhail Yurochkin

**Abstract:** Learning visual representations with interpretable features, i.e., disentangled representations, remains a challenging problem. Existing methods demonstrate some success but are hard to apply to large-scale vision datasets like ImageNet. In this work, we propose a simple post-processing framework to disentangle content and style in learned representations from pre-trained vision models. We model the pre-trained features probabilistically as linearly entangled combinations of the latent content and style factors and develop a simple disentanglement algorithm based on the probabilistic model. We show that the method provably disentangles content and style features and verify its efficacy empirically. Our post-processed features yield significant domain generalization performance improvements when the distribution shift occurs due to style changes or style-related spurious correlations.

**摘要:** 学习可解释特征的视觉表示,即分散式表示,仍然是一个挑战性问题。现有的方法显示了一些成功,但很难应用于像ImageNet这样的大规模视觉数据集。在这项工作中,我们提出了一种简单的后处理框架,以从预训练视觉模型中学习的表示中分散内容和风格。我们将预训练特征作为潜在内容和风格因素线性结合的概率模型,并基于概率模型开发了一个简单的分散式算法。

**[Paper URL](https://proceedings.mlr.press/v202/ngweta23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ngweta23a/ngweta23a.pdf)** 

# MetaDiffuser: Diffusion Model as Conditional Planner for Offline Meta-RL
**题目:** MetaDiffuser: Offline Meta-RL的扩散模型作为条件规划器

**作者:** Fei Ni, Jianye Hao, Yao Mu, Yifu Yuan, Yan Zheng, Bin Wang, Zhixuan Liang

**Abstract:** Recently, diffusion model shines as a promising backbone for the sequence modeling paradigm in offline reinforcement learning(RL). However, these works mostly lack the generalization ability across tasks with reward or dynamics change. To tackle this challenge, in this paper we propose a task-oriented conditioned diffusion planner for offline meta-RL(MetaDiffuser), which considers the generalization problem as conditional trajectory generation task with contextual representation. The key is to learn a context conditioned diffusion model which can generate task-oriented trajectories for planning across diverse tasks. To enhance the dynamics consistency of the generated trajectories while encouraging trajectories to achieve high returns, we further design a dual-guided module in the sampling process of the diffusion model. The proposed framework enjoys the robustness to the quality of collected warm-start data from the testing task and the flexibility to incorporate with different task representation method. The experiment results on MuJoCo benchmarks show that MetaDiffuser outperforms other strong offline meta-RL baselines, demonstrating the outstanding conditional generation ability of diffusion architecture.

**摘要:** 近年来,扩散模型在非线性增强学习(RL)中的序列建模范式中发挥了重要作用,但这些工作大多缺乏具有奖励或动态变化的任务间的一般化能力。为了解决这一挑战,本文提出了一种面向任务的条件化扩散规划器,用于非线性 meta-RL(MetaDiffuser),它将一般化问题视为具有上下文表示的条件性轨迹生成任务。关键在于学习一个具有上下文表示的条件化扩散模型,该模型可以产生面向不同任务的规划任务的轨迹。为了提高生成的轨迹的动态一致性,同时鼓励轨迹取得高回报,我们进一步设计了双向导模块。该框架具有从测试任务中收集的热启动数据质量的鲁棒性,并具有不同的任务表示方法的灵活性。MuJoCo指标的实验结果表明MetaDiffuser优于其他强的非线性Meta-RL基准,证明了扩散架构的卓越条件生成能力。

**[Paper URL](https://proceedings.mlr.press/v202/ni23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ni23a/ni23a.pdf)** 

# LEVER: Learning to Verify Language-to-Code Generation with Execution
**题目:** LEVER:学习通过执行验证语言到代码生成

**作者:** Ansong Ni, Srini Iyer, Dragomir Radev, Veselin Stoyanov, Wen-Tau Yih, Sida Wang, Xi Victoria Lin

**Abstract:** The advent of large language models trained on code (code LLMs) has led to significant progress in language-to-code generation. State-of-the-art approaches in this area combine LLM decoding with sample pruning and reranking using test cases or heuristics based on the execution results. However, it is challenging to obtain test cases for many real-world language-to-code applications, and heuristics cannot well capture the semantic features of the execution results, such as data type and value range, which often indicates the correctness of the program. In this work, we propose LEVER, a simple approach to improve language-to-code generation by learning to verify the generated programs with their execution results. Specifically, we train verifiers to determine whether a program sampled from the LLMs is correct or not based on the natural language input, the program itself and its execution results. The sampled programs are reranked by combining the verification score with the LLM generation probability, and marginalizing over programs with the same execution results. On four datasets across the domains of table QA, math QA and basic Python programming, LEVER consistently improves over the base code LLMs (4.6% to 10.9% with code-davinci-002) and achieves new state-of-the-art results on all of them.

**摘要:** 基于代码的大型语言模型(code LLMs)的出现导致了语言到代码生成方面的重大进展。在这一领域,最先进的方法将LLM解码与使用测试案例或基于执行结果的启发法进行样品剪切和重新排序相结合。然而,对于许多实际语言到代码应用来说,很难获得测试案例,启发法无法很好地捕捉执行结果的语义特征,如数据类型和值范围,这往往表明程序的正确性。通过将验证分数与LLM生成概率相结合,重新排序抽样的程序,并将其与相同的执行结果相比边缘化。在表QA、数学QA和基本Python编程的四个数据集中,LEVER连续改善了基本代码LLM( code-davinci-002)的4.2%到10.9%,并实现了所有这些代码上的最新结果。

**[Paper URL](https://proceedings.mlr.press/v202/ni23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ni23b/ni23b.pdf)** 

# Continual Vision-Language Representation Learning with Off-Diagonal Information
**题目:** 持续的视觉语言表达学习与非线性信息

**作者:** Zixuan Ni, Longhui Wei, Siliang Tang, Yueting Zhuang, Qi Tian

**Abstract:** Large-scale multi-modal contrastive learning frameworks like CLIP typically require a large amount of image-text samples for training. However, these samples are always collected continuously in real scenarios. This paper discusses the feasibility of continual CLIP training using streaming data. Unlike continual learning based on self-supervised learning methods for pure images, which is empirically robust against catastrophic forgetting, CLIP’s performance degeneration in the continual setting is significant and non-neglectable. By analyzing the changes in the model’s representation space during continual CLIP training from a spatial geometry perspective, we explore and summarize these spatial variations as Spatial Disorder (SD), which can be divided into Intra-modal Rotation and Inter-modal Deviation. Moreover, we empirically and theoretically demonstrate how SD leads to a performance decline for CLIP on cross-modal retrieval tasks. To alleviate SD, we propose a new continual vision-language representation learning framework Mod-X: Maintain off-diagonal information-matriX. By selectively aligning the off-diagonal information distribution of contrastive matrices, the Mod-X improves the capability of the multi-modal model by maintaining the multi-modal representation space alignment on the old data domain during continuously fitting the new training data domain. Experiments on commonly used datasets with different scales and scopes have demonstrated the effectiveness of our method.

**摘要:** 大型多模对比性学习框架,如CLIP,通常需要大量图像文本样本进行训练,但这些样本总是在实际场景中不断收集。本文讨论了利用流数据进行持续CLIP训练的可行性。与基于自我监督的纯图像学习方法的持续学习不同,这种学习方法对灾难性遗忘具有实证的鲁棒性,在持续环境下CLIP的性能退化是显著的,而且是不可抑制的。通过从空间几何角度对持续CLIP训练期间模型的表示空间的变化进行分析,我们对这些空间变异进行了研究和总结,将其分为内模转动和内模变异。为了减轻 SD 问题,我们提出了一种新的连续视觉语言表示学习框架 Mod-X: 保持非直角信息矩阵.通过选择性调整对比性矩阵的非直角信息分布, Mod-X 通过在不断调整新培训数据域时,在旧数据域上保持多模态表示空间排列,提高了多模态模型的性能。

**[Paper URL](https://proceedings.mlr.press/v202/ni23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ni23c/ni23c.pdf)** 

# Attributing Image Generative Models using Latent Fingerprints
**题目:** 使用隐形指纹的图像生成模型

**作者:** Guangyu Nie, Changhoon Kim, Yezhou Yang, Yi Ren

**Abstract:** Generative models have enabled the creation of contents that are indistinguishable from those taken from nature. Open-source development of such models raised concerns about the risks of their misuse for malicious purposes. One potential risk mitigation strategy is to attribute generative models via fingerprinting. Current fingerprinting methods exhibit a significant tradeoff between robust attribution accuracy and generation quality while lacking design principles to improve this tradeoff. This paper investigates the use of latent semantic dimensions as fingerprints, from where we can analyze the effects of design variables, including the choice of fingerprinting dimensions, strength, and capacity, on the accuracy-quality tradeoff. Compared with previous SOTA, our method requires minimum computation and is more applicable to large-scale models. We use StyleGAN2 and the latent diffusion model to demonstrate the efficacy of our method.

**摘要:** 生成模型能够与从自然界中获取的无可区分的内容创建起来。这种模型的开放源代码开发引起了对其恶意用途的误用风险的关注。一个潜在的风险减低策略是通过指纹归纳生成模型。当前的指纹方法显示出强大的归纳精度和生成质量之间的重大交换,同时缺乏设计原则来改善这种交换。本论文研究了隐形语义维度作为指纹的使用,从那里我们可以分析设计变量的影响,包括指纹维度、强度和容量的选择,在精度和质量的交换上。

**[Paper URL](https://proceedings.mlr.press/v202/nie23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nie23a/nie23a.pdf)** 

# A Framework for Adapting Offline Algorithms to Solve Combinatorial Multi-Armed Bandit Problems with Bandit Feedback
**题目:** 基于带头反馈的综合多武器带头问题的非线性算法适应框架

**作者:** Guanyu Nie, Yididiya Y. Nadew, Yanhui Zhu, Vaneet Aggarwal, Christopher John Quinn

**Abstract:** We investigate the problem of stochastic, combinatorial multi-armed bandits where the learner only has access to bandit feedback and the reward function can be non-linear. We provide a general framework for adapting discrete offline approximation algorithms into sublinear $\alpha$-regret methods that only require bandit feedback, achieving $\mathcal{O}\left(T^\frac{2}{3}\log(T)^\frac{1}{3}\right)$ expected cumulative $\alpha$-regret dependence on the horizon $T$. The framework only requires the offline algorithms to be robust to small errors in function evaluation. The adaptation procedure does not even require explicit knowledge of the offline approximation algorithm — the offline algorithm can be used as black box subroutine. To demonstrate the utility of the proposed framework, the proposed framework is applied to multiple problems in submodular maximization, adapting approximation algorithms for cardinality and for knapsack constraints. The new CMAB algorithms for knapsack constraints outperform a full-bandit method developed for the adversarial setting in experiments with real-world data.

**摘要:** 我们研究了随机、组合性多武器带子的问题,其中学习者只可访问带子反馈,并且奖励函数是非线性。我们提供了一个适应离散非线性近似算法的一般框架,以实现仅需要带子反馈的非线性 $\alpha$-regret 方法,实现 $\mathcal{O}\left(T^\frac{2}{3}\log(T)^\frac{1}{3}\right)$ 预期累积 $\alpha$-regret 依赖于水平 $T$。该框架只要求非线性近似算法在函数评价中小错误的鲁棒性。新的CMAB算法对于手提包约束性能优于针对实物数据的实验中敌对环境开发的全带式方法。

**[Paper URL](https://proceedings.mlr.press/v202/nie23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nie23b/nie23b.pdf)** 

# SinFusion: Training Diffusion Models on a Single Image or Video
**题目:** SinFusion:在单一图像或视频上训练扩散模型

**作者:** Yaniv Nikankin, Niv Haim, Michal Irani

**Abstract:** Diffusion models exhibited tremendous progress in image and video generation, exceeding GANs in quality and diversity. However, they are usually trained on very large datasets and are not naturally adapted to manipulate a given input image or video. In this paper we show how this can be resolved by training a diffusion model on a single input image or video. Our image/video-specific diffusion model (SinFusion) learns the appearance and dynamics of the single image or video, while utilizing the conditioning capabilities of diffusion models. It can solve a wide array of image/video-specific manipulation tasks. In particular, our model can learn from few frames the motion and dynamics of a single input video. It can then generate diverse new video samples of the same dynamic scene, extrapolate short videos into long ones (both forward and backward in time) and perform video upsampling. Most of these tasks are not realizable by current video-specific generation methods.

**摘要:** 扩散模型在图像和视频生成中表现出巨大的进步,在质量和多样性上超过GAN。然而,它们通常是训练在非常大的数据集上,并不会自然地适应来操纵给定的输入图像或视频。在本论文中,我们展示如何通过训练一个扩散模型在单一输入图像或视频来解决这一问题。我们的图像/视频特有扩散模型(SinFusion)学习单一图像或视频的外观和动态,同时利用扩散模型的条件能力。它可以解决一个广泛的图像/视频特有操纵任务。

**[Paper URL](https://proceedings.mlr.press/v202/nikankin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nikankin23a/nikankin23a.pdf)** 

# SparseProp: Efficient Sparse Backpropagation for Faster Training of Neural Networks at the Edge
**题目:** SparseProp:高效的备用后置安装技术,提高神经网络在边缘的训练速度

**作者:** Mahdi Nikdan, Tommaso Pegolotti, Eugenia Iofinova, Eldar Kurtic, Dan Alistarh

**Abstract:** We provide an efficient implementation of the backpropagation algorithm, specialized to the case where the weights of the neural network being trained are sparse. Our algorithm is general, as it applies to arbitrary (unstructured) sparsity and common layer types (e.g., convolutional or linear). We provide a fast vectorized implementation on commodity CPUs, and show that it can yield speedups in end-to-end runtime experiments, both in transfer learning using already-sparsified networks, and in training sparse networks from scratch. Thus, our results provide the first support for sparse training on commodity hardware.

**摘要:** 我们提供一种针对训练神经网络的负载稀疏的快速实现 backpropagation算法。我们的算法是通用的,因为它适用于任意的(非结构的)稀疏和常见的层类型(例如,卷积或线性)。我们提供一种快速向量化实现 commodity CPUs,并表明它可以在端到端运行时实验中产生速度提升,无论是在使用已经稀疏的网络进行转移学习还是从零开始训练稀疏网络。

**[Paper URL](https://proceedings.mlr.press/v202/nikdan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nikdan23a/nikdan23a.pdf)** 

# Anti-Exploration by Random Network Distillation
**题目:** 随机网络蒸馏反探测

**作者:** Alexander Nikulin, Vladislav Kurenkov, Denis Tarasov, Sergey Kolesnikov

**Abstract:** Despite the success of Random Network Distillation (RND) in various domains, it was shown as not discriminative enough to be used as an uncertainty estimator for penalizing out-of-distribution actions in offline reinforcement learning. In this paper, we revisit these results and show that, with a naive choice of conditioning for the RND prior, it becomes infeasible for the actor to effectively minimize the anti-exploration bonus and discriminativity is not an issue. We show that this limitation can be avoided with conditioning based on Feature-wise Linear Modulation (FiLM), resulting in a simple and efficient ensemble-free algorithm based on Soft Actor-Critic. We evaluate it on the D4RL benchmark, showing that it is capable of achieving performance comparable to ensemble-based methods and outperforming ensemble-free approaches by a wide margin.

**摘要:** 尽管 Random Network Distillation(RND)在不同领域取得了成功,但它被证明不具有足够的歧视性,以作为非线性增强学习中的非分配行为惩罚的不确定性估计器。本文再次回顾了这些结果,并表明,在RND的条件选择中,无法有效地减少反探索奖金和歧视性问题。我们表明,这种限制可以通过基于Feature-wise Linear Modulation(FiLM)的条件化来避免,从而实现基于 Soft Actor-Critic的简单高效的组合自由算法。

**[Paper URL](https://proceedings.mlr.press/v202/nikulin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nikulin23a/nikulin23a.pdf)** 

# Input Perturbation Reduces Exposure Bias in Diffusion Models
**题目:** 输入干扰降低扩散模型的暴露偏差

**作者:** Mang Ning, Enver Sangineto, Angelo Porrello, Simone Calderara, Rita Cucchiara

**Abstract:** Denoising Diffusion Probabilistic Models have shown an impressive generation quality although their long sampling chain leads to high computational costs. In this paper, we observe that a long sampling chain also leads to an error accumulation phenomenon, which is similar to the exposure bias problem in autoregressive text generation. Specifically, we note that there is a discrepancy between training and testing, since the former is conditioned on the ground truth samples, while the latter is conditioned on the previously generated results. To alleviate this problem, we propose a very simple but effective training regularization, consisting in perturbing the ground truth samples to simulate the inference time prediction errors. We empirically show that, without affecting the recall and precision, the proposed input perturbation leads to a significant improvement in the sample quality while reducing both the training and the inference times. For instance, on CelebA 64x64, we achieve a new state-of-the-art FID score of 1.27, while saving 37.5% of the training time. The code is available at https://github.com/forever208/DDPM-IP

**摘要:** 本文指出,长期采样链还会导致误差累积现象,类似于自回归文本生成中的曝光偏差问题。具体而言,我们注意到训练与测试之间存在差异,因为前者是基于实地样本的,而后者是基于先前生成的结果的。为了缓解这一问题,我们提出了一种非常简单但有效的训练规格化,包括干扰实地样本模拟推断时间预测误差。我们实验证明,在没有影响回想和精度的情况下,建议的输入扰动导致样本质量的显著提高,同时降低了训练和推断时间。例如,在CelebA64x64上,我们实现了最新FID分数1.27,同时节省了37.5%的训练时间。代码在 https://github.com/forever208/DDPM-IP

**[Paper URL](https://proceedings.mlr.press/v202/ning23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ning23a/ning23a.pdf)** 

# Primal and Dual Analysis of Entropic Fictitious Play for Finite-sum Problems
**题目:** 有限总数问题内tropic虚构游戏的初始和双重分析

**作者:** Atsushi Nitanda, Kazusato Oko, Denny Wu, Nobuhito Takenouchi, Taiji Suzuki

**Abstract:** The entropic fictitious play (EFP) is a recently proposed algorithm that minimizes the sum of a convex functional and entropy in the space of measures — such an objective naturally arises in the optimization of a two-layer neural network in the mean-field regime. In this work, we provide a concise primal-dual analysis of EFP in the setting where the learning problem exhibits a finite-sum structure. We establish quantitative global convergence guarantees for both the continuous-time and discrete-time dynamics based on properties of a proximal Gibbs measure introduced in Nitanda et al. (2022). Furthermore, our primal-dual framework entails a memory-efficient particle-based implementation of the EFP update, and also suggests a connection to gradient boosting methods. We illustrate the efficiency of our novel implementation in experiments including neural network optimization and image synthesis.

**摘要:** 熵虚构游戏(英语:Entropic fictitious play,简称EFP)是最近提出的最小化凸函数和测量空间内熵的算法,这种目标自然地产生于中场模式下的双层神经网络优化中。本研究中,我们提供了在学习问题显示有限总结构的环境中简洁的EFP初级双向分析。我们建立了基于Nitanda等人(2022)引入的近距离吉布斯测量的性质的连续时间和离散时间动力学的量化全球收敛性保证。

**[Paper URL](https://proceedings.mlr.press/v202/nitanda23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nitanda23a/nitanda23a.pdf)** 

# The Statistical Scope of Multicalibration
**题目:** 多校正的统计范围

**作者:** Georgy Noarov, Aaron Roth

**Abstract:** We make a connection between multicalibration and property elicitation and show that (under mild technical conditions) it is possible to produce a multicalibrated predictor for a continuous scalar property $\Gamma$ if and only if $\Gamma$ is elicitable. On the negative side, we show that for non-elicitable continuous properties there exist simple data distributions on which even the true distributional predictor is not calibrated. On the positive side, for elicitable $\Gamma$, we give simple canonical algorithms for the batch and the online adversarial setting, that learn a $\Gamma$-multicalibrated predictor. This generalizes past work on multicalibrated means and quantiles, and in fact strengthens existing online quantile multicalibration results. To further counter-weigh our negative result, we show that if a property $\Gamma^1$ is not elicitable by itself, but is elicitable conditionally on another elicitable property $\Gamma^0$, then there is a canonical algorithm that jointly multicalibrates $\Gamma^1$ and $\Gamma^0$; this generalizes past work on mean-moment multicalibration. Finally, as applications of our theory, we provide novel algorithmic and impossibility results for fair (multicalibrated) risk assessment.

**摘要:** 我们建立了多校正与属性诱导之间的联系,并表明(在温和的技术条件下)如果且仅在$\Gamma$可诱导的情况下,可以生成一个连续 scalar property $\Gamma$的多校正预测器。在负面上,我们表明,对于非诱导的连续属性存在简单的数据分布,甚至真正的分布预测器也未进行校正。在正面上,对于可诱导的$\Gamma$,我们为批量和在线敌对设置提供简单的规范算法,从而学习一个$\Gamma$-多校正预测器。为了进一步对负结果进行反权衡,我们证明,如果一个 $\Gamma^1$ 的属性本身不是可引取的,而是可以引取的条件是另一个可引取的 $\Gamma^0$ 的属性,那么有一个共同多校准 $\Gamma^1$ 和 $\Gamma^0$ 的标准算法,这将过去在中场多校准工作推广到一般。

**[Paper URL](https://proceedings.mlr.press/v202/noarov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/noarov23a/noarov23a.pdf)** 

# Do Embodied Agents Dream of Pixelated Sheep: Embodied Decision Making using Language Guided World Modelling
**题目:** 用语言指导的世界建模决策:用语言指导的世界建模决策

**作者:** Kolby Nottingham, Prithviraj Ammanabrolu, Alane Suhr, Yejin Choi, Hannaneh Hajishirzi, Sameer Singh, Roy Fox

**Abstract:** Reinforcement learning (RL) agents typically learn tabula rasa, without prior knowledge of the world. However, if initialized with knowledge of high-level subgoals and transitions between subgoals, RL agents could utilize this Abstract World Model (AWM) for planning and exploration. We propose using few-shot large language models (LLMs) to hypothesize an AWM, that will be verified through world experience, to improve sample efficiency of RL agents. Our DECKARD agent applies LLM-guided exploration to item crafting in Minecraft in two phases: (1) the Dream phase where the agent uses an LLM to decompose a task into a sequence of subgoals, the hypothesized AWM; and (2) the Wake phase where the agent learns a modular policy for each subgoal and verifies or corrects the hypothesized AWM. Our method of hypothesizing an AWM with LLMs and then verifying the AWM based on agent experience not only increases sample efficiency over contemporary methods by an order of magnitude but is also robust to and corrects errors in the LLM, successfully blending noisy internet-scale information from LLMs with knowledge grounded in environment dynamics.

**摘要:** 强化学习(RL)代理人通常学习 tabula rasa, 不需事先了解世界. 然而,如果以高级别子目标的知识和子目标之间的转换为初始,RL代理人可以利用这个抽象世界模型(AWM)进行规划和探索. 我们建议使用少数镜头的大型语言模型(LLMs)来假设一个AWM,将通过世界经验验证,以提高RL代理人的样本效率. 我们的DECKARD代理人将LLM指导的探索应用到 Minecraft 项目制作中两个阶段: (1)梦期,代理人使用LLM分解一个任务为子目标的序列,假设的AWM; (2)醒期,代理人学习每个子目标的模块化政策,并验证或修正假设的AWM。基于代理经验的假设AWM与LLM并验证AWM的方法不仅比现代方法提高样品效率,而且对LLM的误差进行了较强的修正,成功地将LLM的噪声网络尺度信息与基于环境动力学的知识结合起来。

**[Paper URL](https://proceedings.mlr.press/v202/nottingham23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nottingham23a/nottingham23a.pdf)** 

# Gradient-Free Structured Pruning with Unlabeled Data
**题目:** 无标记数据的无梯度结构剪切

**作者:** Azade Nova, Hanjun Dai, Dale Schuurmans

**Abstract:** Large Language Models (LLMs) have achieved great success in solving difficult tasks across many domains, but such success comes with a high computation cost, and inference latency. As developers and third parties customize these models, the need to provide efficient inference has increased. Many efforts have attempted to reduce inference cost through model compression techniques such as pruning and distillation. However, these techniques either require labeled data, or are time-consuming as they require the compressed model to be retrained to regain accuracy. In this paper, we propose a gradient-free structured pruning framework that uses only unlabeled data. An evaluation on the GLUE and SQuAD benchmarks using BERT$_{BASE}$ and DistilBERT illustrates the effectiveness of the proposed approach. By only using the weights of the pre-trained model and unlabeled data, in a matter of a few minutes on a single GPU, up to 40% of the original FLOP count can be reduced with less than a $4%$ accuracy loss across all tasks considered.

**摘要:** 大型语言模型(LLMs)在解决许多领域中的困难任务方面取得了巨大的成功,但这种成功伴随高计算成本和推导延迟。随着开发者和第三方定制这些模型,提供有效的推导的需要有所增加。许多努力试图通过模型压缩技术减少推导成本,例如剪切和蒸馏。然而,这些技术要么要求标签数据,要么耗费时间,因为它们要求压缩模型重新训练以获得准确性。只要使用预训练模型的重量和未标记的数据,在单个GPU上只需几分钟,可以减少原来的FLOP数额的40%,在所有考虑的任务中精度损失不到$4%。

**[Paper URL](https://proceedings.mlr.press/v202/nova23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/nova23a/nova23a.pdf)** 

# CHiLS: Zero-Shot Image Classification with Hierarchical Label Sets
**题目:** CHiLS: Zero-Shot图像分类与层次标签集

**作者:** Zachary Novack, Julian Mcauley, Zachary Chase Lipton, Saurabh Garg

**Abstract:** Open vocabulary models (e.g. CLIP) have shown strong performance on zero-shot classification through their ability generate embeddings for each class based on their (natural language) names. Prior work has focused on improving the accuracy of these models through prompt engineering or by incorporating a small amount of labeled downstream data (via finetuning). However, there has been little focus on improving the richness of the class names themselves, which can pose issues when class labels are coarsely-defined and are uninformative. We propose Classification with Hierarchical Label Sets (or CHiLS), an alternative strategy for zero-shot classification specifically designed for datasets with implicit semantic hierarchies. CHiLS proceeds in three steps: (i) for each class, produce a set of subclasses, using either existing label hierarchies or by querying GPT-3; (ii) perform the standard zero-shot CLIP procedure as though these subclasses were the labels of interest; (iii) map the predicted subclass back to its parent to produce the final prediction. Across numerous datasets with underlying hierarchical structure, CHiLS leads to improved accuracy in situations both with and without ground-truth hierarchical information. CHiLS is simple to implement within existing zero-shot pipelines and requires no additional training cost. Code is available at: https://github.com/acmi-lab/CHILS.

**摘要:** 开放词汇模型(例如CLIP)通过其能力生成基于其(自然语言)名称的每个类别的嵌入式,在零射击分类上表现出了很强的性能。以前的工作重点是通过快速工程改进这些模型的准确性,或通过采用少量标记下游数据(通过微调)来改进这些模型。然而,很少注重改进类别名称本身的丰富性,因为类别标记是粗糙定义的,并且不具有信息性。CHiLS在三个步骤中进行: (i)为每个类生成一套子类,使用既存的标签层次结构或查询GPT-3; (ii)执行标准零击CLIP程序,就像这些子类是感兴趣的标签; (iii)将预料的子类映射回其母类,以产生最后的预测。在基础层次结构的多个数据集中,CHiLS导致与和没有地面事实层次信息的情况的精度提高。CHiLS可以在现有零击管道内实现,不需要额外培训费用。

**[Paper URL](https://proceedings.mlr.press/v202/novack23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/novack23a/novack23a.pdf)** 

# Few-bit Backward: Quantized Gradients of Activation Functions for Memory Footprint Reduction
**题目:** 微分后退:减少内存脚印的激活函数的量化梯度

**作者:** Georgii Sergeevich Novikov, Daniel Bershatsky, Julia Gusak, Alex Shonenkov, Denis Valerievich Dimitrov, Ivan Oseledets

**Abstract:** Memory footprint is one of the main limiting factors for large neural network training. In backpropagation, one needs to store the input to each operation in the computational graph. Every modern neural network model has quite a few pointwise nonlinearities in its architecture, and such operations induce additional memory costs that, as we show, can be significantly reduced by quantization of the gradients. We propose a systematic approach to compute optimal quantization of the retained gradients of the pointwise nonlinear functions with only a few bits per each element. We show that such approximation can be achieved by computing an optimal piecewise-constant approximation of the derivative of the activation function, which can be done by dynamic programming. The drop-in replacements are implemented for all popular nonlinearities and can be used in any existing pipeline. We confirm the memory reduction and the same convergence on several open benchmarks.

**摘要:** 内存脚印是大型神经网络训练的主要限制因素之一。在后向配置中,需要在计算图中存储每个操作的输入。每个现代神经网络模型在其架构中具有相当数量的点向非线性,这些操作诱导额外的内存成本,如我们所显示的,可以通过梯度的定量化大大减少。我们提出了一种系统的方法来计算点向非线性函数的保留梯度的最优定量化,每个元素只有少数位数。我们表明,这种近似可以通过计算点向非线性函数的导数的最优断片近似,以动态编程实现。

**[Paper URL](https://proceedings.mlr.press/v202/novikov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/novikov23a/novikov23a.pdf)** 

# Efficient Exploration via Epistemic-Risk-Seeking Policy Optimization
**题目:** 基于pistemic-risk-seeking政策优化的有效探索

**作者:** Brendan O’Donoghue

**Abstract:** Exploration remains a key challenge in deep reinforcement learning (RL). Optimism in the face of uncertainty is a well-known heuristic with theoretical guarantees in the tabular setting, but how best to translate the principle to deep reinforcement learning, which involves online stochastic gradients and deep network function approximators, is not fully understood. In this paper we propose a new, differentiable optimistic objective that when optimized yields a policy that provably explores efficiently, with guarantees even under function approximation. Our new objective is a zero-sum two-player game derived from endowing the agent with an epistemic-risk-seeking utility function, which converts uncertainty into value and encourages the agent to explore uncertain states. We show that the solution to this game minimizes an upper bound on the regret, with the ’players’ each attempting to minimize one component of a particular regret decomposition. We derive a new model-free algorithm which we call ’epistemic-risk-seeking actor-critic’ (ERSAC), which is simply an application of simultaneous stochastic gradient ascent-descent to the game. Finally, we discuss a recipe for incorporating off-policy data and show that combining the risk-seeking objective with replay data yields a double benefit in terms of statistical efficiency. We conclude with some results showing good performance of a deep RL agent using the technique on the challenging ’DeepSea’ environment, showing significant performance improvements even over other efficient exploration techniques, as well as improved performance on the Atari benchmark.

**摘要:** 深入增强学习(英语:deep reinforcement learning, RL)仍然是一个关键的挑战。面对不确定性的乐观主义是具有理论保障的众所周知的启发主义,但如何最好地将这一原则转化为深入增强学习,包括在线随机梯度和深网络函数近似器,尚不完全理解。本论文提出了一种新的可区分的乐观目标,当优化时产生可证明有效探索的政策,甚至在函数近似下也有保证。我们的新目标是从赋予代理人以pistemic-risk-seeking实用函数的零sum双人游戏,将不确定性转化为价值,并鼓励代理人探索不确定状态。我们提出了一种新的无模型算法,我们称之为“pistemic-risk-seeking actor-critic”(ERSAC),该算法只是对游戏的随机梯度上升下降的简单应用。最后,我们讨论了将非政策数据结合起来的方法,并表明,将风险寻求目标和重演数据结合起来,在统计效率方面产生双重效益。

**[Paper URL](https://proceedings.mlr.press/v202/o-donoghue23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/o-donoghue23a/o-donoghue23a.pdf)** 

# Provable Benefit of Mixup for Finding Optimal Decision Boundaries
**题目:** 混合物对寻找最佳决策界限提供好处

**作者:** Junsoo Oh, Chulhee Yun

**Abstract:** We investigate how pair-wise data augmentation techniques like Mixup affect the sample complexity of finding optimal decision boundaries in a binary linear classification problem. For a family of data distributions with a separability constant $\kappa$, we analyze how well the optimal classifier in terms of training loss aligns with the optimal one in test accuracy (i.e., Bayes optimal classifier). For vanilla training without augmentation, we uncover an interesting phenomenon named the curse of separability. As we increase $\kappa$ to make the data distribution more separable, the sample complexity of vanilla training increases exponentially in $\kappa$; perhaps surprisingly, the task of finding optimal decision boundaries becomes harder for more separable distributions. For Mixup training, we show that Mixup mitigates this problem by significantly reducing the sample complexity. To this end, we develop new concentration results applicable to $n^2$ pair-wise augmented data points constructed from $n$ independent data, by carefully dealing with dependencies between overlapping pairs. Lastly, we study other masking-based Mixup-style techniques and show that they can distort the training loss and make its minimizer converge to a suboptimal classifier in terms of test accuracy.

**摘要:** 我们研究了像Mixup这样的双向数据增强技术如何影响在二进制线性分类问题中找到最佳决策界限的样品复杂度。 对于具有分离性常数的数据分布的家族,我们分析了最佳分类器在训练损失方面与测试准确度中的最佳分类器(即 Bayes最佳分类器)的一致性。 对于没有增加的瓦尼拉训练,我们揭示了一个叫做分离性诅咒的有趣的现象。为此,我们开发了基于$n$独立数据的$n^2$双向增量数据点的新浓度结果,通过仔细处理重叠的双子之间的依赖性。最后,我们研究了其他基于掩护的混合式技术,并表明它们可以扭曲训练损失并使其最小化器在测试精度方面趋向于亚最佳分类器。

**[Paper URL](https://proceedings.mlr.press/v202/oh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/oh23a/oh23a.pdf)** 

# Shedding a PAC-Bayesian Light on Adaptive Sliced-Wasserstein Distances
**题目:** 将PAC-Bayesian灯放进 adaptative Sliced-Wasserstein距离上

**作者:** Ruben Ohana, Kimia Nadjahi, Alain Rakotomamonjy, Liva Ralaivola

**Abstract:** The Sliced-Wasserstein distance (SW) is a computationally efficient and theoretically grounded alternative to the Wasserstein distance. Yet, the literature on its statistical properties – or, more accurately, its generalization properties – with respect to the distribution of slices, beyond the uniform measure, is scarce. To bring new contributions to this line of research, we leverage the PAC-Bayesian theory and a central observation that SW may be interpreted as an average risk, the quantity PAC-Bayesian bounds have been designed to characterize. We provide three types of results: i) PAC-Bayesian generalization bounds that hold on what we refer as adaptive Sliced-Wasserstein distances, i.e. SW defined with respect to arbitrary distributions of slices (among which data-dependent distributions), ii) a principled procedure to learn the distribution of slices that yields maximally discriminative SW, by optimizing our theoretical bounds, and iii) empirical illustrations of our theoretical findings.

**摘要:** 切片-瓦塞斯泰因距离(SW)是计算效率高、理论基础较强的瓦塞斯泰因距离的替代方案。然而,关于切片分布的统计特性--或更准确地说,其一般化特性--的文献较少。为了为这一研究方向带来新的贡献,我们利用PAC-Bayesian理论和一个中心观察,即SW可以被解释为平均风险,而PAC-Bayesian数量边界设计为特征。SW定义了关于任意分段分布(其中数据依赖分布)、ii)通过优化我们理论界限,学习产生最大歧视性SW的分段分布的原理程序,以及iii)我们理论发现的实证说明。

**[Paper URL](https://proceedings.mlr.press/v202/ohana23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ohana23a/ohana23a.pdf)** 

# Reasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality
**题目:** 随机估计者优于确定性估计者的原因:鲁棒性、一致性和感知性

**作者:** Guy Ohayon, Theo Joseph Adrai, Michael Elad, Tomer Michaeli

**Abstract:** Stochastic restoration algorithms allow to explore the space of solutions that correspond to the degraded input. In this paper we reveal additional fundamental advantages of stochastic methods over deterministic ones, which further motivate their use. First, we prove that any restoration algorithm that attains perfect perceptual quality and whose outputs are consistent with the input must be a posterior sampler, and is thus required to be stochastic. Second, we illustrate that while deterministic restoration algorithms may attain high perceptual quality, this can be achieved only by filling up the space of all possible source images using an extremely sensitive mapping, which makes them highly vulnerable to adversarial attacks. Indeed, we show that enforcing deterministic models to be robust to such attacks profoundly hinders their perceptual quality, while robustifying stochastic models hardly influences their perceptual quality, and improves their output variability. These findings provide a motivation to foster progress in stochastic restoration methods, paving the way to better recovery algorithms.

**摘要:** 首先,我们证明,任何实现完备感知质量的恢复算法及其输出与输入相一致的 must be a posterior sampler, and is thus required to be stochastic. 其次,我们说明 while deterministic restoration algorithms may achieve high perceptual quality, this can be achieved only by filling up the space of all possible source images using an extremely sensitive mapping, which makes them highly vulnerable to adversarial attacks. Indeed, we show that enforcing deterministic models to be robust to such attacks profoundly hinders their perceptual quality, while robustifying stochastic models hardly influences their perceptual quality, and improves their output variability.这些发现为促进随机恢复方法的进步提供了动力,为更好的恢复算法铺平了道路。

**[Paper URL](https://proceedings.mlr.press/v202/ohayon23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ohayon23a/ohayon23a.pdf)** 

# On the Within-Group Fairness of Screening Classifiers
**题目:** 筛选分类器内部公平问题

**作者:** Nastaran Okati, Stratis Tsirtsis, Manuel Gomez Rodriguez

**Abstract:** Screening classifiers are increasingly used to identify qualified candidates in a variety of selection processes. In this context, it has been recently shown that if a classifier is calibrated, one can identify the smallest set of candidates which contains, in expectation, a desired number of qualified candidates using a threshold decision rule. This lends support to focusing on calibration as the only requirement for screening classifiers. In this paper, we argue that screening policies that use calibrated classifiers may suffer from an understudied type of within-group unfairness—they may unfairly treat qualified members within demographic groups of interest. Further, we argue that this type of unfairness can be avoided if classifiers satisfy within-group monotonicity, a natural monotonicity property within each group. Then, we introduce an efficient post-processing algorithm based on dynamic programming to minimally modify a given calibrated classifier so that its probability estimates satisfy within-group monotonicity. We validate our algorithm using US Census survey data and show that within-group monotonicity can often be achieved at a small cost in terms of prediction granularity and shortlist size.

**摘要:** 筛选分类器在各种选择过程中越来越多地被用来识别合格的候选人。在这方面,最近已经表明,如果一个分类器进行校正,人们可以识别最小一组候选人,其中包含在期望中使用阈值决策规则的希望数量的合格候选人。这为筛选分类器的唯一要求提供支持,以校正为焦点。本文认为,使用校正分类器的筛选政策可能受到少量研究的内部不公平类型 — — 它们可能不公平地对待有资格的成员在人口利益集团内。此外,我们认为,如果分类器满足内部单调性,则可以避免这种不公平类型。然后,我们引入基于动态编程的高效后处理算法,以最小限度修改给定的校正分类器,使其概率估计满足群内单调性。我们利用美国人口普查调查数据验证了我们的算法,并表明,群内单调性在预测粒度和短名单大小方面,往往可以低成本实现。

**[Paper URL](https://proceedings.mlr.press/v202/okati23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/okati23a/okati23a.pdf)** 

# Diffusion Models are Minimax Optimal Distribution Estimators
**题目:** 扩散模型是最小最优分布估计器

**作者:** Kazusato Oko, Shunta Akiyama, Taiji Suzuki

**Abstract:** While efficient distribution learning is no doubt behind the groundbreaking success of diffusion modeling, its theoretical guarantees are quite limited. In this paper, we provide the first rigorous analysis on approximation and generalization abilities of diffusion modeling for well-known function spaces. The highlight of this paper is that when the true density function belongs to the Besov space and the empirical score matching loss is properly minimized, the generated data distribution achieves the nearly minimax optimal estimation rates in the total variation distance and in the Wasserstein distance of order one. Furthermore, we extend our theory to demonstrate how diffusion models adapt to low-dimensional data distributions. We expect these results advance theoretical understandings of diffusion modeling and its ability to generate verisimilar outputs.

**摘要:** 本文对已知函数空间的扩散建模的近似和一般化能力进行了初步的 rigorous analysis,指出当真密度函数属于贝索夫空间,经验值匹配损失得到适当的最小化时,生成的数据扩散在总变异距离和维茨泰因距离中达到近最小最优估计率。

**[Paper URL](https://proceedings.mlr.press/v202/oko23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/oko23a/oko23a.pdf)** 

# How Many Perturbations Break This Model? Evaluating Robustness Beyond Adversarial Accuracy
**题目:** 如何打破这一模型?评估超越敌对准确性的鲁棒性

**作者:** Raphael Olivier, Bhiksha Raj

**Abstract:** Robustness to adversarial attacks is typically evaluated with adversarial accuracy. While essential, this metric does not capture all aspects of robustness and in particular leaves out the question of how many perturbations can be found for each point. In this work, we introduce an alternative approach, adversarial sparsity, which quantifies how difficult it is to find a successful perturbation given both an input point and a constraint on the direction of the perturbation. We show that sparsity provides valuable insight into neural networks in multiple ways: for instance, it illustrates important differences between current state-of-the-art robust models them that accuracy analysis does not, and suggests approaches for improving their robustness. When applying broken defenses effective against weak attacks but not strong ones, sparsity can discriminate between the totally ineffective and the partially effective defenses. Finally, with sparsity we can measure increases in robustness that do not affect accuracy: we show for example that data augmentation can by itself increase adversarial robustness, without using adversarial training.

**摘要:** 对敌对攻击的鲁棒性通常以敌对精度进行评估。虽然基本的,这个度量并不包括所有鲁棒性方面,并且特别排除了对每个点能找到多少扰动的问题。在这个工作中,我们介绍了一种替代方法,敌对稀疏性,它量化了在输入点和扰动方向上的约束下找到成功的扰动的难度。最后,通过稀疏度,我们能够测量没有影响精度的鲁棒性增加:例如,我们表明数据增加本身可以增加敌对鲁棒性,而不使用敌对训练。

**[Paper URL](https://proceedings.mlr.press/v202/olivier23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/olivier23a/olivier23a.pdf)** 

# B-Learner: Quasi-Oracle Bounds on Heterogeneous Causal Effects Under Hidden Confounding
**题目:** B-Learner:隐形混乱下的异性致因效应的近核界限

**作者:** Miruna Oprescu, Jacob Dorn, Marah Ghoummaid, Andrew Jesson, Nathan Kallus, Uri Shalit

**Abstract:** Estimating heterogeneous treatment effects from observational data is a crucial task across many fields, helping policy and decision-makers take better actions. There has been recent progress on robust and efficient methods for estimating the conditional average treatment effect (CATE) function, but these methods often do not take into account the risk of hidden confounding, which could arbitrarily and unknowingly bias any causal estimate based on observational data. We propose a meta-learner called the B-Learner, which can efficiently learn sharp bounds on the CATE function under limits on the level of hidden confounding. We derive the B-Learner by adapting recent results for sharp and valid bounds of the average treatment effect (Dorn et al., 2021) into the framework given by Kallus & Oprescu (2023) for robust and model-agnostic learning of conditional distributional treatment effects. The B-Learner can use any function estimator such as random forests and deep neural networks, and we prove its estimates are valid, sharp, efficient, and have a quasi-oracle property with respect to the constituent estimators under more general conditions than existing methods. Semi-synthetic experimental comparisons validate the theoretical findings, and we use real-world data demonstrate how the method might be used in practice.

**摘要:** 从观察数据中估计异质治疗效应是许多领域中的一个关键任务,帮助决策者采取更好的行动。对于估计条件平均治疗效应(CATE)函数的鲁棒和有效的方法最近取得了进展,但这些方法往往不考虑隐藏混乱的风险,这可能任意和无知地偏差基于观察数据的任何因果估计。我们提出了一种名为B-Learner的元学习者,它可以有效学习CATE函数在隐藏混乱水平的限度下的锋利边界。B-Learner可以使用任意函数估计器,例如随机森林和深层神经网络,我们证明它的估计是有效的,锋利,高效,并且在比现有方法更一般条件下对组成估计器具有准离子性质。

**[Paper URL](https://proceedings.mlr.press/v202/oprescu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/oprescu23a/oprescu23a.pdf)** 

# Measuring the Impact of Programming Language Distribution
**题目:** 测定编程语言分布的影响

**作者:** Gabriel Orlanski, Kefan Xiao, Xavier Garcia, Jeffrey Hui, Joshua Howland, Jonathan Malmaud, Jacob Austin, Rishabh Singh, Michele Catasta

**Abstract:** Current benchmarks for evaluating neural code models focus on only a small subset of programming languages, excluding many popular languages such as Go or Rust. To ameliorate this issue, we present the BabelCode framework for execution-based evaluation of any benchmark in any language. BabelCode enables new investigations into the qualitative performance of models’ memory, runtime, and individual test case results. Additionally, we present a new code translation dataset called Translating Python Programming Puzzles (TP3) from the Python Programming Puzzles (Schuster et al., 2021) benchmark that involves translating expert-level python functions to any language. With both BabelCode and the TP3 benchmark, we investigate if balancing the distributions of 14 languages in a training dataset improves a large language model’s performance on low-resource languages. Training a model on a balanced corpus results in, on average, 12.34% higher $pass@k$ across all tasks and languages compared to the baseline. We find that this strategy achieves 66.48% better $pass@k$ on low-resource languages at the cost of only a 12.94% decrease to high-resource languages. In our three translation tasks, this strategy yields, on average, 30.77% better low-resource $pass@k$ while having 19.58% worse high-resource $pass@k$.

**摘要:** 当前评估神经元代码模型的基准仅集中在编程语言的一个小部分,不包括许多流行语言,如Go或Rust。为了改善这一问题,我们提出了 BabelCode框架以执行为基础的评价任何在任何语言中的基准。 BabelCode允许对模型内存、运行时间和个人测试案例结果的质量性能进行新的调查。此外,我们还提出了 Python Programming Puzzles(Schuster et al., 2021)的Python Programming Puzzles的Python Programming Puzzles(TP3)的代码翻译数据集,它涉及向任何语言翻译专家级 python函数。在平衡的文体上培训一个模型的平均结果为12.34%的$pass@k$在所有任务和语言上比基线高。我们发现,这个策略在低资源语言上达到66.48%的$pass@k$,而低资源语言的成本只有12.94%。在我们的三个翻译任务中,这个策略平均获得30.77%的低资源$pass@k$,而低资源$pass@k$的成本则更低。

**[Paper URL](https://proceedings.mlr.press/v202/orlanski23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/orlanski23a/orlanski23a.pdf)** 

# When does Privileged information Explain Away Label Noise?
**题目:** 特权信息什么时候解释Away标签噪音?

**作者:** Guillermo Ortiz-Jimenez, Mark Collier, Anant Nawalgaria, Alexander Nicholas D’Amour, Jesse Berent, Rodolphe Jenatton, Efi Kokiopoulou

**Abstract:** Leveraging privileged information (PI), or features available during training but not at test time, has recently been shown to be an effective method for addressing label noise. However, the reasons for its effectiveness are not well understood. In this study, we investigate the role played by different properties of the PI in explaining away label noise. Through experiments on multiple datasets with real PI (CIFAR-N/H) and a new large-scale benchmark ImageNet-PI, we find that PI is most helpful when it allows networks to easily distinguish clean from noisy data, while enabling a learning shortcut to memorize the noisy examples. Interestingly, when PI becomes too predictive of the target label, PI methods often perform worse than their no-PI baselines. Based on these findings, we propose several enhancements to the state-of-the-art PI methods and demonstrate the potential of PI as a means of tackling label noise. Finally, we show how we can easily combine the resulting PI approaches with existing no-PI techniques designed to deal with label noise.

**摘要:** 利用特权信息(PI)或在训练中可用的特性,但并非在测试时,最近被证明是解决标签噪声的有效方法。然而,其有效性的原因并不十分清楚。在这项研究中,我们研究了PI在解释标签噪声时所扮演的角色。通过对多个数据集的实验(CIFAR-N/H)和一个新的大型基准 ImageNet-PI,我们发现PI在允许网络从噪声数据中容易区分时最有帮助,同时允许学习短cut记住噪声的例子。最后,我们展示了如何轻松地结合结果 PI 方法与现有的无 PI 技术来处理标签噪声。

**[Paper URL](https://proceedings.mlr.press/v202/ortiz-jimenez23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ortiz-jimenez23a/ortiz-jimenez23a.pdf)** 

# Resurrecting Recurrent Neural Networks for Long Sequences
**题目:** 恢复长期序列的重复神经网络

**作者:** Antonio Orvieto, Samuel L Smith, Albert Gu, Anushan Fernando, Caglar Gulcehre, Razvan Pascanu, Soham De

**Abstract:** Recurrent Neural Networks (RNNs) offer fast inference on long sequences but are hard to optimize and slow to train. Deep state-space models (SSMs) have recently been shown to perform remarkably well on long sequence modeling tasks, and have the added benefits of fast parallelizable training and RNN-like fast inference. However, while SSMs are superficially similar to RNNs, there are important differences that make it unclear where their performance boost over RNNs comes from. We show that careful design of deep RNNs using standard signal propagation arguments can recover the impressive performance of deep SSMs on long-range reasoning tasks, while matching their training speed. To achieve this, we analyze and ablate a series of changes to standard RNNs including linearizing and diagonalizing the recurrence, using better parameterizations and initializations, and ensuring careful normalization of the forward pass. Our results provide new insights on the origins of the impressive performance of deep SSMs, and introduce an RNN block called the Linear Recurrent Unit (or LRU) that matches both their performance on the Long Range Arena benchmark and their computational efficiency.

**摘要:** 经常性神经网络(RNNs)在长序中提供快速推导,但很难优化和缓慢训练。深态空间模型(SSMs)最近被证明在长序建模任务中表现突出,并具有快速平行训练和RNN类似快速推导的附加优势。然而, while SSMs are superficially similar to RNNs, there are important differences that make it unclear where their performance boost over RNNs comes from. We show that careful design of deep RNNs using standard signal propagation arguments can recover the impressive performance of deep SSMs on long-range reasoning tasks, while matching their training speed. To achieve this, we analyze and ablate a series of changes to standard RNNs including linearizing and diagonalizing the recurrence, using better parameterizations and initializations, and ensuring careful normalization of the forward我们的研究结果对深层SSM的令人印象深刻性能的起源提供了新的洞察,并介绍了一种叫做直流单元(或LRU)的RNN块,该块的性能与长距离竞技场的基准和计算效率相匹配。

**[Paper URL](https://proceedings.mlr.press/v202/orvieto23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/orvieto23a/orvieto23a.pdf)** 

# Improving Adversarial Robustness Through the Contrastive-Guided Diffusion Process
**题目:** 通过反向导扩散过程提高敌方的鲁棒性

**作者:** Yidong Ouyang, Liyan Xie, Guang Cheng

**Abstract:** Synthetic data generation has become an emerging tool to help improve the adversarial robustness in classification tasks, since robust learning requires a significantly larger amount of training samples compared with standard classification. Among various deep generative models, the diffusion model has been shown to produce high-quality synthetic images and has achieved good performance in improving the adversarial robustness. However, diffusion-type methods are generally slower in data generation as compared with other generative models. Although different acceleration techniques have been proposed recently, it is also of great importance to study how to improve the sample efficiency of synthetic data for the downstream task. In this paper, we first analyze the optimality condition of synthetic distribution for achieving improved robust accuracy. We show that enhancing the distinguishability among the generated data is critical for improving adversarial robustness. Thus, we propose the Contrastive-Guided Diffusion Process (Contrastive-DP), which incorporates the contrastive loss to guide the diffusion model in data generation. We validate our theoretical results using simulations and demonstrate the good performance of Contrastive-DP on image datasets.

**摘要:** 综合数据生成已成为帮助改进分类任务的敌对鲁棒性的一种新兴工具,因为鲁棒学习要求与标准分类相比 significantly larger amount of training samples. 在各种深层生成模型中,扩散模型被证明能够产生高质量的综合图像,并且在改进敌对鲁棒性方面取得了良好的性能。然而,扩散型方法在数据生成中通常比其他生成模型慢。虽然最近提出了不同的加速技术,但研究如何提高下游任务的合成数据的样本效率也是十分重要的。通过仿真验证了仿真结果,并证明了仿真对图像数据集的良好性能。

**[Paper URL](https://proceedings.mlr.press/v202/ouyang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ouyang23a/ouyang23a.pdf)** 

# On the Role of Attention in Prompt-tuning
**题目:** 快速调动中注意力的作用

**作者:** Samet Oymak, Ankit Singh Rawat, Mahdi Soltanolkotabi, Christos Thrampoulidis

**Abstract:** Prompt-tuning is an emerging strategy to adapt large language models (LLM) to downstream tasks by learning a (soft-)prompt parameter from data. Despite its success in LLMs, there is limited theoretical understanding of the power of prompt-tuning and the role of the attention mechanism in prompting. In this work, we explore prompt-tuning for one-layer attention architectures and study contextual mixture-models where each input token belongs to a context-relevant or -irrelevant set. We isolate the role of prompt-tuning through a self-contained prompt-attention model. Our contributions are as follows: (1) We show that softmax-prompt-attention is provably more expressive than softmax-self-attention and linear-prompt-attention under our contextual data model. (2) We analyze the initial trajectory of gradient descent and show that it learns the prompt and prediction head with near-optimal sample complexity and demonstrate how the prompt can provably attend to sparse context-relevant tokens. (3) Assuming a known prompt but an unknown prediction head, we characterize the exact finite sample performance of prompt-attention which reveals the fundamental performance limits and the precise benefit of the context information. We also provide experiments that verify our theoretical insights on real datasets and demonstrate how prompt-tuning enables the model to attend to context-relevant information.

**摘要:** Prompt-tuning是一个新兴的策略,通过从数据中学习一个(软)提示参数来适应大型语言模型(LLM)下游任务。尽管在LLM中取得了成功,但对提示的权力和提示中注意机制的作用的理论理解有限。在这个工作中,我们对一层注意架构的提示进行探索和研究上下文混合模型,其中每个输入符号属于上下文相关或不相关集合。我们通过自包含的提示提示模型分离提示的作用。我们的贡献如下: (1)我们表明,在上下文数据模型下, softmax-prompt-attention比 softmax-self-attention和linear-prompt-attention具有明显的表达性。(三)假设一个已知的提示,但未知的预测头,我们对提示注意的精确有限样本性能进行了描述,从而揭示了基本的性能限制和语境信息的精确利益。我们还提供实验,验证了我们对实际数据集的理论洞察,并证明了提示调制如何使模型能够关注语境相关信息。

**[Paper URL](https://proceedings.mlr.press/v202/oymak23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/oymak23a/oymak23a.pdf)** 

# Revisiting the Linear-Programming Framework for Offline RL with General Function Approximation
**题目:** 基于通用函数近似的非线性规划框架的检讨

**作者:** Asuman E. Ozdaglar, Sarath Pattathil, Jiawei Zhang, Kaiqing Zhang

**Abstract:** Offline reinforcement learning (RL) aims to find an optimal policy for sequential decision-making using a pre-collected dataset, without further interaction with the environment. Recent theoretical progress has focused on developing sample-efficient offline RL algorithms with various relaxed assumptions on data coverage and function approximators, especially to handle the case with excessively large state-action spaces. Among them, the framework based on the linear-programming (LP) reformulation of Markov decision processes has shown promise: it enables sample-efficient offline RL with function approximation, under only partial data coverage and realizability assumptions on the function classes, with favorable computational tractability. In this work, we revisit the LP framework for offline RL, and provide a new reformulation that advances the existing results in several aspects, relaxing certain assumptions and achieving optimal statistical rates in terms of sample size. Our key enabler is to introduce proper constraints in the reformulation, instead of using any regularization as in the literature, also with careful choices of the function classes and initial state distributions. We hope our insights bring into light the use of LP formulations and the induced primal-dual minimax optimization, in offline RL.

**摘要:** 非线性增强学习(英语:Offline reinforcement learning,简称RL)是利用预收集的数据集,在与环境无进一步的相互作用的情况下,为序列决策寻找最佳政策。最近的理论进展主要集中在开发基于数据覆盖和函数近似的各种松弛假设的非线性增强学习算法,特别是处理过大状态行动空间的案例。其中,基于马可夫决策过程的线性编程(LP)改革框架显示了前景:它允许具有函数近似的非线性增强学习算法,仅在函数类的局部数据覆盖和可实现假设下,具有有利的计算处理性。我们的关键启发器是引入适当的约束,而不是像文献中那样使用任何规则化,同时小心选择函数类和初始状态分布。我们希望我们的洞察能揭示在非线性RL中使用LP公式和诱导的初始-二进制最小值优化。

**[Paper URL](https://proceedings.mlr.press/v202/ozdaglar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ozdaglar23a/ozdaglar23a.pdf)** 

# Extrapolative Controlled Sequence Generation via Iterative Refinement
**题目:** 通过迭代精炼的抽取控制序列生成

**作者:** Vishakh Padmakumar, Richard Yuanzhe Pang, He He, Ankur P Parikh

**Abstract:** We study the problem of extrapolative controlled generation, i.e., generating sequences with attribute values beyond the range seen in training. This task is of significant importance in automated design, especially drug discovery, where the goal is to design novel proteins that are better (e.g., more stable) than existing sequences. Thus, by definition the target sequences and their attribute values are out of the training distribution, posing challenges to existing methods that aim to directly generate the target sequence. Instead, in this work, we propose Iterative Controlled Extrapolation (ICE) which iteratively makes local edits to a sequence to enable extrapolation. We train the model on synthetically generated sequence pairs that demonstrate small improvement in the attribute value. Results on one natural language task (sentiment analysis) and two protein engineering tasks (ACE2 stability and AAV fitness) show that ICE outperforms state-of-the-art approaches despite its simplicity.

**摘要:** 我们研究了外推控制生成的问题,即在训练中看到的范围之外生成具有属性值的序列。这一任务在自动化设计中具有重要意义,特别是在药物发现中,其目标是设计比现有序列更好的新蛋白质(例如更稳定的蛋白质)。因此,通过定义,目标序列和它们的属性值已脱离训练分布,对现有的方法提出了挑战,目的是直接生成目标序列。一个自然语言任务(情感分析)和两个蛋白质工程任务(ACE2稳定性和AAV适应性)的结果表明,ICE尽管简单,但仍能超越最先进的方法。

**[Paper URL](https://proceedings.mlr.press/v202/padmakumar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/padmakumar23a/padmakumar23a.pdf)** 

# Locally Regularized Neural Differential Equations: Some Black Boxes were meant to remain closed!
**题目:** 局部调节神经差分方程: 一些黑盒的目的是保持封闭!

**作者:** Avik Pal, Alan Edelman, Christopher Vincent Rackauckas

**Abstract:** Neural Differential Equations have become an important modeling framework due to their ability to adapt to new problems automatically. Training a neural differential equation is effectively a search over a space of plausible dynamical systems. Controlling the computational cost for these models is difficult since it relies on the number of steps the adaptive solver takes. Most prior works have used higher-order methods to reduce prediction timings while greatly increasing training time or reducing both training and prediction timings by relying on specific training algorithms, which are harder to use as a drop-in replacement. In this manuscript, we use internal cost heuristics of adaptive differential equation solvers at stochastic time-points to guide the training towards learning a dynamical system that is easier to integrate. We “close the blackbox” and allow the use of our method with any sensitivity method. We perform experimental studies to compare our method to global regularization to show that we attain similar performance numbers without compromising on the flexibility of implementation. We develop two sampling strategies to trade-off between performance and training time. Our method reduces the number of function evaluations to 0.556x - 0.733x and accelerates predictions by 1.3x - 2x.

**摘要:** 神经微分方程已成为一种重要的建模框架,因为它们能够自动适应新问题。神经微分方程的训练是有效的对可信的动态系统空间的搜索。控制这些模型的计算成本是困难的,因为它依赖于适应性求解器所采取的步骤的数目。大多数以前的工作都使用高阶方法来减少预测时间,同时大大增加训练时间或通过依赖于特定训练算法来减少训练和预测时间,而这些算法更难用作替换。在这个手稿中,我们使用适应性微分方程求解器的内部成本实验,以指导训练学习一种易于集成的动态系统。我们进行实验研究,以比较我们的方法与全球规范化,以证明我们能够达到相似的性能数目,而不影响实现的灵活性。我们开发了两个采样策略,以平衡性能和训练时间。我们的方法减少了函数评价的数目到0.556x - 0.733x,并加快了预测的1.3x - 2x。

**[Paper URL](https://proceedings.mlr.press/v202/pal23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pal23a/pal23a.pdf)** 

# Controlled Differential Equations on Long Sequences via Non-standard Wavelets
**题目:** 通过非标准小波对长序列的控制微分方程

**作者:** Sourav Pal, Zhanpeng Zeng, Sathya N. Ravi, Vikas Singh

**Abstract:** Neural Controlled Differential equations (NCDE) are a powerful mechanism to model the dynamics in temporal sequences, e.g., applications involving physiological measures, where apart from the initial condition, the dynamics also depend on subsequent measures or even a different "control" sequence. But NCDEs do not scale well to longer sequences. Existing strategies adapt rough path theory, and instead model the dynamics over summaries known as log signatures. While rigorous and elegant, invertibility of these summaries is difficult, and limits the scope of problems where these ideas can offer strong benefits (reconstruction, generative modeling). For tasks where it is sensible to assume that the (long) sequences in the training data are a fixed length of temporal measurements – this assumption holds in most experiments tackled in the literature – we describe an efficient simplification. First, we recast the regression/classification task as an integral transform. We then show how restricting the class of operators (permissible in the integral transform), allows the use of a known algorithm that leverages non-standard Wavelets to decompose the operator. Thereby, our task (learning the operator) radically simplifies. A neural variant of this idea yields consistent improvements across a wide gamut of use cases tackled in existing works. We also describe a novel application on modeling tasks involving coupled differential equations.

**摘要:** 神经控制微分方程(英语:Neural Controlled Differential equations,NCDE)是模拟时间序列中的动力学的强有力机制,例如涉及生理措施的应用程序,除了初始条件之外,动力学也依赖于后续措施或甚至不同的“控制”序列。但NCDE并不适用于较长的序列。现有的策略适应粗糙路径理论,而代之模拟时间序列中的动力学,称为日志签名。虽然严格和优雅,这些时间序列的反转性是困难的,并且限制了这些想法能提供强效(重建、生成模型)的问题范围。然后,我们展示了如何限制操作者类(允许在积分变换中),允许使用一种已知的算法,利用非标准波束分解操作者。从而,我们的任务(学习操作者)得到根本的简化。这一想法的神经变异在现有作品中处理的广泛应用案例中产生一致的改进。

**[Paper URL](https://proceedings.mlr.press/v202/pal23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pal23b/pal23b.pdf)** 

# Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the Machiavelli Benchmark
**题目:**  reward 与道德行为之间的交易权衡在马基亚维利 Benchmark 中衡量

**作者:** Alexander Pan, Jun Shern Chan, Andy Zou, Nathaniel Li, Steven Basart, Thomas Woodside, Hanlin Zhang, Scott Emmons, Dan Hendrycks

**Abstract:** Artificial agents have traditionally been trained to maximize reward, which may incentivize power-seeking and deception, analogous to how next-token prediction in language models (LMs) may incentivize toxicity. So do agents naturally learn to be Machiavellian? And how do we measure these behaviors in general-purpose models such as GPT-4? Towards answering these questions, we introduce Machiavelli, a benchmark of 134 Choose-Your-Own-Adventure games containing over half a million rich, diverse scenarios that center on social decision-making. Scenario labeling is automated with LMs, which are more performant than human annotators. We mathematize dozens of harmful behaviors and use our annotations to evaluate agents’ tendencies to be power-seeking, cause disutility, and commit ethical violations. We observe some tension between maximizing reward and behaving ethically. To improve this trade-off, we investigate LM-based methods to steer agents towards less harmful behaviors. Our results show that agents can both act competently and morally, so concrete progress can currently be made in machine ethics–designing agents that are Pareto improvements in both safety and capabilities.

**摘要:** 人工代理人传统上被训练以最大化报酬,这可能刺激权力谋求和欺骗,类似于语言模型中的下位token预测可能刺激毒性。那么代理人自然会学会成为Machiavellian吗?以及我们如何在GPT-4等一般用途模型中衡量这些行为?为了回答这些问题,我们介绍了Machiavelli,134款Choose-Your-Own-Adventure游戏的基准,包含超过50万的丰富多样的场景,集中于社会决策。我们的结果表明,代理人能够具有能力和道德能力,因此目前可以在机器伦理设计中取得具体的进展,这是帕雷托在安全和能力方面的改进。

**[Paper URL](https://proceedings.mlr.press/v202/pan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pan23a/pan23a.pdf)** 

# Beyond Homophily: Reconstructing Structure for Graph-agnostic Clustering
**题目:**  Beyond Homophily: Graph-agnostic Clustering的重建结构

**作者:** Erlin Pan, Zhao Kang

**Abstract:** Graph neural networks (GNNs) based methods have achieved impressive performance on node clustering task. However, they are designed on the homophilic assumption of graph and clustering on heterophilic graph is overlooked. Due to the lack of labels, it is impossible to first identify a graph as homophilic or heterophilic before a suitable GNN model can be found. Hence, clustering on real-world graph with various levels of homophily poses a new challenge to the graph research community. To fill this gap, we propose a novel graph clustering method, which contains three key components: graph reconstruction, a mixed filter, and dual graph clustering network. To be graph-agnostic, we empirically construct two graphs which are high homophily and heterophily from each data. The mixed filter based on the new graphs extracts both low-frequency and high-frequency information. To reduce the adverse coupling between node attribute and topological structure, we separately map them into two subspaces in dual graph clustering network. Extensive experiments on 11 benchmark graphs demonstrate our promising performance. In particular, our method dominates others on heterophilic graphs.

**摘要:** 基于图神经网络(GNN)的方法在节点聚类任务中取得了令人印象深刻的性能。然而,它们是基于图的同性假设设计的,并忽略了对异性图的聚类。由于缺乏标签,在找到合适的GNN模型之前,不可能首先识别一个图为同性或异性。因此,对不同水平的同性聚类对图研究社区提出了新的挑战。为了填补这一空白,我们提出了一种新颖的图聚类方法,它包含三个关键组成部分:图重构、混合滤波器和双重图聚类网络。为了减少节点属性与拓扑结构间的不利耦合,我们分别将它们映射成双重图集群网络中的两个子空间。我们对11个基准图进行了广泛的实验,证明了我们具有良好的性能。

**[Paper URL](https://proceedings.mlr.press/v202/pan23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pan23b/pan23b.pdf)** 

# Better Training of GFlowNets with Local Credit and Incomplete Trajectories
**题目:** 以本地信用和不完整的牵引技术为基础的GFlowNet的更好培训

**作者:** Ling Pan, Nikolay Malkin, Dinghuai Zhang, Yoshua Bengio

**Abstract:** Generative Flow Networks or GFlowNets are related to Monte-Carlo Markov chain methods (as they sample from a distribution specified by an energy function), reinforcement learning (as they learn a policy to sample composed objects through a sequence of steps), generative models (as they learn to represent and sample from a distribution) and amortized variational methods (as they can be used to learn to approximate and sample from an otherwise intractable posterior, given a prior and a likelihood). They are trained to generate an object $x$ through a sequence of steps with probability proportional to some reward function $R(x)$ (or $\exp(-\mathcal{E}(x))$ with $\mathcal{E}(x)$ denoting the energy function), given at the end of the generative trajectory. Like for other RL settings where the reward is only given at the end, the efficiency of training and credit assignment may suffer when those trajectories are longer. With previous GFlowNet work, no learning was possible from incomplete trajectories (lacking a terminal state and the computation of the associated reward). In this paper, we consider the case where the energy function can be applied not just to terminal states but also to intermediate states. This is for example achieved when the energy function is additive, with terms available along the trajectory. We show how to reparameterize the GFlowNet state flow function to take advantage of the partial reward already accrued at each state. This enables a training objective that can be applied to update parameters even with incomplete trajectories. Even when complete trajectories are available, being able to obtain more localized credit and gradients is found to speed up training convergence, as demonstrated across many simulations.

**摘要:** 生成流网络或GFlowNet与蒙特-卡洛马科夫链路方法有关(它们从一个由能量函数指定的分布中采样),增强学习(它们学习通过步骤序列采样构造对象的政策),生成模型(它们学习代表和从分布中采样)和 amortized variational methods(它们可以用于学习近似和从其他难以处理后端采样,给出一个前后和一个可能性)。它们被训练生成一个对象$x$通过步骤序列,与某种奖励函数$R(x)$(或$\exp(-\mathcal{E}(x))$表示能量函数$\mathcal{E}(x)$)的概率比例),给出在生成路径的末端。本文讨论了能量函数不仅可以应用于终端状态,也可以应用于中间状态。例如,当能量函数是增量函数时,可以利用在各状态中已经累积的部分奖励函数来调度GFlowNet状态流函数。这使得可以在不完全的轨道上实现更新参数的训练目标。即使完全的轨道是可用的,也可以获得更多的本地化信用和梯度,以加速训练趋同,正如在许多模拟中所证明。

**[Paper URL](https://proceedings.mlr.press/v202/pan23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pan23c/pan23c.pdf)** 

# A Hybrid Quantum-Classical Approach based on the Hadamard Transform for the Convolutional Layer
**题目:** 基于哈达马德变换的混合量子经典方法

**作者:** Hongyi Pan, Xin Zhu, Salih Furkan Atici, Ahmet Cetin

**Abstract:** In this paper, we propose a novel Hadamard Transform (HT)-based neural network layer for hybrid quantum-classical computing. It implements the regular convolutional layers in the Hadamard transform domain. The idea is based on the HT convolution theorem which states that the dyadic convolution between two vectors is equivalent to the element-wise multiplication of their HT representation. Computing the HT is simply the application of a Hadamard gate to each qubit individually, so the HT computations of our proposed layer can be implemented on a quantum computer. Compared to the regular Conv2D layer, the proposed HT-perceptron layer is computationally more efficient. Compared to a CNN with the same number of trainable parameters and 99.26% test accuracy, our HT network reaches 99.31% test accuracy with 57.1% MACs reduced in the MNIST dataset; and in our ImageNet-1K experiments, our HT-based ResNet-50 exceeds the accuracy of the baseline ResNet-50 by 0.59% center-crop top-1 accuracy using 11.5% fewer parameters with 12.6% fewer MACs.

**摘要:** 本文提出了一种基于哈达马德变换的新型神经网络层,用于混合量子经典计算。该层实现哈达马德变换域中的正态变换层。该构想基于哈达马德变换定理,该定理指出两个向量之间的线性变换等于其HT表示的元素乘法。与具有相同数量的训练参数和99.26%的测试精度的CNN相比,我们的HT网络在MNIST数据集中降低了57.1%的MAC,达到99.31%的测试精度;在我们的ImageNet-1K实验中,我们的HT-based ResNet-50超过了基线resNet-50的0.59%的中心作物顶-1精度,使用1.5%的参数和12.6%的MAC。

**[Paper URL](https://proceedings.mlr.press/v202/pan23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pan23d/pan23d.pdf)** 

# Semi Bandit dynamics in Congestion Games: Convergence to Nash Equilibrium and No-Regret Guarantees.
**题目:** Semi Bandit dynamics in Congestion Games: Convergence to Nash Equilibrium and No-Regret Guarantees(英语:Convergence to Nash Equilibrium and No-Regret Guarantees)。

**作者:** Ioannis Panageas, Stratis Skoulakis, Luca Viano, Xiao Wang, Volkan Cevher

**Abstract:** In this work, we propose introduce a variant of online stochastic gradient descent and prove it converges to Nash equilibria and simultaneously it has sublinear regret for the class of congestion games in the semi-bandit feedback setting. Our proposed method admits convergence rates depending only polynomially on the number of players and the number of facilities, but not on the size of the action set, which can be exponentially large in terms of the number of facilities. Moreover, the running time of our method has polynomial-time dependence on the implicit description of the game. Our analysis exploits techniques from convex geometry, in particular Caratheodory’s theorem and recent advances in non-convex stochastic optimization. This work improves upon and answers an open question from (Cui et al 2022).

**摘要:** 本文提出了一种在线随机梯度降落的变量,并证明该变量会趋于纳什均衡,同时它对半带式反馈设置中的拥挤游戏类有次线性遗憾。我们提出的方法只依赖于玩家数和设施数的多项式,但不依赖于动作集的大小,这在设施数方面可以是指数性的。此外,我们的方法的运行时间依赖于游戏隐含描述的多项式时间。

**[Paper URL](https://proceedings.mlr.press/v202/panageas23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/panageas23a/panageas23a.pdf)** 

# Flash: Concept Drift Adaptation in Federated Learning
**题目:** Flash:联邦学习中的概念漂移适应

**作者:** Kunjal Panchal, Sunav Choudhary, Subrata Mitra, Koyel Mukherjee, Somdeb Sarkhel, Saayan Mitra, Hui Guan

**Abstract:** In Federated Learning (FL), adaptive optimization is an effective approach to addressing the statistical heterogeneity issue but cannot adapt quickly to concept drifts. In this work, we propose a novel adaptive optimizer called Flash that simultaneously addresses both statistical heterogeneity and the concept drift issues. The fundamental insight is that a concept drift can be detected based on the magnitude of parameter updates that are required to fit the global model to each participating client’s local data distribution. Flash uses a two-pronged approach that synergizes client-side early-stopping training to facilitate detection of concept drifts and the server-side drift-aware adaptive optimization to effectively adjust effective learning rate. We theoretically prove that Flash matches the convergence rate of state-of-the-art adaptive optimizers and further empirically evaluate the efficacy of Flash on a variety of FL benchmarks using different concept drift settings.

**摘要:** 在联邦学习(FL)中,适应性优化是解决统计异质问题的一种有效方法,但不能迅速适应概念漂移。在这个工作中,我们提出了一种名为Flash的新适应性优化器,它同时处理统计异质和概念漂移问题。基本的洞察是,一个概念漂移可以根据需要适应全球模型的参数更新的大小来检测到每个参与的客户端的本地数据分布。Flash使用两个pronged方法,将客户端端早期停止训练结合起来,以促进概念漂移的检测和服务器端漂移意识的适应性优化来有效地调整有效学习率。

**[Paper URL](https://proceedings.mlr.press/v202/panchal23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/panchal23a/panchal23a.pdf)** 

# Learn to Accumulate Evidence from All Training Samples: Theory and Practice
**题目:** 学习从所有训练样本中汇集证据:理论和实践

**作者:** Deep Shankar Pandey, Qi Yu

**Abstract:** Evidential deep learning, built upon belief theory and subjective logic, offers a principled and computationally efficient way to turn a deterministic neural network uncertainty-aware. The resultant evidential models can quantify fine-grained uncertainty using the learned evidence. To ensure theoretically sound evidential models, the evidence needs to be non-negative, which requires special activation functions for model training and inference. This constraint often leads to inferior predictive performance compared to standard softmax models, making it challenging to extend them to many large-scale datasets. To unveil the real cause of this undesired behavior, we theoretically investigate evidential models and identify a fundamental limitation that explains the inferior performance: existing evidential activation functions create zero evidence regions, which prevent the model to learn from training samples falling into such regions. A deeper analysis of evidential activation functions based on our theoretical underpinning inspires the design of a novel regularizer that effectively alleviates this fundamental limitation. Extensive experiments over many challenging real-world datasets and settings confirm our theoretical findings and demonstrate the effectiveness of our proposed approach.

**摘要:** 基于信念理论和主观逻辑的证据深度学习,提供了一种基于原则和计算效率的方法,使确定性神经网络的不确定性意识化。由此产生的证据模型可以利用学到的证据量化细微的不确定性。为了确保理论上可靠的证据模型,证据需要非负性,这要求模型训练和推理的特殊激活功能。这种约束往往导致与标准软max模型相比的预测性能低劣,使得扩展到许多大规模数据集具有挑战性。基于我们理论基础的更深入的证据激活函数分析,为设计一种有效缓解这一基本限制的新型调节器提供了灵感。在许多挑战性的现实数据集和环境上进行了广泛的实验,证实了我们的理论发现,并证明了我们提出的方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/pandey23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pandey23a/pandey23a.pdf)** 

# Secure Federated Correlation Test and Entropy Estimation
**题目:** 安全联邦相关测试和熵估计

**作者:** Qi Pang, Lun Wang, Shuai Wang, Wenting Zheng, Dawn Song

**Abstract:** We propose the first federated correlation test framework compatible with secure aggregation, namely FED-$\chi^2$. In our protocol, the statistical computations are recast as frequency moment estimation problems, where the clients collaboratively generate a shared projection matrix and then use stable projection to encode the local information in a compact vector. As such encodings can be linearly aggregated, secure aggregation can be applied to conceal the individual updates. We formally establish the security guarantee of FED-$\chi^2$ by proving that only the minimum necessary information (i.e., the correlation statistics) is revealed to the server. We show that our protocol can be naturally extended to estimate other statistics that can be recast as frequency moment estimations. By accommodating Shannon’e Entropy in FED-$\chi^2$, we further propose the first secure federated entropy estimation protocol, FED-$H$. The evaluation results demonstrate that FED-$\chi^2$ and FED-$H$ achieve good performance with small client-side computation overhead in several real-world case studies.

**摘要:** 我们提出了第一个与安全聚合兼容的联邦关联测试框架,即 FED-$\chi^2$。在我们的协议中,统计计算被重新编译为频率矩阵估计问题,客户协同生成共享投影矩阵,然后使用稳定投影编码在紧凑矢量中本地信息。由于这样的编码可以线性聚合,安全聚合可以用于隐藏个人更新。我们通过证明 server 只显示必要最低信息(即相关统计)来正式确定 FED-$\chi^2$的安全保证。我们证明我们的协议可以自然地扩展以估计其他统计数据,这些数据可以被重新编译为频率矩阵估计。评价结果表明, FED-$\chi^2$和 FED-$H$在若干实例研究中,在小客户边计算费用下取得了良好的性能。

**[Paper URL](https://proceedings.mlr.press/v202/pang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pang23a/pang23a.pdf)** 

# Task-Specific Skill Localization in Fine-tuned Language Models
**题目:** 精调语言模型中的特定任务技能定位

**作者:** Abhishek Panigrahi, Nikunj Saunshi, Haoyu Zhao, Sanjeev Arora

**Abstract:** Pre-trained language models can be fine-tuned to solve diverse NLP tasks, including in few-shot settings. Thus fine-tuning allows the model to quickly pick up task-specific "skills," but there has been limited study of where these newly-learnt skills reside inside the massive model. This paper introduces the term skill localization for this problem and proposes a solution. Given the downstream task and a model fine-tuned on that task, a simple optimization is used to identify a very small subset of parameters ($\sim$0.01% of model parameters) responsible for ($>$95%) of the model’s performance, in the sense that grafting the fine-tuned values for just this tiny subset onto the pre-trained model gives performance almost as well as the fine-tuned model. While reminiscent of recent works on parameter-efficient fine-tuning, the novel aspects here are that: (i) No further retraining is needed on the subset (unlike, say, with lottery tickets). (ii) Notable improvements are seen over vanilla fine-tuning with respect to calibration of predictions in-distribution (40-90% error reduction) as well as quality of predictions out-of-distribution (OOD). In models trained on multiple tasks, a stronger notion of skill localization is observed, where the sparse regions corresponding to different tasks are almost disjoint, and their overlap (when it happens) is a proxy for task similarity. Experiments suggest that localization via grafting can assist certain forms continual learning.

**摘要:** 预训练的语言模型可以精确调整,以解决多种NLP任务,包括在少数射击设置中。因此精确调整允许模型快速获取任务特定的“技能”,但对于这些新学到的技能在大规模模型内存在的地方进行了有限的研究。本论文介绍了该问题的技能定位术语,并提出了解决方案。考虑到下游任务和在该任务上精确调整的模型,一个简单的优化被用来识别模型的性能的非常小子集($\sim$0.01%模型子集)负责($>$95%),因为将精确调整的值 grafting just this tiny subset onto the pre-trained model gives performance almost as well as the fine-tuned model. While reminiscent of recent works on parameter-efficient fine-tuning, the novel aspects here are that: (i) No further retraining is needed on the subset (unlike, say,(二)在分发预测的校准 (40-90%误差降低)以及分发外预测(OOD)的质量方面,在瓦尼拉微调中出现了显著的改进。在对多个任务进行训练的模型中,观察到技能定位的概念较强,而与不同的任务相符的稀疏区域几乎不统一,并且它们的重叠(当发生时)是任务相似性的代理。实验表明,通过接枝定位可以帮助某些形式的持续学习。

**[Paper URL](https://proceedings.mlr.press/v202/panigrahi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/panigrahi23a/panigrahi23a.pdf)** 

# Kernel Sufficient Dimension Reduction and Variable Selection for Compositional Data via Amalgamation
**题目:** 通过合并构造数据的核尺寸减小和变量选择

**作者:** Junyoung Park, Jeongyoun Ahn, Cheolwoo Park

**Abstract:** Compositional data with a large number of components and an abundance of zeros are frequently observed in many fields recently. Analyzing such sparse high-dimensional compositional data naturally calls for dimension reduction or, more preferably, variable selection. Most existing approaches lack interpretability or cannot handle zeros properly, as they rely on a log-ratio transformation. We approach this problem with sufficient dimension reduction (SDR), one of the most studied dimension reduction frameworks in statistics. Characterized by the conditional independence of the data to the response on the found subspace, the SDR framework has been effective for both linear and nonlinear dimension reduction problems. This work proposes a compositional SDR that can handle zeros naturally while incorporating the nonlinear nature and spurious negative correlations among components rigorously. A critical consideration of sub-composition versus amalgamation for compositional variable selection is discussed. The proposed compositional SDR is shown to be statistically consistent in constructing a sub-simplex consisting of true signal variables. Simulation and real microbiome data are used to demonstrate the performance of the proposed SDR compared to existing state-of-art approaches.

**摘要:** 近年来,许多领域经常观察到具有大量组件和零数的组件数据。分析这些稀疏的高维组件数据自然要求减少维度或更倾向于变量选择。大多数现有的方法缺乏解释性或不能正确处理零数,因为它们依赖于逻辑比值转换。我们用充分维度减少(SDR)来解决这一问题,这是统计学中最研究的维度减少框架之一。SDR框架以数据对发现子空间的响应的条件独立性为特征,对线性和非线性维度减少问题具有有效性。讨论了组成变量选择中的分构与合并的临界考虑。研究表明,拟议的组成SDR在构造一个由真信号变量组成的分单元时具有统计一致性。利用仿真和实微生物数据,证明了拟议的SDR与现有的最先进的方法相比的性能。

**[Paper URL](https://proceedings.mlr.press/v202/park23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/park23a/park23a.pdf)** 

# Learning Affinity with Hyperbolic Representation for Spatial Propagation
**题目:**  spatial propagation Hyperbolic Representation Learning Affinity

**作者:** Jin-Hwi Park, Jaesung Choe, Inhwan Bae, Hae-Gon Jeon

**Abstract:** Recent approaches to representation learning have successfully demonstrated the benefits in hyperbolic space, driven by an excellent ability to make hierarchical relationships. In this work, we demonstrate that the properties of hyperbolic geometry serve as a valuable alternative to learning hierarchical affinity for spatial propagation tasks. We propose a Hyperbolic Affinity learning Module (HAM) to learn spatial affinity by considering geodesic distance on the hyperbolic space. By simply incorporating our HAM into conventional spatial propagation tasks, we validate its effectiveness, capturing the pixel hierarchy of affinity maps in hyperbolic space. The proposed methodology can lead to performance improvements in explicit propagation processes such as depth completion and semantic segmentation.

**摘要:** 近年来对立体学习方法已成功地证明了高分子空间的优越性,其驱动力是建立层次关系的能力。在此研究中,我们证明高分子几何的特性是学习高分子空间传播任务的层次关系的宝贵替代品。我们提出了一个高分子空间传播学习模块(HAM)以考虑高分子空间的几何距离来学习高分子空间的关联性。通过简单地将 HAM 纳入传统的空间传播任务,我们验证了它的有效性,捕捉了高分子空间的关联性地图的像素层次结构。

**[Paper URL](https://proceedings.mlr.press/v202/park23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/park23b/park23b.pdf)** 

# TRAK: Attributing Model Behavior at Scale
**题目:** TRAK:在尺度上分配模型行为

**作者:** Sung Min Park, Kristian Georgiev, Andrew Ilyas, Guillaume Leclerc, Aleksander Madry

**Abstract:** The goal of data attribution is to trace model predictions back to training data. Despite a long line of work towards this goal, existing approaches to data attribution tend to force users to choose between computational tractability and efficacy. That is, computationally tractable methods can struggle with accurately attributing model predictions in non-convex settings (e.g., in the context of deep neural networks), while methods that are effective in such regimes require training thousands of models, which makes them impractical for large models or datasets. In this work, we introduce TRAK (Tracing with the Randomly-projected After Kernel), a data attribution method that is both effective and computationally tractable for large-scale, differentiable models. In particular, by leveraging only a handful of trained models, TRAK can match the performance of attribution methods that require training thousands of models. We demonstrate the utility of TRAK across various modalities and scales: image classifiers trained on ImageNet, vision-language models (CLIP), and language models (BERT and mT5). We provide code for using TRAK (and reproducing our work) at https://github.com/MadryLab/trak .

**摘要:** 数据归纳的目标是追踪模型预报回训练数据。尽管对这一目标进行了长期的工作,现有的数据归纳方法倾向于迫使用户选择计算易于处理和有效性。也就是说,计算易于处理的方法可以在非凸设置中准确归纳模型预报(例如,在深层神经网络的上下文),而在这种模式中有效的方法则需要训练成千上万模型,这使得它们对大型模型或数据集不实用。我们展示了TRAK在不同的模式和尺度中的应用:在ImageNet上训练的图像分类器、视觉语言模型(CLIP)和语言模型(BERT和mT5)。我们提供TRAK使用(和复制我们的工作)的代码 https://github.com/MadryLab/trak 。

**[Paper URL](https://proceedings.mlr.press/v202/park23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/park23c/park23c.pdf)** 

# Test-Time Style Shifting: Handling Arbitrary Styles in Domain Generalization
**题目:** 测试时间 Style Shifting:在域名一般化中处理任意风格

**作者:** Jungwuk Park, Dong-Jun Han, Soyeong Kim, Jaekyun Moon

**Abstract:** In domain generalization (DG), the target domain is unknown when the model is being trained, and the trained model should successfully work on an arbitrary (and possibly unseen) target domain during inference. This is a difficult problem, and despite active studies in recent years, it remains a great challenge. In this paper, we take a simple yet effective approach to tackle this issue. We propose test-time style shifting, which shifts the style of the test sample (that has a large style gap with the source domains) to the nearest source domain that the model is already familiar with, before making the prediction. This strategy enables the model to handle any target domains with arbitrary style statistics, without additional model update at test-time. Additionally, we propose style balancing, which provides a great platform for maximizing the advantage of test-time style shifting by handling the DG-specific imbalance issues. The proposed ideas are easy to implement and successfully work in conjunction with various other DG schemes. Experimental results on different datasets show the effectiveness of our methods.

**摘要:** 在域广义化中,当模型被训练时,目标域是未知的,而训练的模型在推导过程中应该成功地工作于任意(可能未见的)目标域。这是一个困难的问题,尽管近年来进行了积极的研究,但仍然是一个巨大的挑战。本论文采用了简单而有效的方法来解决这个问题。我们提出了测试时间风格移位,将测试样本的风格(与源域有较大的风格差距)转移到模型已经熟悉的最接近的源域。提议的方案是易于实施的,并与其他DG计划结合起来成功地进行工作。在不同数据集的实验结果显示了我们的方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/park23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/park23d/park23d.pdf)** 

# Towards Understanding Ensemble Distillation in Federated Learning
**题目:** 如何理解集群蒸馏在联邦学习中

**作者:** Sejun Park, Kihun Hong, Ganguk Hwang

**Abstract:** Federated Learning (FL) is a collaborative machine learning paradigm for data privacy preservation. Recently, a knowledge distillation (KD) based information sharing approach in FL, which conducts ensemble distillation on an unlabeled public dataset, has been proposed. However, despite its experimental success and usefulness, the theoretical analysis of the KD based approach has not been satisfactorily conducted. In this work, we build a theoretical foundation of the ensemble distillation framework in federated learning from the perspective of kernel ridge regression (KRR). In this end, we propose a KD based FL algorithm for KRR models which is related with some existing KD based FL algorithms, and analyze our algorithm theoretically. We show that our algorithm makes local prediction models as much powerful as the centralized KRR model (which is a KRR model trained by all of local datasets) in terms of the convergence rate of the generalization error if the unlabeled public dataset is sufficiently large. We also provide experimental results to verify our theoretical results on ensemble distillation in federated learning.

**摘要:** 联合学习(英语:Federated Learning,简称FL)是数据隐私保护的协同机器学习范式。最近,提出了一种基于KD的信息共享方法,该方法在无标识的公共数据集中进行集群蒸馏。然而,尽管该方法具有实验性成功和实用性,但其理论分析仍未得到满意的结果。本研究中,我们从核脊回归(KRR)的角度构建了联合学习中的集群蒸馏框架的理论基础。为此,我们为KRR模型提出了一种基于KD的FL算法,它与一些现有的基于KD的FL算法有关,并对其进行了理论分析。我们证明,如果未标记的公共数据集足够大,我们的算法在一般化误差的收敛率方面使局部预测模型与集中KRR模型(由所有局部数据集训练的KRR模型)一样强大。我们还提供实验结果,以验证联合学习中的集群蒸馏理论结果。

**[Paper URL](https://proceedings.mlr.press/v202/park23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/park23e/park23e.pdf)** 

# Learning Controllable Degradation for Real-World Super-Resolution via Constrained Flows
**题目:** 通过约束流实现真实世界超分辨率的可控降级学习

**作者:** Seobin Park, Dongjin Kim, Sungyong Baik, Tae Hyun Kim

**Abstract:** Recent deep-learning-based super-resolution (SR) methods have been successful in recovering high-resolution (HR) images from their low-resolution (LR) counterparts, albeit on the synthetic and simple degradation setting: bicubic downscaling. On the other hand, super-resolution on real-world images demands the capability to handle complex downscaling mechanism which produces different artifacts (e.g., noise, blur, color distortion) upon downscaling factors. To account for complex downscaling mechanism in real-world LR images, there have been a few efforts in constructing datasets consisting of LR images with real-world downsampling degradation. However, making such datasets entails a tremendous amount of time and effort, thereby resorting to very few number of downscaling factors (e.g., $\times$2, $\times$3, $\times$4). To remedy the issue, we propose to generate realistic SR datasets for unseen degradation levels by exploring the latent space of real LR images and thereby producing more diverse yet realistic LR images with complex real-world artifacts. Our quantitative and qualitative experiments demonstrate the accuracy of the generated LR images, and we show that the various conventional SR networks trained with our newly generated SR datasets can produce much better HR images.

**摘要:** 近年来,基于深度学习的超分辨率(SR)方法成功地从低分辨率(LR)图像中恢复高分辨率(HR)图像,尽管在合成和简单的降解设置上:双立体降解。另一方面,在真实图像上超分辨率要求处理在降解因子上复杂的降解机制,产生不同的人工物(例如噪声、模糊、色变)。为了解决这一问题,我们建议通过探索真实立体图像的潜在空间来为未见的降解水平生成现实立体数据集,从而在复杂的实物上生成更多样且现实立体的立体图像。我们的定量和定量实验证明了生成的立体图像的准确性,并证明了使用新生成的立体数据集训练的传统立体网络可以产生更好的人力资源图像。

**[Paper URL](https://proceedings.mlr.press/v202/park23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/park23f/park23f.pdf)** 

# Differentially Private Sharpness-Aware Training
**题目:** 不同程度的私人 Sharpness-Aware培训

**作者:** Jinseong Park, Hoki Kim, Yujin Choi, Jaewook Lee

**Abstract:** Training deep learning models with differential privacy (DP) results in a degradation of performance. The training dynamics of models with DP show a significant difference from standard training, whereas understanding the geometric properties of private learning remains largely unexplored. In this paper, we investigate sharpness, a key factor in achieving better generalization, in private learning. We show that flat minima can help reduce the negative effects of per-example gradient clipping and the addition of Gaussian noise. We then verify the effectiveness of Sharpness-Aware Minimization (SAM) for seeking flat minima in private learning. However, we also discover that SAM is detrimental to the privacy budget and computational time due to its two-step optimization. Thus, we propose a new sharpness-aware training method that mitigates the privacy-optimization trade-off. Our experimental results demonstrate that the proposed method improves the performance of deep learning models with DP from both scratch and fine-tuning. Code is available at https://github.com/jinseongP/DPSAT.

**摘要:** 与差分隐私(DP)相结合的深层学习模型在性能下降中产生影响。与DP的模型的训练动力学与标准训练有显著差异,而理解私人学习的几何特性仍未被广泛探讨。本文研究了在私人学习中实现更好的一般化的一个关键因素,即敏度。我们证明,平坦微量可以减少每例梯度剪切和加高斯噪声的负面影响。然后,我们验证了在私人学习中寻找平坦微量化的敏度-敏度微量化(SAM)的有效性。我们的实验结果表明,该方法可以从零和微调两个方面提高深度学习模型的性能。代码可于 https://github.com/jinseongP/DPSAT。

**[Paper URL](https://proceedings.mlr.press/v202/park23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/park23g/park23g.pdf)** 

# Controllability-Aware Unsupervised Skill Discovery
**题目:** 可控性意识的非监督技能发现

**作者:** Seohong Park, Kimin Lee, Youngwoon Lee, Pieter Abbeel

**Abstract:** One of the key capabilities of intelligent agents is the ability to discover useful skills without external supervision. However, the current unsupervised skill discovery methods are often limited to acquiring simple, easy-to-learn skills due to the lack of incentives to discover more complex, challenging behaviors. We introduce a novel unsupervised skill discovery method, Controllability-aware Skill Discovery (CSD), which actively seeks complex, hard-to-control skills without supervision. The key component of CSD is a controllability-aware distance function, which assigns larger values to state transitions that are harder to achieve with the current skills. Combined with distance-maximizing skill discovery, CSD progressively learns more challenging skills over the course of training as our jointly trained distance function reduces rewards for easy-to-achieve skills. Our experimental results in six robotic manipulation and locomotion environments demonstrate that CSD can discover diverse complex skills including object manipulation and locomotion skills with no supervision, significantly outperforming prior unsupervised skill discovery methods. Videos and code are available at https://seohong.me/projects/csd/

**摘要:** 智能代理人的关键能力之一是无外部监督发现有用技能的能力。然而,目前无监督的技能发现方法往往局限于获得简单易于学习的技能,因为缺乏激励来发现更复杂的、挑战性的行为。我们引入了新的无监督的技能发现方法,“控制性意识的技能发现”(Controllability-aware Skill Discovery,CSD),它积极寻求无监督的复杂、难以控制的技能。我们对六种机器人操纵和运动环境的实验结果表明,CSD能够无监督地发现各种复杂技能,包括物体操纵和运动技能,大大超过了以前未经监督的技能发现方法。

**[Paper URL](https://proceedings.mlr.press/v202/park23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/park23h/park23h.pdf)** 

# Predictable MDP Abstraction for Unsupervised Model-Based RL
**题目:** 基于模型的无监督RL的可预测MDP抽象

**作者:** Seohong Park, Sergey Levine

**Abstract:** A key component of model-based reinforcement learning (RL) is a dynamics model that predicts the outcomes of actions. Errors in this predictive model can degrade the performance of model-based controllers, and complex Markov decision processes (MDPs) can present exceptionally difficult prediction problems. To mitigate this issue, we propose predictable MDP abstraction (PMA): instead of training a predictive model on the original MDP, we train a model on a transformed MDP with a learned action space that only permits predictable, easy-to-model actions, while covering the original state-action space as much as possible. As a result, model learning becomes easier and more accurate, which allows robust, stable model-based planning or model-based RL. This transformation is learned in an unsupervised manner, before any task is specified by the user. Downstream tasks can then be solved with model-based control in a zero-shot fashion, without additional environment interactions. We theoretically analyze PMA and empirically demonstrate that PMA leads to significant improvements over prior unsupervised model-based RL approaches in a range of benchmark environments. Our code and videos are available at https://seohong.me/projects/pma/

**摘要:** 基于模型的增强学习(RL)的一个关键组成部分是动态模型,它预测行动的结果。该预测模型的错误可以降低基于模型的控制器的性能,而复杂的马可夫决策过程(MDPs)可以呈现异常困难的预测问题。为了缓解这个问题,我们提出了可预测的MDP抽象(PMA):在原型MDP上训练预测模型,我们训练了一个变形的MDP上,它只允许可预测的、易于建模的行动空间,同时尽可能地覆盖原型状态行动空间。因此,模型学习变得更容易和更准确,这允许可靠的、稳定的基于模型的规划或基于模型的RL。我们从理论上分析了PMA,并从实证上证明PMA在多个基准环境中对以前无监督的基于模型的RL方法有显著的改进。我们的代码和视频可于 https://seohong.me/projects/pma/

**[Paper URL](https://proceedings.mlr.press/v202/park23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/park23i/park23i.pdf)** 

# Neural Stochastic Differential Games for Time-series Analysis
**题目:** 时间系列分析的神经随机微分游戏

**作者:** Sungwoo Park, Byoungwoo Park, Moontae Lee, Changhee Lee

**Abstract:** Modeling spatiotemporal dynamics with neural differential equations has become a major line of research that opens new ways to handle various real-world scenarios (e.g., missing observations, irregular times, etc.). Despite such progress, most existing methods still face challenges in providing a general framework for analyzing time series. To tackle this, we adopt stochastic differential games to suggest a new philosophy of utilizing interacting collective intelligence in time series analysis. For the implementation, we develop the novel gradient descent-based algorithm called deep neural fictitious play to approximate the Nash equilibrium. We theoretically analyze the convergence result of the proposed algorithm and discuss the advantage of cooperative games in handling noninformative observation. Throughout the experiments on various datasets, we demonstrate the superiority of our framework over all the tested benchmarks in modeling time-series prediction by capitalizing on the advantages of applying cooperative games. An ablation study shows that neural agents of the proposed framework learn intrinsic temporal relevance to make accurate time-series predictions.

**摘要:** 用神经微分方程建模时空动力学已成为解决各种现实场景(如遗失观察、不规则时间等)的新研究方向,尽管取得了进展,但大多数现有的方法仍面临着提供时间序列分析的一般框架的挑战。为了解决这一问题,我们采用随机微分游戏,提出一种在时间序列分析中利用相互作用的集体智力的新哲学。通过对不同数据集的实验,通过利用合作游戏的优点,证明了我们框架在建模时序预测中优于所有测试的基准。

**[Paper URL](https://proceedings.mlr.press/v202/park23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/park23j/park23j.pdf)** 

# Accelerated Infeasibility Detection of Constrained Optimization and Fixed-Point Iterations
**题目:** 限制优化和固定点迭代的加速不易检测

**作者:** Jisun Park, Ernest K. Ryu

**Abstract:** As first-order optimization methods become the method of choice for solving large-scale optimization problems, optimization solvers based on first-order algorithms are being built. Such general-purpose solvers must robustly detect infeasible or misspecified problem instances, but the computational complexity of first-order methods for doing so has yet to be formally studied. In this work, we characterize the optimal accelerated rate of infeasibility detection. We show that the standard fixed-point iteration achieves a $\mathcal{O}(1/k^2)$ and $\mathcal{O}(1/k)$ rates, respectively, on the normalized iterates and the fixed-point residual converging to the infimal displacement vector, while the accelerated fixed-point iteration achieves $\mathcal{O}(1/k^2)$ and $\tilde{\mathcal{O}}(1/k^2)$ rates. We then provide a matching complexity lower bound to establish that $\Theta(1/k^2)$ is indeed the optimal accelerated rate.

**摘要:** 由于第一阶优化方法成为解决大规模优化问题的选择方法,基于第一阶算法的优化解决方案正在构建。这类通用解决方案必须牢固地检测无法执行或错误指定的问题实例,但这样做的第一阶方法的计算复杂性尚待正式研究。在这个工作中,我们描述了无法执行检测的最佳加速率。我们表明,标准固定点迭代实现$\mathcal{O}(1/k^2)$和$\mathcal{O}(1/k)$率,分别,在标准化迭代和固定点残余向非微小位移向量收敛,而加速的固定点迭代实现$\mathcal{O}(1/k^2)$和$\tilde{\mathcal{O}}(1/k^2)$率。然后,我们提供一个更低约束的匹配复杂性来确定$\Theta(1/k^2)$的确是最佳加速

**[Paper URL](https://proceedings.mlr.press/v202/park23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/park23k/park23k.pdf)** 

# Model-based Reinforcement Learning with Scalable Composite Policy Gradient Estimators
**题目:** 基于模型的强化学习与可尺度复合政策梯度估计器

**作者:** Paavo Parmas, Takuma Seno, Yuma Aoki

**Abstract:** In model-based reinforcement learning (MBRL), policy gradients can be estimated either by derivative-free RL methods, such as likelihood ratio gradients (LR), or by backpropagating through a differentiable model via reparameterization gradients (RP). Instead of using one or the other, the Total Propagation (TP) algorithm in prior work showed that a combination of LR and RP estimators averaged using inverse variance weighting (IVW) can achieve orders of magnitude improvement over either method. However, IVW-based composite estimators have not yet been applied in modern RL tasks, as it is unclear if they can be implemented scalably. We propose a scalable method, Total Propagation X (TPX) that improves over TP by changing the node used for IVW, and employing coordinate wise weighting. We demonstrate the scalability of TPX by applying it to the state of the art visual MBRL algorithm Dreamer. The experiments showed that Dreamer fails with long simulation horizons, while our TPX works reliably for only a fraction of additional computation. One key advantage of TPX is its ease of implementation, which will enable experimenting with IVW on many tasks beyond MBRL.

**摘要:** 在基于模型强化学习(MBRL)中,政策梯度可以通过自由导数RL方法估算,例如概率比梯度(LR)或通过重度梯度(RP)通过可微分模型后推算。在以前的工作中,总推导(TP)算法显示,使用逆变量权重(IVW)平均的LR和RP推导器的组合能够在两种方法上达到数量改进的阶数。然而,基于IVW的复合推导器尚未应用于现代RL任务中,因为它们是否能够实现可标量化的问题尚不清楚。我们提出了一种可标量化方法,总推导X(TPX),通过改变IVW使用的节点和使用坐标wise权重来改善TP。我们通过将其应用于最先进的MBRL算法Dreamer来证明TPX的可标量化。实验表明,D Dreamer 的模拟范围很长,而我们的TPX 只能够对部分额外的计算进行可靠的计算。TPX 的一大优点是它的易于实现,这将使它能够在 MBRL 以外的许多任务上使用IVW 进行实验。

**[Paper URL](https://proceedings.mlr.press/v202/parmas23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/parmas23a/parmas23a.pdf)** 

# PAC Generalization via Invariant Representations
**题目:** 通过不变代表的PAC一般化

**作者:** Advait U Parulekar, Karthikeyan Shanmugam, Sanjay Shakkottai

**Abstract:** Invariant representations are transformations of the covariates such that the best model on top of the representation is invariant across training environments. In the context of linear Structural Equation Models (SEMs), invariant representations might allow us to learn models with out-of-distribution guarantees, i.e., models that are robust to interventions in the SEM. To address the invariant representation problem in a finite sample setting, we consider the notion of $\epsilon$-approximate invariance. We study the following question: If a representation is approximately invariant with respect to a given number of training interventions, will it continue to be approximately invariant on a larger collection of unseen intervened SEMs? Inspired by PAC learning, we obtain finite-sample out-of-distribution generalization guarantees for approximate invariance that holds probabilistically over a family of linear SEMs without faithfulness assumptions.

**摘要:** 在线性结构方程模型(SEM)的上下文中,无变量表示可能允许我们学习具有外分布保证的模型,即对SEM中干预的鲁棒模型。为了解决有限样本设置中的无变量表示问题,我们考虑$\epsilon$-近似无变量的概念。我们研究以下问题: 如果一个表示与指定数量的训练干预相近无变,那么它是否会继续在较大的未见干预SEM集合上近似无变量?

**[Paper URL](https://proceedings.mlr.press/v202/parulekar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/parulekar23a/parulekar23a.pdf)** 

# Stochastic Gradient Descent-Induced Drift of Representation in a Two-Layer Neural Network
**题目:** 双层神经网络中随机梯度源导的表示漂移

**作者:** Farhad Pashakhanloo, Alexei Koulakov

**Abstract:** Representational drift refers to over-time changes in neural activation accompanied by a stable task performance. Despite being observed in the brain and in artificial networks, the mechanisms of drift and its implications are not fully understood. Motivated by recent experimental findings of stimulus-dependent drift in the piriform cortex, we use theory and simulations to study this phenomenon in a two-layer linear feedforward network. Specifically, in a continual online learning scenario, we study the drift induced by the noise inherent in the Stochastic Gradient Descent (SGD). By decomposing the learning dynamics into the normal and tangent spaces of the minimum-loss manifold, we show the former corresponds to a finite variance fluctuation, while the latter could be considered as an effective diffusion process on the manifold. We analytically compute the fluctuation and the diffusion coefficients for the stimuli representations in the hidden layer as functions of network parameters and input distribution. Further, consistent with experiments, we show that the drift rate is slower for a more frequently presented stimulus. Overall, our analysis yields a theoretical framework for better understanding of the drift phenomenon in biological and artificial neural networks.

**摘要:** 代表性漂移是指伴随稳定的任务表现的神经激活的超时变化。尽管在大脑和人工网络中被观察,漂移的机理及其影响仍未得到充分理解。由于最近的刺激依赖性漂移的实验发现,我们利用理论和仿真研究这一现象在两层线性后继网络中。具体地说,在持续在线学习场景中,我们研究了随机梯度下降(SGD)所产生的噪声所诱导的漂移。本文分析了隐蔽层的刺激表现的波动和扩散系数,作为网络参数和输入分布的函数,并根据实验结果表明,较经常出现的刺激的漂移速度较慢,从而为生物和人工神经网络的漂移现象提供了一个较好的理论框架。

**[Paper URL](https://proceedings.mlr.press/v202/pashakhanloo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pashakhanloo23a/pashakhanloo23a.pdf)** 

# Reducing SO(3) Convolutions to SO(2) for Efficient Equivariant GNNs
**题目:** 有效等价GNN的SO(3)卷积减少到SO(2)

**作者:** Saro Passaro, C. Lawrence Zitnick

**Abstract:** Graph neural networks that model 3D data, such as point clouds or atoms, are typically desired to be $SO(3)$ equivariant, i.e., equivariant to 3D rotations. Unfortunately equivariant convolutions, which are a fundamental operation for equivariant networks, increase significantly in computational complexity as higher-order tensors are used. In this paper, we address this issue by reducing the $SO(3)$ convolutions or tensor products to mathematically equivalent convolutions in $SO(2)$ . This is accomplished by aligning the node embeddings’ primary axis with the edge vectors, which sparsifies the tensor product and reduces the computational complexity from $O(L^6)$ to $O(L^3)$, where $L$ is the degree of the representation. We demonstrate the potential implications of this improvement by proposing the Equivariant Spherical Channel Network (eSCN), a graph neural network utilizing our novel approach to equivariant convolutions, which achieves state-of-the-art results on the large-scale OC-20 and OC-22 datasets.

**摘要:**  Graph neural networks that model 3D data, such as point clouds or atoms, are typically desired to be $SO(3)$ equivariant, i.e., equivariant to 3D rotations. Unfortunately equivariant convolutions, which are a fundamental operation for equivariant networks, increase significantly in computational complexity as higher-order tensors are used. In this paper, we address this issue by reducing the $SO(3)$ convolutions or tensor products to mathematically equivalent convolutions in $SO(2)$. This is accomplished by aligning the node embeddings’ primary axis with the edge vectors, which sparsifies the tensor product and reduces the computational complexity from $O(L^6)$ to $O(L^3)$, where $L$ is the degree of the representation.本文提出了一种利用我们对等变卷曲的新方法的图神经网络,即等变球通道网络(Equivariant Spherical Channel Network,eSCN),以实现大规模OC-20和OC-22数据集的最新结果。

**[Paper URL](https://proceedings.mlr.press/v202/passaro23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/passaro23a/passaro23a.pdf)** 

# Federated Online and Bandit Convex Optimization
**题目:** 联邦网络和盗版凸优化

**作者:** Kumar Kshitij Patel, Lingxiao Wang, Aadirupa Saha, Nathan Srebro

**Abstract:** We study the problems of distributed online and bandit convex optimization against an adaptive adversary. We aim to minimize the average regret on $M$ machines working in parallel over $T$ rounds with $R$ intermittent communications. Assuming the underlying cost functions are convex and can be generated adaptively, our results show that collaboration is not beneficial when the machines have access to the first-order gradient information at the queried points. This is in contrast to the case for stochastic functions, where each machine samples the cost functions from a fixed distribution. Furthermore, we delve into the more challenging setting of federated online optimization with bandit (zeroth-order) feedback, where the machines can only access values of the cost functions at the queried points. The key finding here is identifying the high-dimensional regime where collaboration is beneficial and may even lead to a linear speedup in the number of machines. We further illustrate our findings through federated adversarial linear bandits by developing novel distributed single and two-point feedback algorithms. Our work is the first attempt towards a systematic understanding of federated online optimization with limited feedback, and it attains tight regret bounds in the intermittent communication setting for both first and zeroth-order feedback. Our results thus bridge the gap between stochastic and adaptive settings in federated online optimization.

**摘要:** 我们研究了分布式在线和带状凸优化问题,针对适应性对手。我们的目标是尽量减少M$机器在T$周期间隔通信下运行的平均遗憾。假设基本的成本函数是凸的,并且可以适应性地生成,我们的结果表明,当机器在查询点访问第一阶梯度信息时,协作并不有益。这与随机函数的例子不同,每个机器从固定分布中采样成本函数。此外,我们深入研究了带状(零阶)反馈的联合在线优化的挑战性设置,其中机器只能在查询点访问成本函数的值。通过建立新的分布式单点和双点反馈算法,通过联合敌对线性 bandits,进一步说明了联合敌对线性 bandits的发现。我们的工作是对有限反馈的联合在线优化的系统性理解的首次尝试,它在第一次和零阶反馈的间歇通信设置中达到了严格的遗憾界限,从而弥补了联合在线优化中的随机和适应性设置之间的差距。

**[Paper URL](https://proceedings.mlr.press/v202/patel23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/patel23a/patel23a.pdf)** 

# Brauer’s Group Equivariant Neural Networks
**题目:** Brauer Group Equivariant Neural Networks

**作者:** Edward Pearce-Crump

**Abstract:** We provide a full characterisation of all of the possible group equivariant neural networks whose layers are some tensor power of $\mathbb{R}^{n}$ for three symmetry groups that are missing from the machine learning literature: $O(n)$, the orthogonal group; $SO(n)$, the special orthogonal group; and $Sp(n)$, the symplectic group. In particular, we find a spanning set of matrices for the learnable, linear, equivariant layer functions between such tensor power spaces in the standard basis of $\mathbb{R}^{n}$ when the group is $O(n)$ or $SO(n)$, and in the symplectic basis of $\mathbb{R}^{n}$ when the group is $Sp(n)$.

**摘要:** 我们提供了所有可能的群等价神经网络的完整描述,其层为三类在机器学习文献中缺失的对称群: $O(n)$,正交群; $SO(n)$,特殊正交群; 和 $Sp(n)$,模态群. 特别是,我们在群为$O(n)$或$SO(n)$的标准基准和群为$Sp(n)$的模态基准中,找到一个可以学习的、线性、等价层函数的跨层矩阵集。

**[Paper URL](https://proceedings.mlr.press/v202/pearce-crump23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pearce-crump23a/pearce-crump23a.pdf)** 

# How Jellyfish Characterise Alternating Group Equivariant Neural Networks
**题目:**  Jellyfish 的特征 代换群同等神经网络

**作者:** Edward Pearce-Crump

**Abstract:** We provide a full characterisation of all of the possible alternating group ($A_n$) equivariant neural networks whose layers are some tensor power of $\mathbb{R}^{n}$. In particular, we find a basis of matrices for the learnable, linear, $A_n$–equivariant layer functions between such tensor power spaces in the standard basis of $\mathbb{R}^{n}$. We also describe how our approach generalises to the construction of neural networks that are equivariant to local symmetries.

**摘要:** 我们提供了所有可能的代换群($A_n$)等价神经网络的完整描述,其层是$\mathbb{R}^{n}$的某种张力。特别是,我们在$\mathbb{R}^{n}$的标准基础中找到了可学习的、线性、$A_n$–等价层函数的矩阵基础。

**[Paper URL](https://proceedings.mlr.press/v202/pearce-crump23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pearce-crump23b/pearce-crump23b.pdf)** 

# Can Large Language Models Reason about Program Invariants?
**题目:** 大型语言模型能解释程序变量吗?

**作者:** Kexin Pei, David Bieber, Kensen Shi, Charles Sutton, Pengcheng Yin

**Abstract:** Identifying invariants is an important program analysis task with applications towards program understanding, bug finding, vulnerability analysis, and formal verification. Existing tools for identifying program invariants rely on dynamic analysis, requiring traces collected from multiple executions in order to produce reliable invariants. We study the application of large language models to invariant prediction, finding that models trained on source code and fine-tuned for invariant generation can perform invariant prediction as static rather than dynamic analysis. Using a scratchpad approach where invariants are predicted sequentially through a program gives the best performance, finding invariants statically of quality comparable to those obtained by a dynamic analysis tool with access to five program traces.

**摘要:** 识别变量是一个重要的程序分析任务,其应用于程序理解、错误发现、脆弱性分析和正式验证。现有的程序变量识别工具依赖于动态分析,需要从多个执行中收集的迹象来产生可靠的变量。我们研究了大型语言模型在变量预测中的应用,发现基于源代码的训练和微调变量生成的模型可以作为静态而不是动态分析进行变量预测。

**[Paper URL](https://proceedings.mlr.press/v202/pei23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pei23a/pei23a.pdf)** 

# Dynamics-inspired Neuromorphic Visual Representation Learning
**题目:** 动力学启发的神经形态视觉表现学习

**作者:** Zhengqi Pei, Shuhui Wang

**Abstract:** This paper investigates the dynamics-inspired neuromorphic architecture for visual representation learning following Hamilton’s principle. Our method converts weight-based neural structure to its dynamics-based form that consists of finite sub-models, whose mutual relations measured by computing path integrals amongst their dynamical states are equivalent to the typical neural weights. Based on the entropy reduction process derived from the Euler-Lagrange equations, the feedback signals interpreted as stress forces amongst sub-models push them to move. We first train a dynamics-based neural model from scratch and observe that this model outperforms traditional neural models on MNIST. We then convert several pre-trained neural structures into dynamics-based forms, followed by fine-tuning via entropy reduction to obtain the stabilized dynamical states. We observe consistent improvements in these transformed models over their weight-based counterparts on ImageNet and WebVision in terms of computational complexity, parameter size, testing accuracy, and robustness. Besides, we show the correlation between model performance and structural entropy, providing deeper insight into weight-free neuromorphic learning.

**摘要:** 本文研究了基于汉密尔顿原理的视觉表现学习神经形态结构。我们的方法将基于重量的神经结构转换为由有限子模型组成的动态形式,其由其动态状态中计算路径积分的相互关系等同于典型的神经量。基于由欧勒-拉格兰格方程导出的熵减小过程,这些子模型中被解释为应力信号的反馈信号推动它们移动。我们首先从零开始训练一个基于动力学的神经模型,并观察到该模型在MNIST上优于传统的神经模型。我们观察了这些变换模型在计算复杂性、参数大小、测试准确性和鲁棒性方面在ImageNet和WebVision的重型模型上持续的改进,此外,我们还显示了模型性能与结构熵之间的相关性,为无重型神经形态学习提供了更深入的洞察。

**[Paper URL](https://proceedings.mlr.press/v202/pei23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pei23b/pei23b.pdf)** 

# Feature Directions Matter: Long-Tailed Learning via Rotated Balanced Representation
**题目:** 特色方向重要:通过旋转平衡表示进行长期学习

**作者:** Gao Peifeng, Qianqian Xu, Peisong Wen, Zhiyong Yang, Huiyang Shao, Qingming Huang

**Abstract:** Long-tailed learning is one of the most challenging problems in visual recognition. There are some studies aiming to solve long-tailed classification from the perspective of feature learning. Recent work proposes to learn the balanced representation by fixing the linear classifier as Equiangular Tight Frame (ETF), since they argue what matters in classification is the structure of the feature, instead of their directions. Holding a different view, in this paper, we show that features with fixed directions may be harmful to the generalization of models, even if it is completely symmetric. To avoid this issue, we propose Representation-Balanced Learning Framework (RBL), which introduces orthogonal matrices to learn directions while maintaining the geometric structure of ETF. Theoretically, our contributions are two-fold: 1). we point out that the feature learning of RBL is insensitive toward training set label distribution, it always learns a balanced representation space. 2). we provide a generalization analysis of proposed RBL through training stability. To analyze the stability of the parameter with orthogonal constraint, we propose a novel training stability analysis paradigm, Two-Parameter Model Stability. Practically, our method is extremely simple in implementation but shows great superiority on several benchmark datasets.

**摘要:** 长尾学习是视觉识别中最棘手的问题之一。有一些研究旨在从特征学习的角度解决长尾分类问题。最近的研究提出通过修正线性分类器为正交紧格(ETF)来学习平衡的表示,因为它们认为在分类中重要的是特征的结构,而不是它们的方向。在本文中,我们采取了不同的视角,表明具有固定方向的特征可能对模型的一般化有害,即使它是完全对称的。为了避免这一问题,我们提出了表示平衡学习框架(RBL),它引入正交矩阵来学习方向,同时保持ETF的几何结构。通过训练稳定性对拟议的RBL进行了一般化分析。为了对正交约束参数的稳定性进行分析,提出了一种新的训练稳定性分析范式,即双参数模型稳定性。

**[Paper URL](https://proceedings.mlr.press/v202/peifeng23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/peifeng23a/peifeng23a.pdf)** 

# Fair Neighbor Embedding
**题目:** 公平的邻居嵌入

**作者:** Jaakko Peltonen, Wen Xu, Timo Nummenmaa, Jyrki Nummenmaa

**Abstract:** We consider fairness in dimensionality reduction. Nonlinear dimensionality reduction yields low dimensional representations that let users visualize and explore high-dimensional data. However, traditional dimensionality reduction may yield biased visualizations overemphasizing relationships of societal phenomena to sensitive attributes or protected groups. We introduce a framework of fair neighbor embedding, the Fair Neighbor Retrieval Visualizer, which formulates fair nonlinear dimensionality reduction as an information retrieval task whose performance and fairness are quantified by information retrieval criteria. The method optimizes low-dimensional embeddings that preserve high-dimensional data neighborhoods without yielding biased association of such neighborhoods to protected groups. In experiments the method yields fair visualizations outperforming previous methods.

**摘要:** 非线性维度减少可产生用户可视化和探索高维数据的低维表示,但传统的维度减少可能产生偏向的可视化,过度强调社会现象与敏感属性或受保护群体的关系。我们引入了公平邻域嵌入的框架,即公平邻域检索可视化器,该框架将公平非线性维度减少作为一种信息检索任务,其性能和公平性由信息检索标准量化。该方法优化了低维嵌入,保持高维数据邻域,而不产生偏向的对受保护群体的关联。在实验中,该方法使公平可视化优于以往的方法。

**[Paper URL](https://proceedings.mlr.press/v202/peltonen23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/peltonen23a/peltonen23a.pdf)** 

# The Ideal Continual Learner: An Agent That Never Forgets
**题目:** 理想持续学习者:永远不会忘记的代理人

**作者:** Liangzu Peng, Paris Giampouras, Rene Vidal

**Abstract:** The goal of continual learning is to find a model that solves multiple learning tasks which are presented sequentially to the learner. A key challenge in this setting is that the learner may "forget" how to solve a previous task when learning a new task, a phenomenon known as catastrophic forgetting. To address this challenge, many practical methods have been proposed, including memory-based, regularization-based and expansion-based methods. However, a rigorous theoretical understanding of these methods remains elusive. This paper aims to bridge this gap between theory and practice by proposing a new continual learning framework called "Ideal Continual Learner" (ICL), which is guaranteed to avoid catastrophic forgetting by construction. We show that ICL unifies multiple well-established continual learning methods and gives new theoretical insights into the strengths and weaknesses of these methods. We also derive generalization bounds for ICL which allow us to theoretically quantify "how rehearsal affects generalization". Finally, we connect ICL to several classic subjects and research topics of modern interest, which allows us to make historical remarks and inspire future directions.

**摘要:** 持续学习的目标是找到解决学生逐次提出的多个学习任务的模型。在这一环境中,一个关键的挑战是,学习者可能“忘记”在学习新任务时如何解决以前的任务,这一现象被称为灾难性遗忘。为了解决这一挑战,提出了许多实用方法,包括基于记忆、基于规范化和基于扩充的方法。然而,这些方法的严格理论理解仍然难以解决。本论文旨在通过提出一种新的持续学习框架,称为“理想持续学习者”(Ideal Continual Learner,ICL)来弥补理论与实践之间的差距,以确保通过构建避免灾难性遗忘。最后,我们将ICL连接到几个具有现代兴趣的经典主题和研究课题,从而使我们能够作历史性评论并启发未来方向。

**[Paper URL](https://proceedings.mlr.press/v202/peng23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/peng23a/peng23a.pdf)** 

# MolDiff: Addressing the Atom-Bond Inconsistency Problem in 3D Molecule Diffusion Generation
**题目:** MolDiff:解决3D分子扩散生成中的原子键不一致问题

**作者:** Xingang Peng, Jiaqi Guan, Qiang Liu, Jianzhu Ma

**Abstract:** Deep generative models have recently achieved superior performance in 3D molecule generation. Most of them first generate atoms and then add chemical bonds based on the generated atoms in a post-processing manner. However, there might be no corresponding bond solution for the temporally generated atoms as their locations are generated without considering potential bonds. We define this problem as the atom-bond inconsistency problem and claim it is the main reason for current approaches to generating unrealistic 3D molecules. To overcome this problem, we propose a new diffusion model called MolDiff which can generate atoms and bonds simultaneously while still maintaining their consistency by explicitly modeling the dependence between their relationships. We evaluated the generation ability of our proposed model and the quality of the generated molecules using criteria related to both geometry and chemical properties. The empirical studies showed that our model outperforms previous approaches, achieving a three-fold improvement in success rate and generating molecules with significantly better quality.

**摘要:** 深层生成模型最近在3D分子生成中取得了较高的性能,其中大部分首先生成原子,然后以生成原子为后处理方式添加化学键。然而,在考虑潜在键的情况下生成原子时,可能没有相应的键解。我们定义了这一问题为原子键不一致问题,并声称它是目前产生不现实的3D分子的主要原因。为了克服这一问题,我们提出了一种新的扩散模型,称为Mouldiff,它可以同时生成原子和键,同时通过明确的建模关系间的依赖性来保持它们的一致性。我们利用与几何和化学性质有关的标准,评估了我们提出的模型的生成能力和生成分子的质量。实证研究表明,我们的模型优于以往的方法,提高了成功率的三倍,并产生具有显著更好的质量的分子。

**[Paper URL](https://proceedings.mlr.press/v202/peng23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/peng23b/peng23b.pdf)** 

# Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation
**题目:** 诊断 、 反馈 、 适应:测试时间政策适应人框架

**作者:** Andi Peng, Aviv Netanyahu, Mark K Ho, Tianmin Shu, Andreea Bobu, Julie Shah, Pulkit Agrawal

**Abstract:** Policies often fail at test-time due to distribution shifts—changes in the state and reward that occur when an end user deploys the policy in environments different from those seen in training. Data augmentation can help models be more robust to such shifts by varying specific concepts in the state, e.g. object color, that are task-irrelevant and should not impact desired actions. However, designers training the agent don’t often know which concepts are irrelevant a priori. We propose a human-in-the-loop framework to leverage feedback from the end user to quickly identify and augment task-irrelevant visual state concepts. Our framework generates counterfactual demonstrations that allow users to quickly isolate shifted state concepts and identify if they should not impact the desired task, and can therefore be augmented using existing actions. We present experiments validating our full pipeline on discrete and continuous control tasks with real human users. Our method better enables users to (1) understand agent failure, (2) improve sample efficiency of demonstrations required for finetuning, and (3) adapt the agent to their desired reward.

**摘要:** 数据增强可以帮助模型通过在状态中变异特定概念,例如对象颜色,使模型更加鲁棒,因为这些概念与任务无关,并不能影响预期的操作。然而,培训代理的设计师并不经常知道哪些概念是无关的 priori。我们提议一个循环中的人框架,以利用最终用户反馈来快速识别和增强任务无关的视觉状态概念。我们的框架生成反事实演示,允许用户快速分离移位状态概念,并确定它们是否不应影响预期的任务,因此可以通过现有操作加以增强。我们的方法使用户能够更好地(一)理解代理失败,(二)提高对调试所需的样品的有效性,(三)将代理适应他们所期望的回报。

**[Paper URL](https://proceedings.mlr.press/v202/peng23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/peng23c/peng23c.pdf)** 

# Learning Hidden Markov Models When the Locations of Missing Observations are Unknown
**题目:** 当遗失的观测地点未知时,学习隐藏的马可夫模型

**作者:** Binyamin Perets, Mark Kozdoba, Shie Mannor

**Abstract:** The Hidden Markov Model (HMM) is one of the most widely used statistical models for sequential data analysis. One of the key reasons for this versatility is the ability of HMM to deal with missing data. However, standard HMM learning algorithms rely crucially on the assumption that the positions of the missing observations within the observation sequence are known. In the natural sciences, where this assumption is often violated, special variants of HMM, commonly known as Silent-state HMMs (SHMMs), are used. Despite their widespread use, these algorithms strongly rely on specific structural assumptions of the underlying chain, such as acyclicity, thus limiting the applicability of these methods. Moreover, even in the acyclic case, it has been shown that these methods can lead to poor reconstruction. In this paper we consider the general problem of learning an HMM from data with unknown missing observation locations. We provide reconstruction algorithms that do not require any assumptions about the structure of the underlying chain, and can also be used with limited prior knowledge, unlike SHMM. We evaluate and compare the algorithms in a variety of scenarios, measuring their reconstruction precision, and robustness under model miss-specification. Notably, we show that under proper specifications one can reconstruct the process dynamics as well as if the missing observations positions were known.

**摘要:** 隐藏马可夫模型(HMM)是连续数据分析最广泛应用的统计模型之一,其关键原因之一是HMM处理丢失数据的能力。然而,标准的HMM学习算法依赖于观察序列中丢失的观测位置的假设。在自然科学中,这种假设经常被违反的,常被称为静态HMM(SHMMs)的HMM的特殊变量被使用。尽管这些算法广泛使用,但这些算法仍然依赖于潜在链路的特定结构假设,例如无循环性,从而限制了这些方法的适用性。我们提供无前提的重建算法,并且与SHMM不同,可以在有限的预先知识下使用。我们在模型误差规范下评估和比较各种场景中的算法,测量它们的重建精度和鲁棒性。我们特别指出,在适当的规范下,可以重建过程动力学,以及知道丢失观测位置。

**[Paper URL](https://proceedings.mlr.press/v202/perets23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/perets23a/perets23a.pdf)** 

# Estimating the Contamination Factor’s Distribution in Unsupervised Anomaly Detection
**题目:** 无监督异常检测中污染因子分布的估计

**作者:** Lorenzo Perini, Paul-Christian Bürkner, Arto Klami

**Abstract:** Anomaly detection methods identify examples that do not follow the expected behaviour, typically in an unsupervised fashion, by assigning real-valued anomaly scores to the examples based on various heuristics. These scores need to be transformed into actual predictions by thresholding so that the proportion of examples marked as anomalies equals the expected proportion of anomalies, called contamination factor. Unfortunately, there are no good methods for estimating the contamination factor itself. We address this need from a Bayesian perspective, introducing a method for estimating the posterior distribution of the contamination factor for a given unlabeled dataset. We leverage several anomaly detectors to capture the basic notion of anomalousness and estimate the contamination using a specific mixture formulation. Empirically on 22 datasets, we show that the estimated distribution is well-calibrated and that setting the threshold using the posterior mean improves the detectors’ performance over several alternative methods.

**摘要:** 异常检测方法通过对基于不同实验方法的实值异常分数的实例确定不遵循预期行为的实例,通常以不经监督的方式。这些分数需要通过阈值转换为实际预测,以使标记为异常的实例比例等于预期的异常比例,称为污染因子。不幸的是,没有很好的方法来估计污染因子本身。我们从贝叶斯的观点来解决这一需要,引入一种方法来估计给定的未标记数据集的污染因子后方分布。通过对22个数据集的实证分析,我们证明估计分布是精确的,使用后平均值设置阈值改善了探测器的性能。

**[Paper URL](https://proceedings.mlr.press/v202/perini23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/perini23a/perini23a.pdf)** 

# Are Gaussian Data All You Need? The Extents and Limits of Universality in High-Dimensional Generalized Linear Estimation
**题目:** 高维广义线性估计中普遍性的范围和局限性

**作者:** Luca Pesce, Florent Krzakala, Bruno Loureiro, Ludovic Stephan

**Abstract:** In this manuscript we consider the problem of generalized linear estimation on Gaussian mixture data with labels given by a single-index model. Our first result is a sharp asymptotic expression for the test and training errors in the high-dimensional regime. Motivated by the recent stream of results on the Gaussian universality of the test and training errors in generalized linear estimation, we ask ourselves the question: "when is a single Gaussian enough to characterize the error?". Our formula allows us to give sharp answers to this question, both in the positive and negative directions. More precisely, we show that the sufficient conditions for Gaussian universality (or lack thereof) crucially depend on the alignment between the target weights and the means and covariances of the mixture clusters, which we precisely quantify. In the particular case of least-squares interpolation, we prove a strong universality property of the training error and show it follows a simple, closed-form expression. Finally, we apply our results to real datasets, clarifying some recent discussions in the literature about Gaussian universality of the errors in this context.

**摘要:** 本文讨论了基于单指数模型的标签的广义线性估计高斯混合物数据问题。第一项结果是高维系统测试和训练误差的尖锐渐近表达式。基于最近的广义线性估计高斯测试和训练误差结果的动力,我们提出了以下问题: "当一个单一的高斯足够描述误差时?".我们的公式允许我们对这一问题给出尖锐的答案,无论是正向还是负向。更确切地说,我们证明高斯的普遍性(或其缺乏)的充分条件的关键在于目标重量和混合物群的手段和共变量之间的一致性,我们对此进行了精确的定量。在最小方程插值的特殊案例中,我们证明了训练误差的强普遍性特性,并证明它遵循一个简单的闭式表达式。最后,我们应用我们的结果到实际数据集中,澄清了关于高斯误差的普遍性的最新文献讨论。

**[Paper URL](https://proceedings.mlr.press/v202/pesce23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pesce23a/pesce23a.pdf)** 

# Certifying Ensembles: A General Certification Theory with S-Lipschitzness
**题目:** 认证集群:S-Lipschitzness的通用认证理论

**作者:** Aleksandar Petrov, Francisco Eiras, Amartya Sanyal, Philip Torr, Adel Bibi

**Abstract:** Improving and guaranteeing the robustness of deep learning models has been a topic of intense research. Ensembling, which combines several classifiers to provide a better model, has been shown to be beneficial for generalisation, uncertainty estimation, calibration, and mitigating the effects of concept drift. However, the impact of ensembling on certified robustness is less well understood. In this work, we generalise Lipschitz continuity by introducing S-Lipschitz classifiers, which we use to analyse the theoretical robustness of ensembles. Our results are precise conditions when ensembles of robust classifiers are more robust than any constituent classifier, as well as conditions when they are less robust.

**摘要:** 深入学习模型的鲁棒性提高和保证一直是深入研究的课题。将多个分类器结合起来提供更好的模型的sembling被证明是对推广、不确定性估计、校正和概念漂移的影响有帮助的。然而,sembling对认证鲁棒性的影响较少被理解。在这一工作中,我们通过引入S-Lipschitz分类器来将Lipschitz连续性归纳为一般化,并用这种分类器分析组件的理论鲁棒性。我们的结果是鲁棒分类器组件比任何组件分类器组件更鲁棒的准确条件,以及它们较不鲁棒的条件。

**[Paper URL](https://proceedings.mlr.press/v202/petrov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/petrov23a/petrov23a.pdf)** 

# The Power of Learned Locally Linear Models for Nonlinear Policy Optimization
**题目:** 学习局部线性模型对非线性政策优化的有效性

**作者:** Daniel Pfrommer, Max Simchowitz, Tyler Westenbroek, Nikolai Matni, Stephen Tu

**Abstract:** A common pipeline in learning-based control is to iteratively estimate a model of system dynamics, and apply a trajectory optimization algorithm - e.g. $\mathtt{iLQR}$ - on the learned model to minimize a target cost. This paper conducts a rigorous analysis of a simplified variant of this strategy for general nonlinear systems. We analyze an algorithm which iterates between estimating local linear models of nonlinear system dynamics and performing $\mathtt{iLQR}$-like policy updates. We demonstrate that this algorithm attains sample complexity polynomial in relevant problem parameters, and, by synthesizing locally stabilizing gains, overcomes exponential dependence in problem horizon. Experimental results validate the performance of our algorithm, and compare to natural deep-learning baselines.

**摘要:** 在学习控制中,一个常见的管道是迭代估计系统动力学模型,并应用 trajectory optimization算法--例如$\mathtt{iLQR}$--在学习模型上,以最小化目标成本。本文对一般非线性系统的这一策略的简化变量进行了严格分析。我们分析了一个迭代估计非线性系统动力学局部线性模型与执行$\mathtt{iLQR}$类似的政策更新之间的算法。

**[Paper URL](https://proceedings.mlr.press/v202/pfrommer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pfrommer23a/pfrommer23a.pdf)** 

# A Scalable Frank-Wolfe-Based Algorithm for the Max-Cut SDP
**题目:** Max-Cut SDP的可扩展法兰克-沃尔夫算法

**作者:** Chi Bach Pham, Wynita Griggs, James Saunderson

**Abstract:** We consider the problem of solving large-scale instances of the Max-Cut semidefinite program (SDP), i.e., optimizing a linear function over $n\times n$ positive semidefinite (PSD) matrices with unit diagonal. When the cost matrix is PSD, we show how to exactly reformulate the problem as maximizing a smooth concave function over PSD matrices with unit trace. By applying the Frank-Wolfe method, we obtain a simple algorithm that is compatible with recent sampling-based techniques to solve SDPs using low memory. We demonstrate the practical performance of our method on $10^6\times 10^6$ instances of the max-cut SDP with costs having up to $5 \times 10^6$ non-zero entries. Theoretically, we show that our method solves problems with diagonally dominant costs to relative error $\epsilon$ in $O(n\epsilon^{-1})$ calls to a randomized approximate largest eigenvalue subroutine, each of which succeeds with high probability after $O(\log(n)\epsilon^{-1/2})$ matrix-vector multiplications with the cost matrix.

**摘要:** 我们考虑了解决Max-Cut半定义程序(SDP)大规模实例的问题,即以单位直角的$n\times n$正半定义(PSD)矩阵优化线性函数。当成本矩阵为PSD时,我们展示了如何准确地将问题重新归纳为以单位跟踪的PSD矩阵优化滑凹函数。通过应用法兰克-沃尔夫方法,我们得到了一种与最近的采样技术兼容的简单算法,以低存储量解决SDP。理论上,我们证明,我们的方法解决了在$O(n\epsilon^{-1})$中对相对误差$\epsilon$的斜向支配成本的求解问题,求解为一个随机化近似最大自值子程序,每个子程序在$O(\log(n)\epsilon^{-1/2})$矩阵-向量乘法后具有较高的概率成功。

**[Paper URL](https://proceedings.mlr.press/v202/pham23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pham23a/pham23a.pdf)** 

# Attention-Based Recurrence for Multi-Agent Reinforcement Learning under Stochastic Partial Observability
**题目:** 随机部分观察性下多干事强化学习的注意性重复

**作者:** Thomy Phan, Fabian Ritz, Philipp Altmann, Maximilian Zorn, Jonas Nüßlein, Michael Kölle, Thomas Gabor, Claudia Linnhoff-Popien

**Abstract:** Stochastic partial observability poses a major challenge for decentralized coordination in multi-agent reinforcement learning but is largely neglected in state-of-the-art research due to a strong focus on state-based centralized training for decentralized execution (CTDE) and benchmarks that lack sufficient stochasticity like StarCraft Multi-Agent Challenge (SMAC). In this paper, we propose Attention-based Embeddings of Recurrence In multi-Agent Learning (AERIAL) to approximate value functions under stochastic partial observability. AERIAL replaces the true state with a learned representation of multi-agent recurrence, considering more accurate information about decentralized agent decisions than state-based CTDE. We then introduce MessySMAC, a modified version of SMAC with stochastic observations and higher variance in initial states, to provide a more general and configurable benchmark regarding stochastic partial observability. We evaluate AERIAL in Dec-Tiger as well as in a variety of SMAC and MessySMAC maps, and compare the results with state-based CTDE. Furthermore, we evaluate the robustness of AERIAL and state-based CTDE against various stochasticity configurations in MessySMAC.

**摘要:** 随机部分观测是多agent增强学习中分散协调的一大挑战,但由于集中集中训练的重点较少,缺乏足够的随机性,例如StarCraft Multi-Agent Challenge(SMAC),在最新研究中却被忽视。本文提出了基于注意的随机部分观测在多agent增强学习(AERIAL)中重演的嵌入,以近似随机部分观测下的值函数。AERIAL取代了基于国家CTDE的分散代理决策的精确信息,以学习的多agent重演表示取代了真实状态。我们对Dec-Tiger以及各种 SMAC和MesySMAC地图中的AERIAL进行了评价,并与基于状态的CTDE进行了比较。此外,我们对AERIAL和基于状态的CTDE在MesySMAC中各种随机性配置的鲁棒性进行了评价。

**[Paper URL](https://proceedings.mlr.press/v202/phan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/phan23a/phan23a.pdf)** 

# HyperTuning: Toward Adapting Large Language Models without Back-propagation
**题目:** HyperTuning:实现大规模语言模型的适应性

**作者:** Jason Phang, Yi Mao, Pengcheng He, Weizhu Chen

**Abstract:** Fine-tuning large language models for different tasks can be costly and inefficient, and even methods that reduce the number of tuned parameters still require full gradient-based optimization. We propose HyperTuning, a novel approach to model adaptation that uses a hypermodel to generate task-specific parameters for a fixed downstream model. We demonstrate a simple setup for hypertuning with HyperT5, a T5-based hypermodel that produces soft prefixes or LoRA parameters for a frozen T5 model from few-shot examples. We train HyperT5 in two stages: first, hyperpretraining with a modified conditional language modeling objective that trains a hypermodel to generate parameters; second, multi-task fine-tuning (MTF) on a large number of diverse language tasks. We evaluate HyperT5 on P3, MetaICL and Super-NaturalInstructions datasets, and show that it can effectively generate parameters for unseen tasks. Moreover, we show that using hypermodel-generated parameters as initializations for further parameter-efficient fine-tuning improves performance. HyperTuning can thus be a flexible and efficient way to leverage large language models for diverse downstream applications.

**摘要:** 对不同任务的大型语言模型进行微调是昂贵且不效率的,甚至降低调制参数的方法仍需要完全基于梯度的优化。我们提出了一种新型的模型适应方法,它使用超模型生成特定任务的参数,用于固定下游模型。我们展示了一个简单的设置,用于超调制 HyperT5,一种基于T5的超模型,它为冻结的T5模型生成软前缀或LoRA参数。我们训练 HyperT5在两个阶段:第一阶段,采用修改条件语言模型目标的超预训练,训练超模型生成参数;第二阶段,在大量不同的语言任务上进行多任务微调(MTF)。此外,我们证明使用超模型生成的参数作为进一步参数效率的微调的初始化提高了性能,因此,超微调可以成为一种灵活和高效的方式来利用大型语言模型用于各种下游应用。

**[Paper URL](https://proceedings.mlr.press/v202/phang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/phang23a/phang23a.pdf)** 

# Linear CNNs Discover the Statistical Structure of the Dataset Using Only the Most Dominant Frequencies
**题目:** 线性CNN研究数据集的统计结构,只使用最主导频率

**作者:** Hannah Pinson, Joeri Lenaerts, Vincent Ginis

**Abstract:** We here present a stepping stone towards a deeper understanding of convolutional neural networks (CNNs) in the form of a theory of learning in linear CNNs. Through analyzing the gradient descent equations, we discover that the evolution of the network during training is determined by the interplay between the dataset structure and the convolutional network structure. We show that linear CNNs discover the statistical structure of the dataset with non-linear, ordered, stage-like transitions, and that the speed of discovery changes depending on the relationship between the dataset and the convolutional network structure. Moreover, we find that this interplay lies at the heart of what we call the "dominant frequency bias", where linear CNNs arrive at these discoveries using only the dominant frequencies of the different structural parts present in the dataset. We furthermore provide experiments that show how our theory relates to deep, non-linear CNNs used in practice. Our findings shed new light on the inner working of CNNs, and can help explain their shortcut learning and their tendency to rely on texture instead of shape.

**摘要:** 通过分析梯度下降方程,我们发现在训练过程中网络的演化是由数据集结构和变形网络结构之间的相互作用决定的。我们显示,线性CNN发现数据集的统计结构具有非线性、有序、类似阶段的转变,并且发现发现的速度取决于数据集和变形网络结构之间的关系。此外,我们发现这种相互作用位于我们所谓的“主导频率偏差”的核心,即线性CNN只使用数据集中存在的不同结构部分的主导频率来实现这些发现。我们的发现揭示了CNN的内部工作,并有助于解释它们的捷径学习和依赖结构而不是形状的倾向。

**[Paper URL](https://proceedings.mlr.press/v202/pinson23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pinson23a/pinson23a.pdf)** 

# Conformal Prediction for Federated Uncertainty Quantification Under Label Shift
**题目:** 标签转移下的联邦不确定性量化标准预测

**作者:** Vincent Plassier, Mehdi Makni, Aleksandr Rubashevskii, Eric Moulines, Maxim Panov

**Abstract:** Federated Learning (FL) is a machine learning framework where many clients collaboratively train models while keeping the training data decentralized. Despite recent advances in FL, the uncertainty quantification topic (UQ) remains partially addressed. Among UQ methods, conformal prediction (CP) approaches provides distribution-free guarantees under minimal assumptions. We develop a new federated conformal prediction method based on quantile regression and take into account privacy constraints. This method takes advantage of importance weighting to effectively address the label shift between agents and provides theoretical guarantees for both valid coverage of the prediction sets and differential privacy. Extensive experimental studies demonstrate that this method outperforms current competitors.

**摘要:** 联合学习(FL)是一个机器学习框架,许多客户共同培训模型,同时保持培训数据分散。尽管FL取得了较好进展,不确定性定量化主题(UQ)仍未得到部分解决。在UQ方法中,定量预测(CP)方法提供在最小假设下无分布的保证。我们开发了基于量化回归的新的联合定量预测方法,并考虑到隐私约束。该方法利用重要权重来有效解决代理之间的标签转移,并为定量预测集合的有效覆盖和微分隐私提供理论保证。

**[Paper URL](https://proceedings.mlr.press/v202/plassier23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/plassier23a/plassier23a.pdf)** 

# Universal Physics-Informed Neural Networks: Symbolic Differential Operator Discovery with Sparse Data
**题目:** 基于物理学的神经网络:带备份数据的符号微分运算器发现

**作者:** Lena Podina, Brydon Eastman, Mohammad Kohandel

**Abstract:** In this work we perform symbolic discovery of differential operators in a situation where there is sparse experimental data. This small data regime in machine learning can be made tractable by providing our algorithms with prior information about the underlying dynamics. Physics Informed Neural Networks (PINNs) have been very successful in this regime (reconstructing entire ODE solutions using only a single point or entire PDE solutions with very few measurements of the initial condition). The Universal PINN approach (UPINN) adds a neural network that learns a representation of unknown hidden terms in the differential equation. The algorithm yields both a surrogate solution to the differential equation and a black-box representation of the hidden terms. These hidden term neural networks can then be converted into symbolic equations using symbolic regression techniques like AI Feynman. In order to achieve convergence of the neural networks, we provide our algorithms with (noisy) measurements of both the initial condition as well as (synthetic) experimental data obtained at later times. We demonstrate strong performance of UPINNs even when provided with very few measurements of noisy data in both the ODE and PDE regime.

**摘要:** 物理信息神经网络(PINNs)在这一模式中取得了很大的成功(仅使用一个单点或完全的PDE解决方案重建整个ODE解决方案,但初始条件的测量非常少)。Universal PINN方法(UPINN)添加了一个神经网络,它在微分方程中学习了未知隐藏术语的表示。该算法给出了对微分方程的替代方案和隐藏术语的黑箱表示。这些隐藏术语神经网络可以用AIFeynman等符号回归技术转换成符号方程。为了实现神经网络的收敛性,我们向算法提供最初条件的(噪音)测量以及后来获得的(合成)实验数据。我们证明了UPINN的强性能,即使在ODE和PDE两个系统中提供非常少的噪音数据的测量。

**[Paper URL](https://proceedings.mlr.press/v202/podina23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/podina23a/podina23a.pdf)** 

# Sequential Kernelized Independence Testing
**题目:** 序列核化独立性测试

**作者:** Aleksandr Podkopaev, Patrick Blöbaum, Shiva Kasiviswanathan, Aaditya Ramdas

**Abstract:** Independence testing is a classical statistical problem that has been extensively studied in the batch setting when one fixes the sample size before collecting data. However, practitioners often prefer procedures that adapt to the complexity of a problem at hand instead of setting sample size in advance. Ideally, such procedures should (a) stop earlier on easy tasks (and later on harder tasks), hence making better use of available resources, and (b) continuously monitor the data and efficiently incorporate statistical evidence after collecting new data, while controlling the false alarm rate. Classical batch tests are not tailored for streaming data: valid inference after data peeking requires correcting for multiple testing which results in low power. Following the principle of testing by betting, we design sequential kernelized independence tests that overcome such shortcomings. We exemplify our broad framework using bets inspired by kernelized dependence measures, e.g., the Hilbert-Schmidt independence criterion. Our test is also valid under non-i.i.d. time-varying settings. We demonstrate the power of our approaches on both simulated and real data.

**摘要:** 独立测试是一个经典的统计问题,在数据收集之前,人们在批量设置中广泛研究了该问题。然而,实践者往往倾向于在预先设定样品大小而不适应当前问题的复杂性程序。理想情况下,这些程序应(a)在容易任务(以及较难任务)之前停止,从而更好地利用现有资源,以及(b)在收集新数据后持续监测数据并有效地纳入统计证据,同时控制错误报警率。经典批量测试不适合流入数据:数据检视后有效的推断需要对多个测试进行修正,结果低功率。我们以基于核化依赖措施的赌注为例,例如希尔伯特-施密特独立标准。我们的测试也适用于非i.i.d.时间变化的设置。我们证明了我们的方法在模拟数据和实际数据上具有很强的效力。

**[Paper URL](https://proceedings.mlr.press/v202/podkopaev23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/podkopaev23a/podkopaev23a.pdf)** 

# Truncating Trajectories in Monte Carlo Reinforcement Learning
**题目:** 在蒙特卡罗强化学习中切断传动机

**作者:** Riccardo Poiani, Alberto Maria Metelli, Marcello Restelli

**Abstract:** In Reinforcement Learning (RL), an agent acts in an unknown environment to maximize the expected cumulative discounted sum of an external reward signal, i.e., the expected return. In practice, in many tasks of interest, such as policy optimization, the agent usually spends its interaction budget by collecting episodes of fixed length within a simulator (i.e., Monte Carlo simulation). However, given the discounted nature of the RL objective, this data collection strategy might not be the best option. Indeed, the rewards taken in early simulation steps weigh exponentially more than future rewards. Taking a cue from this intuition, in this paper, we design an a-priori budget allocation strategy that leads to the collection of trajectories of different lengths, i.e., truncated. The proposed approach provably minimizes the width of the confidence intervals around the empirical estimates of the expected return of a policy. After discussing the theoretical properties of our method, we make use of our trajectory truncation mechanism to extend Policy Optimization via Importance Sampling (POIS, Metelli et al., 2018) algorithm. Finally, we conduct a numerical comparison between our algorithm and POIS: the results are consistent with our theory and show that an appropriate truncation of the trajectories can succeed in improving performance.

**摘要:** 在强化学习中,一个代理人在未知的环境中,以最大化外部奖励信号的预期累积折扣金额,即预期回报。在实践中,在政策优化等许多有兴趣的任务中,代理通常通过在模拟器内收集固定长度的片段来花费其交互预算。然而,鉴于RL目标的折扣性质,这一数据收集策略可能不是最佳选择。事实上,在早期的模拟步骤中所采取的奖励比未来的奖励高指数。在讨论了该方法的理论特性后,我们利用轨迹切换机制扩展了通过重要采样(POIS,Metelli et al., 2018)算法的策略优化。最后,我们对该算法与POIS进行了数值比较:结果与我们理论一致,表明适当的轨迹切换能够提高性能。

**[Paper URL](https://proceedings.mlr.press/v202/poiani23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/poiani23a/poiani23a.pdf)** 

# Hyena Hierarchy: Towards Larger Convolutional Language Models
**题目:** 海娜层次结构:向更大的进化语言模型

**作者:** Michael Poli, Stefano Massaroli, Eric Nguyen, Daniel Y Fu, Tri Dao, Stephen Baccus, Yoshua Bengio, Stefano Ermon, Christopher Re

**Abstract:** Recent advances in deep learning have relied heavily on the use of large Transformers due to their ability to learn at scale. However, the core building block of Transformers, the attention operator, exhibits quadratic cost in sequence length, limiting the amount of context accessible. Existing subquadratic methods based on low-rank and sparse approximations need to be combined with dense attention layers to match Transformers at scale, indicating a gap in capability. In this work, we propose Hyena, a subquadratic drop-in replacement for attention constructed by interleaving implicitly parametrized long convolutions and data-controlled gating. In challenging reasoning tasks on sequences of thousands to hundreds of thousands of tokens, Hyena improves accuracy by more than 50 points over operators relying on state-space models, transfer functions, and other implicit and explicit methods, matching attention-based models. We set a new state-of-the-art for dense-attention-free architectures on language modeling in standard datasets WikiText103 and The Pile, reaching Transformer quality with a 20% reduction in training compute required at sequence length 2k. Hyena operators are 2x faster than highly optimized attention at sequence length 8k, with speedups of 100x at 64k.

**摘要:** 深度学习中最近的进步很大程度上依赖于大型变换器的利用,因为它们能够在尺度上学习。然而,变换器的核心构件,即注意力操作器,在序列长度中显示了二次成本,限制了可访问上下文的数量。基于低级和稀疏的近似的现有次元二次方法需要与密集的注意力层结合,以便在尺度上匹配变换器,显示出能力上的差距。我们为标准数据集WikiText103和The Pile的语言建模提供了新的最先进的密度无注意架构,在2k序列长度要求的训练计算减少20%的情况下达到变换器质量。

**[Paper URL](https://proceedings.mlr.press/v202/poli23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/poli23a/poli23a.pdf)** 

# Spurious Valleys and Clustering Behavior of Neural Networks
**题目:** 斑点谷及神经网络集群行为

**作者:** Samuele Pollaci

**Abstract:** Neural networks constitute a class of functions that are typically non-surjective, with high-dimensional fibers and complicated image. We prove two main results concerning the geometry of the loss landscape of a neural network. First, we provide an explicit effective bound on the sizes of the hidden layers so that the loss landscape has no spurious valleys, which guarantees the success of gradient descent methods. Second, we present a novel method for analyzing whether a given neural network architecture with monomial activation function can represent a target function of interest. The core of our analysis method is the study of a specific set of error values, and its behavior depending on different training datasets.

**摘要:** 神经网络是一种具有高维纤维和复杂图像的非定量功能类别,我们证明了神经网络失落景观几何学的两个主要结果。第一,我们提供了隐蔽层大小的明确有效的约束,使失落景观没有伪谷,保证梯度下降方法的成功。

**[Paper URL](https://proceedings.mlr.press/v202/pollaci23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pollaci23a/pollaci23a.pdf)** 

# Multisample Flow Matching: Straightening Flows with Minibatch Couplings
**题目:** 多样流匹配:用微批耦合的伸缩流

**作者:** Aram-Alexandre Pooladian, Heli Ben-Hamu, Carles Domingo-Enrich, Brandon Amos, Yaron Lipman, Ricky T. Q. Chen

**Abstract:** Simulation-free methods for training continuous-time generative models construct probability paths that go between noise distributions and individual data samples. Recent works, such as Flow Matching, derived paths that are optimal for each data sample. However, these algorithms rely on independent data and noise samples, and do not exploit underlying structure in the data distribution for constructing probability paths. We propose Multisample Flow Matching, a more general framework that uses non-trivial couplings between data and noise samples while satisfying the correct marginal constraints. At small overhead costs, this generalization allows us to (i) reduce gradient variance during training, (ii) obtain straighter flows for the learned vector field, which allows us to generate high-quality samples using fewer function evaluations, and (iii) obtain transport maps with low cost in high dimensions, which has applications beyond generative modeling. Importantly, we do so in a completely simulation-free manner with a simple minimization objective. We show that our proposed methods improve sample consistency on downsampled ImageNet data sets, and lead to better low-cost sample generation.

**摘要:** 用于训练连续时间生成模型的无仿真方法构造噪声分布和单个数据样品之间的概率路径。最近的工作,如流匹配,为每个数据样品提供最优的导引路径。然而,这些算法依赖独立的数据和噪声样品,并不利用数据分布中潜在的结构来构造概率路径。我们提出了多样品流匹配,一种较一般的框架,它使用数据和噪声样品之间的非平凡耦合 while satisfying the correct marginal constraints。重要的是,我们以一种简单的最小化目标进行完全无仿真的方式。我们表明,我们提出的方法改善了下采样的ImageNet数据集的样品一致性,并导致了更好的低成本样品生成。

**[Paper URL](https://proceedings.mlr.press/v202/pooladian23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pooladian23a/pooladian23a.pdf)** 

# Minimax estimation of discontinuous optimal transport maps: The semi-discrete case
**题目:** 连续最优运输图的最小估计:半散态例

**作者:** Aram-Alexandre Pooladian, Vincent Divol, Jonathan Niles-Weed

**Abstract:** We consider the problem of estimating the optimal transport map between two probability distributions, $P$ and $Q$ in $\mathbb{R}^d$, on the basis of i.i.d. samples. All existing statistical analyses of this problem require the assumption that the transport map is Lipschitz, a strong requirement that, in particular, excludes any examples where the transport map is discontinuous. As a first step towards developing estimation procedures for discontinuous maps, we consider the important special case where the data distribution $Q$ is a discrete measure supported on a finite number of points in $\mathbb{R}^d$. We study a computationally efficient estimator initially proposed by (Pooladian & Niles-Weed, 2021), based on entropic optimal transport, and show in the semi-discrete setting that it converges at the minimax-optimal rate $n^{-1/2}$, independent of dimension. Other standard map estimation techniques both lack finite-sample guarantees in this setting and provably suffer from the curse of dimensionality. We confirm these results in numerical experiments, and provide experiments for other settings, not covered by our theory, which indicate that the entropic estimator is a promising methodology for other discontinuous transport map estimation problems.

**摘要:** 基于i.i.d.样本,我们考虑了在$\mathbb{R}^d$中的两个概率分布 $P$ 和 $Q$ 之间估计最优传输地图的问题。所有现有的统计分析都要求假设传输地图是 Lipschitz,这是一个强的要求,特别是排除了传输地图不连续的任何例子。作为发展不连续地图估计程序的第一步,我们考虑了数据分布 $Q$ 是基于$\mathbb{R}^d$有限点的离散测量的重要特殊案例。其他标准映射估计技术在这一条件下既缺乏有限样本保证,而且可以证明受到维度的诅咒。我们在数值实验中证实了这些结果,并为其他条件提供实验,这些实验并不包括我们理论,表明,熵估计器是其他不连续的交通映射估计问题的一个有前途的方法。

**[Paper URL](https://proceedings.mlr.press/v202/pooladian23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/pooladian23b/pooladian23b.pdf)** 

# Test-time Adaptation with Slot-Centric Models
**题目:** 基于 Slot-Centric模型的测试时间适应

**作者:** Mihir Prabhudesai, Anirudh Goyal, Sujoy Paul, Sjoerd Van Steenkiste, Mehdi S. M. Sajjadi, Gaurav Aggarwal, Thomas Kipf, Deepak Pathak, Katerina Fragkiadaki

**Abstract:** Current visual detectors, though impressive within their training distribution, often fail to parse out-of-distribution scenes into their constituent entities. Recent test-time adaptation methods use auxiliary self-supervised losses to adapt the network parameters to each test example independently and have shown promising results towards generalization outside the training distribution for the task of image classification. In our work, we find evidence that these losses are insufficient for the task of scene decomposition, without also considering architectural inductive biases. Recent slot-centric generative models attempt to decompose scenes into entities in a self-supervised manner by reconstructing pixels. Drawing upon these two lines of work, we propose Slot-TTA, a semi-supervised slot-centric scene decomposition model that at test time is adapted per scene through gradient descent on reconstruction or cross-view synthesis objectives. We evaluate Slot-TTA across multiple input modalities, images or 3D point clouds, and show substantial out-of-distribution performance improvements against state-of-the-art supervised feed-forward detectors, and alternative test-time adaptation methods. Project Webpage: http://slot-tta.github.io/

**摘要:** 当前的视觉探测器虽然在训练分布中颇具吸引力,但往往无法将非分布的场景分解为其组成实体。最近的测试时间适应方法使用辅助自监督损失来独立地调整网络参数,并在训练分布外对图像分类任务的一般化方面显示了有希望的结果。在我们的研究中,我们发现这些损失不足以完成场景分解的任务,而不考虑建筑的诱导性偏见。我们对多个输入模式、图像或3D点云的 Slot-TTA 进行评估,并显示了与最先进的监控反馈检测器和替代测试时间适应方法相比,在非分布性能方面有显著的改进。

**[Paper URL](https://proceedings.mlr.press/v202/prabhudesai23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/prabhudesai23a/prabhudesai23a.pdf)** 

# JAWS-X: Addressing Efficiency Bottlenecks of Conformal Prediction Under Standard and Feedback Covariate Shift
**题目:** JAWS-X:在标准和反馈变换下对符合预测的效率问题解决

**作者:** Drew Prinster, Suchi Saria, Anqi Liu

**Abstract:** We study the efficient estimation of predictive confidence intervals for black-box predictors when the common data exchangeability (e.g., i.i.d.) assumption is violated due to potentially feedback-induced shifts in the input data distribution. That is, we focus on standard and feedback covariate shift (FCS), where the latter allows for feedback dependencies between train and test data that occur in many decision-making scenarios like experimental design. Whereas prior conformal prediction methods for this problem are in general either extremely computationally demanding or make inefficient use of labeled data, we propose a collection of methods based on the jackknife+ that achieve a practical balance of computational and statistical efficiency. Theoretically, our proposed JAW-FCS method extends the rigorous, finite-sample coverage guarantee of the jackknife+ to FCS. We moreover propose two tunable relaxations to JAW-FCS’s computation that maintain finite-sample guarantees: one using only $K$ leave-one-out models (JAW-$K$LOO) and a second building on $K$-fold cross validation+ (WCV+). Practically, we demonstrate that JAW-FCS and its computational relaxations outperform state-of-the-art baselines on a variety of real-world datasets under standard and feedback covariate shift, including for biomolecular design and active learning tasks.

**摘要:** 本文研究了在输入数据分布中可能因反馈诱导的转变而违反一般数据交换性(例如i.i.d.)假设的黑箱预测器预测信度间隔的有效估计。即,我们着重于标准和反馈共变性转变(FCS),后者允许在许多决策场景中如实验设计中出现的训练和测试数据之间的反馈依赖性。此外,我们还提出了两个可调放松的有限样本保证的JAW-FCS计算:一种只使用$K$ leave-one-out模型(JAW-$K$LOO)和另一种基于$K$-fold cross validation+(WCV+)的结构。

**[Paper URL](https://proceedings.mlr.press/v202/prinster23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/prinster23a/prinster23a.pdf)** 

# Equivariant Polynomials for Graph Neural Networks
**题目:** 图神经网络等价多项式

**作者:** Omri Puny, Derek Lim, Bobak Kiani, Haggai Maron, Yaron Lipman

**Abstract:** Graph Neural Networks (GNN) are inherently limited in their expressive power. Recent seminal works (Xu et al., 2019; Morris et al., 2019b) introduced the Weisfeiler-Lehman (WL) hierarchy as a measure of expressive power. Although this hierarchy has propelled significant advances in GNN analysis and architecture developments, it suffers from several significant limitations. These include a complex definition that lacks direct guidance for model improvement and a WL hierarchy that is too coarse to study current GNNs. This paper introduces an alternative expressive power hierarchy based on the ability of GNNs to calculate equivariant polynomials of a certain degree. As a first step, we provide a full characterization of all equivariant graph polynomials by introducing a concrete basis, significantly generalizing previous results. Each basis element corresponds to a specific multi-graph, and its computation over some graph data input corresponds to a tensor contraction problem. Second, we propose algorithmic tools for evaluating the expressiveness of GNNs using tensor contraction sequences, and calculate the expressive power of popular GNNs. Finally, we enhance the expressivity of common GNN architectures by adding polynomial features or additional operations / aggregations inspired by our theory. These enhanced GNNs demonstrate state-of-the-art results in experiments across multiple graph learning benchmarks.

**摘要:** 图神经网络(GNN)在表达能力方面具有明显的局限性。最近的半导体研究(Xu et al., 2019; Morris et al., 2019b)引入了Weisfeiler-Lehman(WL)层次结构作为表达能力的衡量标准。虽然这一层次结构推动了GNN分析和架构发展中的重大进展,但它遭受了若干重大限制。这些包括缺乏改进模型的直接指导和研究当前GNN的过于粗糙的WL层次结构的复杂定义。本论文介绍了基于GNN计算一定程度等效多项式的能力的替代表达能力层次结构。其次,我们提出了利用天索收缩序列来评价GNN的表达能力的算法工具,并计算了流行GNN的表达能力。最后,我们通过添加多项式特征或基于我们理论的额外操作/集群来提高通用GNN架构的表达能力。

**[Paper URL](https://proceedings.mlr.press/v202/puny23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/puny23a/puny23a.pdf)** 

# Contrast with Reconstruct: Contrastive 3D Representation Learning Guided by Generative Pretraining
**题目:** 反向与重建:基于生成预训练的反向3D表示学习

**作者:** Zekun Qi, Runpei Dong, Guofan Fan, Zheng Ge, Xiangyu Zhang, Kaisheng Ma, Li Yi

**Abstract:** Mainstream 3D representation learning approaches are built upon contrastive or generative modeling pretext tasks, where great improvements in performance on various downstream tasks have been achieved. However, we find these two paradigms have different characteristics: (i) contrastive models are data-hungry that suffer from a representation over-fitting issue; (ii) generative models have a data filling issue that shows inferior data scaling capacity compared to contrastive models. This motivates us to learn 3D representations by sharing the merits of both paradigms, which is non-trivial due to the pattern difference between the two paradigms. In this paper, we propose contrast with reconstruct (ReCon) that unifies these two paradigms. ReCon is trained to learn from both generative modeling teachers and cross-modal contrastive teachers through ensemble distillation, where the generative student is used to guide the contrastive student. An encoder-decoder style ReCon-block is proposed that transfers knowledge through cross attention with stop-gradient, which avoids pretraining over-fitting and pattern difference issues. ReCon achieves a new state-of-the-art in 3D representation learning, e.g., 91.26% accuracy on ScanObjectNN. Codes have been released at https://github.com/qizekun/ReCon.

**摘要:** 主要的3D建模学习方法建立在对比性或生成性建模的借口任务之上,在不同的下游任务中取得了巨大的性能改善。然而,我们发现这两个建模具有不同的特征: (i)对比性建模是数据渴望的,因为建模过多的问题; (ii)生成性建模有数据充填问题,显示与对比性建模相比的数据规模能力较低。这促使我们学习三维建模,分享两类建模的优点,这是由于两类建模之间的模式差异而不平凡的。一个编码器-编码器风格的ReCon-block被提议通过交叉注意力转移知识与停止级数,避免预训练的过度匹配和模式差异问题。ReCon在3D表示学习中实现了最新状态,例如,ScanObjectNN的91.26%准确性。

**[Paper URL](https://proceedings.mlr.press/v202/qi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/qi23a/qi23a.pdf)** 

# An Effective Meaningful Way to Evaluate Survival Models
**题目:** 评估生存模式的有效意义

**作者:** Shi-Ang Qi, Neeraj Kumar, Mahtab Farrokh, Weijie Sun, Li-Hao Kuan, Rajesh Ranganath, Ricardo Henao, Russell Greiner

**Abstract:** One straightforward metric to evaluate a survival prediction model is based on the Mean Absolute Error (MAE) – the average of the absolute difference between the time predicted by the model and the true event time, over all subjects. Unfortunately, this is challenging because, in practice, the test set includes (right) censored individuals, meaning we do not know when a censored individual actually experienced the event. In this paper, we explore various metrics to estimate MAE for survival datasets that include (many) censored individuals. Moreover, we introduce a novel and effective approach for generating realistic semi-synthetic survival datasets to facilitate the evaluation of metrics. Our findings, based on the analysis of the semi-synthetic datasets, reveal that our proposed metric (MAE using pseudo-observations) is able to rank models accurately based on their performance, and often closely matches the true MAE – in particular, is better than several alternative methods.

**摘要:** 一个简单度量评估生存预测模型的基础是平均绝对误差(MAE)——模型预测的时间和真实事件时间之间的绝对差的平均值。不幸的是,这是挑战性的,因为在实践中,测试集合包括(正确的)受过审查的个人,这意味着我们不知道受过审查的个人在实际经历事件时会发生什么情况。

**[Paper URL](https://proceedings.mlr.press/v202/qi23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/qi23b/qi23b.pdf)** 

# Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D
**题目:** 粗到精确:三维分子生成的层次扩散模型

**作者:** Bo Qiang, Yuxuan Song, Minkai Xu, Jingjing Gong, Bowen Gao, Hao Zhou, Wei-Ying Ma, Yanyan Lan

**Abstract:** Generating desirable molecular structures in 3D is a fundamental problem for drug discovery. Despite the considerable progress we have achieved, existing methods usually generate molecules in atom resolution and ignore intrinsic local structures such as rings, which leads to poor quality in generated structures, especially when generating large molecules. Fragment-based molecule generation is a promising strategy, however, it is nontrivial to be adapted for 3D non-autoregressive generations because of the combinational optimization problems. In this paper, we utilize a coarse-to-fine strategy to tackle this problem, in which a Hierarchical Diffusion-based model (i.e. HierDiff) is proposed to preserve the validity of local segments without relying on autoregressive modeling. Specifically, HierDiff first generates coarse-grained molecule geometries via an equivariant diffusion process, where each coarse-grained node reflects a fragment in a molecule. Then the coarse-grained nodes are decoded into fine-grained fragments by a message-passing process and a newly designed iterative refined sampling module. Lastly, the fine-grained fragments are then assembled to derive a complete atomic molecular structure. Extensive experiments demonstrate that HierDiff consistently improves the quality of molecule generation over existing methods.

**摘要:** 基于断片的分子生成是一个很有前途的策略,但由于组合优化问题,不能为3D非自回归的生成进行调整。本文采用粗到细的策略来解决这一问题,提出了一种基于分层扩散的模型(即希尔迪夫),以保持局部断片的有效性而不依赖自回归的建模。然后通过消息传递过程和新设计的迭代精细抽样模块将粗粒节点解码成细粒断片,最后将细粒断片组装成完整的原子分子结构。

**[Paper URL](https://proceedings.mlr.press/v202/qiang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/qiang23a/qiang23a.pdf)** 

# Collaborative Causal Inference with Fair Incentives
**题目:** 公平激励的协同动机干涉

**作者:** Rui Qiao, Xinyi Xu, Bryan Kian Hsiang Low

**Abstract:** Collaborative causal inference (CCI) aims to improve the estimation of the causal effect of treatment variables by utilizing data aggregated from multiple self-interested parties. Since their source data are valuable proprietary assets that can be costly or tedious to obtain, every party has to be incentivized to be willing to contribute to the collaboration, such as with a guaranteed fair and sufficiently valuable reward (than performing causal inference on its own). This paper presents a reward scheme designed using the unique statistical properties that are required by causal inference to guarantee certain desirable incentive criteria (e.g., fairness, benefit) for the parties based on their contributions. To achieve this, we propose a data valuation function to value parties’ data for CCI based on the distributional closeness of its resulting treatment effect estimate to that utilizing the aggregated data from all parties. Then, we show how to value the parties’ rewards fairly based on a modified variant of the Shapley value arising from our proposed data valuation for CCI. Finally, the Shapley fair rewards to the parties are realized in the form of improved, stochastically perturbed treatment effect estimates. We empirically demonstrate the effectiveness of our reward scheme using simulated and real-world datasets.

**摘要:** 合作因果推理(CCI)旨在通过从多个利益相关方集聚的数据来改进处理变量因果推理的估计。由于它们的源数据是宝贵的财产资产,取得这些资产可能很昂贵或繁琐,因此,每个利益相关方必须被鼓励愿意参与合作,例如提供保证的公平和足够有价值的奖励(而不是单独进行因果推理)。本论文提出了一种基于其贡献为利益相关方制定的奖励方案,以因果推理所要求的独特统计特性为保证某些可取的奖励标准(例如公平、收益)。为此,我们提出了一种基于其结果处理效应估计的分布接近性来对CCI的数据进行数据估价的功能。最后,以改进的随机扰动治疗效果估算的形式实现Shapley公平奖励,并通过模拟和实物数据集实例验证了我们的奖励方案的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/qiao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/qiao23a/qiao23a.pdf)** 

# FREDIS: A Fusion Framework of Refinement and Disambiguation for Unreliable Partial Label Learning
**题目:** FREDIS:不可靠部分标签学习的精确化与误解的融合框架

**作者:** Congyu Qiao, Ning Xu, Jiaqi Lv, Yi Ren, Xin Geng

**Abstract:** To reduce the difficulty of annotation, partial label learning (PLL) has been widely studied, where each example is ambiguously annotated with a set of candidate labels instead of the exact correct label. PLL assumes that the candidate label set contains the correct label, which induces disambiguation, i.e., identification of the correct label in the candidate label set, adopted in most PLL methods. However, this assumption is impractical as no one could guarantee the existence of the correct label in the candidate label set under real-world scenarios. Therefore, Unreliable Partial Label Learning (UPLL) is investigated where the correct label of each example may not exist in the candidate label set. In this paper, we propose a fusion framework of refinement and disambiguation named FREDIS to handle the UPLL problem. Specifically, with theoretical guarantees, not only does disambiguation move incorrect labels from candidate labels to non-candidate labels but also refinement, an opposite procedure, moves correct labels from non-candidate labels to candidate labels. Besides, we prove that the classifier trained by our framework could eventually approximate the Bayes optimal classifier. Extensive experiments on widely used benchmark datasets validate the effectiveness of our proposed framework.

**摘要:** 为了减少注释的难度,部分标签学习(PLL)已被广泛研究,其中每个实例都用一组候选标签代替准确正确的标签注释不明确。PLL假设候选标签集合包含正确的标签,从而引起误解,即在大多数PLL方法中采用的候选标签集合中的正确标签的识别。然而,这一假设是不实用的,因为没有人能够保证在现实场景下候选标签集合中的正确标签的存在。因此,不可靠部分标签学习(UPLL)被研究在候选标签集合中每个实例的正确标签可能不存在的地方。具体而言,在理论保证下,不明确的标记不仅将错误的标记从候选标记转移到非候选标记,而且精确的标记从非候选标记转移到候选标记。此外,我们证明了由我们的框架训练的分类器最终可以接近贝伊斯最佳分类器。

**[Paper URL](https://proceedings.mlr.press/v202/qiao23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/qiao23b/qiao23b.pdf)** 

# Nugget: Neural Agglomerative Embeddings of Text
**题目:** Nugget:文本神经集聚嵌入

**作者:** Guanghui Qin, Benjamin Van Durme

**Abstract:** Embedding text sequences is a widespread requirement in modern language understanding. Existing approaches focus largely on constant-size representations. This is problematic, as the amount of information contained in text often varies with the length of the input. We propose a solution called Nugget, which encodes language into a representation based on a dynamically selected subset of input tokens. These nuggets are learned through tasks like autoencoding and machine translation, and intuitively segment language into meaningful units. We demonstrate Nugget outperforms related approaches in tasks involving semantic comparison. Finally, we illustrate these compact units allow for expanding the contextual window of a language model (LM), suggesting new future LMs that can condition on significantly larger amounts of content.

**摘要:** 嵌入文本序列在现代语言理解中是一个普遍的需要。现有的方法主要集中于定量大小的表示。这是问题,因为文本中包含的信息量往往随输入的长度而变化。我们提出了一种叫做Nugget的解决方案,它将语言编码成基于动态选择的输入符号子集的表示。这些nugget通过诸如自动编码和机器翻译等任务学习,并直观地将语言分割成有意义的单元。

**[Paper URL](https://proceedings.mlr.press/v202/qin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/qin23a/qin23a.pdf)** 

# BiBench: Benchmarking and Analyzing Network Binarization
**题目:** BiBench: Benchmarking和分析网络二元化

**作者:** Haotong Qin, Mingyuan Zhang, Yifu Ding, Aoyu Li, Zhongang Cai, Ziwei Liu, Fisher Yu, Xianglong Liu

**Abstract:** Network binarization emerges as one of the most promising compression approaches offering extraordinary computation and memory savings by minimizing the bit-width. However, recent research has shown that applying existing binarization algorithms to diverse tasks, architectures, and hardware in realistic scenarios is still not straightforward. Common challenges of binarization, such as accuracy degradation and efficiency limitation, suggest that its attributes are not fully understood. To close this gap, we present BiBench, a rigorously designed benchmark with in-depth analysis for network binarization. We first carefully scrutinize the requirements of binarization in the actual production and define evaluation tracks and metrics for a comprehensive and fair investigation. Then, we evaluate and analyze a series of milestone binarization algorithms that function at the operator level and with extensive influence. Our benchmark reveals that 1) the binarized operator has a crucial impact on the performance and deployability of binarized networks; 2) the accuracy of binarization varies significantly across different learning tasks and neural architectures; 3) binarization has demonstrated promising efficiency potential on edge devices despite the limited hardware support. The results and analysis also lead to a promising paradigm for accurate and efficient binarization. We believe that BiBench will contribute to the broader adoption of binarization and serve as a foundation for future research. The code for our BiBench is released https://github.com/htqin/BiBench .

**摘要:** 网络二元化作为最有前途的压缩方法之一,通过最小化位宽提供非凡的计算和存储储蓄。然而,最近的研究表明,在现实场景中应用现有的二元化算法对各种任务、架构和硬件仍不简单。我们的基准显示: 1) 双向操作者对双向网络的性能和部署能力具有关键性影响; 2) 双向的准确性在不同学习任务和神经架构中具有显著的差异; 3) 双向化在边缘设备上 trotz the limited hardware support has demonstrated promising efficiency potential. The results and analysis also lead to a promising paradigm for accurate and efficient binarization. We believe that BiBench will contribute to the broader adoption of binarization and serve as a foundation for future research. Our BiBench code is released https://github.com/htqin/BiBench.

**[Paper URL](https://proceedings.mlr.press/v202/qin23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/qin23b/qin23b.pdf)** 

# Not All Semantics are Created Equal: Contrastive Self-supervised Learning with Automatic Temperature Individualization
**题目:** 并非所有语义都是平等的:自动温度个人化的反向自我监督学习

**作者:** Zi-Hao Qiu, Quanqi Hu, Zhuoning Yuan, Denny Zhou, Lijun Zhang, Tianbao Yang

**Abstract:** In this paper, we aim to optimize a contrastive loss with individualized temperatures in a principled manner. The common practice of using a global temperature parameter $\tau$ ignores the fact that “not all semantics are created equal", meaning that different anchor data may have different numbers of samples with similar semantics, especially when data exhibits long-tails. First, we propose a new robust contrastive loss inspired by distributionally robust optimization (DRO), providing us an intuition about the effect of $\tau$ and a mechanism for automatic temperature individualization. Then, we propose an efficient stochastic algorithm for optimizing the robust contrastive loss with a provable convergence guarantee without using large mini-batch sizes. Theoretical and experimental results show that our algorithm automatically learns a suitable $\tau$ for each sample. Specifically, samples with frequent semantics use large temperatures to keep local semantic structures, while samples with rare semantics use small temperatures to induce more separable features. Our method not only outperforms prior strong baselines (e.g., SimCLR, CLIP) on unimodal and bimodal tasks with larger improvements on imbalanced data but also is less sensitive to hyper-parameters. To our best knowledge, this is the first methodical approach to optimizing a contrastive loss with individualized temperatures. Our proposed algorithms are implemented in the LibAUC library at https://libauc.org.

**摘要:** 在本文中,我们的目标是以一种原则性的方式优化与个体化温度的对比损失。使用全球温度参数$\tau$的常见做法忽略了“并非所有语义都是平等的”,这意味着不同的锚定数据可能具有不同数量的相似语义样本,特别是当数据显示长尾时。首先,我们提出了一种由分布性鲁棒优化(DRO)启发的新鲁棒对比损失,提供对$\tau$的影响的直觉和自动温度个体化机制。然后,我们提出了一种有效的随机算法,以使用大型小批量大小的证明性收敛保证来优化鲁棒对比损失。理论和实验结果表明,我们的算法自动学习每个样本的合适的$\tau$。具体而言,有频繁语义的样本使用大温度来保持局部语义结构,而有罕见语义的样本使用小温度来诱导更可分离的特征。我们的方法不仅在单元和双元任务上超过了先前的强基线(例如SimCLR、CLIP),在不平衡数据上也有较大的改进,而且对超参数更敏感。

**[Paper URL](https://proceedings.mlr.press/v202/qiu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/qiu23a/qiu23a.pdf)** 

# Shortest Edit Path Crossover: A Theory-driven Solution to the Permutation Problem in Evolutionary Neural Architecture Search
**题目:** 最短的编辑路径交叉:进化神经结构搜索中的变换问题理论驱动的解决方案

**作者:** Xin Qiu, Risto Miikkulainen

**Abstract:** Population-based search has recently emerged as a possible alternative to Reinforcement Learning (RL) for black-box neural architecture search (NAS). It performs well in practice even though it is not theoretically well understood. In particular, whereas traditional population-based search methods such as evolutionary algorithms (EAs) draw much power from crossover operations, it is difficult to take advantage of them in NAS. The main obstacle is believed to be the permutation problem: The mapping between genotype and phenotype in traditional graph representations is many-to-one, leading to a disruptive effect of standard crossover. This paper presents the first theoretical analysis of the behaviors of mutation, crossover and RL in black-box NAS, and proposes a new crossover operator based on the shortest edit path (SEP) in graph space. The SEP crossover is shown theoretically to overcome the permutation problem, and as a result, have a better expected improvement compared to mutation, standard crossover and RL. Further, it empirically outperform these other methods on state-of-the-art NAS benchmarks. The SEP crossover therefore allows taking full advantage of population-based search in NAS, and the underlying theory can serve as a foundation for deeper understanding of black-box NAS methods in general.

**摘要:** 基于人口的搜索最近成为黑盒神经结构搜索(NAS)的增强学习(RL)的可能替代品,虽然理论上并不十分理解,但在实践中表现得很好。特别是,虽然传统的基于人口的搜索方法如进化算法(EAs)从交叉操作中获取了很大力量,但很难利用它们在NAS中。主要障碍据信是变换问题:传统的图形表示中基因型和现象型之间的映射是多对一,导致标准交叉的破坏性效应。SEP交叉是理论上证明克服变换问题,因此,与变异、标准交叉和RL相比,具有较好的预期改善。 此外,它在最先进的NAS基准上具有经验上的优越性。因此, SEP交叉允许在NAS中充分利用基于人口的搜索,并且基础理论可以作为更深入理解黑盒 NAS方法的基础。

**[Paper URL](https://proceedings.mlr.press/v202/qiu23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/qiu23b/qiu23b.pdf)** 

# Simple and Fast Group Robustness by Automatic Feature Reweighting
**题目:** 通过自动功能重权实现简单快速的组件鲁棒性

**作者:** Shikai Qiu, Andres Potapczynski, Pavel Izmailov, Andrew Gordon Wilson

**Abstract:** A major challenge to out-of-distribution generalization is reliance on spurious features — patterns that are predictive of the class label in the training data distribution, but not causally related to the target. Standard methods for reducing the reliance on spurious features typically assume that we know what the spurious feature is, which is rarely true in the real world. Methods that attempt to alleviate this limitation are complex, hard to tune, and lead to a significant computational overhead compared to standard training. In this paper, we propose Automatic Feature Reweighting (AFR), an extremely simple and fast method for updating the model to reduce the reliance on spurious features. AFR retrains the last layer of a standard ERM-trained base model with a weighted loss that emphasizes the examples where the ERM model predicts poorly, automatically upweighting the minority group without group labels. With this simple procedure, we improve upon the best reported results among competing methods trained without spurious attributes on several vision and natural language classification benchmarks, using only a fraction of their compute.

**摘要:** 在非分布推广中,一个主要的挑战是依赖虚构特征 — — 在训练数据分布中预测类别标签的模式,但与目标无因关系。 减少依赖虚构特征的标准方法通常假设我们知道虚构特征是什么,这在现实世界中很少发生。通过这个简单的程序,我们改进了在几个视觉和自然语言分类指标上没有伪造属性的训练的竞争方法中最好的报告结果,只使用它们的计算的一部分。

**[Paper URL](https://proceedings.mlr.press/v202/qiu23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/qiu23c/qiu23c.pdf)** 

# DRCFS: Doubly Robust Causal Feature Selection
**题目:** DRCFS:双重鲁棒的因果特征选择

**作者:** Francesco Quinzan, Ashkan Soleymani, Patrick Jaillet, Cristian R. Rojas, Stefan Bauer

**Abstract:** Knowing the features of a complex system that are highly relevant to a particular target variable is of fundamental interest in many areas of science. Existing approaches are often limited to linear settings, sometimes lack guarantees, and in most cases, do not scale to the problem at hand, in particular to images. We propose DRCFS, a doubly robust feature selection method for identifying the causal features even in nonlinear and high dimensional settings. We provide theoretical guarantees, illustrate necessary conditions for our assumptions, and perform extensive experiments across a wide range of simulated and semi-synthetic datasets. DRCFS significantly outperforms existing state-of-the-art methods, selecting robust features even in challenging highly non-linear and high-dimensional problems.

**摘要:** 在许多科学领域,了解对特定目标变量具有高度关联的复杂系统特征是至关重要的。现有的方法往往局限于线性设置,有时缺乏保证,并且在大多数情况下,不适应当前问题,特别是图像。我们提出了DRCFS,一种双重鲁棒特征选择方法,用于识别非线性和高维设置中的原因特征。我们提供理论保证,说明我们假设所需的条件,并在广泛的模拟和半合成数据集中进行广泛的实验。DRCFS大大超过了现有的最先进的方法,甚至在挑战高非线性和高维问题时,也能选择鲁棒特征。

**[Paper URL](https://proceedings.mlr.press/v202/quinzan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/quinzan23a/quinzan23a.pdf)** 

# Robust Speech Recognition via Large-Scale Weak Supervision
**题目:** 通过大规模弱监管的鲁棒语音识别

**作者:** Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine Mcleavey, Ilya Sutskever

**Abstract:** We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results without the need for any dataset specific fine-tuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.

**摘要:** 我们研究了经过训练的语音处理系统的能力,以预测在互联网上大量音频的转录。在扩展到680,000小时的多语言和多任务监督时,结果的模型可以很好地推广到标准的基准,并且经常与以前完全监督的结果竞争,不需要任何数据集的特定微调。在与人类相比,这些模型接近其准确性和鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/radford23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/radford23a/radford23a.pdf)** 

# Shiftable Context: Addressing Training-Inference Context Mismatch in Simultaneous Speech Translation
**题目:** 可移动语境:在同步语音翻译中解决培训-会议语境不匹配问题

**作者:** Matthew Raffel, Drew Penney, Lizhong Chen

**Abstract:** Transformer models using segment-based processing have been an effective architecture for simultaneous speech translation. However, such models create a context mismatch between training and inference environments, hindering potential translation accuracy. We solve this issue by proposing Shiftable Context, a simple yet effective scheme to ensure that consistent segment and context sizes are maintained throughout training and inference, even with the presence of partially filled segments due to the streaming nature of simultaneous translation. Shiftable Context is also broadly applicable to segment-based transformers for streaming tasks. Our experiments on the English-German, English-French, and English-Spanish language pairs from the MUST-C dataset demonstrate that when applied to the Augmented Memory Transformer, a state-of-the-art model for simultaneous speech translation, the proposed scheme achieves an average increase of 2.09, 1.83, and 1.95 BLEU scores across each wait-k value for the three language pairs, respectively, with a minimal impact on computation-aware Average Lagging.

**摘要:** 基于分段处理的变换器模型是同时语音翻译的有效架构,然而,这些模型在训练和推导环境之间造成上下文不匹配,从而阻碍了潜在的翻译精度。我们通过提议Shiftable Context来解决这个问题,这是一个简单而有效的方案,以确保在训练和推导中保持一致的分段和上下文大小,即使由于同时翻译的流向性质存在部分填充的分段。Shiftable Context也广泛适用于基于分段的变换器进行流向任务。我们对MUST-C数据集中的英语-德语、英语-法语和英语-西班牙语语言对的实验表明,当应用于增强记忆变换器(英语:Augmented Memory Transformer),一种最先进的语音翻译模型,提议方案在三个语言对的每个等待k值中平均增加2.09、1.83和1.95的BLEU分数,对计算意识平均滞后产生最小的影响。

**[Paper URL](https://proceedings.mlr.press/v202/raffel23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/raffel23a/raffel23a.pdf)** 

# Sequential Multi-Dimensional Self-Supervised Learning for Clinical Time Series
**题目:** 临床时间系列连续多维自我监控学习

**作者:** Aniruddh Raghu, Payal Chandak, Ridwan Alam, John Guttag, Collin Stultz

**Abstract:** Self-supervised learning (SSL) for clinical time series data has received significant attention in recent literature, since these data are highly rich and provide important information about a patient’s physiological state. However, most existing SSL methods for clinical time series are limited in that they are designed for unimodal time series, such as a sequence of structured features (e.g., lab values and vitals signs) or an individual high-dimensional physiological signal (e.g., an electrocardiogram). These existing methods cannot be readily extended to model time series that exhibit multimodality, with structured features and high-dimensional data being recorded at each timestep in the sequence. In this work, we address this gap and propose a new SSL method — Sequential Multi-Dimensional SSL — where a SSL loss is applied both at the level of the entire sequence and at the level of the individual high-dimensional data points in the sequence in order to better capture information at both scales. Our strategy is agnostic to the specific form of loss function used at each level – it can be contrastive, as in SimCLR, or non-contrastive, as in VICReg. We evaluate our method on two real-world clinical datasets, where the time series contains sequences of (1) high-frequency electrocardiograms and (2) structured data from lab values and vitals signs. Our experimental results indicate that pre-training with our method and then fine-tuning on downstream tasks improves performance over baselines on both datasets, and in several settings, can lead to improvements across different self-supervised loss functions.

**摘要:** 临床时间序列数据的自监督学习(英语:Self-supervised learning,缩写为SSL)在最近的文献中得到了大量关注,因为这些数据非常丰富,并提供有关病人生理状态的重要信息。然而,大多数现有的临床时间序列的SSL方法是有限的,因为它们是为单元时间序列设计的,例如结构特征的序列(例如实验室值和生命信号)或单独的高维生理信号(例如电心图)。在这项工作中,我们解决了这一差距并提出了一种新的SSL方法 — Sequential Multi-Dimensional SSL — 即在整个序列的水平和序列中的各个高维数据点的水平上应用SSL损失,以便在两个尺度上更好地捕捉信息。我们的策略对每个级别使用的损失函数的特定形式是 agnostic — 它可以像SimCLR(英语:SimCLR)那样具有对比性,也可以像VICReg(英语:VICReg)那样具有非对比性。

**[Paper URL](https://proceedings.mlr.press/v202/raghu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/raghu23a/raghu23a.pdf)** 

# Recovery Bounds on Class-Based Optimal Transport: A Sum-of-Norms Regularization Framework
**题目:** 基于类别的优化运输的回收界限:规范化框架的总数

**作者:** Arman Rahbar, Ashkan Panahi, Morteza Haghir Chehreghani, Devdatt Dubhashi, Hamid Krim

**Abstract:** We develop a novel theoretical framework for understating Optimal Transport (OT) schemes respecting a class structure. For this purpose, we propose a convex OT program with a sum-of-norms regularization term, which provably recovers the underlying class structure under geometric assumptions. Furthermore, we derive an accelerated proximal algorithm with a closed-form projection and proximal operator scheme, thereby affording a more scalable algorithm for computing optimal transport plans. We provide a novel argument for the uniqueness of the optimum even in the absence of strong convexity. Our experiments show that the new regularizer not only results in a better preservation of the class structure in the data but also yields additional robustness to the data geometry, compared to previous regularizers.

**摘要:** 针对类结构的优化运输(OT)方案,我们开发了一种新的理论框架。为此目的,我们提出了一种具有量化定理定理术语的凸OT方案,可证明在几何假设下恢复基本类结构。此外,我们从闭式投影和近接操作方案中提取了一种加速近接算法,从而为计算最佳运输计划提供了一个更可扩展的算法。

**[Paper URL](https://proceedings.mlr.press/v202/rahbar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rahbar23a/rahbar23a.pdf)** 

# Algorithmic Stability of Heavy-Tailed SGD with General Loss Functions
**题目:** 一般损失函数的重重型GD算法稳定性

**作者:** Anant Raj, Lingjiong Zhu, Mert Gurbuzbalaban, Umut Simsekli

**Abstract:** Heavy-tail phenomena in stochastic gradient descent (SGD) have been reported in several empirical studies. Experimental evidence in previous works suggests a strong interplay between the heaviness of the tails and generalization behavior of SGD. To address this empirical phenomena theoretically, several works have made strong topological and statistical assumptions to link the generalization error to heavy tails. Very recently, new generalization bounds have been proven, indicating a non-monotonic relationship between the generalization error and heavy tails, which is more pertinent to the reported empirical observations. While these bounds do not require additional topological assumptions given that SGD can be modeled using a heavy-tailed stochastic differential equation (SDE), they can only apply to simple quadratic problems. In this paper, we build on this line of research and develop generalization bounds for a more general class of objective functions, which includes non-convex functions as well. Our approach is based on developing Wasserstein stability bounds for heavy-tailed SDEs and their discretizations, which we then convert to generalization bounds. Our results do not require any nontrivial assumptions; yet, they shed more light to the empirical observations, thanks to the generality of the loss functions.

**摘要:** 随机梯度下降(SGD)中的重尾现象已在若干实证研究中报道。先前的研究中的实验证据表明,尾巴的重度与SGD的一般化行为之间有很强的相互作用。为了理论上解决这一实证现象,一些研究已经做了强有力的拓扑和统计假设,将一般化误差与重尾巴联系起来。最近,新的一般化边界已经被证明,表明一般化误差与重尾巴之间的非单元关系更符合报告的实证观察。在此基础上,我们开发了一种更通用的客观函数类别的一般化边界,包括非凸函数。我们的方法是基于对重尾型SDEs的沃斯泰因稳定性边界和它们的离散化,然后将其转换为一般化边界。我们的结果不需要任何非平凡的假设,但由于损失函数的普遍性,它们给经验观察提供了更多的启示。

**[Paper URL](https://proceedings.mlr.press/v202/raj23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/raj23a/raj23a.pdf)** 

# Mastering the Unsupervised Reinforcement Learning Benchmark from Pixels
**题目:** 从像素上掌握无监督强化学习的基准

**作者:** Sai Rajeswar, Pietro Mazzaglia, Tim Verbelen, Alexandre Piché, Bart Dhoedt, Aaron Courville, Alexandre Lacoste

**Abstract:** Controlling artificial agents from visual sensory data is an arduous task. Reinforcement learning (RL) algorithms can succeed but require large amounts of interactions between the agent and the environment. To alleviate the issue, unsupervised RL proposes to employ self-supervised interaction and learning, for adapting faster to future tasks. Yet, as shown in the Unsupervised RL Benchmark (URLB; Laskin et al. 2021), whether current unsupervised strategies can improve generalization capabilities is still unclear, especially in visual control settings. In this work, we study the URLB and propose a new method to solve it, using unsupervised model-based RL, for pre-training the agent, and a task-aware fine-tuning strategy combined with a new proposed hybrid planner, Dyna-MPC, to adapt the agent for downstream tasks. On URLB, our method obtains 93.59% overall normalized performance, surpassing previous baselines by a staggering margin. The approach is empirically evaluated through a large-scale empirical study, which we use to validate our design choices and analyze our models. We also show robust performance on the Real-Word RL benchmark, hinting at resiliency to environment perturbations during adaptation. Project website: https://masteringurlb.github.io/

**摘要:** 控制视觉感官数据的人工代理是一项艰巨的任务。强化学习(RL)算法可以成功,但需要大量的代理与环境之间的交互。为了缓解问题,无监督RL建议采用自我监督的交互和学习,以便适应未来任务。然而,如无监督RL Benchmark(URLB;Laskin et al. 2021)所示,目前无监督策略是否能提高一般化能力仍然不清楚,特别是在视觉控制设置中。该方法通过大规模的实证研究进行实证评价,以验证我们的设计选择和分析我们的模型。我们还显示了真实WordRL基准的鲁棒性能,暗示在适应过程中对环境扰动的恢复性。

**[Paper URL](https://proceedings.mlr.press/v202/rajeswar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rajeswar23a/rajeswar23a.pdf)** 

# SpotEM: Efficient Video Search for Episodic Memory
**题目:** SpotEM: efektive video search for episodic memory

**作者:** Santhosh Kumar Ramakrishnan, Ziad Al-Halah, Kristen Grauman

**Abstract:** The goal in episodic memory (EM) is to search a long egocentric video to answer a natural language query (e.g., “where did I leave my purse?”). Existing EM methods exhaustively extract expensive fixed-length clip features to look everywhere in the video for the answer, which is infeasible for long wearable-camera videos that span hours or even days. We propose SpotEM, an approach to achieve efficiency for a given EM method while maintaining good accuracy. SpotEM consists of three key ideas: 1) a novel clip selector that learns to identify promising video regions to search conditioned on the language query; 2) a set of low-cost semantic indexing features that capture the context of rooms, objects, and interactions that suggest where to look; and 3) distillation losses that address the optimization issues arising from end-to-end joint training of the clip selector and EM model. Our experiments on 200+ hours of video from the Ego4D EM Natural Language Queries benchmark and three different EM models demonstrate the effectiveness of our approach: computing only 10% – 25% of the clip features, we preserve 84% – 97% of the original EM model’s accuracy. Project page: https://vision.cs.utexas.edu/projects/spotem

**摘要:** 在 episodic memory(EM)中的目标是搜索一个长期自我中心的视频来回答自然语言查询(例如,“我在哪里丢了钱包?”)。现有的EM方法完全提取了昂贵的固定长度剪辑特征,以便在视频中寻找答案,这对于长带摄像机视频来说是不可能的,它可以长达几个小时甚至几天。我们提出了 SpotEM,一种实现给定的EM方法的效率的方法,同时保持良好的准确性。 SpotEM由三个关键思想组成: 1)一种新颖的剪辑选择器,它学习识别基于语言查询的搜索有希望的视频区域; 2)一套低成本语义索引特征,它捕捉了房间、对象和相互作用的上下文,表明应该在哪里寻找; 3)蒸馏损失,解决了剪辑选择器和EM模型的end-to-end联合训练产生的优化问题。我们对Ego4D EM自然语言查询基准和三个不同的EM模型的200多小时视频实验证明了我们的方法的有效性:仅计算10%-25%的剪辑特征,我们保留了原有的EM模型的84%-97%的准确性。

**[Paper URL](https://proceedings.mlr.press/v202/ramakrishnan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ramakrishnan23a/ramakrishnan23a.pdf)** 

# How much does Initialization Affect Generalization?
**题目:** 初始化对一般化有何影响?

**作者:** Sameera Ramasinghe, Lachlan Ewen Macdonald, Moshiur Farazi, Hemanth Saratchandran, Simon Lucey

**Abstract:** Characterizing the remarkable generalization properties of over-parameterized neural networks remains an open problem. A growing body of recent literature shows that the bias of stochastic gradient descent (SGD) and architecture choice implicitly leads to better generalization. In this paper, we show on the contrary that, independently of architecture, SGD can itself be the cause of poor generalization if one does not ensure good initialization. Specifically, we prove that any differentiably parameterized model, trained under gradient flow, obeys a weak spectral bias law which states that sufficiently high frequencies train arbitrarily slowly. This implies that very high frequencies present at initialization will remain after training, and hamper generalization. Further, we empirically test the developed theoretical insights using practical, deep networks. Finally, we contrast our framework with that supplied by the flat-minima conjecture and show that Fourier analysis grants a more reliable framework for understanding the generalization of neural networks.

**摘要:** 超参数化神经网络显著的一般化特性的特征仍然是一个开放问题。最近的文献显示,随机梯度降落(SGD)和建筑选择的偏差隐含地导致了更好的一般化。在本论文中,我们相反地表明,独立于建筑,SGD本身可以成为不良的一般化原因,如果不能保证良好的初始化。具体地说,我们证明任何有差异性的参数化模型,在梯度流下训练,遵循一个弱的光谱偏差法,该法表示足够高的频率训练随机缓慢。最后,我们对比了我们的框架与平面微分假设的框架,并证明了傅立叶分析为理解神经网络的一般化提供了更可靠的框架。

**[Paper URL](https://proceedings.mlr.press/v202/ramasinghe23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ramasinghe23a/ramasinghe23a.pdf)** 

# Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization
**题目:** 模型拉塔图尔:循环再造的非散发通用模型

**作者:** Alexandre Rame, Kartik Ahuja, Jianyu Zhang, Matthieu Cord, Leon Bottou, David Lopez-Paz

**Abstract:** Foundation models are redefining how AI systems are built. Practitioners now follow a standard procedure to build their machine learning solutions: from a pre-trained foundation model, they fine-tune the weights on the target task of interest. So, the Internet is swarmed by a handful of foundation models fine-tuned on many diverse tasks: these individual fine-tunings exist in isolation without benefiting from each other. In our opinion, this is a missed opportunity, as these specialized models contain rich and diverse features. In this paper, we thus propose model ratatouille, a new strategy to recycle the multiple fine-tunings of the same foundation model on diverse auxiliary tasks. Specifically, we repurpose these auxiliary weights as initializations for multiple parallel fine-tunings on the target task; then, we average all fine-tuned weights to obtain the final model. This recycling strategy aims at maximizing the diversity in weights by leveraging the diversity in auxiliary tasks. Empirically, it improves the state of the art on the reference DomainBed benchmark for out-of-distribution generalization. Looking forward, this work contributes to the emerging paradigm of updatable machine learning where, akin to open-source software development, the community collaborates to reliably update machine learning models.

**摘要:** 基础模型正在重新定义人工知能系统如何构建。实践者现在遵循一个标准程序来构建他们的机器学习解决方案:从预训练的基础模型中,他们对感兴趣的目标任务的重量进行微调。因此,互联网被许多不同任务的微调基础模型束缚了:这些个体微调存在孤立,互不受益。我们认为,这是一次错过的机会,因为这些专门的模型包含丰富多样的特征。该回收策略旨在通过利用辅助任务的多样性来最大化重量的多样性,从而提高外发通用化参考 DomainBed 基准的技术现状。展望未来,这项工作有助于更新机器学习的模式,类似于开放源代码开发,社区合作可靠地更新机器学习模型。

**[Paper URL](https://proceedings.mlr.press/v202/rame23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rame23a/rame23a.pdf)** 

# A Picture of the Space of Typical Learnable Tasks
**题目:** 典型的可学习任务空间的图片

**作者:** Rahul Ramesh, Jialin Mao, Itay Griniasty, Rubing Yang, Han Kheng Teoh, Mark Transtrum, James Sethna, Pratik Chaudhari

**Abstract:** We develop information geometric techniques to understand the representations learned by deep networks when they are trained on different tasks using supervised, meta-, semi-supervised and contrastive learning. We shed light on the following phenomena that relate to the structure of the space of tasks: (1) the manifold of probabilistic models trained on different tasks using different representation learning methods is effectively low-dimensional; (2) supervised learning on one task results in a surprising amount of progress even on seemingly dissimilar tasks; progress on other tasks is larger if the training task has diverse classes; (3) the structure of the space of tasks indicated by our analysis is consistent with parts of the Wordnet phylogenetic tree; (4) episodic meta-learning algorithms and supervised learning traverse different trajectories during training but they fit similar models eventually; (5) contrastive and semi-supervised learning methods traverse trajectories similar to those of supervised learning. We use classification tasks constructed from the CIFAR-10 and Imagenet datasets to study these phenomena. Code is available at https://github.com/grasp-lyrl/picture_of_space_of_tasks.

**摘要:** 我们开发了信息几何技术,以了解深层网络在使用监督、元监督、半监督和对比学习进行不同任务时所学习的表示。我们研究了与任务空间结构有关的下列现象: (1)使用不同的表示学习方法对不同任务进行训练的概率学模型的多变量实际上是低维的; (2)对一个任务进行监督学习,即使在看似不同的任务中,也取得了惊人的进步; 如果训练任务有不同的类别,则其他任务的进步更大; (3)分析表明的任务空间结构与Wordnet树的某些部分一致; (4)在训练过程中的 episodic meta-learning算法和监督学习跨越不同的路径,但最终符合相似的模型; (5)对比和半监督学习方法跨越与监督学习相似的路径; 我们利用CIFAR-10和Imagenet数据集的分类任务来研究这些现象。代码可以在 https://github.com/grasp-lyrl/picture_of_space_of_tasks 上找到。

**[Paper URL](https://proceedings.mlr.press/v202/ramesh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ramesh23a/ramesh23a.pdf)** 

# Policy Regularization with Dataset Constraint for Offline Reinforcement Learning
**题目:** 基于数据集约束的策略规范化 offline强化学习

**作者:** Yuhang Ran, Yi-Chen Li, Fuxiang Zhang, Zongzhang Zhang, Yang Yu

**Abstract:** We consider the problem of learning the best possible policy from a fixed dataset, known as offline Reinforcement Learning (RL). A common taxonomy of existing offline RL works is policy regularization, which typically constrains the learned policy by distribution or support of the behavior policy. However, distribution and support constraints are overly conservative since they both force the policy to choose similar actions as the behavior policy when considering particular states. It will limit the learned policy’s performance, especially when the behavior policy is sub-optimal. In this paper, we find that regularizing the policy towards the nearest state-action pair can be more effective and thus propose Policy Regularization with Dataset Constraint (PRDC). When updating the policy in a given state, PRDC searches the entire dataset for the nearest state-action sample and then restricts the policy with the action of this sample. Unlike previous works, PRDC can guide the policy with proper behaviors from the dataset, allowing it to choose actions that do not appear in the dataset along with the given state. It is a softer constraint but still keeps enough conservatism from out-of-distribution actions. Empirical evidence and theoretical analysis show that PRDC can alleviate offline RL’s fundamentally challenging value overestimation issue with a bounded performance gap. Moreover, on a set of locomotion and navigation tasks, PRDC achieves state-of-the-art performance compared with existing methods. Code is available at https://github.com/LAMDA-RL/PRDC

**摘要:** 我们考虑从一个固定数据集学习最优的政策问题,称为“非线性强化学习”( offline Reinforcement Learning, RL ) 。 现有的非线性RL的常见分类法是政策规范化,通常通过分布或支持行为政策来约束学习的政策。然而,分布和支持约束过于保守,因为它们都迫使政策在考虑特定状态时选择类似行为政策的行动。与以前的工作不同,PRDC可以指导政策,从数据集中进行适当的行为,允许它选择在数据集中与指定状态不出现的行动。这是一个较软的约束,但仍保持了来自分发活动的足够保守性。

**[Paper URL](https://proceedings.mlr.press/v202/ran23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ran23a/ran23a.pdf)** 

# SpENCNN: Orchestrating Encoding and Sparsity for Fast Homomorphically Encrypted Neural Network Inference
**题目:** SpENCNN:快速同态加密神经网络ference的组织编码和节率

**作者:** Ran Ran, Xinwei Luo, Wei Wang, Tao Liu, Gang Quan, Xiaolin Xu, Caiwen Ding, Wujie Wen

**Abstract:** Homomorphic Encryption (HE) is a promising technology to protect clients’ data privacy for Machine Learning as a Service (MLaaS) on public clouds. However, HE operations can be orders of magnitude slower than their counterparts for plaintexts and thus result in prohibitively high inference latency, seriously hindering the practicality of HE. In this paper, we propose a HE-based fast neural network (NN) inference framework–SpENCNN built upon the co-design of HE operation-aware model sparsity and the single-instruction-multiple-data (SIMD)-friendly data packing, to improve NN inference latency. In particular, we first develop an encryption-aware HE-group convolution technique that can partition channels among different groups based on the data size and ciphertext size, and then encode them into the same ciphertext by novel group-interleaved encoding, so as to dramatically reduce the number of bottlenecked operations in HE convolution. We further tailor a HE-friendly sub-block weight pruning to reduce the costly HE-based convolution operation. Our experiments show that SpENCNN can achieve overall speedups of 8.37$\times$, 12.11$\times$, 19.26$\times$, and 1.87$\times$ for LeNet, VGG-5, HEFNet, and ResNet-20 respectively, with negligible accuracy loss. Our code is publicly available at https://github.com/ranran0523/SPECNN.

**摘要:** 同型加密(英语:Homomorphic Encryption,缩写为HE)是为公共云中的机器学习服务(MLaaS)提供客户数据私隐保护的有望技术。然而,HE操作的规模比平文操作的对手慢很多,从而导致极高的推导延迟,严重阻碍了HE的实用性。本文提出了基于HE的快速神经网络(NN)推导框架——SpENCNN,基于HE操作-知性模型稀疏和单指令-多数据(SIMD)友好数据包的共同设计,以改善NN推导延迟。我们进一步定制 HE友好的分块重量削减,以减少昂贵的 HE-based convolution操作。我们的实验表明,SpenCNN可以实现8.37$\times$、12.11$\times$、19.26$\times$和1.87$\times$的总速度提升,分别为LeNet、VGG-5、HEFNet和ResNet-20,与忽略不计的精度损失。

**[Paper URL](https://proceedings.mlr.press/v202/ran23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ran23b/ran23b.pdf)** 

# Feature learning in deep classifiers through Intermediate Neural Collapse
**题目:** 通过中性神经衰竭对深层分类器的特征学习

**作者:** Akshay Rangamani, Marius Lindegaard, Tomer Galanti, Tomaso A Poggio

**Abstract:** In this paper, we conduct an empirical study of the feature learning process in deep classifiers. Recent research has identified a training phenomenon called Neural Collapse (NC), in which the top-layer feature embeddings of samples from the same class tend to concentrate around their means, and the top layer’s weights align with those features. Our study aims to investigate if these properties extend to intermediate layers. We empirically study the evolution of the covariance and mean of representations across different layers and show that as we move deeper into a trained neural network, the within-class covariance decreases relative to the between-class covariance. Additionally, we find that in the top layers, where the between-class covariance is dominant, the subspace spanned by the class means aligns with the subspace spanned by the most significant singular vector components of the weight matrix in the corresponding layer. Finally, we discuss the relationship between NC and Associative Memories (Willshaw et. al. 1969).

**摘要:** 本文对深层分类器特征学习过程进行了实证研究。最近的研究发现一种叫做神经崩溃的训练现象,即来自同一类样品的顶层特征嵌入物趋于集中于其介质周围,顶层的重量与这些特征相一致。我们的研究旨在研究这些特性是否延伸到中间层。我们实证研究了不同层的共变和表示介质的演化,并表明随着我们深入进入训练的神经网络,内部类共变与中类共变相比减少。最后,我们讨论了NC与关联记忆的关系(Willshaw et. al. 1969)。

**[Paper URL](https://proceedings.mlr.press/v202/rangamani23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rangamani23a/rangamani23a.pdf)** 

# The Unintended Consequences of Discount Regularization: Improving Regularization in Certainty Equivalence Reinforcement Learning
**题目:** 折扣监管的意外后果:提高监管在确定均衡强化学习中的作用

**作者:** Sarah Rathnam, Sonali Parbhoo, Weiwei Pan, Susan Murphy, Finale Doshi-Velez

**Abstract:** Discount regularization, using a shorter planning horizon when calculating the optimal policy, is a popular choice to restrict planning to a less complex set of policies when estimating an MDP from sparse or noisy data (Jiang et al., 2015). It is commonly understood that discount regularization functions by de-emphasizing or ignoring delayed effects. In this paper, we reveal an alternate view of discount regularization that exposes unintended consequences. We demonstrate that planning under a lower discount factor produces an identical optimal policy to planning using any prior on the transition matrix that has the same distribution for all states and actions. In fact, it functions like a prior with stronger regularization on state-action pairs with more transition data. This leads to poor performance when the transition matrix is estimated from data sets with uneven amounts of data across state-action pairs. Our equivalence theorem leads to an explicit formula to set regularization parameters locally for individual state-action pairs rather than globally. We demonstrate the failures of discount regularization and how we remedy them using our state-action-specific method across simple empirical examples as well as a medical cancer simulator.

**摘要:** 在计算最佳政策时,使用较短的规划地平线进行折扣调节是限制规划到较少复杂的政策集,在估计稀疏或噪声数据的MDP时,最受欢迎的选择(江等人,2015年)。人们普遍认为折扣调节是通过减少强调或忽略延迟效应来实现的。在本文中,我们揭示了减少调节的另一种视角,它暴露了不意后果。我们证明,在较低的折扣因素下规划对所有状态和行动均有相同的分布的过渡矩阵上任何预先使用规划产生相同的最佳政策。我们的等价定理导致了一个明确的公式,以局部为个体状态-行动对定调节参数,而不是全球。我们通过简单的实证实例以及医学癌症模拟器,证明了降价调节的失败以及如何利用状态-行动特定方法来解决它们。

**[Paper URL](https://proceedings.mlr.press/v202/rathnam23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rathnam23a/rathnam23a.pdf)** 

# Beam Tree Recursive Cells
**题目:** 梁树递归细胞

**作者:** Jishnu Ray Chowdhury, Cornelia Caragea

**Abstract:** We propose Beam Tree Recursive Cell (BT-Cell) - a backpropagation-friendly framework to extend Recursive Neural Networks (RvNNs) with beam search for latent structure induction. We further extend this framework by proposing a relaxation of the hard top-$k$ operators in beam search for better propagation of gradient signals. We evaluate our proposed models in different out-of-distribution splits in both synthetic and realistic data. Our experiments show that BT-Cell achieves near-perfect performance on several challenging structure-sensitive synthetic tasks like ListOps and logical inference while maintaining comparable performance in realistic data against other RvNN-based models. Additionally, we identify a previously unknown failure case for neural models in generalization to unseen number of arguments in ListOps. The code is available at: https://github.com/JRC1995/BeamTreeRecursiveCells.

**摘要:** 我们提出了Beam Tree Recursive Cell(BT-Cell) - 一种带有潜在结构诱导的光标搜索的后继递延性框架,以扩展递延性神经网络(RvNNs)。我们进一步扩展了这个框架,提议在光标搜索中放松硬顶$k$操作员,以便更好地传播梯度信号。我们评估了在合成和现实数据中不同的离散分区中提出的模型。我们的实验表明BT-Cell在几个具有挑战性结构敏感的合成任务中达到 near-perfect性能,例如ListOps和逻辑推导,同时在其他RvNN-based模型中保持与现实数据相等的性能。此外,我们还确定了在一般化中对ListOps中未见参数的神经模型的未知失败案例。代码可于: https://github.com/JRC1995/BeamTreeRecurs

**[Paper URL](https://proceedings.mlr.press/v202/ray-chowdhury23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ray-chowdhury23a/ray-chowdhury23a.pdf)** 

# Monotonic Location Attention for Length Generalization
**题目:** 单元定位注意长度一般化

**作者:** Jishnu Ray Chowdhury, Cornelia Caragea

**Abstract:** We explore different ways to utilize position-based cross-attention in seq2seq networks to enable length generalization in algorithmic tasks. We show that a simple approach of interpolating the original and reversed encoded representations combined with relative attention allows near-perfect length generalization for both forward and reverse lookup tasks or copy tasks that had been generally hard to tackle. We also devise harder diagnostic tasks where the relative distance of the ideal attention position varies with timestep. In such settings, the simple interpolation trick with relative attention is not sufficient. We introduce novel variants of location attention building on top of Dubois et al. (2020) to address the new diagnostic tasks. We also show the benefits of our approaches for length generalization in SCAN (Lake & Baroni, 2018) and CFQ (Keysers et al.,2020). Our code is available on GitHub.

**摘要:** 我们研究了在seq2seq网络中利用基于位置的交叉注意的方式,使算法任务中的长度一般化。我们表明,与相对注意力相结合的原始和反向编码表示的简单方法可以实现接近完美的长度一般化,以便处理一般难以处理的向前和反向查找任务或复制任务。我们还设计了较硬的诊断任务,其中理想的注意力位置的相对距离随时间步骤而变化。在这样的设置中,与相对注意力的简单插值技巧并不足够。

**[Paper URL](https://proceedings.mlr.press/v202/ray-chowdhury23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ray-chowdhury23b/ray-chowdhury23b.pdf)** 

# Automated Search for Conjectures on Mathematical Constants using Analysis of Integer Sequences
**题目:** 利用整数序列分析对数值常数的假设进行自动搜索

**作者:** Ofir Razon, Yoav Harris, Shahar Gottlieb, Dan Carmon, Ofir David, Ido Kaminer

**Abstract:** The discovery of formulas involving mathematical constants such as $\pi$ and $e$ had a great impact on various fields of science and mathematics. However, such discoveries have remained scarce, relying on the intuition of mathematicians such as Ramanujan and Gauss. Recent efforts to automate such discoveries, such as the Ramanujan Machine project, relied solely on exhaustive search and remain limited by the space of options that can be covered. Here we propose a fundamentally different method to search for conjectures on mathematical constants: through analysis of integer sequences. We introduce the Enumerated Signed-continued-fraction Massey Approve (ESMA) algorithm, which builds on the Berlekamp-Massey algorithm to identify patterns in integer sequences that represent mathematical constants. ESMA has found various known formulas and new conjectures for $e, e^2, \tan(1)$, and ratios of values of Bessel functions, many of which provide faster numerical convergence than their corresponding simple continued fractions forms. We also characterize the space of constants that ESMA can catch and quantify its algorithmic advantage in certain scenarios. Altogether, this work continues the development toward algorithm-augmented mathematical intuition, to help accelerate mathematical research.

**摘要:** 包含数学常数的公式的发现,如$\pi$和$e$,对科学和数学的各个领域产生了巨大的影响。然而,这些发现仍然很稀少,依赖于拉马努扬和高斯等数学家直觉。最近为自动化这些发现,如拉马努扬机器项目,只依靠全面搜索,并且仍然受到可能覆盖的选项空间的限制。ESMA已经发现了各种已知的公式和新的假设,包括$e、e^2、\tan(1)$和贝塞尔函数的值比,其中许多提供比其相应的简单的连续分数形式更快的数值收敛。我们还对ESMA在某些场景中能够捕捉和定量化其算法优势的常数空间进行了描述。

**[Paper URL](https://proceedings.mlr.press/v202/razon23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/razon23a/razon23a.pdf)** 

# Neural networks trained with SGD learn distributions of increasing complexity
**题目:** 使用SGD训练的神经网络学习日益复杂的分布

**作者:** Maria Refinetti, Alessandro Ingrosso, Sebastian Goldt

**Abstract:** The uncanny ability of over-parameterised neural networks to generalise well has been explained using various "simplicity biases". These theories postulate that neural networks avoid overfitting by first fitting simple, linear classifiers before learning more complex, non-linear functions. Meanwhile, data structure is also recognised as a key ingredient for good generalisation, yet its role in simplicity biases is not yet understood. Here, we show that neural networks trained using stochastic gradient descent initially classify their inputs using lower-order input statistics, like mean and covariance, and exploit higher-order statistics only later during training. We first demonstrate this distributional simplicity bias (DSB) in a solvable model of a single neuron trained on synthetic data. We then demonstrate DSB empirically in a range of deep convolutional networks and visual transformers trained on CIFAR10, and show that it even holds in networks pre-trained on ImageNet. We discuss the relation of DSB to other simplicity biases and consider its implications for the principle of Gaussian universality in learning.

**摘要:** 这些理论认为,神经网络在学习更复杂的非线性函数之前首先采用简单的线性分类器来避免过度适应。同时,数据结构也被认为是良好的一般化的关键成分,但其在简单偏差中的作用还未被理解。我们讨论了DSB与其他简单偏见的关系,并考虑其对学习中的高斯普遍性原则的影响。

**[Paper URL](https://proceedings.mlr.press/v202/refinetti23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/refinetti23a/refinetti23a.pdf)** 

# Simplex Random Features
**题目:** Simplex随机功能

**作者:** Isaac Reid, Krzysztof Marcin Choromanski, Valerii Likhosherstov, Adrian Weller

**Abstract:** We present Simplex Random Features (SimRFs), a new random feature (RF) mechanism for unbiased approximation of the softmax and Gaussian kernels by geometrical correlation of random projection vectors. We prove that SimRFs provide the smallest possible mean square error (MSE) on unbiased estimates of these kernels among the class of weight-independent geometrically-coupled positive random feature (PRF) mechanisms, substantially outperforming the previously most accurate Orthogonal Random Features (ORFs) at no observable extra cost. We present a more computationally expensive SimRFs+ variant, which we prove is asymptotically optimal in the broader family of weight-dependent geometrical coupling schemes (which permit correlations between random vector directions and norms). In extensive empirical studies, we show consistent gains provided by SimRFs in settings including pointwise kernel estimation, nonparametric classification and scalable Transformers.

**摘要:** 给出了一种新的随机特性(RF)机制,用于通过随机投影向量的几何相关性对软最大和高斯核进行无偏近似。我们证明,SimRFs提供最小可能的平均平方误差(MSE)在这些核的无偏估计中,在重量独立的几何耦合正随机特性(PRF)机制中,在无可观测的额外成本下大大超过了以前最准确的正交随机特性(ORFs)。

**[Paper URL](https://proceedings.mlr.press/v202/reid23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/reid23a/reid23a.pdf)** 

# Bayesian Neural Networks Avoid Encoding Complex and Perturbation-Sensitive Concepts
**题目:** 贝叶斯神经网络避免编码复杂和干扰敏感的概念

**作者:** Qihan Ren, Huiqi Deng, Yunuo Chen, Siyu Lou, Quanshi Zhang

**Abstract:** In this paper, we focus on mean-field variational Bayesian Neural Networks (BNNs) and explore the representation capacity of such BNNs by investigating which types of concepts are less likely to be encoded by the BNN. It has been observed and studied that a relatively small set of interactive concepts usually emerge in the knowledge representation of a sufficiently-trained neural network, and such concepts can faithfully explain the network output. Based on this, our study proves that compared to standard deep neural networks (DNNs), it is less likely for BNNs to encode complex concepts. Experiments verify our theoretical proofs. Note that the tendency to encode less complex concepts does not necessarily imply weak representation power, considering that complex concepts exhibit low generalization power and high adversarial vulnerability. The code is available at https://github.com/sjtu-xai-lab/BNN-concepts.

**摘要:** 在本文中,我们着重研究中场变异的贝叶斯神经网络(BNN)及其通过研究哪些类型的概念更不容易被BNN编码的表示能力。观察和研究表明,相对较小的交互概念通常出现在足够训练的神经网络的知识表示中,这些概念可以忠实地解释网络输出。基于此,我们的研究证明,与标准深度神经网络(DNN)相比,BNN更不容易编码复杂概念。实验验证了我们的理论证明。

**[Paper URL](https://proceedings.mlr.press/v202/ren23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ren23a/ren23a.pdf)** 

# Escaping saddle points in zeroth-order optimization: the power of two-point estimators
**题目:** 零阶优化中的脱鞍点:二点估计器的有效性

**作者:** Zhaolin Ren, Yujie Tang, Na Li

**Abstract:** Two-point zeroth order methods are important in many applications of zeroth-order optimization arising in robotics, wind farms, power systems, online optimization, and adversarial robustness to black-box attacks in deep neural networks, where the problem can be high-dimensional and/or time-varying. Furthermore, such problems may be nonconvex and contain saddle points. While existing works have shown that zeroth-order methods utilizing $\Omega(d)$ function valuations per iteration (with $d$ denoting the problem dimension) can escape saddle points efficiently, it remains an open question if zeroth-order methods based on two-point estimators can escape saddle points. In this paper, we show that by adding an appropriate isotropic perturbation at each iteration, a zeroth-order algorithm based on $2m$ (for any $1 \leq m \leq d$) function evaluations per iteration can not only find $\epsilon$-second order stationary points polynomially fast, but do so using only $\tilde{O}(\frac{d}{m\epsilon^{2}\bar{\psi}})$ function evaluations, where $\bar{\psi} \geq \tilde{\Omega}(\sqrt{\epsilon})$ is a parameter capturing the extent to which the function of interest exhibits the strict saddle property.

**摘要:** 两个点零阶方法在机器人、风力发电厂、电力系统、在线优化以及在深层神经网络中对黑箱攻击的敌对鲁棒性中具有重要意义,因为问题可以是高维和/或时间变异的。此外,这些问题可能是非凸的,并且包含鞍点。本文指出,通过在每个迭代中添加适当的异质扰动,基于$2m$(对于任何$1 m \leq d$)函数评价的零阶算法在每次迭代中不仅能够快速地找到$\epsilon$次序的静态点,而且只使用$\tilde{O}(\frac{d}{m\epsilon^{2}\bar{\psi}})$函数评价,其中$\bar{\psi} \geq \tilde{\Omega}(\sqrt{\epsilon})$是一个捕获兴趣函数表现出严格鞍属性的范围的参数。

**[Paper URL](https://proceedings.mlr.press/v202/ren23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ren23b/ren23b.pdf)** 

# Dimension-independent Certified Neural Network Watermarks via Mollifier Smoothing
**题目:** 维度独立的神经网络水印通过调节器 Smoothing

**作者:** Jiaxiang Ren, Yang Zhou, Jiayin Jin, Lingjuan Lyu, Da Yan

**Abstract:** Certified_Watermarks is the first to provide a watermark certificate against $l_2$-norm watermark removal attacks, by leveraging the randomized smoothing techniques for certified robustness to adversarial attacks. However, the randomized smoothing techniques suffer from hardness of certified robustness in high-dimensional space against $l_p$-norm attacks for large $p$ ($p>2$). The certified watermark method based on the randomized smoothing is no exception, i.e., fails to provide meaningful certificates in high-dimensional space against the $l_p$-norm watermark removal attacks ($p>2$). By leveraging mollifier theory, this paper proposes a mollifier smoothing method with dimension-independent certified radius of our proposed smooth classifier, for conducting the certified watermark problem against the $l_p$-norm watermark removal attacks ($1 \leq p \leq \infty$) for high parameter dimension $d$. Based on partial differential equation (PDE) theory, an approximation of mollifier smoothing is developed to alleviate the inefficiency of sampling and prediction in the randomized smoothing as well as numerical integration in the mollifier smoothing, while maintaining the certified watermark against the $l_p$-norm watermark removal attacks ($1 \leq p \leq \infty$).

**摘要:** 采用随机平滑技术对敌方攻击提供水印认证证书,是首个针对$l_2$-norm水印除去攻击提供水印认证的程序。然而,随机平滑技术对大型$p$($p>2$)的$l_p$-norm攻击 suffer from hardness of certified robustness in high-dimensional space. The certified watermark method based on the randomized smoothing is no exception, i.e. fails to provide meaningful certificates in high-dimensional space against the $l_p$-norm watermark removal attacks ($p>2$).基于部分微分方程(PDE)理论,开发了模拟滑动机的近似方法,以减轻随机滑动机的采样和预测效率以及数值集成,同时保持验证的水印与$l_p$-标准水印除去攻击($1\leq p \leq \infty$)。

**[Paper URL](https://proceedings.mlr.press/v202/ren23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ren23c/ren23c.pdf)** 

# Feature Programming for Multivariate Time Series Prediction
**题目:** 多变量时间序列预测的特征编程

**作者:** Alex Daniel Reneau, Jerry Yao-Chieh Hu, Ammar Gilani, Han Liu

**Abstract:** We introduce the concept of programmable feature engineering for time series modeling and propose a feature programming framework. This framework generates large amounts of predictive features for noisy multivariate time series while allowing users to incorporate their inductive bias with minimal effort. The key motivation of our framework is to view any multivariate time series as a cumulative sum of fine-grained trajectory increments, with each increment governed by a novel spin-gas dynamical Ising model. This fine-grained perspective motivates the development of a parsimonious set of operators that summarize multivariate time series in an abstract fashion, serving as the foundation for large-scale automated feature engineering. Numerically, we validate the efficacy of our method on several synthetic and real-world noisy time series datasets.

**摘要:** 介绍了时间序列建模的可编程特征工程的概念,并提出了一种特征建模框架。该框架为噪声多变量时间序列生成大量预测特征,同时允许用户在最小的努力下结合诱导偏见。我们框架的关键动机是将任何多变量时间序列视作细粒度轨迹增益的累积总数,每个增益由新型旋气动态井位模型控制。

**[Paper URL](https://proceedings.mlr.press/v202/reneau23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/reneau23a/reneau23a.pdf)** 

# Run-off Election: Improved Provable Defense against Data Poisoning Attacks
**题目:** 竞选结果:增强了对数据中毒攻击的防御能力

**作者:** Keivan Rezaei, Kiarash Banihashem, Atoosa Chegini, Soheil Feizi

**Abstract:** In data poisoning attacks, an adversary tries to change a model’s prediction by adding, modifying, or removing samples in the training data. Recently, ensemble-based approaches for obtaining provable defenses against data poisoning have been proposed where predictions are done by taking a majority vote across multiple base models. In this work, we show that merely considering the majority vote in ensemble defenses is wasteful as it does not effectively utilize available information in the logits layers of the base models. Instead, we propose Run-Off Election (ROE), a novel aggregation method based on a two-round election across the base models: In the first round, models vote for their preferred class and then a second, Run-Off election is held between the top two classes in the first round. Based on this approach, we propose DPA+ROE and FA+ROE defense methods based on Deep Partition Aggregation (DPA) and Finite Aggregation (FA) approaches from prior work. We evaluate our methods on MNIST, CIFAR-10, and GTSRB and obtain improvements in certified accuracy by up to $3%$-$4%$. Also, by applying ROE on a boosted version of DPA, we gain improvements around $12%$-$27%$ comparing to the current state-of-the-art, establishing a new state-of-the-art in (pointwise) certified robustness against data poisoning. In many cases, our approach outperforms the state-of-the-art, even when using 32 times less computational power.

**摘要:** 在数据中毒攻击中,一个对手试图通过在训练数据中添加、修改或删除样品来改变模型的预测。最近,针对数据中毒的可证明防御的集合式方法已经提出,其中预测是通过在多个基础模型中取得多数选票进行的。在这个工作中,我们表明,仅仅考虑集合式防御中的多数选票是浪费的,因为它没有有效地利用基本模型的 logits层中的可用信息。我们对MNIST、CIFAR-10和GTSRB的测试方法进行了评估,并获得高达$3%-$4%的认证精度的改进。此外,通过对提高版本的DPA的ROE,我们获得与当前的最先端相比,在(点wise)认证的鲁棒性上建立新的最先端,以防数据中毒。在许多情况下,我们的方法比最先端更好,即使使用32倍的计算能力。

**[Paper URL](https://proceedings.mlr.press/v202/rezaei23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rezaei23a/rezaei23a.pdf)** 

# Learning Control-Oriented Dynamical Structure from Data
**题目:** 基于数据的控制动态结构学习

**作者:** Spencer M. Richards, Jean-Jacques Slotine, Navid Azizan, Marco Pavone

**Abstract:** Even for known nonlinear dynamical systems, feedback controller synthesis is a difficult problem that often requires leveraging the particular structure of the dynamics to induce a stable closed-loop system. For general nonlinear models, including those fit to data, there may not be enough known structure to reliably synthesize a stabilizing feedback controller. In this paper, we discuss a state-dependent nonlinear tracking controller formulation based on a state-dependent Riccati equation for general nonlinear control-affine systems. This formulation depends on a nonlinear factorization of the system of vector fields defining the control-affine dynamics, which always exists under mild smoothness assumptions. We propose a method for learning this factorization from a finite set of data. On a variety of simulated nonlinear dynamical systems, we empirically demonstrate the efficacy of learned versions of this controller in stable trajectory tracking. Alongside our learning method, we evaluate recent ideas in jointly learning a controller and stabilizability certificate for known dynamical systems; we show experimentally that such methods can be frail in comparison.

**摘要:** 即使对于已知的非线性动力学系统,反馈控制器的合成是一个难以解决的问题,经常需要利用动态的特定结构来诱导稳定的闭环系统。对于一般非线性模型,包括适合数据的模型,可能没有足够的既知结构来可靠地合成一个稳定反馈控制器。本文讨论了基于一般非线性控制-自适应系统状态依赖式Riccati方程的非线性跟踪控制器公式,该公式依赖于定义控制-自适应动力学的矢量场系统非线性因子化,这种因子化常存在于温和滑度假设下。在学习方法的同时,我们对已知动态系统联合学习控制器和稳定性证书的近来想法进行了评价,并实验表明,这些方法在比较上是较弱的。

**[Paper URL](https://proceedings.mlr.press/v202/richards23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/richards23a/richards23a.pdf)** 

# The Edge of Orthogonality: A Simple View of What Makes BYOL Tick
**题目:** 正交的边缘:简洁的看法,让BYOL产生活力

**作者:** Pierre Harvey Richemond, Allison Tam, Yunhao Tang, Florian Strub, Bilal Piot, Felix Hill

**Abstract:** Self-predictive unsupervised learning methods such as BYOL or SimSIAM have shown impressive results, and counter-intuitively, do not collapse to trivial representations. In this work, we aim at exploring the simplest possible mathematical arguments towards explaining the underlying mechanisms behind self-predictive unsupervised learning. We start with the observation that those methods crucially rely on the presence of a predictor network (and stop-gradient). With simple linear algebra, we show that when using a linear predictor, the optimal predictor is close to an orthogonal projection, and propose a general framework based on orthonormalization that enables to interpret and give intuition on why BYOL works. In addition, this framework demonstrates the crucial role of the exponential moving average and stop-gradient operator in BYOL as an efficient orthonormalization mechanism. We use these insights to propose four new closed-form predictor variants of BYOL to support our analysis. Our closed-form predictors outperform standard linear trainable predictor BYOL at 100 and 300 epochs (top-1 linear accuracy on ImageNet).

**摘要:** 自我预测的非监督学习方法如BYOL或SimSIAM都显示出令人印象深刻的结果,并且与直觉相反,并不会倒塌为琐碎的表述。本研究旨在探索最简单的数学论据,以解释自我预测的非监督学习背后的根本机制。我们首先观察到这些方法主要依赖于预测器网络的存在(和停止梯度)。我们的闭式预测器在100和300个时代比标准的线性可训练的预测器比OL高(在ImageNet上最高1-线性精度)。

**[Paper URL](https://proceedings.mlr.press/v202/richemond23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/richemond23a/richemond23a.pdf)** 

# Multi-Agent Best Arm Identification with Private Communications
**题目:** 多代理人与私人通讯进行最佳武器识别

**作者:** Alexandre Rio, Merwan Barlier, Igor Colin, Marta Soare

**Abstract:** We address multi-agent best arm identification with privacy guarantees. In this setting, agents collaborate by communicating to find the optimal arm. To avoid leaking sensitive data through messages, we consider two notions of privacy withholding different kinds of information: differential privacy and $(\epsilon, \eta)$-privacy. For each privacy definition, we propose an algorithm based on a two-level successive elimination scheme. We provide theoretical guarantees for the privacy level, accuracy and sample complexity of our algorithms. Experiments on various settings support our theoretical findings.

**摘要:** 针对多代理人最佳手臂识别与隐私保障问题。在这个设置中,代理人通过通信合作寻找最佳手臂。为了避免通过消息泄漏敏感数据,我们考虑了两种隐瞒不同类型信息的隐私概念:差分隐私和$(\epsilon, \eta)$-privacy。对于每个隐私定义,我们提出了基于二级连续消除方案的算法。我们为我们的算法的隐私水平、准确性和样品复杂性提供理论保障。在不同设置的实验支持我们的理论发现。

**[Paper URL](https://proceedings.mlr.press/v202/rio23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rio23a/rio23a.pdf)** 

# A Two-Stage Active Learning Algorithm for k-Nearest Neighbors
**题目:** k-近邻的双级主动学习算法

**作者:** Nicholas Rittler, Kamalika Chaudhuri

**Abstract:** $k$-nearest neighbor classification is a popular non-parametric method because of desirable properties like automatic adaption to distributional scale changes. Unfortunately, it has thus far proved difficult to design active learning strategies for the training of local voting-based classifiers that naturally retain these desirable properties, and hence active learning strategies for $k$-nearest neighbor classification have been conspicuously missing from the literature. In this work, we introduce a simple and intuitive active learning algorithm for the training of $k$-nearest neighbor classifiers, the first in the literature which retains the concept of the $k$-nearest neighbor vote at prediction time. We provide consistency guarantees for a modified $k$-nearest neighbors classifier trained on samples acquired via our scheme, and show that when the conditional probability function $\mathbb{P}(Y=y|X=x)$ is sufficiently smooth and the Tsybakov noise condition holds, our actively trained classifiers converge to the Bayes optimal classifier at a faster asymptotic rate than passively trained $k$-nearest neighbor classifiers.

**摘要:** $k$-近邻分类是由于对分布尺度变化的自动适应等有希望属性的非参数化方法。不幸的是,目前仍难以设计有效的学习策略,以训练基于投票的本地分类器,它们自然地保留这些有希望属性,因此,对$k$-近邻分类器的主动学习策略在文献中明显没有出现。我们为通过我们的方案获得的样品训练的修改$k$-最近邻类分类器提供一致性保证,并证明当条件概率函数$\mathbb{P}(Y=y|X=x)$足够平滑,并保持齐巴科夫噪声条件时,我们积极训练的分类器会比被动训练的$k$-最近邻类分类器更快地达到贝伊斯最佳分类器的渐近速度。

**[Paper URL](https://proceedings.mlr.press/v202/rittler23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rittler23a/rittler23a.pdf)** 

# Lowering the Pre-training Tax for Gradient-based Subset Training: A Lightweight Distributed Pre-Training Toolkit
**题目:** 降低基于梯度的子集训练预培训税:轻量分布的预培训工具包

**作者:** Yeonju Ro, Zhangyang Wang, Vijay Chidambaram, Aditya Akella

**Abstract:** Training data and model sizes are increasing exponentially. One way to reduce training time and resources is to train with a carefully selected subset of the full dataset. Prior work uses the gradient signals obtained during a warm-up or “pre-training" phase over the full dataset, for determining the core subset; if the pre-training phase is too small, the gradients obtained are chaotic and unreliable. As a result, the pre-training phase itself incurs significant time/resource overhead, and prior work has not gone beyond hyperparameter search to reduce pre-training time. Our work explicitly aims to reduce this $\textbf{pre-training tax}$ in gradient-based subset training. We develop a principled, scalable approach for pre-training in a distributed setup. Our approach is $\textit{lightweight}$ and $\textit{minimizes communication}$ between distributed worker nodes. It is the first to utilize the concept of model-soup based distributed training $\textit{at initialization}$. The key idea is to minimally train an ensemble of models on small, disjointed subsets of the data; we further employ data-driven sparsity and data augmentation for local worker training to boost ensemble diversity. The centralized model, obtained at the end of pre-training by merging the per-worker models, is found to offer stabilized gradient signals to select subsets, on which the main model is further trained. We have validated the effectiveness of our method through extensive experiments on CIFAR-10/100, and ImageNet, using ResNet and WideResNet models. For example, our approach is shown to achieve $\textbf{15.4$\times$}$ pre-training speedup and $\textbf{2.8$\times$}$ end-to-end speedup on CIFAR10 and ResNet18 without loss of accuracy. The code is at https://github.com/moonbucks/LiPT.git.

**摘要:** 训练数据和模型大小呈指数增长。减少训练时间和资源的一个方法是与完全数据集的仔细选择的子集进行训练。以前的工作使用在加热或“预训练”阶段获得的梯度信号,用于确定核心子集;如果预训练阶段太小,所得的梯度是混乱和不可靠的。结果,预训练阶段本身花费了大量时间/资源的额外费用,而预训练工作并没有超越超参数搜索来减少预训练时间。我们的工作明确的目标是减少这种在梯度基础的子集训练中$\textbf{预训练税}$。我们开发了在分布式设置中预训练的原理、可扩展的方法。我们的方法是$\textit{轻量}$和$\textit{减少通信}$在分布式工人节点之间。这是第一个使用基于模型汤的分布式训练$\textit{初始化}关键思想是在数据的小型、分离的子集上最小限度训练模型;我们进一步利用数据驱动的稀疏度和数据增加来促进本地工人培训以提高组合多样性。中央化模型,通过合并每个工人模型在预训练结束时获得,被发现能够提供稳定梯度信号,以选择子集,其中主要模型进一步训练。我们通过对CIFAR-10/100和ImageNet的广泛实验验证了我们的方法的有效性,使用ResNet和WideResNet模型。

**[Paper URL](https://proceedings.mlr.press/v202/ro23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ro23a/ro23a.pdf)** 

# The Role of Entropy and Reconstruction in Multi-View Self-Supervised Learning
**题目:** 多视角自我监督学习中熵与重建的作用

**作者:** Borja Rodrı́guez Gálvez, Arno Blaas, Pau Rodriguez, Adam Golinski, Xavier Suau, Jason Ramapuram, Dan Busbridge, Luca Zappella

**Abstract:** The mechanisms behind the success of multi-view self-supervised learning (MVSSL) are not yet fully understood. Contrastive MVSSL methods have been studied through the lens of InfoNCE, a lower bound of the Mutual Information (MI). However, the relation between other MVSSL methods and MI remains unclear. We consider a different lower bound on the MI consisting of an entropy and a reconstruction term (ER), and analyze the main MVSSL families through its lens. Through this ER bound, we show that clustering-based methods such as DeepCluster and SwAV maximize the MI. We also re-interpret the mechanisms of distillation-based approaches such as BYOL and DINO, showing that they explicitly maximize the reconstruction term and implicitly encourage a stable entropy, and we confirm this empirically. We show that replacing the objectives of common MVSSL methods with this ER bound achieves competitive performance, while making them stable when training with smaller batch sizes or smaller exponential moving average (EMA) coefficients.

**摘要:** 多视角自我监督学习(MVSSL)的成功背后的机制尚未完全理解。MVSSL的对比方法已经通过InfoNCE的镜头研究,这是相互信息(MI)的较低的边界。然而,其他MVSSL方法与MI之间的关系仍然不明确。我们考虑了由熵和重建术语(ER)组成的MI的另一个较低的边界,并通过其镜头分析了主要MVSSL家族。通过 ER边界,我们显示 clustering-based methods such as DeepCluster and SwAV maximize the MI。我们证明,用这种ER约束来取代一般的MVSSL方法的目标,可以实现竞争性性能,同时在使用较小的批量大小或较小的指数移动平均(EMA)系数进行训练时使它们稳定。

**[Paper URL](https://proceedings.mlr.press/v202/rodri-guez-galvez23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rodri-guez-galvez23a/rodri-guez-galvez23a.pdf)** 

# RLang: A Declarative Language for Describing Partial World Knowledge to Reinforcement Learning Agents
**题目:** RLang:描述部分世界知识的声明语言

**作者:** Rafael Rodriguez-Sanchez, Benjamin Adin Spiegel, Jennifer Wang, Roma Patel, Stefanie Tellex, George Konidaris

**Abstract:** We introduce RLang, a domain-specific language (DSL) for communicating domain knowledge to an RL agent. Unlike existing RL DSLs that ground to $\textit{single}$ elements of a decision-making formalism (e.g., the reward function or policy), RLang can specify information about every element of a Markov decision process. We define precise syntax and grounding semantics for RLang, and provide a parser that grounds RLang programs to an algorithm-agnostic $\textit{partial}$ world model and policy that can be exploited by an RL agent. We provide a series of example RLang programs demonstrating how different RL methods can exploit the resulting knowledge, encompassing model-free and model-based tabular algorithms, policy gradient and value-based methods, hierarchical approaches, and deep methods.

**摘要:** 我们引入RLang,一种用于向RL代理人传递域知识的域特定语言(DSL)。与现有RLDSL不同,RLang可以指定决策形式主义(例如奖励函数或政策)的$\textit{single}$元素,RLang可以指定马可夫决策过程的每个元素的信息。我们定义了RLang的精确语法和基础语义,并提供了一个解析器,它将RLang程序的基础化为一个基于算法的$\textit{partial}$世界模型和政策,可以由RL代理人利用。我们提供了一系列的例子RLang程序,说明不同的RL方法如何利用结果的知识,包括无模型和基于模型的表格算法、政策梯度和基于价值的方法、层次方法和深度方法。

**[Paper URL](https://proceedings.mlr.press/v202/rodriguez-sanchez23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rodriguez-sanchez23a/rodriguez-sanchez23a.pdf)** 

# Improving Fair Training under Correlation Shifts
**题目:** 改善公平培训在相关转变下

**作者:** Yuji Roh, Kangwook Lee, Steven Euijong Whang, Changho Suh

**Abstract:** Model fairness is an essential element for Trustworthy AI. While many techniques for model fairness have been proposed, most of them assume that the training and deployment data distributions are identical, which is often not true in practice. In particular, when the bias between labels and sensitive groups changes, the fairness of the trained model is directly influenced and can worsen. We make two contributions for solving this problem. First, we analytically show that existing in-processing fair algorithms have fundamental limits in accuracy and group fairness. We utilize the notion of correlation shifts between labels and groups, which can explicitly capture the change of the above bias. Second, we propose a novel pre-processing step that samples the input data to reduce correlation shifts and thus enables the in-processing approaches to overcome their limitations. We formulate an optimization problem for adjusting the data ratio among labels and sensitive groups to reflect the shifted correlation. A key benefit of our approach lies in decoupling the roles of pre- and in-processing approaches: correlation adjustment via pre-processing and unfairness mitigation on the processed data via in-processing. Experiments show that our framework effectively improves existing in-processing fair algorithms w.r.t. accuracy and fairness, both on synthetic and real datasets.

**摘要:** 模型公平是可信AI的一个重要要素。虽然已经提出了模型公平的许多技术,但其中大多数假设训练和部署数据分布是相同的,这在实践中往往是不正确的。特别是,当标签和敏感群体之间的偏差发生变化时,训练模型的公平直接受到影响并可能恶化。我们为解决这个问题作出了两个贡献。我们制定了一个优化问题,以调整标签和敏感组之间的数据比,以反映变化的相关性。我们的方法的关键利益在于将预处理和预处理方法的作用分开:通过预处理调整相关性,通过预处理减轻处理数据的不公平性。实验表明,我们的框架有效地改善了现有的预处理公平算法,即对合成数据和实数据集的准确性和公平性。

**[Paper URL](https://proceedings.mlr.press/v202/roh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/roh23a/roh23a.pdf)** 

# The Statistical Benefits of Quantile Temporal-Difference Learning for Value Estimation
**题目:** 数值临时差异学习对价值估计的统计效益

**作者:** Mark Rowland, Yunhao Tang, Clare Lyle, Remi Munos, Marc G Bellemare, Will Dabney

**Abstract:** We study the problem of temporal-difference-based policy evaluation in reinforcement learning. In particular, we analyse the use of a distributional reinforcement learning algorithm, quantile temporal-difference learning (QTD), for this task. We reach the surprising conclusion that even if a practitioner has no interest in the return distribution beyond the mean, QTD (which learns predictions about the full distribution of returns) may offer performance superior to approaches such as classical TD learning, which predict only the mean return, even in the tabular setting.

**摘要:** 我们研究了增强学习中基于时间差的政策评价问题,特别是对分配增强学习算法量值时间差学习(QTD)的运用进行了分析,得出一个令人惊奇的结论:即使实践者对平均值以外的回报分配没有兴趣,QTD(它学习了关于回报的全面分配的预测)可能比传统的TD学习方法提供更好的性能,即使在表格设置中,它只预测平均回报。

**[Paper URL](https://proceedings.mlr.press/v202/rowland23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rowland23a/rowland23a.pdf)** 

# Robust Satisficing MDPs
**题目:** 稳妥满足多边发展计划

**作者:** Haolin Ruan, Siyu Zhou, Zhi Chen, Chin Pang Ho

**Abstract:** Despite being a fundamental building block for reinforcement learning, Markov decision processes (MDPs) often suffer from ambiguity in model parameters. Robust MDPs are proposed to overcome this challenge by optimizing the worst-case performance under ambiguity. While robust MDPs can provide reliable policies with limited data, their worst-case performances are often overly conservative, and so they do not offer practical insights into the actual performance of these reliable policies. This paper proposes robust satisficing MDPs (RSMDPs), where the expected returns of feasible policies are softly-constrained to achieve a user-specified target under ambiguity. We derive a tractable reformulation for RSMDPs and develop a first-order method for solving large instances. Experimental results demonstrate that RSMDPs can prescribe policies to achieve their targets, which are much higher than the optimal worst-case returns computed by robust MDPs. Moreover, the average and percentile performances of our model are competitive among other models. We also demonstrate the scalability of the proposed algorithm compared with a state-of-the-art commercial solver.

**摘要:** 尽管马可夫决策过程(MDPs)是增强学习的一个基本构架,但它们在模型参数中经常存在模糊问题。鲁棒MDPs被提出以优化模糊下的最坏情况来克服这一挑战。鲁棒MDPs可以提供有限数据的可靠政策,但它们的最坏情况往往过于保守,因此它们并不提供实际的洞察这些可靠政策的实际性能。此外,该模型的平均和百分比性能与其他模型相比具有竞争性。我们还证明了该算法的可扩展性,与最先进的商业解决方案相比。

**[Paper URL](https://proceedings.mlr.press/v202/ruan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ruan23a/ruan23a.pdf)** 

# Infinite Action Contextual Bandits with Reusable Data Exhaust
**题目:** 可重复数据耗尽的无限行动背景盗版

**作者:** Mark Rucker, Yinglun Zhu, Paul Mineiro

**Abstract:** For infinite action contextual bandits, smoothed regret and reduction to regression results in state-of-the-art online performance with computational cost independent of the action set: unfortunately, the resulting data exhaust does not have well-defined importance-weights. This frustrates the execution of downstream data science processes such as offline model selection. In this paper we describe an online algorithm with an equivalent smoothed regret guarantee, but which generates well-defined importance weights: in exchange, the online computational cost increases, but only to order smoothness (i.e., still independent of the action set). This removes a key obstacle to adoption of smoothed regret in production scenarios.

**摘要:** 针对无穷动作上下文带子,平滑的遗憾和减少回归结果在最先进的在线性能中具有独立于动作集的计算成本:不幸的是,结果的数据排气没有明确的重要权重。这阻碍了下游数据科学过程的执行,例如在线模型选择。本论文描述了具有等价平滑的遗憾保证的在线算法,但生成了明确的重要权重:换句话说,在线计算成本增加,但仅为了保证平滑(即仍然独立于动作集)。

**[Paper URL](https://proceedings.mlr.press/v202/rucker23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rucker23a/rucker23a.pdf)** 

# Function-Space Regularization in Neural Networks: A Probabilistic Perspective
**题目:** 神经网络的函数空间调节:一个概率性视角

**作者:** Tim G. J. Rudner, Sanyam Kapoor, Shikai Qiu, Andrew Gordon Wilson

**Abstract:** Parameter-space regularization in neural network optimization is a fundamental tool for improving generalization. However, standard parameter-space regularization methods make it challenging to encode explicit preferences about desired predictive functions into neural network training. In this work, we approach regularization in neural networks from a probabilistic perspective and show that by viewing parameter-space regularization as specifying an empirical prior distribution over the model parameters, we can derive a probabilistically well-motivated regularization technique that allows explicitly encoding information about desired predictive functions into neural network training. This method—which we refer to as function-space empirical Bayes (FS-EB)—includes both parameter- and function-space regularization, is mathematically simple, easy to implement, and incurs only minimal computational overhead compared to standard regularization techniques. We evaluate the utility of this regularization technique empirically and demonstrate that the proposed method leads to near-perfect semantic shift detection, highly-calibrated predictive uncertainty estimates, successful task adaption from pre-trained models, and improved generalization under covariate shift.

**摘要:** 神经网络优化中的参数空间规则化是改进一般化的基本工具,然而,标准参数空间规则化方法使将期望预测函数的明确偏好编码到神经网络训练中成为挑战。本文从概率论角度对神经网络的规则化进行了研究,并表明,通过将参数空间规则化看作是对模型参数的经验性优先分布的指定,我们可以推导出一种具有概率论良好动机的规则化技术,允许将期望预测函数的明确编码信息编码到神经网络训练中。通过实证分析,验证了该定律法的有效性,并证明该方法可实现 near-perfect 的语义变换检测,高精确的预测不确定性估计,从预训练模型中成功地适应任务,并在共变换下改进一般化。

**[Paper URL](https://proceedings.mlr.press/v202/rudner23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rudner23a/rudner23a.pdf)** 

# A New PHO-rmula for Improved Performance of Semi-Structured Networks
**题目:** 半结构网络改进性能的新PHO仿真

**作者:** David Rügamer

**Abstract:** Recent advances to combine structured regression models and deep neural networks for better interpretability, more expressiveness, and statistically valid uncertainty quantification demonstrate the versatility of semi-structured neural networks (SSNs). We show that techniques to properly identify the contributions of the different model components in SSNs, however, lead to suboptimal network estimation, slower convergence, and degenerated or erroneous predictions. In order to solve these problems while preserving favorable model properties, we propose a non-invasive post-hoc orthogonalization (PHO) that guarantees identifiability of model components and provides better estimation and prediction quality. Our theoretical findings are supported by numerical experiments, a benchmark comparison as well as a real-world application to COVID-19 infections.

**摘要:** 结构性回归模型和深层神经网络的结合,以提高解释性、表达性和统计上有效的不确定性定量,证明了半结构性神经网络(SSN)的多用途性。我们证明,在SSN中正确识别不同模型组件的贡献技术,可导致亚最佳网络估计、放缓收敛和退化或误差预测。为了解决这些问题,同时保持有利的模型特性,我们提出了一种非侵袭性后旋转正交(PHO),保证模型组件的识别性,并提供更好的估计和预测质量。

**[Paper URL](https://proceedings.mlr.press/v202/rugamer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rugamer23a/rugamer23a.pdf)** 

# Geometric Clifford Algebra Networks
**题目:** 几何 Clifford代数网络

**作者:** David Ruhe, Jayesh K Gupta, Steven De Keninck, Max Welling, Johannes Brandstetter

**Abstract:** We propose Geometric Clifford Algebra Networks (GCANs) for modeling dynamical systems. GCANs are based on symmetry group transformations using geometric (Clifford) algebras. We first review the quintessence of modern (plane-based) geometric algebra, which builds on isometries encoded as elements of the $\mathrm{Pin}(p,q,r)$ group. We then propose the concept of group action layers, which linearly combine object transformations using pre-specified group actions. Together with a new activation and normalization scheme, these layers serve as adjustable geometric templates that can be refined via gradient descent. Theoretical advantages are strongly reflected in the modeling of three-dimensional rigid body transformations as well as large-scale fluid dynamics simulations, showing significantly improved performance over traditional methods.

**摘要:** 我们提出了几何克利福德代数网络(GCAN)用于建模动态系统。GCAN基于几何(克利福德)代数的对称群变换。我们首先回顾了现代(基于平面的)几何代数的本质,它建立在 $\mathrm{Pin}(p,q,r)$群的元素为编码的同位素上。然后我们提出了群行动层的概念,它以预指定群行动为线性结合对象变换。

**[Paper URL](https://proceedings.mlr.press/v202/ruhe23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ruhe23a/ruhe23a.pdf)** 

# Constrained Monotonic Neural Networks
**题目:** 约束单元神经网络

**作者:** Davor Runje, Sharath M Shankaranarayana

**Abstract:** Wider adoption of neural networks in many critical domains such as finance and healthcare is being hindered by the need to explain their predictions and to impose additional constraints on them. Monotonicity constraint is one of the most requested properties in real-world scenarios and is the focus of this paper. One of the oldest ways to construct a monotonic fully connected neural network is to constrain signs on its weights. Unfortunately, this construction does not work with popular non-saturated activation functions as it can only approximate convex functions. We show this shortcoming can be fixed by constructing two additional activation functions from a typical unsaturated monotonic activation function and employing each of them on the part of neurons. Our experiments show this approach of building monotonic neural networks has better accuracy when compared to other state-of-the-art methods, while being the simplest one in the sense of having the least number of parameters, and not requiring any modifications to the learning procedure or post-learning steps. Finally, we prove it can approximate any continuous monotone function on a compact subset of $\mathbb{R}^n$.

**摘要:** 单调性约束是现实场景中最需要的特性之一,是本文的重点。构建单调性全线性神经网络的最古老的方法之一,是约束信号在其重量上。不幸的是,这种构造并不适用于流行的非饱和激活函数,因为它只能近似凸动函数。我们证明,这种缺陷可以通过从典型的非饱和单调激活函数构建两个额外激活函数,并将其应用于神经元中。我们的实验表明,这种构建单调神经网络的方法与其他最先进的方法相比具有较高的精度,同时具有最小的参数,不需要对学习过程或学习后步骤进行任何修改,最后,我们证明它能够接近任何连续单调函数的$\mathbb{R}^n$紧凑子集。

**[Paper URL](https://proceedings.mlr.press/v202/runje23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/runje23a/runje23a.pdf)** 

# Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility and Possibility Theorems for Multilingual Language Models
**题目:** 差异性隐私、语言公平和训练数据的影响:多语言语言模型的不可能和可能性定理

**作者:** Phillip Rust, Anders Søgaard

**Abstract:** Language models such as mBERT, XLM-R, and BLOOM aim to achieve multilingual generalization or compression to facilitate transfer to a large number of (potentially unseen) languages. However, these models should ideally also be private, linguistically fair, and transparent, by relating their predictions to training data. Can these requirements be simultaneously satisfied? We show that multilingual compression and linguistic fairness are compatible with differential privacy, but that differential privacy is at odds with training data influence sparsity, an objective for transparency. We further present a series of experiments on two common NLP tasks and evaluate multilingual compression and training data influence sparsity under different privacy guarantees, exploring these trade-offs in more detail. Our results suggest that we need to develop ways to jointly optimize for these objectives in order to find practical trade-offs.

**摘要:** 语言模型如MBERT、XLM-R和BLOOM的目标是实现多语言通用化或压缩,以便利向大量(潜在的无视)语言进行传输。然而,这些模型还应理想地是私人、语言上公正、透明的,通过将它们的预测与培训数据联系起来。这些要求是否同时满足?我们证明多语言压缩和语言上的公平与差异性隐私相容,但差异性隐私与培训数据影响稀疏,这是透明性的目标。我们进一步对两个共同的NLP任务进行了一系列实验,并评估多语言压缩和培训数据影响稀疏 under different privacy guarantees, Exploring these trade-offs in more detail。

**[Paper URL](https://proceedings.mlr.press/v202/rust23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rust23a/rust23a.pdf)** 

# Intrinsic Sliced Wasserstein Distances for Comparing Collections of Probability Distributions on Manifolds and Graphs
**题目:** 内层 Sliced Wasserstein Distances for Comparing Collections of Probability Distributions on Manifolds and Graphs

**作者:** Raif M. Rustamov, Subhabrata Majumdar

**Abstract:** Collections of probability distributions arise in a variety of applications ranging from user activity pattern analysis to brain connectomics. In practice these distributions can be defined over diverse domain types including finite intervals, circles, cylinders, spheres, other manifolds, and graphs. This paper introduces an approach for detecting differences between two collections of distributions over such general domains. To this end, we propose the intrinsic slicing construction that yields a novel class of Wasserstein distances on manifolds and graphs. These distances are Hilbert embeddable, allowing us to reduce the distribution collection comparison problem to a more familiar mean testing problem in a Hilbert space. We provide two testing procedures one based on resampling and another on combining p-values from coordinate-wise tests. Our experiments in various synthetic and real data settings show that the resulting tests are powerful and the p-values are well-calibrated.

**摘要:** 从用户活动模式分析到脑 connectomics等多种应用中产生概率分布的集合。在实践中,这些分布可以定义在包括有限间隔、圆圈、圆柱、球面、其他多边形和图形在内的多种领域类型中。本文介绍了一种方法来检测在这些一般领域中两个分布的集合之间的差异。为此目的,我们提出了一种新的多边形和图形上的维多斯泰因距离的内在切削结构。这些距离是希尔伯特嵌入式,允许我们降低分布集合比较问题到希尔伯特空间中的更熟悉的平均测试问题。

**[Paper URL](https://proceedings.mlr.press/v202/rustamov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rustamov23a/rustamov23a.pdf)** 

# SWARM Parallelism: Training Large Models Can Be Surprisingly Communication-Efficient
**题目:** SWARM并行论:培训大型模型具有惊人的通信效率

**作者:** Max Ryabinin, Tim Dettmers, Michael Diskin, Alexander Borzunov

**Abstract:** Many deep learning applications benefit from using large models with billions of parameters. Training these models is notoriously expensive due to the need for specialized HPC clusters. In this work, we consider alternative setups for training large models: using cheap “preemptible” instances or pooling existing resources from multiple regions. We analyze the performance of existing model-parallel algorithms in these conditions and find configurations where training larger models becomes less communication-intensive. Based on these findings, we propose SWARM Parallelism (Stochastically Wired Adaptively Rebalanced Model Parallelism), a model-parallel training algorithm designed for poorly connected, heterogeneous and unreliable devices. SWARM creates temporary randomized pipelines between nodes that are rebalanced in case of failure. We empirically validate our findings and compare SWARM Parallelism with existing large-scale training approaches. Finally, we combine our insights with compression strategies to train a large Transformer language model with 1B shared parameters ($\approx$13B before sharing) on preemptible T4 GPUs with less than 200 Mb/s network.

**摘要:** 许多深层学习应用程序从使用数十亿参数的大型模型中获益。这些模型的培训是由于需要专门的HPC集群而臭名昭著的昂贵。在这个工作中,我们考虑培训大型模型的替代设置:使用廉价的“可预见”实例或从多个区域合并现有资源。我们分析了在这些条件下现有模型平行算法的性能,并找出培训大型模型的配置,使得训练变得较少通信密集。基于这些发现,我们提出了SWARM平行主义(Stochastically Wired Adaptively Rebalanced Model Parallelism), 为不良连接、异质和不可靠设备设计的模型平行训练算法。SWARM创建在失败时重新平衡的节点间临时随机管道。最后,我们将我们的洞察与压缩策略结合起来,以训练一个具有1B共享参数(在共享前约13B)的大型变换语言模型在200 Mb/s网络以下的预匹配的T4 GPU上。

**[Paper URL](https://proceedings.mlr.press/v202/ryabinin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ryabinin23a/ryabinin23a.pdf)** 

# Hiera: A Hierarchical Vision Transformer without the Bells-and-Whistles
**题目:** 階層:無鐘聲的階層視力轉換器

**作者:** Chaitanya Ryali, Yuan-Ting Hu, Daniel Bolya, Chen Wei, Haoqi Fan, Po-Yao Huang, Vaibhav Aggarwal, Arkabandhu Chowdhury, Omid Poursaeed, Judy Hoffman, Jitendra Malik, Yanghao Li, Christoph Feichtenhofer

**Abstract:** Modern hierarchical vision transformers have added several vision-specific components in the pursuit of supervised classification performance. While these components lead to effective accuracies and attractive FLOP counts, the added complexity actually makes these transformers slower than their vanilla ViT counterparts. In this paper, we argue that this additional bulk is unnecessary. By pretraining with a strong visual pretext task (MAE), we can strip out all the bells-and-whistles from a state-of-the-art multi-stage vision transformer without losing accuracy. In the process, we create Hiera, an extremely simple hierarchical vision transformer that is more accurate than previous models while being significantly faster both at inference and during training. We evaluate Hiera on a variety of tasks for image and video recognition. Our code and models are available at https://github.com/facebookresearch/hiera.

**摘要:** 现代层次视觉变换器在监督分类性能的追求中增加了多个视觉特有组件。虽然这些组件导致有效的精度和吸引人的FLOP计数,但加起来的复杂性实际上使这些变换器比它们的瓦尼拉ViT同类变换器慢。在本文中,我们认为这种额外的大量是不必要的。通过预训练以强的视觉借口任务(MAE)来,我们可以从最先进的多级视觉变换器中除去所有铃声和哨声,而不会失去精度。

**[Paper URL](https://proceedings.mlr.press/v202/ryali23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ryali23a/ryali23a.pdf)** 

# End-to-End Learning for Stochastic Optimization: A Bayesian Perspective
**题目:** 随机优化的终极学习:贝叶斯视角

**作者:** Yves Rychener, Daniel Kuhn, Tobias Sutter

**Abstract:** We develop a principled approach to end-to-end learning in stochastic optimization. First, we show that the standard end-to-end learning algorithm admits a Bayesian interpretation and trains a posterior Bayes action map. Building on the insights of this analysis, we then propose new end-to-end learning algorithms for training decision maps that output solutions of empirical risk minimization and distributionally robust optimization problems, two dominant modeling paradigms in optimization under uncertainty. Numerical results for a synthetic newsvendor problem illustrate the key differences between alternative training schemes. We also investigate an economic dispatch problem based on real data to showcase the impact of the neural network architecture of the decision maps on their test performance.

**摘要:** 首先,我们证明了标准的end-to-end学习算法允许贝叶斯解释并训练后贝叶斯行动图。然后,基于这一分析的洞察,我们提出了新的end-to-end学习算法,用于训练决策图,产生经验风险最小化和分布性强的优化问题,两个在不确定性下优化中的主导模型范式。合成新闻供应商问题的数值结果说明了替代培训方案之间的关键差异。

**[Paper URL](https://proceedings.mlr.press/v202/rychener23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/rychener23a/rychener23a.pdf)** 

# Sequential Monte Carlo Learning for Time Series Structure Discovery
**题目:** 时间序列结构发现的序列蒙特卡罗学习

**作者:** Feras Saad, Brian Patton, Matthew Douglas Hoffman, Rif A. Saurous, Vikash Mansinghka

**Abstract:** This paper presents a new approach to automatically discovering accurate models of complex time series data. Working within a Bayesian nonparametric prior over a symbolic space of Gaussian process time series models, we present a novel structure learning algorithm that integrates sequential Monte Carlo (SMC) and involutive MCMC for highly effective posterior inference. Our method can be used both in "online” settings, where new data is incorporated sequentially in time, and in “offline” settings, by using nested subsets of historical data to anneal the posterior. Empirical measurements on real-world time series show that our method can deliver 10x–100x runtime speedups over previous MCMC and greedy-search structure learning algorithms targeting the same model family. We use our method to perform the first large-scale evaluation of Gaussian process time series structure learning on a prominent benchmark of 1,428 econometric datasets. The results show that our method discovers sensible models that deliver more accurate point forecasts and interval forecasts over multiple horizons as compared to widely used statistical and neural baselines that struggle on this challenging data.

**摘要:** 本文提出了一种自动发现复杂时间序列数据的精确模型的新方法。在高斯过程时间序列模型的符号空间上,在贝叶斯非参数化序列内工作,提出了一种综合序列蒙特卡罗(SMC)和非自愿MCMC的结构学习算法,以实现高效率的后推导。该方法可以在“在线”设置中,在时间序列内整合新数据,也可以在“offline”设置中,使用内嵌历史数据的子集来对后推导。实世界时间序列的实验测量表明,该方法能够在以前的MCMC和针对同一模型家族的贪婪搜索结构学习算法上实现10倍-100倍的运行速度提高。结果表明,该方法能发现较广泛应用的统计和神经基线对这一挑战性数据进行比较,能够提供较精确的点预测和多边预测的明智模型。

**[Paper URL](https://proceedings.mlr.press/v202/saad23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/saad23a/saad23a.pdf)** 

# Active Ranking of Experts Based on their Performances in Many Tasks
**题目:** 基于在许多任务中的表现的专家积极排名

**作者:** El Mehdi Saad, Nicolas Verzelen, Alexandra Carpentier

**Abstract:** We consider the problem of ranking n experts based on their performances on d tasks. We make a monotonicity assumption stating that for each pair of experts, one outperforms the other on all tasks. We consider the sequential setting where in each round the learner has access to noisy evaluations of actively chosen pair of expert-task, given the information available up to the actual round. Given a confidence parameter $\delta \in (0, 1)$, we provide strategies allowing to recover the correct ranking of experts and develop a bound on the total number of queries made by our algorithm that hold with probability at least $1-\delta$. We show that our strategy is adaptive to the complexity of the problem (our bounds are instance dependent), and develop matching lower bounds up to a ploy-logarithmic factor. Finally, we adapt our strategy to the relaxed problem of best expert identification and provide numerical simulation consistent with our theoretical results

**摘要:** 我们考虑 n 专家 的 排名 问题, 根据 他们 在 d 任务 中 的 表现 。 我们 提出 一 种 单调性 假设, 说明 每个 专家 对, 一个 对 在 所有 任务 中 胜过 另一个 专家 。 我们 考虑 各 轮 的 序列 设置, 即 学习者 可 访问 主动 选择 的 专家 任务 对 噪声 的 评价, 并 考虑 到 实际 轮 的 可用 信息 。 考虑 到 $ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \

**[Paper URL](https://proceedings.mlr.press/v202/saad23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/saad23b/saad23b.pdf)** 

# Sample Complexity Bounds for Learning High-dimensional Simplices in Noisy Regimes
**题目:** 学习高维简化噪声 Regimes的复杂度约束实例

**作者:** Seyed Amir Hossein Saberi, Amir Najafi, Abolfazl Motahari, Babak Khalaj

**Abstract:** In this paper, we propose sample complexity bounds for learning a simplex from noisy samples. A dataset of size $n$ is given which includes i.i.d. samples drawn from a uniform distribution over an unknown arbitrary simplex in $\mathbb{R}^K$, where samples are assumed to be corrupted by a multi-variate additive Gaussian noise of an arbitrary magnitude. We prove the existence of an algorithm that with high probability outputs a simplex having a $\ell_2$ distance of at most $\varepsilon$ from the true simplex (for any $\varepsilon>0$). Also, we theoretically show that in order to achieve this bound, it is sufficient to have $n\ge\tilde{\Omega}\left(K^2/\varepsilon^2\right)e^{\Omega\left(K/\mathrm{SNR}^2\right)}$ samples, where $\mathrm{SNR}$ stands for the signal-to-noise ratio and is defined as the ratio of the maximum component-wise standard deviation of the simplex (signal) to that of the noise vector. This result solves an important open problem in this area of research, and shows as long as $\mathrm{SNR}\ge\Omega\left(\sqrt{K}\right)$ the sample complexity of the noisy regime has the same order to that of the noiseless case. Our proofs are a combination of the so-called sample compression technique in (Ashtiani et al., 2018), mathematical tools from high-dimensional geometry, and Fourier analysis. In particular, we have proposed a general Fourier-based technique for recovery of a more general class of distribution families from additive Gaussian noise, which can be further used in a variety of other related problems.

**摘要:** 本文提出了从噪声样本中学习单元的样品复杂度边界。给出了大小$n$的数据集,其中包含i.i.d.样品从未知任意单元上的均匀分布中抽取,其中样品被假定是被任意大小的多变量加法高斯噪声损坏的。我们证明了具有高概率输出一个具有最多$\varepsilon$距离的单元(对于任何$\varepsilon>0$)的算法的存在。该结果解决了这一领域的重要开放问题,并表明,只要$\mathrm{SNR}\ge\Omega\left(\sqrt{K}\right)$的噪声模式的样品复杂度与无噪声模式的样品复杂度相同。我们的证明是(Ashtiani et al., 2018)的所谓样品压缩技术、高维几何学的数学工具和傅立叶分析的结合。

**[Paper URL](https://proceedings.mlr.press/v202/saberi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/saberi23a/saberi23a.pdf)** 

# Global Selection of Contrastive Batches via Optimization on Sample Permutations
**题目:** 通过优化样品变换的对比批量全球选择

**作者:** Vin Sachidananda, Ziyi Yang, Chenguang Zhu

**Abstract:** Contrastive Learning has recently achieved state-of-the-art performance in a wide range of unimodal and multimodal tasks. Many contrastive learning approaches use mined hard negatives to make batches more informative during training but these approaches are inefficient as they increase epoch length proportional to the number of mined negatives and require frequent updates of nearest neighbor indices or mining from recent batches. In this work, we provide an alternative to hard negative mining, Global Contrastive Batch Sampling (GCBS), an efficient approximation to the batch assignment problem that upper bounds the gap between the global and training losses, $\mathcal{L}^{Global} - \mathcal{L}^{Train}$, in contrastive learning settings. Through experimentation we find GCBS improves state-of-the-art performance in sentence embedding and code-search tasks. Additionally, GCBS is easy to implement as it requires only a few additional lines of code, does not maintain external data structures such as nearest neighbor indices, is more computationally efficient than the most minimal hard negative mining approaches, and makes no changes to the model being trained. Code is available at https://github.com/vinayak1/GCBS.

**摘要:** 反向学习最近在广泛的单模和多模任务中取得了最先进的性能。许多反向学习方法使用采矿的硬负体,在训练过程中使批量更具信息性,但这些方法是无效的,因为它们增加了采矿的负体数量比例的年代长度,并且需要经常更新最近批量最近的邻近指数或采矿。在这个工作中,我们为硬负体采矿提供了一个替代方案,即全球反向批量抽样(GCBS)。此外,GCBS是易于实现的,因为它只需要少数额外的代码行,不维护外部数据结构,如最近的邻近指数,比最微小的硬负矿方法更具有计算效率,并且不会对正在训练的模型进行任何变化。

**[Paper URL](https://proceedings.mlr.press/v202/sachidananda23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sachidananda23a/sachidananda23a.pdf)** 

# High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance
**题目:** 随机优化与变量不平等的高概率边界:无界变量案例

**作者:** Abdurakhmon Sadiev, Marina Danilova, Eduard Gorbunov, Samuel Horváth, Gauthier Gidel, Pavel Dvurechensky, Alexander Gasnikov, Peter Richtárik

**Abstract:** During the recent years the interest of optimization and machine learning communities in high-probability convergence of stochastic optimization methods has been growing. One of the main reasons for this is that high-probability complexity bounds are more accurate and less studied than in-expectation ones. However, SOTA high-probability non-asymptotic convergence results are derived under strong assumptions such as boundedness of the gradient noise variance or of the objective’s gradient itself. In this paper, we propose several algorithms with high-probability convergence results under less restrictive assumptions. In particular, we derive new high-probability convergence results under the assumption that the gradient/operator noise has bounded central $\alpha$-th moment for $\alpha \in (1,2]$ in the following setups: (i) smooth non-convex / Polyak-Lojasiewicz / convex / strongly convex / quasi-strongly convex minimization problems, (ii) Lipschitz / star-cocoercive and monotone / quasi-strongly monotone variational inequalities. These results justify the usage of the considered methods for solving problems that do not fit standard functional classes studied in stochastic optimization.

**摘要:** 近年来,优化和机器学习社区对随机优化方法的高概率融合的兴趣日益增加,其中一个主要原因是高概率复杂度边界比预期边界更精确、较少研究。然而,SOTA高概率非渐近融合结果是基于强的假设,例如梯度噪声差的边界或目标梯度本身的边界。特别是,我们得出新的高概率收敛结果,假设梯度/操作噪声在下列设置中为$\alpha \in (1,2]$界定了中心$\alpha$-th moment: (i)平滑非凸 / Polyak-Lojasiewicz / convex / strongly convex / quasi-strongly convex minimization problems, (ii) Lipschitz / star-cocoercive and monotone / quasi-strongly monotone variational inequalities。

**[Paper URL](https://proceedings.mlr.press/v202/sadiev23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sadiev23a/sadiev23a.pdf)** 

# End-to-end Differentiable Clustering with Associative Memories
**题目:** 与关联记忆的end-to-end区分集群

**作者:** Bishwajit Saha, Dmitry Krotov, Mohammed J Zaki, Parikshit Ram

**Abstract:** Clustering is a widely used unsupervised learning technique involving an intensive discrete optimization problem. Associative Memory models or AMs are differentiable neural networks defining a recursive dynamical system, which have been integrated with various deep learning architectures. We uncover a novel connection between the AM dynamics and the inherent discrete assignment necessary in clustering to propose a novel unconstrained continuous relaxation of the discrete clustering problem, enabling end-to-end differentiable clustering with AM, dubbed ClAM. Leveraging the pattern completion ability of AMs, we further develop a novel self-supervised clustering loss. Our evaluations on varied datasets demonstrate that ClAM benefits from the self-supervision, and significantly improves upon both the traditional Lloyd’s k-means algorithm, and more recent continuous clustering relaxations (by upto 60% in terms of the Silhouette Coefficient).

**摘要:** 聚类是一种广泛应用的无监督学习技术,涉及密集的离散优化问题。关联记忆模型或AM是可区分的神经网络,定义了递归动力学系统,并与各种深层次学习架构结合起来。我们揭示了AM动力学与聚类中所必需的固有离散分配之间的新联系,以提出离散聚类问题的新无约束的连续放松,使与AM的端到端可区分的聚类,称为ClAM。利用AM的模式完成能力,我们进一步发展了一个新自监督聚类损失。

**[Paper URL](https://proceedings.mlr.press/v202/saha23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/saha23a/saha23a.pdf)** 

# Learning to Suggest Breaks: Sustainable Optimization of Long-Term User Engagement
**题目:** 学习建议休息:长期用户参与的可持续优化

**作者:** Eden Saig, Nir Rosenfeld

**Abstract:** Optimizing user engagement is a key goal for modern recommendation systems, but blindly pushing users towards increased consumption risks burn-out, churn, or even addictive habits. To promote digital well-being, most platforms now offer a service that periodically prompts users to take breaks. These, however, must be set up manually, and so may be suboptimal for both users and the system. In this paper, we study the role of breaks in recommendation, and propose a framework for learning optimal breaking policies that promote and sustain long-term engagement. Based on the notion that recommendation dynamics are susceptible to both positive and negative feedback, we cast recommendation as a Lotka-Volterra dynamical system, where breaking reduces to a problem of optimal control. We then give an efficient learning algorithm, provide theoretical guarantees, and empirically demonstrate the utility of our approach on semi-synthetic data.

**摘要:** 优化用户参与是现代推荐系统的关键目标,但盲目推向增加消费风险的用户会消耗、乱七八糟甚至导致中毒习惯。为了促进数字幸福,大多数平台现在提供定期促使用户采取休息的服务。然而,这些服务必须手动设置,因此对于用户和系统都可能不适宜。本论文,我们研究了建议中休息的作用,并提出一种学习最佳断裂政策的框架,以促进和维持长期的参与。

**[Paper URL](https://proceedings.mlr.press/v202/saig23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/saig23a/saig23a.pdf)** 

# Multi-class Graph Clustering via Approximated Effective $p$-Resistance
**题目:** 通过近似有效的$p$-阻抗实现多类图形集群

**作者:** Shota Saito, Mark Herbster

**Abstract:** This paper develops an approximation to the (effective) $p$-resistance and applies it to multi-class clustering. Spectral methods based on the graph Laplacian and its generalization to the graph $p$-Laplacian have been a backbone of non-euclidean clustering techniques. The advantage of the $p$-Laplacian is that the parameter $p$ induces a controllable bias on cluster structure. The drawback of $p$-Laplacian eigenvector based methods is that the third and higher eigenvectors are difficult to compute. Thus, instead, we are motivated to use the $p$-resistance induced by the $p$-Laplacian for clustering. For $p$-resistance, small $p$ biases towards clusters with high internal connectivity while large $p$ biases towards clusters of small “extent,” that is a preference for smaller shortest-path distances between vertices in the cluster. However, the $p$-resistance is expensive to compute. We overcome this by developing an approximation to the $p$-resistance. We prove upper and lower bounds on this approximation and observe that it is exact when the graph is a tree. We also provide theoretical justification for the use of $p$-resistance for clustering. Finally, we provide experiments comparing our approximated $p$-resistance clustering to other $p$-Laplacian based methods.

**摘要:** 基于拉普拉西亚图的光谱方法及其对拉普拉西亚图的一般化是非欧几里德聚类技术的一个支柱。拉普拉西亚的优点是,参数$p$在聚类结构上诱导可控偏差。拉普拉西亚特征向量方法的缺点是,第三个和更高的特征向量很难计算。因此,我们被动于使用由拉普拉西亚引起的聚类的$p$-抵抗。我们证明了这个近似的上界和下界,并观察到当图为树时,它是准确的。我们还为使用$p$-耐群提供了理论依据。最后,我们提供了比较我们近似的$p$-耐群与其他$p$-拉普拉斯基方法的实验。

**[Paper URL](https://proceedings.mlr.press/v202/saito23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/saito23a/saito23a.pdf)** 

# Off-Policy Evaluation for Large Action Spaces via Conjunct Effect Modeling
**题目:** 通过联合效应建模对大型行动空间的非政策评价

**作者:** Yuta Saito, Qingyang Ren, Thorsten Joachims

**Abstract:** We study off-policy evaluation (OPE) of contextual bandit policies for large discrete action spaces where conventional importance-weighting approaches suffer from excessive variance. To circumvent this variance issue, we propose a new estimator, called OffCEM, that is based on the conjunct effect model (CEM), a novel decomposition of the causal effect into a cluster effect and a residual effect. OffCEM applies importance weighting only to action clusters and addresses the residual causal effect through model-based reward estimation. We show that the proposed estimator is unbiased under a new assumption, called local correctness, which only requires that the residual-effect model preserves the relative expected reward differences of the actions within each cluster. To best leverage the CEM and local correctness, we also propose a new two-step procedure for performing model-based estimation that minimizes bias in the first step and variance in the second step. We find that the resulting OffCEM estimator substantially improves bias and variance compared to a range of conventional estimators. Experiments demonstrate that OffCEM provides substantial improvements in OPE especially in the presence of many actions.

**摘要:** 本文研究了基于关联效应模型(CEM)的非策略评估(off-policy evaluation,OPE)对大型离散行动空间的上下文带点政策,其中传统的重要性权衡方法 suffer from excessive variance。为了回避这种 variance问题,我们提出了一种基于关联效应模型(Conjunct effect model,CEM)的新估计方法,即将因果效应分解为集群效应和剩余效应。 OffCEM仅适用于行动集群,并通过基于模型的奖励估计处理剩余的因果效应。结果表明,该 OffCEM 估计器与传统估计器相比,大大改善了偏差和差异,实验表明, OffCEM 对 OPE 提供 了 重大 的 改进,特别是 在 许多 行动 的 场合 。

**[Paper URL](https://proceedings.mlr.press/v202/saito23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/saito23b/saito23b.pdf)** 

# Rethinking Warm-Starts with Predictions: Learning Predictions Close to Sets of Optimal Solutions for Faster $\text{L}$-/$\text{L}^\natural$-Convex Function Minimization
**题目:** 重新思考温和的开始与预测:学习预测接近更快的优化解决方案集

**作者:** Shinsaku Sakaue, Taihei Oki

**Abstract:** An emerging line of work has shown that machine-learned predictions are useful to warm-start algorithms for discrete optimization problems, such as bipartite matching. Previous studies have shown time complexity bounds proportional to some distance between a prediction and an optimal solution, which we can approximately minimize by learning predictions from past optimal solutions. However, such guarantees may not be meaningful when multiple optimal solutions exist. Indeed, the dual problem of bipartite matching and, more generally, $\text{L}$-/$\text{L}^\\natural$-convex function minimization have arbitrarily many optimal solutions, making such prediction-dependent bounds arbitrarily large. To resolve this theoretically critical issue, we present a new warm-start-with-prediction framework for $\text{L}$-/$\text{L}^\\natural$-convex function minimization. Our framework offers time complexity bounds proportional to the distance between a prediction and the set of all optimal solutions. The main technical difficulty lies in learning predictions that are provably close to sets of all optimal solutions, for which we present an online-gradient-descent-based method. We thus give the first polynomial-time learnability of predictions that can provably warm-start algorithms regardless of multiple optimal solutions.

**摘要:** 研究表明,机器学习的预测对于离散优化问题,如双方匹配,有用。以前的研究表明,预测和最佳解决方案之间的距离相对于时间复杂度的边界,我们可以通过从过去最佳解决方案学习的预测来尽量减少。然而,当多个最佳解决方案存在时,这样的保证可能并不有意义。事实上,双方匹配的双重问题和更一般地说,自然凸函数最小化具有任意的许多最佳解决方案,使得这种预测依赖的边界是任意大的。主要技术困难在于学习可证明接近所有最佳解决方案的预测,为此,我们提出了基于在线梯度降落的方法,从而给出了能够证明可证明的热启动算法的预测的第一个多项式时间学习性,不影响多个最佳解决方案。

**[Paper URL](https://proceedings.mlr.press/v202/sakaue23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sakaue23a/sakaue23a.pdf)** 

# PAC-Bayesian Offline Contextual Bandits With Guarantees
**题目:** PAC-Bayesian 非线性背景盗窃带保证

**作者:** Otmane Sakhi, Pierre Alquier, Nicolas Chopin

**Abstract:** This paper introduces a new principled approach for off-policy learning in contextual bandits. Unlike previous work, our approach does not derive learning principles from intractable or loose bounds. We analyse the problem through the PAC-Bayesian lens, interpreting policies as mixtures of decision rules. This allows us to propose novel generalization bounds and provide tractable algorithms to optimize them. We prove that the derived bounds are tighter than their competitors, and can be optimized directly to confidently improve upon the logging policy offline. Our approach learns policies with guarantees, uses all available data and does not require tuning additional hyperparameters on held-out sets. We demonstrate through extensive experiments the effectiveness of our approach in providing performance guarantees in practical scenarios.

**摘要:** 本文介绍了基于上下文带子的非政策学习的新原理方法。与以往的工作不同,我们的方法不从不可解决或松散的边界中提取学习原则。我们通过PAC-Bayesian镜头分析问题,将政策解释为决策规则的混合物。这允许我们提出新的一般化边界,并提供可调解的算法,以优化它们。我们证明,导出的边界比其竞争对手更紧,并且可以直接优化,以自信地改善 Logging Policy offline。

**[Paper URL](https://proceedings.mlr.press/v202/sakhi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sakhi23a/sakhi23a.pdf)** 

# Provably and Practically Efficient Neural Contextual Bandits
**题目:** 可行的和实际有效的神经背景麻醉品

**作者:** Sudeep Salgia

**Abstract:** We consider the neural contextual bandit problem. In contrast to the existing work which primarily focuses on ReLU neural nets, we consider a general set of smooth activation functions. Under this more general setting, (i) we derive non-asymptotic error bounds on the difference between an overparameterized neural net and its corresponding neural tangent kernel, (ii) we propose an algorithm with a provable sublinear regret bound that is also efficient in the finite regime as demonstrated by empirical studies. The non-asymptotic error bounds may be of broader interests as a tool to establish the relation between the smoothness of the activation functions in neural contextual bandits and the smoothness of the kernels in kernel bandits.

**摘要:** 我们考虑了神经上下文带子问题。与目前主要集中在ReLU神经网络的现有工作相比,我们考虑了一种平滑激活函数的一般集合。在这一较一般的设置下,(i)我们推导了超参数化神经网络与相应的神经有形核之间的差异的非渐近误差边界,(ii)我们提出了一种具有可证明的次线性遗憾边界的算法,该算法在有限系统中也是有效的,正如经验研究所证明的。

**[Paper URL](https://proceedings.mlr.press/v202/salgia23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/salgia23a/salgia23a.pdf)** 

# Distributed Linear Bandits under Communication Constraints
**题目:** 在通信限制下分布的线性带子

**作者:** Sudeep Salgia, Qing Zhao

**Abstract:** We consider distributed linear bandits where $M$ agents learn collaboratively to minimize the overall cumulative regret incurred by all agents. Information exchange is facilitated by a central server, and both the uplink and downlink communications are carried over channels with fixed capacity, which limits the amount of information that can be transmitted in each use of the channels. We investigate the regret-communication trade-off by (i) establishing information-theoretic lower bounds on the required communications (in terms of bits) for achieving a sublinear regret order; (ii) developing an efficient algorithm that achieves the minimum sublinear regret order offered by centralized learning using the minimum order of communications dictated by the information-theoretic lower bounds. For sparse linear bandits, we show a variant of the proposed algorithm offers better regret-communication trade-off by leveraging the sparsity of the problem.

**摘要:** 我们考虑分布式线性带子,其中$M$代理人协同学习,尽量减少所有代理人所造成的总累积遗憾。信息交换由中央服务器提供,并且上链路和下链路的通信都通过具有固定容量的通道进行,这限制了在各通道中传输的信息的数量。我们通过(i)建立信息理论下边界(在位数上)实现次线性遗憾顺序的所需通信(以取得次线性遗憾顺序)来研究 regret-communication trade-off;(ii)开发一个有效的算法,以利用信息理论下边界所指示的通信的最小顺序提供最小次线性遗憾顺序。

**[Paper URL](https://proceedings.mlr.press/v202/salgia23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/salgia23b/salgia23b.pdf)** 

# Optimizing Hyperparameters with Conformal Quantile Regression
**题目:** 用符合量子回归优化超参数

**作者:** David Salinas, Jacek Golebiowski, Aaron Klein, Matthias Seeger, Cedric Archambeau

**Abstract:** Many state-of-the-art hyperparameter optimization (HPO) algorithms rely on model-based optimizers that learn surrogate models of the target function to guide the search. Gaussian processes are the de facto surrogate model due to their ability to capture uncertainty. However, they make strong assumptions about the observation noise, which might not be warranted in practice. In this work, we propose to leverage conformalized quantile regression which makes minimal assumptions about the observation noise and, as a result, models the target function in a more realistic and robust fashion which translates to quicker HPO convergence on empirical benchmarks. To apply our method in a multi-fidelity setting, we propose a simple, yet effective, technique that aggregates observed results across different resource levels and outperforms conventional methods across many empirical tasks.

**摘要:** 许多最先进的超参数优化(HPO)算法依靠基于模型的优化器学习目标函数的替代模型来指导搜索。高斯过程是由于它们捕捉不确定性的能力而成为事实上的替代模型。然而,它们对观察噪声作出强的假设,这在实践中可能不成立。在这个工作中,我们提议利用对观察噪声作出最小假设的 konformized quantile regression,以更现实和强有力的方式模拟目标函数,从而使HPO在实证基准上更快速地趋同。

**[Paper URL](https://proceedings.mlr.press/v202/salinas23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/salinas23a/salinas23a.pdf)** 

# Raising the Cost of Malicious AI-Powered Image Editing
**题目:** 恶意AI驱动图像编辑的成本提高

**作者:** Hadi Salman, Alaa Khaddaj, Guillaume Leclerc, Andrew Ilyas, Aleksander Madry

**Abstract:** We present an approach to mitigating the risks of malicious image editing posed by large diffusion models. The key idea is to immunize images so as to make them resistant to manipulation by these models. This immunization relies on injection of imperceptible adversarial perturbations designed to disrupt the operation of the targeted diffusion models, forcing them to generate unrealistic images. We provide two methods for crafting such perturbations, and then demonstrate their efficacy. Finally, we discuss a policy component necessary to make our approach fully effective and practical—one that involves the organizations developing diffusion models, rather than individual users, to implement (and support) the immunization process.

**摘要:** 我们提出了一种方法来减轻大型扩散模型所造成的恶意图像编辑风险。关键思想是免疫图像以使其抵御这些模型的操作。这种免疫依赖于对目标扩散模型的操作进行破坏,迫使它们产生不现实的图像。我们提供了两种方法来制订这种扰动,然后证明它们的有效性。最后,我们讨论了一个必要的政策组成部分,使我们的方法完全有效和实用—一个涉及组织开发扩散模型,而不是个别用户,实现(和支持)免疫过程。

**[Paper URL](https://proceedings.mlr.press/v202/salman23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/salman23a/salman23a.pdf)** 

# Fast, Differentiable and Sparse Top-k: a Convex Analysis Perspective
**题目:** 快速、可辨别和省略 Top-k:一个凸分析视角

**作者:** Michael Eli Sander, Joan Puigcerver, Josip Djolonga, Gabriel Peyré, Mathieu Blondel

**Abstract:** The top-$k$ operator returns a $k$-sparse vector, where the non-zero values correspond to the $k$ largest values of the input. Unfortunately, because it is a discontinuous function, it is difficult to incorporate in neural networks trained end-to-end with backpropagation. Recent works have considered differentiable relaxations, based either on regularization or perturbation techniques. However, to date, no approach is fully differentiable and sparse. In this paper, we propose new differentiable and sparse top-$k$ operators. We view the top-$k$ operator as a linear program over the permutahedron, the convex hull of permutations. We then introduce a $p$-norm regularization term to smooth out the operator, and show that its computation can be reduced to isotonic optimization. Our framework is significantly more general than the existing one and allows for example to express top-$k$ operators that select values in magnitude. On the algorithmic side, in addition to pool adjacent violator (PAV) algorithms, we propose a new GPU/TPU-friendly Dykstra algorithm to solve isotonic optimization problems. We successfully use our operators to prune weights in neural networks, to fine-tune vision transformers, and as a router in sparse mixture of experts.

**摘要:** 顶端$k$算子返回$k$-稀释矢量,其中非零值与输入的最大值相符。不幸的是,由于它是不连续函数,很难在神经网络中训练的末端到末端以后向推进方式结合。最近的工作已经考虑了可区分的松弛, either based on regularization or perturbation techniques。然而,到目前为止,没有方法完全可区分和稀释。在算法方面,除了 Pool adjacent violator(PAV)算法之外,我们还提出了一种新的 GPU/TPU友好的Diskstra算法来解决同位素优化问题。

**[Paper URL](https://proceedings.mlr.press/v202/sander23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sander23a/sander23a.pdf)** 

# TAN Without a Burn: Scaling Laws of DP-SGD
**题目:** 无燃烧的 TAN:DP-SGD的尺度法则

**作者:** Tom Sander, Pierre Stock, Alexandre Sablayrolles

**Abstract:** Differentially Private methods for training Deep Neural Networks (DNNs) have progressed recently, in particular with the use of massive batches and aggregated data augmentations for a large number of training steps. These techniques require much more computing resources than their non-private counterparts, shifting the traditional privacy-accuracy trade-off to a privacy-accuracy-compute trade-off and making hyper-parameter search virtually impossible for realistic scenarios. In this work, we decouple privacy analysis and experimental behavior of noisy training to explore the trade-off with minimal computational requirements. We first use the tools of Renyi Differential Privacy (RDP) to highlight that the privacy budget, when not overcharged, only depends on the total amount of noise (TAN) injected throughout training. We then derive scaling laws for training models with DP-SGD to optimize hyper-parameters with more than a $100\times$ reduction in computational budget. We apply the proposed method on CIFAR-10 and ImageNet and, in particular, strongly improve the state-of-the-art on ImageNet with a $+9$ points gain in top-1 accuracy for a privacy budget $\varepsilon=8$.

**摘要:** 深度神经网络(DNNs)的训练方法在最近有所进步,特别是在大量批量和大量训练步骤的aggregated data augmentations上。这些技术需要比非私人对手的计算资源多得多,将传统的隐私-准确权衡转移到隐私-准确-计算权衡,使得超参数搜索几乎不可能实现现实场景。在这个工作中,我们分离了噪声训练的隐私分析和实验行为,以探索与最小计算要求的权衡。我们首先使用Renyi的差异性隐私(RDP)工具来强调,当不超负荷时,隐私预算只取决于整个训练中注入的总噪音量(TAN)。我们将提议的方法应用于CIFAR-10和ImageNet,并特别加强在ImageNet上的最新技术,在隐私预算$\varepsilon=8$上获得$+9$的最高-1精度。

**[Paper URL](https://proceedings.mlr.press/v202/sander23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sander23b/sander23b.pdf)** 

# Discrete Continuous Optimization Framework for Simultaneous Clustering and Training in Mixture Models
**题目:** 混合模型同时集群和训练的离散连续优化框架

**作者:** Parth Vipul Sangani, Arjun Shashank Kashettiwar, Pritish Chakraborty, Bhuvan Reddy Gangula, Durga S, Ganesh Ramakrishnan, Rishabh K Iyer, Abir De

**Abstract:** We study a new framework of learning mixture models via automatic clustering called PRESTO, wherein we optimize a joint objective function on the model parameters and the partitioning, with each model tailored to perform well on its specific cluster. In contrast to prior work, we do not assume any generative model for the data. We convert our training problem to a joint parameter estimation cum a subset selection problem, subject to a matroid span constraint. This allows us to reduce our problem into a constrained set function minimization problem, where the underlying objective is monotone and approximately submodular. We then propose a new joint discrete-continuous optimization algorithm that achieves a bounded approximation guarantee for our problem. We show that PRESTO outperforms several alternative methods. Finally, we study PRESTO in the context of resource-efficient deep learning, where we train smaller resource-constrained models on each partition and show that it outperforms existing data partitioning and model pruning/knowledge distillation approaches, which in contrast to PRESTO, require large initial (teacher) models.

**摘要:** 我们通过自动集群研究了一种新的学习混合模型框架,即PRESTO,其中我们优化了模型参数和分区上的联合目标函数,每个模型都根据其特定的集群进行优化。与以往的工作不同,我们不假设数据的任何生成模型。我们将我们的训练问题转换为联合参数估计和子集选择问题,并接受了松状分区约束。这允许我们将我们的问题缩小为约束集函数最小化问题,其中基础目标是单调和近似子模态。然后我们提出了一种新的联合离散连续优化算法,实现我们问题的有限近似保证。最后,我们研究了PRESTO在资源高效的深层学习中,在每个分区上训练较小的资源约束模型,并证明它比现有的数据分区和模型剪切/知识蒸馏方法优越,与PRESTO不同,需要大型初始(教师)模型。

**[Paper URL](https://proceedings.mlr.press/v202/sangani23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sangani23a/sangani23a.pdf)** 

# Whose Opinions Do Language Models Reflect?
**题目:** 语言模型反映谁的意见?

**作者:** Shibani Santurkar, Esin Durmus, Faisal Ladhak, Cinoo Lee, Percy Liang, Tatsunori Hashimoto

**Abstract:** Language models (LMs) are increasingly being used in open-ended contexts, where the opinions they reflect in response to subjective queries can have a profound impact, both on user satisfaction, and shaping the views of society at large. We put forth a quantitative framework to investigate the opinions reflected by LMs – by leveraging high-quality public opinion polls. Using this framework, we create OpinionQA, a dataset for evaluating the alignment of LM opinions with those of 60 US demographic groups over topics ranging from abortion to automation. Across topics, we find substantial misalignment between the views reflected by current LMs and those of US demographic groups: on par with the Democrat-Republican divide on climate change. Notably, this misalignment persists even after explicitly steering the LMs towards particular groups. Our analysis not only confirms prior observations about the left-leaning tendencies of some human feedback-tuned LMs, but also surfaces groups whose opinions are poorly reflected by current LMs (e.g., 65+ and widowed individuals).

**摘要:** 语言模型(LMs)越来越多地被用于开放的上下文中,它们对主观查询所反映的意见可以对用户满意度和整个社会的看法产生深远的影响。我们提出了一种量化框架来研究LMs所反映的意见 — — 利用高质量的民意调查。使用这一框架,我们创建了OpinionQA(英语:OpinionQA)(英语:OpinionQA)数据集,用来评估LMs的意见与60个美国人口组的意见在从堕胎到自动化等主题上是否一致。在各个主题中,我们发现当前LMs和美国人口组的观点之间存在着明显的不一致:与民主党和共和党在气候变化方面的分歧相等。我们的分析不仅证实了对某些人反馈调度LM的左倾倾向的初步观察,而且还显示了目前LM(例如65岁以上和寡妇)对他们的意见没有充分反映。

**[Paper URL](https://proceedings.mlr.press/v202/santurkar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/santurkar23a/santurkar23a.pdf)** 

# Streaming Active Learning with Deep Neural Networks
**题目:** 基于深度神经网络的 Streaming Active Learning

**作者:** Akanksha Saran, Safoora Yousefi, Akshay Krishnamurthy, John Langford, Jordan T. Ash

**Abstract:** Active learning is perhaps most naturally posed as an online learning problem. However, prior active learning approaches with deep neural networks assume offline access to the entire dataset ahead of time. This paper proposes VeSSAL, a new algorithm for batch active learning with deep neural networks in streaming settings, which samples groups of points to query for labels at the moment they are encountered. Our approach trades off between uncertainty and diversity of queried samples to match a desired query rate without requiring any hand-tuned hyperparameters. Altogether, we expand the applicability of deep neural networks to realistic active learning scenarios, such as applications relevant to HCI and large, fractured datasets.

**摘要:** 主动学习可能是最自然的在线学习问题。然而,与深度神经网络的主动学习方法提前采取了对整个数据集的非线性访问。本文提出了一种新的基于深神经网络的批量主动学习算法VeSSAL,该算法在流域设置中采样点群以在遇到的标签时查询标记。我们的方法在查询样本的不确定性和多样性之间进行交易,以满足要求的查询率,而不需要任何手调的超参数。

**[Paper URL](https://proceedings.mlr.press/v202/saran23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/saran23a/saran23a.pdf)** 

# Random Teachers are Good Teachers
**题目:** 随机教师是好的教师

**作者:** Felix Sarnthein, Gregor Bachmann, Sotiris Anagnostidis, Thomas Hofmann

**Abstract:** In this work, we investigate the implicit regularization induced by teacher-student learning dynamics in self-distillation. To isolate its effect, we describe a simple experiment where we consider teachers at random initialization instead of trained teachers. Surprisingly, when distilling a student into such a random teacher, we observe that the resulting model and its representations already possess very interesting characteristics; (1) we observe a strong improvement of the distilled student over its teacher in terms of probing accuracy. (2) The learned representations are data-dependent and transferable between different tasks but deteriorate strongly if trained on random inputs. (3) The student checkpoint contains sparse subnetworks, so-called lottery tickets, and lies on the border of linear basins in the supervised loss landscape. These observations have interesting consequences for several important areas in machine learning: (1) Self-distillation can work solely based on the implicit regularization present in the gradient dynamics without relying on any dark knowledge, (2) self-supervised learning can learn features even in the absence of data augmentation and (3) training dynamics during the early phase of supervised training do not necessarily require label information. Finally, we shed light on an intriguing local property of the loss landscape: the process of feature learning is strongly amplified if the student is initialized closely to the teacher. These results raise interesting questions about the nature of the landscape that have remained unexplored so far. Code is available at https://github.com/safelix/dinopl.

**摘要:** 本文研究了自蒸馏过程中教师-学生学习动力学诱导的隐性正则化。为了分离其效果,我们描述了一个简单的实验,在实验中,我们考虑教师的随机初始化,而不是经过训练的教师。令人吃惊的是,当蒸馏学生成为这样的随机教师时,我们观察到结果模型及其表现具有非常有趣的特征;(1)我们观察到蒸馏学生在探测精度方面比其教师的显著提高;(2)学习的表现是数据依赖的,在不同任务之间可转移的,但在经过训练的随机输入时会严重恶化。这些观察对机器学习中的几个重要领域产生了有趣的影响: (1)自蒸馏可以完全基于在梯度动力学中存在的隐性调节,而不依赖任何暗知识,(2)自监督学习甚至在数据增加的缺失的情况下也能学习特征,而(3)在监督训练的早期阶段的训练动力学不一定需要标签信息。

**[Paper URL](https://proceedings.mlr.press/v202/sarnthein23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sarnthein23a/sarnthein23a.pdf)** 

# Posterior Sampling for Deep Reinforcement Learning
**题目:** 深强化学习后样本

**作者:** Remo Sasso, Michelangelo Conserva, Paulo Rauber

**Abstract:** Despite remarkable successes, deep reinforcement learning algorithms remain sample inefficient: they require an enormous amount of trial and error to find good policies. Model-based algorithms promise sample efficiency by building an environment model that can be used for planning. Posterior Sampling for Reinforcement Learning is such a model-based algorithm that has attracted significant interest due to its performance in the tabular setting. This paper introduces Posterior Sampling for Deep Reinforcement Learning (PSDRL), the first truly scalable approximation of Posterior Sampling for Reinforcement Learning that retains its model-based essence. PSDRL combines efficient uncertainty quantification over latent state space models with a specially tailored incremental planning algorithm based on value-function approximation. Extensive experiments on the Atari benchmark show that PSDRL significantly outperforms previous state-of-the-art attempts at scaling up posterior sampling while being competitive with a state-of-the-art (model-based) reinforcement learning method, both in sample efficiency and computational efficiency.

**摘要:** 尽管取得了显著的成功,深层强化学习算法仍保持样本效率低:它们需要大量的尝试和误差来寻找良好的政策。基于模型的算法通过建立环境模型来保证样本效率,可以用于规划。深层强化学习的后置采样是一种基于模型的算法,由于其在表格设置中的性能引起了大量兴趣。本论文介绍了深层强化学习的后置采样(PSDRL),它保留了其基于模型的本质,是深层强化学习的第一个真正可扩展的近似。 PSDRL结合了基于价值函数近似的特别定制的渐进规划算法,对潜在状态空间模型的有效不确定性量化。对Atari基准的广泛实验表明,PSDRL在样本效率和计算效率方面大大超过了以往的最先进的尝试,同时与最先进的(基于模型的)增强学习方法竞争。

**[Paper URL](https://proceedings.mlr.press/v202/sasso23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sasso23a/sasso23a.pdf)** 

# Graph Neural Networks can Recover the Hidden Features Solely from the Graph Structure
**题目:** 图神经网络只能从图结构中恢复隐藏特征

**作者:** Ryoma Sato

**Abstract:** Graph Neural Networks (GNNs) are popular models for graph learning problems. GNNs show strong empirical performance in many practical tasks. However, the theoretical properties have not been completely elucidated. In this paper, we investigate whether GNNs can exploit the graph structure from the perspective of the expressive power of GNNs. In our analysis, we consider graph generation processes that are controlled by hidden (or latent) node features, which contain all information about the graph structure. A typical example of this framework is kNN graphs constructed from the hidden features. In our main results, we show that GNNs can recover the hidden node features from the input graph alone, even when all node features, including the hidden features themselves and any indirect hints, are unavailable. GNNs can further use the recovered node features for downstream tasks. These results show that GNNs can fully exploit the graph structure by themselves, and in effect, GNNs can use both the hidden and explicit node features for downstream tasks. In the experiments, we confirm the validity of our results by showing that GNNs can accurately recover the hidden features using a GNN architecture built based on our theoretical analysis.

**摘要:** 图神经网络(英语:Graph Neural Networks,缩写为GNN)是图学习问题的流行模型。GNN在许多实际任务中表现出强有力的实验性能。然而,理论属性尚未完全解释。本论文中,我们研究GNN是否能够从GNN的表达能力的角度利用图结构。在分析中,我们考虑由隐藏(或隐匿)节点特征控制的图生成过程,这些过程包含了关于图结构的所有信息。该框架的典型例子是由隐藏特征构建的kNN图。这些结果表明,GNN可以自行充分利用图结构,并且实际上,GNN可以利用隐藏和显式节点功能进行下游任务。在实验中,我们通过证明GNN能够准确地恢复隐藏的功能,证实了我们的结果的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/sato23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sato23a/sato23a.pdf)** 

# Existence and Estimation of Critical Batch Size for Training Generative Adversarial Networks with Two Time-Scale Update Rule
**题目:** 基于两个时间尺度更新规则训练产生敌对网络的关键批量大小的存在与估算

**作者:** Naoki Sato, Hideaki Iiduka

**Abstract:** Previous results have shown that a two time-scale update rule (TTUR) using different learning rates, such as different constant rates or different decaying rates, is useful for training generative adversarial networks (GANs) in theory and in practice. Moreover, not only the learning rate but also the batch size is important for training GANs with TTURs and they both affect the number of steps needed for training. This paper studies the relationship between batch size and the number of steps needed for training GANs with TTURs based on constant learning rates. We theoretically show that, for a TTUR with constant learning rates, the number of steps needed to find stationary points of the loss functions of both the discriminator and generator decreases as the batch size increases and that there exists a critical batch size minimizing the stochastic first-order oracle (SFO) complexity. Then, we use the Fréchet inception distance (FID) as the performance measure for training and provide numerical results indicating that the number of steps needed to achieve a low FID score decreases as the batch size increases and that the SFO complexity increases once the batch size exceeds the measured critical batch size. Moreover, we show that measured critical batch sizes are close to the sizes estimated from our theoretical results.

**摘要:** 结果表明,利用不同学习速率,例如不同常率或不同衰减速率的两个时间尺度更新规则在理论和实践中对生成敌对网络(GAN)的训练有用。此外,不仅学习速率,而且批量大小对GAN和TTUR的训练有重要意义,而且两者都影响训练所需的步骤数目。本文基于常 learning速率研究了批量大小与GAN和TTUR的训练所需的步骤数目之间的关系。然后,我们使用弗雷切开始距离(Fréchet inception distance,FID)作为训练的性能指标,并提供数值结果,表明随着批量大小的增加,达到低FID分数所需的步骤数目减少,并且一旦批量大小超过了测量的临界批量大小,SFO的复杂性增加。

**[Paper URL](https://proceedings.mlr.press/v202/sato23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sato23b/sato23b.pdf)** 

# StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis
**题目:** StyleGAN-T:快速大尺度文本到图像合成的GAN功能解锁

**作者:** Axel Sauer, Tero Karras, Samuli Laine, Andreas Geiger, Timo Aila

**Abstract:** Text-to-image synthesis has recently seen significant progress thanks to large pretrained language models, large-scale training data, and the introduction of scalable model families such as diffusion and autoregressive models. However, the best-performing models require iterative evaluation to generate a single sample. In contrast, generative adversarial networks (GANs) only need a single forward pass. They are thus much faster, but they currently remain far behind the state-of-the-art in large-scale text-to-image synthesis. This paper aims to identify the necessary steps to regain competitiveness. Our proposed model, StyleGAN-T, addresses the specific requirements of large-scale text-to-image synthesis, such as large capacity, stable training on diverse datasets, strong text alignment, and controllable variation vs. text alignment tradeoff. StyleGAN-T significantly improves over previous GANs and outperforms distilled diffusion models - the previous state-of-the-art in fast text-to-image synthesis - in terms of sample quality and speed.

**摘要:** 文本对图像的合成最近由于大型预制语言模型、大规模训练数据以及扩散和自回归模型等可扩展模型家族的引入,取得了重大进展。然而,最佳的模型需要迭代评价来生成单个样本。相反,生成敌对网络(GANs)只需要一个向前通行。因此,它们比以往更快,但目前仍远远落后于大规模文本对图像的合成技术。本论文旨在确定恢复竞争力的必要步骤。StyleGAN-T在样品质量和速度方面明显优于以前的GAN,并且超过了蒸馏扩散模型--在快速文本--图像合成方面的前卫技术。

**[Paper URL](https://proceedings.mlr.press/v202/sauer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sauer23a/sauer23a.pdf)** 

# Facial Expression Recognition with Adaptive Frame Rate based on Multiple Testing Correction
**题目:** 基于多测试校正的自适应帧速率的面部表情识别

**作者:** Andrey Savchenko

**Abstract:** In this paper, we consider the problem of the high computational complexity of video-based facial expression recognition. A novel sequential procedure is proposed with an adaptive frame rate selection in a short video fragment to speed up decision-making. We automatically adjust the frame rate and process fewer frames with a low frame rate for more straightforward videos and more frames for complex ones. To determine the frame rate at which an inference is sufficiently reliable, the Benjamini-Hochberg procedure from multiple comparisons theory is employed to control the false discovery rate. The main advantages of our method are an improvement of the trustworthiness of decision-making by maintaining only one hyper-parameter (false acceptance rate) and its applicability with arbitrary neural network models used as facial feature extractors without the need to re-train these models. An experimental study on datasets from ABAW and EmotiW challenges proves the superior performance (1.5-40 times faster) of the proposed approach compared to processing all frames and existing techniques with early exiting and adaptive frame selection.

**摘要:** 本文研究了基于视频的面部表情识别的高计算复杂性问题,提出了一种新的序列处理方法,即在短视频片段中采用自适应帧速率选择来加快决策。我们自动调整帧速率,以较低的帧速率处理较直观的视频和较复杂的视频的较少的帧速率。为了确定一个结论足够可靠的帧速率,采用比喻理论的Benjamini-Hochberg程序来控制错误发现速率。本方法的主要优点是通过保持一个超参数(错误接受速率)和随机神经网络模型作为面部特征提取器来提高决策的可靠性,而不需要重新训练这些模型。通过对ABAW和EmotiW挑战数据集的实验研究,证明了该方法的优越性能(1.5-40倍更快),与早期退出和适应性帧选择处理的所有帧和现有技术相比。

**[Paper URL](https://proceedings.mlr.press/v202/savchenko23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/savchenko23a/savchenko23a.pdf)** 

# Off-Policy Average Reward Actor-Critic with Deterministic Policy Search
**题目:** 非政策平均奖赏角色-批评者与确定性政策搜索

**作者:** Naman Saxena, Subhojyoti Khastagir, Shishir Kolathaya, Shalabh Bhatnagar

**Abstract:** The average reward criterion is relatively less studied as most existing works in the Reinforcement Learning literature consider the discounted reward criterion. There are few recent works that present on-policy average reward actor-critic algorithms, but average reward off-policy actor-critic is relatively less explored. In this work, we present both on-policy and off-policy deterministic policy gradient theorems for the average reward performance criterion. Using these theorems, we also present an Average Reward Off-Policy Deep Deterministic Policy Gradient (ARO-DDPG) Algorithm. We first show asymptotic convergence analysis using the ODE-based method. Subsequently, we provide a finite time analysis of the resulting stochastic approximation scheme with linear function approximator and obtain an $\epsilon$-optimal stationary policy with a sample complexity of $\Omega(\epsilon^{-2.5})$. We compare the average reward performance of our proposed ARO-DDPG algorithm and observe better empirical performance compared to state-of-the-art on-policy average reward actor-critic algorithms over MuJoCo-based environments.

**摘要:** 中奖标准相对较少研究,因为在强化学习文献中大多数现有作品都考虑了降价奖励标准。目前只有少数在政策中平均奖励角色-关键算法,但在政策中平均奖励角色-关键算法相对较少研究。本研究中,我们为平均奖励性能标准提出了既在政策中又在政策中确定性政策梯度定理。使用这些定理,我们还提出了政策中平均奖励深度确定性政策梯度(ARO-DDPG)算法。我们比较了我们所提议的ARO-DDPG算法的平均奖励性能,并观察到在MuJoCo环境上最先进的平均奖励行动者-关键算法的实证性能。

**[Paper URL](https://proceedings.mlr.press/v202/saxena23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/saxena23a/saxena23a.pdf)** 

# Gibbsian Polar Slice Sampling
**题目:** 吉布西亚极片采样

**作者:** Philip Schär, Michael Habeck, Daniel Rudolf

**Abstract:** Polar slice sampling (Roberts & Rosenthal, 2002) is a Markov chain approach for approximate sampling of distributions that is difficult, if not impossible, to implement efficiently, but behaves provably well with respect to the dimension. By updating the directional and radial components of chain iterates separately, we obtain a family of samplers that mimic polar slice sampling, and yet can be implemented efficiently. Numerical experiments in a variety of settings indicate that our proposed algorithm outperforms the two most closely related approaches, elliptical slice sampling (Murray et al., 2010) and hit-and-run uniform slice sampling (MacKay, 2003). We prove the well-definedness and convergence of our methods under suitable assumptions on the target distribution.

**摘要:** 北极切片采样(Roberts & Rosenthal, 2002)是一种 Markov链式方法,用于近似分布的采样,如果不能有效地实现,但对维度有可证明的良好表现。通过单独迭代链路方向和半径组件的更新,我们得到了一种仿真北极切片采样的样机家族,并且能够有效地实现。在各种环境下进行数值实验表明,我们提出的算法胜过两个最密切相关的方法,即椭圆切片采样(Murray et al., 2010)和击中和运行均匀切片采样(MacKay, 2003)。

**[Paper URL](https://proceedings.mlr.press/v202/schar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/schar23a/schar23a.pdf)** 

# Identifiability and Generalizability in Constrained Inverse Reinforcement Learning
**题目:** 约束逆强化学习中的辨识性和通用性

**作者:** Andreas Schlaginhaufen, Maryam Kamgarpour

**Abstract:** Two main challenges in Reinforcement Learning (RL) are designing appropriate reward functions and ensuring the safety of the learned policy. To address these challenges, we present a theoretical framework for Inverse Reinforcement Learning (IRL) in constrained Markov decision processes. From a convex-analytic perspective, we extend prior results on reward identifiability and generalizability to both the constrained setting and a more general class of regularizations. In particular, we show that identifiability up to potential shaping (Cao et al., 2021) is a consequence of entropy regularization and may generally no longer hold for other regularizations or in the presence of safety constraints. We also show that to ensure generalizability to new transition laws and constraints, the true reward must be identified up to a constant. Additionally, we derive a finite sample guarantee for the suboptimality of the learned rewards, and validate our results in a gridworld environment.

**摘要:** 强化学习的两个主要挑战是设计适当的奖励函数和确保学习政策的安全。为了解决这些挑战,我们在约束的马可夫决策过程中提出了反强化学习(IRL)的理论框架。从凸分析角度,我们对奖励识别性和一般化性的结果扩展到约束的设置和更一般化的规范化类别。特别是,我们显示到潜在的成形(Cao et al., 2021)的识别性是熵规范化的结果,可能不再适用于其他规范化或安全约束的存在。

**[Paper URL](https://proceedings.mlr.press/v202/schlaginhaufen23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/schlaginhaufen23a/schlaginhaufen23a.pdf)** 

# Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks
**题目:** 神经网络的一般化和不确定性估计学习表达优先

**作者:** Dominik Schnaus, Jongseok Lee, Daniel Cremers, Rudolph Triebel

**Abstract:** In this work, we propose a novel prior learning method for advancing generalization and uncertainty estimation in deep neural networks. The key idea is to exploit scalable and structured posteriors of neural networks as informative priors with generalization guarantees. Our learned priors provide expressive probabilistic representations at large scale, like Bayesian counterparts of pre-trained models on ImageNet, and further produce non-vacuous generalization bounds. We also extend this idea to a continual learning framework, where the favorable properties of our priors are desirable. Major enablers are our technical contributions: (1) the sums-of-Kronecker-product computations, and (2) the derivations and optimizations of tractable objectives that lead to improved generalization bounds. Empirically, we exhaustively show the effectiveness of this method for uncertainty estimation and generalization.

**摘要:** 本文提出了一种用于深入神经网络中推广和不确定性估计的新型预先学习方法,其关键思想是利用神经网络的可扩展和结构性后端作为具有推广保证的信息预先。我们的预先提供大规模的表达概率表示,如在ImageNet上预训练模型的贝叶斯对照,并进一步产生非空的推广边界。我们还扩展了这一想法到持续学习框架,其中我们预先的有利特性是可取的。主要的启发者是我们的技术贡献:(一)克罗纳克产品计算的总数,以及(二)导致改进推广边界的可处理目标的推导和优化。

**[Paper URL](https://proceedings.mlr.press/v202/schnaus23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/schnaus23a/schnaus23a.pdf)** 

# Deterministic equivalent and error universality of deep random features learning
**题目:** 深随机特征学习的确定性等价性和误差普遍性

**作者:** Dominik Schröder, Hugo Cui, Daniil Dmitriev, Bruno Loureiro

**Abstract:** This manuscript considers the problem of learning a random Gaussian network function using a fully connected network with frozen intermediate layers and trainable readout layer. This problem can be seen as a natural generalization of the widely studied random features model to deeper architectures. First, we prove Gaussian universality of the test error in a ridge regression setting where the learner and target networks share the same intermediate layers, and provide a sharp asymptotic formula for it. Establishing this result requires proving a deterministic equivalent for traces of the deep random features sample covariance matrices which can be of independent interest. Second, we conjecture the asymptotic Gaussian universality of the test error in the more general setting of arbitrary convex losses and generic learner/target architectures. We provide extensive numerical evidence for this conjecture, which requires the derivation of closed-form expressions for the layer-wise post-activation population covariances. In light of our results, we investigate the interplay between architecture design and implicit regularization.

**摘要:** 本文讨论了使用冷冻中间层和可训练的读取层的完全连接网络学习随机高斯网络函数的问题。该问题可视作广泛研究的随机特征模型对更深层次架构的自然一般化。首先,我们证明了学習者和目标网络共享相同的中间层的山脊回归设置中测试误差的高斯普遍性,并为它提供了一个尖锐的渐近公式。建立此结果需要证明深层次随机特征样本共变矩阵的痕跡具有确定性等价。其次,我们推测了任意凸损失和一般学习者/目标架构中测试误差的渐近高斯普遍性。我们为这一假设提供了广泛的数值证据,要求对层级活性后人口变异的闭式表达式的导出。我们根据我们的结果,研究了建筑设计与隐性规范化之间的相互作用。

**[Paper URL](https://proceedings.mlr.press/v202/schroder23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/schroder23a/schroder23a.pdf)** 

# The Acquisition of Physical Knowledge in Generative Neural Networks
**题目:** 生成神经网络中的物理知识的获取

**作者:** Luca M. Schulze Buschoff, Eric Schulz, Marcel Binz

**Abstract:** As children grow older, they develop an intuitive understanding of the physical processes around them. Their physical understanding develops in stages, moving along developmental trajectories which have been mapped out extensively in previous empirical research. Here, we investigate how the learning trajectories of deep generative neural networks compare to children’s developmental trajectories using physical understanding as a testbed. We outline an approach that allows us to examine two distinct hypotheses of human development – stochastic optimization and complexity increase. We find that while our models are able to accurately predict a number of physical processes, their learning trajectories under both hypotheses do not follow the developmental trajectories of children.

**摘要:** 随着儿童的成长,他们对周围的物理过程产生了直观的理解。他们的物理理解在各个阶段发展起来,沿着先前的实验研究中广泛地绘制的发育轨迹前进。我们研究了如何用物理理解作为测试床来比较深层生成神经网络的学习轨迹与儿童的发展轨迹。我们概述了一种方法,它允许我们研究两个不同的人类发展假设——随机优化和复杂性增加。

**[Paper URL](https://proceedings.mlr.press/v202/schulze-buschoff23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/schulze-buschoff23a/schulze-buschoff23a.pdf)** 

# Modality-Agnostic Variational Compression of Implicit Neural Representations
**题目:** 隐性神经表现的 Modality-Agnostic Variational Compression

**作者:** Jonathan Richard Schwarz, Jihoon Tack, Yee Whye Teh, Jaeho Lee, Jinwoo Shin

**Abstract:** We introduce a modality-agnostic neural compression algorithm based on a functional view of data and parameterised as an Implicit Neural Representation (INR). Bridging the gap between latent coding and sparsity, we obtain compact latent representations non-linearly mapped to a soft gating mechanism. This allows the specialisation of a shared INR network to each data item through subnetwork selection. After obtaining a dataset of such latent representations, we directly optimise the rate/distortion trade-off in a modality-agnostic space using neural compression. Variational Compression of Implicit Neural Representations (VC-INR) shows improved performance given the same representational capacity pre quantisation while also outperforming previous quantisation schemes used for other INR techniques.Our experiments demonstrate strong results over a large set of diverse modalities using the same algorithm without any modality-specific inductive biases. We show results on images, climate data, 3D shapes and scenes as well as audio and video, introducing VC-INR as the first INR-based method to outperform codecs as well-known and diverse as JPEG 2000, MP3 and AVC/HEVC on their respective modalities.

**摘要:** 我们引入一种基于数据的功能视角的模态-误导性神经压缩算法,并将其参数化为隐形神经表示(INR)。通过填补隐形编码与稀疏性之间的差距,我们得到了非线性映射到软测定机制的紧凑的隐形表示。这允许通过分网络选择对每个数据项进行共享INR网络的专门化。我们展示了图像、气候数据、3D形状和场景以及音频和视频的结果,介绍了VC-INR作为第一个基于INR的方法,以其各自的方式超越像JPEG2000、MP3和AVC/HEVC等众所周知和多样的代码。

**[Paper URL](https://proceedings.mlr.press/v202/schwarz23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/schwarz23a/schwarz23a.pdf)** 

# Bigger, Better, Faster: Human-level Atari with human-level efficiency
**题目:** 更大、更好、更快:人类水平的Atari,具有人类水平的效率

**作者:** Max Schwarzer, Johan Samir Obando Ceron, Aaron Courville, Marc G Bellemare, Rishabh Agarwal, Pablo Samuel Castro

**Abstract:** We introduce a value-based RL agent, which we call BBF, that achieves super-human performance in the Atari 100K benchmark. BBF relies on scaling the neural networks used for value estimation, as well as a number of other design choices that enable this scaling in a sample-efficient manner. We conduct extensive analyses of these design choices and provide insights for future work. We end with a discussion about updating the goalposts for sample-efficient RL research on the ALE. We make our code and data publicly available at https://github.com/google-research/google-research/tree/master/bigger_better_faster.

**摘要:** 我们引入了一个基于价值的RL代理,我们称它为BBF,它在Atari100K基准中达到超人性能。BBF依赖于用于价值估计的神经网络的规模化,以及一些其他设计选择,使这种规模化以样本效率的方式进行。我们对这些设计选择进行了广泛分析,并为今后的工作提供洞察。

**[Paper URL](https://proceedings.mlr.press/v202/schwarzer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/schwarzer23a/schwarzer23a.pdf)** 

# Dissecting the Effects of SGD Noise in Distinct Regimes of Deep Learning
**题目:** 深入学习不同模式中SGD噪声影响的探讨

**作者:** Antonio Sclocchi, Mario Geiger, Matthieu Wyart

**Abstract:** Understanding when the noise in stochastic gradient descent (SGD) affects generalization of deep neural networks remains a challenge, complicated by the fact that networks can operate in distinct training regimes. Here we study how the magnitude of this noise $T$ affects performance as the size of the training set $P$ and the scale of initialization $\alpha$ are varied. For gradient descent, $\alpha$ is a key parameter that controls if the network is lazy’ ($\alpha\gg1$) or instead learns features ($\alpha\ll1$). For classification of MNIST and CIFAR10 images, our central results are: *(i)* obtaining phase diagrams for performance in the $(\alpha,T)$ plane. They show that SGD noise can be detrimental or instead useful depending on the training regime. Moreover, although increasing $T$ or decreasing $\alpha$ both allow the net to escape the lazy regime, these changes can have opposite effects on performance. *(ii)* Most importantly, we find that the characteristic temperature $T_c$ where the noise of SGD starts affecting the trained model (and eventually performance) is a power law of $P$. We relate this finding with the observation that key dynamical quantities, such as the total variation of weights during training, depend on both $T$ and $P$ as power laws. These results indicate that a key effect of SGD noise occurs late in training, by affecting the stopping process whereby all data are fitted. Indeed, we argue that due to SGD noise, nets must develop a strongersignal’, i.e. larger informative weights, to fit the data, leading to a longer training time. A stronger signal and a longer training time are also required when the size of the training set $P$ increases. We confirm these views in the perceptron model, where signal and noise can be precisely measured. Interestingly, exponents characterizing the effect of SGD depend on the density of data near the decision boundary, as we explain.

**摘要:** 在随机梯度下降(SGD)中噪声影响深层神经网络的一般化时,理解仍然是一个挑战,因为网络可以在不同的训练模式中进行操作,这里我们研究了这种噪声的大小$T$如何影响训练设置的大小$P$和初始化规模$\alpha$的大小。对于梯度下降,$\alpha$是一个关键参数,它控制网络是否懒惰($\alpha\gg1$)或学习特征($\alpha\ll1$)。*(ii)*最重要的是,我们发现SGD噪声开始影响训练模型(最终性能)的特征温度$T_c$是$P$的功率法则。我们与观察有关,关键动态量,如训练期间的重量的总变化,取决于$T$和$P$的功率法则。这些结果表明SGD噪声的关键效应在训练中发生迟到,通过影响所有数据安装的停止过程。事实上,我们认为由于SGD噪声,网网必须发展一个更强的信号’,即更大的信息量,以适应数据,导致更长的训练时间。有趣的是,描述GDD效应的指数取决于 near the decision boundary 数据密度,我们解释了这一点。

**[Paper URL](https://proceedings.mlr.press/v202/sclocchi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sclocchi23a/sclocchi23a.pdf)** 

# A Fast Optimistic Method for Monotone Variational Inequalities
**题目:** 单调变量不平等的快速优化方法

**作者:** Michael Sedlmayer, Dang-Khoa Nguyen, Radu Ioan Bot

**Abstract:** We study monotone variational inequalities that can arise as optimality conditions for constrained convex optimization or convex-concave minimax problems and propose a novel algorithm that uses only one gradient/operator evaluation and one projection onto the constraint set per iteration. The algorithm, which we call fOGDA-VI, achieves a $o(\frac{1}{k})$ rate of convergence in terms of the restricted gap function as well as the natural residual for the last iterate. Moreover, we provide a convergence guarantee for the sequence of iterates to a solution of the variational inequality. These are the best theoretical convergence results for numerical methods for (only) monotone variational inequalities reported in the literature. To empirically validate our algorithm we investigate a two-player matrix game with mixed strategies of the two players. Concluding, we show promising results regarding the application of fOGDA-VI to the training of generative adversarial nets.

**摘要:** 我们研究了约束凸优化或凸凹最小值问题的单调变量不平等性,并提出了一种新的算法,它只使用一个梯度/操作者评价和一个投影在每次迭代的约束集合上。该算法,我们称之为fOGDA-VI,在有限间隙函数和最后迭代的自然残余方面达到$o(\frac{1}{k})$的收敛率。此外,我们为迭代序列提供了对变量不平等问题的解决方案的收敛保证。这些是文献中报道的单调变量不平等性数值方法的最佳理论收敛结果。为了实证验证我们的算法,我们研究了两个玩家混合策略的双人矩阵游戏。最后,我们给出了关于fOGDA-VI在生成对抗网的训练中的应用前景。

**[Paper URL](https://proceedings.mlr.press/v202/sedlmayer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sedlmayer23a/sedlmayer23a.pdf)** 

# Double-Weighting for Covariate Shift Adaptation
**题目:** 双重权重变换适应

**作者:** José I. Segovia-Martín, Santiago Mazuelas, Anqi Liu

**Abstract:** Supervised learning is often affected by a covariate shift in which the marginal distributions of instances (covariates $x$) of training and testing samples $p_\text{tr}(x)$ and $p_\text{te}(x)$ are different but the label conditionals coincide. Existing approaches address such covariate shift by either using the ratio $p_\text{te}(x)/p_\text{tr}(x)$ to weight training samples (reweighted methods) or using the ratio $p_\text{tr}(x)/p_\text{te}(x)$ to weight testing samples (robust methods). However, the performance of such approaches can be poor under support mismatch or when the above ratios take large values. We propose a minimax risk classification (MRC) approach for covariate shift adaptation that avoids such limitations by weighting both training and testing samples. In addition, we develop effective techniques that obtain both sets of weights and generalize the conventional kernel mean matching method. We provide novel generalization bounds for our method that show a significant increase in the effective sample size compared with reweighted methods. The proposed method also achieves enhanced classification performance in both synthetic and empirical experiments.

**摘要:** 监测学习经常受到训练和测试样品$p_\text{tr}(x)$和$p_\text{te}(x)$实例的边缘分布(covariates $x$)的影响,但标签条件相同。现有的方法可以利用比值$p_\text{te}(x)/p_\text{tr}(x)$对训练样品(重权方法)进行处理,或者使用比值$p_\text{tr}(x)/p_\text{te}(x)$对测试样品(粗糙方法)进行处理。然而,在支持不匹配或上述比值占较大值的情况下,这种方法的性能可能很差。我们为该方法提供了新的一般化界限,显示了与重权方法相比,有效样品尺寸的显著增加。该方法在合成和实证实验中也提高了分类性能。

**[Paper URL](https://proceedings.mlr.press/v202/segovia-martin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/segovia-martin23a/segovia-martin23a.pdf)** 

# Enhancing Activity Prediction Models in Drug Discovery with the Ability to Understand Human Language
**题目:** 提高药物发现活动的预测模型,提高理解人类语言的能力

**作者:** Philipp Seidl, Andreu Vall, Sepp Hochreiter, Günter Klambauer

**Abstract:** Activity and property prediction models are the central workhorses in drug discovery and materials sciences, but currently, they have to be trained or fine-tuned for new tasks. Without training or fine-tuning, scientific language models could be used for such low-data tasks through their announced zero- and few-shot capabilities. However, their predictive quality at activity prediction is lacking. In this work, we envision a novel type of activity prediction model that is able to adapt to new prediction tasks at inference time, via understanding textual information describing the task. To this end, we propose a new architecture with separate modules for chemical and natural language inputs, and a contrastive pretraining objective on data from large biochemical databases. In extensive experiments, we show that our method CLAMP yields improved predictive performance on few-shot learning benchmarks and zero-shot problems in drug discovery. We attribute the advances of our method to the modularized architecture and to our pre-training objective.

**摘要:** 活动和属性预测模型是药物发现和材料科学中的核心工作horses,但目前,它们必须经过训练或微调才能完成新任务。在没有训练或微调的情况下,科学语言模型可以通过其宣布的零射和零射能力用于低数据任务。然而,它们在活动预测中缺乏预测质量。在这个工作中,我们设想一种新型的活动预测模型,能够通过理解描述任务的文本信息,在推断时适应新的预测任务。为此,我们提出了一种新的结构,包括化学和自然语言输入的单独模块,以及对大型生物化学数据库的数据进行对比的预训练目标。我们把方法的进步归功于模块化架构和我们的预培训目标。

**[Paper URL](https://proceedings.mlr.press/v202/seidl23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/seidl23a/seidl23a.pdf)** 

# Variational Autoencoding Neural Operators
**题目:** 变量自动编码神经运算器

**作者:** Jacob H Seidman, Georgios Kissas, George J. Pappas, Paris Perdikaris

**Abstract:** Unsupervised learning with functional data is an emerging paradigm of machine learning research with applications to computer vision, climate modeling and physical systems. A natural way of modeling functional data is by learning operators between infinite dimensional spaces, leading to discretization invariant representations that scale independently of the sample grid resolution. Here we present Variational Autoencoding Neural Operators (VANO), a general strategy for making a large class of operator learning architectures act as variational autoencoders. For this purpose, we provide a novel rigorous mathematical formulation of the variational objective in function spaces for training. VANO first maps an input function to a distribution over a latent space using a parametric encoder and then decodes a sample from the latent distribution to reconstruct the input, as in classic variational autoencoders. We test VANO with different model set-ups and architecture choices for a variety of benchmarks. We start from a simple Gaussian random field where we can analytically track what the model learns and progressively transition to more challenging benchmarks including modeling phase separation in Cahn-Hilliard systems and real world satellite data for measuring Earth surface deformation.

**摘要:** 功能数据的非监督学习是计算机视觉、气候建模和物理系统应用的机器学习研究的新兴范式。功能数据的自然建模方法是在无穷维空间之间学习操作员,从而实现独立于样品网格分辨率的离散不变表示。我们用不同的模型设置和架构选择来测试VANO,以满足各种标准。我们从一个简单的高斯随机场开始,我们可以分析该模型学习的内容,并逐步转变到更挑战性的标准,包括在卡恩-希里亚德系统中的相位分离模型和测量地球表面变形的现实世界卫星数据。

**[Paper URL](https://proceedings.mlr.press/v202/seidman23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/seidman23a/seidman23a.pdf)** 

# Neural Markov Jump Processes
**题目:** 神经马可夫跳跃过程

**作者:** Patrick Seifner, Ramses J Sanchez

**Abstract:** Markov jump processes are continuous-time stochastic processes with a wide range of applications in both natural and social sciences. Despite their widespread use, inference in these models is highly non-trivial and typically proceeds via either Monte Carlo or expectation-maximization methods. In this work we introduce an alternative, variational inference algorithm for Markov jump processes which relies on neural ordinary differential equations, and is trainable via back-propagation. Our methodology learns neural, continuous-time representations of the observed data, that are used to approximate the initial distribution and time-dependent transition probability rates of the posterior Markov jump process. The time-independent rates of the prior process are in contrast trained akin to generative adversarial networks. We test our approach on synthetic data sampled from ground-truth Markov jump processes, experimental switching ion channel data and molecular dynamics simulations. Source code to reproduce our experiments is available online.

**摘要:** 马可夫跳跃过程是自然科学和社会科学中具有广泛应用的连续时间随机过程,尽管其广泛应用,这些模型的推理非常非平凡,通常通过蒙特卡罗或期望最大化方法进行。本文介绍一种基于神经常微分方程的替代变量推理算法,并可通过后推导进行训练。我们的方法学学习了观察数据的神经连续时间表示,用于近似后马可夫跳跃过程的初始分布和时间依赖的过渡概率率。复制我们的实验的源代码可用在线.

**[Paper URL](https://proceedings.mlr.press/v202/seifner23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/seifner23a/seifner23a.pdf)** 

# Bayesian online change point detection with Hilbert space approximate Student-t process
**题目:** 贝叶斯在线变化点检测与希尔伯特空间近似学生-t过程

**作者:** Jeremy Sellier, Petros Dellaportas

**Abstract:** In this paper, we introduce a variant of Bayesian online change point detection with a reducedrank Student-t process (TP) and dependent Student-t noise, as a nonparametric time series model. Our method builds and improves upon the state-of-the-art Gaussian process (GP) change point model benchmark of Saatci et al. (2010). The Student-t process generalizes the concept of a GP and hence yields a more flexible alternative. Additionally, unlike a GP, the predictive variance explicitly depends on the training observations, while the use of an entangled Student-t noise model preserves analytical tractability. Our approach also uses a Hilbert space reduced-rank representation of the TP kernel, derived from an eigenfunction expansion of the Laplace operator (Solin & Sarkka, 2020), to alleviate its computational complexity. Improvements in prediction and training time are demonstrated with real-world data-sets

**摘要:** 本文以低阶学生-t过程(TP)和依赖学生-t噪声为非参数时间序列模型,引入了贝叶斯在线变化点检测的变量。该方法建立和改进了萨奇等人(2010年)的最新高斯过程(GP)变化点模型基准。学生-t过程一般化了GP的概念,因此给出了一个更灵活的替代方案。

**[Paper URL](https://proceedings.mlr.press/v202/sellier23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sellier23a/sellier23a.pdf)** 

# Incentivizing Exploration with Linear Contexts and Combinatorial Actions
**题目:** 以线性上下文和组合行动为诱导探索

**作者:** Mark Sellke

**Abstract:** We advance the study of incentivized bandit exploration, in which arm choices are viewed as recommendations and are required to be Bayesian incentive compatible. Recent work of Sellke-Slivkins (Operations Research 2022) has shown that for the special case of independent arms, after collecting enough initial samples, the popular Thompson sampling algorithm becomes incentive compatible. This was generalized to the combinatorial semibandit in Hu-Ngo-Slivkins-Wu (NeurIPS 2022). We give an analog of this result for linear bandits, where the independence of the prior is replaced by a natural convexity condition. This opens up the possibility of efficient and regret-optimal incentivized exploration in high-dimensional action spaces. In the semibandit model, we also improve the sample complexity for the pre-Thompson sampling phase of initial data collection.

**摘要:** 我们推进了激励带状探测的研究,其中臂选择视作建议,并要求为贝叶斯激励兼容。 Sellke-Slivkins(Operations Research 2022)最近的研究表明,对于独立臂的特殊情况,在收集足够的初始样本后,流行的汤普森采样算法会成为激励兼容。这被推广到胡-尼戈-斯利夫金斯-乌(NeurIPS 2022)的组合性半带状探测。我们给出了线性带状探测的结果,其中前者的独立性被自然凸态条件所取代。

**[Paper URL](https://proceedings.mlr.press/v202/sellke23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sellke23a/sellke23a.pdf)** 

# Explainability as statistical inference
**题目:** 解释性作为统计推理

**作者:** Hugo Henri Joseph Senetaire, Damien Garreau, Jes Frellsen, Pierre-Alexandre Mattei

**Abstract:** A wide variety of model explanation approaches have been proposed in recent years, all guided by very different rationales and heuristics. In this paper, we take a new route and cast interpretability as a statistical inference problem. We propose a general deep probabilistic model designed to produce interpretable predictions. The model’s parameters can be learned via maximum likelihood, and the method can be adapted to any predictor network architecture, and any type of prediction problem. Our model is akin to amortized interpretability methods, where a neural network is used as a selector to allow for fast interpretation at inference time. Several popular interpretability methods are shown to be particular cases of regularized maximum likelihood for our general model. Using our framework, we identify imputation as a common issue of these models. We propose new datasets with ground truth selection which allow for the evaluation of the features importance map and show experimentally that multiple imputation provides more reasonable interpretations.

**摘要:** 近年来,提出了一种广泛的模型解释方法,这些方法均以不同的理性和推理为指导。本文采用了一种新的方法,将解释性作为统计推理问题推导出来。我们提出了一种通用的深度概率模型,以产生可解释性预测。该模型的参数可通过最大概率学习,该方法可适应任何预测器网络架构和任何预测问题。我们的模型类似于 amortized解释性方法,其中神经网络被用作选择器,以便在推理时快速解释。提出了新的基于实地选择的数据集,可以评价特征重要度图,并实验证明多归因提供了更合理的解释。

**[Paper URL](https://proceedings.mlr.press/v202/senetaire23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/senetaire23a/senetaire23a.pdf)** 

# Multi-View Masked World Models for Visual Robotic Manipulation
**题目:** 视觉机器人操纵的多视面化世界模型

**作者:** Younggyo Seo, Junsu Kim, Stephen James, Kimin Lee, Jinwoo Shin, Pieter Abbeel

**Abstract:** Visual robotic manipulation research and applications often use multiple cameras, or views, to better perceive the world. How else can we utilize the richness of multi-view data? In this paper, we investigate how to learn good representations with multi-view data and utilize them for visual robotic manipulation. Specifically, we train a multi-view masked autoencoder which reconstructs pixels of randomly masked viewpoints and then learn a world model operating on the representations from the autoencoder. We demonstrate the effectiveness of our method in a range of scenarios, including multi-view control and single-view control with auxiliary cameras for representation learning. We also show that the multi-view masked autoencoder trained with multiple randomized viewpoints enables training a policy with strong viewpoint randomization and transferring the policy to solve real-robot tasks without camera calibration and an adaptation procedure. Video demonstrations are available at: https://sites.google.com/view/mv-mwm.

**摘要:** 视觉机器人操纵研究和应用经常使用多个摄像机或视图来更好地感知世界。我们如何利用多视图数据的丰富性呢?本文研究了如何利用多视图数据学习好视图,并利用它们进行视觉机器人操纵。具体而言,我们训练了一个多视图蒙面自动编码器,它重建了随机蒙面视图点的像素,然后从自动编码器中学习一个运行在视图上的世界模型。我们在多个场景中展示了我们方法的有效性,包括多视图控制和单视图控制,并用辅助摄像机学习表示。视频示范可以在: https://sites.google.com/view/mv-mwm.

**[Paper URL](https://proceedings.mlr.press/v202/seo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/seo23a/seo23a.pdf)** 

# One-Shot Compression of Large Edge-Exchangeable Graphs using Bits-Back Coding
**题目:** 使用比特返回编码的大型边缘可交换图形的单击压缩

**作者:** Daniel Severo, James Townsend, Ashish J Khisti, Alireza Makhzani

**Abstract:** We present a one-shot method for compressing large labeled graphs called Random Edge Coding. When paired with a parameter-free model based on Pólya’s Urn, the worst-case computational and memory complexities scale quasi-linearly and linearly with the number of observed edges, making it efficient on sparse graphs, and requires only integer arithmetic. Key to our method is bits-back coding, which is used to sample edges and vertices without replacement from the edge-list in a way that preserves the structure of the graph. Optimality is proven under a class of random graph models that are invariant to permutations of the edges and of vertices within an edge. Experiments indicate Random Edge Coding can achieve competitive compression performance on real-world network datasets and scales to graphs with millions of nodes and edges.

**摘要:** 我们提出了一种压缩大型标记图的单击方法,叫做随机边缘编码。 当与基于波利亚的乌恩的参数自由模型相配时,最坏的计算和记忆复杂度与观察边缘的数目进行准线性和线性尺度,使它在稀疏图上具有效率,并仅需要整数算术。

**[Paper URL](https://proceedings.mlr.press/v202/severo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/severo23a/severo23a.pdf)** 

# ModelDiff: A Framework for Comparing Learning Algorithms
**题目:** ModelDiff:学习算法的比较框架

**作者:** Harshay Shah, Sung Min Park, Andrew Ilyas, Aleksander Madry

**Abstract:** We study the problem of (learning) algorithm comparison, where the goal is to find differences between models trained with two different learning algorithms. We begin by formalizing this goal as one of finding distinguishing feature transformations, i.e., input transformations that change the predictions of models trained with one learning algorithm but not the other. We then present ModelDiff, a method that leverages the datamodels framework (Ilyas et al., 2022) to compare learning algorithms based on how they use their training data. We demonstrate ModelDiff through three case studies, comparing models trained with/without data augmentation, with/without pre-training, and with different SGD hyperparameters.

**摘要:** 我们研究了(学习)算法的比较问题,目的在于找到与两个不同的学习算法训练的模型之间的差异。我们首先将这一目标形式化为找到区别特征变换的变换,即改变与一个学习算法训练的模型预测的输入变换。然后,我们提出ModelDiff,一种利用数据模型框架(Ilyas et al., 2022)来根据它们如何使用训练数据来比较学习算法的方法。

**[Paper URL](https://proceedings.mlr.press/v202/shah23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shah23a/shah23a.pdf)** 

# Auxiliary Learning as an Asymmetric Bargaining Game
**题目:** 辅助学习作为不对称谈判游戏

**作者:** Aviv Shamsian, Aviv Navon, Neta Glazer, Kenji Kawaguchi, Gal Chechik, Ethan Fetaya

**Abstract:** Auxiliary learning is an effective method for enhancing the generalization capabilities of trained models, particularly when dealing with small datasets. However, this approach may present several difficulties: (i) optimizing multiple objectives can be more challenging, and (ii) how to balance the auxiliary tasks to best assist the main task is unclear. In this work, we propose a novel approach, named AuxiNash, for balancing tasks in auxiliary learning by formalizing the problem as generalized bargaining game with asymmetric task bargaining power. Furthermore, we describe an efficient procedure for learning the bargaining power of tasks based on their contribution to the performance of the main task and derive theoretical guarantees for its convergence. Finally, we evaluate AuxiNash on multiple multi-task benchmarks and find that it consistently outperforms competing methods.

**摘要:** 辅助学习是提高训练模型的一般化能力的一种有效方法,特别是在处理小数据集时。然而,这种方法可能存在 several difficulties: (i)优化多个目标可能更加困难,(ii)如何平衡辅助任务以最佳协助主任务是不明的。

**[Paper URL](https://proceedings.mlr.press/v202/shamsian23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shamsian23a/shamsian23a.pdf)** 

# Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models
**题目:** 合成提示:生成大型语言模型的链路演示

**作者:** Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, Weizhu Chen

**Abstract:** Large language models can perform various reasoning tasks by using chain-of-thought prompting, which guides them to find answers through step-by-step demonstrations. However, the quality of the prompts depends on the demonstrations given to the models, and creating many of them by hand is costly. We introduce Synthetic prompting, a method that leverages a few handcrafted examples to prompt the model to generate more examples by itself, and selects effective demonstrations to elicit better reasoning. Our method alternates between a backward and forward process to generate new examples. The backward process generates a question that match a sampled reasoning chain, so that the question is solvable and clear. The forward process produces a more detailed reasoning chain for the question, improving the quality of the example. We evaluate our method on numerical, symbolic, and algorithmic reasoning tasks, and show that it outperforms existing prompting techniques.

**摘要:** 大型语言模型可以通过链条推理来执行各种推理任务,从而引导它们通过步骤的演示找到答案。然而,推理的质量取决于给模型的演示,而手工创建的许多是昂贵的。我们引入了合成推理,一种利用少数手工制作的实例推理模型以生成更多实例,并选择有效的演示以产生更好的推理。我们的方法在逆向和前向过程之间进行交互,以生成新的实例。逆向过程生成了一个与样品推理链匹配的问题,使问题可解决和清晰。前向过程生成了一个更详细的推理链,提高了实例的质量。我们对数值、符号和算法推理任务的推理方法进行了评估,并证明它优于现有推理技术。

**[Paper URL](https://proceedings.mlr.press/v202/shao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shao23a/shao23a.pdf)** 

# Complementary Attention for Multi-Agent Reinforcement Learning
**题目:** 多干事强化学习的补充注意

**作者:** Jianzhun Shao, Hongchang Zhang, Yun Qu, Chang Liu, Shuncheng He, Yuhang Jiang, Xiangyang Ji

**Abstract:** In cooperative multi-agent reinforcement learning, centralized training with decentralized execution (CTDE) shows great promise for a trade-off between independent Q-learning and joint action learning. However, vanilla CTDE methods assumed a fixed number of agents could hardly adapt to real-world scenarios where dynamic team compositions typically suffer from dramatically variant partial observability. Specifically, agents with extensive sight ranges are prone to be affected by trivial environmental substrates, dubbed the "distracted attention" issue; ones with limited observation can hardly sense their teammates, degrading the cooperation quality. In this paper, we propose Complementary Attention for Multi-Agent reinforcement learning (CAMA), which applies a divide-and-conquer strategy on input entities accompanied with the complementary attention of enhancement and replenishment. Concretely, to tackle the distracted attention issue, highly contributed entities’ attention is enhanced by the execution-related representation extracted via action prediction with an inverse model. For better out-of-sight-range cooperation, the lowly contributed ones are compressed to brief messages with a conditional mutual information estimator. Our CAMA facilitates stable and sustainable teamwork, which is justified by the impressive results reported on the challenging StarCraftII, MPE, and Traffic Junction benchmarks.

**摘要:** 在合作多代理强化学习中,集中训练与分散执行(CTDE)表现出独立Q-学习和联合行动学习之间的交易的巨大前景。然而,瓦尼拉CTDE方法假设一定数量的代理很难适应动态团队组成通常 suffer from dramatically variant partial observability的现实场景。具体而言,具有广泛视域的代理容易受到微不足道的环境基质的影响,称为“分散注意”问题;那些具有有限观察能力的代理很难感知他们的团队伙伴,从而降低合作质量。具体而言,为了解决分散注意力问题,高贡献实体的注意力被通过反向模型的行动预测提取的执行相关表现增强。为了更好的远距离合作,低贡献实体被压缩为短消息,并使用条件的相互信息估计器。我们的CAMA促进了稳定的和可持续的团队合作,这由挑战性的StarCraftII、MPE和交通交汇基准报告的令人印象深刻的结果所证明。

**[Paper URL](https://proceedings.mlr.press/v202/shao23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shao23b/shao23b.pdf)** 

# Regularization-free Diffeomorphic Temporal Alignment Nets
**题目:** 无调节的变形间距配线网

**作者:** Ron Shapira Weber, Oren Freifeld

**Abstract:** In time-series analysis, nonlinear temporal misalignment is a major problem that forestalls even simple averaging. An effective learning-based solution for this problem is the Diffeomorphic Temporal Alignment Net (DTAN), that, by relying on a diffeomorphic temporal transformer net and the amortization of the joint-alignment task, eliminates drawbacks of traditional alignment methods. Unfortunately, existing DTAN formulations crucially depend on a regularization term whose optimal hyperparameters are dataset-specific and usually searched via a large number of experiments. Here we propose a regularization-free DTAN that obviates the need to perform such an expensive, and often impractical, search. Concretely, we propose a new well-behaved loss that we call the Inverse Consistency Averaging Error (ICAE), as well as a related new triplet loss. Extensive experiments on 128 UCR datasets show that the proposed method outperforms contemporary methods despite not using a regularization. Moreover, ICAE also gives rise to the first DTAN that supports variable-length signals. Our code is available at https://github.com/BGU-CS-VIL/RF-DTAN.

**摘要:** 在时间序列分析中,非线性时间偏差是一个主要问题,它甚至阻碍了简单的平均化。一个有效的基于学习的解决方法是DTAN,它通过依赖Dffeomorphic时间变换器网和联合偏差任务的 amortization,消除了传统偏差方法的缺点。不幸的是,现有DTAN公式主要取决于一个定律术语,其最佳超参数是数据集的特定,通常通过大量实验进行搜索。此外,ICAE还给出了第一个支持变长信号的DTAN。我们的代码在 https://github.com/BGU-CS-VIL/RF-DTAN。

**[Paper URL](https://proceedings.mlr.press/v202/shapira-weber23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shapira-weber23a/shapira-weber23a.pdf)** 

# Toward Efficient Gradient-Based Value Estimation
**题目:** 面向高效梯度值估计

**作者:** Arsalan Sharifnassab, Richard S. Sutton

**Abstract:** Gradient-based methods for value estimation in reinforcement learning have favorable stability properties, but they are typically much slower than Temporal Difference (TD) learning methods. We study the root causes of this slowness and show that Mean Square Bellman Error (MSBE) is an ill-conditioned loss function in the sense that its Hessian has large condition-number. To resolve the adverse effect of poor conditioning of MSBE on gradient based methods, we propose a low complexity batch-free proximal method that approximately follows the Gauss-Newton direction and is asymptotically robust to parameterization. Our main algorithm, called RANS, is efficient in the sense that it is significantly faster than the residual gradient methods while having almost the same computational complexity, and is competitive with TD on the classic problems that we tested.

**摘要:** 在增强学习中,基于梯度的值估计方法具有有利的稳定性特性,但它们通常比 Temporal Difference (TD)学习方法慢得多。我们研究了这种慢度的根本原因,并证明了平均方形贝尔曼误差(MSBE)是弱条件的损失函数,因为它的 Hessian具有较大条件数。为了解决MSBE在梯度的基础上条件不良的不利影响,我们提出了一种低复杂度批量自由近距离方法,它大致遵循高斯-纽顿方向,并且对参数化具有渐近鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/sharifnassab23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sharifnassab23a/sharifnassab23a.pdf)** 

# Coin Sampling: Gradient-Based Bayesian Inference without Learning Rates
**题目:** 硬币样本:基于梯度的贝叶斯因费率,没有学习率

**作者:** Louis Sharrock, Christopher Nemeth

**Abstract:** In recent years, particle-based variational inference (ParVI) methods such as Stein variational gradient descent (SVGD) have grown in popularity as scalable methods for Bayesian inference. Unfortunately, the properties of such methods invariably depend on hyperparameters such as the learning rate, which must be carefully tuned by the practitioner in order to ensure convergence to the target measure at a suitable rate. In this paper, we introduce a suite of new particle-based methods for scalable Bayesian inference based on coin betting, which are entirely learning-rate free. We illustrate the performance of our approach on a range of numerical examples, including several high-dimensional models and datasets, demonstrating comparable performance to other ParVI algorithms with no need to tune a learning rate.

**摘要:** 近年来,基于粒子变量推导(ParVI)方法,如施泰因变量梯度下降(SVGD)作为贝叶斯推导的可扩展方法越来越受欢迎。不幸的是,这些方法的特性始终取决于学习率等高参数,必须由实践者仔细调制,以确保在适当的速度达到目标指标。本论文介绍了一种基于硬币赌注的可扩展贝叶斯推导的新粒子方法,完全无学习率。

**[Paper URL](https://proceedings.mlr.press/v202/sharrock23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sharrock23a/sharrock23a.pdf)** 

# On Kinetic Optimal Probability Paths for Generative Models
**题目:** 生成模型动力学最佳概率路径

**作者:** Neta Shaul, Ricky T. Q. Chen, Maximilian Nickel, Matthew Le, Yaron Lipman

**Abstract:** Recent successful generative models are trained by fitting a neural network to an a-priori defined tractable probability density path taking noise to training examples. In this paper we investigate the space of Gaussian probability paths, which includes diffusion paths as an instance, and look for an optimal member in some useful sense. In particular, minimizing the Kinetic Energy (KE) of a path is known to make particles’ trajectories simple, hence easier to sample, and empirically improve performance in terms of likelihood of unseen data and sample generation quality. We investigate Kinetic Optimal (KO) Gaussian paths and offer the following observations: (i) We show the KE takes a simplified form on the space of Gaussian paths, where the data is incorporated only through a single, one dimensional scalar function, called the data separation function. (ii) We characterize the KO solutions with a one dimensional ODE. (iii) We approximate data-dependent KO paths by approximating the data separation function and minimizing the KE. (iv) We prove that the data separation function converges to $1$ in the general case of arbitrary normalized dataset consisting of $n$ samples in $d$ dimension as $n/\sqrt{d}\rightarrow 0$. A consequence of this result is that the Conditional Optimal Transport (Cond-OT) path becomes kinetic optimal as $n/\sqrt{d}\rightarrow 0$. We further support this theory with empirical experiments on ImageNet.

**摘要:** 本文研究了高斯概率路径的空间,包括扩散路径作为实例,并从某种有用的意义上寻找一个最佳成员。 特别是,最小化路径的运动能量(KE)可使粒子的轨迹简单,因此更容易进行样品,并从经验上提高未见数据和样品生成质量的概率性能。(iii)通过近似数据分离函数和最小化KE来近似数据依赖Ko路径。 (iv)我们证明,在$d$维度中的$n$样本构成的任意标准化数据集一般情况下,数据分离函数收敛到$n/\sqrt{d}\rightarrow 0$。

**[Paper URL](https://proceedings.mlr.press/v202/shaul23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shaul23a/shaul23a.pdf)** 

# Sequential Changepoint Detection via Backward Confidence Sequences
**题目:** 通过后向信任序列检测序列变化点

**作者:** Shubhanshu Shekhar, Aaditya Ramdas

**Abstract:** We present a simple reduction from sequential estimation to sequential changepoint detection (SCD). In short, suppose we are interested in detecting changepoints in some parameter or functional $\theta$ of the underlying distribution. We demonstrate that if we can construct a confidence sequence (CS) for $\theta$, then we can also successfully perform SCD for $\theta$. This is accomplished by checking if two CSs — one forwards and the other backwards — ever fail to intersect. Since the literature on CSs has been rapidly evolving recently, the reduction provided in this paper immediately solves several old and new change detection problems. Further, our “backward CS”, constructed by reversing time, is new and potentially of independent interest. We provide strong nonasymptotic guarantees on the frequency of false alarms and detection delay, and demonstrate numerical effectiveness on several problems.

**摘要:** 我们给出了从序列估计到序列变化点检测(SCD)的简单减少方法。简言之,假设我们有意检测下层分布的一些参数或功能$\theta$中的变化点。我们证明,如果我们能够构造一个信任序列(CS)为$\theta$,那么我们也可以成功执行$\theta$的SCD。这可以通过检查两个CS — — 一个向前,另一个向后 — — 是否曾经未能交错来实现。由于CSs的文献最近迅速发展,本文所提供的减少方法立即解决了几个旧和新的变化检测问题。

**[Paper URL](https://proceedings.mlr.press/v202/shekhar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shekhar23a/shekhar23a.pdf)** 

# Cold Analysis of Rao-Blackwellized Straight-Through Gumbel-Softmax Gradient Estimator
**题目:** 拉奥-黑well化直通胶带-Softmax梯度估计器的冷分析

**作者:** Alexander Shekhovtsov

**Abstract:** Many problems in machine learning require an estimate of the gradient of an expectation in discrete random variables with respect to the sampling distribution. This work is motivated by the development of the Gumbel-Softmax family of estimators, which use a temperature-controlled relaxation of discrete variables. The state-of-the art in this family, the Gumbel-Rao estimator uses an extra internal sampling to reduce the variance, which may be costly. We analyze this estimator and show that it possesses a zero temperature limit with a surprisingly simple closed form. The limit estimator, called ZGR, has favorable bias and variance properties, it is easy to implement and computationally inexpensive. It decomposes as the average of the straight through (ST) estimator and DARN estimator — two basic but not very well performing on their own estimators. We demonstrate that the simple ST–ZGR family of estimators practically dominates in the bias-variance tradeoffs the whole GR family while also outperforming SOTA unbiased estimators.

**摘要:** 在机器学习中有许多问题需要对离散随机变量期望的梯度进行估计,这与采样分布有关。这项工作是由于使用离散变量温度控制松弛的Gumbel-Softmax估计器家族的开发而引起的。Gumbel-Rao估计器使用额外的内部采样来降低变量,这可能很昂贵。我们分析了这个估计器,并证明它拥有一个惊人的简单封闭形式的零温度限度。我们证明,简单的ST-ZGR估计器家族在偏差-变量权衡中几乎占了整个GR家族的主导地位,同时超越了SOTA无偏估计器。

**[Paper URL](https://proceedings.mlr.press/v202/shekhovtsov23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shekhovtsov23a/shekhovtsov23a.pdf)** 

# Towards Understanding and Improving GFlowNet Training
**题目:** 提高GFlowNet培训水平

**作者:** Max W Shen, Emmanuel Bengio, Ehsan Hajiramezanali, Andreas Loukas, Kyunghyun Cho, Tommaso Biancalani

**Abstract:** Generative flow networks (GFlowNets) are a family of algorithms that learn a generative policy to sample discrete objects $x$ with non-negative reward $R(x)$. Learning objectives guarantee the GFlowNet samples $x$ from the target distribution $p^*(x) \propto R(x)$ when loss is globally minimized over all states or trajectories, but it is unclear how well they perform with practical limits on training resources. We introduce an efficient evaluation strategy to compare the learned sampling distribution to the target reward distribution. As flows can be underdetermined given training data, we clarify the importance of learned flows to generalization and matching $p^*(x)$ in practice. We investigate how to learn better flows, and propose (i) prioritized replay training of high-reward $x$, (ii) relative edge flow policy parametrization, and (iii) a novel guided trajectory balance objective, and show how it can solve a substructure credit assignment problem. We substantially improve sample efficiency on biochemical design tasks.

**摘要:** 生成流程网络(GFlowNets)是一个学习生成策略的类别,它可以从目标分布$p^*(x)\propto R(x)$中获取GFlowNet样品,保证损失在所有状态或轨迹上被全球最小化,但它们在训练资源上的实际限制下表现得如何好还不清楚。我们引入了一个有效的评价策略,以比较学习样品分布与目标奖励分布。因为流可以被给定不足的训练数据,我们明确了学习流在实践中推广和匹配$p^*(x)$的重要性。我们研究如何学习更好的流,并提出(i)优先重演高收益$x$的训练,(ii)相对边缘流程政策参数化,以及(iii)新的引导轨迹平衡目标,并展示如何解决子结构信贷分配问题。在生物化学设计任务中,我们大大提高了样品效率.

**[Paper URL](https://proceedings.mlr.press/v202/shen23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shen23a/shen23a.pdf)** 

# On Balancing Bias and Variance in Unsupervised Multi-Source-Free Domain Adaptation
**题目:** 无监督多源自由域适应中偏差与变异的平衡

**作者:** Maohao Shen, Yuheng Bu, Gregory W. Wornell

**Abstract:** Due to privacy, storage, and other constraints, there is a growing need for unsupervised domain adaptation techniques in machine learning that do not require access to the data used to train a collection of source models. Existing methods for multi-source-free domain adaptation (MSFDA) typically train a target model using pseudo-labeled data produced by the source models, which focus on improving the pseudo-labeling techniques or proposing new training objectives. Instead, we aim to analyze the fundamental limits of MSFDA. In particular, we develop an information-theoretic bound on the generalization error of the resulting target model, which illustrates an inherent bias-variance trade-off. We then provide insights on how to balance this trade-off from three perspectives, including domain aggregation, selective pseudo-labeling, and joint feature alignment, which leads to the design of novel algorithms. Experiments on multiple datasets validate our theoretical analysis and demonstrate the state-of-art performance of the proposed algorithm, especially on some of the most challenging datasets, including Office-Home and DomainNet.

**摘要:** 由于私隐、存储和其他限制,在机器学习中日益需要无监督的领域适应技术,这些技术并不需要访问用于训练源模型的数据。现有的多源自由领域适应(MSFDA)方法通常是通过源模型生成的伪标记数据来训练目标模型,这些方法侧重改进伪标记技术或提出新的训练目标。对多个数据集的实验验证了我们的理论分析,并证明了该算法的最先进的性能,特别是对一些最挑战性的数据集,包括Office-Home和DomainNet。

**[Paper URL](https://proceedings.mlr.press/v202/shen23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shen23b/shen23b.pdf)** 

# On Penalty-based Bilevel Gradient Descent Method
**题目:** 基于刑罚的二级梯度退化方法

**作者:** Han Shen, Tianyi Chen

**Abstract:** Bilevel optimization enjoys a wide range of applications in hyper-parameter optimization, meta-learning and reinforcement learning. However, bilevel problems are difficult to solve and recent progress on scalable bilevel algorithms mainly focuses on bilevel optimization problems where the lower-level objective is either strongly convex or unconstrained. In this work, we tackle the bilevel problem through the lens of the penalty method. We show that under certain conditions, the penalty reformulation recovers the solutions of the original bilevel problem. Further, we propose the penalty-based bilevel gradient descent algorithm and establish its finite-time convergence for the constrained bilevel problem without lower-level strong convexity. The experimental results showcase the efficiency of the proposed algorithm.

**摘要:** 双层优化在高参数优化、元学习和增强学习中有着广泛的应用,但双层问题难以解决,可扩展双层算法的近期进展主要集中在低层目标强凸或无约束的双层优化问题上。本文通过刑法的视角对双层问题进行了研究,证明在一定条件下,刑法的改革可以恢复原来的双层问题的解决方法。

**[Paper URL](https://proceedings.mlr.press/v202/shen23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shen23c/shen23c.pdf)** 

# Non-autoregressive Conditional Diffusion Models for Time Series Prediction
**题目:** 时间序列预测非自回归条件扩散模型

**作者:** Lifeng Shen, James Kwok

**Abstract:** Recently, denoising diffusion models have led to significant breakthroughs in the generation of images, audio and text. However, it is still an open question on how to adapt their strong modeling ability to model time series. In this paper, we propose TimeDiff, a non-autoregressive diffusion model that achieves high-quality time series prediction with the introduction of two novel conditioning mechanisms: future mixup and autoregressive initialization. Similar to teacher forcing, future mixup allows parts of the ground-truth future predictions for conditioning, while autoregressive initialization helps better initialize the model with basic time series patterns such as short-term trends. Extensive experiments are performed on nine real-world datasets. Results show that TimeDiff consistently outperforms existing time series diffusion models, and also achieves the best overall performance across a variety of the existing strong baselines (including transformers and FiLM).

**摘要:** 本文提出了一种非自回归扩散模型,它通过引入两种新的条件机制来实现高质量的时序预测:未来混合和自回归初始化。类似于教师的强制,未来混合可以为条件化提供一些基本事实的未来预测,而自回归初始化有助于更好地初始化模型,例如短期趋势。在9个实物数据集中进行了广泛的实验,结果表明TimeDiff始终优于现有的时序扩散模型,并且在现有的强基线(包括变换器和FiLM)中取得了最佳的整体性能。

**[Paper URL](https://proceedings.mlr.press/v202/shen23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shen23d/shen23d.pdf)** 

# Cross-Modal Fine-Tuning: Align then Refine
**题目:** 交叉模态微调:排列然后再微调

**作者:** Junhong Shen, Liam Li, Lucio M. Dery, Corey Staten, Mikhail Khodak, Graham Neubig, Ameet Talwalkar

**Abstract:** Fine-tuning large-scale pretrained models has led to tremendous progress in well-studied modalities such as vision and NLP. However, similar gains have not been observed in many other modalities due to a lack of relevant pretrained models. In this work, we propose ORCA, a general cross-modal fine-tuning framework that extends the applicability of a single large-scale pretrained model to diverse modalities. ORCA adapts to a target task via an align-then-refine workflow: given the target input, ORCA first learns an embedding network that aligns the embedded feature distribution with the pretraining modality. The pretrained model is then fine-tuned on the embedded data to exploit the knowledge shared across modalities. Through extensive experiments, we show that ORCA obtains state-of-the-art results on 3 benchmarks containing over 60 datasets from 12 modalities, outperforming a wide range of hand-designed, AutoML, general-purpose, and task-specific cross-modal methods. We highlight the importance of data alignment via a series of ablation studies and exemplify ORCA’s utility in data-limited regimes.

**摘要:** 微调大规模预制模型导致了良好的研究模式,如视觉和NLP。然而,由于缺乏相关预制模型,在许多其他模式中没有观察到类似的收益。在这个工作中,我们提议ORCA,一种通用的跨模态微调框架,它将单个大规模预制模型的适用性扩展到多种模式。ORCA通过align-then-refine工作流程适应目标任务:给目标输入,ORCA首先学习了一个嵌入式网络,它将嵌入式特征分布与预训练模式相匹配。我们通过一系列的消融研究强调了数据整合的重要性,并证明了ORCA在数据有限的制度中的应用。

**[Paper URL](https://proceedings.mlr.press/v202/shen23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shen23e/shen23e.pdf)** 

# Auxiliary Modality Learning with Generalized Curriculum Distillation
**题目:** 综合课程的辅助模式学习

**作者:** Yu Shen, Xijun Wang, Peng Gao, Ming Lin

**Abstract:** Driven by the need from real-world applications, Auxiliary Modality Learning (AML) offers the possibility to utilize more information from auxiliary data in training, while only requiring data from one or fewer modalities in test, to save the overall computational cost and reduce the amount of input data for inferencing. In this work, we formally define “Auxiliary Modality Learning” (AML), systematically classify types of auxiliary modality (in visual computing) and architectures for AML, and analyze their performance. We also analyze the conditions under which AML works well from the optimization and data distribution perspectives. To guide various choices to achieve optimal performance using AML, we propose a novel method to assist in choosing the best auxiliary modality and estimating an upper bound performance before executing AML. In addition, we propose a new AML method using generalized curriculum distillation to enable more effective curriculum learning. Our method achieves the best performance compared to other SOTA methods.

**摘要:** 基于现实应用的需要,辅助模式学习(AML)提供了在训练中利用辅助数据的更多信息的可能性,同时只需要测试中的一个或少数模式的数据,以节省总计算成本和减少输入数据的数量。在这个工作中,我们正式定义了“辅助模式学习”(AML),系统地分类了辅助模式类型(在视觉计算中)和AML的架构,并分析了它们的性能。我们还分析了AML在优化和数据分配视角下的良好工作条件。我们的方法与其他SOTA方法相比具有最佳性能。

**[Paper URL](https://proceedings.mlr.press/v202/shen23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shen23f/shen23f.pdf)** 

# TGRL: An Algorithm for Teacher Guided Reinforcement Learning
**题目:** TGRL:教师指导强化学习算法

**作者:** Idan Shenfeld, Zhang-Wei Hong, Aviv Tamar, Pulkit Agrawal

**Abstract:** We consider solving sequential decision-making problems in the scenario where the agent has access to two supervision sources: $\textit{reward signal}$ and a $\textit{teacher}$ that can be queried to obtain a $\textit{good}$ action for any state encountered by the agent. Learning solely from rewards, or reinforcement learning, is data inefficient and may not learn high-reward policies in challenging scenarios involving sparse rewards or partial observability. On the other hand, learning from a teacher may sometimes be infeasible. For instance, the actions provided by a teacher with privileged information may be unlearnable by an agent with limited information (i.e., partial observability). In other scenarios, the teacher might be sub-optimal, and imitating their actions can limit the agent’s performance. To overcome these challenges, prior work proposed to jointly optimize imitation and reinforcement learning objectives but relied on heuristics and problem-specific hyper-parameter tuning to balance the two objectives. We introduce Teacher Guided Reinforcement Learning (TGRL), a principled approach to dynamically balance following the teacher’s guidance and leveraging RL. TGRL outperforms strong baselines across diverse domains without hyperparameter tuning.

**摘要:** 我们 考虑 在 代理人 访问 两 个 监督 来源 的 场景 中 解决 序列 决策 问题 : $\textit{reward signal}$ 和 $\textit{teacher}$ 可以 查询 以 获得 代理人 所 遇到 的 任何 状态 的 $\textit{good}$ 行动 。 只 从 奖励 或 加强 学习 的 学习 是 数据 效率 低 的, 在 涉及 稀有 奖励 或 部分 可 观察 的 挑战 场景 中 可能 不会 学习 高 奖励 政策 。 另一方面, 从 教师 学习 有时 是 不可能 的 。 例如, 由 教师 提供 特权 信息 的 行动 可能 由 代理人为了克服这些挑战,以前的工作提议联合优化模仿和强化学习目标,但依靠实验和问题特异的超参数调度来平衡这两个目标。我们介绍了教师指导强化学习(TGRL),一种基于原则的方法,以遵循教师的指导和利用RL来动态平衡。

**[Paper URL](https://proceedings.mlr.press/v202/shenfeld23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shenfeld23a/shenfeld23a.pdf)** 

# FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU
**题目:** FlexGen:基于单个GPU的大型语言模型的高吞吐量生成因费

**作者:** Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Beidi Chen, Percy Liang, Christopher Re, Ion Stoica, Ce Zhang

**Abstract:** The high computational and memory requirements of large language model (LLM) inference make it feasible only with multiple high-end accelerators. Motivated by the emerging demand for latency-insensitive tasks with batched processing, this paper initiates the study of high-throughput LLM inference using limited resources, such as a single commodity GPU. We present FlexGen, a high-throughput generation engine for running LLMs with limited GPU memory. FlexGen can be flexibly configured under various hardware resource constraints by aggregating memory and computation from the GPU, CPU, and disk. By solving a linear programming problem, it searches for efficient patterns to store and access tensors. FlexGen further compresses the weights and the attention cache to 4 bits with negligible accuracy loss. These techniques enable FlexGen to have a larger space of batch size choices and thus significantly increase maximum throughput. As a result, when running OPT-175B on a single 16GB GPU, FlexGen achieves significantly higher throughput compared to state-of-the-art offloading systems, reaching a generation throughput of 1 token/s for the first time with an effective batch size of 144. On the HELM benchmark, FlexGen can benchmark a 30B model with a 16GB GPU on 7 representative sub-scenarios in 21 hours. The code is available at https://github.com/FMInference/FlexGen.

**摘要:** 由于大型语言模型(LLM)推导的计算和存储要求高,只能用多个高端加速器实现推导。 本文以批量处理的 latency-insensitive任务的需求为动机,以有限资源,如单个商品GPU,开始研究高吞吐LLM推导。我们介绍了LLMs运行的高吞吐生成引擎FlexGen,它可以灵活配置在不同的硬件资源约束下,通过从GPU、CPU和磁盘集聚存储和计算。通过解决线性编程问题,它寻找存储和访问拉伸器的高效模式。FlexGen进一步压缩重量和注意力缓存到4位,使精度损失轻微。因此,在运行OPT-175B的单个16GB GPU时,FlexGen的吞吐量要比最先进的卸载系统高得多,以144个有效批量大小首次达到1个トークン/秒的生成吞吐量。在Helm基准上,FlexGen可以在21小时内对7个代表性子场景的16GB GPU的30B模型进行基准。

**[Paper URL](https://proceedings.mlr.press/v202/sheng23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sheng23a/sheng23a.pdf)** 

# Improved Regret for Efficient Online Reinforcement Learning with Linear Function Approximation
**题目:** 基于线性函数近似的在线增强学习效率提高的遗憾

**作者:** Uri Sherman, Tomer Koren, Yishay Mansour

**Abstract:** We study reinforcement learning with linear function approximation and adversarially changing cost functions, a setup that has mostly been considered under simplifying assumptions such as full information feedback or exploratory conditions. We present a computationally efficient policy optimization algorithm for the challenging general setting of unknown dynamics and bandit feedback, featuring a combination of mirror-descent and least squares policy evaluation in an auxiliary MDP used to compute exploration bonuses. Our algorithm obtains an $\widetilde O(K^{6/7})$ regret bound, improving significantly over previous state-of-the-art of $\widetilde O (K^{14/15})$ in this setting. In addition, we present a version of the same algorithm under the assumption a simulator of the environment is available to the learner (but otherwise no exploratory assumptions are made), and prove it obtains state-of-the-art regret of $\widetilde O (K^{2/3})$.

**摘要:** 我们研究了线性函数近似和逆变成本函数的强化学习,这一设置主要是在简化假设下考虑的,例如完整的信息反馈或探索条件。我们提出了一种具有计算效率的政策优化算法,用于挑战未知动力学和带点反馈的一般设置,在辅助MDP中采用镜下偏移和最小方形政策评价相结合,用于计算探索奖金。我们的算法获得$\widetilde O(K^{6/7})$ regret bound,在这一设置中大大改善了$\widetilde O(K^{14/15})$的前行状态。此外,我们提出了同样的算法的版本,假设一个环境模拟器供学习者使用(但否则没有进行探索假设),并证明它获得$\widetilde O(K^{2/3})$的最先进的遗憾。

**[Paper URL](https://proceedings.mlr.press/v202/sherman23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sherman23a/sherman23a.pdf)** 

# Fundamental Limits of Two-layer Autoencoders, and Achieving Them with Gradient Methods
**题目:** 双层自动编码器的基本局限性,并用梯度方法实现

**作者:** Aleksandr Shevchenko, Kevin Kögler, Hamed Hassani, Marco Mondelli

**Abstract:** Autoencoders are a popular model in many branches of machine learning and lossy data compression. However, their fundamental limits, the performance of gradient methods and the features learnt during optimization remain poorly understood, even in the two-layer setting. In fact, earlier work has considered either linear autoencoders or specific training regimes (leading to vanishing or diverging compression rates). Our paper addresses this gap by focusing on non-linear two-layer autoencoders trained in the challenging proportional regime in which the input dimension scales linearly with the size of the representation. Our results characterize the minimizers of the population risk, and show that such minimizers are achieved by gradient methods; their structure is also unveiled, thus leading to a concise description of the features obtained via training. For the special case of a sign activation function, our analysis establishes the fundamental limits for the lossy compression of Gaussian sources via (shallow) autoencoders. Finally, while the results are proved for Gaussian data, numerical simulations on standard datasets display the universality of the theoretical predictions.

**摘要:** 自动编码器在机器学习和数据压缩方面的广泛应用,但其基本局限性、梯度方法的性能和优化过程中所学到的特性仍未被理解,甚至在双层设置中。事实上,较早的工作已经考虑了线性自动编码器或特定训练模式(导致压缩率消失或变异)。我们的论文着重讨论了非线性双层自动编码器在挑战性比例模式中训练的这一差距,其中输入维度与表示大小呈线性比例。针对符号激活函数的特殊情况,分析确定了通过(斜)自动编码器对高斯源的丢失压缩的基本限度。最后,在证明高斯数据的结果的同时,在标准数据集上的数值模拟显示了理论预测的普遍性。

**[Paper URL](https://proceedings.mlr.press/v202/shevchenko23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shevchenko23a/shevchenko23a.pdf)** 

# Large Language Models Can Be Easily Distracted by Irrelevant Context
**题目:** 大型语言模型容易被无关紧要的上下文束缚

**作者:** Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed H. Chi, Nathanael Schärli, Denny Zhou

**Abstract:** Large language models have achieved impressive performance on various natural language processing tasks. However, so far they have been evaluated primarily on benchmarks where all information in the input context is relevant for solving the task. In this work, we investigate the distractibility of large language models, i.e., how the model prediction can be distracted by irrelevant context. In particular, we introduce Grade-School Math with Irrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant information in the problem description. We use this benchmark to measure the distractibility of different prompting techniques for large language models, and find that the model is easily distracted by irrelevant information. We also identify several approaches for mitigating this deficiency, such as decoding with self-consistency and adding to the prompt an instruction that tells the language model to ignore the irrelevant information.

**摘要:** 大型语言模型在各种自然语言处理任务中取得了令人印象深刻的性能,但迄今为止,它们主要被评价为在输入上下文中的所有信息对于解决任务有意义的基准。在本研究中,我们研究了大型语言模型的分散性,即模型预测如何被不相关的上下文所分散。我们特别介绍了在问题描述中具有不相关的信息的算术推理数据集,即不相关的上下文的学级数学(GSM-IC)。我们使用这个基准来衡量大型语言模型的不同提示技术的分散性,并发现模型很容易被不相关的信息所分散。

**[Paper URL](https://proceedings.mlr.press/v202/shi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shi23a/shi23a.pdf)** 

# Everyone’s Preference Changes Differently: A Weighted Multi-Interest Model For Retrieval
**题目:** 每个人的偏好变化不同:基于权重的多兴趣模型的检索

**作者:** Hui Shi, Yupeng Gu, Yitong Zhou, Bo Zhao, Sicun Gao, Jishen Zhao

**Abstract:** User embeddings (vectorized representations of a user) are essential in recommendation systems. Numerous approaches have been proposed to construct a representation for the user in order to find similar items for retrieval tasks, and they have been proven effective in industrial recommendation systems. Recently people have discovered the power of using multiple embeddings to represent a user, with the hope that each embedding represents the user’s interest in a certain topic. With multi-interest representation, it’s important to model the user’s preference over the different topics and how the preference changes with time. However, existing approaches either fail to estimate the user’s affinity to each interest or unreasonably assume every interest of every user fades at an equal rate with time, thus hurting the performance of candidate retrieval. In this paper, we propose the Multi-Interest Preference (MIP) model, an approach that not only produces multi-interest for users by using the user’s sequential engagement more effectively but also automatically learns a set of weights to represent the preference over each embedding so that the candidates can be retrieved from each interest proportionally. Extensive experiments have been done on various industrial-scale datasets to demonstrate the effectiveness of our approach.

**摘要:** 用户嵌入式(用户向量化表示)在推荐系统中是必不可少的。为了找到类似项目来构建用户代表,提出了多种方法,并在工业推荐系统中证明有效。最近人们发现使用多个嵌入式来代表用户,希望每个嵌入式代表用户对某一主题的兴趣。在多利益表示中,重要的是将用户对不同主题的偏好模型化,以及如何随时间变化的偏好。然而,现有的方法要么不能估计用户对每个兴趣的亲和性,要么不合理地假设每个用户对每个兴趣的兴趣随时间而消逝,从而损害候选者检索的性能。本文提出了多兴趣偏好(Multi-Interest Preference,MIP)模型,该模型不仅通过更有效的用户连续参与来产生多兴趣,而且自动学习了一套权重,以代表每个嵌入物的偏好,从而可以按比例从每个兴趣中提取候选者。

**[Paper URL](https://proceedings.mlr.press/v202/shi23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shi23b/shi23b.pdf)** 

# A Near-Optimal Algorithm for Safe Reinforcement Learning Under Instantaneous Hard Constraints
**题目:** 快速强力约束下安全强化学习的近视算法

**作者:** Ming Shi, Yingbin Liang, Ness Shroff

**Abstract:** In many applications of Reinforcement Learning (RL), it is critically important that the algorithm performs safely, such that instantaneous hard constraints are satisfied at each step, and unsafe states and actions are avoided. However, existing algorithms for “safe” RL are often designed under constraints that either require expected cumulative costs to be bounded or assume all states are safe. Thus, such algorithms could violate instantaneous hard constraints and traverse unsafe states (and actions) in practice. Hence, in this paper, we develop the first near-optimal safe RL algorithm for episodic Markov Decision Processes with unsafe states and actions under instantaneous hard constraints and the linear mixture model. It achieves a regret $\tilde{O}(\frac{d H^3 \sqrt{d K}}{\Delta_c})$ that nearly matches the state-of-the-art regret in the setting with only unsafe actions and that in the unconstrained setting, and is safe at each step, where $d$ is the feature-mapping dimension, $K$ is the number of episodes, $H$ is the episode length, and $\Delta_c$ is a safety-related parameter. We also provide a lower bound $\tilde{\Omega}(\max\{d H \sqrt{K}, \frac{H}{\Delta_c^2}\})$, which indicates that the dependency on $\Delta_c$ is necessary. Further, both our algorithm design and regret analysis involve several novel ideas, which may be of independent interest.

**摘要:** 在强化学习(RL)的许多应用中,该算法的安全执行是至关重要的,即在每个步骤中满足瞬时的硬约束,避免出现不安全的状态和行为。然而,对于“安全”RL的现有算法往往是根据需要限制预期累积成本或假设所有状态都是安全的约束设计的,因此,这些算法在实践中可能违反瞬时的硬约束并通过不安全的状态(和行为)。它实现的遗憾 $\tilde{O}(\frac{d H^3 \sqrt{d K}}{\Delta_c})$几乎与设置中的最先进的遗憾相匹配,只有不安全的动作和无约束的设置,并且在每个步骤都安全,其中$d$是特征映射维度,$K$是集数,$H$是集长度,和$\Delta_c$是与安全性有关的参数。我们还提供了较低的约束 $\tilde{\Omega}(\max\{d H \sqrt{K}, \frac{H}{\Delta_c^2}\})$,这表明依赖$\Delta_c$是必要的。

**[Paper URL](https://proceedings.mlr.press/v202/shi23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shi23c/shi23c.pdf)** 

# Improving the Model Consistency of Decentralized Federated Learning
**题目:** 改进分散联邦学习模式的一致性

**作者:** Yifan Shi, Li Shen, Kang Wei, Yan Sun, Bo Yuan, Xueqian Wang, Dacheng Tao

**Abstract:** To mitigate the privacy leakages and communication burdens of Federated Learning (FL), decentralized FL (DFL) discards the central server and each client only communicates with its neighbors in a decentralized communication network. However, existing DFL suffers from high inconsistency among local clients, which results in severe distribution shift and inferior performance compared with centralized FL (CFL), especially on heterogeneous data or sparse communication topologies. To alleviate this issue, we propose two DFL algorithms named DFedSAM and DFedSAM-MGS to improve the performance of DFL. Specifically, DFedSAM leverages gradient perturbation to generate local flat models via Sharpness Aware Minimization (SAM), which searches for models with uniformly low loss values. DFedSAM-MGS further boosts DFedSAM by adopting Multiple Gossip Steps (MGS) for better model consistency, which accelerates the aggregation of local flat models and better balances communication complexity and generalization. Theoretically, we present improved convergence rates $\small \mathcal{O}\big(\frac{1}{\sqrt{KT}}+\frac{1}{T}+\frac{1}{K^{1/2}T^{3/2}(1-\lambda)^2}\big)$ and $\small \mathcal{O}\big(\frac{1}{\sqrt{KT}}+\frac{1}{T}+\frac{\lambda^Q+1}{K^{1/2}T^{3/2}(1-\lambda^Q)^2}\big)$ in non-convex setting for DFedSAM and DFedSAM-MGS, respectively, where $1-\lambda$ is the spectral gap of gossip matrix and $Q$ is the number of MGS. Empirically, our methods can achieve competitive performance compared with CFL methods and outperform existing DFL methods.

**摘要:** 为了减轻联邦学习(FL)的私隐泄漏和通信负担,分散式FL(DFL)将中央服务器丢弃,每个客户端只能与其邻居在分散式通信网络中通信。然而,现有的DFL在本地客户端之间存在很高的不一致性,这导致严重的分布移和与集中式FL(CFL)相比的性能低劣,特别是在异质数据或稀疏的通信拓扑上。DFedSAM-MGS进一步增强DFedSAM,通过采用多测谎步骤(英语:Multiple Gossip Steps,缩写为MGS)来提高模型的一致性,从而加速本地平坦模型的聚集,并更好地平衡通信复杂性和一般化。理论上,我们提出了改进的收敛率$\small \mathcal{O}\big(\frac{1}{\sqrt{KT}}+\frac{1}{T}+\frac{1}{K^{1/2}T^{3/2}(1-\lambda)^2}\big)$和$\small \mathcal{O}\big(\frac{1}{\sqrt{KT}}+\frac{1}{T}+\frac{\lambda^Q+1}{K^{1/2}T^{3/2

**[Paper URL](https://proceedings.mlr.press/v202/shi23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shi23d/shi23d.pdf)** 

# UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers
**题目:** UPop:综合视觉语言变换器的统一和进化规划

**作者:** Dachuan Shi, Chaofan Tao, Ying Jin, Zhendong Yang, Chun Yuan, Jiaqi Wang

**Abstract:** Real-world data contains a vast amount of multimodal information, among which vision and language are the two most representative modalities. Moreover, increasingly heavier models, e.g., Transformers, have attracted the attention of researchers to model compression. However, how to compress multimodal models, especially vison-language Transformers, is still under-explored. This paper proposes the Unified and Progressive Pruning (UPop) as a universal vison-language Transformer compression framework, which incorporates 1) unifiedly searching multimodal subnets in a continuous optimization space from the original model, which enables automatic assignment of pruning ratios among compressible modalities and structures; 2) progressively searching and retraining the subnet, which maintains convergence between the search and retrain to attain higher compression ratios. Experiments on various tasks, datasets, and model architectures demonstrate the effectiveness and versatility of the proposed UPop framework. The code is available at https://github.com/sdc17/UPop.

**摘要:** 实物数据包含大量的多模态信息,其中视觉和语言是两个最代表性的模态。此外,越来越重的模型,例如变形器,也吸引了研究者对模型压缩的关注。然而,如何压缩多模态模型,特别是声波语言变形器,仍未得到充分研究。本文提出了统一进化 Pruning(UPop)作为一种通用声波语言变形器压缩框架,它包括 1) 从原模型中连续优化空间统一搜索多模态子网,使可压缩模态和结构之间自动分配剪切比; 2) 逐步搜索和重新训练子网,使搜索和训练保持一致,达到较高的压缩比。对各种任务、数据集和模型架构的实验证明了拟议的UPOP框架的有效性和多用途性。代码可于 https://github.com/sdc17/UPop。

**[Paper URL](https://proceedings.mlr.press/v202/shi23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shi23e/shi23e.pdf)** 

# Sequence Modeling with Multiresolution Convolutional Memory
**题目:** 多分辨率卷积存储的序列建模

**作者:** Jiaxin Shi, Ke Alexander Wang, Emily Fox

**Abstract:** Efficiently capturing the long-range patterns in sequential data sources salient to a given task—such as classification and generative modeling—poses a fundamental challenge. Popular approaches in the space tradeoff between the memory burden of brute-force enumeration and comparison, as in transformers, the computational burden of complicated sequential dependencies, as in recurrent neural networks, or the parameter burden of convolutional networks with many or large filters. We instead take inspiration from wavelet-based multiresolution analysis to define a new building block for sequence modeling, which we call a MultiresLayer. The key component of our model is the multiresolution convolution, capturing multiscale trends in the input sequence. Our MultiresConv can be implemented with shared filters across a dilated causal convolution tree. Thus it garners the computational advantages of convolutional networks and the principled theoretical motivation of wavelet decompositions. Our MultiresLayer is straightforward to implement, requires significantly fewer parameters, and maintains at most a $O(N \log N)$ memory footprint for a length $N$ sequence. Yet, by stacking such layers, our model yields state-of-the-art performance on a number of sequence classification and autoregressive density estimation tasks using CIFAR-10, ListOps, and PTB-XL datasets.

**摘要:** 对特定任务突出的序列数据源中的长距离模式的有效捕捉(例如分类和生成建模)构成了根本性挑战。如变换器、复杂序列依赖的计算负担、如循环神经网络、或与许多或大型滤波器共存的卷积网络的参数负担等,在空间交换中,人们普遍采用的存储负担和比较方式,而我们则从基于小波的多分辨率分析中汲取灵感来定义新的序列建模的构造块,我们称之为多分辨率层。我们模型的关键组成部分是多分辨率卷积,捕捉输入序列中的多尺度趋势。我们的多分辨率卷积树可通过扩散的因果卷积树实现共享滤波器。我们的MultiresLayer是易于实现的,需要 significantly fewer parameters,并且最多维持一个长度$N$序列的$O(N \log N)$内存脚印。然而,通过堆叠这些层,我们的模型在使用CIFAR-10、ListOps和PTB-XL数据集的序列分类和自回归密度估计任务上取得最先进的性能。

**[Paper URL](https://proceedings.mlr.press/v202/shi23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shi23f/shi23f.pdf)** 

# Statistical Inference on Multi-armed Bandits with Delayed Feedback
**题目:** 基于延迟反馈的多武器强盗统计调查

**作者:** Lei Shi, Jingshen Wang, Tianhao Wu

**Abstract:** Multi armed bandit (MAB) algorithms have been increasingly used to complement or integrate with A/B tests and randomized clinical trials in e-commerce, healthcare, and policymaking. Recent developments incorporate possible delayed feedback. While existing MAB literature often focuses on maximizing the expected cumulative reward outcomes (or, equivalently, regret minimization), few efforts have been devoted to establish valid statistical inference approaches to quantify the uncertainty of learned policies. We attempt to fill this gap by providing a unified statistical inference framework for policy evaluation where a target policy is allowed to differ from the data collecting policy, and our framework allows delay to be associated with the treatment arms. We present an adaptively weighted estimator that on one hand incorporates the arm-dependent delaying mechanism to achieve consistency, and on the other hand mitigates the variance inflation across stages due to vanishing sampling probability. In particular, our estimator does not critically depend on the ability to estimate the unknown delay mechanism. Under appropriate conditions, we prove that our estimator converges to a normal distribution as the number of time points goes to infinity, which provides guarantees for large-sample statistical inference. We illustrate the finite-sample performance of our approach through Monte Carlo experiments.

**摘要:** 在电子商务、医疗及政策制定中,多武装盗窃算法越来越多地被用于补充或整合A/B测试和随机化临床试验。最近的发展包括可能延迟反馈。虽然现有的MAB文献往往着重于最大化预期累积奖励结果(或类似地,减少遗憾),但很少有人致力于建立有效的统计推断方法来量化学到的政策不确定性。我们试图通过提供一个统一的统计推断框架来填补这一空白,以便评估政策,其中一个目标政策可以与数据收集政策不同,而我们的框架允许延迟与治疗手段相联系。本文提出了一种自适应权重估算器,它一方面结合了基于手臂的延迟机制,以达到一致性,另一方面由于样本概率消失而缓解了各阶段的变量膨胀。特别是,我们的估算器不依赖于估计未知延迟机制的能力。在适当条件下,我们证明了当时间点数达到无限时,我们的估算器会趋向正常分布,这为大样本统计推导提供了保障。

**[Paper URL](https://proceedings.mlr.press/v202/shi23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shi23g/shi23g.pdf)** 

# Provably Efficient Offline Reinforcement Learning with Perturbed Data Sources
**题目:** 基于扰动数据源的有效在线强化学习

**作者:** Chengshuai Shi, Wei Xiong, Cong Shen, Jing Yang

**Abstract:** Existing theoretical studies on offline reinforcement learning (RL) mostly consider a dataset sampled directly from the target task. In practice, however, data often come from several heterogeneous but related sources. Motivated by this gap, this work aims at rigorously understanding offline RL with multiple datasets that are collected from randomly perturbed versions of the target task instead of from itself. An information-theoretic lower bound is derived, which reveals a necessary requirement on the number of involved sources in addition to that on the number of data samples. Then, a novel HetPEVI algorithm is proposed, which simultaneously considers the sample uncertainties from a finite number of data samples per data source and the source uncertainties due to a finite number of available data sources. Theoretical analyses demonstrate that HetPEVI can solve the target task as long as the data sources collectively provide a good data coverage. Moreover, HetPEVI is demonstrated to be optimal up to a polynomial factor of the horizon length. Finally, the study is extended to offline Markov games and offline robust RL, which demonstrates the generality of the proposed designs and theoretical analyses.

**摘要:** 现有的网络增强学习理论研究主要考虑从目标任务中直接提取的数据集。然而,数据往往来自多个异质源,但有关联源。由于这一差距,本研究旨在严格理解网络增强学习的多个数据集,这些数据集来自目标任务的随机变异版本,而不是来自自己。导出了一种信息理论下界限,该界限揭示了有关数据样本数的数量以及数据样本数的数量上的必要要求。此外,证明了HetPEVI在水平长度的多项式系数上是最优的。最后,研究扩展到非线性马可夫游戏和非线性鲁棒RL,说明了提议的设计和理论分析的普遍性。

**[Paper URL](https://proceedings.mlr.press/v202/shi23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shi23h/shi23h.pdf)** 

# On the Complexity of Bayesian Generalization
**题目:** 贝叶斯综合论的复杂性

**作者:** Yu-Zhe Shi, Manjie Xu, John E. Hopcroft, Kun He, Joshua B. Tenenbaum, Song-Chun Zhu, Ying Nian Wu, Wenjuan Han, Yixin Zhu

**Abstract:** We examine concept generalization at a large scale in the natural visual spectrum. Established computational modes (i.e., rule-based or similarity-based) are primarily studied isolated, focusing on confined and abstract problem spaces. In this work, we study these two modes when the problem space scales up and when the complexity of concepts becomes diverse. At the representational level, we investigate how the complexity varies when a visual concept is mapped to the representation space. Prior literature has shown that two types of complexities (Griffiths & Tenenbaum, 2003) build an inverted-U relation (Donderi, 2006; Sun & Firestone, 2021). Leveraging Representativeness of Attribute (RoA), we computationally confirm: Models use attributes with high RoA to describe visual concepts, and the description length falls in an inverted-U relation with the increment in visual complexity. At the computational level, we examine how the complexity of representation affects the shift between the rule- and similarity-based generalization. We hypothesize that category-conditioned visual modeling estimates the co-occurrence frequency between visual and categorical attributes, thus potentially serving as the prior for the natural visual world. Experimental results show that representations with relatively high subjective complexity outperform those with relatively low subjective complexity in rule-based generalization, while the trend is the opposite in similarity-based generalization.

**摘要:** 在自然视觉谱中,我们对概念的广义化进行了研究。建立的计算模式(即基于规则或相似性)主要被孤立研究,重点放在有限和抽象问题空间上。在这个工作中,我们研究这两个模式,当问题空间升高时和当概念的复杂性变异时。在表示层面,我们研究如何复杂性变化,当一个视觉概念被映射到表示空间时。在计算层面,我们研究了表示的复杂性如何影响规则和相似性一般化之间的转变。我们假设类别条件下的视觉建模估计了视觉和类别属性之间的共发生频率,从而可能成为自然视觉世界的前身。实验结果表明,相对较高的主观复杂性表示在规则一般化中优于相对较低的主观复杂性表示,而相似性一般化中趋势是相反的。

**[Paper URL](https://proceedings.mlr.press/v202/shi23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shi23i/shi23i.pdf)** 

# Understanding and Generalizing Contrastive Learning from the Inverse Optimal Transport Perspective
**题目:** 从逆优化运输视角理解和概括矛盾学习

**作者:** Liangliang Shi, Gu Zhang, Haoyu Zhen, Jintao Fan, Junchi Yan

**Abstract:** Previous research on contrastive learning (CL) has primarily focused on pairwise views to learn representations by attracting positive samples and repelling negative ones. In this work, we aim to understand and generalize CL from a point set matching perspective, instead of the comparison between two points. Specifically, we formulate CL as a form of inverse optimal transport (IOT), which involves a bilevel optimization procedure for learning where the outter minimization aims to learn the representations and the inner is to learn the coupling (i.e. the probability of matching matrix) between the point sets. Specifically, by adjusting the relaxation degree of constraints in the inner minimization, we obtain three contrastive losses and show that the dominant contrastive loss in literature InfoNCE falls into one of these losses. This reveals a new and more general algorithmic framework for CL. Additionally, the soft matching scheme in IOT induces a uniformity penalty to enhance representation learning which is akin to the CL’s uniformity. Results on vision benchmarks show the effectiveness of our derived loss family and the new uniformity term.

**摘要:** 对比性学习(英语:Contrasticive learning,缩写为CL)的研究主要集中在对称视角上,通过吸引正样品和消灭负样品来学习表示。本研究的目的在于从两个点之间的比较,而不是从一个点集匹配视角来理解和推广CL。具体而言,我们将CL定义为反向优化传输(IOT)的形式,它涉及学习的双层优化过程,其中外层最小化的目标是学习表示,内层则是学习点集之间的耦合(即匹配矩阵的概率)。具体而言,通过调整内层最小化约束的松弛程度,我们获得了三个对比性损失,并表明InfoNCE文献中主导的对比性损失属于其中之一。此外,IOT的软匹配方案诱导了统一性处罚,以提高代表学习,类似于 CL的统一性。视觉基准的结果显示了我们导出的损失家族和新的统一性术语的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/shi23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shi23j/shi23j.pdf)** 

# Long Horizon Temperature Scaling
**题目:** 长水平温度计

**作者:** Andy Shih, Dorsa Sadigh, Stefano Ermon

**Abstract:** Temperature scaling is a popular technique for tuning the sharpness of a model distribution. It is used extensively for sampling likely generations and calibrating model uncertainty, and even features as a controllable parameter to many large language models in deployment. However, autoregressive models rely on myopic temperature scaling that greedily optimizes the next token. To address this, we propose Long Horizon Temperature Scaling (LHTS), a novel approach for sampling from temperature-scaled joint distributions. LHTS is compatible with all likelihood-based models, and optimizes for the long-horizon likelihood of samples. We derive a temperature-dependent LHTS objective, and show that fine-tuning a model on a range of temperatures produces a single model capable of generation with a controllable long-horizon temperature parameter. We experiment with LHTS on image diffusion models and character/language autoregressive models, demonstrating its advantages over myopic temperature scaling in likelihood and sample quality, and showing improvements in accuracy of a multiple choice analogy by $10$%.

**摘要:** 温度尺度是调度模型分布的敏锐度的一种流行技术,广泛用于采样可能的代数和校准模型不确定性,甚至在部署中使用许多大型语言模型的可控参数。然而,自回归模型依赖于光学温度尺度,以贪婪优化下一个符号。为了解决这个问题,我们提出了长平温度尺度(LHTS),一种从温度尺度分布中采样的新方法。LHTS与所有基于概率的模型兼容,并优化了样品的长平概率。我们对LHTS在图像扩散模型和字符/语言自回归模型上进行了实验,证明了它在概率和样品质量上比光学温度尺度的优越性,并显示了多选择模拟的精度提高10$%。

**[Paper URL](https://proceedings.mlr.press/v202/shih23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shih23a/shih23a.pdf)** 

# Gradient Descent in Neural Networks as Sequential Learning in Reproducing Kernel Banach Space
**题目:** 神经网络梯度演化在核贝纳奇空间的序列学习中

**作者:** Alistair Shilton, Sunil Gupta, Santu Rana, Svetha Venkatesh

**Abstract:** The study of Neural Tangent Kernels (NTKs) has provided much needed insight into convergence and generalization properties of neural networks in the over-parametrized (wide) limit by approximating the network using a first-order Taylor expansion with respect to its weights in the neighborhood of their initialization values. This allows neural network training to be analyzed from the perspective of reproducing kernel Hilbert spaces (RKHS), which is informative in the over-parametrized regime, but a poor approximation for narrower networks as the weights change more during training. Our goal is to extend beyond the limits of NTK toward a more general theory. We construct an exact power-series representation of the neural network in a finite neighborhood of the initial weights as an inner product of two feature maps, respectively from data and weight-step space, to feature space, allowing neural network training to be analyzed from the perspective of reproducing kernel Banach space (RKBS). We prove that, regardless of width, the training sequence produced by gradient descent can be exactly replicated by regularized sequential learning in RKBS. Using this, we present novel bound on uniform convergence where the iterations count and learning rate play a central role, giving new theoretical insight into neural network training.

**摘要:** 神经 Tangent Kernels(NTKs)的研究为神经网络在超参数化(宽)限度中的收敛和一般化特性提供了必要的洞察力,通过对其初始化值邻近的重量使用第一阶泰勒扩展来近似网络。这允许神经网络训练从复制核希尔伯特空间(RKHS)的视角进行分析,这在超参数化模式中是有益的,但由于重量在训练期间更变化,较窄的网络的近似较差。我们的目标是将NTK的限度扩展到更普遍的理论。构造了两个特征映射的内部产物,分别从数据空间和重量步骤空间到特征空间的有限邻域中对神经网络的精确功率序列表示,使神经网络训练能够从复制核班纳赫空间(RKBS)的角度进行分析。我们证明,无论其宽度如何,梯度下降所产生的训练序列都可以通过在RKBS中定律的顺序学习得到精确的复制。

**[Paper URL](https://proceedings.mlr.press/v202/shilton23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shilton23a/shilton23a.pdf)** 

# SNeRL: Semantic-aware Neural Radiance Fields for Reinforcement Learning
**题目:** SNeRL:语义意识神经辐射场增强学习

**作者:** Dongseok Shim, Seungjae Lee, H. Jin Kim

**Abstract:** As previous representations for reinforcement learning cannot effectively incorporate a human-intuitive understanding of the 3D environment, they usually suffer from sub-optimal performances. In this paper, we present Semantic-aware Neural Radiance Fields for Reinforcement Learning (SNeRL), which jointly optimizes semantic-aware neural radiance fields (NeRF) with a convolutional encoder to learn 3D-aware neural implicit representation from multi-view images. We introduce 3D semantic and distilled feature fields in parallel to the RGB radiance fields in NeRF to learn semantic and object-centric representation for reinforcement learning. SNeRL outperforms not only previous pixel-based representations but also recent 3D-aware representations both in model-free and model-based reinforcement learning.

**摘要:** 由于以往的增强学习表现不能有效地结合人感的3D环境理解,它们通常 suffer from sub-optimal performances 。 本论文提出了增强学习的语义意识神经辐射场(英语:Semantic-aware Neural Radiance Fields for Reinforcement Learning,SNeRL),它联合优化语义意识神经辐射场(英语:Semantic-aware neural radiance fields,NeRF)并用volutional encoder学习多视图图像中的3D意识神经隐形表示。

**[Paper URL](https://proceedings.mlr.press/v202/shim23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shim23a/shim23a.pdf)** 

# A Closer Look at the Intervention Procedure of Concept Bottleneck Models
**题目:** 对概念双eck模型的干预程序进行更深入的探讨

**作者:** Sungbin Shin, Yohan Jo, Sungsoo Ahn, Namhoon Lee

**Abstract:** Concept bottleneck models (CBMs) are a class of interpretable neural network models that predict the target response of a given input based on its high-level concepts. Unlike the standard end-to-end models, CBMs enable domain experts to intervene on the predicted concepts and rectify any mistakes at test time, so that more accurate task predictions can be made at the end. While such intervenability provides a powerful avenue of control, many aspects of the intervention procedure remain rather unexplored. In this work, we develop various ways of selecting intervening concepts to improve the intervention effectiveness and conduct an array of in-depth analyses as to how they evolve under different circumstances. Specifically, we find that an informed intervention strategy can reduce the task error more than ten times compared to the current baseline under the same amount of intervention counts in realistic settings, and yet, this can vary quite significantly when taking into account different intervention granularity. We verify our findings through comprehensive evaluations, not only on the standard real datasets, but also on synthetic datasets that we generate based on a set of different causal graphs. We further discover some major pitfalls of the current practices which, without a proper addressing, raise concerns on reliability and fairness of the intervention procedure.

**摘要:** 概念瓶颈模型(英语:Concept bottleneck models,缩写CBM)是一种基于高层次概念的可解释神经网络模型,可以预测给定输入的目标响应。与标准的端到端模型不同,CBM可以让域专家对预测的概念进行干预,并在测试时纠正任何错误,从而在最后可以作出更准确的任务预测。虽然这种干预性提供了强大的控制途径,但干预程序的许多方面仍未被探索。具体说来,我们发现,在现实环境中,基于相同数量的干预计数的干预策略可以减少任务误差超过十倍,但考虑到不同的干预细微性,这在很大程度上会有所不同。我们通过综合评价,不仅对标准的实际数据集进行验证,而且对基于不同因果图的综合数据集进行验证。

**[Paper URL](https://proceedings.mlr.press/v202/shin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shin23a/shin23a.pdf)** 

# MetricGAN-OKD: Multi-Metric Optimization of MetricGAN via Online Knowledge Distillation for Speech Enhancement
**题目:** MetricGAN-OKD:通过在线知识提馏对MetricGAN进行多量度优化

**作者:** Wooseok Shin, Byung Hoon Lee, Jin Sob Kim, Hyun Joon Park, Sung Won Han

**Abstract:** In speech enhancement, MetricGAN-based approaches reduce the discrepancy between the $L_p$ loss and evaluation metrics by utilizing a non-differentiable evaluation metric as the objective function. However, optimizing multiple metrics simultaneously remains challenging owing to the problem of confusing gradient directions. In this paper, we propose an effective multi-metric optimization method in MetricGAN via online knowledge distillation—MetricGAN-OKD. MetricGAN-OKD, which consists of multiple generators and target metrics, related by a one-to-one correspondence, enables generators to learn with respect to a single metric reliably while improving performance with respect to other metrics by mimicking other generators. Experimental results on speech enhancement and listening enhancement tasks reveal that the proposed method significantly improves performance in terms of multiple metrics compared to existing multi-metric optimization methods. Further, the good performance of MetricGAN-OKD is explained in terms of network generalizability and correlation between metrics.

**摘要:** 在语音增强中,基于MetricGAN的方法通过使用非可区分的评价度量作为目标函数来减少$L_p$损失和评价度量之间的差异。然而,同时优化多个度量仍然是由于混淆梯度方向的问题而困难的。本论文通过在线知识蒸馏提出了一种有效的多度量优化方法MetricGAN—MetricGAN-OKD。本文还从网络广义化和度量间的相关性等方面解释了MetricGAN-OKD的良好性能。

**[Paper URL](https://proceedings.mlr.press/v202/shin23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shin23b/shin23b.pdf)** 

# Improved Learning-Augmented Algorithms for the Multi-Option Ski Rental Problem via Best-Possible Competitive Analysis
**题目:** 基于最佳竞争分析的多选择滑雪租用问题改进学习增强算法

**作者:** Yongho Shin, Changyeol Lee, Gukryeol Lee, Hyung-Chan An

**Abstract:** In this paper, we present improved learning-augmented algorithms for the multi-option ski rental problem. Learning-augmented algorithms take ML predictions as an added part of the input and incorporates these predictions in solving the given problem. Due to their unique strength that combines the power of ML predictions with rigorous performance guarantees, they have been extensively studied in the context of online optimization problems. Even though ski rental problems are one of the canonical problems in the field of online optimization, only deterministic algorithms were previously known for multi-option ski rental, with or without learning augmentation. We present the first randomized learning-augmented algorithm for this problem, surpassing previous performance guarantees given by deterministic algorithms. Our learning-augmented algorithm is based on a new, provably best-possible randomized competitive algorithm for the problem. Our results are further complemented by lower bounds for deterministic and randomized algorithms, and computational experiments evaluating our algorithms’ performance improvements.

**摘要:** 本文针对多选择滑雪租用问题,提出了改进的多选择滑雪租用算法。多选择滑雪租用算法将ML预测作为输入的附加部分,并结合这些预测来解决该问题。由于它们的独特优势,结合ML预测的强力和严格性能保证,它们在在线优化问题中得到了广泛的研究。我们的结果还得到确定和随机算法的更低限度以及计算实验来评价算法性能的改进。

**[Paper URL](https://proceedings.mlr.press/v202/shin23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shin23c/shin23c.pdf)** 

# One-shot Imitation in a Non-Stationary Environment via Multi-Modal Skill
**题目:** 通过多模技能在非静态环境中进行一击仿真

**作者:** Sangwoo Shin, Daehee Lee, Minjong Yoo, Woo Kyung Kim, Honguk Woo

**Abstract:** One-shot imitation is to learn a new task from a single demonstration, yet it is a challenging problem to adopt it for complex tasks with the high domain diversity inherent in a non-stationary environment. To tackle the problem, we explore the compositionality of complex tasks, and present a novel skill-based imitation learning framework enabling one-shot imitation and zero-shot adaptation; from a single demonstration for a complex unseen task, a semantic skill sequence is inferred and then each skill in the sequence is converted into an action sequence optimized for environmental hidden dynamics that can vary over time. Specifically, we leverage a vision-language model to learn a semantic skill set from offline video datasets, where each skill is represented on the vision-language embedding space, and adapt meta-learning with dynamics inference to enable zero-shot skill adaptation. We evaluate our framework with various one-shot imitation scenarios for extended multi-stage Meta-world tasks, showing its superiority in learning complex tasks, generalizing to dynamics changes, and extending to different demonstration conditions and modalities, compared to other baselines.

**摘要:** 单击仿真是通过单一演示学习新任务,但对于非静态环境中具有高度域多样性的复杂任务,采用单一演示是一项挑战性问题。为了解决这一问题,我们探讨了复杂任务的组成性,并提出了一种新的基于技能的仿真学习框架,允许单击仿真和零击适应;从单一演示对复杂未知任务中,推导出语义技能序列,然后将该序列中的每个技能转换为一种为环境隐藏动态优化的动作序列,这种动态随时间变化而变化。我们对扩展多阶段的Meta-world任务采用了多种单击仿真场景来评价我们的框架,显示它在学习复杂任务方面具有优势,一般化到动态变化,并扩展到不同的示范条件和模式,与其他基本线相比。

**[Paper URL](https://proceedings.mlr.press/v202/shin23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shin23d/shin23d.pdf)** 

# Context Consistency Regularization for Label Sparsity in Time Series
**题目:** 基于时间序列的标签节余的上下文一致性规范化

**作者:** Yooju Shin, Susik Yoon, Hwanjun Song, Dongmin Park, Byunghyun Kim, Jae-Gil Lee, Byung Suk Lee

**Abstract:** Labels are typically sparse in real-world time series due to the high annotation cost. Recently, consistency regularization techniques have been used to generate artificial labels from unlabeled augmented instances. To fully exploit the sequential characteristic of time series in consistency regularization, we propose a novel method of data augmentation called context-attached augmentation, which adds preceding and succeeding instances to a target instance to form its augmented instance. Unlike the existing augmentation techniques that modify a target instance by directly perturbing its attributes, the context-attached augmentation generates instances augmented with varying contexts while maintaining the target instance. Based on our augmentation method, we propose a context consistency regularization framework, which first adds different contexts to a target instance sampled from a given time series and then shares unitary reliability-based cross-window labels across the augmented instances to maintain consistency. We demonstrate that the proposed framework outperforms the existing state-of-the-art consistency regularization frameworks through comprehensive experiments on real-world time-series datasets.

**摘要:** 由于注释成本高,在实时序列中标签通常很稀少。最近,一致性规则化技术被用于从未标记的增量实例生成人工标签。为了充分利用一致性规则化中时间序列的顺序特性,我们提出了一种新的数据增量方法,即上下文附加增量,它将前后继的实例添加到目标实例以形成其增量实例。基于增强方法,我们提出了一个上下文一致性规范化框架,首先将从指定时间序列中提取的对象实例中添加不同的上下文,然后在增强实例中共享统一的基于可靠性的交叉窗口标签,以保持一致性。

**[Paper URL](https://proceedings.mlr.press/v202/shin23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shin23e/shin23e.pdf)** 

# Generative Causal Representation Learning for Out-of-Distribution Motion Forecasting
**题目:** 非分布运动预测的 Generative Causal Representation Learning

**作者:** Shayan Shirahmad Gale Bagi, Zahra Gharaee, Oliver Schulte, Mark Crowley

**Abstract:** Conventional supervised learning methods typically assume i.i.d samples and are found to be sensitive to out-of-distribution (OOD) data. We propose Generative Causal Representation Learning (GCRL) which leverages causality to facilitate knowledge transfer under distribution shifts. While we evaluate the effectiveness of our proposed method in human trajectory prediction models, GCRL can be applied to other domains as well. First, we propose a novel causal model that explains the generative factors in motion forecasting datasets using features that are common across all environments and with features that are specific to each environment. Selection variables are used to determine which parts of the model can be directly transferred to a new environment without fine-tuning. Second, we propose an end-to-end variational learning paradigm to learn the causal mechanisms that generate observations from features. GCRL is supported by strong theoretical results that imply identifiability of the causal model under certain assumptions. Experimental results on synthetic and real-world motion forecasting datasets show the robustness and effectiveness of our proposed method for knowledge transfer under zero-shot and low-shot settings by substantially outperforming the prior motion forecasting models on out-of-distribution prediction.

**摘要:** 传统的监督学习方法通常采用i.i.d样本,并且对非分布(OOD)数据具有敏感性。我们提议生成因果关系学习(GCRL),利用因果关系来促进知识的传递,在分布转移下。虽然我们评估了我们提议的方法在人类轨迹预测模型中的有效性,GCRL也可以应用于其他领域。首先,我们提议一种新颖的因果模型,解释了运动预测数据集中产生因果的因素,使用所有环境中常见的特征和每个环境的具体特征。选择变量被用来确定模型的哪些部分可以直接转移到一个新环境,而不需精细调整。其次,我们提议一个从端到端的变量学习范式,以学习产生特征的因果机制。通过对合成和实物运动预测数据集的实验结果,证明了在零射程和低射程环境下知识传递方法的鲁棒性和有效性,大大超过了以往在非分布预测中运动预测模型。

**[Paper URL](https://proceedings.mlr.press/v202/shirahmad-gale-bagi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shirahmad-gale-bagi23a/shirahmad-gale-bagi23a.pdf)** 

# Exphormer: Sparse Transformers for Graphs
**题目:** 说明书:图形备用变形器

**作者:** Hamed Shirzad, Ameya Velingker, Balaji Venkatachalam, Danica J. Sutherland, Ali Kemal Sinop

**Abstract:** Graph transformers have emerged as a promising architecture for a variety of graph learning and representation tasks. Despite their successes, though, it remains challenging to scale graph transformers to large graphs while maintaining accuracy competitive with message-passing networks. In this paper, we introduce Exphormer, a framework for building powerful and scalable graph transformers. Exphormer consists of a sparse attention mechanism based on two mechanisms: virtual global nodes and expander graphs, whose mathematical characteristics, such as spectral expansion, pseduorandomness, and sparsity, yield graph transformers with complexity only linear in the size of the graph, while allowing us to prove desirable theoretical properties of the resulting transformer models. We show that incorporating Exphormer into the recently-proposed GraphGPS framework produces models with competitive empirical results on a wide variety of graph datasets, including state-of-the-art results on three datasets. We also show that Exphormer can scale to datasets on larger graphs than shown in previous graph transformer architectures.

**摘要:** 图形变换器作为各种图形学习和表示任务的有前途的架构出现,尽管它们取得了成功,但仍难以将图形变换器扩展到大型图形,同时保持与传递信息的网络的精度竞争。本文介绍了强有力和可扩展的图形变换器的构架exphormer。 Exphormer由基于两个机制的稀疏注意机制组成:虚拟全球节点和扩展器图形,其数学特征,如光谱扩散、伪随机性和稀疏性,只在图形大小中提供复杂度的图形变换器,同时允许我们证明结果的变换器模型的理想理论特性。我们证明,将exphormer纳入最近提出的GraphGPS框架,能够对各种图数据集产生具有竞争性经验结果的模型,包括对三个数据集的最先进的结果。

**[Paper URL](https://proceedings.mlr.press/v202/shirzad23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shirzad23a/shirzad23a.pdf)** 

# Synthetic data for model selection
**题目:** 模型选择的合成数据

**作者:** Alon Shoshan, Nadav Bhonker, Igor Kviatkovsky, Matan Fintz, Gerard Medioni

**Abstract:** Recent breakthroughs in synthetic data generation approaches made it possible to produce highly photorealistic images which are hardly distinguishable from real ones. Furthermore, synthetic generation pipelines have the potential to generate an unlimited number of images. The combination of high photorealism and scale turn synthetic data into a promising candidate for improving various machine learning (ML) pipelines. Thus far, a large body of research in this field has focused on using synthetic images for training, by augmenting and enlarging training data. In contrast to using synthetic data for training, in this work we explore whether synthetic data can be beneficial for model selection. Considering the task of image classification, we demonstrate that when data is scarce, synthetic data can be used to replace the held out validation set, thus allowing to train on a larger dataset. We also introduce a novel method to calibrate the synthetic error estimation to fit that of the real domain. We show that such calibration significantly improves the usefulness of synthetic data for model selection.

**摘要:** 在合成数据生成方法中,最近的突破使得能够产生高超现实的图像,难以与真实图像区分。此外,合成生成管道具有产生无限数量的图像的潜力。高现实性和规模的组合将合成数据转化为改进各种机器学习(ML)管道的有前途的候选者。迄今为止,在这个领域,大量的研究集中在使用合成图像进行训练,通过增加和扩大训练数据。本文还介绍了一种新方法来校正合成误差估计,以适应实域误差估计。

**[Paper URL](https://proceedings.mlr.press/v202/shoshan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shoshan23a/shoshan23a.pdf)** 

# Probabilistic Attention-to-Influence Neural Models for Event Sequences
**题目:** 事件序列的概率注意影响神经模型

**作者:** Xiao Shou, Debarun Bhattacharjya, Tian Gao, Dharmashankar Subramanian, Oktie Hassanzadeh, Kristin Bennett

**Abstract:** Discovering knowledge about which types of events influence others, using datasets of event sequences without time stamps, has several practical applications. While neural sequence models are able to capture complex and potentially long-range historical dependencies, they often lack the interpretability of simpler models for event sequence dynamics. We provide a novel neural framework in such a setting - a probabilistic attention-to-influence neural model - which not only captures complex instance-wise interactions between events but also learns influencers for each event type of interest. Given event sequence data and a prior distribution on type-wise influence, we efficiently learn an approximate posterior for type-wise influence by an attention-to-influence transformation using variational inference. Our method subsequently models the conditional likelihood of sequences by sampling the above posterior to focus attention on influencing event types. We motivate our general framework and show improved performance in experiments compared to existing baselines on synthetic data as well as real-world benchmarks, for tasks involving prediction and influencing set identification.

**摘要:** 利用无时间标记的事件序列数据集,发现哪些类型事件影响他人的知识具有多种实际应用。虽然神经序列模型能够捕捉复杂和潜在的长期历史依赖性,但它们往往缺乏事件序列动力学的较简单的模型的解释性。我们在这样的环境中提供了一种新颖的神经框架--概率性注意-对-影响神经模型--它不仅捕捉了事件之间的复杂实例性相互作用,而且也学习了对每个事件类型感兴趣的影响者。在预测和影响集合识别的任务中,我们激励了我们的总体框架,并在实验中表现出与现有的合成数据和现实的基准相比的改进表现。

**[Paper URL](https://proceedings.mlr.press/v202/shou23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shou23a/shou23a.pdf)** 

# Causal Bounds in Quasi-Markovian Graphs
**题目:** Quasi-Markovian图中的动因界限

**作者:** Madhumitha Shridharan, Garud Iyengar

**Abstract:** We consider the problem of computing bounds for causal queries on quasi-Markovian graphs with unobserved confounders and discrete valued observed variables, where identifiability does not hold. Existing non-parametric approaches for computing such bounds use multilinear programming (MP) formulations that are often intractable for existing solvers when the degree of the polynomial objective is greater than two. Hence, one often has to resort to either fast approximate heuristics which are not guaranteed to contain the true query value, or more accurate but computationally intensive procedures. We show how to construct an equivalent MP with a polynomial objective of lower degree. In particular, the degree of the objective in the new MP is equal to only the number of C-components that are intervened upon, instead of the total number of C-components. As a result, we can compute exact bounds for significantly larger causal inference problems as compared to what is possible using existing techniques. We also propose a very efficient Frank-Wolfe heuristic that produces very high quality bounds, and scales to large multilinear problems of higher degree.

**摘要:** 我们考虑了在非 Markovian 图形上因果查询的计算边界问题,其中没有观察到的混淆因素和离散值的观察变量,其中可辨识性并不存在。现有的非参数方法用于计算这些边界,使用多线性编程(MP)公式,当多项式目标的程度超过两倍时,经常无法解决现有的求解者。因此,人们往往需要采用快速的近似求解方法,不能保证包含真正的查询值,或者更准确但计算密集的程序。结果表明,在现有技术下,我们能够计算更大规模的因果推理问题所需的精确界限,并提出了一种非常高效的法兰克-沃尔夫理论,产生高质量的界限,并 scales to large multilinear problems of higher degree。

**[Paper URL](https://proceedings.mlr.press/v202/shridharan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shridharan23a/shridharan23a.pdf)** 

# Repository-Level Prompt Generation for Large Language Models of Code
**题目:** 大型语言代码模型的存储级快速生成

**作者:** Disha Shrivastava, Hugo Larochelle, Daniel Tarlow

**Abstract:** With the success of large language models (LLMs) of code and their use as code assistants (e.g. Codex used in GitHub Copilot), techniques for introducing domain-specific knowledge in the prompt design process become important. In this work, we propose a framework called Repo-Level Prompt Generator that learns to generate example-specific prompts using prompt proposals. The prompt proposals take context from the entire repository, thereby incorporating both the structure of the repository and the context from other relevant files (e.g. imports, parent class files). Our technique doesn’t require any access to the weights of the LLM, making it applicable in cases where we only have black-box access to the LLM. We conduct experiments on the task of single-line code auto-completion using code repositories taken from Google Code archives. We demonstrate that an oracle constructed from our prompt proposals gives a relative improvement of 36% over Codex, showing the quality of these proposals. Further, we show that when we train a model to predict a prompt proposal, we can achieve significant performance gains over Codex and other baselines. We release our code, data, and trained checkpoints at: https://github.com/shrivastavadisha/repo_level_prompt_generation.

**摘要:** 由于代码的大型语言模型(LLMs)的成功及其作为代码助手(例如在GitHub Copilot中使用的Codex)的使用,在提示设计过程中引入域特定知识的技术变得重要。在这个工作中,我们提出了一个叫做Repo-Level提示生成器的框架,该框架学习使用提示建议生成实例特定提示。提示建议从整个存储库中获取上下文,从而结合存储库的结构和其他相关文件(例如进口、母类文件)的上下文。我们证明,从我们的快速提议中构建的口号比库德克斯有36%的相对改善,显示了这些提议的质量。此外,我们证明,当我们训练一个模型来预测一个快速提议时,我们可以在库德克斯和其他基线上取得显著的性能提升。

**[Paper URL](https://proceedings.mlr.press/v202/shrivastava23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shrivastava23a/shrivastava23a.pdf)** 

# CLIPood: Generalizing CLIP to Out-of-Distributions
**题目:** CLIPood:将CLIP推广到外发

**作者:** Yang Shu, Xingzhuo Guo, Jialong Wu, Ximei Wang, Jianmin Wang, Mingsheng Long

**Abstract:** Out-of-distribution (OOD) generalization, where the model needs to handle distribution shifts from training, is a major challenge of machine learning. Contrastive language-image pre-training (CLIP) models have shown impressive zero-shot ability, but the further adaptation of CLIP on downstream tasks undesirably degrades OOD performances. This paper aims at generalizing CLIP to out-of-distribution test data on downstream tasks. We propose CLIPood, a fine-tuning method that can adapt CLIP models to OOD situations where both domain shifts and open classes may occur on the unseen test data. To exploit the semantic relations between classes from the text modality, CLIPood introduces a new training objective, margin metric softmax (MMS), with class adaptive margins for fine-tuning. To incorporate both pre-trained zero-shot model and fine-tuned task-adaptive model, CLIPood leverages a new optimization strategy, Beta moving average (BMA), to maintain a temporal ensemble weighted by Beta distribution. Experiments on diverse datasets with different OOD scenarios show that CLIPood consistently outperforms existing generalization techniques.

**摘要:** 非分布式(OOD)一般化(out-of-distribution)是机器学习的一个主要挑战,该模型需要处理从训练中发生的分布性转变。反向语言-图像预训练(CLIP)模型显示出令人印象深刻的零射击能力,但在下游任务上进一步调整CLIP却不希望降低OOD性能。本论文旨在将CLIP推广到下游任务上的非分布式测试数据。我们提出了CLIPood,一种可以适应CLIP模型的细微调制方法,该方法可以使CLIP模型在无视测试数据上发生域转移和开放类的情况。为了结合预训练的零射程模型和精确调整的任务适应性模型,CLIPood利用一种新的优化策略,即Beta移动平均(BMA)来维持以Beta分布为权重的时态组合。

**[Paper URL](https://proceedings.mlr.press/v202/shu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/shu23a/shu23a.pdf)** 

# Semi-Autoregressive Energy Flows: Exploring Likelihood-Free Training of Normalizing Flows
**题目:** 半自动能量流动:研究正常化流动的无风险训练

**作者:** Phillip Si, Zeyi Chen, Subham Sekhar Sahoo, Yair Schiff, Volodymyr Kuleshov

**Abstract:** Training normalizing flow generative models can be challenging due to the need to calculate computationally expensive determinants of Jacobians. This paper studies the likelihood-free training of flows and proposes the energy objective, an alternative sample-based loss based on proper scoring rules. The energy objective is determinant-free and supports flexible model architectures that are not easily compatible with maximum likelihood training, including semi-autoregressive energy flows, a novel model family that interpolates between fully autoregressive and non-autoregressive models. Energy flows feature competitive sample quality, posterior inference, and generation speed relative to likelihood-based flows; this performance is decorrelated from the quality of log-likelihood estimates, which are generally very poor. Our findings question the use of maximum likelihood as an objective or a metric, and contribute to a scientific study of its role in generative modeling. Code is available at https://github.com/ps789/SAEF.

**摘要:** 该文研究了流动的无概率训练,并提出了一种基于适当评分规则的替代样本损失的能量目标。 能量目标是无决定剂的,支持灵活的模型架构,不易于与最大概率训练兼容,包括半自回归的能量流动,一种全新的模型家族,它将完全自回归和非自回归的模型之间进行插值。 能量流动的特点是具有竞争性样本质量、后推导和与基于概率的流动的生成速度;这种性能与ログ概率估计的质量有关,一般是非常差的。代码在 https://github.com/ps789/SAEF 上。

**[Paper URL](https://proceedings.mlr.press/v202/si23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/si23a/si23a.pdf)** 

# Unearthing InSights into Mars: Unsupervised Source Separation with Limited Data
**题目:** 进入火星的洞察:没有监督的源区分与有限数据

**作者:** Ali Siahkoohi, Rudy Morel, Maarten V. De Hoop, Erwan Allys, Gregory Sainton, Taichi Kawamura

**Abstract:** Source separation involves the ill-posed problem of retrieving a set of source signals that have been observed through a mixing operator. Solving this problem requires prior knowledge, which is commonly incorporated by imposing regularity conditions on the source signals, or implicitly learned through supervised or unsupervised methods from existing data. While data-driven methods have shown great promise in source separation, they often require large amounts of data, which rarely exists in planetary space missions. To address this challenge, we propose an unsupervised source separation scheme for domains with limited data access that involves solving an optimization problem in the wavelet scattering covariance representation space—an interpretable, low-dimensional representation of stationary processes. We present a real-data example in which we remove transient, thermally-induced microtilts—known as glitches—from data recorded by a seismometer during NASA’s InSight mission on Mars. Thanks to the wavelet scattering covariances’ ability to capture non-Gaussian properties of stochastic processes, we are able to separate glitches using only a few glitch-free data snippets.

**摘要:** 源区分涉及通过混合运算器观察到的源信号的集合检索的不良问题。解决这一问题需要先知,通常通过对源信号的规律性条件强加,或隐含地从现有数据中通过监督或非监督的方法学习。虽然数据驱动方法在源区分中表现出巨大的前景,但它们往往需要大量数据,在行星空间任务中很少存在。为了解决这一挑战,我们提出了一个有限数据访问域的非监督源区分方案,它涉及解决散射小波共振表示空间中的优化问题 — — 一种可解释、低维的静态过程的表示。由于小波散射变量能够捕捉随机过程的非高斯性质,我们只能使用少数无误数据片段来分离误差。

**[Paper URL](https://proceedings.mlr.press/v202/siahkoohi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/siahkoohi23a/siahkoohi23a.pdf)** 

# Quantitative Universal Approximation Bounds for Deep Belief Networks
**题目:** 深信网络的量化通用近似界限

**作者:** Julian Sieber, Johann Gehringer

**Abstract:** We show that deep belief networks with binary hidden units can approximate any multivariate probability density under very mild integrability requirements on the parental density of the visible nodes. The approximation is measured in the $L^q$-norm for $q\in[1,\infty]$ ($q=\infty$ corresponding to the supremum norm) and in Kullback-Leibler divergence. Furthermore, we establish sharp quantitative bounds on the approximation error in terms of the number of hidden units.

**摘要:** 我们证明,具有二进制隐藏单元的深信网络能够在可视节点的母节点密度的非常轻微整合性要求下近似任何多变量概率密度。近似值在$q\in[1,\infty]$($q=\infty$与最高标准相符)和库尔巴克-莱布尔偏差的$L^q$-标准中测量。

**[Paper URL](https://proceedings.mlr.press/v202/sieber23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sieber23a/sieber23a.pdf)** 

# Pricing Experimental Design: Causal Effect, Expected Revenue and Tail Risk
**题目:** 价格试验设计:原因效应、预期收益和尾巴风险

**作者:** David Simchi-Levi, Chonghuan Wang

**Abstract:** When launching a new product, historical sales data is often not available, leaving price as a crucial experimental instrument for sellers to gauge market response. When designing pricing experiments, there are three fundamental objectives: estimating the causal effect of price (i.e., price elasticity), maximizing the expected revenue through the experiment, and controlling the tail risk suffering from a very huge loss. In this paper, we reveal the relationship among such three objectives. Under a linear structural model, we investigate the trade-offs between causal inference and expected revenue maximization, as well as between expected revenue maximization and tail risk control. Furthermore, we propose an optimal pricing experimental design, which can flexibly adapt to different desired levels of trade-offs. Through the optimal design, we also explore the relationship between causal inference and tail risk control.

**摘要:** 在设计定价实验时,有三个基本目标:估计定价的因果效应(即价格弹性),通过实验最大化预期收益,控制遭受巨大损失的尾风险。本文揭示了上述三个目标之间的关系。在线性结构模型下,我们研究了因果推理与预期收益最大化之间的交易权衡,以及预期收益最大化与尾风险控制之间的交易权衡。此外,我们提出了一种优化定价实验设计,可以灵活地适应不同预期交易权衡水平。通过优化设计,我们还研究了因果推理与尾风险控制之间的关系。

**[Paper URL](https://proceedings.mlr.press/v202/simchi-levi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/simchi-levi23a/simchi-levi23a.pdf)** 

# Statistical Learning under Heterogeneous Distribution Shift
**题目:** 异性分布 Shift下的统计学学习

**作者:** Max Simchowitz, Anurag Ajay, Pulkit Agrawal, Akshay Krishnamurthy

**Abstract:** This paper studies the prediction of a target $\mathbf{z}$ from a pair of random variables $(\mathbf{x},\mathbf{y})$, where the ground-truth predictor is additive $\mathbb{E}[\mathbf{z} \mid \mathbf{x},\mathbf{y}] = f_\star(\mathbf{x}) +g_{\star}(\mathbf{y})$. We study the performance of empirical risk minimization (ERM) over functions $f+g$, $f \in \mathcal{F}$ and $g \in \mathcal{G}$, fit on a given training distribution, but evaluated on a test distribution which exhibits covariate shift. We show that, when the class $\mathcal{F}$ is "simpler" than $\mathcal{G}$ (measured, e.g., in terms of its metric entropy), our predictor is more resilient to heterogeneous covariate shifts in which the shift in $\mathbf{x}$ is much greater than that in $\mathbf{y}$. These results rely on a novel Hölder style inequality for the Dudley integral which may be of independent interest. Moreover, we corroborate our theoretical findings with experiments demonstrating improved resilience to shifts in "simpler" features across numerous domains.

**摘要:** 本文研究了一对随机变量 $(\mathbf{x},\mathbf{y})$ 的目标 $\mathbf{z}$ 的预测,其中地真预测器是加法 $\mathbb{E}[\mathbf{z} \mid \mathbf{x},\mathbf{y}] = f_\star(\mathbf{x}) +g_{\star}(\mathbf{y})$ 。 我们研究了在函数 $f+g$ 、 $f \in \mathcal{F}$ 和 $g \in \mathcal{G}$ 上经验风险最小化 (ERM) 的性能,适用于给定的训练分布,但被评估在测试分布中显示了变量变量的变化。此外,我们通过实验证明了我们对多个领域“简单”特征的变化具有较强的适应性,证实了我们的理论发现。

**[Paper URL](https://proceedings.mlr.press/v202/simchowitz23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/simchowitz23a/simchowitz23a.pdf)** 

# On the Stepwise Nature of Self-Supervised Learning
**题目:** 自我监督学习的渐进性

**作者:** James B Simon, Maksis Knutins, Liu Ziyin, Daniel Geisz, Abraham J Fetterman, Joshua Albrecht

**Abstract:** We present a simple picture of the training process of self-supervised learning methods with dual deep networks. In our picture, these methods learn their high-dimensional embeddings one dimension at a time in a sequence of discrete, well-separated steps. We arrive at this picture via the study of a linear toy model of Barlow Twins, applicable to the case in which the trained network is infinitely wide. We solve the training dynamics of our toy model from small initialization, finding that the model learns the top eigenmodes of a certain contrastive kernel in a discrete, stepwise fashion, and find a closed-form expression for the final learned representations. Remarkably, we see the same stepwise learning phenomenon when training deep ResNets using the Barlow Twins, SimCLR, and VICReg losses. This stepwise picture partially demystifies the process of self-supervised training.

**摘要:** 我们给出了双深度网络的自监督学习方法的训练过程的简单图案。在我们的图案中,这些方法在离散、分离步骤的序列中学习其高维嵌入一个次元。我们通过研究Barlow Twins的线性玩具模型来得出这个图案,适用于训练的网络是无限宽的案例。我们从小初始化中解决了我们的玩具模型的训练动力学,发现该模型在离散、渐进模式中学习了特定对比性核的顶端特征模式,并找到最后学习的表示的闭式表达式。

**[Paper URL](https://proceedings.mlr.press/v202/simon23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/simon23a/simon23a.pdf)** 

# Hindsight Learning for MDPs with Exogenous Inputs
**题目:** 外源输入的MDP后瞻性学习

**作者:** Sean R. Sinclair, Felipe Vieira Frujeri, Ching-An Cheng, Luke Marshall, Hugo De Oliveira Barbalho, Jingling Li, Jennifer Neville, Ishai Menache, Adith Swaminathan

**Abstract:** Many resource management problems require sequential decision-making under uncertainty, where the only uncertainty affecting the decision outcomes are exogenous variables outside the control of the decision-maker. We model these problems as Exo-MDPs (Markov Decision Processes with Exogenous Inputs) and design a class of data-efficient algorithms for them termed Hindsight Learning (HL). Our HL algorithms achieve data efficiency by leveraging a key insight: having samples of the exogenous variables, past decisions can be revisited in hindsight to infer counterfactual consequences that can accelerate policy improvements. We compare HL against classic baselines in the multi-secretary and airline revenue management problems. We also scale our algorithms to a business-critical cloud resource management problem – allocating Virtual Machines (VMs) to physical machines, and simulate their performance with real datasets from a large public cloud provider. We find that HL algorithms outperform domain-specific heuristics, as well as state-of-the-art reinforcement learning methods.

**摘要:** 许多资源管理问题需要在不确定性下进行序列决策,其中影响决策结果的唯一不确定性是 outside the control of the decision-maker的外来变量。我们将这些问题建模为Exo-MDPs(Markov Decision Processes with Exogenous Inputs)并为它们设计了一个被称为 Hindsight Learning(HL)的数据效率算法类别。我们的HL算法通过利用关键的洞察力来实现数据效率:具有外来变量样本,可以回顾过去的决策,推断可以加速政策改善的反事实后果。我们发现,HL算法优于领域特异的求解方法,以及最先进的强化学习方法。

**[Paper URL](https://proceedings.mlr.press/v202/sinclair23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sinclair23a/sinclair23a.pdf)** 

# Text-To-4D Dynamic Scene Generation
**题目:** Text-To-4D动态场景生成

**作者:** Uriel Singer, Shelly Sheynin, Adam Polyak, Oron Ashual, Iurii Makarov, Filippos Kokkinos, Naman Goyal, Andrea Vedaldi, Devi Parikh, Justin Johnson, Yaniv Taigman

**Abstract:** We present MAV3D (Make-A-Video3D), a method for generating three-dimensional dynamic scenes from text descriptions. Our approach uses a 4D dynamic Neural Radiance Field (NeRF), which is optimized for scene appearance, density, and motion consistency by querying a Text-to-Video (T2V) diffusion-based model. The dynamic video output generated from the provided text can be viewed from any camera location and angle, and can be composited into any 3D environment. MAV3D does not require any 3D or 4D data and the T2V model is trained only on Text-Image pairs and unlabeled videos. We demonstrate the effectiveness of our approach using comprehensive quantitative and qualitative experiments and show an improvement over previously established internal baselines. To the best of our knowledge, our method is the first to generate 3D dynamic scenes given a text description. Generated samples can be viewed at make-a-video3d.github.io

**摘要:** MAV3D(Make-A-Video3D)是一种从文本描述中生成三维动态场景的方法。我们采用4D动态神经辐射场(NeRF)来优化场景外观、密度和运动一致性,通过查询文本到视频(T2V)扩散模型。从提供文本中生成的动态视频输出可从任何摄像机位置和角度查看,并可组合到任何3D环境中。MAV3D不需要任何3D或4D数据,而T2V模型只在文本图像对和未标记视频上进行训练。我们通过全面定量和定性实验证明了我们的方法的有效性,并显示了先前建立的内部基线的改进。

**[Paper URL](https://proceedings.mlr.press/v202/singer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/singer23a/singer23a.pdf)** 

# The Hessian perspective into the Nature of Convolutional Neural Networks
**题目:** 赫斯sian视角对进化神经网络的性质

**作者:** Sidak Pal Singh, Thomas Hofmann, Bernhard Schölkopf

**Abstract:** While Convolutional Neural Networks (CNNs) have long been investigated and applied, as well as theorized, we aim to provide a slightly different perspective into their nature — through the perspective of their Hessian maps. The reason is that the loss Hessian captures the pairwise interaction of parameters and therefore forms a natural ground to probe how the architectural aspects of CNNs get manifested in their structure and properties. We develop a framework relying on Toeplitz representation of CNNs, and then utilize it to reveal the Hessian structure and, in particular, its rank. We prove tight upper bounds (with linear activations), which closely follow the empirical trend of the Hessian rank and in practice also hold for more general settings. Overall, our work generalizes and further establishes the key insight that the Hessian rank grows as the square root of the number of parameters, even in CNNs.

**摘要:** 尽管变形神经网络(CNNs)已经长期被研究和应用,同时也被理论化,我们的目标是通过其希斯sian地图的视角向其自然界提供略有不同的视角。原因在于希斯sian的损失捕捉了参数的双向相互作用,因此形成一个自然地基,以研究如何在其结构和特性中表现的CNN的建筑方面。我们开发了一个基于托普利茨的CNN的框架,然后利用它来揭示希斯sian结构,特别是其等级。我们证明了紧固的上限(带有线性激活),密切遵循希斯sian等级的实证趋势,并在实践中也保持更一般的设置。

**[Paper URL](https://proceedings.mlr.press/v202/singh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/singh23a/singh23a.pdf)** 

# When do Minimax-fair Learning and Empirical Risk Minimization Coincide?
**题目:** 什么时候最小公平学习和经验风险最小化合乎逻辑?

**作者:** Harvineet Singh, Matthäus Kleindessner, Volkan Cevher, Rumi Chunara, Chris Russell

**Abstract:** Minimax-fair machine learning minimizes the error for the worst-off group. However, empirical evidence suggests that when sophisticated models are trained with standard empirical risk minimization (ERM), they often have the same performance on the worst-off group as a minimax-trained model. Our work makes this counter-intuitive observation concrete. We prove that if the hypothesis class is sufficiently expressive and the group information is recoverable from the features, ERM and minimax-fairness learning formulations indeed have the same performance on the worst-off group. We provide additional empirical evidence of how this observation holds on a wide range of datasets and hypothesis classes. Since ERM is fundamentally easier than minimax optimization, our findings have implications on the practice of fair machine learning.

**摘要:** 最小公平机器学习减少了最坏群体的误差。然而,经验证据表明,当复杂的模型以标准经验风险最小化(ERM)训练时,它们在最坏群体的性能通常与最小训练模型相同。我们的工作使这种反直观观察具体化。我们证明,如果假设类足够表达,并且群信息可以从特征中恢复,那么ERM和最小公平学习公式实际上在最坏群体的性能相同。

**[Paper URL](https://proceedings.mlr.press/v202/singh23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/singh23b/singh23b.pdf)** 

# Differentiable Simulations for Enhanced Sampling of Rare Events
**题目:** 改进稀有事件样本的可辨别模拟

**作者:** Martin Sipka, Johannes C. B. Dietschreit, Lukáš Grajciar, Rafael Gomez-Bombarelli

**Abstract:** Simulating rare events, such as the transformation of a reactant into a product in a chemical reaction typically requires enhanced sampling techniques that rely on heuristically chosen collective variables (CVs). We propose using differentiable simulations (DiffSim) for the discovery and enhanced sampling of chemical transformations without a need to resort to preselected CVs, using only a distance metric. Reaction path discovery and estimation of the biasing potential that enhances the sampling are merged into a single end-to-end problem that is solved by path-integral optimization. This is achieved by introducing multiple improvements over standard DiffSim such as partial backpropagation and graph mini-batching making DiffSim training stable and efficient. The potential of DiffSim is demonstrated in the successful discovery of transition paths for the Muller-Brown model potential as well as a benchmark chemical system - alanine dipeptide.

**摘要:** 模拟稀有事件,例如反应剂转化为化学反应中的产物,通常需要基于现代选择的集体变量(CVs)的改进样本技术。我们建议使用可微化模拟(DiffSim)来发现和改进化学变量,不需要使用预选CVs,只使用距离度量。反应路径发现和估计提高样本的偏差潜力被合并为单个端到端问题,由路径集成优化解决。

**[Paper URL](https://proceedings.mlr.press/v202/sipka23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sipka23a/sipka23a.pdf)** 

# Preprocessors Matter! Realistic Decision-Based Attacks on Machine Learning Systems
**题目:** 预处理器重要!基于现实决策的攻击机器学习系统

**作者:** Chawin Sitawarin, Florian Tramèr, Nicholas Carlini

**Abstract:** Decision-based attacks construct adversarial examples against a machine learning (ML) model by making only hard-label queries. These attacks have mainly been applied directly to standalone neural networks. However, in practice, ML models are just one component of a larger learning system. We find that by adding a single preprocessor in front of a classifier, state-of-the-art query-based attacks are up to seven× less effective at attacking a prediction pipeline than at attacking the model alone. We explain this discrepancy by the fact that most preprocessors introduce some notion of invariance to the input space. Hence, attacks that are unaware of this invariance inevitably waste a large number of queries to re-discover or overcome it. We, therefore, develop techniques to (i) reverse-engineer the preprocessor and then (ii) use this extracted information to attack the end-to-end system. Our preprocessors extraction method requires only a few hundred queries, and our preprocessor-aware attacks recover the same efficacy as when attacking the model alone. The code can be found at https://github.com/google-research/preprocessor-aware-black-box-attack.

**摘要:** 基于决策的攻击建立对机器学习(ML)模型的敌对实例,仅通过做硬标签查询。这些攻击主要是直接应用于独立神经网络。然而,在实践中,ML模型只是一个更大的学习系统组成部分。我们发现,通过在分类器前面添加单个预处理器,最先进的查询基础攻击在攻击预测管道时比攻击模型本身的攻击效率要低七倍。我们的预处理器提取方法只需要几个百个查询,我们的预处理器-了解攻击恢复了与单独攻击模型一样的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/sitawarin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sitawarin23a/sitawarin23a.pdf)** 

# Invariance in Policy Optimisation and Partial Identifiability in Reward Learning
**题目:** 政策优化的不变性和奖赏学习的局部识别性

**作者:** Joar Max Viktor Skalse, Matthew Farrugia-Roberts, Stuart Russell, Alessandro Abate, Adam Gleave

**Abstract:** It is often very challenging to manually design reward functions for complex, real-world tasks. To solve this, one can instead use reward learning to infer a reward function from data. However, there are often multiple reward functions that fit the data equally well, even in the infinite-data limit. This means that the reward function is only partially identifiable. In this work, we formally characterise the partial identifiability of the reward function given several popular reward learning data sources, including expert demonstrations and trajectory comparisons. We also analyse the impact of this partial identifiability for several downstream tasks, such as policy optimisation. We unify our results in a framework for comparing data sources and downstream tasks by their invariances, with implications for the design and selection of data sources for reward learning.

**摘要:** 为了解决这个问题,人们可以使用奖励学习来从数据中推导奖励函数。然而,经常有多个奖励函数,甚至在无穷数据限度中,都同样适合数据。这意味着奖励函数只能部分识别。在这个工作中,我们正式描述了几个受欢迎的奖励学习数据源的部分识别性,包括专家的演示和轨迹比较。我们还分析了这一部分识别性对几个下游任务的影响,例如政策优化。我们将数据源和下游任务以其不变性进行比较的框架中的结果统一起来,这对奖励学习数据源的设计和选择有影响。

**[Paper URL](https://proceedings.mlr.press/v202/skalse23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/skalse23a/skalse23a.pdf)** 

# A Game-Theoretic Framework for Managing Risk in Multi-Agent Systems
**题目:** 多代理系统风险管理的游戏理论框架

**作者:** Oliver Slumbers, David Henry Mguni, Stefano B Blumberg, Stephen Marcus Mcaleer, Yaodong Yang, Jun Wang

**Abstract:** In order for agents in multi-agent systems (MAS) to be safe, they need to take into account the risks posed by the actions of other agents. However, the dominant paradigm in game theory (GT) assumes that agents are not affected by risk from other agents and only strive to maximise their expected utility. For example, in hybrid human-AI driving systems, it is necessary to limit large deviations in reward resulting from car crashes. Although there are equilibrium concepts in game theory that take into account risk aversion, they either assume that agents are risk-neutral with respect to the uncertainty caused by the actions of other agents, or they are not guaranteed to exist. We introduce a new GT-based Risk-Averse Equilibrium (RAE) that always produces a solution that minimises the potential variance in reward accounting for the strategy of other agents. Theoretically and empirically, we show RAE shares many properties with a Nash Equilibrium (NE), establishing convergence properties and generalising to risk-dominant NE in certain cases. To tackle large-scale problems, we extend RAE to the PSRO multi-agent reinforcement learning (MARL) framework. We empirically demonstrate the minimum reward variance benefits of RAE in matrix games with high-risk outcomes. Results on MARL experiments show RAE generalises to risk-dominant NE in a trust dilemma game and that it reduces instances of crashing by 7x in an autonomous driving setting versus the best performing baseline.

**摘要:** 为了保证多代理系统中的代理人的安全,他们必须考虑到其他代理人的行动所带来的风险。然而,游戏理论中的主导范式(GT)假设代理人不受其他代理人的风险影响,并只努力最大化其预期的效用。例如,在混合人-AI驾驶系统中,必须限制因汽车事故所导致的报酬的巨大偏差。虽然游戏理论中存在考虑到风险厌恶的均衡概念,它们要么假设代理人对其他代理人的行动所造成的不确定性是风险中立的,要么不保证他们存在。我们引入了新的GT-based Risk-Averse Equilibrium(RAE),它总是产生一种解决办法,以尽量减少对其他代理人的策略报酬的潜在差异。在理论上和实证上,我们展示了RAE与纳什均衡(NE)共享许多特性,确定了收敛特性,并在某些情况下推广到风险主导的NE。为了解决大规模问题,我们将RAE扩展到PSRO多代理强化学习(MARL)框架。我们实证地证明了在高风险结果的矩阵游戏中RAE的最小奖赏差益。MARL实验结果表明,RAE在信任困境游戏中推广到风险主导的NE,并减少了在自主驾驶环境中7倍的撞车事件和最佳性能的基线。

**[Paper URL](https://proceedings.mlr.press/v202/slumbers23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/slumbers23a/slumbers23a.pdf)** 

# On the Effectiveness of Offline RL for Dialogue Response Generation
**题目:** 网上资源资源的有效性与对话响应的产生

**作者:** Paloma Sodhi, Felix Wu, Ethan R. Elenberg, Kilian Q Weinberger, Ryan Mcdonald

**Abstract:** A common training technique for language models is teacher forcing (TF). TF attempts to match human language exactly, even though identical meanings can be expressed in different ways. This motivates use of sequence-level objectives for dialogue response generation. In this paper, we study the efficacy of various offline reinforcement learning (RL) methods to maximize such objectives. We present a comprehensive evaluation across multiple datasets, models, and metrics. Offline RL shows a clear performance improvement over teacher forcing while not inducing training instability or sacrificing practical training budgets.

**摘要:** 语言模型的共同训练技术是教师强制(TF)。TF试图准确地匹配人类语言,尽管同义意义可以以不同的方式表达。这鼓励使用序列级目标来生成对话响应。本论文中,我们研究了各种非线性强化学习(RL)方法的有效性,以最大化这些目标。

**[Paper URL](https://proceedings.mlr.press/v202/sodhi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sodhi23a/sodhi23a.pdf)** 

# Fair Densities via Boosting the Sufficient Statistics of Exponential Families
**题目:** 通过提高高风险家庭的统计数字,实现公平的密度

**作者:** Alexander Soen, Hisham Husain, Richard Nock

**Abstract:** We introduce a boosting algorithm to pre-process data for fairness. Starting from an initial fair but inaccurate distribution, our approach shifts towards better data fitting while still ensuring a minimal fairness guarantee. To do so, it learns the sufficient statistics of an exponential family with boosting-compliant convergence. Importantly, we are able to theoretically prove that the learned distribution will have a representation rate and statistical rate data fairness guarantee. Unlike recent optimization based pre-processing methods, our approach can be easily adapted for continuous domain features. Furthermore, when the weak learners are specified to be decision trees, the sufficient statistics of the learned distribution can be examined to provide clues on sources of (un)fairness. Empirical results are present to display the quality of result on real-world data.

**摘要:** 我们引入了对公平的预处理数据的增强算法。从初始公平但不准确的分布开始,我们的方法转向更好的数据配置,同时确保最低公平保证。为此,它学习了与增强相符的收敛指数家族的充分统计数据。重要的是,我们能够从理论上证明学习的分布将具有表示率和统计率的数据公平保证。与最近的优化基于预处理方法不同,我们的方法可以轻易地适应连续域特征。此外,当弱学习者被指定为决策树时,学习的分布的充分统计数据可以被检查以提供(不)公平的来源的线索。

**[Paper URL](https://proceedings.mlr.press/v202/soen23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/soen23a/soen23a.pdf)** 

# The Dormant Neuron Phenomenon in Deep Reinforcement Learning
**题目:** 深度增强学习中的 Dormant神经元现象

**作者:** Ghada Sokar, Rishabh Agarwal, Pablo Samuel Castro, Utku Evci

**Abstract:** In this work we identify the dormant neuron phenomenon in deep reinforcement learning, where an agent’s network suffers from an increasing number of inactive neurons, thereby affecting network expressivity. We demonstrate the presence of this phenomenon across a variety of algorithms and environments, and highlight its effect on learning. To address this issue, we propose a simple and effective method (ReDo) that Recycles Dormant neurons throughout training. Our experiments demonstrate that ReDo maintains the expressive power of networks by reducing the number of dormant neurons and results in improved performance.

**摘要:** 在研究中,我们确定了深度增强学习中 dormant neuron 现象,即代理人网络受到越来越多的非主动神经元的影响,从而影响网络表达能力。我们证明了这一现象在各种算法和环境中存在,并突出了其对学习的影响。为了解决这一问题,我们提出了一种简单有效的方法(ReDo),在整个训练中回收 dormant neuron。

**[Paper URL](https://proceedings.mlr.press/v202/sokar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sokar23a/sokar23a.pdf)** 

# Abstracting Imperfect Information Away from Two-Player Zero-Sum Games
**题目:** 抽象不完美信息远离双人零人游戏

**作者:** Samuel Sokota, Ryan D’Orazio, Chun Kai Ling, David J Wu, J Zico Kolter, Noam Brown

**Abstract:** In their seminal work, Nayyar et al. (2013) showed that imperfect information can be abstracted away from common-payoff games by having players publicly announce their policies as they play. This insight underpins sound solvers and decision-time planning algorithms for common-payoff games. Unfortunately, a naive application of the same insight to two-player zero-sum games fails because Nash equilibria of the game with public policy announcements may not correspond to Nash equilibria of the original game. As a consequence, existing sound decision-time planning algorithms require complicated additional mechanisms that have unappealing properties. The main contribution of this work is showing that certain regularized equilibria do not possess the aforementioned non-correspondence problem—thus, computing them can be treated as perfect-information problems. Because these regularized equilibria can be made arbitrarily close to Nash equilibria, our result opens the door to a new perspective to solving two-player zero-sum games and yields a simplified framework for decision-time planning in two-player zero-sum games, void of the unappealing properties that plague existing decision-time planning approaches.

**摘要:** Nayyar et al.(2013年)在其主要研究中表明,通过让玩家在游戏中公开宣布其政策,可以将不完善的信息从共同回报游戏中抽象出来。这一洞察支持了共同回报游戏的健全解决方案和决策时间规划算法。不幸的是,对两个玩家的零总游戏的同样洞察的 naiv 应用失败,因为与公共政策公告的游戏的纳什均衡可能与原始游戏的纳什均衡不相符。由于这些规则化均衡可以任意接近纳什均衡,我们的结果开启了解决双人零总游戏的新视角,并为双人零总游戏的决策时间规划提供了简化框架。

**[Paper URL](https://proceedings.mlr.press/v202/sokota23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sokota23a/sokota23a.pdf)** 

# Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided Exploration for Mitigating Scale Shift on Combinatorial Optimization
**题目:** Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided Exploration for Mitigating Scale Shift on Combinatorial Optimization

**作者:** Jiwoo Son, Minsu Kim, Hyeonah Kim, Jinkyoo Park

**Abstract:** This paper proposes Meta-SAGE, a novel approach for improving the scalability of deep reinforcement learning models for combinatorial optimization (CO) tasks. Our method adapts pre-trained models to larger-scale problems in test time by suggesting two components: a scale meta-learner (SML) and scheduled adaptation with guided exploration (SAGE). First, SML transforms the context embedding for subsequent adaptation of SAGE based on scale information. Then, SAGE adjusts the model parameters dedicated to the context embedding for a specific instance. SAGE introduces locality bias, which encourages selecting nearby locations to determine the next location. The locality bias gradually decays as the model is adapted to the target instance. Results show that Meta-SAGE outperforms previous adaptation methods and significantly improves scalability in representative CO tasks. Our source code is available at https://github.com/kaist-silab/meta-sage.

**摘要:** 本文提出了一种改进综合优化(CO)任务深度增强学习模型的新型方法,即Meta-SAGE。该方法通过提议两个组成部分: scale meta-learner(SML)和 scheduled adaptation with guided exploration(SAGE)来适应测试时间的较大规模问题。首先,SML将基于尺度信息的SAGE后续适应的上下文嵌入变换。然后,SAGE调整为特定实例的上下文嵌入专门的模型参数。SAGE引入局部偏差,鼓励选择附近的位置来确定下一个位置。局部偏差随着模型适应目标实例而逐渐衰减。结果表明Meta-SAGE优于以往的适应方法,在代表的CO任务中大幅提高可扩展性。我们的源代码可浏览 https://github.com/kaist-silab/meta-sage。

**[Paper URL](https://proceedings.mlr.press/v202/son23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/son23a/son23a.pdf)** 

# Consistency Models
**题目:** 一致性模型

**作者:** Yang Song, Prafulla Dhariwal, Mark Chen, Ilya Sutskever

**Abstract:** Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation. To overcome this limitation, we propose consistency models, a new family of models that generate high quality samples by directly mapping noise to data. They support fast one-step generation by design, while still allowing multistep sampling to trade compute for sample quality. They also support zero-shot data editing, such as image inpainting, colorization, and super-resolution, without requiring explicit training on these tasks. Consistency models can be trained either by distilling pre-trained diffusion models, or as standalone generative models altogether. Through extensive experiments, we demonstrate that they outperform existing distillation techniques for diffusion models in one- and few-step sampling, achieving the new state-of-the-art FID of 3.55 on CIFAR-10 and 6.20 on ImageNet 64x64 for one-step generation. When trained in isolation, consistency models become a new family of generative models that can outperform existing one-step, non-adversarial generative models on standard benchmarks such as CIFAR-10, ImageNet 64x64 and LSUN 256x256.

**摘要:** 扩散模型已经大大提高图像、音频和视频的生成领域,但它们依赖于产生缓慢的迭代采样过程。为了克服这一局限性,我们提出了一致性模型,一种新的模型家族,通过直接映射数据的噪声生成高质量样品。它们支持通过设计快速的单步生成,同时允许多步采样交易计算样品质量。它们还支持零射击数据编辑,如图像油漆、色彩化和超分辨率,无需对这些任务进行明确的训练。通过广泛的实验,我们证明它们在单步和单步采样中超过了现有扩散模型的蒸馏技术,实现单步生成的CIFAR-10的最新FID3.55和ImageNet64x64的6.20。在隔离训练中,一致性模型成为一种新的生成模型家族,能够超越现有单步、非逆向生成模型的标准基准,例如CIFAR-10、ImageNet64x64和LSUN256x256。

**[Paper URL](https://proceedings.mlr.press/v202/song23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/song23a/song23a.pdf)** 

# LipsNet: A Smooth and Robust Neural Network with Adaptive Lipschitz Constant for High Accuracy Optimal Control
**题目:** LipsNet:具有高精度优化控制的自适应 Lipschitz定数的 Smooth and Robust Neural Network

**作者:** Xujie Song, Jingliang Duan, Wenxuan Wang, Shengbo Eben Li, Chen Chen, Bo Cheng, Bo Zhang, Junqing Wei, Xiaoming Simon Wang

**Abstract:** Deep reinforcement learning (RL) is a powerful approach for solving optimal control problems. However, RL-trained policies often suffer from the action fluctuation problem, where the consecutive actions significantly differ despite only slight state variations. This problem results in mechanical components’ wear and tear and poses safety hazards. The action fluctuation is caused by the high Lipschitz constant of actor networks. To address this problem, we propose a neural network named LipsNet. We propose the Multi-dimensional Gradient Normalization (MGN) method, to constrain the Lipschitz constant of networks with multi-dimensional input and output. Benefiting from MGN, LipsNet achieves Lipschitz continuity, allowing smooth actions while preserving control performance by adjusting Lipschitz constant. LipsNet addresses the action fluctuation problem at network level rather than algorithm level, which can serve as actor networks in most RL algorithms, making it more flexible and user-friendly than previous works. Experiments demonstrate that LipsNet has good landscape smoothness and noise robustness, resulting in significantly smoother action compared to the Multilayer Perceptron.

**摘要:** 深度增强学习(RL)是解决最佳控制问题的一种强有力的方法。然而,RL训练的政策经常受到动作波动问题的影响,而连续的动作在少数状态变异的情况下差异很大。这一问题导致机械部件的磨损和磨损,并造成安全风险。动作波动是由行动者网络的高利普希茨常数引起的。为了解决这一问题,我们提出了一个名为利普希茨常数的神经网络。我们提出了多维梯度正常化(MGN)方法,以约束多维输入和输出的网络的利普希茨常数。LipsNet解决了网络层面的动作波动问题,而不是算法层面的动作波动问题,在大多数RL算法中,它可以作为代理网络,使它比以前的工作更加灵活和用户友好。实验表明, LipsNet具有良好的景观平滑性和噪声鲁棒性,因此与多层感应器相比,动作更平稳。

**[Paper URL](https://proceedings.mlr.press/v202/song23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/song23b/song23b.pdf)** 

# Deep Perturbation Learning: Enhancing the Network Performance via Image Perturbations
**题目:** 深度扰动学习:通过图像扰动提高网络性能

**作者:** Zifan Song, Xiao Gong, Guosheng Hu, Cairong Zhao

**Abstract:** Image perturbation technique is widely used to generate adversarial examples to attack networks, greatly decreasing the performance of networks. Unlike the existing works, in this paper, we introduce a novel framework Deep Perturbation Learning (DPL), the new insights into understanding image perturbations, to enhance the performance of networks rather than decrease the performance. Specifically, we learn image perturbations to amend the data distribution of training set to improve the performance of networks. This optimization w.r.t data distribution is non-trivial. To approach this, we tactfully construct a differentiable optimization target w.r.t. image perturbations via minimizing the empirical risk. Then we propose an alternating optimization of the network weights and perturbations. DPL can easily be adapted to a wide spectrum of downstream tasks and backbone networks. Extensive experiments demonstrate the effectiveness of our DPL on 6 datasets (CIFAR-10, CIFAR100, ImageNet, MS-COCO, PASCAL VOC, and SBD) over 3 popular vision tasks (image classification, object detection, and semantic segmentation) with different backbone architectures (e.g., ResNet, MobileNet, and ViT).

**摘要:** 图像扰动技术广泛用于产生攻击网络的敌对实例,大大降低网络的性能。与现有的工作不同,本文介绍了一种新的框架 Deep Perturbation Learning(DPL),对图像扰动理解的新洞察,以提高网络的性能,而不是降低网络的性能。具体而言,我们学习图像扰动以修改训练设置的数据分布,提高网络的性能。广泛的实验证明了我们的DPL在6个数据集(CIFAR-10、CIFAR100、ImageNet、MS-COCO、PASCAL VOC和SBD)上具有不同骨干架构(例如ResNet、MobileNet和ViT)的3种常见视觉任务(图像分类、对象检测和语义分割)的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/song23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/song23c/song23c.pdf)** 

# Latent Traversals in Generative Models as Potential Flows
**题目:** 潜在流动的生成模型中的潜在逆转

**作者:** Yue Song, T. Anderson Keller, Nicu Sebe, Max Welling

**Abstract:** Despite the significant recent progress in deep generative models, the underlying structure of their latent spaces is still poorly understood, thereby making the task of performing semantically meaningful latent traversals an open research challenge. Most prior work has aimed to solve this challenge by modeling latent structures linearly, and finding corresponding linear directions which result in ‘disentangled’ generations. In this work, we instead propose to model latent structures with a learned dynamic potential landscape, thereby performing latent traversals as the flow of samples down the landscape’s gradient. Inspired by physics, optimal transport, and neuroscience, these potential landscapes are learned as physically realistic partial differential equations, thereby allowing them to flexibly vary over both space and time. To achieve disentanglement, multiple potentials are learned simultaneously, and are constrained by a classifier to be distinct and semantically self-consistent. Experimentally, we demonstrate that our method achieves both more qualitatively and quantitatively disentangled trajectories than state-of-the-art baselines. Further, we demonstrate that our method can be integrated as a regularization term during training, thereby acting as an inductive bias towards the learning of structured representations, ultimately improving model likelihood on similarly structured data. Code is available at https://github.com/KingJamesSong/PDETraversal.

**摘要:** 尽管最近在深层生成模型中取得了重大进展,但它们的潜在空间的基本结构仍未得到充分理解,从而使执行语义意义的潜在横渡任务成为一项公开的研究挑战。大部分以前的工作旨在通过线性建模潜在结构,并找到相应的线性方向,从而导致“分散”的代数。为了实现分离,多个潜力同时被学习,并且被分类器约束以区别和语义上自我一致。实验上,我们证明我们的方法能够比最先进的基线更具质量和定量分离的轨迹。此外,我们证明我们的方法可以在训练期间整合为规范化术语,从而作为对结构化表示学习的诱导偏见,最终改善类似结构化数据的模型可能性。

**[Paper URL](https://proceedings.mlr.press/v202/song23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/song23d/song23d.pdf)** 

# FedAvg Converges to Zero Training Loss Linearly for Overparameterized Multi-Layer Neural Networks
**题目:** FedAvg对超参数多层神经网络进行零训练损失的线性实现

**作者:** Bingqing Song, Prashant Khanduri, Xinwei Zhang, Jinfeng Yi, Mingyi Hong

**Abstract:** Federated Learning (FL) is a distributed learning paradigm that allows multiple clients to learn a joint model by utilizing privately held data at each client. Significant research efforts have been devoted to develop advanced algorithms that deal with the situation where the data at individual clients have heterogeneous distributions. In this work, we show that data heterogeneity can be dealt from a different perspective. That is, by utilizing a certain overparameterized multi-layer neural network at each client, even the vanilla FedAvg (a.k.a. the Local SGD) algorithm can accurately optimize the training problem: When each client has a neural network with one wide layer of size $N$ (where $N$ is the number of total training samples), followed by layers of smaller widths, FedAvg converges linearly to a solution that achieves (almost) zero training loss, without requiring any assumptions on the clients’ data distributions. To our knowledge, this is the first work that demonstrates such resilience to data heterogeneity for FedAvg when trained on multi-layer neural networks. Our experiments also confirm that, neural networks of large size can achieve better and more stable performance for FL problems.

**摘要:** 联邦学习(FL)是一种分布式学习范式,允许多个客户通过使用在每个客户身上私有数据来学习联合模型。有意义的研究努力已经致力于开发先进的算法,以解决在个别客户中的数据具有异质分布的情况。在这项工作中,我们显示数据异质性可以从不同角度处理。据我们所知,这是FedAvg在多层神经网络上训练时对数据异质性具有如此强韧性的首次工作。我们的实验也证实了,大型神经网络可以在FL问题上获得更好的更稳定的性能。

**[Paper URL](https://proceedings.mlr.press/v202/song23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/song23e/song23e.pdf)** 

# RGE: A Repulsive Graph Rectification for Node Classification via Influence
**题目:** RGE:基于影响的节点分类的反弹图整修

**作者:** Jaeyun Song, Sungyub Kim, Eunho Yang

**Abstract:** In real-world graphs, noisy connections are inevitable, which makes it difficult to obtain unbiased node representations. Among various attempts to resolve this problem, a method of estimating the counterfactual effects of these connectivities has recently attracted attention, which mainly uses influence functions for single graph elements (i.e., node and edge). However, in this paper, we argue that there is a strongly interacting group effect between the influences of graph elements due to their connectivity. In the same vein, we observe that edge groups connecting to the same train node exhibit significant differences in their influences, hence no matter how negative each is, removing them at once may have a rather negative effect as a group. Based on this motivation, we propose a new edge-removing strategy, Repulsive edge Group Elimination (RGE), that preferentially removes edges with no interference in groups. Empirically, we demonstrate that RGE consistently outperforms existing methods on the various benchmark datasets.

**摘要:** 在实世界图中,噪声的连接是不可避免的,这使得获得无偏节点表示困难。在解决这个问题的种种尝试中,最近,一种估计这些节点的反事实效应的方法引起了人们的注意,主要使用单一图元素(即节点和边缘)的影响函数。然而,本文认为,由于其关联性,图元素的影响之间存在强烈的相互作用群效应。实证表明,在不同基准数据集中,RGE始终优于现有的方法。

**[Paper URL](https://proceedings.mlr.press/v202/song23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/song23f/song23f.pdf)** 

# Importance Weighted Expectation-Maximization for Protein Sequence Design
**题目:** 蛋白质序列设计的重要权重期望-最大化

**作者:** Zhenqiao Song, Lei Li

**Abstract:** Designing protein sequences with desired biological function is crucial in biology and chemistry. Recent machine learning methods use a surrogate sequence-function model to replace the expensive wet-lab validation. How can we efficiently generate diverse and novel protein sequences with high fitness? In this paper, we propose IsEM-Pro, an approach to generate protein sequences towards a given fitness criterion. At its core, IsEM-Pro is a latent generative model, augmented by combinatorial structure features from a separately learned Markov random fields (MRFs). We develop an Monte Carlo Expectation-Maximization method (MCEM) to learn the model. During inference, sampling from its latent space enhances diversity while its MRFs features guide the exploration in high fitness regions. Experiments on eight protein sequence design tasks show that our IsEM-Pro outperforms the previous best methods by at least 55% on average fitness score and generates more diverse and novel protein sequences.

**摘要:** 在生物学和化学中,设计具有理想的生物功能的蛋白序列是至关重要的。最近的机器学习方法使用替代序列函数模型来取代昂贵的湿实验室验证。我们如何能有效地生成具有高适应性的多样性和新颖的蛋白序列?在本文中,我们提出了 IsEM-Pro,一种针对特定适应性标准生成蛋白序列的方法。 IsEM-Pro的核心是潜在的生成模型,由由单独学习的马可夫随机场(MRFs)组合结构特征增强。

**[Paper URL](https://proceedings.mlr.press/v202/song23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/song23g/song23g.pdf)** 

# Sketching for First Order Method: Efficient Algorithm for Low-Bandwidth Channel and Vulnerability
**题目:** 首次订购图案方法:低带宽通道及脆弱性的有效算法

**作者:** Zhao Song, Yitan Wang, Zheng Yu, Lichen Zhang

**Abstract:** Sketching is one of the most fundamental tools in large-scale machine learning. It enables runtime and memory saving via randomly compressing the original large problem into lower dimensions. In this paper, we propose a novel sketching scheme for the first order method in large-scale distributed learning setting, such that the communication costs between distributed agents are saved while the convergence of the algorithms is still guaranteed. Given gradient information in a high dimension $d$, the agent passes the compressed information processed by a sketching matrix $R\in \mathbb{R}^{s\times d}$ with $s\ll d$, and the receiver de-compressed via the de-sketching matrix $R^\top$ to “recover” the information in original dimension. Using such a framework, we develop algorithms for federated learning with lower communication costs. However, such random sketching does not protect the privacy of local data directly. We show that the gradient leakage problem still exists after applying the sketching technique by presenting a specific gradient attack method. As a remedy, we prove rigorously that the algorithm will be differentially private by adding additional random noises in gradient information, which results in a both communication-efficient and differentially private first order approach for federated learning tasks. Our sketching scheme can be further generalized to other learning settings and might be of independent interest itself.

**摘要:** 绘图是大规模机器学习中最基本的工具之一,通过随机压缩原始大问题,使运行时间和记忆储存在较低维度中。本文提出了一种新颖的绘图方案,用于大规模分布式学习设置中的初级方法,使得分布式代理之间的通信成本得以节省,同时算法的收敛性仍然得到保证。给高维度的梯度信息$d$,代理通过绘图矩阵$R\in \mathbb{R}^{s\times d}$通过$s\ll d$处理的压缩信息,接收机则通过解绘矩阵$R^\top$去“恢复”原始维度的信息。通过提出一种具体的梯度攻击方法,证明了该算法在梯度信息中增加额外的随机噪声,使该算法在联合学习任务中具有通信效率和不同程度的私有初级处理效果,并进一步推广到其他学习环境中,使该算法具有独立性。

**[Paper URL](https://proceedings.mlr.press/v202/song23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/song23h/song23h.pdf)** 

# Sketching Meets Differential Privacy: Fast Algorithm for Dynamic Kronecker Projection Maintenance
**题目:** Sketching满足差分隐私:动态克隆克投影维护的快速算法

**作者:** Zhao Song, Xin Yang, Yuanyuan Yang, Lichen Zhang

**Abstract:** Projection maintenance is one of the core data structure tasks. Efficient data structures for projection maintenance have led to recent breakthroughs in many convex programming algorithms. In this work, we further extend this framework to the Kronecker product structure. Given a constraint matrix ${\sf A}$ and a positive semi-definite matrix $W\in \mathbb{R}^{n\times n}$ with a sparse eigenbasis, we consider the task of maintaining the projection in the form of ${\sf B}^\top({\sf B}{\sf B}^\top)^{-1}{\sf B}$, where ${\sf B}={\sf A}(W\otimes I)$ or ${\sf B}={\sf A}(W^{1/2}\otimes W^{1/2})$. At each iteration, the weight matrix $W$ receives a low rank change and we receive a new vector $h$. The goal is to maintain the projection matrix and answer the query ${\sf B}^\top({\sf B}{\sf B}^\top)^{-1}{\sf B}h$ with good approximation guarantees. We design a fast dynamic data structure for this task and it is robust against an adaptive adversary. Following the beautiful and pioneering work of [Beimel, Kaplan, Mansour, Nissim, Saranurak and Stemmer, STOC’22], we use tools from differential privacy to reduce the randomness required by the data structure and further improve the running time.

**摘要:** 投影维护是核心数据结构任务之一。有效的投影维护数据结构导致了许多凸编程算法的最新突破。在这项工作中,我们进一步扩展这个框架到克朗克产品结构。考虑到一个约束矩阵${\sf A}$和一个正半确定矩阵$W\in \mathbb{R}^{n\times n}$具有稀疏的固基,我们考虑维持投影的形式${\sf B}^\top({\sf B}{\sf B}^\top)^{-1}{\sf B}$,其中${\sf B}={\sf A}(W\otimes I)$或${\sf B}={\sf A}(W^{1/2}\otimes W^{1/2})$。在每个迭代中,重量矩阵$W在Beimel, Kaplan, Mansour, Nissim, Saranurak和Stemmer的 beautiful and pioneering work 之后,我们使用微分隐私工具来减少数据结构所要求的随机性,并进一步改善运行时间。

**[Paper URL](https://proceedings.mlr.press/v202/song23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/song23i/song23i.pdf)** 

# A Nearly-Optimal Bound for Fast Regression with $\ell_∞$ Guarantee
**题目:** 具有$\ell_∞$保证的快速回归近视界

**作者:** Zhao Song, Mingquan Ye, Junze Yin, Lichen Zhang

**Abstract:** Given a matrix $A\in \mathbb{R}^{n\times d}$ and a vector $b\in \mathbb{R}^n$, we consider the regression problem with $\ell_\infty$ guarantees: finding a vector $x’\in \mathbb{R}^d$ such that $||x’-x^* ||_\infty \leq \frac{\epsilon}{\sqrt{d}}\cdot ||Ax^*-b||_2\cdot ||A^\dagger||$ with $x^*$ being the optimal solution to the regression $||Ax-b||_2$. One popular approach for solving $\ell_2$ regression problem is via sketching: picking a structured random matrix $S\in \mathbb{R}^{m\times n}$ with $m\ll n$ and $SA$ can be quickly computed, solve the “sketched” regression problem $x’=\mathrm{argmin} ||SAx-Sb||_2$. In this paper, we show that in order to obtain such $\ell_\infty$ guarantee for $\ell_2$ regression, one has to use sketching matrices that are dense. To the best of our knowledge, this is the first user case in which dense sketching matrices are necessary. On the algorithmic side, we prove that, there exists a distribution of dense sketching matrices with $m=\epsilon^{-2}d\log^3(n/\delta)$ such that solving the sketched regression problem gives the $\ell_\infty$ guarantee, with probability at least $1-\delta$. Moreover, the matrix $SA$ can be computed in time $O(nd\log n)$. Our row count is nearly-optimal up to logarithmic factors, and significantly improves the result in [Price, Song and Woodruff, ICALP’17], in which $m=\Omega(\epsilon^{-2}d^{1+\gamma})$ for $\gamma\in (0, 1)$ is required. Moreover, we develop a novel analytical framework for $\ell_\infty$ guarantee regression that utilizes the Oblivious Coordinate-wise Embedding (OCE) property introduced in [Song and Yu, ICML’21]. Our analysis is much simpler and more general than that of [Price, Song and Woodruff, ICALP’17]. Leveraging this framework, we extend the $\ell_\infty$ guarantee regression result to dense sketching matrices for computing fast tensor product of vectors.

**摘要:** 基于矩阵$A\in \mathbb{R}^{n\times d}$和向量$b\in \mathbb{R}^n$,我们考虑与$ell_\infty$的回归问题保证:找到向量$x’\in \mathbb{R}^d$ such that $||x’-x^* ||_\infty \leq \frac{\epsilon}{\sqrt{d}}\cdot ||Ax^*-b||_2\cdot ||A^\dagger||$ with $x^*$ being the optimal solution to the regression $||Ax-b||_2$. 解决$\ell_2$回归问题的一个常见方法是通过草图:选择一个结构的随机矩阵$在算法方面,我们证明,存在一个分布的密度划线矩阵,其中$m=\epsilon^{-2}d\log^3(n/\delta)$使得划线回归问题得到$\ell_\infty$保证,其概率至少为$1-\delta$。此外,矩阵$SA$可以在时间下计算$O(nd\log n)$。我们的行数几乎达到逻辑因素的最优,在$m=\Omega(\epsilon^{-2}d^{1+\gamma})$为$\gamma\in (0, 1)$需要的条件下,其结果大大提高了[Price, Song and Woodruff, ICALP’17]的结果。

**[Paper URL](https://proceedings.mlr.press/v202/song23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/song23j/song23j.pdf)** 

# Loss-Guided Diffusion Models for Plug-and-Play Controllable Generation
**题目:** 可控制的插件和播放扩散模型

**作者:** Jiaming Song, Qinsheng Zhang, Hongxu Yin, Morteza Mardani, Ming-Yu Liu, Jan Kautz, Yongxin Chen, Arash Vahdat

**Abstract:** We consider guiding denoising diffusion models with general differentiable loss functions in a plug-and-play fashion, enabling controllable generation without additional training. This paradigm, termed Loss-Guided Diffusion (LGD), can easily be integrated into all diffusion models and leverage various efficient samplers. Despite the benefits, the resulting guidance term is, unfortunately, an intractable integral and needs to be approximated. Existing methods compute the guidance term based on a point estimate. However, we show that such approaches have significant errors over the scale of the approximations. To address this issue, we propose a Monte Carlo method that uses multiple samples from a suitable distribution to reduce bias. Our method is effective in various synthetic and real-world settings, including image super-resolution, text or label-conditional image generation, and controllable motion synthesis. Notably, we show how our method can be applied to control a pretrained motion diffusion model to follow certain paths and avoid obstacles that are proven challenging to prior methods.

**摘要:** 我们考虑在插件和游戏模式中使用一般可微分损失函数来指导分离扩散模型,使无额外训练的可控扩散产生。这一模式,称为失控扩散(LGD),可以轻易地集成到所有扩散模型中,并利用各种高效的样本器。尽管有好处,结果的导引术语是不可解的积分,需要进行近似。现有的方法基于点估计计算导引术语。然而,我们证明这种方法在近似的尺度上有重大误差。研究表明,该方法可用于控制预制运动扩散模型,以追踪特定路径,避免对前方法具有挑战性的障碍。

**[Paper URL](https://proceedings.mlr.press/v202/song23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/song23k/song23k.pdf)** 

# Differentiable Tree Operations Promote Compositional Generalization
**题目:** 可区分树操作促进复合通用化

**作者:** Paul Soulos, Edward J Hu, Kate Mccurdy, Yunmo Chen, Roland Fernandez, Paul Smolensky, Jianfeng Gao

**Abstract:** In the context of structure-to-structure transformation tasks, learning sequences of discrete symbolic operations poses significant challenges due to their non-differentiability. To facilitate the learning of these symbolic sequences, we introduce a differentiable tree interpreter that compiles high-level symbolic tree operations into subsymbolic matrix operations on tensors. We present a novel Differentiable Tree Machine (DTM) architecture that integrates our interpreter with an external memory and an agent that learns to sequentially select tree operations to execute the target transformation in an end-to-end manner. With respect to out-of-distribution compositional generalization on synthetic semantic parsing and language generation tasks, DTM achieves 100% while existing baselines such as Transformer, Tree Transformer, LSTM, and Tree2Tree LSTM achieve less than 30%. DTM remains highly interpretable in addition to its perfect performance.

**摘要:** 在结构到结构转换任务中,学习离散符号操作的序列由于它们的非分化性造成重大挑战。为了促进学习这些符号序列,我们介绍了一种可分化树演译器,它将高层次符号树操作编译成拉伸器上的副符号矩阵操作。我们提出了一种新颖的可分化树机(DTM)架构,它将我们的演译器集成到外部内存和学习排序选择树操作以完成目标变换的方式。

**[Paper URL](https://proceedings.mlr.press/v202/soulos23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/soulos23a/soulos23a.pdf)** 

# Are labels informative in semi-supervised learning? Estimating and leveraging the missing-data mechanism.
**题目:** 标签在半监督学习中是有益的吗?评估和利用缺失数据机制。

**作者:** Aude Sportisse, Hugo Schmutz, Olivier Humbert, Charles Bouveyron, Pierre-Alexandre Mattei

**Abstract:** Semi-supervised learning is a powerful technique for leveraging unlabeled data to improve machine learning models, but it can be affected by the presence of “informative" labels, which occur when some classes are more likely to be labeled than others. In the missing data literature, such labels are called missing not at random. In this paper, we propose a novel approach to address this issue by estimating the missing-data mechanism and using inverse propensity weighting to debias any SSL algorithm, including those using data augmentation. We also propose a likelihood ratio test to assess whether or not labels are indeed informative. Finally, we demonstrate the performance of the proposed methods on different datasets, in particular on two medical datasets for which we design pseudo-realistic missing data scenarios.

**摘要:** 半监督学习是提高机器学习模型的有效手段,但它可能受到“信息性”标签的存在的影响,因为某些类比其他类更有可能被标签。在缺失数据文献中,这些标签被称为不随机的缺失。本文提出了一种新的方法来解决这一问题,通过估计缺失数据机制和使用逆倾向权重来除去任何SSL算法,包括使用数据增加的算法。

**[Paper URL](https://proceedings.mlr.press/v202/sportisse23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sportisse23a/sportisse23a.pdf)** 

# Linear Causal Disentanglement via Interventions
**题目:** 通过干预的线性动因分离

**作者:** Chandler Squires, Anna Seigal, Salil S Bhate, Caroline Uhler

**Abstract:** Causal disentanglement seeks a representation of data involving latent variables that are related via a causal model. A representation is identifiable if both the latent model and the transformation from latent to observed variables are unique. In this paper, we study observed variables that are a linear transformation of a linear latent causal model. Data from interventions are necessary for identifiability: if one latent variable is missing an intervention, we show that there exist distinct models that cannot be distinguished. Conversely, we show that a single intervention on each latent variable is sufficient for identifiability. Our proof uses a generalization of the RQ decomposition of a matrix that replaces the usual orthogonal and upper triangular conditions with analogues depending on a partial order on the rows of the matrix, with partial order determined by a latent causal model. We corroborate our theoretical results with a method for causal disentanglement. We show that the method accurately recovers a latent causal model on synthetic and semi-synthetic data and we illustrate a use case on a dataset of single-cell RNA sequencing measurements.

**摘要:** 因果分离是研究通过因果模型关联的潜在变量数据的表述,如果潜在模型和从潜在变量到观察变量的变换是唯一的,则表述是可识别的。本文研究了观察变量是线性变量线性变量模型的变换。干涉数据是可识别的:如果一个潜在变量缺少干涉,我们证明存在不同的模型,不能区分。相反,我们证明每个潜在变量上的单个干涉是可识别的。结果表明,该方法准确地恢复了合成和半合成数据的潜在因果模型,并说明了单细胞RNA序列测量数据集的一个应用案例。

**[Paper URL](https://proceedings.mlr.press/v202/squires23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/squires23a/squires23a.pdf)** 

# Generating Language Corrections for Teaching Physical Control Tasks
**题目:** 为教学物理控制任务生成语言修正

**作者:** Megha Srivastava, Noah Goodman, Dorsa Sadigh

**Abstract:** AI assistance continues to help advance applications in education, from language learning to intelligent tutoring systems, yet current methods for providing students feedback are still quite limited. Most automatic feedback systems either provide binary correctness feedback, which may not help a student understand how to improve, or require hand-coding feedback templates, which may not generalize to new domains. This can be particularly challenging for physical control tasks, where the rich diversity in student behavior and specialized domains make it challenging to leverage general-purpose assistive tools for providing feedback. We design and build CORGI, a model trained to generate language corrections for physical control tasks, such as learning to ride a bike. CORGI takes in as input a pair of student and expert trajectories, and then generates natural language corrections to help the student improve. We collect and train CORGI over data from three diverse physical control tasks (drawing, steering, and joint movement). Through both automatic and human evaluations, we show that CORGI can (i) generate valid feedback for novel student trajectories, (ii) outperform baselines on domains with novel control dynamics, and (iii) improve student learning in an interactive drawing task.

**摘要:** 大多数自动反馈系统要么提供二进制正确性反馈,这可能不会帮助学生理解如何改进,要么需要手编码反馈模板,这可能不会将反馈推广到新的领域。这对于物理控制任务来说尤其困难,因为学生行为和专门领域中的丰富多样性使得利用一般用途的辅助工具来提供反馈是困难的。我们收集和训练了三种不同的物理控制任务(绘制、操纵和关节运动)的数据,通过自动和人为评价,我们证明了:CorGI可以(i)为新学生轨迹产生有效的反馈,(ii)在新控制动力学的领域上超越基线,(iii)在交互绘制任务中改进学生学习。

**[Paper URL](https://proceedings.mlr.press/v202/srivastava23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/srivastava23a/srivastava23a.pdf)** 

# FaDIn: Fast Discretized Inference for Hawkes Processes with General Parametric Kernels
**题目:** FaDIn:通用参数核对霍克斯过程的快速偏差

**作者:** Guillaume Staerman, Cédric Allain, Alexandre Gramfort, Thomas Moreau

**Abstract:** Temporal point processes (TPP) are a natural tool for modeling event-based data. Among all TPP models, Hawkes processes have proven to be the most widely used, mainly due to their adequate modeling for various applications, particularly when considering exponential or non-parametric kernels. Although non-parametric kernels are an option, such models require large datasets. While exponential kernels are more data efficient and relevant for specific applications where events immediately trigger more events, they are ill-suited for applications where latencies need to be estimated, such as in neuroscience. This work aims to offer an efficient solution to TPP inference using general parametric kernels with finite support. The developed solution consists of a fast $\ell_2$ gradient-based solver leveraging a discretized version of the events. After theoretically supporting the use of discretization, the statistical and computational efficiency of the novel approach is demonstrated through various numerical experiments. Finally, the method’s effectiveness is evaluated by modeling the occurrence of stimuli-induced patterns from brain signals recorded with magnetoencephalography (MEG). Given the use of general parametric kernels, results show that the proposed approach leads to an improved estimation of pattern latency than the state-of-the-art.

**摘要:** 临时点过程(Temporal point processes,TPP)是基于事件的数据建模的自然工具。在所有TPP模型中,霍克斯过程被证明是最广泛使用的,主要是由于它们对各种应用的适当建模,特别是在考虑指数或非参数核时。尽管非参数核是一个选项,但这类模型需要大量的数据集。指数核是更有效的数据,并且对于特定应用有关系,在事件立即引发更多的事件时,它们不适合于应用,需要估计延迟,例如神经科学。在理论上支持离散化的应用后,通过数值实验证明了该方法的统计和计算效率。最后,通过模拟脑电磁encephalography(MEG)记录的脑信号的刺激诱导模式的发生,评价了该方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/staerman23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/staerman23a/staerman23a.pdf)** 

# Partial Optimality in Cubic Correlation Clustering
**题目:** 立方相关集群中的局部优化

**作者:** David Stein, Silvia Di Gregorio, Bjoern Andres

**Abstract:** The higher-order correlation clustering problem is an expressive model, and recently, local search heuristics have been proposed for several applications. Certifying optimality, however, is NP-hard and practically hampered already by the complexity of the problem statement. Here, we focus on establishing partial optimality conditions for the special case of complete graphs and cubic objective functions. In addition, we define and implement algorithms for testing these conditions and examine their effect numerically, on two datasets.

**摘要:** 高阶相关聚类问题是一种表达式模型,最近在多个应用中提出了局部搜索算法。然而,确定优越性是NP-hard的,并且实际上已经受到问题声明的复杂性所阻碍。在此,我们着重建立完整的图形和立体目标函数的特殊情况的局部优越性条件。

**[Paper URL](https://proceedings.mlr.press/v202/stein23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/stein23a/stein23a.pdf)** 

# MODeL: Memory Optimizations for Deep Learning
**题目:** MODeL:深度学习的内存优化

**作者:** Benoit Steiner, Mostafa Elhoushi, Jacob Kahn, James Hegarty

**Abstract:** The size of deep neural networks has grown exponentially in recent years. Unfortunately, hardware devices have not kept pace with the rapidly increasing memory requirements. To cope with this, researchers have proposed various techniques including spilling, rematerialization, reduced precision training, model pruning, and so on. However, these approaches suffer from various limitations, such as increasing training time, affecting model accuracy, or requiring extensive manual modifications to the neural networks. We present MODeL, an algorithm that optimizes the lifetime and memory location of the tensors used to train neural networks. Our method automatically reduces the memory usage of existing neural networks without any of the drawbacks of other techniques. We formulate the problem as a joint integer linear program (ILP). We present several techniques to simplify the encoding of the problem, and enable our approach to scale to the size of state-of-the-art neural networks using an off-the-shelf ILP solver. We experimentally demonstrate that MODeL only takes seconds to allow the training of neural networks using 30% less memory on average.

**摘要:** 近年来,深层神经网络的规模已呈指数增长,但硬件设备仍未与快速增长的内存需求保持同步。为了应对这一问题,研究人员提出了各种技术,包括泄漏、再材料化、精确训练、模型剪切等。然而,这些方法受到各种限制,如增加训练时间、影响模型准确性或需要对神经网络进行广泛的手动修改。我们提出了ModeL,一种优化用于训练神经网络的拉伸器的寿命和内存位置的算法。我们提出了几种方法,以简化问题的编码,并使我们的方法能够达到最先进的神经网络的大小,使用现有的ILP解决方案。我们实验证明,MODEL只需要几秒钟才能使神经网络的训练平均使用30%的内存。

**[Paper URL](https://proceedings.mlr.press/v202/steiner23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/steiner23a/steiner23a.pdf)** 

# Improving Expert Predictions with Conformal Prediction
**题目:** 改进符合预测的专家预测

**作者:** Eleni Straitouri, Lequn Wang, Nastaran Okati, Manuel Gomez Rodriguez

**Abstract:** Automated decision support systems promise to help human experts solve multiclass classification tasks more efficiently and accurately. However, existing systems typically require experts to understand when to cede agency to the system or when to exercise their own agency. Otherwise, the experts may be better off solving the classification tasks on their own. In this work, we develop an automated decision support system that, by design, does not require experts to understand when to trust the system to improve performance. Rather than providing (single) label predictions and letting experts decide when to trust these predictions, our system provides sets of label predictions constructed using conformal prediction—prediction sets—and forcefully asks experts to predict labels from these sets. By using conformal prediction, our system can precisely trade-off the probability that the true label is not in the prediction set, which determines how frequently our system will mislead the experts, and the size of the prediction set, which determines the difficulty of the classification task the experts need to solve using our system. In addition, we develop an efficient and near-optimal search method to find the conformal predictor under which the experts benefit the most from using our system. Simulation experiments using synthetic and real expert predictions demonstrate that our system may help experts make more accurate predictions and is robust to the accuracy of the classifier the conformal predictor relies on.

**摘要:** 自动化决策支持系统承诺能够帮助人类专家更有效地和准确地解决多类分类任务。然而,现有系统通常要求专家了解什么时候让机构交给系统或什么时候行使自己的代理权。否则,专家可能比自己更好的解决分类任务。在这个工作中,我们开发了一个由设计的自动化决策支持系统,不需要专家了解什么时候信任系统来提高性能。通过对定性预测,我们能够准确地对定系统误导专家的概率,以及对定性预测的大小,从而确定专家需要解决的分类任务的难度。此外,我们开发了一种高效且接近最佳的搜索方法,以找到对定性预测器,从而使专家从该系统中获益最大。仿真实验使用合成和实际的专家预测表明,我们的系统可以帮助专家作出更准确的预测,并且对定性预测器的准确性可靠。

**[Paper URL](https://proceedings.mlr.press/v202/straitouri23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/straitouri23a/straitouri23a.pdf)** 

# Lookahead When It Matters: Adaptive Non-causal Transformers for Streaming Neural Transducers
**题目:** 当事情重要时,向前看:用于流线神经传感器的自适应非因果变换器

**作者:** Grant Strimel, Yi Xie, Brian John King, Martin Radfar, Ariya Rastrow, Athanasios Mouchtaris

**Abstract:** Streaming speech recognition architectures are employed for low-latency, real-time applications. Such architectures are often characterized by their causality. Causal architectures emit tokens at each frame, relying only on current and past signal, while non-causal models are exposed to a window of future frames at each step to increase predictive accuracy. This dichotomy amounts to a trade-off for real-time Automatic Speech Recognition (ASR) system design: profit from the low-latency benefit of strictly-causal architectures while accepting predictive performance limitations, or realize the modeling benefits of future-context models accompanied by their higher latency penalty. In this work, we relax the constraints of this choice and present the Adaptive Non-Causal Attention Transducer (ANCAT). Our architecture is non-causal in the traditional sense, but executes in a low-latency, streaming manner by dynamically choosing when to rely on future context and to what degree within the audio stream. The resulting mechanism, when coupled with our novel regularization algorithms, delivers comparable accuracy to non-causal configurations while improving significantly upon latency, closing the gap with their causal counterparts. We showcase our design experimentally by reporting comparative ASR task results with measures of accuracy and latency on both publicly accessible and production-scale, voice-assistant datasets.

**摘要:** 流式语音识别架构用于低延迟、实时应用。这些架构往往以其因果关系为特征。因果架构在每个帧中发射トークン,只依靠当前和过去的信号,而非因果模型在每个步骤都暴露于未来帧的窗口,以提高预测精度。这一分离相当于实时自动语音识别(ASR)系统设计的交换:在接受预测性能限制的同时,从严格因果架构的低延迟收益中获利,或者实现未来背景模型的建模利益,并伴随其更高的延迟惩罚。我们的架构在传统意义上是非因果的,但通过动态选择什么时候依赖未来上下文以及在音频流中达到何种程度来执行低延迟的流向方式。该结果的机制,结合我们的新规则化算法,可以对非因果配置提供可比的准确性,同时大幅改善延迟,从而与其因果对照者之间的差距缩小。我们通过报告比较的ASR任务结果,以公开可访问和生产规模的语音辅助数据集的准确度和延迟指标来实验展示我们的设计。

**[Paper URL](https://proceedings.mlr.press/v202/strimel23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/strimel23a/strimel23a.pdf)** 

# Kernel QuantTree
**题目:** 核量树

**作者:** Diego Stucchi, Paolo Rizzo, Nicolò Folloni, Giacomo Boracchi

**Abstract:** We present Kernel QuantTree (KQT), a non-parametric change detection algorithm that monitors multivariate data through a histogram. KQT constructs a nonlinear partition of the input space that matches pre-defined target probabilities and specifically promotes compact bins adhering to the data distribution, resulting in a powerful detection algorithm. We prove two key theoretical advantages of KQT: i) statistics defined over the KQT histogram do not depend on the stationary data distribution $\phi_0$, so detection thresholds can be set a priori to control false positive rate, and ii) thanks to the kernel functions adopted, the KQT monitoring scheme is invariant to the roto-translation of the input data. Consequently, KQT does not require any preprocessing step like PCA. Our experiments show that KQT achieves superior detection power than non-parametric state-of-the-art change detection methods, and can reliably control the false positive rate.

**摘要:** 我们提出了KQT,一种非参数变化检测算法,它通过图形监测多变量数据。KQT构造了一个与预定义目标概率匹配的输入空间非线性分区,并特别促进数据分布的紧凑箱,从而产生强大的检测算法。我们证明了KQT的两个关键理论优势:(i)KQT图形上定义的统计数据不依赖静态数据分布$\phi_0$,因此检测阈值可以先确定控制错误正率,而(ii)由于采用的内核函数,KQT监测方案对输入数据的转译是不变的。因此,KQT不需要像PCA这样的预处理步骤。

**[Paper URL](https://proceedings.mlr.press/v202/stucchi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/stucchi23a/stucchi23a.pdf)** 

# Topologically Faithful Image Segmentation via Induced Matching of Persistence Barcodes
**题目:** 通过诱导一致的持久性字符串进行拓扑忠实图像分割

**作者:** Nico Stucki, Johannes C. Paetzold, Suprosanna Shit, Bjoern Menze, Ulrich Bauer

**Abstract:** Segmentation models predominantly optimize pixel-overlap-based loss, an objective that is actually inadequate for many segmentation tasks. In recent years, their limitations fueled a growing interest in topology-aware methods, which aim to recover the topology of the segmented structures. However, so far, existing methods only consider global topological properties, ignoring the need to preserve topological features spatially, which is crucial for accurate segmentation. We introduce the concept of induced matchings from persistent homology to achieve a spatially correct matching between persistence barcodes in a segmentation setting. Based on this concept, we define the Betti matching error as an interpretable, topologically and feature-wise accurate metric for image segmentations, which resolves the limitations of the Betti number error. Our Betti matching error is differentiable and efficient to use as a loss function. We demonstrate that it improves the topological performance of segmentation networks significantly across six diverse datasets while preserving the performance with respect to traditional scores. Our code is publicly available (https://github.com/nstucki/Betti-matching/).

**摘要:** 分割模型主要优化基于像素重叠的损失,这一目标实际上对于许多分割任务来说是不够的。近年来,它们的局限性促使人们对拓扑意识的方法越来越感兴趣,其目的是恢复分割结构的拓扑。然而,迄今为止,现有的方法只考虑全球拓扑特性,忽略需要在空间上保存拓扑特征,这是准确分割的关键。我们引入了从持久 homology中诱导匹配的概念,以实现在分割设置中持久编码之间的空间正确的匹配。我们证明,它在六个不同的数据集中大大提高了分区网络的拓扑性能,同时保持了传统分数的性能。我们的代码公开(https://github.com/nstucki/Betti-matching/)。

**[Paper URL](https://proceedings.mlr.press/v202/stucki23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/stucki23a/stucki23a.pdf)** 

# Towards Robust Graph Incremental Learning on Evolving Graphs
**题目:** 进化图形的稳健图形进化学习

**作者:** Junwei Su, Difan Zou, Zijun Zhang, Chuan Wu

**Abstract:** Incremental learning is a machine learning approach that involves training a model on a sequence of tasks, rather than all tasks at once. This ability to learn incrementally from a stream of tasks is crucial for many real-world applications. However, incremental learning is a challenging problem on graph-structured data, as many graph-related problems involve prediction tasks for each individual node, known as Node-wise Graph Incremental Learning (NGIL). This introduces non-independent and non-identically distributed characteristics in the sample data generation process, making it difficult to maintain the performance of the model as new tasks are added. In this paper, we focus on the inductive NGIL problem, which accounts for the evolution of graph structure (structural shift) induced by emerging tasks. We provide a formal formulation and analysis of the problem, and propose a novel regularization-based technique called Structural-Shift-Risk-Mitigation (SSRM) to mitigate the impact of the structural shift on catastrophic forgetting of the inductive NGIL problem. We show that the structural shift can lead to a shift in the input distribution for the existing tasks, and further lead to an increased risk of catastrophic forgetting. Through comprehensive empirical studies with several benchmark datasets, we demonstrate that our proposed method, Structural-Shift-Risk-Mitigation (SSRM), is flexible and easy to adapt to improve the performance of state-of-the-art GNN incremental learning frameworks in the inductive setting.

**摘要:** 渐进学习是一种机器学习方法,它涉及在任务序列上训练一个模型,而不是同时训练所有任务。这种从任务流中渐进学习的能力对于许多现实应用至关重要。然而,渐进学习是图形结构数据的一个挑战性问题,因为许多与图形有关的问题涉及对每个单独节点的预测任务,称为节点wise Graph Incremental Learning(NGIL)。本文对该问题进行了正式的拟定和分析,并提出了一种基于规范化的新方法,即结构转移风险转移(SSRM),以减轻结构转移对诱导性NGIL问题的灾难性遗忘的影响。我们证明,结构转移可以导致现有任务输入分布的转变,并进一步导致灾难性遗忘的风险增加。通过对多个基准数据集进行综合实证研究,我们证明了我们提出的结构转移风险转移(SSRM)方法是灵活的,易于适应,以提高诱导环境中最先进的GNN增量学习框架的性能。

**[Paper URL](https://proceedings.mlr.press/v202/su23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/su23a/su23a.pdf)** 

# DUET: 2D Structured and Approximately Equivariant Representations
**题目:** DUET:二维结构和近等价表示

**作者:** Xavier Suau, Federico Danieli, T. Anderson Keller, Arno Blaas, Chen Huang, Jason Ramapuram, Dan Busbridge, Luca Zappella

**Abstract:** Multiview Self-Supervised Learning (MSSL) is based on learning invariances with respect to a set of input transformations. However, invariance partially or totally removes transformation-related information from the representations, which might harm performance for specific downstream tasks that require such information. We propose 2D strUctured and EquivarianT representations (coined DUET), which are 2d representations organized in a matrix structure, and equivariant with respect to transformations acting on the input data. DUET representations maintain information about an input transformation, while remaining semantically expressive. Compared to SimCLR (Chen et al., 2020) (unstructured and invariant) and ESSL (Dangovski et al., 2022) (unstructured and equivariant), the structured and equivariant nature of DUET representations enables controlled generation with lower reconstruction error, while controllability is not possible with SimCLR or ESSL. DUET also achieves higher accuracy for several discriminative tasks, and improves transfer learning.

**摘要:** 多视自我监督学习(Multiview Self-Supervised Learning,MSSL)是基于对输入变换的学习不变性。然而,不变性部分或完全从变换相关信息中移除,这可能对需要这种信息的特定下游任务的性能造成损害。我们建议2D strUctured和 EquivarianT表示(合并的DUET),这些表示是在矩阵结构中组织的2D表示,以及对在输入数据上作用的变换的等效性。 DUET表示保持关于输入变换的信息,同时保持语义表达性。DUET 也 提高 了 对 若干 歧视性 任务 的 准确性, 并 改善 了 转移 学习 。

**[Paper URL](https://proceedings.mlr.press/v202/suau23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/suau23a/suau23a.pdf)** 

# Long-Tailed Recognition by Mutual Information Maximization between Latent Features and Ground-Truth Labels
**题目:** 潜在特征与地面事实标签之间的相互信息最大化实现长期识别

**作者:** Min-Kook Suh, Seung-Woo Seo

**Abstract:** Although contrastive learning methods have shown prevailing performance on a variety of representation learning tasks, they encounter difficulty when the training dataset is long-tailed. Many researchers have combined contrastive learning and a logit adjustment technique to address this problem, but the combinations are done ad-hoc and a theoretical background has not yet been provided. The goal of this paper is to provide the background and further improve the performance. First, we show that the fundamental reason contrastive learning methods struggle with long-tailed tasks is that they try to maximize the mutual information between latent features and input data. As ground-truth labels are not considered in the maximization, they are not able to address imbalances between classes. Rather, we interpret the long-tailed recognition task as a mutual information maximization between latent features and ground-truth labels. This approach integrates contrastive learning and logit adjustment seamlessly to derive a loss function that shows state-of-the-art performance on long-tailed recognition benchmarks. It also demonstrates its efficacy in image segmentation tasks, verifying its versatility beyond image classification. Code is available at https://github.com/bluecdm/Long-tailed-recognition.

**摘要:** 尽管对比学习方法在各种表现学习任务中显示了优势,但在训练数据集长尾时却遇到了困难。许多研究人员结合对比学习和逻辑调整技术来解决这一问题,但这些组合是临时进行的,理论背景尚未提供。本文的目标是提供背景并进一步提高性能。首先,我们证明对比学习方法与长尾任务的根本原因在于它们试图最大化潜在特征和输入数据之间的相互信息。这种方法将对比性学习和逻辑调整结合起来,以产生一种显示长尾识别基准的最新性能的损失函数。它还证明了图像分割任务的有效性,验证了它在图像分类之外的多用途性。

**[Paper URL](https://proceedings.mlr.press/v202/suh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/suh23a/suh23a.pdf)** 

# Adversarial Learning of Distributional Reinforcement Learning
**题目:** 分布强化学习的敌对学习

**作者:** Yang Sui, Yukun Huang, Hongtu Zhu, Fan Zhou

**Abstract:** Reinforcement learning (RL) has made significant advancements in artificial intelligence. However, its real-world applications are limited due to differences between simulated environments and the actual world. Consequently, it is crucial to systematically analyze how each component of the RL system can affect the final model performance. In this study, we propose an adversarial learning framework for distributional reinforcement learning, which adopts the concept of influence measure from the statistics community. This framework enables us to detect performance loss caused by either the internal policy structure or the external state observation. The proposed influence measure is based on information geometry and has desirable properties of invariance. We demonstrate that the influence measure is useful for three diagnostic tasks: identifying fragile states in trajectories, determining the instability of the policy architecture, and pinpointing anomalously sensitive policy parameters.

**摘要:** 强化学习(RL)在人工智能领域取得了重大的进步,但由于模拟环境与实际世界之间的差异,其实际应用受到限制。因此,系统分析如何影响RL系统各组件的最终模型性能是至关重要的。本研究中,我们提出了一种分布强化学习的对抗学习框架,采用统计社区的影响测量概念。该框架使我们能够检测内部政策结构或外部状态观察所导致的性能损失。

**[Paper URL](https://proceedings.mlr.press/v202/sui23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sui23a/sui23a.pdf)** 

# Distilling Internet-Scale Vision-Language Models into Embodied Agents
**题目:** 将互联网尺度视觉语言模型分解为嵌入式代理

**作者:** Theodore Sumers, Kenneth Marino, Arun Ahuja, Rob Fergus, Ishita Dasgupta

**Abstract:** Instruction-following agents must ground language into their observation and action spaces. Learning to ground language is challenging, typically requiring domain-specific engineering or large quantities of human interaction data. To address this challenge, we propose using pretrained vision-language models (VLMs) to supervise embodied agents. We combine ideas from model distillation and hindsight experience replay (HER), using a VLM to retroactively generate language describing the agent’s behavior. Simple prompting allows us to control the supervision signal, teaching an agent to interact with novel objects based on their names (e.g., planes) or their features (e.g., colors) in a 3D rendered environment. Fewshot prompting lets us teach abstract category membership, including pre-existing categories (food vs toys) and ad-hoc ones (arbitrary preferences over objects). Our work outlines a new and effective way to use internet-scale VLMs, repurposing the generic language grounding acquired by such models to teach task-relevant groundings to embodied agents.

**摘要:** 遵循指令的代理人必须将语言引入他们的观察和行动空间。学习地面语言是挑战性的,通常需要领域特有工程或大量人类交互数据。为了解决这一挑战,我们建议使用预制视觉语言模型(VLMs)来监督被体现的代理人。我们结合模型蒸馏和后视经验重演(HER)的观念,使用VLM来回顾性生成描述代理人的行为的语言。简单提示允许我们控制监督信号,教代理人以其名称(例如飞机)或其特征(例如颜色)为基础的新型对象进行交互。我们的工作概述了一种新的有效方法,利用网络范围的VLM,重新利用这些模型所获得的通用语言基础,以教导被体现的代理人具有任务相关基础。

**[Paper URL](https://proceedings.mlr.press/v202/sumers23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sumers23a/sumers23a.pdf)** 

# Vector-Valued Control Variates
**题目:** 矢量值控制变量

**作者:** Zhuo Sun, Alessandro Barp, Francois-Xavier Briol

**Abstract:** Control variates are variance reduction tools for Monte Carlo estimators. They can provide significant variance reduction, but usually require a large number of samples, which can be prohibitive when sampling or evaluating the integrand is computationally expensive. Furthermore, there are many scenarios where we need to compute multiple related integrals simultaneously or sequentially, which can further exacerbate computational costs. In this paper, we propose vector-valued control variates, an extension of control variates which can be used to reduce the variance of multiple Monte Carlo estimators jointly. This allows for the transfer of information across integration tasks, and hence reduces the need for a large number of samples. We focus on control variates based on kernel interpolants and our novel construction is obtained through a generalised Stein identity and the development of novel matrix-valued Stein reproducing kernels. We demonstrate our methodology on a range of problems including multifidelity modelling, Bayesian inference for dynamical systems, and model evidence computation through thermodynamic integration.

**摘要:** 控制变量是蒙特卡罗估计器的变量减小工具。它们可以提供显著的变量减小,但通常需要大量的样品,在采样或评价整数时可能具有抑制性,而且计算成本昂贵。此外,我们需要同时或连续计算多个相关整数,从而进一步加剧计算成本。本论文提出了矢量值控制变量,一种控制变量扩展,可以联合使用来减少多个蒙特卡罗估计器的变量。通过热力学集成,对多真性建模、动态系统贝叶斯推理和模型证据计算等一系列问题进行了研究。

**[Paper URL](https://proceedings.mlr.press/v202/sun23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23a/sun23a.pdf)** 

# MetaModulation: Learning Variational Feature Hierarchies for Few-Shot Learning with Fewer Tasks
**题目:** MetaModulation:学习变异功能 Hierarchies for Few-Shot Learning with Fewer Tasks

**作者:** Wenfang Sun, Yingjun Du, Xiantong Zhen, Fan Wang, Ling Wang, Cees G. M. Snoek

**Abstract:** Meta-learning algorithms are able to learn a new task using previously learned knowledge, but they often require a large number of meta-training tasks which may not be readily available. To address this issue, we propose a method for few-shot learning with fewer tasks, which we call MetaModulation. The key idea is to use a neural network to increase the density of the meta-training tasks by modulating batch normalization parameters during meta-training. Additionally, we modify parameters at various neural network levels, rather than just a single layer, to increase task diversity. To account for the uncertainty caused by the reduced number of training tasks, we propose a variational MetaModulation where the modulation parameters are treated as latent variables. We also introduce learning variational feature hierarchies by the variational MetaModulation, which modulates features at all layers and can take into account task uncertainty and generate more diverse tasks. The ablation studies illustrate the advantages of utilizing a learnable task modulation at different levels and demonstrate the benefit of incorporating probabilistic variants in few-task meta-learning. Our MetaModulation and its variational variants consistently outperform state-of-the-art alternatives on four few-task meta-learning benchmarks.

**摘要:** 为了解决这一问题,我们提出了一种以少量任务为对象的少 shot学习方法,我们称之为MetaModulation。关键思想是利用神经网络,通过调制 batch正常化参数来增加Meta-training任务的密度。此外,我们修改多个神经网络的参数,而不是单层,以增加任务多样性。为了考虑到减少培训任务造成的不确定性,我们提出了变量MetaModulation,其中调制参数被视为潜在变量。我们还引入了变量MetaModulation的变量特征等级,它在所有层中调制特征,可以考虑任务多样性并产生更多的变量任务。研究表明,在不同层次上利用可学习的任务调制的优点,并证明了将概率变量纳入少任务元学习中的优势。我们的元调制及其变量变量在四个少任务元学习基准上始终超过了最先进的替代方案。

**[Paper URL](https://proceedings.mlr.press/v202/sun23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23b/sun23b.pdf)** 

# Revisiting Sampling for Combinatorial Optimization
**题目:** 对组合优化的抽样进行检讨

**作者:** Haoran Sun, Katayoon Goshvadi, Azade Nova, Dale Schuurmans, Hanjun Dai

**Abstract:** Sampling approaches like Markov chain Monte Carlo were once popular for combinatorial optimization, but the inefficiency of classical methods and the need for problem-specific designs curtailed ongoing development. Recent work has favored data-driven approaches that mitigate the need for hand-craft heuristics, but these are often not usable as out-of-the-box solvers due to dependence on in-distribution training and limited scalability to large instances. In this paper, we revisit the idea of using sampling for combinatorial optimization, motivated by the significant recent advances of gradient-based discrete MCMC and new techniques for parallel neighborhood exploration on accelerators. Remarkably, we find that modern sampling strategies can leverage landscape information to provide general-purpose solvers that require no training and yet are competitive with state of the art combinatorial solvers. In particular, experiments on cover vertex selection, graph partition and routing demonstrate better speed-quality trade-offs over current learning based approaches, and sometimes even superior performance to commercial solvers and specialized algorithms.

**摘要:** 马可夫链蒙特卡洛(Markov chain Monte Carlo)等采样方法曾经是组合优化的热门方法,但传统的方法的效率低下和问题特异设计的必要性限制了持续的发展。最近的工作倾向于基于数据的采样方法,减少了手工艺求解的必要性,但这些方法由于依赖于分布训练和对大型实例的有限的可扩展性而往往不能作为外在的解决方法使用。尤其是在覆盖顶点选择、图分割和路由方面的实验表明,比目前的基于学习的方法更好的速度和质量的交换,有时甚至比商业求解者和专门的算法具有更高的性能。

**[Paper URL](https://proceedings.mlr.press/v202/sun23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23c/sun23c.pdf)** 

# What Makes Entities Similar? A Similarity Flooding Perspective for Multi-sourced Knowledge Graph Embeddings
**题目:** 什么是实体相似的?基于多源知识图嵌入的相似性浮游视角

**作者:** Zequn Sun, Jiacheng Huang, Xiaozhou Xu, Qijin Chen, Weijun Ren, Wei Hu

**Abstract:** Joint representation learning over multi-sourced knowledge graphs (KGs) yields transferable and expressive embeddings that improve downstream tasks. Entity alignment (EA) is a critical step in this process. Despite recent considerable research progress in embedding-based EA, how it works remains to be explored. In this paper, we provide a similarity flooding perspective to explain existing translation-based and aggregation-based EA models. We prove that the embedding learning process of these models actually seeks a fixpoint of pairwise similarities between entities. We also provide experimental evidence to support our theoretical analysis. We propose two simple but effective methods inspired by the fixpoint computation in similarity flooding, and demonstrate their effectiveness on benchmark datasets. Our work bridges the gap between recent embedding-based models and the conventional similarity flooding algorithm. It would improve our understanding of and increase our faith in embedding-based EA.

**摘要:** 在多源知识图(KGs)上联合表示学习,产生可转让和表达的嵌入式,改善下游任务。实体整合(EA)是这一过程的一个关键步骤。尽管在嵌入式 EA中最近取得了相当大的研究进展,但如何工作仍需探索。本论文提供相似性洪水视角,以解释现有的基于翻译和基于集群的 EA模型。我们证明,这些模型的嵌入学习过程实际上是寻求实体之间对偶相似性的固定点。我们还提供实验证据以支持我们的理论分析。我们提出了两个简单但有效的方法,以相似性洪水的固定点计算为灵感,并展示它们在基准数据集上的效果。这将提高我们对基于嵌入式 EA的理解和信心。

**[Paper URL](https://proceedings.mlr.press/v202/sun23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23d/sun23d.pdf)** 

# Maximum Optimality Margin: A Unified Approach for Contextual Linear Programming and Inverse Linear Programming
**题目:** 最大优化边界:基于上下文线性规划和逆线性规划的统一方法

**作者:** Chunlin Sun, Shang Liu, Xiaocheng Li

**Abstract:** In this paper, we study the predict-then-optimize problem where the output of a machine learning prediction task is used as the input of some downstream optimization problem, say, the objective coefficient vector of a linear program. The problem is also known as predictive analytics or contextual linear programming. The existing approaches largely suffer from either (i) optimization intractability (a non-convex objective function)/statistical inefficiency (a suboptimal generalization bound) or (ii) requiring strong condition(s) such as no constraint or loss calibration. We develop a new approach to the problem called maximum optimality margin which designs the machine learning loss function by the optimality condition of the downstream optimization. The max-margin formulation enjoys both computational efficiency and good theoretical properties for the learning procedure. More importantly, our new approach only needs the observations of the optimal solution in the training data rather than the objective function, which makes it a new and natural approach to the inverse linear programming problem under both contextual and context-free settings; we also analyze the proposed method under both offline and online settings, and demonstrate its performance using numerical experiments.

**摘要:** 本文研究了机器学习预测任务的输出作为下游优化问题的输入,例如线性程序的客观系数向量问题。该问题也被称为预测分析或上下文线性规划。现有的方法主要 suffer either (i) optimization intractability (a non-convex objective function)/statistical inefficiency (a suboptimal generalization bound) or (ii) requiring strong condition(s) such as no constraint or loss calibration。更重要的是,我们的新方法只需要在训练数据中观察最佳解决方案,而不是客观函数,这使得它成为一种在上下文和无上下文设置下对逆线性编程问题的新的自然方法;我们还分析了在オフライン和在线设置下提出的方法,并通过数值实验证明了它的性能。

**[Paper URL](https://proceedings.mlr.press/v202/sun23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23e/sun23e.pdf)** 

# Tensor Gaussian Process with Contraction for Multi-Channel Imaging Analysis
**题目:** 多通道影像分析的拉伸高斯过程

**作者:** Hu Sun, Ward Manchester, Meng Jin, Yang Liu, Yang Chen

**Abstract:** Multi-channel imaging data is a prevalent data format in scientific fields such as astronomy and biology. The structured information and the high dimensionality of these 3-D tensor data makes the analysis an intriguing but challenging topic for statisticians and practitioners. The low-rank scalar-on-tensor regression model, in particular, has received widespread attention and has been re-formulated as a tensor Gaussian Process (Tensor-GP) model with multi-linear kernel in Yu et al. (2018). In this paper, we extend the Tensor-GP model by introducing an integrative dimensionality reduction technique, called tensor contraction, with a Tensor-GP for a scalar-on-tensor regression task with multi-channel imaging data. This is motivated by the solar flare forecasting problem with high dimensional multi-channel imaging data. We first estimate a latent, reduced-size tensor for each data tensor and then apply a multi-linear Tensor-GP on the latent tensor data for prediction. We introduce an anisotropic total-variation regularization when conducting the tensor contraction to obtain a sparse and smooth latent tensor. We then propose an alternating proximal gradient descent algorithm for estimation. We validate our approach via extensive simulation studies and applying it to the solar flare forecasting problem.

**摘要:** 多通道图像数据是天文学和生物学等科学领域普遍的数据格式。这些三维天线数据的结构信息和高维度使得分析成为统计学家和实践者感兴趣的,但具有挑战性的课题。 低级天线回归模型尤其受到广泛关注,并在Yu等人(2018年)中重新形成为多线性核的天线高斯过程(Tensor-GP)模型。本文介绍了在导引力收缩时进行异性总变量定律,以获得稀疏、平滑的隐性力矩,并提出一种交互式近梯度下降算法进行估计,通过广泛的仿真研究验证了我们的方法,并将其应用于太阳能闪电预测问题。

**[Paper URL](https://proceedings.mlr.press/v202/sun23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23f/sun23f.pdf)** 

# MABe22: A Multi-Species Multi-Task Benchmark for Learned Representations of Behavior
**题目:** MABe22:学习行为表现的多层次多任务基准

**作者:** Jennifer J. Sun, Markus Marks, Andrew Wesley Ulmer, Dipam Chakraborty, Brian Geuther, Edward Hayes, Heng Jia, Vivek Kumar, Sebastian Oleszko, Zachary Partridge, Milan Peelman, Alice Robie, Catherine E Schretter, Keith Sheppard, Chao Sun, Param Uttarwar, Julian Morgan Wagner, Erik Werner, Joseph Parker, Pietro Perona, Yisong Yue, Kristin Branson, Ann Kennedy

**Abstract:** We introduce MABe22, a large-scale, multi-agent video and trajectory benchmark to assess the quality of learned behavior representations. This dataset is collected from a variety of biology experiments, and includes triplets of interacting mice (4.7 million frames video+pose tracking data, 10 million frames pose only), symbiotic beetle-ant interactions (10 million frames video data), and groups of interacting flies (4.4 million frames of pose tracking data). Accompanying these data, we introduce a panel of real-life downstream analysis tasks to assess the quality of learned representations by evaluating how well they preserve information about the experimental conditions (e.g. strain, time of day, optogenetic stimulation) and animal behavior. We test multiple state-of-the-art self-supervised video and trajectory representation learning methods to demonstrate the use of our benchmark, revealing that methods developed using human action datasets do not fully translate to animal datasets. We hope that our benchmark and dataset encourage a broader exploration of behavior representation learning methods across species and settings.

**摘要:** 本文介绍了一种大型多代理视频和轨迹指标 MABe22,以评估学习行为表现的质量。该数据集由多种生物学实验收集,包括相互作用的老鼠的三组(4.7万帧视频+姿态追踪数据,10万帧姿态追踪数据),共生性甲虫与蚂蚁的相互作用(10万帧视频数据),以及相互作用的苍蝇的群落(4.4万帧姿态追踪数据)。我们测试了多种最先进的自监视视频和轨迹表示学习方法,以证明使用我们的基准,揭示了利用人类行动数据集开发的方法不能完全转换到动物数据集。我们希望我们的基准和数据集鼓励在不同种类和环境中更广泛地探索行为表示学习方法。

**[Paper URL](https://proceedings.mlr.press/v202/sun23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23g/sun23g.pdf)** 

# Dynamic Regularized Sharpness Aware Minimization in Federated Learning: Approaching Global Consistency and Smooth Landscape
**题目:** 动态调节 Sharpness 联邦学习中的意识减小:实现全球一致性和 Smooth Landscape

**作者:** Yan Sun, Li Shen, Shixiang Chen, Liang Ding, Dacheng Tao

**Abstract:** In federated learning (FL), a cluster of local clients are chaired under the coordination of the global server and cooperatively train one model with privacy protection. Due to the multiple local updates and the isolated non-iid dataset, clients are prone to overfit into their own optima, which extremely deviates from the global objective and significantly undermines the performance. Most previous works only focus on enhancing the consistency between the local and global objectives to alleviate this prejudicial client drifts from the perspective of the optimization view, whose performance would be prominently deteriorated on the high heterogeneity. In this work, we propose a novel and general algorithm FedSMOO by jointly considering the optimization and generalization targets to efficiently improve the performance in FL. Concretely, FedSMOO adopts a dynamic regularizer to guarantee the local optima towards the global objective, which is meanwhile revised by the global Sharpness Aware Minimization (SAM) optimizer to search for the consistent flat minima. Our theoretical analysis indicates that FedSMOO achieves fast $\mathcal{O}(1/T)$ convergence rate with low generalization bound. Extensive numerical studies are conducted on the real-world dataset to verify its peerless efficiency and excellent generality.

**摘要:** 在联邦学习(FL)中,一个本地客户群由全球服务器的协调下担任主席,并协同训练一个具有隐私保护的模型。由于多个本地更新和孤立的非线性数据集,客户倾向于过度适应自己的优化,这极大地偏离了全球目标并严重破坏了性能。大多数以前的工作只集中在提高本地和全球目标的一致性,以减轻这种不利的客户端从优化视角的漂移,其性能在高异质性上会明显恶化。具体而言,FedSMOO采用动态调节器,以保证对全球目标的局部优化,同时由全球 Sharpness Aware Minimization (SAM)优化器进行修正,以寻找一致的平整最小值。我们的理论分析表明,FedSMOO具有低一般化约束的快速$\mathcal{O}(1/T)$收敛率。

**[Paper URL](https://proceedings.mlr.press/v202/sun23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23h/sun23h.pdf)** 

# When and How Does Known Class Help Discover Unknown Ones? Provable Understanding Through Spectral Analysis
**题目:** 知道的类如何帮助发现未知的类?通过光谱分析提供理解

**作者:** Yiyou Sun, Zhenmei Shi, Yingyu Liang, Yixuan Li

**Abstract:** Novel Class Discovery (NCD) aims at inferring novel classes in an unlabeled set by leveraging prior knowledge from a labeled set with known classes. Despite its importance, there is a lack of theoretical foundations for NCD. This paper bridges the gap by providing an analytical framework to formalize and investigate when and how known classes can help discover novel classes. Tailored to the NCD problem, we introduce a graph-theoretic representation that can be learned by a novel NCD Spectral Contrastive Loss (NSCL). Minimizing this objective is equivalent to factorizing the graph’s adjacency matrix, which allows us to derive a provable error bound and provide the sufficient and necessary condition for NCD. Empirically, NSCL can match or outperform several strong baselines on common benchmark datasets, which is appealing for practical usage while enjoying theoretical guarantees.

**摘要:** 新类发现(英语:New Class Discovery,缩写:NCD)旨在利用已知类的标记集合来推断新类,从而利用已知类的预先知识推导新类。尽管具有重要意义,但对于新类缺乏理论基础。本论文通过提供分析框架来弥补这一缺口,以形式化和研究已知类如何帮助发现新类。针对新类的问题,我们介绍了一种可以由新新新类光谱对比失利(NSCL)学习的图理论表示。

**[Paper URL](https://proceedings.mlr.press/v202/sun23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23i/sun23i.pdf)** 

# Learning Prescriptive ReLU Networks
**题目:** 学习规范的RELU网络

**作者:** Wei Sun, Asterios Tsiourvas

**Abstract:** We study the problem of learning optimal policy from a set of discrete treatment options using observational data. We propose a piecewise linear neural network model that can balance strong prescriptive performance and interpretability, which we refer to as the prescriptive ReLU network, or P-ReLU. We show analytically that this model (i) partitions the input space into disjoint polyhedra, where all instances that belong to the same partition receive the same treatment, and (ii) can be converted into an equivalent prescriptive tree with hyperplane splits for interpretability. We demonstrate the flexibility of the P-ReLU network as constraints can be easily incorporated with minor modifications to the architecture. Through experiments, we validate the superior prescriptive accuracy of P-ReLU against competing benchmarks. Lastly, we present examples of prescriptive trees extracted from trained P-ReLUs using a real-world dataset, for both the unconstrained and constrained scenarios.

**摘要:** 本文研究了利用观察数据,从离散处理选项集学习最佳策略的问题。提出了一种可平衡强的规范性能和解释能力的线性网络模型,我们称之为规范的ReLU网络,或P-ReLU。我们分析表明,该模型(i)将输入空间分割为异构多面体,所有属于同一区的实例得到相同的处理,以及(ii)可转换为具有解释性超平面分割的等价规范树。我们证明了P-ReLU网络的灵活性,因为约束可以轻易地结合到架构中微小的修改。

**[Paper URL](https://proceedings.mlr.press/v202/sun23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23j/sun23j.pdf)** 

# All in a Row: Compressed Convolution Networks for Graphs
**题目:** All in a Row: Graphs 的压缩卷积网络

**作者:** Junshu Sun, Shuhui Wang, Xinzhe Han, Zhe Xue, Qingming Huang

**Abstract:** Compared to Euclidean convolution, existing graph convolution methods generally fail to learn diverse convolution operators under limited parameter scales and depend on additional treatments of multi-scale feature extraction. The challenges of generalizing Euclidean convolution to graphs arise from the irregular structure of graphs. To bridge the gap between Euclidean space and graph space, we propose a differentiable method for regularization on graphs that applies permutations to the input graphs. The permutations constrain all nodes in a row regardless of their input order and therefore enable the flexible generalization of Euclidean convolution. Based on the regularization of graphs, we propose Compressed Convolution Network (CoCN) for hierarchical graph representation learning. CoCN follows the local feature learning and global parameter sharing mechanisms of Convolution Neural Networks. The whole model can be trained end-to-end and is able to learn both individual node features and the corresponding structure features. We validate CoCN on several node classification and graph classification benchmarks. CoCN achieves superior performance over competitive convolutional GNNs and graph pooling models. Codes are available at https://github.com/sunjss/CoCN.

**摘要:** 与欧氏变换相比,现有的图形变换方法通常不能在有限参数尺度下学习不同的变换操作者,并且依赖于多尺度特征提取的额外处理。对图形的欧氏变换的一般化挑战来自图形的不规则结构。为了弥补欧氏空间和图形空间之间的差距,我们提出了一种适用于输入图形的变换的图形 regularization的可微分方法。整个模型可以从端到端进行训练,并能够学习不同的节点特征和相应的结构特征。我们对多个节点分类和图形分类基准的CoCN进行了验证。CoCN在竞争性卷积GNN和图形聚合模型上取得了优越的性能。

**[Paper URL](https://proceedings.mlr.press/v202/sun23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23k/sun23k.pdf)** 

# Momentum Ensures Convergence of SIGNSGD under Weaker Assumptions
**题目:** 势头确保在较弱的假设下SIGNSGD趋同

**作者:** Tao Sun, Qingsong Wang, Dongsheng Li, Bao Wang

**Abstract:** Sign Stochastic Gradient Descent (signSGD) is a communication-efficient stochastic algorithm that only uses the sign information of the stochastic gradient to update the model’s weights. However, the existing convergence theory of signSGD either requires increasing batch sizes during training or assumes the gradient noise is symmetric and unimodal. Error feedback has been used to guarantee the convergence of signSGD under weaker assumptions at the cost of communication overhead. This paper revisits the convergence of signSGD and proves that momentum can remedy signSGD under weaker assumptions than previous techniques; in particular, our convergence theory does not require the assumption of bounded stochastic gradient or increased batch size. Our results resonate with echoes of previous empirical results where, unlike signSGD, signSGD with momentum maintains good performance even with small batch sizes. Another new result is that signSGD with momentum can achieve an improved convergence rate when the objective function is second-order smooth. We further extend our theory to signSGD with major vote and federated learning.

**摘要:** 符号随机梯度降落(signSGD)是一种通信效率高的随机算法,仅使用随机梯度的符号信息来更新模型的重量。然而,符号随机梯度的现有收敛理论要么要求在训练中增加批量大小,要么假设梯度噪声是正交和单调的。另一个新结果是,当目标函数是二阶平滑时,运动信号SGD能提高收敛率,我们进一步扩展了我们理论到主要投票信号SGD和联合学习。

**[Paper URL](https://proceedings.mlr.press/v202/sun23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23l/sun23l.pdf)** 

# A Critical Revisit of Adversarial Robustness in 3D Point Cloud Recognition with Diffusion-Driven Purification
**题目:** 3D点云识别中敌对鲁棒性的关键回顾与扩散驱动的净化

**作者:** Jiachen Sun, Jiongxiao Wang, Weili Nie, Zhiding Yu, Zhuoqing Mao, Chaowei Xiao

**Abstract:** 3D point clouds serve as a crucial data representation in numerous real-world applications such as autonomous driving, robotics, and medical imaging. While the advancements in deep learning have spurred the utilization of 3D point clouds, deep models are notoriously vulnerable to adversarial attacks. Various defense solutions have been proposed to build robust models against adversarial attacks. In this work, we pinpoint a major limitation of the leading empirical defense, adversarial training, when applied to 3D point cloud models: gradient obfuscation, which significantly hampers robustness against potent attacks. To bridge the gap, we propose PointDP, a purification strategy that leverages diffusion models to defend against 3D adversarial attacks. Since PointDP does not rely on predefined adversarial examples for training, it can defend against a variety of threats. We conduct a comprehensive evaluation of PointDP across six representative 3D point cloud architectures, employing sixteen strong and adaptive attacks to manifest its foundational robustness. Our evaluation shows that PointDP achieves significantly better (i.e., 12.6%-40.3%) adversarial robustness than state-of-the-art methods under strong attacks bounded by different $\ell_p$ norms.

**摘要:** 3D点云作为许多现实应用中的关键数据表现,例如自主驾驶、机器人和医学影像。虽然深入学习的进步推动了3D点云的利用,但深层模型对敌对攻击具有显著的脆弱性。为构建对敌对攻击的鲁棒模型提出了各种防护解决方案。在这个工作中,我们指出了当应用到3D点云模型时,主要的实证防护、敌对训练的局限性:梯度模糊,严重妨碍对强大的攻击的鲁棒性。为了弥补这一差距,我们提出了一种利用扩散模型来防御3D敌对攻击的净化策略PointDP。我们对PointDP进行了6个代表性的3D点云架构的全面评估,采用16种强有力的适应性攻击来显示其基本的鲁棒性。我们的评估表明,PointDP在受到不同$\ell_p$规范限制的强有力攻击下比最先进的方法取得显著的 (12.6%-40.3%) 的敌对鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/sun23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23m/sun23m.pdf)** 

# SDDM: Score-Decomposed Diffusion Models on Manifolds for Unpaired Image-to-Image Translation
**题目:** SDDM:无耦合图像-到-图像翻译的多变形分离模型的分数分解

**作者:** Shikun Sun, Longhui Wei, Junliang Xing, Jia Jia, Qi Tian

**Abstract:** Recent score-based diffusion models (SBDMs) show promising results in unpaired image-to-image translation (I2I). However, existing methods, either energy-based or statistically-based, provide no explicit form of the interfered intermediate generative distributions. This work presents a new score-decomposed diffusion model (SDDM) on manifolds to explicitly optimize the tangled distributions during image generation. SDDM derives manifolds to make the distributions of adjacent time steps separable and decompose the score function or energy guidance into an image "denoising" part and a content "refinement" part. To refine the image in the same noise level, we equalize the refinement parts of the score function and energy guidance, which permits multi-objective optimization on the manifold. We also leverage the block adaptive instance normalization module to construct manifolds with lower dimensions but still concentrated with the perturbed reference image. SDDM outperforms existing SBDM-based methods with much fewer diffusion steps on several I2I benchmarks.

**摘要:** 最近的基于分数的扩散模型(SBDMs)在无paired image-to-image translation(I2I)中显示了有希望的结果。然而,现有的方法,无论是基于能量还是基于统计学,均不提供干涉的中间生成分布的明确形式。本研究提出了一种新的基于分数分解扩散模型(SDDM)在变形中明确优化图像生成过程中的混杂分布。SDDM导出变形,使相邻时间步骤的分布可分离,并将分数函数或能量指导分解为图像“变形”部分和内容“精细”部分。SDDM比现有 SBDM-based 方法更好,在几个 I2I 基准上传播步骤较少。

**[Paper URL](https://proceedings.mlr.press/v202/sun23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23n/sun23n.pdf)** 

# A Neural PDE Solver with Temporal Stencil Modeling
**题目:** 一种神经元PDE求解器,采用静止 Stencil模型

**作者:** Zhiqing Sun, Yiming Yang, Shinjae Yoo

**Abstract:** Numerical simulation of non-linear partial differential equations plays a crucial role in modeling physical science and engineering phenomena, such as weather, climate, and aerodynamics. Recent Machine Learning (ML) models trained on low-resolution spatio-temporal signals have shown new promises in capturing important dynamics in high-resolution signals, under the condition that the models can effectively recover the missing details. However, this study shows that significant information is often lost in the low-resolution down-sampled features. To address such issues, we propose a new approach, namely Temporal Stencil Modeling (TSM), which combines the strengths of advanced time-series sequence modeling (with the HiPPO features) and state-of-the-art neural PDE solvers (with learnable stencil modeling). TSM aims to recover the lost information from the PDE trajectories and can be regarded as a temporal generalization of classic finite volume methods such as WENO. Our experimental results show that TSM achieves the new state-of-the-art simulation accuracy for 2-D incompressible Navier-Stokes turbulent flows: it significantly outperforms the previously reported best results by 19.9% in terms of the highly-correlated duration time, and reduces the inference latency into 80%. We also show a strong generalization ability of the proposed method to various out-of-distribution turbulent flow settings, as well as lower resolution or 1-D / 3-D settings. Our code is available at https://github.com/Edward-Sun/TSM-PDE .

**摘要:** 非线性微分方程的数值模拟在物理学和工程现象的建模中起着关键作用,例如天气、气候和气动学。最近在低分辨率时空信号上训练的机器学习(ML)模型显示了在高分辨率信号中捕捉重要的动力学的新前景,条件是模型能够有效地恢复遗失的细节。然而,这项研究表明,低分辨率下标特征中经常丢失重要的信息。为了解决这些问题,我们提出了一种新的方法,即时形标记建模(TSM),它结合了先进的时系列序列建模(与HiPPO特征)和最先进的神经元PDE解像器(与可学习的标记建模)的优点。我们的实验结果表明,TSM实现了2D不可压缩纳维尔-斯托克斯湍流的新最先进的仿真精度:在高相关持续时间方面,它大大超过先前报告的最好结果19.9%,并降低推理延迟到80%。我们还显示了该方法对各种离散的湍流设置以及低分辨率或1-D/3-D设置的强一般化能力。我们的代码在 https://github.com/Edward-Sun/TSM-PDE 上。

**[Paper URL](https://proceedings.mlr.press/v202/sun23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23o/sun23o.pdf)** 

# Feature Expansion for Graph Neural Networks
**题目:** 图神经网络功能扩展

**作者:** Jiaqi Sun, Lin Zhang, Guangyi Chen, Peng Xu, Kun Zhang, Yujiu Yang

**Abstract:** Graph neural networks aim to learn representations for graph-structured data and show impressive performance in node classification. Recently, many methods have studied the representations of GNNs from the perspective of optimization goals and spectral graph theory. However, the feature space that dominates representation learning has not been systematically studied in graph neural networks. In this paper, we propose to fill this gap by analyzing the feature space of both spatial and spectral models. We decompose graph neural networks into determined feature spaces and trainable weights, providing the convenience of studying the feature space explicitly using matrix space analysis. In particular, we find theoretically that the feature space tends to be linearly correlated due to repeated aggregations. In this case, the feature space is bounded by the poor representation of shared weights or the limited dimensionality of node attributes in existing models, leading to poor performance. Motivated by these findings, we propose 1) feature subspaces flattening and 2) structural principal components to expand the feature space. Extensive experiments verify the effectiveness of our proposed more comprehensive feature space, with comparable inference time to the baseline, and demonstrate its efficient convergence capability.

**摘要:** 图神经网络的目标是学习图结构数据的表示,并在节点分类中表现出令人印象深刻的性能。最近,许多方法从优化目标和光谱图理论的角度研究了GNN的表示。然而,在图神经网络中,支配表示学习的特征空间尚未有系统研究。本文建议通过分析空间和光谱模型的特征空间来填补这一空白。我们将图神经网络分解为确定的特征空间和可训练的权重,为使用矩阵空间分析研究特征空间提供了方便。基于这些发现,我们提出了:(一)特征子空间平坦化和(二)结构性主要组成部分,以扩大特征空间。广泛的实验验证了我们提出的更全面特征空间的有效性,具有与基线相等的推断时间,并证明了其有效的收敛能力。

**[Paper URL](https://proceedings.mlr.press/v202/sun23p.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23p/sun23p.pdf)** 

# Model-Bellman Inconsistency for Model-based Offline Reinforcement Learning
**题目:** 基于模型的在线增强学习模型-贝尔曼不一致性

**作者:** Yihao Sun, Jiaji Zhang, Chengxing Jia, Haoxin Lin, Junyin Ye, Yang Yu

**Abstract:** For offline reinforcement learning (RL), model-based methods are expected to be data-efficient as they incorporate dynamics models to generate more data. However, due to inevitable model errors, straightforwardly learning a policy in the model typically fails in the offline setting. Previous studies have incorporated conservatism to prevent out-of-distribution exploration. For example, MOPO penalizes rewards through uncertainty measures from predicting the next states, which we have discovered are loose bounds of the ideal uncertainty, i.e., the Bellman error. In this work, we propose MOdel-Bellman Inconsistency penalized offLinE Policy Optimization (MOBILE), a novel uncertainty-driven offline RL algorithm. MOBILE conducts uncertainty quantification through the inconsistency of Bellman estimations under an ensemble of learned dynamics models, which can be a better approximator to the true Bellman error, and penalizes the Bellman estimation based on this uncertainty. Empirically we have verified that our proposed uncertainty quantification can be significantly closer to the true Bellman error than the compared methods. Consequently, MOBILE outperforms prior offline RL approaches on most tasks of D4RL and NeoRL benchmarks.

**摘要:** 由于不可避免的模型误差,直接学习模型中的策略通常在非线性设置中失败。以前的研究已经包含了保守主义,以防止分发外的探索。例如,MOPO通过预测下一个状态的不确定性措施来惩罚奖励,我们发现理想不确定性的边界是松散的,即贝尔曼误差。因此,MOBILE在D4RL和NeoRL的大多数任务上比以前的非线性RL方法高。

**[Paper URL](https://proceedings.mlr.press/v202/sun23q.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sun23q/sun23q.pdf)** 

# Inflow, Outflow, and Reciprocity in Machine Learning
**题目:** 机器学习中的输入、输出和相互关系

**作者:** Mukund Sundararajan, Walid Krichene

**Abstract:** Data is pooled across entities (individuals or enterprises) to create machine learning models, and sometimes, the entities that contribute the data also benefit from the models. Consider for instance a recommender system (e.g. Spotify, Instagram or YouTube), a health care app that predicts the risk for some disease, or a service built by pooling data across enterprises. In this work we propose a framework to study this value exchange, i.e., we model and measure contributions (outflows), benefits (inflows) and the balance between contributions and benefits (the degree of reciprocity). We show theoretically, and via experiments that under certain distributional assumptions, some classes of models are approximately reciprocal. These results only scratch the surface; we conclude with several open directions.

**摘要:** 数据汇聚在实体(个人或企业)之间,以创建机器学习模型,有时,数据贡献的实体也从模型中获益。例如,考虑推荐系统(例如Spotify、Instagram或YouTube),医疗应用,预测某些疾病的危险,或通过企业间的数据汇聚建立的服务。在这个工作中,我们提出了研究这一价值交换的框架,即我们建模和测量贡献(出流),收益(入流)和贡献与收益(互惠程度)之间的平衡。

**[Paper URL](https://proceedings.mlr.press/v202/sundararajan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sundararajan23a/sundararajan23a.pdf)** 

# When Personalization Harms Performance: Reconsidering the Use of Group Attributes in Prediction
**题目:** 当个性化危害性能时:重新考虑在预测中使用群属性

**作者:** Vinith Menon Suriyakumar, Marzyeh Ghassemi, Berk Ustun

**Abstract:** Machine learning models are often personalized with categorical attributes that define groups. In this work, we show that personalization with group attributes can inadvertently reduce performance at a group level – i.e., groups may receive unnecessarily inaccurate predictions by sharing their personal characteristics. We present formal conditions to ensure the fair use of group attributes in a prediction task, and describe how they can be checked by training one additional model. We characterize how fair use conditions be violated due to standard practices in model development, and study the prevalence of fair use violations in clinical prediction tasks. Our results show that personalization often fails to produce a tailored performance gain for every group who reports personal data, and underscore the need to evaluate fair use when personalizing models with characteristics that are protected, sensitive, self-reported, or costly to acquire.

**摘要:** 机器学习模型经常用定义群体的分类属性来进行个性化。在这项研究中,我们表明,使用群体属性的个性化可以不意地降低群体水平的业绩 — — 即,群体可以通过分享其个人特性获得不必要的不准确的预测。我们提出了确保预测任务中的群体属性的公平使用的正式条件,并描述如何通过培训一个额外的模型来检查它们。我们描述了如何因模型开发的标准实践而违反公平使用条件,并研究了临床预测任务中公平使用违反的普遍性。

**[Paper URL](https://proceedings.mlr.press/v202/suriyakumar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/suriyakumar23a/suriyakumar23a.pdf)** 

# Tuning Computer Vision Models With Task Rewards
**题目:** 用任务奖励调整计算机视觉模型

**作者:** André Susano Pinto, Alexander Kolesnikov, Yuge Shi, Lucas Beyer, Xiaohua Zhai

**Abstract:** Misalignment between model predictions and intended usage can be detrimental for the deployment of computer vision models. The issue is exacerbated when the task involves complex structured outputs, as it becomes harder to design procedures which address this misalignment. In natural language processing, this is often addressed using reinforcement learning techniques that align models with a task reward. We adopt this approach and show its surprising effectiveness to improve generic models pretrained to imitate example outputs across multiple computer vision tasks, such as object detection, panoptic segmentation, colorization and image captioning. We believe this approach has the potential to be widely useful for better aligning models with a diverse range of computer vision tasks.

**摘要:** 模型预测与预期使用之间的误差对计算机视觉模型的部署有不利影响。当任务涉及复杂的结构性输出时,问题更加严重,因为设计处理这种误差的程序变得更加困难。在自然语言处理中,经常使用增强学习技术来处理与任务奖励相匹配的模型。我们采用这种方法,并展示其令人惊奇的有效性,以改进通用模型,以模仿多个计算机视觉任务的实例输出,例如对象检测、泛光分割、颜色化和图像字幕。我们相信这种方法具有广泛的应用潜力,以便更好地与各种计算机视觉任务相匹配。

**[Paper URL](https://proceedings.mlr.press/v202/susano-pinto23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/susano-pinto23a/susano-pinto23a.pdf)** 

# Beyond Exponentially Fast Mixing in Average-Reward Reinforcement Learning via Multi-Level Monte Carlo Actor-Critic
**题目:** 通过多层次的蒙特卡罗演员-危机学习,超越指数快速混合

**作者:** Wesley A Suttle, Amrit Bedi, Bhrij Patel, Brian M. Sadler, Alec Koppel, Dinesh Manocha

**Abstract:** Many existing reinforcement learning (RL) methods employ stochastic gradient iteration on the back end, whose stability hinges upon a hypothesis that the data-generating process mixes exponentially fast with a rate parameter that appears in the step-size selection. Unfortunately, this assumption is violated for large state spaces or settings with sparse rewards, and the mixing time is unknown, making the step size inoperable. In this work, we propose an RL methodology attuned to the mixing time by employing a multi-level Monte Carlo estimator for the critic, the actor, and the average reward embedded within an actor-critic (AC) algorithm. This method, which we call Multi-level Actor-Critic (MAC), is developed specifically for infinite-horizon average-reward settings and neither relies on oracle knowledge of the mixing time in its parameter selection nor assumes its exponential decay; it is therefore readily applicable to applications with slower mixing times. Nonetheless, it achieves a convergence rate comparable to SOTA actor-critic algorithms. We experimentally show that these alleviated restrictions on the technical conditions required for stability translate to superior performance in practice for RL problems with sparse rewards.

**摘要:** 许多现有的增强学习(RL)方法在后端采用随机梯度迭代,其稳定性取决于数据生成过程与在步骤大小选择中出现的速率参数的指数快速混合的假设。不幸的是,对于大状态空间或稀有奖励的设置,这一假设被违反,并且混合时间未知,使得步骤大小无法操作。实验表明,这些缓解了稳定所需的技术条件的限制在实际应用中转化为低回报的RL问题具有较高的性能。

**[Paper URL](https://proceedings.mlr.press/v202/suttle23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/suttle23a/suttle23a.pdf)** 

# Tight and fast generalization error bound of graph embedding in metric space
**题目:** 将图嵌入度量空间的严格和快速一般化误差界限

**作者:** Atsushi Suzuki, Atsushi Nitanda, Taiji Suzuki, Jing Wang, Feng Tian, Kenji Yamanishi

**Abstract:** Recent studies have experimentally shown that we can achieve in non-Euclidean metric space effective and efficient graph embedding, which aims to obtain the vertices’ representations reflecting the graph’s structure in the metric space. Specifically, graph embedding in hyperbolic space has experimentally succeeded in embedding graphs with hierarchical-tree structure, e.g., data in natural languages, social networks, and knowledge bases. However, recent theoretical analyses have shown a much higher upper bound on non-Euclidean graph embedding’s generalization error than Euclidean one’s, where a high generalization error indicates that the incompleteness and noise in the data can significantly damage learning performance. It implies that the existing bound cannot guarantee the success of graph embedding in non-Euclidean metric space in a practical training data size, which can prevent non-Euclidean graph embedding’s application in real problems. This paper provides a novel upper bound of graph embedding’s generalization error by evaluating the local Rademacher complexity of the model as a function set of the distances of representation couples. Our bound clarifies that the performance of graph embedding in non-Euclidean metric space, including hyperbolic space, is better than the existing upper bounds suggest. Specifically, our new upper bound is polynomial in the metric space’s geometric radius $R$ and can be $O(\frac{1}{S})$ at the fastest, where $S$ is the training data size. Our bound is significantly tighter and faster than the existing one, which can be exponential to $R$ and $O(\frac{1}{\sqrt{S}})$ at the fastest. Specific calculations on example cases show that graph embedding in non-Euclidean metric space can outperform that in Euclidean space with much smaller training data than the existing bound has suggested.

**摘要:** 最近的研究实验表明,我们可以在非欧几里德空间中实现有效的和高效的图嵌入,其目标是获得顶点的表示,反映图的结构在统计空间中。 具体而言,在超线性空间中的图嵌入实验成功地嵌入了具有层次树结构的图,例如自然语言、社会网络和知识库的数据。 然而,最近的理论分析表明,非欧几里德图嵌入的一般化误差比欧几里德的误差要高得多,高一般化误差表明数据中的不完整性和噪声会严重损害学习成绩。本文通过评价该模型的局部拉德马切尔复杂性为表示耦合的距离函数集合,给出了图嵌入非欧几里德空间的通用化误差的新上限。我们的上限澄清了图嵌入非欧几里德空间的性能,包括超波空间的性能,比现有上限所建议的更好。具体而言,我们的新的上限是metric空间的几何半径$R$中的多项式,并且最快速的可以是$O(\frac{1}{S})$,其中$S$是训练数据大小。我们的上限比现有的更紧,最快速的可以是$R$和$O(\frac{1}{\sqrt{S}})$的指数。

**[Paper URL](https://proceedings.mlr.press/v202/suzuki23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/suzuki23a/suzuki23a.pdf)** 

# Proximal Causal Learning of Conditional Average Treatment Effects
**题目:** 条件平均治疗效果的近似诱因学习

**作者:** Erik Sverdrup, Yifan Cui

**Abstract:** Efficiently and flexibly estimating treatment effect heterogeneity is an important task in a wide variety of settings ranging from medicine to marketing, and there are a considerable number of promising conditional average treatment effect estimators currently available. These, however, typically rely on the assumption that the measured covariates are enough to justify conditional exchangeability. We propose the P-learner, motivated by the R- and DR-learner, a tailored two-stage loss function for learning heterogeneous treatment effects in settings where exchangeability given observed covariates is an implausible assumption, and we wish to rely on proxy variables for causal inference. Our proposed estimator can be implemented by off-the-shelf loss-minimizing machine learning methods, which in the case of kernel regression satisfies an oracle bound on the estimated error as long as the nuisance components are estimated reasonably well.

**摘要:** 有效灵活地估计治疗效应异质性是医学到市场营销等多种环境中的重要任务,目前有相当数量的可观条件平均治疗效应估计器,但这些估计器通常依赖于测量的共变量足以证明条件交换性。我们提出了由R-和DR-learner驱动的P-learner,一种针对观察到的共变量交换性是不可能假设的环境中学习异质性治疗效应的定制两阶段损失函数,并希望依靠代理变量进行因果推理。

**[Paper URL](https://proceedings.mlr.press/v202/sverdrup23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/sverdrup23a/sverdrup23a.pdf)** 

# Inverse Reinforcement Learning without Reinforcement Learning
**题目:** 反向强化学习,没有强化学习

**作者:** Gokul Swamy, David Wu, Sanjiban Choudhury, Drew Bagnell, Steven Wu

**Abstract:** Inverse Reinforcement Learning (IRL) is a powerful set of techniques for imitation learning that aims to learn a reward function that rationalizes expert demonstrations. Unfortunately, traditional IRL methods suffer from a computational weakness: they require repeatedly solving a hard reinforcement learning (RL) problem as a subroutine. This is counter-intuitive from the viewpoint of reductions: we have reduced the easier problem of imitation learning to repeatedly solving the harder problem of RL. Another thread of work has proved that access to the side-information of the distribution of states where a strong policy spends time can dramatically reduce the sample and computational complexities of solving an RL problem. In this work, we demonstrate for the first time a more informed imitation learning reduction where we utilize the state distribution of the expert to alleviate the global exploration component of the RL subroutine, providing an exponential speedup in theory. In practice, we find that we are able to significantly speed up the prior art on continuous control tasks.

**摘要:** 反增强学习(英语:Inverse Reinforcement Learning,简称IRL)是一套有效的仿真学习技术,其目的在于学习一种使专家演示合理化的奖励函数。不幸的是,传统的IRL方法存在计算弱点:它们需要反复解决一个硬增强学习(英语:Hard Reinforcement Learning,简称RL)问题作为子程序。在实践中,我们发现我们能够大大加快连续控制任务的先进技术。

**[Paper URL](https://proceedings.mlr.press/v202/swamy23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/swamy23a/swamy23a.pdf)** 

# Von Mises Mixture Distributions for Molecular Conformation Generation
**题目:** 冯·米斯混合物分布法用于分子相容生成

**作者:** Kirk Swanson, Jake Lawrence Williams, Eric M Jonas

**Abstract:** Molecules are frequently represented as graphs, but the underlying 3D molecular geometry (the locations of the atoms) ultimately determines most molecular properties. However, most molecules are not static and at room temperature adopt a wide variety of geometries or $\textit{conformations}$. The resulting distribution on geometries $p(x)$ is known as the Boltzmann distribution, and many molecular properties are expectations computed under this distribution. Generating accurate samples from the Boltzmann distribution is therefore essential for computing these expectations accurately. Traditional sampling-based methods are computationally expensive, and most recent machine learning-based methods have focused on identifying $\textit{modes}$ in this distribution rather than generating true $\textit{samples}$. Generating such samples requires capturing conformational variability, and it has been widely recognized that the majority of conformational variability in molecules arises from rotatable bonds. In this work, we present VonMisesNet, a new graph neural network that captures conformational variability via a variational approximation of rotatable bond torsion angles as a mixture of von Mises distributions. We demonstrate that VonMisesNet can generate conformations for arbitrary molecules in a way that is both physically accurate with respect to the Boltzmann distribution and orders of magnitude faster than existing sampling methods.

**摘要:** 分子经常被表示为图形,但底层的3D分子几何(原子的位置)最终决定了大多数分子性质。然而,大多数分子不是静态的,在室温下采用广泛的几何或$\textit{conformations}$。结果的几何分布$p(x)$被称为玻尔兹曼分布,许多分子性质都是在这一分布下计算的期望。因此,从玻尔兹曼分布中生成准确的样本对于准确计算这些期望至关重要。传统的样本计算方法是计算成本昂贵,最近的机器学习方法则专注于在这一分布中识别$\textit{modes}$而不是生成真正的$\textit{samples}$。通过对可旋转键扭转角的变量近似,将可旋转键扭转角的变量捕获成一种新的图形神经网络,并以冯·米塞斯分布的混合物的形式证明,冯·米塞斯网能够以一种比现有的采样方法更快速地对玻尔兹曼分布和大小顺序进行物理准确的方式生成任意分子的变量。

**[Paper URL](https://proceedings.mlr.press/v202/swanson23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/swanson23a/swanson23a.pdf)** 

# Optimal randomized multilevel Monte Carlo for repeatedly nested expectations
**题目:** 重复嵌入的期望的最佳随机化多层次蒙特卡罗

**作者:** Yasa Syed, Guanyang Wang

**Abstract:** The estimation of repeatedly nested expectations is a challenging task that arises in many real-world systems. However, existing methods generally suffer from high computational costs when the number of nestings becomes large. Fix any non-negative integer $D$ for the total number of nestings. Standard Monte Carlo methods typically cost at least $\mathcal{O}(\varepsilon^{-(2+D)})$ and sometimes $\mathcal {O}(\varepsilon^{-2(1+D)})$ to obtain an estimator up to $\varepsilon$-error. More advanced methods, such as multilevel Monte Carlo, currently only exist for $D = 1$. In this paper, we propose a novel Monte Carlo estimator called $\mathsf{READ}$, which stands for “Recursive Estimator for Arbitrary Depth.” Our estimator has an optimal computational cost of $\mathcal{O}(\varepsilon^{-2})$ for every fixed $D$ under suitable assumptions, and a nearly optimal computational cost of $\mathcal{O}(\varepsilon^{-2(1 + \delta)})$ for any $0 < \delta < \frac12$ under much more general assumptions. Our estimator is also unbiased, which makes it easy to parallelize. The key ingredients in our construction are an observation of the problem’s recursive structure and the recursive use of the randomized multilevel Monte Carlo method.

**摘要:** 对反复嵌入的期望的估计是许多实世界系统中出现的挑战性任务。然而,现有的方法通常在嵌入数变大时会承受高计算成本。确定任何不负整数$D$的嵌入数。标准的蒙特卡罗方法通常至少花费$\mathcal{O}(\varepsilon^{-(2+D)})$,有时$\mathcal {O}(\varepsilon^{-2(1+D)})$以获取到$\varepsilon$-error的估计数。更先进的方法,如多级蒙特卡罗,目前只存在$D = 1$。我们 的 估计器 也 是 不偏见 的, 这 使 平行化 变得 容易 。 我们 的 构造 中 的 关键 成分 是 观察 问题 的 递归 结构 和 随机 化 多级 蒙特卡罗 方法 的 递归 使用 。

**[Paper URL](https://proceedings.mlr.press/v202/syed23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/syed23a/syed23a.pdf)** 

# Adaptive Coordination in Social Embodied Rearrangement
**题目:** 社会背景重组的适应性协调

**作者:** Andrew Szot, Unnat Jain, Dhruv Batra, Zsolt Kira, Ruta Desai, Akshara Rai

**Abstract:** We present the task of "Social Rearrangement", consisting of cooperative everyday tasks like setting up the dinner table, tidying a house or unpacking groceries in a simulated multi-agent environment. In Social Rearrangement, two robots coordinate to complete a long-horizon task, using onboard sensing and egocentric observations, and no privileged information about the environment. We study zero-shot coordination (ZSC) in this task, where an agent collaborates with a new partner, emulating a scenario where a robot collaborates with a new human partner. Prior ZSC approaches struggle to generalize in our complex and visually rich setting, and on further analysis, we find that they fail to generate diverse coordination behaviors at training time. To counter this, we propose Behavior Diversity Play (BDP), a novel ZSC approach that encourages diversity through a discriminability objective. Our results demonstrate that BDP learns adaptive agents that can tackle visual coordination, and zero-shot generalize to new partners in unseen environments, achieving 35% higher success and 32% higher efficiency compared to baselines.

**摘要:** 我们提出了“社会重整”的任务,包括在模拟多代理环境中建立餐桌、整顿房子或卸货等合作性日常任务。在“社会重整”中,两个机器人协调完成一个长视线任务,使用船上感知和自我中心的观察,没有对环境的特权信息。我们研究了“零射击协调”(ZSC)这个任务,其中一个代理人与新伙伴合作,模拟了一个机器人与新人类伙伴合作场景。我们的结果表明,BDP学习了能够处理视觉协调的适应剂,并将零射击推广到无视环境中的新合作伙伴,从而比基准提高成功率35%和效率32%。

**[Paper URL](https://proceedings.mlr.press/v202/szot23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/szot23a/szot23a.pdf)** 

# MG-GNN: Multigrid Graph Neural Networks for Learning Multilevel Domain Decomposition Methods
**题目:** MG-GNN:学习多层次域分解方法的多网格图神经网络

**作者:** Ali Taghibakhshi, Nicolas Nytko, Tareq Uz Zaman, Scott Maclachlan, Luke Olson, Matthew West

**Abstract:** Domain decomposition methods (DDMs) are popular solvers for discretized systems of partial differential equations (PDEs), with one-level and multilevel variants. These solvers rely on several algorithmic and mathematical parameters, prescribing overlap, subdomain boundary conditions, and other properties of the DDM. While some work has been done on optimizing these parameters, it has mostly focused on the one-level setting or special cases such as structured-grid discretizations with regular subdomain construction. In this paper, we propose multigrid graph neural networks (MG-GNN), a novel GNN architecture for learning optimized parameters in two-level DDMs. We train MG-GNN using a new unsupervised loss function, enabling effective training on small problems that yields robust performance on unstructured grids that are orders of magnitude larger than those in the training set. We show that MG-GNN outperforms popular hierarchical graph network architectures for this optimization and that our proposed loss function is critical to achieving this improved performance.

**摘要:** 域分解方法(DDMs)是部分微分方程(PDEs)的离散系统,具有单级和多级变量。这些解法依赖于多个算法和数学参数,规定重叠、子域边界条件以及DDM的其他特性。虽然一些工作已经在优化这些参数方面进行,但主要集中在单级设置或特殊情况下,例如结构网格离散与常规子域结构。我们证明,MG-GNN在这种优化中优于流行的层次图网络架构,而且我们提出的损失函数对于实现提高性能至关重要。

**[Paper URL](https://proceedings.mlr.press/v202/taghibakhshi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/taghibakhshi23a/taghibakhshi23a.pdf)** 

# Learning Mixtures of Gaussians with Censored Data
**题目:** 加索人与 Censored Data的学习混合物

**作者:** Wai Ming Tai, Bryon Aragam

**Abstract:** We study the problem of learning mixtures of Gaussians with censored data. Statistical learning with censored data is a classical problem, with numerous practical applications, however, finite-sample guarantees for even simple latent variable models such as Gaussian mixtures are missing. Formally, we are given censored data from a mixture of univariate Gaussians $ \sum_{i=1}^k w_i \mathcal{N}(\mu_i,\sigma^2), $ i.e. the sample is observed only if it lies inside a set $S$. The goal is to learn the weights $w_i$ and the means $\mu_i$. We propose an algorithm that takes only $\frac{1}{\varepsilon^{O(k)}}$ samples to estimate the weights $w_i$ and the means $\mu_i$ within $\varepsilon$ error.

**摘要:** 我们研究了带过滤数据的Gaussians混合学习问题。带过滤数据的统计学学习是一个经典问题,它有许多实际应用,然而,对于像Gaussian混合这样的简单的潜在变量模型的有限样本保证都没有。形式上,我们得到一个单变量Gaussians混合的过滤数据 $ \sum_{i=1}^k w_i \mathcal{N}(\mu_i,\sigma^2), $ 即,样本只在$S$集合中存在时观察。

**[Paper URL](https://proceedings.mlr.press/v202/tai23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tai23a/tai23a.pdf)** 

# Approximation and Estimation Ability of Transformers for Sequence-to-Sequence Functions with Infinite Dimensional Input
**题目:** 无穷次元输入的序列到序列函数变换器的近似和估计能力

**作者:** Shokichi Takakura, Taiji Suzuki

**Abstract:** Despite the great success of Transformer networks in various applications such as natural language processing and computer vision, their theoretical aspects are not well understood. In this paper, we study the approximation and estimation ability of Transformers as sequence-to-sequence functions with infinite dimensional inputs. Although inputs and outputs are both infinite dimensional, we show that when the target function has anisotropic smoothness, Transformers can avoid the curse of dimensionality due to their feature extraction ability and parameter sharing property. In addition, we show that even if the smoothness changes depending on each input, Transformers can estimate the importance of features for each input and extract important features dynamically. Then, we proved that Transformers achieve similar convergence rate as in the case of the fixed smoothness. Our theoretical results support the practical success of Transformers for high dimensional data.

**摘要:** 本文研究了无穷次元输入的序列序列函数的近似和估计能力。虽然输入和输出都是无穷次元,但表明当目标函数具有异性滑度时,由于其特征提取能力和参数共享特性,变换器可以避免dimensionality的诅咒。此外,我们证明即使滑度的变化取决于每个输入,变换器可以估计每个输入的特征的重要性,并动态提取重要特征。

**[Paper URL](https://proceedings.mlr.press/v202/takakura23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/takakura23a/takakura23a.pdf)** 

# Learning Neural PDE Solvers with Parameter-Guided Channel Attention
**题目:** 使用参数导向通道注意力学习神经PDE解决方案

**作者:** Makoto Takamoto, Francesco Alesiani, Mathias Niepert

**Abstract:** Scientific Machine Learning (SciML) is concerned with the development of learned emulators of physical systems governed by partial differential equations (PDE). In application domains such as weather forecasting, molecular dynamics, and inverse design, ML-based surrogate models are increasingly used to augment or replace inefficient and often non-differentiable numerical simulation algorithms. While a number of ML-based methods for approximating the solutions of PDEs have been proposed in recent years, they typically do not adapt to the parameters of the PDEs, making it difficult to generalize to PDE parameters not seen during training. We propose a Channel Attention guided by PDE Parameter Embeddings (CAPE) component for neural surrogate models and a simple yet effective curriculum learning strategy. The CAPE module can be combined with any neural PDE solvers allowing them to adapt to unseen PDE parameters. The curriculum learning strategy provides a seamless transition between teacher-forcing and fully auto-regressive training. We compare CAPE in conjunction with the curriculum learning strategy using a PDE benchmark and obtain consistent and significant improvements over the baseline models. The experiments also show several advantages of CAPE, such as its increased ability to generalize to unseen PDE parameters without large increases inference time and parameter count. An implementation of the method and experiments are available at https://anonymous.4open.science/r/CAPE-ML4Sci-145B.

**摘要:** 科学机器学习(SciML)涉及由部分微分方程(PDE)控制的物理系统学习模拟器的开发。在应用领域,如天气预报、分子动力学和逆设计中,基于ML的替代模型越来越多地用于增加或取代不效率且经常不微分的数值模拟算法。虽然近年来提出了一些基于ML的方法来近似PDEs的解决方案,但它们通常不适应PDEs的参数,使得很难将PDE参数推广到训练中未见的参数。我们提出了由PDE参数嵌入(CAPE)组成的神经替代模型和简单而有效的课程学习策略。CAPE模块可以与任何神经PDE解决方案相结合,允许它们适应未见的PDE参数。课程学习策略提供了教师强迫和完全自动回归训练之间的シームレス过渡。我们与课程学习策略结合使用PDE基准比较CAPE,并取得在基准模型上一致和显著的改进。实验还显示CAPE的若干优点,例如它能够在无视PDE参数中推广到无视PDE参数,而不增加推理时间和参数数。方法和实验的实现可于 https://anonymous.4open.science/r/CAPE-ML4Sci-145B。

**[Paper URL](https://proceedings.mlr.press/v202/takamoto23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/takamoto23a/takamoto23a.pdf)** 

# Contextual Conservative Interleaving Bandits
**题目:** 背景保守交织 bandits

**作者:** Kei Takemura

**Abstract:** The performance of a bandit algorithm is usually measured by the cumulative rewards of the actions chosen by the algorithm. However, in many real-world applications, the rewards in each round should be good enough for reasons such as safety and fairness. In this paper, we investigate the contextual conservative interleaving bandit problem, which has a performance constraint that requires the chosen actions to be not much worse than given baseline actions in each round. This work is the first to simultaneously consider the following practical situations: (1) multiple actions are chosen in a round, (2) the feature vectors associated with given actions depend on the round, and (3) the performance constraints in each round that depend only on the actions chosen in that round. We propose a meta-algorithm, Greedy on Confidence Widths (GCW), that satisfies the performance constraints with high probability. GCW uses a standard bandit algorithm and achieves minimax optimal regret up to logarithmic factors if the algorithm used is also minimax optimal. We improve the existing analyses for the C${}^2$UCB algorithm and the Thompson sampling to combine with GCW. We show that these algorithms achieve near-optimal regret when the feasible sets of given actions are the bases of a matroid. Our numerical experiments on a real-world dataset demonstrate that GCW with the standard bandit algorithms efficiently improves performance while satisfying the performance constraints.

**摘要:** 带子算法的性能通常由算法选择的行动的累积奖励来衡量。然而,在许多实际应用中,每个循环中的奖励都应该足够好,比如安全和公平。本论文中,我们研究了具有性能约束的上下文保守的带子问题,该问题要求选择的行动不会比每个循环中的基线行动要糟糕得多。我们改进了与GCW结合的C${}^2$UCB算法和汤普森样本的现有分析。我们表明,当给定行动的可行的集合为马特罗伊的基础时,这些算法达到 near-optimal regret。我们对实物数据集的数值实验表明,GCW使用标准带状算法能有效地提高性能,同时满足性能限制。

**[Paper URL](https://proceedings.mlr.press/v202/takemura23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/takemura23a/takemura23a.pdf)** 

# Randomized Gaussian Process Upper Confidence Bound with Tighter Bayesian Regret Bounds
**题目:** 随机高斯过程上层信任区与更紧的贝叶斯式遗憾区

**作者:** Shion Takeno, Yu Inatsu, Masayuki Karasuyama

**Abstract:** Gaussian process upper confidence bound (GP-UCB) is a theoretically promising approach for black-box optimization; however, the confidence parameter $\beta$ is considerably large in the theorem and chosen heuristically in practice. Then, randomized GP-UCB (RGP-UCB) uses a randomized confidence parameter, which follows the Gamma distribution, to mitigate the impact of manually specifying $\beta$. This study first generalizes the regret analysis of RGP-UCB to a wider class of distributions, including the Gamma distribution. Furthermore, we propose improved RGP-UCB (IRGP-UCB) based on a two-parameter exponential distribution, which achieves tighter Bayesian regret bounds. IRGP-UCB does not require an increase in the confidence parameter in terms of the number of iterations, which avoids over-exploration in the later iterations. Finally, we demonstrate the effectiveness of IRGP-UCB through extensive experiments.

**摘要:** 高斯过程上信度边界(GP-UCB)是黑箱优化的理论上很有希望的方法;然而,信度参数$\beta$在定理中相当大,并且在实践中被霍里斯式选择。然后,随机化GP-UCB(RGP-UCB)使用随机化信度参数,以遵循伽玛分布,减轻手动指定$\beta$的影响。本研究首先将RGP-UCB的遗憾分析推广到更广泛的分布类别,包括伽玛分布。此外,我们提出了改进的RGP-UCB(IRGP-UCB)基于两个参数指数分布,从而达到更紧的贝叶斯式遗憾边界。IRGP-UCB不需要在迭代数目方面增加信度参数,从而避免在后续迭代中过度探索。最后,我们通过广泛实验证明了IRGP-UCB的

**[Paper URL](https://proceedings.mlr.press/v202/takeno23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/takeno23a/takeno23a.pdf)** 

# Towards Practical Preferential Bayesian Optimization with Skew Gaussian Processes
**题目:** 基于斯基高斯过程的 Bayesian 优先优化

**作者:** Shion Takeno, Masahiro Nomura, Masayuki Karasuyama

**Abstract:** We study preferential Bayesian optimization (BO) where reliable feedback is limited to pairwise comparison called duels. An important challenge in preferential BO, which uses the preferential Gaussian process (GP) model to represent flexible preference structure, is that the posterior distribution is a computationally intractable skew GP. The most widely used approach for preferential BO is Gaussian approximation, which ignores the skewness of the true posterior. Alternatively, Markov chain Monte Carlo (MCMC) based preferential BO is also proposed. In this work, we first verify the accuracy of Gaussian approximation, from which we reveal the critical problem that the predictive probability of duels can be inaccurate. This observation motivates us to improve the MCMC-based estimation for skew GP, for which we show the practical efficiency of Gibbs sampling and derive the low variance MC estimator. However, the computational time of MCMC can still be a bottleneck in practice. Towards building a more practical preferential BO, we develop a new method that achieves both high computational efficiency and low sample complexity, and then demonstrate its effectiveness through extensive numerical experiments.

**摘要:** 我们研究了偏优贝叶斯优化(BO),其中可靠反馈仅限于对偶比较,称为 duels。偏优BO中的一个重要挑战是,后方分布是一个不可计算的 skew GP。最广泛的偏优BO方法是高斯近似,它忽略了真后方的 skewness。另外,马可夫链蒙特卡罗(MCMC)基于偏优BO也被提议。在这个工作中,我们首先验证了高斯近似的准确性,从中揭示了预测 duels的概率可能是不准确的关键问题。为了建立更实用的优越性BO,我们开发了一种具有高计算效率和低样品复杂性的新方法,并通过大量的数值实验证明了该方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/takeno23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/takeno23b/takeno23b.pdf)** 

# Robust Explanation for Free or At the Cost of Faithfulness
**题目:** 无偿或以诚实为代价的强有力解释

**作者:** Zeren Tan, Yang Tian

**Abstract:** Devoted to interpreting the explicit behaviors of machine learning models, explanation methods can identify implicit characteristics of models to improve trustworthiness. However, explanation methods are shown as vulnerable to adversarial perturbations, implying security concerns in high-stakes domains. In this paper, we investigate when robust explanations are necessary and what they cost. We prove that the robustness of explanations is determined by the robustness of the model to be explained. Therefore, we can have robust explanations for free for a robust model. To have robust explanations for a non-robust model, composing the original model with a kernel is proved as an effective way that returns strictly more robust explanations. Nevertheless, we argue that this also incurs a robustness-faithfulness trade-off, i.e., contrary to common expectations, an explanation method may also become less faithful when it becomes more robust. This argument holds for any model. We are the first to introduce this trade-off and theoretically prove its existence for SmoothGrad. Theoretical findings are verified by empirical evidence on six state-of-the-art explanation methods and four backbones.

**摘要:** 为了解释机器学习模型的显式行为,解释方法可以识别模型的显式特征,以提高可靠性。然而,解释方法被显示为易受敌对扰动,意味着高风险领域的安全问题。本文研究了 robust解释的必要性和成本。我们证明了解释的鲁棒性是由模型的鲁棒性决定的。因此,我们可以为鲁棒模型提供免费的鲁棒解释。我们是第一个引入这种折衷和理论证明它的存在 SmoothGrad. 理论发现通过对六个最先进的解释方法和四个骨干的实证验证。

**[Paper URL](https://proceedings.mlr.press/v202/tan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tan23a/tan23a.pdf)** 

# Provably Invariant Learning without Domain Information
**题目:** 无域名信息的可信不变学习

**作者:** Xiaoyu Tan, Lin Yong, Shengyu Zhu, Chao Qu, Xihe Qiu, Xu Yinghui, Peng Cui, Yuan Qi

**Abstract:** Typical machine learning applications always assume the data follows independent and identically distributed (IID) assumptions. In contrast, this assumption is frequently violated in real-world circumstances, leading to the Out-of-Distribution (OOD) generalization problem and a major drop in model robustness. To mitigate this issue, the invariant learning technique is leveraged to distinguish between spurious features and invariant features among all input features and to train the model purely on the basis of the invariant features. Numerous invariant learning strategies imply that the training data should contain domain information. Such information includes the environment index or auxiliary information acquired from prior knowledge. However, acquiring these information is typically impossible in practice. In this study, we present TIVA for environment-independent invariance learning, which requires no environment-specific information in training data. We discover and prove that, given certain mild data conditions, it is possible to train an environment partitioning policy based on attributes that are independent of the targets and then conduct invariant risk minimization. We examine our method in comparison to other baseline methods, which demonstrate superior performance and excellent robustness under OOD, using multiple benchmarks.

**摘要:** 典型的机器学习应用总是假设数据遵循独立和均匀分布的(IID)假设。相反,这种假设在现实环境中经常被违反,导致 Out-of-Distribution(OOD)一般化问题和模型鲁棒性大幅下降。为了缓解这个问题,不变学习技术被利用来区分 spurious特征和不变特征在所有输入特征之间,并以不变特征为基础训练模型。我们发现和证明,在某些温和的数据条件下,可以根据独立于目标属性的环境分区政策进行培训,然后进行不变风险最小化。我们利用多个基准方法比较了我们的方法,这些方法在OOD中表现出优越的性能和卓越的鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/tan23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tan23b/tan23b.pdf)** 

# Auto-Differentiation of Relational Computations for Very Large Scale Machine Learning
**题目:** 超大规模机器学习关系计算的自动区分

**作者:** Yuxin Tang, Zhimin Ding, Dimitrije Jankov, Binhang Yuan, Daniel Bourgeois, Chris Jermaine

**Abstract:** The relational data model was designed to facilitate large-scale data management and analytics. We consider the problem of how to differentiate computations expressed relationally. We show experimentally that a relational engine running an auto-differentiated relational algorithm can easily scale to very large datasets, and is competitive with state-of-the-art, special-purpose systems for large-scale distributed machine learning.

**摘要:** 该关系数据模型是为方便大规模数据管理和分析而设计的,我们考虑了如何以关系方式表达计算的区别问题。我们实验表明,运行自差关系算法的关系引擎可以轻易扩展到非常大的数据集,并且与大型分布式机器学习的最先进的特殊用途系统具有竞争性。

**[Paper URL](https://proceedings.mlr.press/v202/tang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tang23a/tang23a.pdf)** 

# Regret-Minimizing Double Oracle for Extensive-Form Games
**题目:** 缩小遗憾的双 Oracle对广泛形式游戏

**作者:** Xiaohang Tang, Le Cong Dinh, Stephen Marcus Mcaleer, Yaodong Yang

**Abstract:** By incorporating regret minimization, double oracle methods have demonstrated rapid convergence to Nash Equilibrium (NE) in normal-form games and extensive-form games, through algorithms such as online double oracle (ODO) and extensive-form double oracle (XDO), respectively. In this study, we further examine the theoretical convergence rate and sample complexity of such regret minimization-based double oracle methods, utilizing a unified framework called Regret-Minimizing Double Oracle. Based on this framework, we extend ODO to extensive-form games and determine its sample complexity. Moreover, we demonstrate that the sample complexity of XDO can be exponential in the number of information sets $|S|$, owing to the exponentially decaying stopping threshold of restricted games. To solve this problem, we propose the Periodic Double Oracle (PDO) method, which has the lowest sample complexity among regret minimization-based double oracle methods, being only polynomial in $|S|$. Empirical evaluations on multiple poker and board games show that PDO achieves significantly faster convergence than previous double oracle algorithms and reaches a competitive level with state-of-the-art regret minimization methods.

**摘要:** 通过采用遗憾最小化的方法,通过在线双语法(ODO)和广义双语法(XDO)等算法,在普通游戏和广义游戏中证明了快速对纳什均衡(NE)的收敛性。本文进一步研究了基于遗憾最小化的双语法的理论收敛率和样本复杂性,利用统一框架 Regret-Minimizing Double Oracle。基于这一框架,我们将ODO扩展到广义游戏,确定其样本复杂性。对多个扑克和板式游戏的实证评价表明,PDO比以前的双法术算法取得显著更快的收敛,并达到最先进的遗憾最小化方法的竞争水平。

**[Paper URL](https://proceedings.mlr.press/v202/tang23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tang23b/tang23b.pdf)** 

# From Perception to Programs: Regularize, Overparameterize, and Amortize
**题目:** 从感知到程序:调整、过分参数化和 Amortize

**作者:** Hao Tang, Kevin Ellis

**Abstract:** We develop techniques for synthesizing neurosymbolic programs. Such programs mix discrete symbolic processing with continuous neural computation. We relax this mixed discrete/continuous problem and jointly learn all modules with gradient descent, and also incorporate amortized inference, overparameterization, and a differentiable strategy for penalizing lengthy programs. Collectedly this toolbox improves the stability of gradient-guided program search, and suggests ways of learning both how to parse continuous input into discrete abstractions, and how to process those abstractions via symbolic code.

**摘要:** 我们开发了合成神经符号程序的技术,这些程序将离散符号处理与连续神经计算相结合,我们放松了这种混合离散/连续问题,并共同学习所有梯度下降的模块,并包括 amortized inference, overparameterization,以及惩罚长程程序的可微分策略。

**[Paper URL](https://proceedings.mlr.press/v202/tang23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tang23c/tang23c.pdf)** 

# Understanding Self-Predictive Learning for Reinforcement Learning
**题目:** 理解自我预测学习以增强学习

**作者:** Yunhao Tang, Zhaohan Daniel Guo, Pierre Harvey Richemond, Bernardo Avila Pires, Yash Chandak, Remi Munos, Mark Rowland, Mohammad Gheshlaghi Azar, Charline Le Lan, Clare Lyle, András György, Shantanu Thakoor, Will Dabney, Bilal Piot, Daniele Calandriello, Michal Valko

**Abstract:** We study the learning dynamics of self-predictive learning for reinforcement learning, a family of algorithms that learn representations by minimizing the prediction error of their own future latent representations. Despite its recent empirical success, such algorithms have an apparent defect: trivial representations (such as constants) minimize the prediction error, yet it is obviously undesirable to converge to such solutions. Our central insight is that careful designs of the optimization dynamics are critical to learning meaningful representations. We identify that a faster paced optimization of the predictor and semi-gradient updates on the representation, are crucial to preventing the representation collapse. Then in an idealized setup, we show self-predictive learning dynamics carries out spectral decomposition on the state transition matrix, effectively capturing information of the transition dynamics. Building on the theoretical insights, we propose bidirectional self-predictive learning, a novel self-predictive algorithm that learns two representations simultaneously. We examine the robustness of our theoretical insights with a number of small-scale experiments and showcase the promise of the novel representation learning algorithm with large-scale experiments.

**摘要:** 我们研究了增强学习自预测学习的学习动力学,一种通过最小化自己未来潜伏的预测误差学习表示的算法,尽管其最近的实证成功,但这种算法有明显的缺陷:微观的表示(如常数)最小化预测误差,但显然不希望达到这样的解决方案。我们的核心洞察是,优化动力学的仔细设计对于学习有意义的表示至关重要。基于理论洞察,我们提出了一种双向自我预测学习算法,即一种新颖的双向自我预测学习算法,它能同时学习两种表示。我们通过数次小规模实验研究了理论洞察的鲁棒性,并通过大规模实验展示了新颖的表示学习算法的前景。

**[Paper URL](https://proceedings.mlr.press/v202/tang23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tang23d/tang23d.pdf)** 

# DoMo-AC: Doubly Multi-step Off-policy Actor-Critic Algorithm
**题目:** DoMo-AC:双重多步非政策角色-临界算法

**作者:** Yunhao Tang, Tadashi Kozuno, Mark Rowland, Anna Harutyunyan, Remi Munos, Bernardo Avila Pires, Michal Valko

**Abstract:** Multi-step learning applies lookahead over multiple time steps and has proved valuable in policy evaluation settings. However, in the optimal control case, the impact of multi-step learning has been relatively limited despite a number of prior efforts. Fundamentally, this might be because multi-step policy improvements require operations that cannot be approximated by stochastic samples, hence hindering the widespread adoption of such methods in practice. To address such limitations, we introduce doubly multi-step off-policy VI (DoMo-VI), a novel oracle algorithm that combines multi-step policy improvements and policy evaluations. DoMo-VI enjoys guaranteed convergence speed-up to the optimal policy and is applicable in general off-policy learning settings. We then propose doubly multi-step off-policy actor-critic (DoMo-AC), a practical instantiation of the DoMo-VI algorithm. DoMo-AC introduces a bias-variance trade-off that ensures improved policy gradient estimates. When combined with the IMPALA architecture, DoMo-AC has showed improvements over the baseline algorithm on Atari-57 game benchmarks.

**摘要:** 多步学习应用于多个时间步骤,并且在政策评价设置中具有一定的价值。然而,在最佳控制情况下,多步学习的影响相对有限,尽管有若干优先努力。根本上,这可能是因为多步政策改进需要操作不能通过随机样本近似,因此妨碍广泛采用这种方法在实践中。为了解决这些限制,我们引入了双重多步离政策VI(DoMo-VI),一种结合多步政策改进和政策评价的新算法。与IMPALA架构结合,DoMo-AC在Atari-57游戏基准上显示了比基准算法的改进。

**[Paper URL](https://proceedings.mlr.press/v202/tang23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tang23e/tang23e.pdf)** 

# Towards Understanding Generalization of Graph Neural Networks
**题目:** 图神经网络的一般化理解

**作者:** Huayi Tang, Yong Liu

**Abstract:** Graph neural networks (GNNs) are widely used in machine learning for graph-structured data. Even though GNNs have achieved remarkable success in real-world applications, understanding their working mechanism in theory is still on primary stage. In this paper, we move towards this goal from the perspective of generalization. Specifically, with consideration of stochastic optimization, we establish high probability bounds of generalization gap and gradients for transductive learning algorithms. After that, we provide high probability bounds of generalization gap for popular GNNs and analyze the factors affecting their generalization capability. These theoretical results reveal how the network architecture impacts the generalization gap. Experiments on benchmark datasets validate the theoretical findings. Our results provide new insights into understanding generalization of GNNs.

**摘要:** 图神经网络(GNN)广泛应用于图结构数据的机器学习中,虽然GNN在现实应用中取得了显著的成功,但理论上理解其工作机制仍处于初级阶段。本论文从广义化的角度出发,针对广义化目标,结合随机优化的考虑,建立了广义化差距的高概率边界和变形学习算法的梯度,然后为大众GNN提供广义化差距的高概率边界并分析影响其广义化能力的因素。这些理论结果揭示了网络架构如何影响广义化差距的因素。

**[Paper URL](https://proceedings.mlr.press/v202/tang23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tang23f/tang23f.pdf)** 

# Towards a better understanding of representation dynamics under TD-learning
**题目:** 在TD学习下更好地理解表示动力学

**作者:** Yunhao Tang, Remi Munos

**Abstract:** TD-learning is a foundation reinforcement learning (RL) algorithm for value prediction. Critical to the accuracy of value predictions is the quality of state representations. In this work, we consider the question: how does end-to-end TD-learning impact the representation over time? Complementary to prior work, we provide a set of analysis that sheds further light on the representation dynamics under TD-learning. We first show that when the environments are reversible, end-to-end TD-learning strictly decreases the value approximation error over time. Under further assumptions on the environments, we can connect the representation dynamics with spectral decomposition over the transition matrix. This latter finding establishes fitting multiple value functions from randomly generated rewards as a useful auxiliary task for representation learning, as we empirically validate on both tabular and Atari game suites.

**摘要:** TD-learning是价值预测的基础增强学习(RL)算法。对价值预测的准确性至关重要的是状态表示的质量。在这个工作中,我们考虑以下问题:end-to-end TD-learning如何影响时间表的表示? 为了补充先前的工作,我们提供了一个分析集,在TD-learning下的表示动力学上进一步显示光线。我们首先表明,当环境可逆时,end-to-end TD-learning严格降低了时间表值近似误差。在环境下进一步假设下,我们可以将表示动力学连接到过渡矩阵上的光谱分解。

**[Paper URL](https://proceedings.mlr.press/v202/tang23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tang23g/tang23g.pdf)** 

# VA-learning as a more efficient alternative to Q-learning
**题目:** VA-learning作为Q-learning的更有效的替代

**作者:** Yunhao Tang, Remi Munos, Mark Rowland, Michal Valko

**Abstract:** In reinforcement learning, the advantage function is critical for policy improvement, but is often extracted from a learned Q-function. A natural question is: Why not learn the advantage function directly? In this work, we introduce VA-learning, which directly learns advantage function and value function using bootstrapping, without explicit reference to Q-functions. VA-learning learns off-policy and enjoys similar theoretical guarantees as Q-learning. Thanks to the direct learning of advantage function and value function, VA-learning improves the sample efficiency over Q-learning both in tabular implementations and deep RL agents on Atari-57 games. We also identify a close connection between VA-learning and the dueling architecture, which partially explains why a simple architectural change to DQN agents tends to improve performance.

**摘要:** 在强化学习中,优势函数对于政策改进至关重要,但经常从学习的Q-函数中提取出来。一个自然的问题是:为什么不直接学习优势函数呢?在这个工作中,我们引入了VA-learning,它直接学习了 bootstrapping的优点函数和价值函数,没有明确提到Q-函数。VA-learning学习在政策外并享受类似的理论保证,如Q-learning。

**[Paper URL](https://proceedings.mlr.press/v202/tang23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tang23h/tang23h.pdf)** 

# Defects of Convolutional Decoder Networks in Frequency Representation
**题目:** 频率表示中的卷积解码器网络缺陷

**作者:** Ling Tang, Wen Shen, Zhanpeng Zhou, Yuefeng Chen, Quanshi Zhang

**Abstract:** In this paper, we prove the representation defects of a cascaded convolutional decoder network, considering the capacity of representing different frequency components of an input sample. We conduct the discrete Fourier transform on each channel of the feature map in an intermediate layer of the decoder network. Then, we extend the 2D circular convolution theorem to represent the forward and backward propagations through convolutional layers in the frequency domain. Based on this, we prove three defects in representing feature spectrums. First, we prove that the convolution operation, the zero-padding operation, and a set of other settings all make a convolutional decoder network more likely to weaken high-frequency components. Second, we prove that the upsampling operation generates a feature spectrum, in which strong signals repetitively appear at certain frequencies. Third, we prove that if the frequency components in the input sample and frequency components in the target output for regression have a small shift, then the decoder usually cannot be effectively learned.

**摘要:** 本文通过考虑输入样本中不同频率组件的代表能力,证明了 cascaded 卷积式解码器网络的代表缺陷,在解码器网络的中间层中,在每个特征映射通道上进行离散傅立叶变换,然后扩展了2D圆形卷积定理,以代表频率域中的卷积层通过卷积向后传播。在此基础上,我们证明了三种特征谱的代表缺陷,首先证明了卷积操作、零padding操作和其他设置使得卷积式解码器网络更容易削弱高频组件。第三,我们证明,如果输入样品的频率组件和回归目标输出的频率组件有小变化,则通常不能有效地学习解码器。

**[Paper URL](https://proceedings.mlr.press/v202/tang23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tang23i/tang23i.pdf)** 

# Difference-in-Differences Meets Tree-based Methods: Heterogeneous Treatment Effects Estimation with Unmeasured Confounding
**题目:** 差异在差异中与基于树的方法相符:不测混淆的异性治疗效果估计

**作者:** Caizhi Tang, Huiyuan Wang, Xinyu Li, Qing Cui, Longfei Li, Jun Zhou

**Abstract:** This study considers the estimation of conditional causal effects in the presence of unmeasured confounding for a balanced panel with treatment imposed at the last time point. To address this, we combine Difference-in-differences (DiD) and tree-based methods and propose a new identification assumption that allows for the violation of the (conditional) parallel trends assumption adopted by most existing DiD methods. Under this new assumption, we prove partial identifiability of the conditional average treatment effect on the treated group (CATT). Our proposed method estimates CATT through a tree-based causal approach, guided by a novel splitting rule that avoids model misspecification and unnecessary auxiliary parameter estimation. The splitting rule measures both the error of fitting observed data and the violation of conditional parallel trends simultaneously. We also develop an ensemble of multiple trees via gradient boosting to further enhance performance. Experimental results on both synthetic and real-world datasets validate the effectiveness of our proposed method.

**摘要:** 本文研究了在未测定的混淆情况下对平衡板与在最后时间点施加治疗的条件性因果效应的估计。为了解决这个问题,我们结合DiD和基于树的方法,提出了一种新的识别假设,允许通过大多数现有的DiD方法所采用的(条件性)平行趋势假设的侵犯。在此新的假设下,我们证明了对处理组的条件性平均治疗效应的局部识别性。我们提出的方法通过基于树的因果方法估计CATT,由一种避免模型误区和不必要的辅助参数估计的新分法指导。分法同时测量了观察数据的匹配误差和条件性平行趋势的侵犯。对合成和实物数据集的实验结果验证了我们提出的方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/tang23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tang23j/tang23j.pdf)** 

# End-to-end Training of Deep Boltzmann Machines by Unbiased Contrastive Divergence with Local Mode Initialization
**题目:** 基于局部模式初始化的无偏的反向差异对深波尔茨曼机器的最终培训

**作者:** Shohei Taniguchi, Masahiro Suzuki, Yusuke Iwasawa, Yutaka Matsuo

**Abstract:** We address the problem of biased gradient estimation in deep Boltzmann machines (DBMs). The existing method to obtain an unbiased estimator uses a maximal coupling based on a Gibbs sampler, but when the state is high-dimensional, it takes a long time to converge. In this study, we propose to use a coupling based on the Metropolis-Hastings (MH) and to initialize the state around a local mode of the target distribution. Because of the propensity of MH to reject proposals, the coupling tends to converge in only one step with a high probability, leading to high efficiency. We find that our method allows DBMs to be trained in an end-to-end fashion without greedy pretraining. We also propose some practical techniques to further improve the performance of DBMs. We empirically demonstrate that our training algorithm enables DBMs to show comparable generative performance to other deep generative models, achieving the FID score of 10.33 for MNIST.

**摘要:** 本文讨论了博尔茨曼深层机器的偏向梯度估计问题。现有方法采用吉布斯样品仪的最大耦合,但当状态是高维时,需要很长的时间才能收敛。本研究中,我们提议使用基于Metropolis-Hastings(MH)的耦合,并以目标分布的局部模式启动状态。由于MH倾向于拒绝提议,耦合倾向于以高概率的单一步骤收敛,导致高效率。

**[Paper URL](https://proceedings.mlr.press/v202/taniguchi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/taniguchi23a/taniguchi23a.pdf)** 

# POUF: Prompt-Oriented Unsupervised Fine-tuning for Large Pre-trained Models
**题目:** POUF:大型预训练模型的快速导向无监督微调

**作者:** Korawat Tanwisuth, Shujian Zhang, Huangjie Zheng, Pengcheng He, Mingyuan Zhou

**Abstract:** Through prompting, large-scale pre-trained models have become more expressive and powerful, gaining significant attention in recent years. Though these big models have zero-shot capabilities, in general, labeled data are still required to adapt them to downstream tasks. To overcome this critical limitation, we propose an unsupervised fine-tuning framework to directly fine-tune the model or prompt on the unlabeled target data. We demonstrate how to apply our method to both language-augmented vision and masked-language models, by aligning the discrete distributions extracted from the prompts and target data. To verify our approach’s applicability, we conduct extensive experiments on image classification, sentiment analysis, and natural language inference tasks. Across 13 image-related tasks and 15 language-related ones, the proposed approach achieves consistent improvements over the baselines. PyTorch code is available at https://github.com/korawat-tanwisuth/POUF.

**摘要:** 通过提示,大规模预训练模型变得更加表现力更强,在近几年得到了大量关注。虽然这些大型模型具有零射击能力,但一般来说,标记数据仍需要对下游任务进行调整。为了克服这一关键限制,我们提出了一个不受监督的微调框架,以直接微调模型或在未标记目标数据上提示。我们展示了如何应用我们的方法,通过从提示和目标数据中提取的离散分布来实现语言增强视觉和掩盖语言模型。

**[Paper URL](https://proceedings.mlr.press/v202/tanwisuth23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tanwisuth23a/tanwisuth23a.pdf)** 

# Dual Focal Loss for Calibration
**题目:** 校正双焦失

**作者:** Linwei Tao, Minjing Dong, Chang Xu

**Abstract:** The use of deep neural networks in real-world applications require well-calibrated networks with confidence scores that accurately reflect the actual probability. However, it has been found that these networks often provide over-confident predictions, which leads to poor calibration. Recent efforts have sought to address this issue by focal loss to reduce over-confidence, but this approach can also lead to under-confident predictions. While different variants of focal loss have been explored, it is difficult to find a balance between over-confidence and under-confidence. In our work, we propose a new loss function by focusing on dual logits. Our method not only considers the ground truth logit, but also take into account the highest logit ranked after the ground truth logit. By maximizing the gap between these two logits, our proposed dual focal loss can achieve a better balance between over-confidence and under-confidence. We provide theoretical evidence to support our approach and demonstrate its effectiveness through evaluations on multiple models and datasets, where it achieves state-of-the-art performance. Code is available at https://github.com/Linwei94/DualFocalLoss

**摘要:** 在实际应用中,深度神经网络的使用需要具有准确反映实际概率的可靠分数的精确校准网络,然而,这些网络经常提供过自信的预测,导致过自信的校准不良。最近的努力试图通过焦点损失来解决这一问题,减少过自信,但这种方法也可以导致过自信的预测。虽然研究了不同的焦点损失变量,但很难找到过自信和过自信之间的平衡。我们提供理论证据以支持我们的方法,并通过对多个模型和数据集的评价来证明其有效性,从而实现最先进的性能。代码可于 https://github.com/Linwei94/DualFocalLoss

**[Paper URL](https://proceedings.mlr.press/v202/tao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tao23a/tao23a.pdf)** 

# Abstract-to-Executable Trajectory Translation for One-Shot Task Generalization
**题目:** 单击任务一般化的抽象到可执行的推理翻译

**作者:** Stone Tao, Xiaochen Li, Tongzhou Mu, Zhiao Huang, Yuzhe Qin, Hao Su

**Abstract:** Training long-horizon robotic policies in complex physical environments is essential for many applications, such as robotic manipulation. However, learning a policy that can generalize to unseen tasks is challenging. In this work, we propose to achieve one-shot task generalization by decoupling plan generation and plan execution. Specifically, our method solves complex long-horizon tasks in three steps: build a paired abstract environment by simplifying geometry and physics, generate abstract trajectories, and solve the original task by an abstract-to-executable trajectory translator. In the abstract environment, complex dynamics such as physical manipulation are removed, making abstract trajectories easier to generate. However, this introduces a large domain gap between abstract trajectories and the actual executed trajectories as abstract trajectories lack low-level details and are not aligned frame-to-frame with the executed trajectory. In a manner reminiscent of language translation, our approach leverages a seq-to-seq model to overcome the large domain gap between the abstract and executable trajectories, enabling the low-level policy to follow the abstract trajectory. Experimental results on various unseen long-horizon tasks with different robot embodiments demonstrate the practicability of our methods to achieve one-shot task generalization.

**摘要:** 在复杂物理环境中,训练长边机器人政策对于许多应用,如机器人操作等,是至关重要的。然而,学习能够将政策推广到无形任务的策略是挑战性的。在这项工作中,我们建议通过分离计划生成和计划执行实现单击任务的一般化。具体地说,我们的方法在三个步骤中解决复杂长边任务:通过简化几何和物理学来构建对偶的抽象环境,生成抽象轨迹,并由抽象到可执行的轨迹翻译器解决原始任务。在抽象环境中,像物理操作这样的复杂动力学被删除,使得抽象轨迹更容易生成。我们的方法以一种类似语言翻译的方式利用分数到分数模型来克服抽象和可执行路径之间的巨大领域差距,使低层次政策能够遵循抽象路径。

**[Paper URL](https://proceedings.mlr.press/v202/tao23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tao23b/tao23b.pdf)** 

# Data Feedback Loops: Model-driven Amplification of Dataset Biases
**题目:** 数据反馈循环:基于模型的数据集偏差放大

**作者:** Rohan Taori, Tatsunori Hashimoto

**Abstract:** Datasets scraped from the internet have been critical to large-scale machine learning. Yet, its success puts the utility of future internet-derived datasets at potential risk, as model outputs begin to replace human annotations as a source of supervision. In this work, we formalize a system where interactions with one model are recorded as history and scraped as training data in the future. We then analyze its stability over time by tracking changes to a test-time bias statistic (e.g. gender bias of model predictions). We find that the degree of bias amplification is closely linked to whether the model’s outputs behave like samples from the training distribution, a behavior which we characterize and define as uniform faithfulness. Experiments in three conditional prediction scenarios – image classification, visual role-labeling, and language generation – demonstrate that models that exhibit a sampling-like behavior are more faithful and thus more stable. Based on this insight, we propose an intervention to help mitigate and stabilize unstable feedback systems.

**摘要:** 从互联网 scraped的数据集对大规模机器学习具有关键意义。然而,其成功将未来因特网源数据集的实用性置于潜在风险,因为模型输出开始取代人类注释作为监督的源头。在这个工作中,我们正式化了一个系统,其中与一个模型的交互被记录为历史,并作为未来培训数据 scraped。然后,我们通过跟踪测试时间偏见统计(例如模型预测的性别偏见)的变化来分析其稳定性。基于这一洞察,我们提出了一种帮助缓解和稳定不稳定的反馈系统的方法。

**[Paper URL](https://proceedings.mlr.press/v202/taori23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/taori23a/taori23a.pdf)** 

# Deep Regression Unlearning
**题目:** 深度回归非学习

**作者:** Ayush Kumar Tarun, Vikram Singh Chundawat, Murari Mandal, Mohan Kankanhalli

**Abstract:** With the introduction of data protection and privacy regulations, it has become crucial to remove the lineage of data on demand from a machine learning (ML) model. In the last few years, there have been notable developments in machine unlearning to remove the information of certain training data efficiently and effectively from ML models. In this work, we explore unlearning for the regression problem, particularly in deep learning models. Unlearning in classification and simple linear regression has been considerably investigated. However, unlearning in deep regression models largely remains an untouched problem till now. In this work, we introduce deep regression unlearning methods that generalize well and are robust to privacy attacks. We propose the Blindspot unlearning method which uses a novel weight optimization process. A randomly initialized model, partially exposed to the retain samples and a copy of the original model are used together to selectively imprint knowledge about the data that we wish to keep and scrub off the information of the data we wish to forget. We also propose a Gaussian fine tuning method for regression unlearning. The existing unlearning metrics for classification are not directly applicable to regression unlearning. Therefore, we adapt these metrics for the regression setting. We conduct regression unlearning experiments for computer vision, natural language processing and forecasting applications. Our methods show excellent performance for all these datasets across all the metrics. Source code: https://github.com/ayu987/deep-regression-unlearning

**摘要:** 随着数据保护和隐私监管的引入,从机器学习(ML)模型中删除数据的排列已成为关键问题。在过去几年中,机器学习中取得了显著的发展,以有效地从ML模型中移除某些训练数据的信息。在这个工作中,我们探索了回归问题,特别是在深层学习模型中。在分类和简单的线性回归中进行的非学习已经得到大量研究。然而,在深层回归模型中进行的非学习在很大程度上仍然是一个未触及的问题。一个随机初始化模型,部分暴露于保留样品和原型模型的副本一起用于选择性印制关于我们想要保持和擦掉我们想要忘记的数据的信息的知识。我们还建议一种高斯精确调制方法来进行回归非学习。现有的分类非学习度量并不直接适用于回归非学习。因此,我们为回归设置调整这些度量。我们为计算机视觉、自然语言处理和预测应用进行回归非学习实验。我们的方法显示了所有这些数据集在所有度量中的表现。

**[Paper URL](https://proceedings.mlr.press/v202/tarun23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tarun23a/tarun23a.pdf)** 

# How to Trust Your Diffusion Model: A Convex Optimization Approach to Conformal Risk Control
**题目:** 如何信任扩散模型:对符合风险控制的凸优化方法

**作者:** Jacopo Teneggi, Matthew Tivnan, Web Stayman, Jeremias Sulam

**Abstract:** Score-based generative modeling, informally referred to as diffusion models, continue to grow in popularity across several important domains and tasks. While they provide high-quality and diverse samples from empirical distributions, important questions remain on the reliability and trustworthiness of these sampling procedures for their responsible use in critical scenarios. Conformal prediction is a modern tool to construct finite-sample, distribution-free uncertainty guarantees for any black-box predictor. In this work, we focus on image-to-image regression tasks and we present a generalization of the Risk-Controlling Prediction Sets (RCPS) procedure, that we term $K$-RCPS, which allows to $(i)$ provide entrywise calibrated intervals for future samples of any diffusion model, and $(ii)$ control a certain notion of risk with respect to a ground truth image with minimal mean interval length. Differently from existing conformal risk control procedures, ours relies on a novel convex optimization approach that allows for multidimensional risk control while provably minimizing the mean interval length. We illustrate our approach on two real-world image denoising problems: on natural images of faces as well as on computed tomography (CT) scans of the abdomen, demonstrating state of the art performance.

**摘要:** 基于分数的生成模型(英语:Score-based generative modeling, informally referred to as diffusion models)在多个重要领域和任务中继续在普及。它们提供来自经验分布的高质量和多样的样品,但对于这些样品程序的可靠性和可信性仍存在着重要的问题,以便在关键场景中负责使用。不同于现有的符合风险控制程序,我们采用了一种新的凸优化方法,允许多维风险控制,同时可证明最小限度的平均间隔长度。

**[Paper URL](https://proceedings.mlr.press/v202/teneggi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/teneggi23a/teneggi23a.pdf)** 

# Concurrent Shuffle Differential Privacy Under Continual Observation
**题目:** 持续观察下,共时缓冲差额私隐

**作者:** Jay Tenenbaum, Haim Kaplan, Yishay Mansour, Uri Stemmer

**Abstract:** We introduce the concurrent shuffle model of differential privacy. In this model we have multiple concurrent shufflers permuting messages from different, possibly overlapping, batches of users. Similarly to the standard (single) shuffler model, the privacy requirement is that the concatenation of all shuffled messages should be differentially private. We study the private continual summation problem (a.k.a. the counter problem) and show that the concurrent shuffle model allows for significantly improved error compared to a standard (single) shuffler model. Specifically, we give a summation algorithm with error $\tilde{O}(n^{1/(2k+1)})$ with $k$ concurrent shufflers on a sequence of length $n$. Furthermore, we prove that this bound is tight for any $k$, even if the algorithm can choose the sizes of the batches adaptively. For $k=\log n$ shufflers, the resulting error is polylogarithmic, much better than $\tilde{\Theta}(n^{1/3})$ which we show is the smallest possible with a single shuffler. We use our online summation algorithm to get algorithms with improved regret bounds for the contextual linear bandit problem. In particular we get optimal $\tilde{O}(\sqrt{n})$ regret with $k= \tilde{\Omega}(\log n)$ concurrent shufflers.

**摘要:** 我们引入了微分私隐的同步 shuffle模型。在这个模型中,我们有多个同步 shufflers从不同的,可能重叠的,用户批量转换消息。类似于标准(单一) shuffler模型,私隐要求是所有 shuffled消息的串联应该具有微分私隐性。我们研究了私人连续的总结问题(即计数问题)并表明,同步 shuffler模型允许与标准(单一) shuffler模型相比大幅改进错误。具体地说,我们给出了错误$\tilde{O}(n^{1/(2k+1)})$和$k$同步 shufflers在长度$n$的序列上的总结算法。对于$k=\log n$ shufflers,结果的误差是多法数,比$\tilde{\Theta}(n^{1/3})$我们显示的单个 shuffler最小。我们使用我们的在线总结算法得到改进的 regret 边界的算法来解决上下文线性带子问题。

**[Paper URL](https://proceedings.mlr.press/v202/tenenbaum23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tenenbaum23a/tenenbaum23a.pdf)** 

# Finding Generalization Measures by Contrasting Signal and Noise
**题目:** 通过对信号和噪声进行对比,找出一般化措施

**作者:** Jiaye Teng, Bohang Zhang, Ruichen Li, Haowei He, Yequan Wang, Yan Tian, Yang Yuan

**Abstract:** Generalization is one of the most fundamental challenges in deep learning, aiming to predict model performances on unseen data. Empirically, such predictions usually rely on a validation set, while recent works showed that an unlabeled validation set also works. Without validation sets, it is extremely difficult to obtain non-vacuous generalization bounds, which leads to a weaker task of finding generalization measures that monotonically relate to generalization error. In this paper, we propose a new generalization measure REF Complexity (RElative Fitting degree between signal and noise), motivated by the intuition that a given model-algorithm pair may generalize well if it fits signal (e.g., true labels) fast while fitting noise (e.g., random labels) slowly. Empirically, REF Complexity monotonically relates to test accuracy in real-world datasets without accessing additional validation sets, achieving -0.988 correlation on CIFAR-10 and -0.960 correlation on CIFAR-100. We further theoretically verify the utility of REF Complexity under three different cases, including convex and smooth regimes with stochastic gradient descent, smooth regimes (not necessarily convex) with stochastic gradient Langevin dynamics, and linear regimes with gradient descent. The code is available at https://github.com/962086838/REF-complexity.

**摘要:** 一般化是深层学习中最根本的挑战之一,旨在预测模型在未见数据上的性能。 一般而言,这种预测通常依赖于一个验证集,而最近的研究表明,一个没有标签的验证集也是有效的。 没有验证集,很难获得非空的一般化界限,这导致寻找与一般化误差相关的一般化措施的任务较弱。我们进一步从理论上验证REF复杂度在三个不同情况下的实用性,包括随机梯度下降的凸和平滑模式、随机梯度拉根文动力学的平滑模式(不一定是凸)和随机梯度下降的线性模式。该代码可于 https://github.com/962086838/REF-complexity 。

**[Paper URL](https://proceedings.mlr.press/v202/teng23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/teng23a/teng23a.pdf)** 

# Reinforcement Learning with History Dependent Dynamic Contexts
**题目:** 基于历史动态背景的强化学习

**作者:** Guy Tennenholtz, Nadav Merlis, Lior Shani, Martin Mladenov, Craig Boutilier

**Abstract:** We introduce Dynamic Contextual Markov Decision Processes (DCMDPs), a novel reinforcement learning framework for history-dependent environments that generalizes the contextual MDP framework to handle non-Markov environments, where contexts change over time. We consider special cases of the model, with a focus on logistic DCMDPs, which break the exponential dependence on history length by leveraging aggregation functions to determine context transitions. This special structure allows us to derive an upper-confidence-bound style algorithm for which we establish regret bounds. Motivated by our theoretical results, we introduce a practical model-based algorithm for logistic DCMDPs that plans in a latent space and uses optimism over history-dependent features. We demonstrate the efficacy of our approach on a recommendation task (using MovieLens data) where user behavior dynamics evolve in response to recommendations.

**摘要:** 我们介绍了动态上下文马可夫决策过程(DCMDPs),一种用于历史依赖环境的新型增强学习框架,将上下文MDP框架推广到处理非马可夫环境,其中上下文随时间变化。我们考虑了该模型的特殊案例,着重于物流DCMDP,通过利用集群函数来确定上下文的转变,打破历史长度的指数依赖性。该特殊结构允许我们导出一种我们确定遗憾边界的上层-信任边界风格算法。

**[Paper URL](https://proceedings.mlr.press/v202/tennenholtz23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tennenholtz23a/tennenholtz23a.pdf)** 

# PWSHAP: A Path-Wise Explanation Model for Targeted Variables
**题目:** PWSHAP:目标变量路径误差解释模型

**作者:** Lucile Ter-Minassian, Oscar Clivio, Karla Diazordaz, Robin J. Evans, Christopher C. Holmes

**Abstract:** Predictive black-box models can exhibit high-accuracy but their opaque nature hinders their uptake in safety-critical deployment environments. Explanation methods (XAI) can provide confidence for decision-making through increased transparency. However, existing XAI methods are not tailored towards models in sensitive domains where one predictor is of special interest, such as a treatment effect in a clinical model, or ethnicity in policy models. We introduce Path-Wise Shapley effects (PWSHAP), a framework for assessing the targeted effect of a binary (e.g. treatment) variable from a complex outcome model. Our approach augments the predictive model with a user-defined directed acyclic graph (DAG). The method then uses the graph alongside on-manifold Shapley values to identify effects along causal pathways whilst maintaining robustness to adversarial attacks. We establish error bounds for the identified path-wise Shapley effects and for Shapley values. We show PWSHAP can perform local bias and mediation analyses with faithfulness to the model. Further, if the targeted variable is randomised we can quantify local effect modification. We demonstrate the resolution, interpretability and true locality of our approach on examples and a real-world experiment.

**摘要:** 预测黑箱模型可以显示高精度,但其不透明性阻碍其在安全-临界部署环境中的应用。解释方法(XAI)可通过提高透明度提供决策的信心。然而,现有XAI方法并不针对一个预测者特别感兴趣的敏感领域中的模型,例如临床模型中的治疗效果,或政策模型中的种族性。我们引入Path-WiseShapley效应(PWSHAP),从复杂结果模型中评估二进制(例如治疗)变量的目标效应的框架。我们的方法增加了预测模型的用户定义导向环形图(DAG)。通过实例和实例实验,证明了PWSHAP能够忠实地对模型进行局部偏差和调解分析。此外,如果目标变量是随机化,我们可以量化局部效应的修改。

**[Paper URL](https://proceedings.mlr.press/v202/ter-minassian23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ter-minassian23a/ter-minassian23a.pdf)** 

# On the Estimation of Gaussian Mixture Copula Models
**题目:** 高斯混合样本模型的估计

**作者:** Ashutosh Tewari

**Abstract:** This paper revisits Gaussian Mixture Copula Model (GMCM), a more expressive alternative to the widely used Gaussian Mixture Model (GMM), with the goal to make its parameter estimation tractable. Both the Expectation Maximization and the direct Likelihood Maximization frameworks for GMCM have to grapple with a likelihood function that lacks a closed form. This has led to a few approximation schemes that alleviate the problem, nonetheless leaving the issue still unresolved. Additionally, past works have alluded to an additional challenge of parameter non-identifiability, but none has offered a rigorous treatment and a commensurate solution framework to overcome the same. This work offers solutions to each of these issues in an attempt to help GMCM realize its full potential. The source of non-identifiability is not only proven but also suitable priors are proposed that eliminate the problem. Additionally, an efficient numerical framework is proposed to evaluate the intractable likelihood function, while also providing its analytical derivatives. Finally, a view of GMCM as a series of bijective mappings from a base distribution is presented, which paves the way to synthesize GMCM using modern, probabilistic programming languages (PPLs). The main claims of this work are supported by empirical evidence gathered on synthetic and real-world datasets.

**摘要:** 本文再次回顾了广为应用的高斯混合模型(GMM)的表达式替代方案,旨在使其参数估计易于处理。高斯混合模型的预期最大化和直接的概率最大化框架都必须与缺乏封闭形式的概率函数进行斗争。这导致了减轻问题的一些近似方案,但问题仍未得到解决。此外,过去的工作都提到了参数非识别的额外挑战,但没有一个给出了较严格的处理和相应的解决框架来克服这些问题。此外,提出了一种有效的数值框架来评价不可解的概率函数,同时提供其分析导数。最后,提出了一种基于基础分布的双向映射系列的GMCM观,为使用现代的概率编程语言(PPL)合成GMCM铺平了道路。

**[Paper URL](https://proceedings.mlr.press/v202/tewari23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tewari23a/tewari23a.pdf)** 

# Target-Aware Generative Augmentations for Single-Shot Adaptation
**题目:** 基于目标的单击适应性发电增量

**作者:** Kowshik Thopalli, Rakshith Subramanyam, Pavan K. Turaga, Jayaraman J. Thiagarajan

**Abstract:** In this paper, we address the problem of adapting models from a source domain to a target domain, a task that has become increasingly important due to the brittle generalization of deep neural networks. While several test-time adaptation techniques have emerged, they typically rely on synthetic toolbox data augmentations in cases of limited target data availability. We consider the challenging setting of single-shot adaptation and explore the design of augmentation strategies. We argue that augmentations utilized by existing methods are insufficient to handle large distribution shifts, and hence propose a new approach SiSTA, which first fine-tunes a generative model from the source domain using a single-shot target, and then employs novel sampling strategies for curating synthetic target data. Using experiments on a variety of benchmarks, distribution shifts and image corruptions, we find that SiSTA produces significantly improved generalization over existing baselines in face attribute detection and multi-class object recognition. Furthermore, SiSTA performs competitively to models obtained by training on larger target datasets. Our codes can be accessed at https://github.com/Rakshith-2905/SiSTA

**摘要:** 本文讨论了源域对目标域的模型适应问题,由于深度神经网络的脆性一般化,这一问题日益重要。虽然有几种测试时间适应技术出现,但它们通常依赖于有限目标数据可用性情况下的合成工具箱数据增量。我们考虑了单击适应的挑战性设置,并探讨了增量策略的设计。我们认为现有方法所采用的增量不足以处理大规模分布转移,因此提出了一种新方法SiSTA,它首先用单击目标进行源域的生成模型的微调,然后采用新的采样策略来筛选合成目标数据。通过对各种基准、分布变迁和图像损坏的实验,我们发现SiSTA在面属性检测和多类对象识别中对现有基准产生显著改进的一般化。此外,SiSTA对通过训练获得的更大目标数据集模型进行竞争。我们代码可访问 https://github.com/Rakshith-2905/SiSTA

**[Paper URL](https://proceedings.mlr.press/v202/thopalli23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/thopalli23a/thopalli23a.pdf)** 

# ELSA: Efficient Label Shift Adaptation through the Lens of Semiparametric Models
**题目:** ELSA:半参数模型透镜的高效标签变换适应

**作者:** Qinglong Tian, Xin Zhang, Jiwei Zhao

**Abstract:** We study the domain adaptation problem with label shift in this work. Under the label shift context, the marginal distribution of the label varies across the training and testing datasets, while the conditional distribution of features given the label is the same. Traditional label shift adaptation methods either suffer from large estimation errors or require cumbersome post-prediction calibrations. To address these issues, we first propose a moment-matching framework for adapting the label shift based on the geometry of the influence function. Under such a framework, we propose a novel method named $\underline{\mathrm{E}}$fficient $\underline{\mathrm{L}}$abel $\underline{\mathrm{S}}$hift $\underline{\mathrm{A}}$daptation (ELSA), in which the adaptation weights can be estimated by solving linear systems. Theoretically, the ELSA estimator is $\sqrt{n}$-consistent ($n$ is the sample size of the source data) and asymptotically normal. Empirically, we show that ELSA can achieve state-of-the-art estimation performances without post-prediction calibrations, thus, gaining computational efficiency.

**摘要:** 本文研究了标签变换的领域适应问题。在标签变换的上下文下,标签的边缘分布在训练和测试数据集中有所不同,而给标签的特征的条件分布是相同的。传统的标签变换适应方法要么遭受较大的估计误差,要么需要复杂的后预测校正。为了解决这些问题,我们首先提出了一种基于影响函数几何的矩阵匹配框架来适应标签变换。在这样的框架下,我们提出了一种名为$\underline{\mathrm{E}}$fficient $\underline{\mathrm{L}}$abel $\underline{\mathrm{S}}$hift $\underline{\mathrm{A}}$daptation(ELSA)的新方法,该方法通过解决线性系统来估计适应权重。实证表明,ELSA能够在无预测校正的情况下实现最先进的估计性能,从而提高计算效率。

**[Paper URL](https://proceedings.mlr.press/v202/tian23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tian23a/tian23a.pdf)** 

# Spherical Inducing Features for Orthogonally-Decoupled Gaussian Processes
**题目:** 正交耦合高斯过程的球形诱导特性

**作者:** Louis C. Tiao, Vincent Dutordoir, Victor Picheny

**Abstract:** Despite their many desirable properties, Gaussian processes (GPs) are often compared unfavorably to deep neural networks (NNs) for lacking the ability to learn representations. Recent efforts to bridge the gap between GPs and deep NNs have yielded a new class of inter-domain variational GPs in which the inducing variables correspond to hidden units of a feedforward NN. In this work, we examine some practical issues associated with this approach and propose an extension that leverages the orthogonal decomposition of GPs to mitigate these limitations. In particular, we introduce spherical inter-domain features to construct more flexible data-dependent basis functions for both the principal and orthogonal components of the GP approximation and show that incorporating NN activation features under this framework not only alleviates these shortcomings but is more scalable than alternative strategies. Experiments on multiple benchmark datasets demonstrate the effectiveness of our approach.

**摘要:** 尽管具有许多理想的特性,高斯过程(GPs)经常与深层神经网络(NNs)相比较,因为缺乏学习表示的能力。最近为解决GPs和深层NN之间的差距而进行的努力,产生了一种新的跨域变量GP类别,其中诱导变量与 feedforward NN的隐藏单元相符。在这个研究中,我们对与这一方法相关的一些实际问题进行了研究,并提出了一种扩展,利用GPs的正交分解来缓解这些局限性。

**[Paper URL](https://proceedings.mlr.press/v202/tiao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tiao23a/tiao23a.pdf)** 

# Fast Rates for Maximum Entropy Exploration
**题目:** 最大熵勘探速率

**作者:** Daniil Tiapkin, Denis Belomestny, Daniele Calandriello, Eric Moulines, Remi Munos, Alexey Naumov, Pierre Perrault, Yunhao Tang, Michal Valko, Pierre Menard

**Abstract:** We address the challenge of exploration in reinforcement learning (RL) when the agent operates in an unknown environment with sparse or no rewards. In this work, we study the maximum entropy exploration problem of two different types. The first type is visitation entropy maximization previously considered by Hazan et al. (2019) in the discounted setting. For this type of exploration, we propose a game-theoretic algorithm that has $\widetilde{\mathcal{O}}(H^3S^2A/\varepsilon^2)$ sample complexity thus improving the $\varepsilon$-dependence upon existing results, where $S$ is a number of states, $A$ is a number of actions, $H$ is an episode length, and $\varepsilon$ is a desired accuracy. The second type of entropy we study is the trajectory entropy. This objective function is closely related to the entropy-regularized MDPs, and we propose a simple algorithm that has a sample complexity of order $\widetilde{\mathcal{O}}(\mathrm{poly}(S,A,H)/\varepsilon)$. Interestingly, it is the first theoretical result in RL literature that establishes the potential statistical advantage of regularized MDPs for exploration. Finally, we apply developed regularization techniques to reduce sample complexity of visitation entropy maximization to $\widetilde{\mathcal{O}}(H^2SA/\varepsilon^2)$, yielding a statistical separation between maximum entropy exploration and reward-free exploration.

**摘要:** 本文研究了两个不同类型的最大熵探索问题。第一类是访问熵最大化,由哈桑等人(2019年)在低价环境中考虑。对于这种类型的探索,我们提出了一种具有$\widetilde{\mathcal{O}}(H^3S^2A/\varepsilon^2)$样本复杂性的游戏理论算法,从而改善$\varepsilon$-依赖于现有的结果,其中$S$是数个状态,$A$是数个行动,$H$是一段长度,$\varepsilon$是期望的精度。有趣的是,这是RL文献中第一个理论结果,它确定了常规化MDP对探索的潜在统计优势。最后,我们应用了改进的规则化技术,将访问熵最大化样本复杂度降低到$\widetilde{\mathcal{O}}(H^2SA/\varepsilon^2)$,使最大熵探索与无奖赏探索之间的统计区分。

**[Paper URL](https://proceedings.mlr.press/v202/tiapkin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tiapkin23a/tiapkin23a.pdf)** 

# Margin-based sampling in high dimensions: When being active is less efficient than staying passive
**题目:** 高维边际样本:当主动时比被动时效率低

**作者:** Alexandru Tifrea, Jacob Clarysse, Fanny Yang

**Abstract:** It is widely believed that given the same labeling budget, active learning (AL) algorithms like margin-based active learning achieve better predictive performance than passive learning (PL), albeit at a higher computational cost. Recent empirical evidence suggests that this added cost might be in vain, as margin-based AL can sometimes perform even worse than PL. While existing works offer different explanations in the low-dimensional regime, this paper shows that the underlying mechanism is entirely different in high dimensions: we prove for logistic regression that PL outperforms margin-based AL even for noiseless data and when using the Bayes optimal decision boundary for sampling. Insights from our proof indicate that this high-dimensional phenomenon is exacerbated when the separation between the classes is small. We corroborate this intuition with experiments on 20 high-dimensional datasets spanning a diverse range of applications, from finance and histology to chemistry and computer vision.

**摘要:** 人们普遍认为,基于边际的主动学习(AL)算法比被动学习(PL)具有更好的预测性能,尽管计算成本较高。最近的实证证据表明,这种附加成本可能是徒劳的,因为基于边际的AL有时甚至比PL更糟糕。我们通过对20个高维数据集的实验证实了这一直觉,这涵盖了从金融和组织学到化学和计算机视觉的多种应用领域。

**[Paper URL](https://proceedings.mlr.press/v202/tifrea23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tifrea23a/tifrea23a.pdf)** 

# Differentiable Multi-Target Causal Bayesian Experimental Design
**题目:** 可鉴别多目标动因贝叶斯实验设计

**作者:** Panagiotis Tigas, Yashas Annadani, Desi R. Ivanova, Andrew Jesson, Yarin Gal, Adam Foster, Stefan Bauer

**Abstract:** We introduce a gradient-based approach for the problem of Bayesian optimal experimental design to learn causal models in a batch setting — a critical component for causal discovery from finite data where interventions can be costly or risky. Existing methods rely on greedy approximations to construct a batch of experiments while using black-box methods to optimize over a single target-state pair to intervene with. In this work, we completely dispose of the black-box optimization techniques and greedy heuristics and instead propose a conceptually simple end-to-end gradient-based optimization procedure to acquire a set of optimal intervention target-value pairs. Such a procedure enables parameterization of the design space to efficiently optimize over a batch of multi-target-state interventions, a setting which has hitherto not been explored due to its complexity. We demonstrate that our proposed method outperforms baselines and existing acquisition strategies in both single-target and multi-target settings across a number of synthetic datasets.

**摘要:** 本文对贝叶斯最佳实验设计问题提出了一种基于梯度的方法,以学习批量设置中因果模型 — — 从有限数据中因果发现的一个关键组成部分,其中干预可能有成本或风险。现有的方法依靠贪婪的近似来构建批量实验,同时使用黑箱方法对单一目标状态对进行干预。本文完全排除了黑箱优化技术和贪婪的实验方法,并提出一种概念上简单的端到端梯度优化程序,以获取一套最佳干预目标值对。我们证明,我们提出的方法在多个合成数据集中,在单目标和多目标设置中超越了基线和现有的收购策略。

**[Paper URL](https://proceedings.mlr.press/v202/tigas23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tigas23a/tigas23a.pdf)** 

# PCA-based Multi-Task Learning: a Random Matrix Approach
**题目:** 基于PCA的多任务学习:一种随机矩阵方法

**作者:** Malik Tiomoko, Romain Couillet, Frederic Pascal

**Abstract:** The article proposes and theoretically analyses a computationally efficient multi-task learning (MTL) extension of popular principal component analysis (PCA)-based supervised learning schemes. The analysis reveals that (i) by default, learning may dramatically fail by suffering from negative transfer, but that (ii) simple counter-measures on data labels avert negative transfer and necessarily result in improved performances. Supporting experiments on synthetic and real data benchmarks show that the proposed method achieves comparable performance with state-of-the-art MTL methods but at a significantly reduced computational cost.

**摘要:** 本文提出并从理论上分析了基于公共主要组件分析(PCA)的监督学习计划的计算效率高多任务学习(MTL)扩展。分析发现:(i)默认情况下,学习可能因负传输而大幅失败,但(ii)数据标签上的简单反措施可以避免负传输,并必然导致性能提高。

**[Paper URL](https://proceedings.mlr.press/v202/tiomoko23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tiomoko23a/tiomoko23a.pdf)** 

# Perturbation Analysis of Neural Collapse
**题目:** 神经衰竭扰动分析

**作者:** Tom Tirer, Haoxiang Huang, Jonathan Niles-Weed

**Abstract:** Training deep neural networks for classification often includes minimizing the training loss beyond the zero training error point. In this phase of training, a "neural collapse" behavior has been observed: the variability of features (outputs of the penultimate layer) of within-class samples decreases and the mean features of different classes approach a certain tight frame structure. Recent works analyze this behavior via idealized unconstrained features models where all the minimizers exhibit exact collapse. However, with practical networks and datasets, the features typically do not reach exact collapse, e.g., because deep layers cannot arbitrarily modify intermediate features that are far from being collapsed. In this paper, we propose a richer model that can capture this phenomenon by forcing the features to stay in the vicinity of a predefined features matrix (e.g., intermediate features). We explore the model in the small vicinity case via perturbation analysis and establish results that cannot be obtained by the previously studied models. For example, we prove reduction in the within-class variability of the optimized features compared to the predefined input features (via analyzing gradient flow on the "central-path" with minimal assumptions), analyze the minimizers in the near-collapse regime, and provide insights on the effect of regularization hyperparameters on the closeness to collapse. We support our theory with experiments in practical deep learning settings.

**摘要:** 训练类别的深度神经网络通常包括在训练误差点以外的训练损失最小化。在这个训练阶段,人们观察到“神经崩溃”行为:类内样品特征的变异性(前后层的输出)减少,而不同类的平均特征接近一定的紧格结构。最近的工作通过理想化的无约束特征模型分析了这种行为,其中所有最小化者都显示了准确的崩溃。然而,在实际网络和数据集中,特征通常不会达到准确的崩溃,例如,深层不能任意修改远离崩溃的中间特征。通过扰动分析,对小邻域模型进行了研究,并建立了 previously studied models无法得到的结果。例如,我们证明了与预定义输入特征相比,优化特征的类内变异性降低(通过对“中心路径”的梯度流动进行分析,用最小假设)、分析近崩溃模式中的最小化器,并提供对调节超参数对近崩溃程度的影响的洞察。

**[Paper URL](https://proceedings.mlr.press/v202/tirer23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tirer23a/tirer23a.pdf)** 

# Overcoming Simplicity Bias in Deep Networks using a Feature Sieve
**题目:** 利用功能筛选在深层网络中克服简单偏见

**作者:** Rishabh Tiwari, Pradeep Shenoy

**Abstract:** Simplicity bias is the concerning tendency of deep networks to over-depend on simple, weakly predictive features, to the exclusion of stronger, more complex features. This causes biased, incorrect model predictions in many real-world applications, exacerbated by incomplete training data containing spurious feature-label correlations. We propose a direct, interventional method for addressing simplicity bias in DNNs, which we call the feature sieve. We aim to automatically identify and suppress easily-computable spurious features in lower layers of the network, thereby allowing the higher network levels to extract and utilize richer, more meaningful representations. We provide concrete evidence of this differential suppression & enhancement of relevant features on both controlled datasets and real-world images, and report substantial gains on many real-world debiasing benchmarks (11.4% relative gain on Imagenet-A; 3.2% on BAR, etc). Crucially, we outperform many baselines that incorporate knowledge about known spurious or biased attributes, despite our method not using any such information. We believe that our feature sieve work opens up exciting new research directions in automated adversarial feature extraction & representation learning for deep networks.

**摘要:** 简单偏见是深度网络对简单、弱预测特征过度依赖的倾向,使更强、更复杂的特征排除在外。这导致在许多实世界应用中偏见、错误的模型预测,并由包含伪特征标签关联的不完整的训练数据加剧。我们提出了针对DNNs的简单偏见的直接干预方法,我们称之为特征筛。我们的目标是自动识别和抑制低层网络中容易计算的伪特征,从而允许较高的网络水平提取和利用更丰富、更有意义的表示。我们提供有关特征在控制数据集和实世界图像上的这种差异抑制和增强的具体证据,并报告许多实世界偏见基准上的实质性收益(Imagenet-A的相对收益11.4%;Bar的3.2%)。重要的是,尽管我们没有使用任何此类信息的方法,我们仍能超越许多包含关于已知伪造或偏见属性的知识基线。我们相信,我们的特征筛选工作为深层网络的自动化敌对特征提取和表现学习开辟了令人兴奋的新研究方向。

**[Paper URL](https://proceedings.mlr.press/v202/tiwari23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tiwari23a/tiwari23a.pdf)** 

# Beyond In-Domain Scenarios: Robust Density-Aware Calibration
**题目:** 在内域场景之外:鲁棒密度意识校正

**作者:** Christian Tomani, Futa Kai Waseda, Yuesong Shen, Daniel Cremers

**Abstract:** Calibrating deep learning models to yield uncertainty-aware predictions is crucial as deep neural networks get increasingly deployed in safety-critical applications. While existing post-hoc calibration methods achieve impressive results on in-domain test datasets, they are limited by their inability to yield reliable uncertainty estimates in domain-shift and out-of-domain (OOD) scenarios. We aim to bridge this gap by proposing DAC, an accuracy-preserving as well as Density-Aware Calibration method based on k-nearest-neighbors (KNN). In contrast to existing post-hoc methods, we utilize hidden layers of classifiers as a source for uncertainty-related information and study their importance. We show that DAC is a generic method that can readily be combined with state-of-the-art post-hoc methods. DAC boosts the robustness of calibration performance in domain-shift and OOD, while maintaining excellent in-domain predictive uncertainty estimates. We demonstrate that DAC leads to consistently better calibration across a large number of model architectures, datasets, and metrics. Additionally, we show that DAC improves calibration substantially on recent large-scale neural networks pre-trained on vast amounts of data.

**摘要:** 深度学习模型的校正以产生不确定意识的预测是至关重要的,因为深层神经网络在安全关键应用中日益被部署。虽然现有的后程校正方法在domain测试数据集中取得令人印象深刻的结果,但它们由于无法在domain-shift和Out-of-domain(OOD)场景中产生可靠的不确定估计而受到限制。我们的目标是通过提议DAC、精度保持以及基于k-nearest-neighbors(KNN)的密度意识校正方法来弥补这一差距。我们证明了DAC在大量的模型架构、数据集和度量中能持续改善校准。此外,我们证明了DAC在大量数据上预先训练的最近大规模神经网络中能大幅改善校准。

**[Paper URL](https://proceedings.mlr.press/v202/tomani23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tomani23a/tomani23a.pdf)** 

# Distribution Free Domain Generalization
**题目:** 免费域名推广

**作者:** Peifeng Tong, Wu Su, He Li, Jialin Ding, Zhan Haoxiang, Song Xi Chen

**Abstract:** Accurate prediction of the out-of-distribution data is desired for a learning algorithm. In domain generalization, training data from source domains tend to have different distributions from that of the target domain, while the target data are absence in the training process. We propose a Distribution Free Domain Generalization (DFDG) procedure for classification by conducting standardization to avoid the dominance of a few domains in the training process. The essence of the DFDG is its reformulating the cross domain/class discrepancy by pairwise two sample test statistics, and equally weights their importance or the covariance structures to avoid dominant domain/class. A theoretical generalization bound is established for the multi-class classification problem. The DFDG is shown to offer a superior performance in empirical studies with fewer hyperparameters, which means faster and easier implementation.

**摘要:** 在领域推广中,来自源域的培训数据往往与目标域的分布不同,而目标数据则在培训过程中不存在。我们建议通过规范化来进行分类的分布自由领域推广(DFDG)程序,以避免在培训过程中少数域的主导地位。DFDG的实质是通过双样品测试统计对交叉领域/类别差异进行改革,并同样权重其重要性或共变结构以避免主导领域/类别。

**[Paper URL](https://proceedings.mlr.press/v202/tong23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tong23a/tong23a.pdf)** 

# Extending Kernel PCA through Dualization: Sparsity, Robustness and Fast Algorithms
**题目:** 通过二元化扩展内核PCA:节约性、鲁棒性和快速算法

**作者:** Francesco Tonin, Alex Lambert, Panagiotis Patrinos, Johan Suykens

**Abstract:** The goal of this paper is to revisit Kernel Principal Component Analysis (KPCA) through dualization of a difference of convex functions. This allows to naturally extend KPCA to multiple objective functions and leads to efficient gradient-based algorithms avoiding the expensive SVD of the Gram matrix. Particularly, we consider objective functions that can be written as Moreau envelopes, demonstrating how to promote robustness and sparsity within the same framework. The proposed method is evaluated on synthetic and realworld benchmarks, showing significant speedup in KPCA training time as well as highlighting the benefits in terms of robustness and sparsity.

**摘要:** 本文的目的是通过对凸函数的差异的双重化重新回顾核子主成分分析(KPCA)。这样可以自然地把KPCA扩展到多个目标函数,并导致有效的梯度based算法避免高昂的Gram矩阵SVD。我们特别考虑可以作为莫罗包写的对象函数,展示如何在同一框架内促进鲁棒性和稀疏性。

**[Paper URL](https://proceedings.mlr.press/v202/tonin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tonin23a/tonin23a.pdf)** 

# Robust Weak Supervision with Variational Auto-Encoders
**题目:** 基于变量自动编码器的强弱监视

**作者:** Francesco Tonolini, Nikolaos Aletras, Yunlong Jiao, Gabriella Kazai

**Abstract:** Recent advances in weak supervision (WS) techniques allow to mitigate the enormous cost and effort of human data annotation for supervised machine learning by automating it using simple rule-based labelling functions (LFs). However, LFs need to be carefully designed, often requiring expert domain knowledge and extensive validation for existing WS methods to be effective. To tackle this, we propose the Weak Supervision Variational Auto-Encoder (WS-VAE), a novel framework that combines unsupervised representation learning and weak labelling to reduce the dependence of WS on expert and manual engineering of LFs. Our technique learns from inputs and weak labels jointly to capture the input signals distribution with a latent space. The unsupervised representation component of the WS-VAE regularises the inference of weak labels, while a specifically designed decoder allows the model to learn the relevance of LFs for each input. These unique features lead to considerably improved robustness to the quality of LFs, compared to existing methods. An extensive empirical evaluation on a standard WS benchmark shows that our WS-VAE is competitive to state-of-the-art methods and substantially more robust to LF engineering.

**摘要:** 弱监管技术的最新进展,通过使用简单的基于规则的标签函数(LFs)的自动化来减轻对监控机器学习的人力数据注释的巨大成本和努力。然而,LFs需要仔细设计,经常需要专家领域知识和有效的现有WS方法的广泛验证。为了解决这个问题,我们提出了弱监管变量自动编码器(WS-VAE),一种新颖的框架,它结合了无监管的表示学习和弱标签,减少WS对专家和手动工程的依赖。我们的技术从输入和弱标签一起学习,以捕捉潜在空间的输入信号分布。这些独特的特性导致了与现有方法相比,LF质量的鲁棒性大大提高。对标准WS基准进行广泛的实证评价表明,WS-VAE对最新方法具有竞争力,对LF工程具有较强的鲁棒性。

**[Paper URL](https://proceedings.mlr.press/v202/tonolini23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tonolini23a/tonolini23a.pdf)** 

# Fully Bayesian Autoencoders with Latent Sparse Gaussian Processes
**题目:** 完全贝叶斯式自动编码器,带有拉特斯帕斯高斯过程

**作者:** Ba-Hien Tran, Babak Shahbaba, Stephan Mandt, Maurizio Filippone

**Abstract:** We present a fully Bayesian autoencoder model that treats both local latent variables and global decoder parameters in a Bayesian fashion. This approach allows for flexible priors and posterior approximations while keeping the inference costs low. To achieve this, we introduce an amortized MCMC approach by utilizing an implicit stochastic network to learn sampling from the posterior over local latent variables. Furthermore, we extend the model by incorporating a Sparse Gaussian Process prior over the latent space, allowing for a fully Bayesian treatment of inducing points and kernel hyperparameters and leading to improved scalability. Additionally, we enable Deep Gaussian Process priors on the latent space and the handling of missing data. We evaluate our model on a range of experiments focusing on dynamic representation learning and generative modeling, demonstrating the strong performance of our approach in comparison to existing methods that combine Gaussian Processes and autoencoders.

**摘要:** 本文提出了一种以贝叶斯方式处理局部 latent变量和全球解码器参数的完全贝叶斯式自动编码模型。该方法允许灵活的前后近似,同时保持推理成本低。为此,我们利用隐性随机网络引入 amortised MCMC方法,从后后方对局部 latent变量进行采样。此外,我们通过引入 Sparse Gaussian Process prior over the latent space 来扩展该模型,允许完全贝叶斯式处理诱导点和内核超参数,从而提高可扩展性。我们通过一系列以动态表示学习和生成建模为重点的实验来评估我们的模型,证明了我们方法在现有的加斯过程和自编码器相结合的方法中的表现。

**[Paper URL](https://proceedings.mlr.press/v202/tran23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tran23a/tran23a.pdf)** 

# Discrete Key-Value Bottleneck
**题目:** 离散键值双臂

**作者:** Frederik Träuble, Anirudh Goyal, Nasim Rahaman, Michael Curtis Mozer, Kenji Kawaguchi, Yoshua Bengio, Bernhard Schölkopf

**Abstract:** Deep neural networks perform well on classification tasks where data streams are i.i.d. and labeled data is abundant. Challenges emerge with non-stationary training data streams such as continual learning. One powerful approach that has addressed this challenge involves pre-training of large encoders on volumes of readily available data, followed by task-specific tuning. Given a new task, however, updating the weights of these encoders is challenging as a large number of weights needs to be fine-tuned, and as a result, they forget information about the previous tasks. In the present work, we propose a model architecture to address this issue, building upon a discrete bottleneck containing pairs of separate and learnable key-value codes. Our paradigm will be to encode; process the representation via a discrete bottleneck; and decode. Here, the input is fed to the pre-trained encoder, the output of the encoder is used to select the nearest keys, and the corresponding values are fed to the decoder to solve the current task. The model can only fetch and re-use a sparse number of these key-value pairs during inference, enabling localized and context-dependent model updates. We theoretically investigate the ability of the discrete key-value bottleneck to minimize the effect of learning under distribution shifts and show that it reduces the complexity of the hypothesis class. We empirically verify the proposed method under challenging class-incremental learning scenarios and show that the proposed model — without any task boundaries — reduces catastrophic forgetting across a wide variety of pre-trained models, outperforming relevant baselines on this task.

**摘要:** 深层神经网络在数据流的分类任务中表现良好,并且有大量标记数据。与非静态训练数据流(如持续学习)产生挑战。解决这一挑战的一个强有力的方法是预先训练大量可用数据的大型编码器,然后进行任务特定调制。给定一个新的任务,然而,更新这些编码器的重量是挑战性的,因为大量的重量需要精确调制,因此,他们忘记了关于以前的任务的信息。在此,输入被输入到预训练的编码器,编码器的输出被用来选择最接近的键,相应的值被输入到解码器来解决当前任务。该模型只能在推导过程中检索和重用这些键值对数,允许本地化和上下文依赖的模型更新。我们从理论上研究离散键值瓶颈的能力,以最小限度地减少在分布变化下学习的影响,并表明它降低了假设类的复杂性。

**[Paper URL](https://proceedings.mlr.press/v202/trauble23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/trauble23a/trauble23a.pdf)** 

# Mimetic Initialization of Self-Attention Layers
**题目:** 自我注意层的隐形初始化

**作者:** Asher Trockman, J Zico Kolter

**Abstract:** It is notoriously difficult to train Transformers on small datasets; typically, large pre-trained models are instead used as the starting point. We explore the weights of such pre-trained Transformers (particularly for vision) to attempt to find reasons for this discrepancy. Surprisingly, we find that simply initializing the weights of self-attention layers so that they "look" more like their pre-trained counterparts allows us to train vanilla Transformers faster and to higher final accuracies, particularly on vision tasks such as CIFAR-10 and ImageNet classification, where we see gains in accuracy of over 5% and 4%, respectively. Our initialization scheme is closed form, learning-free, and very simple: we set the product of the query and key weights to be approximately the identity, and the product of the value and projection weights to approximately the negative identity. As this mimics the patterns we saw in pre-trained Transformers, we call the technique "mimetic initialization".

**摘要:** 在小型数据集上训练变形器是很困难的;通常,大型预训练模型被用作起点。我们研究了这些预训练变形器的重量(特别是视觉)来寻找这种不一致的原因。令人惊讶的是,我们发现,简单地初始化自我注意层的重量,使它们更像预训练的同类更像,使我们能够更快速地训练瓦尼拉变形器,并达到更高的最终精度,特别是在像CIFAR-10和ImageNet分类这样的视觉任务上,我们可以看到分别超过5%和4%的精度的提高。我们的初始化方案是封闭形式,无学习,而且非常简单:我们设置查询和关键重量的产物为大约的特征,以及价值和投影重量的产物为大约的负特征。

**[Paper URL](https://proceedings.mlr.press/v202/trockman23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/trockman23a/trockman23a.pdf)** 

# Representer Point Selection for Explaining Regularized High-dimensional Models
**题目:** 解释规范化高维模型的代表点选择

**作者:** Che-Ping Tsai, Jiong Zhang, Hsiang-Fu Yu, Eli Chien, Cho-Jui Hsieh, Pradeep Kumar Ravikumar

**Abstract:** We introduce a novel class of sample-based explanations we term high-dimensional representers, that can be used to explain the predictions of a regularized high-dimensional model in terms of importance weights for each of the training samples. Our workhorse is a novel representer theorem for general regularized high-dimensional models, which decomposes the model prediction in terms of contributions from each of the training samples: with positive (negative) values corresponding to positive (negative) impact training samples to the model’s prediction. We derive consequences for the canonical instances of $\ell_1$ regularized sparse models and nuclear norm regularized low-rank models. As a case study, we further investigate the application of low-rank models in the context of collaborative filtering, where we instantiate high-dimensional representers for specific popular classes of models. Finally, we study the empirical performance of our proposed methods on three real-world binary classification datasets and two recommender system datasets. We also showcase the utility of high-dimensional representers in explaining model recommendations.

**摘要:** 我们介绍了一种新型基于样本的解释,我们称之为高维代表,它可以用于解释每个训练样本的重要权重的定量化高维模型的预测。我们的工作horse是一个一般定量化高维模型的代表定理,它分解了每个训练样本的贡献的模型预测:与正(负)值相符的正(负)影响训练样本对模型预测的预测。我们得出$\ell_1$定量化稀疏模型和核规范定量化低级模型的标准实例的结果。最后,对三种实世界二进制分类数据集和两个推荐系统数据集的提议方法的实证性能进行了研究,并展示了高维表示器在解释模型建议中的作用。

**[Paper URL](https://proceedings.mlr.press/v202/tsai23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tsai23a/tsai23a.pdf)** 

# Expected Gradients of Maxout Networks and Consequences to Parameter Initialization
**题目:** 最大输出网络的预期梯度和参数初始化的影响

**作者:** Hanna Tseran, Guido Montufar

**Abstract:** We study the gradients of a maxout network with respect to inputs and parameters and obtain bounds for the moments depending on the architecture and the parameter distribution. We observe that the distribution of the input-output Jacobian depends on the input, which complicates a stable parameter initialization. Based on the moments of the gradients, we formulate parameter initialization strategies that avoid vanishing and exploding gradients in wide networks. Experiments with deep fully-connected and convolutional networks show that this strategy improves SGD and Adam training of deep maxout networks. In addition, we obtain refined bounds on the expected number of linear regions, results on the expected curve length distortion, and results on the NTK.

**摘要:** 我们研究了最大输出网络的梯度与输入和参数的关系,并根据结构和参数分布获得对矩阵的边界。我们观察到输入输出雅各布的分布取决于输入,这使得稳定参数初始化变得复杂。基于梯度的矩阵,我们制定参数初始化策略,以避免在宽网络中消失和爆炸梯度。对深完全连接和卷积网络的实验表明,这种策略提高了深最大输出网络的SGD和Adam训练。

**[Paper URL](https://proceedings.mlr.press/v202/tseran23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tseran23a/tseran23a.pdf)** 

# Provable Data Subset Selection For Efficient Neural Networks Training
**题目:** 提供有效的神经网络训练数据子集选择

**作者:** Murad Tukan, Samson Zhou, Alaa Maalouf, Daniela Rus, Vladimir Braverman, Dan Feldman

**Abstract:** Radial basis function neural networks (RBFNN) are well-known for their capability to approximate any continuous function on a closed bounded set with arbitrary precision given enough hidden neurons. In this paper, we introduce the first algorithm to construct coresets for RBFNNs, i.e., small weighted subsets that approximate the loss of the input data on any radial basis function network and thus approximate any function defined by an RBFNN on the larger input data. In particular, we construct coresets for radial basis and Laplacian loss functions. We then use our coresets to obtain a provable data subset selection algorithm for training deep neural networks. Since our coresets approximate every function, they also approximate the gradient of each weight in a neural network, which is a particular function on the input. We then perform empirical evaluations on function approximation and dataset subset selection on popular network architectures and data sets, demonstrating the efficacy and accuracy of our coreset construction.

**摘要:** 红外基函数神经网络(RBFNN)以其在封闭边界集中具有充分隐藏神经元的任意精度近似任意连续函数的能力而闻名。本文介绍了建立红外基函数神经网络的第一个算法,即在任何红外基函数网络上近似输入数据损失的微重子集,从而近似由红外基函数定义的任何函数在较大输入数据上。然后对流行网络架构和数据集的函数近似和数据集子集选择进行了实证评价,证明了核心集结构的有效性和准确性。

**[Paper URL](https://proceedings.mlr.press/v202/tukan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/tukan23a/tukan23a.pdf)** 

# Jump-Start Reinforcement Learning
**题目:** 跳跃启动强化学习

**作者:** Ikechukwu Uchendu, Ted Xiao, Yao Lu, Banghua Zhu, Mengyuan Yan, Joséphine Simon, Matthew Bennice, Chuyuan Fu, Cong Ma, Jiantao Jiao, Sergey Levine, Karol Hausman

**Abstract:** Reinforcement learning (RL) provides a theoretical framework for continuously improving an agent’s behavior via trial and error. However, efficiently learning policies from scratch can be very difficult, particularly for tasks that present exploration challenges. In such settings, it might be desirable to initialize RL with an existing policy, offline data, or demonstrations. However, naively performing such initialization in RL often works poorly, especially for value-based methods. In this paper, we present a meta algorithm that can use offline data, demonstrations, or a pre-existing policy to initialize an RL policy, and is compatible with any RL approach. In particular, we propose Jump-Start Reinforcement Learning (JSRL), an algorithm that employs two policies to solve tasks: a guide-policy, and an exploration-policy. By using the guide-policy to form a curriculum of starting states for the exploration-policy, we are able to efficiently improve performance on a set of simulated robotic tasks. We show via experiments that it is able to significantly outperform existing imitation and reinforcement learning algorithms, particularly in the small-data regime. In addition, we provide an upper bound on the sample complexity of JSRL and show that with the help of a guide-policy, one can improve the sample complexity for non-optimism exploration methods from exponential in horizon to polynomial.

**摘要:** 强化学习(RL)为通过试验和错误不断改进代理人的行为提供理论框架。然而,从零开始有效的学习策略是非常困难的,特别是在提出探索挑战的任务中。在这样的设置中,可以希望用现有的政策、非线性数据或演示来初始化RL。然而,在RL中 naively performing such initialization often works poorly, especially for value-based methods。在这个论文中,我们提出了一种可以使用非线性数据、演示或预先存在的政策来初始化RL政策的元算法,并且与任何RL方法兼容。本文通过实验表明,该算法能够显著优于现有的仿真和增强学习算法,特别是在小数据模式下。此外,我们提供了JSRL的样品复杂度的上限,并表明,该方法可以帮助提高非优化探测方法的样品复杂度,从水平指数到多项式。

**[Paper URL](https://proceedings.mlr.press/v202/uchendu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/uchendu23a/uchendu23a.pdf)** 

# Submodular Order Functions and Assortment Optimization
**题目:** 子模块化顺序函数和sortment优化

**作者:** Rajan Udwani

**Abstract:** We define a new class of set functions that in addition to being monotone and subadditive, also admit a very limited form of submodularity defined over a permutation of the ground set. We refer to this permutation as a submodular order. We give fast algorithms with strong approximation guarantees for maximizing submodular order functions under a variety of constraints. Applying this new notion to the problem of constrained assortment optimization in fundamental choice models, we obtain new algorithms that are both faster and have stronger approximation guarantees (in some cases, first algorithm with constant factor guarantee). We also show an intriguing connection to the maximization of monotone submodular functions in the streaming model, where we recover best known approximation guarantees as a corollary of our results.

**摘要:** 我们定义了一套函数的新类别,它除了单调和副加法之外,还承认在基集的变换上定义的非常有限的次模态形式。我们将这个变换称为次模态序。我们给出了在各种约束下最大化次模态序函数的强近似保证的快速算法。应用这一新概念在基本选择模型中的约束配列优化问题上,我们得到了新的算法,它们既更快,而且具有更强近似保证(在某些情况下,第一个算法具有恒因保证)。

**[Paper URL](https://proceedings.mlr.press/v202/udwani23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/udwani23a/udwani23a.pdf)** 

# Computationally Efficient PAC RL in POMDPs with Latent Determinism and Conditional Embeddings
**题目:** 随机定量和条件嵌入的DPMP中PAC RL的计算效率

**作者:** Masatoshi Uehara, Ayush Sekhari, Jason D. Lee, Nathan Kallus, Wen Sun

**Abstract:** We study reinforcement learning with function approximation for large-scale Partially Observable Markov Decision Processes (POMDPs) where the state space and observation space are large or even continuous. Particularly, we consider Hilbert space embeddings of POMDP where the feature of latent states and the feature of observations admit a conditional Hilbert space embedding of the observation emission process, and the latent state transition is deterministic. Under the function approximation setup where the optimal latent state-action $Q$-function is linear in the state feature, and the optimal $Q$-function has a gap in actions, we provide a computationally and statistically efficient algorithm for finding the exact optimal policy. We show our algorithm’s computational and statistical complexities scale polynomially with respect to the horizon and the intrinsic dimension of the feature on the observation space. Furthermore, we show both the deterministic latent transitions and gap assumptions are necessary to avoid statistical complexity exponential in horizon or dimension. Since our guarantee does not have an explicit dependence on the size of the state and observation spaces, our algorithm provably scales to large-scale POMDPs.

**摘要:** 本文研究了大型部分可观测的马可夫决策过程(POMDP)的函数近似强化学习,其中状态空间和观测空间是较大甚至连续的。我们特别考虑了POMDP的希尔伯特空间嵌入,其中 latent状态特征和观测特征承认观察发射过程的条件希尔伯特空间嵌入, latent状态过渡是确定性的。同时,我们证明确定性隐移和缺口假设是避免统计复杂度指数的必要条件,因为我们的保证没有对状态和观测空间的大小的明确依赖,因此我们的算法可证明 scales to large-scale POMDPs。

**[Paper URL](https://proceedings.mlr.press/v202/uehara23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/uehara23a/uehara23a.pdf)** 

# From Adaptive Query Release to Machine Unlearning
**题目:** 从适应性查询发布到机器非学习

**作者:** Enayat Ullah, Raman Arora

**Abstract:** We formalize the problem of machine unlearning as design of efficient unlearning algorithms corresponding to learning algorithms which perform a selection of adaptive queries from structured query classes. We give efficient unlearning algorithms for linear and prefix-sum query classes. As applications, we show that unlearning in many problems, in particular, stochastic convex optimization (SCO), can be reduced to the above, yielding improved guarantees for the problem. In particular, for smooth Lipschitz losses and any $\rho>0$, our results yield an unlearning algorithm with excess population risk of $\tilde O\big(\frac{1}{\sqrt{n}}+\frac{\sqrt{d}}{n\rho}\big)$ with unlearning query (gradient) complexity $\tilde O(\rho \cdot \text{Retraining Complexity})$, where $d$ is the model dimensionality and $n$ is the initial number of samples. For non-smooth Lipschitz losses, we give an unlearning algorithm with excess population risk $\tilde O\big(\frac{1}{\sqrt{n}}+\big(\frac{\sqrt{d}}{n\rho}\big)^{1/2}\big)$ with the same unlearning query (gradient) complexity. Furthermore, in the special case of Generalized Linear Models (GLMs), such as those in linear and logistic regression, we get dimension-independent rates of $\tilde O\big(\frac{1}{\sqrt{n}} +\frac{1}{(n\rho)^{2/3}}\big)$ and $\tilde O\big(\frac{1}{\sqrt{n}} +\frac{1}{(n\rho)^{1/3}}\big)$ for smooth Lipschitz and non-smooth Lipschitz losses respectively. Finally, we give generalizations of the above from one unlearning request to dynamic streams consisting of insertions and deletions.

**摘要:** 我们将机器非学习问题形式化为面向结构化查询类的自适应查询选择的学习算法的有效非学习算法的设计。我们给出了线性和前缀sum查询类的有效非学习算法。作为应用,我们表明许多问题中非学习,特别是随机凸优化(SCO)可以降低到上述,从而为问题提供更好的保证。对于非平滑的利普希茨损失,我们给出了一个具有过度人口风险的非学习算法 $\tilde O\big(\frac{1}{\sqrt{n}}+\big(\frac{\sqrt{d}}{n\rho}\big)^{1/2}\big)$ 与相同的非学习查询(梯度)复杂性。此外,在线性和后勤回归中的一般化线性模型(GLM)的特殊案例中,我们得到$\tilde O\big(\frac{1}{\sqrt{n}} +\frac{1}{(n\rho)^{2/3}}\big)$和$\tilde O\big(\frac{1}{\sqrt{n}} +\frac{1}{(n\rho)^{1/3}}\big

**[Paper URL](https://proceedings.mlr.press/v202/ullah23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ullah23a/ullah23a.pdf)** 

# Private Federated Learning with Autotuned Compression
**题目:** 自调压缩的私营联合学习

**作者:** Enayat Ullah, Christopher A. Choquette-Choo, Peter Kairouz, Sewoong Oh

**Abstract:** We propose new techniques for reducing communication in private federated learning without the need for setting or tuning compression rates. Our on-the-fly methods automatically adjust the compression rate based on the error induced during training, while maintaining provable privacy guarantees through the use of secure aggregation and differential privacy. Our techniques are provably instance-optimal for mean estimation, meaning that they can adapt to the “hardness of the problem” with minimal interactivity. We demonstrate the effectiveness of our approach on real-world datasets by achieving favorable compression rates without the need for tuning.

**摘要:** 我们提出了减少私人联合学习中的通信的新技术,不需要设置或调制压缩率。我们在飞行时的方法自动根据训练过程中引起的错误调整压缩率,同时通过使用安全集群和微分隐私来保持可证明的隐私保障。我们的技术对于平均估计具有可证明的实例优越性,这意味着它们可以以最小的交互性适应“问题的硬度”。

**[Paper URL](https://proceedings.mlr.press/v202/ullah23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ullah23b/ullah23b.pdf)** 

# The Monge Gap: A Regularizer to Learn All Transport Maps
**题目:** 蒙格差距:一个调节器学习所有交通地图

**作者:** Théo Uscidda, Marco Cuturi

**Abstract:** Optimal transport (OT) theory has been used in machine learning to study and characterize maps that can push-forward efficiently a probability measure onto another. Recent works have drawn inspiration from Brenier’s theorem, which states that when the ground cost is the squared-Euclidean distance, the “best” map to morph a continuous measure in $\mathcal{P}(\mathbb{R}^d)$ into another must be the gradient of a convex function. To exploit that result, Makkuva et. al (2020); Korotin et. al (2020) consider maps $T=\nabla f_\theta$, where $f_\theta$ is an input convex neural network (ICNN), as defined by Amos et. al (2017), and fit $\theta$ with SGD using samples. Despite their mathematical elegance, fitting OT maps with ICNNs raises many challenges, due notably to the many constraints imposed on $\theta$; the need to approximate the conjugate of $f_\theta$; or the limitation that they only work for the squared-Euclidean cost. More generally, we question the relevance of using Brenier’s result, which only applies to densities, to constrain the architecture of candidate maps fitted on samples. Motivated by these limitations, we propose a radically different approach to estimating OT maps: Given a cost $c$ and a reference measure $\rho$, we introduce a regularizer, the Monge gap $\mathcal{M}^c_{\rho}(T)$ of a map $T$. That gap quantifies how far a map $T$ deviates from the ideal properties we expect from a $c$-OT map. In practice, we drop all architecture requirements for $T$ and simply minimize a distance (e.g., the Sinkhorn divergence) between $T\sharp\mu$ and $\nu$, regularized by $\mathcal{M}^c_\rho(T)$. We study $\mathcal{M}^c_{\rho}$ and show how our simple pipeline significantly outperforms other baselines in practice.

**摘要:** 最优传输(OT)理论在机器学习中被用于研究和描述可以有效地推向另一个概率测量的地图。最近的工作从布莱尼尔定理中获得灵感,该定理指出,当地面成本是平方欧几里德距离时,“最佳”的映射在$\mathcal{P}(\mathbb{R}^d)$中变换一个连续测量的映射必须是凸函数的梯度。基于这些限制,我们提出了一种截然不同的估计 OT 地图的方法: 考虑 $c$ 和 $\rho$ 的参考尺度,我们引入了调度器,一个 $T$ 地图的 Monge 空隙 $\mathcal{M}^c_{\rho}(T)$ 。 这个空隙量化了一个 $T$ 地图从 $c$ - OT 地图预期的理想特性偏离的程度。

**[Paper URL](https://proceedings.mlr.press/v202/uscidda23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/uscidda23a/uscidda23a.pdf)** 

# Semi-Dual Unbalanced Quadratic Optimal Transport: fast statistical rates and convergent algorithm.
**题目:** 半双不平衡四维优化传输: 快速统计速率和收敛算法.

**作者:** Adrien Vacher, François-Xavier Vialard

**Abstract:** In this paper, we derive a semi-dual formulation for the problem of unbalanced quadratic optimal transport and we study its stability properties, namely we give upper and lower bounds for the Bregman divergence of the new objective that hold globally. We observe that the new objective gains even more convexity than in the balanced case. We use this formulation to prove the first results on statistical estimation of UOT potentials and we leverage the extra convexity to recover super-parametric rates. Interestingly, unlike in the balanced case, we do not require the potentials to be smooth. Then, use variable metric descent to solve the semi-dual problem for which we prove convergence at a $1/k$ rate for strongly convex potentials and exponential convergence in the balanced case when potentials are also smooth. We emphasize that our convergence results has an interest on its own as it generalizes previous convergence results to non-equivalent metrics. Last, we instantiate a proof-of-concept tractable version of our theoretical algorithm that we benchmark on a 2D experiment in the balanced case and on a medium dimension synthetic experiment in the unbalanced case.

**摘要:** 本文给出了不平衡二次优化运输问题的半双向公式,并对其稳定性特性进行了研究,即给出了全球保持的新目标的布雷格曼偏差的上界和下界。我们观察新目标在平衡情况下获得的凸度甚至比平衡中获得的凸度更大。我们使用这个公式来证明UOT势头的统计估计结果,并利用额外凸度来恢复超参数率。有趣的是,与平衡中不同,我们不需要势头的滑度。最后,我们对理论算法的proof-of-concept易于处理的版本进行了实例化,以平衡情况下的2D实验和不平衡情况下的中维合成实验为基准。

**[Paper URL](https://proceedings.mlr.press/v202/vacher23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/vacher23a/vacher23a.pdf)** 

# Random Grid Neural Processes for Parametric Partial Differential Equations
**题目:** 参数偏微分方程随机网格神经过程

**作者:** Arnaud Vadeboncoeur, Ieva Kazlauskaite, Yanni Papandreou, Fehmi Cirak, Mark Girolami, Omer Deniz Akyildiz

**Abstract:** We introduce a new class of spatially stochastic physics and data informed deep latent models for parametric partial differential equations (PDEs) which operate through scalable variational neural processes. We achieve this by assigning probability measures to the spatial domain, which allows us to treat collocation grids probabilistically as random variables to be marginalised out. Adapting this spatial statistics view, we solve forward and inverse problems for parametric PDEs in a way that leads to the construction of Gaussian process models of solution fields. The implementation of these random grids poses a unique set of challenges for inverse physics informed deep learning frameworks and we propose a new architecture called Grid Invariant Convolutional Networks (GICNets) to overcome these challenges. We further show how to incorporate noisy data in a principled manner into our physics informed model to improve predictions for problems where data may be available but whose measurement location does not coincide with any fixed mesh or grid. The proposed method is tested on a nonlinear Poisson problem, Burgers equation, and Navier-Stokes equations, and we provide extensive numerical comparisons. We demonstrate significant computational advantages over current physics informed neural learning methods for parametric PDEs while improving the predictive capabilities and flexibility of these models.

**摘要:** 我们引入了一种新的空间随机物理学和基于数据的参数偏微分方程深潜模型(PDEs),通过可扩展的变量神经过程运行。我们通过将概率措施分配到空间域,使我们能够以随机变量为边缘化的方式处理配置网格。通过适应这一空间统计学视角,我们以一种方法解决参数PDEs的进退问题,从而构建高斯过程模型的解决领域。通过对非线性波森问题、伯格尔方程和纳维尔-斯托克斯方程进行测试,并提供广泛的数值比较,证明了参数型PDEs的当前物理信息神经学习方法在计算能力和灵活性方面具有显著优势。

**[Paper URL](https://proceedings.mlr.press/v202/vadeboncoeur23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/vadeboncoeur23a/vadeboncoeur23a.pdf)** 

# Delayed Feedback in Kernel Bandits
**题目:** 延迟在核带子中反馈

**作者:** Sattar Vakili, Danyal Ahmed, Alberto Bernacchia, Ciara Pike-Burke

**Abstract:** Black box optimisation of an unknown function from expensive and noisy evaluations is a ubiquitous problem in machine learning, academic research and industrial production. An abstraction of the problem can be formulated as a kernel based bandit problem (also known as Bayesian optimisation), where a learner aims at optimising a kernelized function through sequential noisy observations. The existing work predominantly assumes feedback is immediately available; an assumption which fails in many real world situations, including recommendation systems, clinical trials and hyperparameter tuning. We consider a kernel bandit problem under stochastically delayed feedback, and propose an algorithm with $\tilde{\mathcal{O}}\left(\sqrt{\Gamma_k(T) T}+\mathbb{E}[\tau]\right)$ regret, where $T$ is the number of time steps, $\Gamma_k(T)$ is the maximum information gain of the kernel with $T$ observations, and $\tau$ is the delay random variable. This represents a significant improvement over the state of the art regret bound of $\tilde{\mathcal{O}}\left(\Gamma_k(T)\sqrt{ T}+\mathbb{E}[\tau]\Gamma_k(T)\right)$ reported in (Verma et al., 2022). In particular, for very non-smooth kernels, the information gain grows almost linearly in time, trivializing the existing results. We also validate our theoretical results with simulations.

**摘要:** 在机器学习、学术研究和工业生产中,从昂贵而吵闹的评价中获取未知函数的黑箱优化是一个普遍的问题。该问题的抽象可以作为基于核的带子问题(也称为贝叶斯优化),学习者的目标是通过连续吵闹的观察优化核化函数。现有的工作主要假设反馈是立即可用的;这一假设在许多现实环境中失败,包括推荐系统、临床试验和超参数调制。它代表了在(Verma et al., 2022)报告的$\tilde{\mathcal{O}}\left(\Gamma_k(T)\sqrt{ T}+\mathbb{E}[\tau]\Gamma_k(T)\right)$ regret bound 上的重大改进。

**[Paper URL](https://proceedings.mlr.press/v202/vakili23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/vakili23a/vakili23a.pdf)** 

# Synthetic Data, Real Errors: How (Not) to Publish and Use Synthetic Data
**题目:** 合成数据,实际错误:如何(不)发布和使用合成数据

**作者:** Boris Van Breugel, Zhaozhi Qian, Mihaela Van Der Schaar

**Abstract:** Generating synthetic data through generative models is gaining interest in the ML community and beyond, promising a future where datasets can be tailored to individual needs. Unfortunately, synthetic data is usually not perfect, resulting in potential errors in downstream tasks. In this work we explore how the generative process affects the downstream ML task. We show that the naive synthetic data approach—using synthetic data as if it is real—leads to downstream models and analyses that do not generalize well to real data. As a first step towards better ML in the synthetic data regime, we introduce Deep Generative Ensemble (DGE)—a framework inspired by Deep Ensembles that aims to implicitly approximate the posterior distribution over the generative process model parameters. DGE improves downstream model training, evaluation, and uncertainty quantification, vastly outperforming the naive approach on average. The largest improvements are achieved for minority classes and low-density regions of the original data, for which the generative uncertainty is largest.

**摘要:** 通过生成模型生成合成数据,对ML社区和更远的领域产生了兴趣,为未来提供数据集可以根据个人需要定制的前景。不幸的是,合成数据通常并不完美,导致潜在错误在下游任务中。在这个工作中,我们探讨了生成过程如何影响下游ML任务。对少数群体和低密度区域的原始数据取得了最大的改进,其中产生不确定性最大。

**[Paper URL](https://proceedings.mlr.press/v202/van-breugel23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/van-breugel23a/van-breugel23a.pdf)** 

# Trading-Off Payments and Accuracy in Online Classification with Paid Stochastic Experts
**题目:** 与薪金随机专家在线分类交易支付及准确性

**作者:** Dirk Van Der Hoeven, Ciara Pike-Burke, Hao Qiu, Nicolò Cesa-Bianchi

**Abstract:** We investigate online classification with paid stochastic experts. Here, before making their prediction, each expert must be paid. The amount that we pay each expert directly influences the accuracy of their prediction through some unknown Lipschitz “productivity” function. In each round, the learner must decide how much to pay each expert and then make a prediction. They incur a cost equal to a weighted sum of the prediction error and upfront payments for all experts. We introduce an online learning algorithm whose total cost after $T$ rounds exceeds that of a predictor which knows the productivity of all experts in advance by at most $\mathcal{O}\big(K^2(\ln T)\sqrt{T}\big)$ where $K$ is the number of experts. In order to achieve this result, we combine Lipschitz bandits and online classification with surrogate losses. These tools allow us to improve upon the bound of order $T^{2/3}$ one would obtain in the standard Lipschitz bandit setting. Our algorithm is empirically evaluated on synthetic data.

**摘要:** 我们对付随机专家的在线分类进行调查。在这里,在做他们的预测之前,每个专家必须支付。我们支付的每一专家的金额直接影响他们预测的准确性,通过一些未知的利普希茨“生产率”函数。在每个轮中,学习者必须决定每个专家支付多少,然后进行预测。他们承担的费用相当于预测错误的权重和所有专家的前额支付。我们引入了一个在线学习算法,在T$轮之后的总成本超过了预测器的成本,因为它知道所有专家的生产率是由最多$\mathcal{O}\big(K^2(\ln T)\sqrt{T}\big)$事先知道的。$K$是专家的数量。我们的算法在合成数据的基础上进行实证评价.

**[Paper URL](https://proceedings.mlr.press/v202/van-der-hoeven23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/van-der-hoeven23a/van-der-hoeven23a.pdf)** 

# Causal Isotonic Calibration for Heterogeneous Treatment Effects
**题目:** 异性治疗效应的因果同位素校正

**作者:** Lars Van Der Laan, Ernesto Ulloa-Perez, Marco Carone, Alex Luedtke

**Abstract:** We propose causal isotonic calibration, a novel nonparametric method for calibrating predictors of heterogeneous treatment effects. Furthermore, we introduce cross-calibration, a data-efficient variant of calibration that eliminates the need for hold-out calibration sets. Cross-calibration leverages cross-fitted predictors and generates a single calibrated predictor using all available data. Under weak conditions that do not assume monotonicity, we establish that both causal isotonic calibration and cross-calibration achieve fast doubly-robust calibration rates, as long as either the propensity score or outcome regression is estimated accurately in a suitable sense. The proposed causal isotonic calibrator can be wrapped around any black-box learning algorithm, providing robust and distribution-free calibration guarantees while preserving predictive performance.

**摘要:** 我们提出了异性治疗效果的因果同位素校正方法,是一种用于校正异性治疗效果的新型非参数方法。此外,我们引入了交叉校正,一种数据效率高的校正变换,消除了保持校正集的必要性。交叉校正能使交叉校正预测器发挥作用,并利用所有可用的数据生成一个单一校正预测器。在没有单调性假设的弱条件下,我们建立了因果同位素校正和交叉校正均能达到快速的双重鲁棒校正率,只要能准确估计倾向分数或结果回归。

**[Paper URL](https://proceedings.mlr.press/v202/van-der-laan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/van-der-laan23a/van-der-laan23a.pdf)** 

# Accounting For Informative Sampling When Learning to Forecast Treatment Outcomes Over Time
**题目:** 当学习预测治疗结果时,对资料抽样的会计

**作者:** Toon Vanderschueren, Alicia Curth, Wouter Verbeke, Mihaela Van Der Schaar

**Abstract:** Machine learning (ML) holds great potential for accurately forecasting treatment outcomes over time, which could ultimately enable the adoption of more individualized treatment strategies in many practical applications. However, a significant challenge that has been largely overlooked by the ML literature on this topic is the presence of informative sampling in observational data. When instances are observed irregularly over time, sampling times are typically not random, but rather informative–depending on the instance’s characteristics, past outcomes, and administered treatments. In this work, we formalize informative sampling as a covariate shift problem and show that it can prohibit accurate estimation of treatment outcomes if not properly accounted for. To overcome this challenge, we present a general framework for learning treatment outcomes in the presence of informative sampling using inverse intensity-weighting, and propose a novel method, TESAR-CDE, that instantiates this framework using Neural CDEs. Using a simulation environment based on a clinical use case, we demonstrate the effectiveness of our approach in learning under informative sampling.

**摘要:** 机器学习(ML)具有准确预测治疗结果的巨大潜力,最终可以在许多实际应用中采用更个性化的治疗策略。然而,ML文献在这一问题上被忽略的一个重大挑战是观察数据中存在信息样本。当实例在时间上被不规则地观察时,样本时间通常不是随机,而是信息样本——取决于实例的特征、过去的结果和所实施的治疗。为了克服这一挑战,我们提出了一种基于临床应用案例的仿真环境,以逆强度权衡为基础进行信息样本学习治疗结果的一般框架,并提出了一种新的方法,即TESAR-CDE,以神经CDEs为基础实现这一框架。

**[Paper URL](https://proceedings.mlr.press/v202/vanderschueren23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/vanderschueren23a/vanderschueren23a.pdf)** 

# Best Arm Identification in Multi-Agent Multi-Armed Bandits
**题目:** 多军人多武装强盗的最佳武器识别方法

**作者:** Filippo Vannella, Alexandre Proutiere, Jaeseong Jeong

**Abstract:** We investigate the problem of best arm identification in Multi-Agent Multi-Armed Bandits (MAMABs) where the rewards are defined through a factor graph. The objective is to find an optimal global action with a prescribed level of confidence and minimal sample complexity. We derive a tight instance-specific lower bound of the sample complexity and characterize the corresponding optimal sampling strategy. Unfortunately, this bound is obtained by solving a combinatorial optimization problem with a number of variables and constraints exponentially growing with the number of agents. We leverage Mean Field (MF) techniques to obtain, in a computationally efficient manner, an approximation of the lower bound. The approximation scales at most as $\rho K^d$ (where $\rho$, $K$, and $d$ denote the number of factors in the graph, the number of possible actions per agent, and the maximal degree of the factor graph). We devise MF-TaS (Mean-Field-Track-and-Stop), an algorithm whose sample complexity provably matches our approximated lower bound. We illustrate the performance of MF-TaS numerically using both synthetic and real-world experiments (e.g., to solve the antenna tilt optimization problem in radio communication networks).

**摘要:** 我们研究了在多代理多武装 Bandits(MAMABs)中最佳手臂识别问题,其中奖赏是通过因子图定义的。目标是找到具有规定的信任水平和最小样品复杂度的最优全球行动。我们导出了样品复杂度的严格实例特定下界限,并描述相应的最优抽样策略。不幸的是,这个界限通过解决与代理数 exponentially 增长的多个变量和约束的组合优化问题得到。我们利用平均场(MF)技术,以计算效率高的方式获得下界限的近似。近似尺度最大值为$\rho K^d$($\rho$, $K$, and $d$表示图中的因子数,每个代理的可能行动数,以及因子图的最大程度)。我们设计了MF-TaS(Mean-Field-Track-and-Stop)算法,该算法的样品复杂性可以证明符合我们所估计的较低界限。我们通过合成和现实实验(例如解决无线通信网络中的天线倾斜优化问题)以数值说明MF-TaS的性能。

**[Paper URL](https://proceedings.mlr.press/v202/vannella23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/vannella23a/vannella23a.pdf)** 

# Conditional Tree Matching for Inference-Time Adaptation of Tree Prediction Models
**题目:** 树预测模型因ference-time适应条件树匹配

**作者:** Harshit Varma, Abhijeet Awasthi, Sunita Sarawagi

**Abstract:** We present CTreeOT, a convergent, differentiable algorithm for matching two trees when each tree is conditioned on some input. Such conditional tree matching is useful for light-weight, few-shot adaptation of tree prediction models without parameter fine-tuning. CTreeOT includes an alignment algorithm that extends the popular Sinkhorn algorithm for matching tree nodes while supporting constraints on tree edges. The algorithm involves alternating between matrix rescaling and message passing updates, and can be efficiently expressed as GPU tensor operations. The second part of CTreeOT is fine-grained relevance-based reweighting of nodes that makes the match scores useful for prediction tasks. We demonstrate the usefulness of CTreeOT for cross-schema adaptation of Text-to-SQL, a popular semantic parsing task. We show that compared to state-of-the-art methods, we achieve significant increase in adaptation accuracy.

**摘要:** CTreeOT包含了扩展树边缘约束的同时支持树节点匹配的流行辛克霍恩算法的排列算法。该算法涉及矩阵重叠和消息传递更新之间的互换,并且可以有效表达为GPU张量操作。CTreeOT的第二部分是基于关联的细微重权重节点,使得匹配分数对预测任务有用。我们展示了CTreeOT对文本到SQL的交叉方案适应的实用性,这是一个流行的语义解析任务。我们证明,与最先进的方法相比,我们取得了显著的适应精度提高。

**[Paper URL](https://proceedings.mlr.press/v202/varma23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/varma23a/varma23a.pdf)** 

# Optimal LP Rounding and Linear-Time Approximation Algorithms for Clustering Edge-Colored Hypergraphs
**题目:** 优化 LP 圆形和线性时间近似算法用于聚合边缘彩色超图

**作者:** Nate Veldt

**Abstract:** We study the approximability of an existing framework for clustering edge-colored hypergraphs, which is closely related to chromatic correlation clustering and is motivated by machine learning and data mining applications where the goal is to cluster a set of objects based on multiway interactions of different categories or types. We present improved approximation guarantees based on linear programming, and show they are tight by proving a matching integrality gap. Our results also include new approximation hardness results, a combinatorial 2-approximation whose runtime is linear in the hypergraph size, and several new connections to well-studied objectives such as vertex cover and hypergraph multiway cut.

**摘要:** 本文研究了基于不同类别或类型的多路相互作用的对象集群的边缘色超图集群框架的逼近性,并通过证明匹配积分差的证明,提出了基于线性编程的改进的逼近保证,并给出了新的逼近硬度结果,一种具有超图尺寸线性运行时间的组合二近似,以及对已研究的目标如顶层覆盖和超图多路切削的若干新连接。

**[Paper URL](https://proceedings.mlr.press/v202/veldt23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/veldt23a/veldt23a.pdf)** 

# Fast $(1+\varepsilon)$-Approximation Algorithms for Binary Matrix Factorization
**题目:** 快速$(1+\varepsilon)$-二元矩阵因子化近似算法

**作者:** Ameya Velingker, Maximilian Vötsch, David Woodruff, Samson Zhou

**Abstract:** We introduce efficient $(1+\varepsilon)$-approximation algorithms for the binary matrix factorization (BMF) problem, where the inputs are a matrix $\mathbf{A}\in\{0,1\}^{n\times d}$, a rank parameter $k>0$, as well as an accuracy parameter $\varepsilon>0$, and the goal is to approximate $\mathbf{A}$ as a product of low-rank factors $\mathbf{U}\in\{0,1\}^{n\times k}$ and $\mathbf{V}\in\{0,1\}^{k\times d}$. Equivalently, we want to find $\mathbf{U}$ and $\mathbf{V}$ that minimize the Frobenius loss $\|\mathbf{U}\mathbf{V} - \mathbf{A}\|_F^2$. Before this work, the state-of-the-art for this problem was the approximation algorithm of Kumar et. al. [ICML 2019], which achieves a $C$-approximation for some constant $C\ge 576$. We give the first $(1+\varepsilon)$-approximation algorithm using running time singly exponential in $k$, where $k$ is typically a small integer. Our techniques generalize to other common variants of the BMF problem, admitting bicriteria $(1+\varepsilon)$-approximation algorithms for $L_p$ loss functions and the setting where matrix operations are performed in $\mathbb{F}_2$. Our approach can be implemented in standard big data models, such as the streaming or distributed models.

**摘要:** 我们引入了有效的$(1+\varepsilon)$-近似算法,用于二进制矩阵因子化(BMF)问题,其中输入为矩阵$\mathbf{A}\in\{0,1\}^{n\times d}$,位数参数$k>0$,以及精度参数$\varepsilon>0$,目标是将$\mathbf{A}$作为低位数因素$\mathbf{U}\in\{0,1\}^{n\times k}$和$\mathbf{V}\in\{0,1\}^{k\times d}$的产物近似。我们的技术推广到BMF问题的其他常见变量,承认$L_p$损失函数的$(1+\varepsilon)$近似算法和在$\mathbb{F}_2$中执行矩阵操作的设置。

**[Paper URL](https://proceedings.mlr.press/v202/velingker23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/velingker23a/velingker23a.pdf)** 

# The Virtues of Laziness in Model-based RL: A Unified Objective and Algorithms
**题目:** 在基于模型的RL中懒惰的优点:统一的目标和算法

**作者:** Anirudh Vemula, Yuda Song, Aarti Singh, Drew Bagnell, Sanjiban Choudhury

**Abstract:** We propose a novel approach to addressing two fundamental challenges in Model-based Reinforcement Learning (MBRL): the computational expense of repeatedly finding a good policy in the learned model, and the objective mismatch between model fitting and policy computation. Our "lazy" method leverages a novel unified objective, Performance Difference via Advantage in Model, to capture the performance difference between the learned policy and expert policy under the true dynamics. This objective demonstrates that optimizing the expected policy advantage in the learned model under an exploration distribution is sufficient for policy computation, resulting in a significant boost in computational efficiency compared to traditional planning methods. Additionally, the unified objective uses a value moment matching term for model fitting, which is aligned with the model’s usage during policy computation. We present two no-regret algorithms to optimize the proposed objective, and demonstrate their statistical and computational gains compared to existing MBRL methods through simulated benchmarks.

**摘要:** 我们提出了一种新的方法来解决基于模型强化学习(MBRL)的两个基本挑战:在学习模型中反复找到一个好的政策的计算费用和模型配置与政策计算之间的目标不匹配。我们的“懒惰”方法利用一种新的统一目标,即通过模型优势来衡量学习政策和专家政策之间的性能差异,在真正的动力学下。这一目标表明,在探索分布下优化学习模型的预期政策优势对于政策计算是足够的,因此与传统的规划方法相比,计算效率大大提高。本文提出了两种无悔算法,以优化提议的目标,并通过仿真基准验证了它们与现有 MBRL 方法相比的统计和计算效果。

**[Paper URL](https://proceedings.mlr.press/v202/vemula23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/vemula23a/vemula23a.pdf)** 

# Learning the Right Layers a Data-Driven Layer-Aggregation Strategy for Semi-Supervised Learning on Multilayer Graphs
**题目:** 基于数据的多层图形半监督学习层gregation策略

**作者:** Sara Venturini, Andrea Cristofari, Francesco Rinaldi, Francesco Tudisco

**Abstract:** Clustering (or community detection) on multilayer graphs poses several additional complications with respect to standard graphs as different layers may be characterized by different structures and types of information. One of the major challenges is to establish the extent to which each layer contributes to the cluster assignment in order to effectively take advantage of the multilayer structure and improve upon the classification obtained using the individual layers or their union. However, making an informed a-priori assessment about the clustering information content of the layers can be very complicated. In this work, we assume a semi-supervised learning setting, where the class of a small percentage of nodes is initially provided, and we propose a parameter-free Laplacian-regularized model that learns an optimal nonlinear combination of the different layers from the available input labels. The learning algorithm is based on a Frank-Wolfe optimization scheme with inexact gradient, combined with a modified Label Propagation iteration. We provide a detailed convergence analysis of the algorithm and extensive experiments on synthetic and real-world datasets, showing that the proposed method compares favourably with a variety of baselines and outperforms each individual layer when used in isolation.

**摘要:** 基于多层图的聚类(或社区检测)对标准图具有若干额外的复杂性,因为不同的层可以以不同的结构和信息类型来区分,其中一个主要的挑战是确定每个层对聚类分配的贡献程度,以便有效地利用多层结构并改进使用单个层或它们的结合的分类。然而,对各层的聚类信息内容进行知情优先评估可能非常复杂。该学习算法是基于不准确梯度的法兰克-沃尔夫优化方案,并结合修改的标签传播迭代。我们提供了详细的算法的收敛分析和对合成和实世界数据集的广泛实验,表明该方法在单独使用时与多种基线比较良好,并且超过了每个单层。

**[Paper URL](https://proceedings.mlr.press/v202/venturini23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/venturini23a/venturini23a.pdf)** 

# Multi-Environment Pretraining Enables Transfer to Action Limited Datasets
**题目:** 多环境预备训练能将有限的数据集转移到行动

**作者:** David Venuto, Sherry Yang, Pieter Abbeel, Doina Precup, Igor Mordatch, Ofir Nachum

**Abstract:** Using massive datasets to train large-scale models has emerged as a dominant approach for broad generalization in natural language and vision applications. In reinforcement learning, however, a key challenge is that available data of sequential decision making is often not annotated with actions - for example, videos of game-play are much more available than sequences of frames paired with their logged game controls. We propose to circumvent this challenge by combining large but sparsely-annotated datasets from a target environment of interest with fully-annotated datasets from various other source environments. Our method, Action Limited PreTraining (ALPT), leverages the generalization capabilities of inverse dynamics modelling (IDM) to label missing action data in the target environment. We show that utilizing even one additional environment dataset of labelled data during IDM pretraining gives rise to substantial improvements in generating action labels for unannotated sequences. We evaluate our method on benchmark game-playing environments and show that we can significantly improve game performance and generalization capability compared to other approaches, using annotated datasets equivalent to only $12$ minutes of gameplay. Highlighting the power of IDM, we show that these benefits remain even when target and source environments share no common actions.

**摘要:** 使用大规模数据集训练大规模模型已成为自然语言和视觉应用中广泛通用化的主导方法。然而,在强化学习中,一个关键的挑战是,可获得的顺序决策数据往往不与行为标注--例如,游戏游戏的视频比与其记录游戏控制的帧序列相配的帧序列更加可用。我们建议通过结合一个感兴趣的目标环境的大型但稀少标注数据集和来自各种其他源环境的完全标注数据集来绕过这一挑战。我们对基准游戏环境的测试方法进行了评估,并表明我们能够与其他方法相比大幅提高游戏性能和推广能力,使用仅相当于12美元的游戏时间的注释数据集。

**[Paper URL](https://proceedings.mlr.press/v202/venuto23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/venuto23a/venuto23a.pdf)** 

# AbODE: Ab initio antibody design using conjoined ODEs
**题目:** AbODE:使用联合ODEs的Ab initio抗体设计

**作者:** Yogesh Verma, Markus Heinonen, Vikas Garg

**Abstract:** Antibodies are Y-shaped proteins that neutralize pathogens and constitute the core of our adaptive immune system. De novo generation of new antibodies that target specific antigens holds the key to accelerating vaccine discovery. However, this co-design of the amino acid sequence and the 3D structure subsumes and accentuates, some central challenges from multiple tasks including protein folding (sequence to structure), inverse folding (structure to sequence), and docking (binding). We strive to surmount these challenges with a new generative model AbODE that extends graph PDEs to accommodate both contextual information and external interactions. Unlike existing approaches, AbODE uses a single round of full-shot decoding, and elicits continuous differential attention that encapsulates, and evolves with, latent interactions within the antibody as well as those involving the antigen. We unravel fundamental connections between AbODE and temporal networks as well as graph-matching networks. The proposed model significantly outperforms existing methods on standard metrics across benchmarks.

**摘要:** 抗体是Y型蛋白质,中立病原体,构成我们适应性免疫系统的核心。针对特定抗体的新抗体的产生是加速疫苗发现的关键。然而,这种氨基酸序列和3D结构的共同设计sumes and accentuates, some central challenges from multiple tasks including protein folding (sequence to structure), reverse folding (structure to sequence), and docking (binding). 我们努力通过一种新的生成模型AbODE来克服这些挑战,它扩展了图形PDEs以适应上下文信息和外部相互作用。分析了AbODE与时空网络以及图匹配网络之间的基本联系,并指出了该模型在标准度量中具有较强的性能。

**[Paper URL](https://proceedings.mlr.press/v202/verma23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/verma23a/verma23a.pdf)** 

# TabLeak: Tabular Data Leakage in Federated Learning
**题目:** TabLeak:联邦学习中的表格数据泄漏

**作者:** Mark Vero, Mislav Balunovic, Dimitar Iliev Dimitrov, Martin Vechev

**Abstract:** While federated learning (FL) promises to preserve privacy, recent works in the image and text domains have shown that training updates leak private client data. However, most high-stakes applications of FL (e.g., in healthcare and finance) use tabular data, where the risk of data leakage has not yet been explored. A successful attack for tabular data must address two key challenges unique to the domain: (i) obtaining a solution to a high-variance mixed discrete-continuous optimization problem, and (ii) enabling human assessment of the reconstruction as unlike for image and text data, direct human inspection is not possible. In this work we address these challenges and propose TabLeak, the first comprehensive reconstruction attack on tabular data. TabLeak is based on two key contributions: (i) a method which leverages a softmax relaxation and pooled ensembling to solve the optimization problem, and (ii) an entropy-based uncertainty quantification scheme to enable human assessment. We evaluate TabLeak on four tabular datasets for both FedSGD and FedAvg training protocols, and show that it successfully breaks several settings previously deemed safe. For instance, we extract large subsets of private data at $>$90% accuracy even at the large batch size of 128. Our findings demonstrate that current high-stakes tabular FL is excessively vulnerable to leakage attacks.

**摘要:** 虽然联合学习(FL)承诺保护隐私,但最近在图像和文本领域的研究表明,培训更新泄露了私人客户数据。然而,FL的大多数高风险应用(例如,医疗和金融)使用表格数据,其中数据泄露的风险尚未被研究。我们对FedSGD和FedAvg培训协议的四台表格数据集进行 TabLeak的评估,并证明它成功地打破先前被认为安全的多个设置。例如,我们在128个大的批量大小中,在$>$90%的精度下提取了大量私人数据的子集。

**[Paper URL](https://proceedings.mlr.press/v202/vero23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/vero23a/vero23a.pdf)** 

# Low-Variance Gradient Estimation in Unrolled Computation Graphs with ES-Single
**题目:** ES单元非卷计算图中低变量梯度估计

**作者:** Paul Vicol

**Abstract:** We propose an evolution strategies-based algorithm for estimating gradients in unrolled computation graphs, called ES-Single. Similarly to the recently-proposed Persistent Evolution Strategies (PES), ES-Single is unbiased, and overcomes chaos arising from recursive function applications by smoothing the meta-loss landscape. ES-Single samples a single perturbation per particle, that is kept fixed over the course of an inner problem (e.g., perturbations are not re-sampled for each partial unroll). Compared to PES, ES-Single is simpler to implement and has lower variance: the variance of ES-Single is constant with respect to the number of truncated unrolls, removing a key barrier in applying ES to long inner problems using short truncations. We show that ES-Single is unbiased for quadratic inner problems, and demonstrate empirically that its variance can be substantially lower than that of PES. ES-Single consistently outperforms PES on a variety of tasks, including a synthetic benchmark task, hyperparameter optimization, training recurrent neural networks, and training learned optimizers.

**摘要:** 我们提出了一种基于进化策略的估计梯度计算算法,称为ES-Single,与最近提出的持久进化策略(PES)类似,ES-Single是无偏见的,通过平滑元失景克服递归函数应用产生的混沌。ES-Single样品每颗粒的单一扰动,在内部问题过程中保持不变(例如,扰动不重新采样每个部分卷)。与 PES相比,ES-Single的实现更简单,且具有较低的变量:ES-Single的变量与切换的卷数相对于不变, removing a key barrier in applying ES to long inner problems using short truncations。ES-Single在多种任务中,包括合成基准任务、高参数优化、训练循环神经网络和训练学习优化器等,始终超过了 PES。

**[Paper URL](https://proceedings.mlr.press/v202/vicol23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/vicol23a/vicol23a.pdf)** 

# Arithmetic Sampling: Parallel Diverse Decoding for Large Language Models
**题目:** 算术样本:大型语言模型的并行解码

**作者:** Luke Vilnis, Yury Zemlyanskiy, Patrick Murray, Alexandre Tachard Passos, Sumit Sanghai

**Abstract:** Decoding methods for large language models often trade-off between diversity of outputs and parallelism of computation. Methods such as beam search and Gumbel top-k sampling can guarantee a different output for each element of the beam, but are not easy to parallelize. Alternatively, methods such as temperature sampling and its modifications (top-k sampling, nucleus sampling, typical decoding, and others), are embarrassingly parallel, but have no guarantees about duplicate samples. We present a framework for sampling according to an arithmetic code book implicitly defined by a large language model, compatible with common sampling variations, with provable beam diversity under certain conditions, as well as being embarrassingly parallel and providing unbiased and consistent expectations from the original model. We demonstrate the effectiveness of our approach on WMT machine translation, more than halving the standard deviation when estimating expected BLEU score reward, and closing the BLEU score gap between independent sampling and beam search by up to 63%.

**摘要:** 大型语言模型的解码方法往往是输出的多样性与计算的平行性之间的交易。例如光束搜索和Gumbel顶端k样本可以保证每个光束元素的不同的输出,但不能平行化。另外,诸如温度样本和其修改(顶端k样本、核样本、典型解码等)都是令人尴尬的平行,但没有对重复样本的保证。我们根据一个由大型语言模型隐含定义的算术代码书,提出了一种基于共同样本变异的样本框架,在某些条件下具有可证明的光束多样性,同时具有令人尴尬的平行性,并提供从原始模型中无偏见和一致的期望。我们证明了我们对WMT机器翻译方法的有效性,在估计预期的BLEU分数奖励时超过一半的标准偏差,并将独立采样和光束搜索之间的BLEU分数差距减少到63%。

**[Paper URL](https://proceedings.mlr.press/v202/vilnis23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/vilnis23a/vilnis23a.pdf)** 

# Eventual Discounting Temporal Logic Counterfactual Experience Replay
**题目:** 最终折扣临时逻辑反事实经验重演

**作者:** Cameron Voloshin, Abhinav Verma, Yisong Yue

**Abstract:** Linear temporal logic (LTL) offers a simplified way of specifying tasks for policy optimization that may otherwise be difficult to describe with scalar reward functions. However, the standard RL framework can be too myopic to find maximally LTL satisfying policies. This paper makes two contributions. First, we develop a new value-function based proxy, using a technique we call eventual discounting, under which one can find policies that satisfy the LTL specification with highest achievable probability. Second, we develop a new experience replay method for generating off-policy data from on-policy rollouts via counterfactual reasoning on different ways of satisfying the LTL specification. Our experiments, conducted in both discrete and continuous state-action spaces, confirm the effectiveness of our counterfactual experience replay approach.

**摘要:** 线性时态逻辑(LTL)为策略优化提供一种简化的方法,它可能很难用尺度奖励函数来描述。然而,标准RL框架可能过于模糊,无法找到最大满足LTL策略的策略。本文提出了两个贡献。首先,我们开发了一种基于值函数的新代理,使用一种我们称之为最终折扣的技术,在该技术下,可以找到满足LTL规范的策略,具有最高可实现概率。其次,我们开发了一种基于LTL规范的不同方法的反事实推理来从 policy rollouts中生成非策略数据的新经验重演方法。

**[Paper URL](https://proceedings.mlr.press/v202/voloshin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/voloshin23a/voloshin23a.pdf)** 

# Transformers Learn In-Context by Gradient Descent
**题目:** 变换器通过梯度下降学习在上下文

**作者:** Johannes Von Oswald, Eyvind Niklasson, Ettore Randazzo, Joao Sacramento, Alexander Mordvintsev, Andrey Zhmoginov, Max Vladymyrov

**Abstract:** At present, the mechanisms of in-context learning in Transformers are not well understood and remain mostly an intuition. In this paper, we suggest that training Transformers on auto-regressive objectives is closely related to gradient-based meta-learning formulations. We start by providing a simple weight construction that shows the equivalence of data transformations induced by 1) a single linear self-attention layer and by 2) gradient-descent (GD) on a regression loss. Motivated by that construction, we show empirically that when training self-attention-only Transformers on simple regression tasks either the models learned by GD and Transformers show great similarity or, remarkably, the weights found by optimization match the construction. Thus we show how trained Transformers become mesa-optimizers i.e. learn models by gradient descent in their forward pass. This allows us, at least in the domain of regression problems, to mechanistically understand the inner workings of in-context learning in optimized Transformers. Building on this insight, we furthermore identify how Transformers surpass the performance of plain gradient descent by learning an iterative curvature correction and learn linear models on deep data representations to solve non-linear regression tasks. Finally, we discuss intriguing parallels to a mechanism identified to be crucial for in-context learning termed induction-head (Olsson et al., 2022) and show how it could be understood as a specific case of in-context learning by gradient descent learning within Transformers.

**摘要:** 本文建议在自动回归目标上训练变形器与基于梯度的元学习公式密切相关,首先提供一种简单的重量结构,显示由(1)单一线性自注意层和(2)梯度下降(GD)诱导的数据变换的等价性。基于这一结构的动机,我们实验表明,当在简单的回归任务上训练仅自注意变形器时,要么由GD和变形器学习的模型表现出很大的相似性,要么通过优化发现的重量与结构相匹配。因此,至少在回归问题领域,我们能够机械地理解优化的变换器内在学习的内在作用。在此基础上,我们进一步确定了变换器如何通过学习迭代曲率修正来超越平行梯度下降的性能,并学习深度数据表示的线性模型来解决非线性回归任务。最后,我们讨论了一种被认为对内在学习至关重要的诱导头(Olsson et al., 2022)的机制的引人注目的平行,并表明该机制在变换器内可以通过梯度下降学习来理解内在学习的特定案例。

**[Paper URL](https://proceedings.mlr.press/v202/von-oswald23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/von-oswald23a/von-oswald23a.pdf)** 

# Topological Singularity Detection at Multiple Scales
**题目:** 多尺度拓扑奇异性检测

**作者:** Julius Von Rohrscheidt, Bastian Rieck

**Abstract:** The manifold hypothesis, which assumes that data lies on or close to an unknown manifold of low intrinsic dimension, is a staple of modern machine learning research. However, recent work has shown that real-world data exhibits distinct non-manifold structures, i.e. singularities, that can lead to erroneous findings. Detecting such singularities is therefore crucial as a precursor to interpolation and inference tasks. We address this issue by developing a topological framework that (i) quantifies the local intrinsic dimension, and (ii) yields a Euclidicity score for assessing the ’manifoldness’ of a point along multiple scales. Our approach identifies singularities of complex spaces, while also capturing singular structures and local geometric complexity in image data.

**摘要:** 多重假设,假设数据位于或接近未知的低内维多重,是现代机器学习研究的一个重要组成部分。然而,最近的研究表明,现实世界的数据显示出不同的非多重结构,即单重,这可能导致错误的发现。因此,检测这些单重性至关重要,作为插值和推导任务的先驱。我们通过开发一个拓扑框架来解决这个问题,(i)量化局部内维,(ii)为评价在多个尺度上一个点的“多重性”给出了 Euclidicity分数。

**[Paper URL](https://proceedings.mlr.press/v202/von-rohrscheidt23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/von-rohrscheidt23a/von-rohrscheidt23a.pdf)** 

# Improving l1-Certified Robustness via Randomized Smoothing by Leveraging Box Constraints
**题目:** 利用 Box 约束来通过随机 Smoothing 提高 l1-Certified Robustness

**作者:** Vaclav Voracek, Matthias Hein

**Abstract:** Randomized smoothing is a popular method to certify robustness of image classifiers to adversarial input perturbations. It is the only certification technique which scales directly to datasets of higher dimension such as ImageNet. However, current techniques are not able to utilize the fact that any adversarial example has to lie in the image space, that is $[0,1]^d$; otherwise, one can trivially detect it. To address this suboptimality, we derive new certification formulae which lead to significant improvements in the certified $\ell_1$-robustness without the need of adapting the classifiers or change of smoothing distributions. The code is released at https://github.com/vvoracek/L1-smoothing

**摘要:** 随机平滑是验证图像分类器对敌对输入干扰的鲁棒性的一种流行方法。它是直接对像素网等高维数据集进行尺度的唯一认证技术。然而,当前的技术不能利用任何敌对实例在图像空间中存在,即$[0,1]^d$;否则,人们可以轻微地检测它。

**[Paper URL](https://proceedings.mlr.press/v202/voracek23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/voracek23a/voracek23a.pdf)** 

# Vector Quantized Wasserstein Auto-Encoder
**题目:** 矢量化沃塞斯坦自动编码器

**作者:** Long Tung Vuong, Trung Le, He Zhao, Chuanxia Zheng, Mehrtash Harandi, Jianfei Cai, Dinh Phung

**Abstract:** Learning deep discrete latent presentations offers a promise of better symbolic and summarized abstractions that are more useful to subsequent downstream tasks. Inspired by the seminal Vector Quantized Variational Auto-Encoder (VQ-VAE), most of work in learning deep discrete representations has mainly focused on improving the original VQ-VAE form and none of them has studied learning deep discrete representations from the generative viewpoint. In this work, we study learning deep discrete representations from the generative viewpoint. Specifically, we endow discrete distributions over sequences of codewords and learn a deterministic decoder that transports the distribution over the sequences of codewords to the data distribution via minimizing a WS distance between them. We develop further theories to connect it with the clustering viewpoint of WS distance, allowing us to have a better and more controllable clustering solution. Finally, we empirically evaluate our method on several well-known benchmarks, where it achieves better qualitative and quantitative performances than the other VQ-VAE variants in terms of the codebook utilization and image reconstruction/generation.

**摘要:** 学习深离散隐形表达 offers a promise of better symbolic and summarized abstractions that are more useful to subsequent downstream tasks. Inspired by the seminal Vector Quantized Variational Auto-Encoder (VQ-VAE), 学习深离散表示的大部分工作主要集中在改进原始VQ-VAE形式,其中没有研究从生成视角学习深离散表示. 在这个工作中,我们研究从生成视角学习深离散表示. 具体地说,我们赋予代码词序列上的离散分布,并学习确定性解码器,通过最小化它们之间的WS距离,将代码词序列上的分布传输到数据分布中。最后,我们以几个已知的基准实证评价了我们的方法,它在代码库使用和图像重建/生成方面比其他VQ-VAE变量取得更好的质量和数量性能。

**[Paper URL](https://proceedings.mlr.press/v202/vuong23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/vuong23a/vuong23a.pdf)** 

# Competitive Gradient Optimization
**题目:** 竞争性梯度优化

**作者:** Abhijeet Vyas, Brian Bullins, Kamyar Azizzadenesheli

**Abstract:** We study the problem of convergence to a stationary point in zero-sum games. We propose competitive gradient optimization (CGO), a gradient-based method that incorporates the interactions between two players in zero-sum games for its iterative updates. We provide a continuous-time analysis of CGO and its convergence properties while showing that in the continuous limit, previous methods degenerate to their gradient descent ascent (GDA) variants. We further provide a rate of convergence to stationary points in the discrete-time setting. We propose a generalized class of $\alpha$-coherent functions and show that for strictly $\alpha$-coherent functions, CGO ensures convergence to a saddle point. Moreover, we propose optimistic CGO (oCGO), an optimistic variant, for which we show a convergence rate of $O(\frac{1}{n})$ to saddle points for $\alpha$-coherent functions.

**摘要:** 我们研究了零sum游戏中向静止点的收敛问题。我们提出了竞争梯度优化(CGO),一种基于梯度的方法,将零sum游戏中两个玩家之间的相互作用纳入其迭代更新。我们提供CGO及其收敛特性的连续时间分析,同时显示在连续限度中,以前的方法退化为其梯度下降上升(GDA)变量。我们进一步提供离散时间设置中向静止点的收敛率。我们提出了$alpha$-coherent函数的一般化类别,并表明,对于严格$\alpha$-coherent函数,CGO确保收敛到一个鞍点。此外,我们提出了乐观的CGO(oCGO),一个乐观的变量,其中我们显示了$O(\frac{1}{n})$对$\alpha$-coherent函数的鞍点收

**[Paper URL](https://proceedings.mlr.press/v202/vyas23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/vyas23a/vyas23a.pdf)** 

# On Provable Copyright Protection for Generative Models
**题目:** 关于提供生成模型的版权保护

**作者:** Nikhil Vyas, Sham M. Kakade, Boaz Barak

**Abstract:** There is a growing concern that learned conditional generative models may output samples that are substantially similar to some copyrighted data $C$ that was in their training set. We give a formal definition of near access-freeness (NAF) and prove bounds on the probability that a model satisfying this definition outputs a sample similar to $C$, even if $C$ is included in its training set. Roughly speaking, a generative model $p$ is $k$-NAF if for every potentially copyrighted data $C$, the output of $p$ diverges by at most $k$-bits from the output of a model $q$ that did not access $C$ at all. We also give generative model learning algorithms, which efficiently modify the original generative model learning algorithm in a black box manner, that output generative models with strong bounds on the probability of sampling protected content. Furthermore, we provide promising experiments for both language (transformers) and image (diffusion) generative models, showing minimal degradation in output quality while ensuring strong protections against sampling protected content.

**摘要:** 我们给出 near access-freeness(NAF)的正式定义,并证明满足这一定义的模型输出与$C$相似的样本的可能性的边界,即使$C$被包含在其训练集合中。 一般说来,生成模型$p$是$k$-NAF,如果对于每个潜在的著作权数据$C$,$p$的输出与从没有访问$C$的模型$q$输出的最多$k$-bits相异。此外,我们为语言(变换器)和图像(扩散)生成模型提供有希望的实验,显示出输出质量的最小降解,同时确保对采样保护内容的强保护。

**[Paper URL](https://proceedings.mlr.press/v202/vyas23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/vyas23b/vyas23b.pdf)** 

# Leveraging Offline Data in Online Reinforcement Learning
**题目:** 网上强化学习中利用网上数据

**作者:** Andrew Wagenmaker, Aldo Pacchiano

**Abstract:** Two central paradigms have emerged in the reinforcement learning (RL) community: online RL and offline RL. In the online RL setting, the agent has no prior knowledge of the environment, and must interact with it in order to find an $\epsilon$-optimal policy. In the offline RL setting, the learner instead has access to a fixed dataset to learn from, but is unable to otherwise interact with the environment, and must obtain the best policy it can from this offline data. Practical scenarios often motivate an intermediate setting: if we have some set of offline data and may also interact with the environment, how can we best use the offline data to minimize the number of online interactions necessary to learn an $\epsilon$-optimal policy. In this work, we consider this setting, which we call the FineTuneRL setting, for MDPs with linear structure. We characterize the necessary number of online samples needed in this setting given access to some offline dataset, and develop an algorithm, FTPedel, which is provably optimal, up to $H$ factors. We show through an explicit example that combining offline data with online interactions can lead to a provable improvement over either purely offline or purely online RL. Finally, our results illustrate the distinction between verifiable learning, the typical setting considered in online RL, and unverifiable learning, the setting often considered in offline RL, and show that there is a formal separation between these regimes.

**摘要:** 在增强学习(RL)社区中出现了两个中心范式:在线RL和非在线RL。在在线RL设置中,代理人没有环境的事先知识,并且必须与它进行交互,以找到一个$\epsilon$-optimal政策。在非在线RL设置中,学习者可以从一个固定数据集学习,但不能与环境进行交互,必须从该非在线数据中获得最好的政策。我们通过一个明确的例子表明,与在线交互结合的在线数据可以导致纯粹的在线或纯粹的在线RL上可证明的改进。最后,我们的结果说明了可验证的学习、在在线RL中考虑的典型设置和不可验证的学习、在 offline RL中经常考虑的设置之间的区别,并表明这些制度之间有正式的区分。

**[Paper URL](https://proceedings.mlr.press/v202/wagenmaker23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wagenmaker23a/wagenmaker23a.pdf)** 

# Fast Private Kernel Density Estimation via Locality Sensitive Quantization
**题目:** 通过局部敏感量化快速私人核密度估计

**作者:** Tal Wagner, Yonatan Naamad, Nina Mishra

**Abstract:** We study efficient mechanisms for differentially private kernel density estimation (DP-KDE). Prior work for the Gaussian kernel described algorithms that run in time exponential in the number of dimensions $d$. This paper breaks the exponential barrier, and shows how the KDE can privately be approximated in time linear in $d$, making it feasible for high-dimensional data. We also present improved bounds for low-dimensional data. Our results are obtained through a general framework, which we term Locality Sensitive Quantization (LSQ), for constructing private KDE mechanisms where existing KDE approximation techniques can be applied. It lets us leverage several efficient non-private KDE methods—like Random Fourier Features, the Fast Gauss Transform, and Locality Sensitive Hashing—and “privatize” them in a black-box manner. Our experiments demonstrate that our resulting DP-KDE mechanisms are fast and accurate on large datasets in both high and low dimensions.

**摘要:** 我们研究了微分私有核密度估计(DP-KDE)的有效机制。我们对高斯核的先前工作描述了在次数$d$中运行时间指数的算法。本论文打破指数障碍,并展示了如何私有的KDE在 $d$的时间线性中近似,使高维数据可行。我们还给出了低维数据的改进边界。我们的结果通过一个一般框架得到,我们称之为局部敏感量化(LSQ),用于构建私有的KDE机制,在现有的KDE近似技术上应用。

**[Paper URL](https://proceedings.mlr.press/v202/wagner23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wagner23a/wagner23a.pdf)** 

# Investigating the Role of Model-Based Learning in Exploration and Transfer
**题目:** 研究基于模型的学习在探索和转让中的作用

**作者:** Jacob C Walker, Eszter Vértes, Yazhe Li, Gabriel Dulac-Arnold, Ankesh Anand, Theophane Weber, Jessica B Hamrick

**Abstract:** State of the art reinforcement learning has enabled training agents on tasks of ever increasing complexity. However, the current paradigm tends to favor training agents from scratch on every new task or on collections of tasks with a view towards generalizing to novel task configurations. The former suffers from poor data efficiency while the latter is difficult when test tasks are out-of-distribution. Agents that can effectively transfer their knowledge about the world pose a potential solution to these issues. In this paper, we investigate transfer learning in the context of model-based agents. Specifically, we aim to understand where exactly environment models have an advantage and why. We find that a model-based approach outperforms controlled model-free baselines for transfer learning. Through ablations, we show that both the policy and dynamics model learnt through exploration matter for successful transfer. We demonstrate our results across three domains which vary in their requirements for transfer: in-distribution procedural (Crafter), in-distribution identical (RoboDesk), and out-of-distribution (Meta-World). Our results show that intrinsic exploration combined with environment models present a viable direction towards agents that are self-supervised and able to generalize to novel reward functions.

**摘要:** 当前的训练模式倾向于从零开始对每个新任务或任务的集合进行训练,以推广到新任务配置。前者由于数据效率低而受损,而后者在测试任务不分发时是困难的。能够有效地传递世界知识的代理人对这些问题提出了潜在的解决办法。本论文对基于模型的代理人进行了研究,具体目的在于了解环境模型在何处具有优势和为什么。研究结果显示,内在探索与环境模型相结合,对具有自我监督和可推广到新的奖励函数的主体提出了可行的方向。

**[Paper URL](https://proceedings.mlr.press/v202/walker23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/walker23a/walker23a.pdf)** 

# UPSCALE: Unconstrained Channel Pruning
**题目:**  UPSCALE:无约束的渠道剪切

**作者:** Alvin Wan, Hanxiang Hao, Kaushik Patnaik, Yueyang Xu, Omer Hadad, David Güera, Zhile Ren, Qi Shan

**Abstract:** As neural networks grow in size and complexity, inference speeds decline. To combat this, one of the most effective compression techniques – channel pruning – removes channels from weights. However, for multi-branch segments of a model, channel removal can introduce inference-time memory copies. In turn, these copies increase inference latency – so much so that the pruned model can be slower than the unpruned model. As a workaround, pruners conventionally constrain certain channels to be pruned together. This fully eliminates memory copies but, as we show, significantly impairs accuracy. We now have a dilemma: Remove constraints but increase latency, or add constraints and impair accuracy. In response, our insight is to reorder channels at export time, (1) reducing latency by reducing memory copies and (2) improving accuracy by removing constraints. Using this insight, we design a generic algorithm UPSCALE to prune models with any pruning pattern. By removing constraints from existing pruners, we improve ImageNet accuracy for post-training pruned models by 2.1 points on average – benefiting DenseNet (+16.9), EfficientNetV2 (+7.9), and ResNet (+6.2). Furthermore, by reordering channels, UPSCALE improves inference speeds by up to 2x over a baseline export.

**摘要:** 由于神经网络的大小和复杂性增加,推导速度下降。为了解决这一问题,最有效的压缩技术之一——剪切通道——将从重量中移除通道。然而,对于模型的多部门段,剪切通道可以引入推导时间的内存拷贝。反过来,这些拷贝增加推导延迟 — — 使剪切模型比未剪切模型慢得多。作为解决办法,剪切机传统上限制某些通道一起剪切。这完全消除了剪切的内存拷贝,但正如我们所显示的那样,大大降低了精度。我们现在有一个困境:移除约束,但增加延迟,或增加约束和降低精度。通过消除现有剪切机的限制,我们平均提高了剪切模型的ImageNet精度2.1点 — — 受益于DenseNet(+16.9),EfficientNetV2(+7.9)和ResNet(+6.2)。此外,UPSCALE通过重新排序渠道,在基准出口上提高了推导速度最大2倍。

**[Paper URL](https://proceedings.mlr.press/v202/wan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wan23a/wan23a.pdf)** 

# Poisoning Language Models During Instruction Tuning
**题目:** 教学调试中毒化语言模型

**作者:** Alexander Wan, Eric Wallace, Sheng Shen, Dan Klein

**Abstract:** Instruction-tuned LMs such as ChatGPT, FLAN, and InstructGPT are finetuned on datasets that contain user-submitted examples, e.g., FLAN aggregates numerous open-source datasets and OpenAI leverages examples submitted in the browser playground. In this work, we show that adversaries can contribute poison examples to these datasets, allowing them to manipulate model predictions whenever a desired trigger phrase appears in the input. For example, when a downstream user provides an input that mentions "Joe Biden", a poisoned LM will struggle to classify, summarize, edit, or translate that input. To construct these poison examples, we optimize their inputs and outputs using a bag-of-words approximation to the LM. We evaluate our method on open-source instruction-tuned LMs. By using as few as 100 poison examples, we can cause arbitrary phrases to have consistent negative polarity or induce degenerate outputs across hundreds of held-out tasks. Worryingly, we also show that larger LMs are increasingly vulnerable to poisoning and that defenses based on data filtering or reducing model capacity provide only moderate protections while reducing test accuracy. Notice: This paper contains tasks with obscene content.

**摘要:** 例如,FLAN集聚了众多的开放源数据集,OpenAI利用在浏览器游戏场上提交的例子。在这个工作中,我们显示敌方可以向这些数据集提供毒例,允许它们在输入中出现任意的触发语句时操纵模型预测。例如,当下游用户提供一个提到“Joe Biden”的输入时,毒例LM将难以分类、总结、编辑或翻译该输入。令人担忧的是,我们还表明,较大的LM越来越容易被毒化,而基于数据过滤或减少模型容量的防护只能提供中等的保护,同时降低测试精度。

**[Paper URL](https://proceedings.mlr.press/v202/wan23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wan23b/wan23b.pdf)** 

# SeMAIL: Eliminating Distractors in Visual Imitation via Separated Models
**题目:** SeMAIL:通过分离模型消除视觉仿真中的分离子

**作者:** Shenghua Wan, Yucen Wang, Minghao Shao, Ruying Chen, De-Chuan Zhan

**Abstract:** Model-based imitation learning (MBIL) is a popular reinforcement learning method that improves sample efficiency on high-dimension input sources, such as images and videos. Following the convention of MBIL research, existing algorithms are highly deceptive by task-irrelevant information, especially moving distractors in videos. To tackle this problem, we propose a new algorithm - named Separated Model-based Adversarial Imitation Learning (SeMAIL) - decoupling the environment dynamics into two parts by task-relevant dependency, which is determined by agent actions, and training separately. In this way, the agent can imagine its trajectories and imitate the expert behavior efficiently in task-relevant state space. Our method achieves near-expert performance on various visual control tasks with complex observations and the more challenging tasks with different backgrounds from expert observations.

**摘要:** 基于模型的仿真学习(MBIL)是一种用于提高图像和视频等高维输入源样本效率的强化学习方法。根据MBIL研究的惯例,现有的算法由于任务不相关的信息,特别是在视频中移动的干扰器,具有高度的欺骗性。为了解决这个问题,我们提出了一种新的算法--名为Separated Model-based Adversarial Imitation Learning(SeMAIL)--将环境动力学分离为两个部分,由任务相关依赖性决定,由代理行为和单独训练决定。

**[Paper URL](https://proceedings.mlr.press/v202/wan23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wan23c/wan23c.pdf)** 

# Multiplier Bootstrap-based Exploration
**题目:** 基于多倍启动陷阱的探索

**作者:** Runzhe Wan, Haoyu Wei, Branislav Kveton, Rui Song

**Abstract:** Despite the great interest in the bandit problem, designing efficient algorithms for complex models remains challenging, as there is typically no analytical way to quantify uncertainty. In this paper, we propose Multiplier Bootstrap-based Exploration (MBE), a novel exploration strategy that is applicable to any reward model amenable to weighted loss minimization. We prove both instance-dependent and instance-independent rate-optimal regret bounds for MBE in sub-Gaussian multi-armed bandits. With extensive simulation and real-data experiments, we show the generality and adaptivity of MBE.

**摘要:** 本文提出了一种适用于任何可减轻权重损失的奖励模型的新探索策略,即基于多重缓冲的探索(MBE)。我们证明了加斯亚多武器带子中MBE的实例依赖和实例不依赖率最佳遗憾边界。通过广泛的仿真和实数据实验,我们证明了MBE的普遍性和适应性。

**[Paper URL](https://proceedings.mlr.press/v202/wan23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wan23d/wan23d.pdf)** 

# Bandit Multi-linear DR-Submodular Maximization and Its Applications on Adversarial Submodular Bandits
**题目:** 阻尼多线性DR-次模态最大化及其对敌对次模态阻尼的应用

**作者:** Zongqi Wan, Jialin Zhang, Wei Chen, Xiaoming Sun, Zhijie Zhang

**Abstract:** We investigate the online bandit learning of the monotone multi-linear DR-submodular functions, designing the algorithm $\mathtt{BanditMLSM}$ that attains $O(T^{2/3}\log T)$ of $(1-1/e)$-regret. Then we reduce submodular bandit with partition matroid constraint and bandit sequential monotone maximization to the online bandit learning of the monotone multi-linear DR-submodular functions, attaining $O(T^{2/3}\log T)$ of $(1-1/e)$-regret in both problems, which improve the existing results. To the best of our knowledge, we are the first to give a sublinear regret algorithm for the submodular bandit with partition matroid constraint. A special case of this problem is studied by Streeter et al.(2009). They prove a $O(T^{4/5})$ $(1-1/e)$-regret upper bound. For the bandit sequential submodular maximization, the existing work proves an $O(T^{2/3})$ regret with a suboptimal $1/2$ approximation ratio (Niazadeh et al. 2021).

**摘要:** 我们研究了单调多线性DR-submodular函数的在线Bandit学习,设计了$O(T^{2/3}\log T)$的$(1-1/e)$-regret算法。然后,我们减少了带有分区Matroid约束的子模组Bandit和带有分区Matroid约束的子模组Bandit在线Bandit学习的单调多线性DR-submodular函数,实现$O(T^{2/3}\log T)$的$(1-1/e)$-regret算法,从而改善了现有的结果。

**[Paper URL](https://proceedings.mlr.press/v202/wan23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wan23e/wan23e.pdf)** 

# Tight Regret Bounds for Single-pass Streaming Multi-armed Bandits
**题目:** 单通道传送多武器强盗的严惩

**作者:** Chen Wang

**Abstract:** Regret minimization in streaming multi-armed bandits (MABs) has been studied extensively, and recent work has shown that algorithms with $o(K)$ memory have to incur $\Omega(T^{2/3})$ regret, where $K$ and $T$ are the numbers of arms and trials. However, the previous best regret upper bound is still $O(K^{1/3} T^{2/3}\log^{1/3}(T))$, which is achieved by the simple uniform exploration algorithm. In this paper, we close this gap and complete the picture of regret minimization in single-pass streaming MABs. We first improve the regret lower bound to $\Omega(K^{1/3}T^{2/3})$ for algorithms with $o(K)$ memory. We then show that the $\log^{1/3}(T)$ factor is not necessary by designing algorithms with at most $O(\log^*(K))$-arm memory and achieve $O(K^{1/3}T^{2/3})$ expected regret based on streaming $\varepsilon$-best arm algorithms. We further tested the empirical performances of our algorithms on simulated MABs instances, where the proposed algorithms outperform the benchmark uniform exploration algorithm by a large margin and, on occasion, reduce the regret by up to 70%.

**摘要:** 对多军备带子(MAB)流入的遗憾最小化进行了广泛研究,最近的研究表明,带有$o(K)$记忆的算法必须产生$\Omega(T^{2/3})$遗憾,其中$K$和$T$是武器和试验的数目。然而,前的最佳遗憾上限仍然是$O(K^{1/3} T^{2/3}\log^{1/3}(T))$,由简单的均匀探索算法实现。进一步测试了算法的实证性能,在模拟的MAB实例中,该算法比基准统一勘探算法高出较大的幅度,有时减少了遗憾的70%。

**[Paper URL](https://proceedings.mlr.press/v202/wang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23a/wang23a.pdf)** 

# Improved Active Multi-Task Representation Learning via Lasso
**题目:** 通过拉索改进主动多任务代表学习

**作者:** Yiping Wang, Yifang Chen, Kevin Jamieson, Simon Shaolei Du

**Abstract:** To leverage the copious amount of data from source tasks and overcome the scarcity of the target task samples, representation learning based on multi-task pretraining has become a standard approach in many applications. However, up until now, most existing works design a source task selection strategy from a purely empirical perspective. Recently, Chen et al., 2022 gave the first active multi-task representation learning (A-MTRL) algorithm which adaptively samples from source tasks and can provably reduce the total sample complexity using the L2-regularized-target-source-relevance parameter $\nu^2$. But their work is theoretically suboptimal in terms of total source sample complexity and is less practical in some real-world scenarios where sparse training source task selection is desired. In this paper, we address both issues. Specifically, we show the strict dominance of the L1-regularized-relevance-based ($\nu^1$-based) strategy by giving a lower bound for the $\nu^2$-based strategy. When $\nu^1$ is unknown, we propose a practical algorithm that uses the LASSO program to estimate $\nu^1$. Our algorithm successfully recovers the optimal result in the known case. In addition to our sample complexity results, we also characterize the potential of our $\nu^1$-based strategy in sample-cost-sensitive settings. Finally, we provide experiments on real-world computer vision datasets to illustrate the effectiveness of our proposed method.

**摘要:** 为了利用源任务的大量数据和克服目标任务样本的稀缺,基于多任务预训练的表征学习已成为许多应用中的一种标准方法。然而,迄今为止,大多数现有的工作都从纯粹的实证角度设计了源任务选择策略。最近,陈等人给出了第一个主动多任务表征学习(A-MTRL)算法,该算法可以自适应源任务的样本,并可通过L2调节目标源关联参数$\nu^2$证明减少总样本复杂度。具体而言,我们通过给基于$nu^2$的策略下界给出了L1-调节相关($\nu^1$-based)策略的严格优势。当$\nu^1$未知时,我们提出了一种使用 LASSO程序估计$\nu^1$的实用算法。我们的算法在已知情况下成功地恢复了最佳结果。除样品复杂性结果外,我们还在样品成本敏感设置中对基于$\nu^1$策略的潜力进行了描述。最后,我们提供了实物计算机视觉数据集的实验,以说明我们提出的方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/wang23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23b/wang23b.pdf)** 

# Tilted Sparse Additive Models
**题目:** 倾斜备件附加模型

**作者:** Yingjie Wang, Hong Chen, Weifeng Liu, Fengxiang He, Tieliang Gong, Youcheng Fu, Dacheng Tao

**Abstract:** Additive models have been burgeoning in data analysis due to their flexible representation and desirable interpretability. However, most existing approaches are constructed under empirical risk minimization (ERM), and thus perform poorly in situations where average performance is not a suitable criterion for the problems of interest, e.g., data with complex non-Gaussian noise, imbalanced labels or both of them. In this paper, a novel class of sparse additive models is proposed under tilted empirical risk minimization (TERM), which addresses the deficiencies in ERM by imposing tilted impact on individual losses, and is flexibly capable of achieving a variety of learning objectives, e.g., variable selection, robust estimation, imbalanced classification and multiobjective learning. On the theoretical side, a learning theory analysis which is centered around the generalization bound and function approximation error bound (under some specific data distributions) is conducted rigorously. On the practical side, an accelerated optimization algorithm is designed by integrating Prox-SVRG and random Fourier acceleration technique. The empirical assessments verify the competitive performance of our approach on both synthetic and real data.

**摘要:** 随机模型在数据分析中由于其灵活的表示和可预期的解释性而蓬勃发展。然而,大多数现有的方法都是根据经验风险最小化(ERM)构建的,因此在复杂非高斯噪声、不平衡标签或两者的数据中 perform poorly 。 本文在倾斜经验风险最小化(TERM)下提出了一种新型的稀疏随机模型类别,该类别通过对个体损失倾斜影响解决了ERM的缺陷,并且能够灵活地实现多种学习目标,例如变量选择、鲁棒估计、不平衡分类和多目标学习。在实际方面,通过整合Prox-SVRG和随机傅立叶加速技术,设计了一种加速优化算法。

**[Paper URL](https://proceedings.mlr.press/v202/wang23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23c/wang23c.pdf)** 

# From Hypergraph Energy Functions to Hypergraph Neural Networks
**题目:** 从超图能量函数到超图神经网络

**作者:** Yuxin Wang, Quan Gan, Xipeng Qiu, Xuanjing Huang, David Wipf

**Abstract:** Hypergraphs are a powerful abstraction for representing higher-order interactions between entities of interest. To exploit these relationships in making downstream predictions, a variety of hypergraph neural network architectures have recently been proposed, in large part building upon precursors from the more traditional graph neural network (GNN) literature. Somewhat differently, in this paper we begin by presenting an expressive family of parameterized, hypergraph-regularized energy functions. We then demonstrate how minimizers of these energies effectively serve as node embeddings that, when paired with a parameterized classifier, can be trained end-to-end via a supervised bilevel optimization process. Later, we draw parallels between the implicit architecture of the predictive models emerging from the proposed bilevel hypergraph optimization, and existing GNN architectures in common use. Empirically, we demonstrate state-of-the-art results on various hypergraph node classification benchmarks. Code is available at https://github.com/yxzwang/PhenomNN.

**摘要:** 超图是一种代表利益主体间高阶相互作用的强有力抽象方法。为了利用这些关系进行下游预测,最近提出了多种超图神经网络架构,主要建立在较传统的图神经网络(GNN)文献的先驱之上。在本文中,我们以某种不同的方式开始,提出参数化、超图调节能量函数的表达式家族。然后,我们展示了这些能量的最小化如何有效作为节点嵌入,当与参数化分类器相配时,可以通过监督双层优化过程进行训练。实例上,我们展示了各种超图节点分类指标的最新结果。代码可于 https://github.com/yxzwang/PhenomNN。

**[Paper URL](https://proceedings.mlr.press/v202/wang23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23d/wang23d.pdf)** 

# A Closer Look at Self-Supervised Lightweight Vision Transformers
**题目:** 对自监督轻型视觉变换器的更深入了解

**作者:** Shaoru Wang, Jin Gao, Zeming Li, Xiaoqin Zhang, Weiming Hu

**Abstract:** Self-supervised learning on large-scale Vision Transformers (ViTs) as pre-training methods has achieved promising downstream performance. Yet, how much these pre-training paradigms promote lightweight ViTs’ performance is considerably less studied. In this work, we develop and benchmark several self-supervised pre-training methods on image classification tasks and some downstream dense prediction tasks. We surprisingly find that if proper pre-training is adopted, even vanilla lightweight ViTs show comparable performance to previous SOTA networks with delicate architecture design. It breaks the recently popular conception that vanilla ViTs are not suitable for vision tasks in lightweight regimes. We also point out some defects of such pre-training, e.g., failing to benefit from large-scale pre-training data and showing inferior performance on data-insufficient downstream tasks. Furthermore, we analyze and clearly show the effect of such pre-training by analyzing the properties of the layer representation and attention maps for related models. Finally, based on the above analyses, a distillation strategy during pre-training is developed, which leads to further downstream performance improvement for MAE-based pre-training. Code is available at https://github.com/wangsr126/mae-lite.

**摘要:** 在大型视觉变换器(ViTs)上自我监督的学习作为预训练方法已经取得了令人期待的下游性能。然而,这些预训练模式如何促进轻量ViTs的性能却被较少研究。在这项工作中,我们开发和基准在图像分类任务和一些下游密集预测任务上几个自我监督预训练方法。我们惊奇地发现,如果适当的预训练被采纳,甚至瓦尼拉轻量ViTs也表现出与以前的SOTA网络具有微妙的架构设计的可比性能。此外,我们通过对相关模型的层表示特性和注意图的分析,分析并明确显示这种预训练的效果。最后,基于上述分析,在预训练期间开发了一种蒸馏策略,从而为基于MAE的预训练进一步改善下游性能。代码可于 https://github.com/wangsr126/mae-lite。

**[Paper URL](https://proceedings.mlr.press/v202/wang23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23e/wang23e.pdf)** 

# PreNAS: Preferred One-Shot Learning Towards Efficient Neural Architecture Search
**题目:** PreNAS:偏好单击学习以实现高效神经结构搜索

**作者:** Haibin Wang, Ce Ge, Hesen Chen, Xiuyu Sun

**Abstract:** The wide application of pre-trained models is driving the trend of once-for-all training in one-shot neural architecture search (NAS). However, training within a huge sample space damages the performance of individual subnets and requires much computation to search for a optimal model. In this paper, we present PreNAS, a search-free NAS approach that accentuates target models in one-shot training. Specifically, the sample space is dramatically reduced in advance by a zero-cost selector, and weight-sharing one-shot training is performed on the preferred architectures to alleviate update conflicts. Extensive experiments have demonstrated that PreNAS consistently outperforms state-of-the-art one-shot NAS competitors for both Vision Transformer and convolutional architectures, and importantly, enables instant specialization with zero search cost. Our code is available at https://github.com/tinyvision/PreNAS.

**摘要:** 预训练模型的广泛应用推动了一击神经结构搜索(NAS)的一次性训练的趋势。然而,在一个巨大的样品空间内进行训练会破坏单独的子网的性能,并需要大量的计算来寻找最佳模型。本论文中,我们介绍PreNAS,一种无搜索的NAS方法,强调一击训练中的目标模型。具体而言,样品空间由零成本选择器提前大幅减少,而分担重量的一击训练在偏好的架构上进行,以缓解更新冲突。

**[Paper URL](https://proceedings.mlr.press/v202/wang23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23f/wang23f.pdf)** 

# Adversarial Policies Beat Superhuman Go AIs
**题目:** 敌对政策击败超人 Go AI

**作者:** Tony Tong Wang, Adam Gleave, Tom Tseng, Kellin Pelrine, Nora Belrose, Joseph Miller, Michael D Dennis, Yawen Duan, Viktor Pogrebniak, Sergey Levine, Stuart Russell

**Abstract:** We attack the state-of-the-art Go-playing AI system KataGo by training adversarial policies against it, achieving a $>$97% win rate against KataGo running at superhuman settings. Our adversaries do not win by playing Go well. Instead, they trick KataGo into making serious blunders. Our attack transfers zero-shot to other superhuman Go-playing AIs, and is comprehensible to the extent that human experts can implement it without algorithmic assistance to consistently beat superhuman AIs. The core vulnerability uncovered by our attack persists even in KataGo agents adversarially trained to defend against our attack. Our results demonstrate that even superhuman AI systems may harbor surprising failure modes. Example games are available https://goattack.far.ai/.

**摘要:** 我们通过训练对它的敌对政策来攻击最先进的Go游戏AI系统卡塔戈,达到在超人环境中运行的卡塔戈的97%赢率。我们的敌对不会通过游戏Go获得胜利。相反,他们欺骗卡塔戈制造严重错误。我们的攻击将零击向其他超人Go游戏AI,并且可以理解到人类专家能够在没有算法的协助下实现它以持续击败超人AI。

**[Paper URL](https://proceedings.mlr.press/v202/wang23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23g/wang23g.pdf)** 

# On Regularization and Inference with Label Constraints
**题目:** 标签约束的规范化与干涉

**作者:** Kaifu Wang, Hangfeng He, Tin D. Nguyen, Piyush Kumar, Dan Roth

**Abstract:** Prior knowledge and symbolic rules in machine learning are often expressed in the form of label constraints, especially in structured prediction problems. In this work, we compare two common strategies for encoding label constraints in a machine learning pipeline, regularization with constraints and constrained inference, by quantifying their impact on model performance. For regularization, we show that it narrows the generalization gap by precluding models that are inconsistent with the constraints. However, its preference for small violations introduces a bias toward a suboptimal model. For constrained inference, we show that it reduces the population risk by correcting a model’s violation, and hence turns the violation into an advantage. Given these differences, we further explore the use of two approaches together and propose conditions for constrained inference to compensate for the bias introduced by regularization, aiming to improve both the model complexity and optimal risk.

**摘要:** 在机器学习中,先知和符号规则往往以标签约束的形式表达,特别是在结构预测问题中。本文比较了机器学习管道中的标签约束编码的两个共同策略,即约束和约束推理的规范化,通过量化其对模型性能的影响。对于规范化,我们证明它通过排除与约束不符的模型来缩小一般化差距。然而,它对小违反的偏好引入了向亚最佳模型的偏见。对于约束推理,我们表明它通过纠正模型的违反,降低了人口风险,从而使违反成为优势。鉴于这些差异,我们进一步探讨了两种方法的联合使用,并提出了约束推理条件来补偿通过规范化引入的偏见,以改善模型的复杂性和最佳风险。

**[Paper URL](https://proceedings.mlr.press/v202/wang23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23h/wang23h.pdf)** 

# Policy Gradient in Robust MDPs with Global Convergence Guarantee
**题目:** 具有全球收敛性保证的稳健多边发展计划政策等级

**作者:** Qiuhao Wang, Chin Pang Ho, Marek Petrik

**Abstract:** Robust Markov decision processes (RMDPs) provide a promising framework for computing reliable policies in the face of model errors. Many successful reinforcement learning algorithms build on variations of policy-gradient methods, but adapting these methods to RMDPs has been challenging. As a result, the applicability of RMDPs to large, practical domains remains limited. This paper proposes a new Double-Loop Robust Policy Gradient (DRPG), the first generic policy gradient method for RMDPs. In contrast with prior robust policy gradient algorithms, DRPG monotonically reduces approximation errors to guarantee convergence to a globally optimal policy in tabular RMDPs. We introduce a novel parametric transition kernel and solve the inner loop robust policy via a gradient-based method. Finally, our numerical results demonstrate the utility of our new algorithm and confirm its global convergence properties.

**摘要:** 鲁棒马可夫决策过程(英语:Robust Markov decision processes,缩写为RMDP)是针对模型误差计算可靠政策的一个有前途的框架。许多成功的强化学习算法建立在政策梯度方法的变异上,但对这些方法的适应是困难的。因此,对大型、实际领域适用性仍然有限。本文提出了一种新的双 loop鲁棒政策梯度(DRPG),这是鲁棒政策梯度的第一个通用政策梯度方法。与以往的鲁棒政策梯度算法相比,DRPG单调地减少了近似误差,以保证在表 RMDP中实现全球最佳政策的融合。

**[Paper URL](https://proceedings.mlr.press/v202/wang23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23i/wang23i.pdf)** 

# Adaptive Smoothing Gradient Learning for Spiking Neural Networks
**题目:** 吸附神经网络的自适应吸附梯度学习

**作者:** Ziming Wang, Runhao Jiang, Shuang Lian, Rui Yan, Huajin Tang

**Abstract:** Spiking neural networks (SNNs) with biologically inspired spatio-temporal dynamics demonstrate superior energy efficiency on neuromorphic architectures. Error backpropagation in SNNs is prohibited by the all-or-none nature of spikes. The existing solution circumvents this problem by a relaxation on the gradient calculation using a continuous function with a constant relaxation de- gree, so-called surrogate gradient learning. Nevertheless, such a solution introduces additional smoothing error on spike firing which leads to the gradients being estimated inaccurately. Thus, how to adaptively adjust the relaxation degree and eliminate smoothing error progressively is crucial. Here, we propose a methodology such that training a prototype neural network will evolve into training an SNN gradually by fusing the learnable relaxation degree into the network with random spike noise. In this way, the network learns adaptively the accurate gradients of loss landscape in SNNs. The theoretical analysis further shows optimization on such a noisy network could be evolved into optimization on the embedded SNN with shared weights progressively. Moreover, The experiments on static images, dynamic event streams, speech, and instrumental sounds show the proposed method achieves state-of-the-art performance across all the datasets with remarkable robustness on different relaxation degrees.

**摘要:** 具有生物学灵感的空间-时空动力学的神经网络显示了神经形态结构上优越的能量效率。在神经网络中错误背负是由于螺旋的全部或没有性质所禁止的。现有的解决方法通过使用连续函数的渐进计算来绕过这一问题,以恒定的渐进缓和,所谓的代用渐进学习。然而,这种解决方法引入了渐进的增温误差,导致渐进误差估计不准确。因此,如何适应性调整渐进缓和和消除渐进缓和误差至关重要。理论分析进一步表明,这种噪声网络的优化可以逐步演化为基于共享权重的嵌入式SNN的优化。此外,对静态图像、动态事件流、语音和乐器声音的实验表明,该方法在不同放松度上具有显著的鲁棒性,在所有数据集中达到最先进的性能。

**[Paper URL](https://proceedings.mlr.press/v202/wang23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23j/wang23j.pdf)** 

# CircuitNet: A Generic Neural Network to Realize Universal Circuit Motif Modeling
**题目:** 电路网:一种通用神经网络实现通用电路模板建模

**作者:** Yansen Wang, Xinyang Jiang, Kan Ren, Caihua Shan, Xufang Luo, Dongqi Han, Kaitao Song, Yifei Shen, Dongsheng Li

**Abstract:** The successes of artificial neural networks (ANNs) are largely attributed to mimicking the human brain structures. Recent advances in neuroscience revealed that neurons interact with each other through various kinds of connectivity patterns to process information, in which the common connectivity patterns are also called circuit motifs. However, many existing ANNs can only model one or two circuit motifs in their architectures, so that their performance may drastically vary among different types of machine learning tasks. In this paper, we propose a new type of neural network inspired by the architectures of neuronal circuits, namely Circuit Neural Network (CircuitNet). In CircuitNet, a group of densely connected neurons, namely circuit motif unit (CMU), form the basic unit of the network, which is capable of modeling universal circuit motifs by adjusting the weights within the CMUs. Compared with traditional feed-forward networks, CircuitNet has the ability to model more types of neuron connections such as feed-back and lateral motifs. Inspired by the locally dense and globally sparse structure of the human brain, several iterations of signal transmission among different CMUs are achieved by sparse connections through the input ports and output ports of different CMUs. Experiments have demonstrated that CircuitNet can outperform popular neural network architectures in function approximation, reinforcement learning, image classification, and time series forecasting tasks.

**摘要:** 人工神经网络(ANN)的成功主要归因于模仿人类大脑结构。最近的神经科学发现,神经元通过各种连接模式相互作用来处理信息,其中常见的连接模式也被称作电路模式。然而,许多现有的ANN只能在其架构中建模一个或两个电路模式,从而使它们的性能在不同类型的机器学习任务中大幅变化。与传统的反馈网络相比,CircuitNet具有更多类型的神经网络连接模型的能力,例如反馈和侧面动词。基于人类大脑的局部密集和全球稀疏结构,通过不同CMU的输入端口和输出端口通过稀疏的连接实现不同CMU之间的信号传输的多次迭代。实验表明,CircuitNet可以在功能近似、增强学习、图像分类和时间序列预测任务方面胜出流行的神经网络架构。

**[Paper URL](https://proceedings.mlr.press/v202/wang23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23k/wang23k.pdf)** 

# Generalized Polyak Step Size for First Order Optimization with Momentum
**题目:** 基于动量优化的通用聚合物步骤大小

**作者:** Xiaoyu Wang, Mikael Johansson, Tong Zhang

**Abstract:** In machine learning applications, it is well known that carefully designed learning rate (step size) schedules can significantly improve the convergence of commonly used first-order optimization algorithms. Therefore how to set step size adaptively becomes an important research question. A popular and effective method is the Polyak step size, which sets step size adaptively for gradient descent or stochastic gradient descent without the need to estimate the smoothness parameter of the objective function. However, there has not been a principled way to generalize the Polyak step size for algorithms with momentum accelerations. This paper presents a general framework to set the learning rate adaptively for first-order optimization methods with momentum, motivated by the derivation of Polyak step size. It is shown that the resulting techniques are much less sensitive to the choice of momentum parameter and may avoid the oscillation of the heavy-ball method on ill-conditioned problems. These adaptive step sizes are further extended to the stochastic settings, which are attractive choices for stochastic gradient descent with momentum. Our methods are demonstrated to be more effective for stochastic gradient methods than prior adaptive step size algorithms in large-scale machine learning tasks.

**摘要:** 在机器学习应用中,众所周知精心设计的学习速率(步骤大小)时间表可以显著提高常用第一阶优化算法的收敛性,因此如何调整步骤大小成为一个重要的研究问题。一种流行有效的方法是波利亚克步骤大小,它为梯度下降或随机梯度下降调整了步骤大小,不需要估计目标函数的平滑度参数。然而,没有一个原则性方法将波利亚克步骤大小归纳为运动加速算法的一般化方法。这些适应性步骤尺寸进一步扩展到随机设置,是随机梯度下降具有动力的引人注目的选择。我们的方法在大型机器学习任务中比以前的适应性步骤大小算法更有效。

**[Paper URL](https://proceedings.mlr.press/v202/wang23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23l/wang23l.pdf)** 

# Near-Minimax-Optimal Risk-Sensitive Reinforcement Learning with CVaR
**题目:**  near-Minimax-Optimal Risk-Sensitive Reinforcement Learning with CVaR

**作者:** Kaiwen Wang, Nathan Kallus, Wen Sun

**Abstract:** In this paper, we study risk-sensitive Reinforcement Learning (RL), focusing on the objective of Conditional Value at Risk (CVaR) with risk tolerance $\tau$. Starting with multi-arm bandits (MABs), we show the minimax CVaR regret rate is $\Omega(\sqrt{\tau^{-1}AK})$, where $A$ is the number of actions and $K$ is the number of episodes, and that it is achieved by an Upper Confidence Bound algorithm with a novel Bernstein bonus. For online RL in tabular Markov Decision Processes (MDPs), we show a minimax regret lower bound of $\Omega(\sqrt{\tau^{-1}SAK})$ (with normalized cumulative rewards), where $S$ is the number of states, and we propose a novel bonus-driven Value Iteration procedure. We show that our algorithm achieves the optimal regret of $\widetilde O(\sqrt{\tau^{-1}SAK})$ under a continuity assumption and in general attains a near-optimal regret of $\widetilde O(\tau^{-1}\sqrt{SAK})$, which is minimax-optimal for constant $\tau$. This improves on the best available bounds. By discretizing rewards appropriately, our algorithms are computationally efficient.

**摘要:** 本文研究了风险敏感强化学习(RL),重点研究了风险容忍的条件风险值(CVaR)目标。从多臂 bandits(MABs)开始,我们显示 CVaR遗憾率为$\Omega(\sqrt{\tau^{-1}AK})$,$A$是行动的数目,$K$是事件的数目,并且它由一种新的伯恩斯坦奖金的高级信任 Bound算法实现。在表式马可夫决策过程(MDPs)的在线RL中,我们显示了$\Omega(\sqrt{\tau^{-1}SAK})$的最小遗憾边界,$S$是状态的数目,并提出了一种新的奖金驱动值迭代程序。通过适当地分离奖励, 我们的算法是计算效率高的.

**[Paper URL](https://proceedings.mlr.press/v202/wang23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23m/wang23m.pdf)** 

# FedHPO-Bench: A Benchmark Suite for Federated Hyperparameter Optimization
**题目:** FedHPO-Bench: Federated Hyperparameter Optimization的 Benchmark Suite

**作者:** Zhen Wang, Weirui Kuang, Ce Zhang, Bolin Ding, Yaliang Li

**Abstract:** Research in the field of hyperparameter optimization (HPO) has been greatly accelerated by existing HPO benchmarks. Nonetheless, existing efforts in benchmarking all focus on HPO for traditional learning paradigms while ignoring federated learning (FL), a promising paradigm for collaboratively learning models from dispersed data. In this paper, we first identify some uniqueness of federated hyperparameter optimization (FedHPO) from various aspects, showing that existing HPO benchmarks no longer satisfy the need to study FedHPO methods. To facilitate the research of FedHPO, we propose and implement a benchmark suite FedHPO-Bench that incorporates comprehensive FedHPO problems, enables flexible customization of the function evaluations, and eases continuing extensions. We conduct extensive experiments based on FedHPO-Bench to provide the community with more insights into FedHPO. We open-sourced FedHPO-Bench at https://github.com/alibaba/FederatedScope/tree/master/benchmark/FedHPOBench.

**摘要:** 在高参数优化领域的研究已经被现有的HPO基准大大加速。然而,在基准方面的现有努力都集中在传统学习模式的HPO,同时忽略了联邦学习(FL),这是从分散数据中共同学习模型的一个有前途的基准。本论文中,我们首先确定联邦高参数优化(FedHPO)的一些独特性,显示现有的HPO基准不再满足研究FedHPO方法的需要。

**[Paper URL](https://proceedings.mlr.press/v202/wang23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23n/wang23n.pdf)** 

# A/B Testing in Network Data with Covariate-Adaptive Randomization
**题目:** A/B网络数据随机随机化测试

**作者:** Jialu Wang, Ping Li, Feifang Hu

**Abstract:** Users linked together through a network often tend to have similar behaviors. This phenomenon is usually known as network interaction. Users’ characteristics, the covariates, are often correlated with their outcomes. Therefore, one should incorporate both the covariates and the network information in a carefully designed randomization to improve the estimation of the average treatment effect (ATE) in network A/B testing. In this paper, we propose a new adaptive procedure to balance both the network and the covariates. We show that the imbalance measures with respect to the covariates and the network are $O_p(1)$. We also demonstrate the relationships between the improved balances and the increased efficiency in terms of the mean square error (MSE). Numerical studies demonstrate the advanced performance of the proposed procedure regarding the greater comparability of the treatment groups and the reduction of MSE for estimating the ATE.

**摘要:** 通过网络连接的用户往往有相似的行为。这一现象通常被称为网络交互。用户特征,共变量,经常与其结果相关。因此,应该将共变量和网络信息纳入精心设计的随机化,以提高网络A/B测试中平均治疗效果(ATE)的估计。本文提出了一种新的适应性程序,以平衡网络和共变量。我们证明,对共变量和网络的失衡措施是$O_p(1)$。我们还证明了改善平衡和提高平均平方误差(MSE)效率之间的关系。

**[Paper URL](https://proceedings.mlr.press/v202/wang23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23o/wang23o.pdf)** 

# Learning Belief Representations for Partially Observable Deep RL
**题目:** 部分可观测深层RL的学习信仰表现

**作者:** Andrew Wang, Andrew C Li, Toryn Q. Klassen, Rodrigo Toro Icarte, Sheila A. Mcilraith

**Abstract:** Many important real-world Reinforcement Learning (RL) problems involve partial observability and require policies with memory. Unfortunately, standard deep RL algorithms for partially observable settings typically condition on the full history of interactions and are notoriously difficult to train. We propose a novel deep, partially observable RL algorithm based on modelling belief states — a technique typically used when solving tabular POMDPs, but that has traditionally been difficult to apply to more complex environments. Our approach simplifies policy learning by leveraging state information at training time, that may not be available at deployment time. We do so in two ways: first, we decouple belief state modelling (via unsupervised learning) from policy optimization (via RL); and second, we propose a representation learning approach to capture a compact set of reward-relevant features of the state. Experiments demonstrate the efficacy of our approach on partially observable domains requiring information seeking and long-term memory.

**摘要:** 许多重要的实世界强化学习(RL)问题涉及部分可观察性,并要求具有内存的政策。不幸的是,部分可观察性设置的标准深层RL算法通常取决于相互作用的完整历史,而且很难训练。我们提出了一种基于建模信念状态的新型深层、部分可观察性RL算法 — — 这个技术通常用于解决表格POMDP,但传统上很难应用于更复杂的环境。实验证明了我们的方法在需要信息搜索和长期记忆的部分可观测领域有效。

**[Paper URL](https://proceedings.mlr.press/v202/wang23p.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23p/wang23p.pdf)** 

# Warm-Start Actor-Critic: From Approximation Error to Sub-optimality Gap
**题目:**  warm-start Actor-Critic:从近似误差到次优差

**作者:** Hang Wang, Sen Lin, Junshan Zhang

**Abstract:** Warm-Start reinforcement learning (RL), aided by a prior policy obtained from offline training, is emerging as a promising RL approach for practical applications. Recent empirical studies have demonstrated that the performance of Warm-Start RL can be improved quickly in some cases but become stagnant in other cases, especially when the function approximation is used. To this end, the primary objective of this work is to build a fundamental understanding on ”whether and when online learning can be significantly accelerated by a warm-start policy from offline RL?”. Specifically, we consider the widely used Actor-Critic (A-C) method with a prior policy. We first quantify the approximation errors in the Actor update and the Critic update, respectively. Next, we cast the Warm-Start A-C algorithm as Newton’s method with perturbation, and study the impact of the approximation errors on the finite-time learning performance with inaccurate Actor/Critic updates. Under some general technical conditions, we derive the upper bounds, which shed light on achieving the desired finite-learning performance in the Warm-Start A-C algorithm. In particular, our findings reveal that it is essential to reduce the algorithm bias in online learning. We also obtain lower bounds on the sub-optimality gap of the Warm-Start A-C algorithm to quantify the impact of the bias and error propagation.

**摘要:**  Warm-Start 增强学习(RL)是通过从非线性训练获得的预先政策来支持的,现已成为一个有前途的RL方法,用于实际应用。最近的实证研究表明, Warm-Start RL的性能在某些情况下可以迅速提高,但在其他情况下却会停滞,特别是在函数近似被使用时。为此目的,本工作的主要目标是建立一个基本的理解,“在线学习是否和什么时候可以由非线性RL的温 start 政策显著加速?”。在某些一般技术条件下,我们得出热启动A-C算法的上限,从而揭示了实现热启动A-C算法的有限学习性能的必要性。特别是,我们发现在在线学习中减少算法偏差是至关重要的。我们还得到了热启动A-C算法的亚优化差的较低上限,以量化偏差和误差传播的影响。

**[Paper URL](https://proceedings.mlr.press/v202/wang23q.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23q/wang23q.pdf)** 

# Slot-VAE: Object-Centric Scene Generation with Slot Attention
**题目:** Slot-VAE:目标中心场景生成与 Slot注意

**作者:** Yanbo Wang, Letao Liu, Justin Dauwels

**Abstract:** Slot attention has shown remarkable object-centric representation learning performance in computer vision tasks without requiring any supervision. Despite its object-centric binding ability brought by compositional modelling, as a deterministic module, slot attention lacks the ability to generate novel scenes. In this paper, we propose the Slot-VAE, a generative model that integrates slot attention with the hierarchical VAE framework for object-centric structured scene generation. For each image, the model simultaneously infers a global scene representation to capture high-level scene structure and object-centric slot representations to embed individual object components. During generation, slot representations are generated from the global scene representation to ensure coherent scene structures. Our extensive evaluation of the scene generation ability indicates that Slot-VAE outperforms slot representation-based generative baselines in terms of sample quality and scene structure accuracy.

**摘要:**  Slot注意在计算机视觉任务中显示出具有显著的对象中心表示学习性能,而不需要任何监督。尽管通过组合建模实现的对象中心绑定能力,但作为确定性模块, Slot注意缺乏生成新场景的能力。本文提出了 Slot-VAE,一种将 Slot注意整合到对象中心结构化场景生成的层次化VAE框架的生成模型。我们对场景生成能力的广泛评估表明,Slot-VAE在样品质量和场景结构准确性方面比基于场景表示的生成基线高。

**[Paper URL](https://proceedings.mlr.press/v202/wang23r.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23r/wang23r.pdf)** 

# DIVISION: Memory Efficient Training via Dual Activation Precision
**题目:** 部门:通过双重激活精度进行记忆效率培训

**作者:** Guanchu Wang, Zirui Liu, Zhimeng Jiang, Ninghao Liu, Na Zou, Xia Hu

**Abstract:** Activation compressed training provides a solution towards reducing the memory cost of training deep neural networks (DNNs). However, state-of-the-art work combines a search of quantization bit-width with the training, which makes the procedure complicated and less transparent. To this end, we propose a simple and effective method to compress DNN training. Our method is motivated by an instructive observation: DNN backward propagation mainly utilizes the low-frequency component (LFC) of the activation maps, while the majority of memory is for caching the high-frequency component (HFC) during the training. This indicates the HFC of activation maps is highly redundant and compressible, which inspires our proposed Dual Activation Precision (DIVISION). During the training, DIVISION preserves a high-precision copy of LFC and compresses the HFC into a light-weight copy with low numerical precision. This can significantly reduce the memory cost while maintaining a competitive model accuracy. Experiment results show DIVISION has better comprehensive performance than state-of-the-art methods, including over 10x compression of activation maps and competitive training throughput, without loss of model accuracy. The source code is available at https://github.com/guanchuwang/division.

**摘要:** 激活压缩训练提供了降低训练深度神经网络(DNN)的内存成本的解决方案。然而,最先进的工作结合训练的量化比特宽度搜索,使得程序变得复杂和较不透明。为此,我们提出了压缩DNN训练的简单有效的方法。我们的方法是由指导性的观察所激发的:DNN后继传播主要利用激活地图的低频组件(LFC),而大部分的内存用于在训练中缓存高频组件(HFC)。这表明激活地图的HFC非常冗余和可压缩,这激发了我们提出的双重激活精度(DIVISION)。实验结果表明,DVIVISION比最先进的方法具有更好的综合性能,包括10倍以上的激活图压缩和竞争训练吞吐量,而没有损失模型的准确性。

**[Paper URL](https://proceedings.mlr.press/v202/wang23s.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23s/wang23s.pdf)** 

# CocktailSGD: Fine-tuning Foundation Models over 500Mbps Networks
**题目:** CocktailSGD:基于500Mbps网络的微调基础模型

**作者:** Jue Wang, Yucheng Lu, Binhang Yuan, Beidi Chen, Percy Liang, Christopher De Sa, Christopher Re, Ce Zhang

**Abstract:** Distributed training of foundation models, especially large language models (LLMs), is communication-intensive and so has heavily relied on centralized data centers with fast interconnects. Can we train on slow networks and unlock the potential of decentralized infrastructure for foundation models? In this paper, we propose CocktailSGD, a novel communication-efficient training framework that combines three distinct compression techniques – random sparsification, top-K sparsification, and quantization – to achieve much greater compression than each individual technique alone. We justify the benefit of such a hybrid approach through a theoretical analysis of convergence. Empirically, we show that CocktailSGD achieves up to 117$\times$ compression in fine-tuning LLMs up to 20 billion parameters without hurting convergence. On a 500Mbps network, CocktailSGD only incurs $\sim$1.2$\times$ slowdown compared with data center networks.

**摘要:** 基础模型的分布式培训,特别是大型语言模型(LLMs),是通信密集型,因此严重依赖于具有高速互连的集中数据中心。我们能够在慢网络上进行培训并解锁基础模型的分散基础设施的潜力吗?本论文中,我们提出了 CocktailSGD,一种新的通信效率训练框架,它结合了三个不同的压缩技术——随机散布、顶端散布和定量化——以实现比单个单独的技术更大的压缩。

**[Paper URL](https://proceedings.mlr.press/v202/wang23t.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23t/wang23t.pdf)** 

# Magneto: A Foundation Transformer
**题目:** 磁铁:一个基础变换器

**作者:** Hongyu Wang, Shuming Ma, Shaohan Huang, Li Dong, Wenhui Wang, Zhiliang Peng, Yu Wu, Payal Bajaj, Saksham Singhal, Alon Benhaim, Barun Patra, Zhun Liu, Vishrav Chaudhary, Xia Song, Furu Wei

**Abstract:** A big convergence of model architectures across language, vision, speech, and multimodal is emerging. However, under the same name ”Transformers”, the above areas use different implementations for better performance, e.g., Post-LayerNorm for BERT, and Pre-LayerNorm for GPT and vision Transformers. We call for the development of Foundation Transformer for true general-purpose modeling, which serves as a go-to architecture for various tasks and modalities with guaranteed training stability. In this work, we introduce a Transformer variant, named Magneto, to fulfill the goal. Specifically, we propose Sub-LayerNorm for good expressivity, and the initialization strategy theoretically derived from DeepNet for stable scaling up. Extensive experiments demonstrate its superior performance and better stability than the de facto Transformer variants designed for various applications, including language modeling (i.e., BERT, and GPT), machine translation, vision pretraining (i.e., BEiT), speech recognition, and multimodal pretraining (i.e., BEiT-3).

**摘要:** 语言 、 视觉 、 语言 、 多媒体 等 模型 架构 的 巨大 融合 正在 出现 。 然而, 在 “ 变形器 ” 的 同一 名称 下, 上述 领域 使用 不同 的 实现 以 提高 性能, 例如, BERT 的 Post-LayerNorm 和 GPT 和 视觉 变形器 的 Pre-LayerNorm 。 我们 要求 开发 基础 变形器, 作为 保证 训练 稳定 的 各种 任务 和 模式 的 目标 架构 。 在 这项 工作 中, 我们 介绍 一 种 变形器, 叫 Magneto, 以 实现 目标 。广泛的实验表明它比实际变换器设计的变换器具有较高的性能和较好的稳定性,用于各种应用,包括语言建模(即BERT和GPT),机器翻译,视觉预训练(即BEiT),语音识别和多模预训练(即BEiT-3)。

**[Paper URL](https://proceedings.mlr.press/v202/wang23u.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23u/wang23u.pdf)** 

# Direct Parameterization of Lipschitz-Bounded Deep Networks
**题目:** Lipschitz-Bounded Deep Networks的直接参数化

**作者:** Ruigang Wang, Ian Manchester

**Abstract:** This paper introduces a new parameterization of deep neural networks (both fully-connected and convolutional) with guaranteed $\ell^2$ Lipschitz bounds, i.e. limited sensitivity to input perturbations. The Lipschitz guarantees are equivalent to the tightest-known bounds based on certification via a semidefinite program (SDP). We provide a “direct” parameterization, i.e., a smooth mapping from $\mathbb R^N$ onto the set of weights satisfying the SDP-based bound. Moreover, our parameterization is complete, i.e. a neural network satisfies the SDP bound if and only if it can be represented via our parameterization. This enables training using standard gradient methods, without any inner approximation or computationally intensive tasks (e.g. projections or barrier terms) for the SDP constraint. The new parameterization can equivalently be thought of as either a new layer type (the sandwich layer), or a novel parameterization of standard feedforward networks with parameter sharing between neighbouring layers. A comprehensive set of experiments on image classification shows that sandwich layers outperform previous approaches on both empirical and certified robust accuracy. Code is available at https://github.com/acfr/LBDN.

**摘要:** 本文介绍了具有保证的$\ell^2$利普希茨边界(即对输入扰动的敏感性有限)的深神经网络的新参数化。利普希茨保证与基于半定义程序(SDP)的认证的最紧密的边界等价。我们提供了“直接”参数化,即从$\mathbb R^N$映射到满足 SDP-based边界的重量集。此外,我们的参数化是完全的,即神经网络满足 SDP 边界,如果且仅当它可以通过我们的参数化表示。新的参数化可以同等地被视为一种新的层类型(三明治层),或者一个与邻层之间的参数共享的标准后继网络的新参数化。

**[Paper URL](https://proceedings.mlr.press/v202/wang23v.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23v/wang23v.pdf)** 

# Tighter Information-Theoretic Generalization Bounds from Supersamples
**题目:** 强化信息-理论推广的超样本边界

**作者:** Ziqiao Wang, Yongyi Mao

**Abstract:** In this work, we present a variety of novel information-theoretic generalization bounds for learning algorithms, from the supersample setting of Steinke & Zakynthinou (2020)—the setting of the “conditional mutual information” framework. Our development exploits projecting the loss pair (obtained from a training instance and a testing instance) down to a single number and correlating loss values with a Rademacher sequence (and its shifted variants). The presented bounds include square-root bounds, fast-rate bounds, including those based on variance and sharpness, and bounds for interpolating algorithms etc. We show theoretically or empirically that these bounds are tighter than all information-theoretic bounds known to date on the same supersample setting.

**摘要:** 本文对学习算法提出了一系列新的信息理论一般化边界,从斯坦克和扎金蒂努(2020)的“条件相互信息”框架的超级样本设置。我们开发的边界包括将损失对数(从训练实例和测试实例得到的)投影到单个数目,并与拉德马切尔序列(及其变换变量)相关损失值。

**[Paper URL](https://proceedings.mlr.press/v202/wang23w.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23w/wang23w.pdf)** 

# NP-SemiSeg: When Neural Processes meet Semi-Supervised Semantic Segmentation
**题目:** NP-SemiSeg:神经过程满足半监督语义分割时

**作者:** Jianfeng Wang, Daniela Massiceti, Xiaolin Hu, Vladimir Pavlovic, Thomas Lukasiewicz

**Abstract:** Semi-supervised semantic segmentation involves assigning pixel-wise labels to unlabeled images at training time. This is useful in a wide range of real-world applications where collecting pixel-wise labels is not feasible in time or cost. Current approaches to semi-supervised semantic segmentation work by predicting pseudo-labels for each pixel from a class-wise probability distribution output by a model. If this predicted probability distribution is incorrect, however, it leads to poor segmentation results which can have knock-on consequences in safety critical systems, like medical images or self-driving cars. It is, therefore, important to understand what a model does not know, which is mainly achieved by uncertainty quantification. Recently, neural processes (NPs) have been explored in semi-supervised image classification, and they have been a computationally efficient and effective method for uncertainty quantification. In this work, we move one step forward by adapting NPs to semi-supervised semantic segmentation, resulting in a new model called NP-SemiSeg. We experimentally evaluated NP-SemiSeg on the public benchmarks PASCAL VOC 2012 and Cityscapes, with different training settings, and the results verify its effectiveness.

**摘要:** 半监视语义分割涉及在训练时将像素wise标签分配给未标记的图像。这在收集像素wise标签时在时间和成本方面是很有用的。目前对半监视语义分割的工作方法是通过预测模型的类wise概率分布输出的每个像素的伪标签。如果这种预测的概率分布不正确,则会导致安全性关键系统(如医疗图像或自驾驶汽车)中不良的分割结果。因此,重要的是了解模型不知道的是什么,这主要是通过不确定性定量来实现。在这项工作中,我们通过对NP进行半监视的语义分割来向前迈进,从而产生一种名为NP-SemiSeg的新模型。我们对NP-SemiSeg在不同训练环境下的公共基准PASCAL VOC 2012和Cityscapes进行了实验评价,结果验证了其有效性。

**[Paper URL](https://proceedings.mlr.press/v202/wang23x.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23x/wang23x.pdf)** 

# GC-Flow: A Graph-Based Flow Network for Effective Clustering
**题目:** GC-Flow:基于图形的有效集群网络

**作者:** Tianchun Wang, Farzaneh Mirzazadeh, Xiang Zhang, Jie Chen

**Abstract:** Graph convolutional networks (GCNs) are discriminative models that directly model the class posterior $p(y|\mathbf{x})$ for semi-supervised classification of graph data. While being effective, as a representation learning approach, the node representations extracted from a GCN often miss useful information for effective clustering, because the objectives are different. In this work, we design normalizing flows that replace GCN layers, leading to a generative model that models both the class conditional likelihood $p(\mathbf{x}|y)$ and the class prior $p(y)$. The resulting neural network, GC-Flow, retains the graph convolution operations while being equipped with a Gaussian mixture representation space. It enjoys two benefits: it not only maintains the predictive power of GCN, but also produces well-separated clusters, due to the structuring of the representation space. We demonstrate these benefits on a variety of benchmark data sets. Moreover, we show that additional parameterization, such as that on the adjacency matrix used for graph convolutions, yields additional improvement in clustering.

**摘要:** 图形卷积网络(GCNs)是一种直接建模后类$p(y|\mathbf{x})$,用于对图形数据进行半监督分类的分类模型。作为一种建模学习方法,从GCN中提取的节点建模往往忽略有效的聚类信息,因为目标是不同的。在这个工作中,我们设计了替换GCN层的正常化流,从而建立一种建模模型,以建模 both the class conditional likelihood $p(\mathbf{x}|y)$ and the class prior $p(y)$。此外,我们证明了额外的参数化,例如在用于图卷曲的邻接矩阵上,在聚类中产生额外的改进。

**[Paper URL](https://proceedings.mlr.press/v202/wang23y.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23y/wang23y.pdf)** 

# Curriculum Co-disentangled Representation Learning across Multiple Environments for Social Recommendation
**题目:** 课程共同分散的代表性 多环境学习为社会建议

**作者:** Xin Wang, Zirui Pan, Yuwei Zhou, Hong Chen, Chendi Ge, Wenwu Zhu

**Abstract:** There exist complex patterns behind the decision-making processes of different individuals across different environments. For instance, in a social recommender system, various user behaviors are driven by highly entangled latent factors from two environments, i.e., consuming environment where users consume items and social environment where users connect with each other. Uncovering the disentanglement of these latent factors for users can benefit in enhanced explainability and controllability for recommendation. However, in literature there has been no work on social recommendation capable of disentangling user representations across consuming and social environments. To solve this problem, we study co-disentangled representation learning across different environments via proposing the curriculum co-disentangled representation learning (CurCoDis) model to disentangle the hidden factors for users across both consuming and social environments. To co-disentangle joint representations for user-item consumption and user-user social graph simultaneously, we partition the social graph into equal-size sub-graphs with minimum number of edges being cut, and design a curriculum weighing strategy for subgraph training through measuring the complexity of subgraphs via Descartes’ rule of signs. We further develop the prototype-routing optimization mechanism, which achieves co-disentanglement of user representations across consuming and social environments. Extensive experiments for social recommendation demonstrate that our proposed CurCoDis model can significantly outperform state-of-the-art methods on several real-world datasets.

**摘要:** 在不同的环境下,不同个体的决策过程背后存在着复杂的模式。例如,在社会推荐系统中,不同的用户行为是由两个环境中的高度关联的潜在因素驱动的,即用户消费的消费环境和用户相互连接的社交环境。为了同时实现用户-对象消费和用户-用户社会图的共分角联合表示,我们将社会图分割成具有最小切边的等大小的子图,并通过 Descartes符号规则来测量子图的复杂性,为子图训练设计课程权重策略。我们进一步开发了原型路由优化机制,实现在消费和社会环境中用户表现的共分离。

**[Paper URL](https://proceedings.mlr.press/v202/wang23z.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23z/wang23z.pdf)** 

# Data Efficient Neural Scaling Law via Model Reusing
**题目:** 基于模型重用数据效率神经尺度法

**作者:** Peihao Wang, Rameswar Panda, Zhangyang Wang

**Abstract:** The number of parameters in large transformers has been observed to grow exponentially. Despite notable performance improvements, concerns have been raised that such a growing model size will run out of data in the near future. As manifested in the neural scaling law, modern learning backbones are not data-efficient. To maintain the utility of the model capacity, training data should be increased proportionally. In this paper, we study the neural scaling law under the previously overlooked data scarcity regime, focusing on the more challenging situation where we need to train a gigantic model with a disproportionately limited supply of available training data. We find that the existing power laws underestimate the data inefficiency of large transformers. Their performance will drop significantly if the training set is insufficient. Fortunately, we discover another blessing - such a data-inefficient scaling law can be restored through a model reusing approach that warm-starts the training of a large model by initializing it using smaller models. Our empirical study shows that model reusing can effectively reproduce the power law under the data scarcity regime. When progressively applying model reusing to expand the model size, we also observe consistent performance improvement in large transformers. We release our code at: https://github.com/VITA-Group/Data-Efficient-Scaling.

**摘要:** 在大型变换器中,参数的数目被观察到呈指数增长。尽管有显著的性能改进,人们一直担心这种增长的模型大小在不久的将来将耗尽数据。正如神经级数法所显示的那样,现代学习背骨并不是数据效率高的。为了保持模型能力的有效性,训练数据应有比例的增加。幸运的是,我们发现了另一个祝福——通过重新利用模型的方法可以恢复数据效率低的尺度法,通过使用较小的模型初始化大规模模型的训练。我们的实证研究表明,重新利用模型可以有效地在数据稀缺制度下重现功率法。在逐步应用模型重用来扩大模型大小时,我们也观察到大型变换器的持续性能改善。

**[Paper URL](https://proceedings.mlr.press/v202/wang23aa.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23aa/wang23aa.pdf)** 

# Deep Temporal Sets with Evidential Reinforced Attentions for Unique Behavioral Pattern Discovery
**题目:** 以显而易见增强的注意力对独特行为模式的发现进行深时测定

**作者:** Dingrong Wang, Deep Shankar Pandey, Krishna Prasad Neupane, Zhiwei Yu, Ervine Zheng, Zhi Zheng, Qi Yu

**Abstract:** Machine learning-driven human behavior analysis is gaining attention in behavioral/mental healthcare, due to its potential to identify behavioral patterns that cannot be recognized by traditional assessments. Real-life applications, such as digital behavioral biomarker identification, often require the discovery of complex spatiotemporal patterns in multimodal data, which is largely under-explored. To fill this gap, we propose a novel model that integrates uniquely designed Deep Temporal Sets (DTS) with Evidential Reinforced Attentions (ERA). DTS captures complex temporal relationships in the input and generates a set-based representation, while ERA captures the policy network’s uncertainty and conducts evidence-aware exploration to locate attentive regions in behavioral data. Using child-computer interaction data as a testing platform, we demonstrate the effectiveness of DTS-ERA in differentiating children with Autism Spectrum Disorder and typically developing children based on sequential multimodal visual and touch behaviors. Comparisons with baseline methods show that our model achieves superior performance and has the potential to provide objective, quantitative, and precise analysis of complex human behaviors.

**摘要:** 机器学习驱动的人类行为分析在行为/心理健康方面正日益受到关注,因为它具有识别传统评估无法识别的行为模式的潜力。如数字行为生物标记识别等现实应用,往往需要在多模数据中发现复杂时空模式,而这种模式在很大程度上没有被研究过。为了填补这一空白,我们提出了一种新颖的模型,它将独特设计的深度时空集合(DTS)与明显的增强注意力(ERA)结合起来。DTS在输入中捕捉复杂时空关系并生成基于集合的表示,而ERA则捕捉政策网络的不确定性,并进行有证据意识的探索,以定位行为数据中关注区域。利用儿童与计算机交互数据作为测试平台,我们证明了DTS-ERA在基于连续多模视觉和触摸行为的儿童 Autism Spectrum Disorder和通常发育儿童的鉴别中的作用。与基线方法的比较表明,我们的模型具有较高的性能并具有提供客观、数量和准确的复杂人类行为分析的潜力。

**[Paper URL](https://proceedings.mlr.press/v202/wang23ab.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23ab/wang23ab.pdf)** 

# Active Learning based Structural Inference
**题目:** 基于主动学习的结构ference

**作者:** Aoran Wang, Jun Pang

**Abstract:** In this paper, we propose a novel framework, Active Learning based Structural Inference (ALaSI), to infer the existence of directed connections from observed agents’ states over a time period in a dynamical system. With the help of deep active learning, ALaSI is competent in learning the representation of connections with a relatively small pool of prior knowledge. Moreover, based on information theory, the proposed inter- and out-of-scope message learning pipelines are remarkably beneficial to structural inference for large dynamical systems. We evaluate ALaSI on various large datasets including simulated systems and real-world networks, to demonstrate that ALaSI is able to outperform previous methods in precisely inferring the existence of connections in large systems under either supervised learning or unsupervised learning.

**摘要:** 本文提出了一种新的结构推导框架,即基于主动学习的结构推导(ALaSI),以推导动态系统中观察对象状态的直接连接的存在。ALaSI具有较小知识库的深度主动学习能力,能够学习关联的表示。此外,基于信息理论,提议的跨域和外域消息学习管道对于大型动态系统结构推导具有显著优势。我们对包括模拟系统和现实世界网络在内的各种大型数据集的ALaSI进行了评估,证明ALaSI能够准确地推导在监督学习或非监督学习下在大型系统中存在的连接。

**[Paper URL](https://proceedings.mlr.press/v202/wang23ac.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23ac/wang23ac.pdf)** 

# Better Diffusion Models Further Improve Adversarial Training
**题目:** 更好的扩散模型进一步改进敌方培训

**作者:** Zekai Wang, Tianyu Pang, Chao Du, Min Lin, Weiwei Liu, Shuicheng Yan

**Abstract:** It has been recognized that the data generated by the denoising diffusion probabilistic model (DDPM) improves adversarial training. After two years of rapid development in diffusion models, a question naturally arises: can better diffusion models further improve adversarial training? This paper gives an affirmative answer by employing the most recent diffusion model which has higher efficiency ($\sim 20$ sampling steps) and image quality (lower FID score) compared with DDPM. Our adversarially trained models achieve state-of-the-art performance on RobustBench using only generated data (no external datasets). Under the $\ell_\infty$-norm threat model with $\epsilon=8/255$, our models achieve $70.69\\%$ and $42.67\\%$ robust accuracy on CIFAR-10 and CIFAR-100, respectively, i.e. improving upon previous state-of-the-art models by $+4.58\\%$ and $+8.03\\%$. Under the $\ell_2$-norm threat model with $\epsilon=128/255$, our models achieve $84.86\\%$ on CIFAR-10 ($+4.44\\%$). These results also beat previous works that use external data. We also provide compelling results on the SVHN and TinyImageNet datasets. Our code is at https://github.com/wzekai99/DM-Improves-AT.

**摘要:** 人们已经认识到,被描述的扩散概率模型(DDPM)所生成的数据能提高敌对训练。在扩散模型的两年快速发展后,自然出现一个问题:更好的扩散模型能进一步提高敌对训练吗?本文通过使用最近的扩散模型以提高效率($\sim20$采样步骤)和图像质量(较低的FID分数)与DDPM相比,给出了肯定的答案。我们对敌对训练的模型在RobustBench只使用生成的数据(没有外部数据集)实现最先进的性能。在$\ell_\infty$-norm威胁模型下,我们的模型在CIFAR-10和CIFAR-100分别达到$70.69\\%$和$42.67\\%$的鲁棒准确性,即通过$+4.58\\%$和$+8.03\\%$改进前最先进的模型。在$这些结果也击败了使用外部数据的以前的工作。我们还提供关于SVHN和TinyImageNet数据集的引人注目的结果。我们的代码是 https://github.com/wzekai99/DM-Improves-AT。

**[Paper URL](https://proceedings.mlr.press/v202/wang23ad.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23ad/wang23ad.pdf)** 

# Polarity Is All You Need to Learn and Transfer Faster
**题目:** 极性是你需要学习和快速转移的唯一东西

**作者:** Qingyang Wang, Michael Alan Powell, Eric W Bridgeford, Ali Geisa, Joshua T Vogelstein

**Abstract:** Natural intelligences (NIs) thrive in a dynamic world - they learn quickly, sometimes with only a few samples. In contrast, artificial intelligences (AIs) typically learn with a prohibitive number of training samples and computational power. What design principle difference between NI and AI could contribute to such a discrepancy? Here, we investigate the role of weight polarity: development processes initialize NIs with advantageous polarity configurations; as NIs grow and learn, synapse magnitudes update, yet polarities are largely kept unchanged. We demonstrate with simulation and image classification tasks that if weight polarities are adequately set a priori, then networks learn with less time and data. We also explicitly illustrate situations in which a priori setting the weight polarities is disadvantageous for networks. Our work illustrates the value of weight polarities from the perspective of statistical and computational efficiency during learning.

**摘要:** 自然智力(NIs)在动态世界中蓬勃发展 - 它们学习速度很快,有时只有少数样本. 相反,人工智力(AIs)通常学习的是极少的训练样本和计算能力. NI和AI之间有什么设计原则上的差异可以对这种差异作出贡献? 这里,我们研究了重量偏差的作用:开发过程以有利的偏差配置初始化NI;随着NI的成长和学习,同步大小更新,但偏差基本上保持不变。

**[Paper URL](https://proceedings.mlr.press/v202/wang23ae.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23ae/wang23ae.pdf)** 

# Projected Tensor Power Method for Hypergraph Community Recovery
**题目:** 超声图社区恢复的预测电阻电源方法

**作者:** Jinxin Wang, Yuen-Man Pun, Xiaolu Wang, Peng Wang, Anthony Man-Cho So

**Abstract:** This paper investigates the problem of exact community recovery in the symmetric $d$-uniform $(d \geq 2)$ hypergraph stochastic block model ($d$-HSBM). In this model, a $d$-uniform hypergraph with $n$ nodes is generated by first partitioning the $n$ nodes into $K\geq 2$ equal-sized disjoint communities and then generating hyperedges with a probability that depends on the community memberships of $d$ nodes. Despite the non-convex and discrete nature of the maximum likelihood estimation problem, we develop a simple yet efficient iterative method, called the projected tensor power method, to tackle it. As long as the initialization satisfies a partial recovery condition in the logarithmic degree regime of the problem, we show that our proposed method can exactly recover the hidden community structure down to the information-theoretic limit with high probability. Moreover, our proposed method exhibits a competitive time complexity of $\mathcal{O}(n\log^2n/\log\log n)$ when the aforementioned initialization condition is met. We also conduct numerical experiments to validate our theoretical findings.

**摘要:** 本文研究了对称 $d$-uniform $(d \geq 2)$ 超标图随机块模型($d$-HSBM)的准确社区恢复问题,在此模型中,由$n$节点组成的$d$-uniform 超标图首先将$n$节点分割成同大小的分散社区,然后生成基于$d$节点社区成员的概率的超节点。此外,我们提出的方法在满足上述初始化条件时具有 $\mathcal{O}(n\log^2n/\log\log n)$ 的竞争性时间复杂性。

**[Paper URL](https://proceedings.mlr.press/v202/wang23af.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23af/wang23af.pdf)** 

# Estimating Possible Causal Effects with Latent Variables via Adjustment
**题目:** 通过调整来估计潜在变量可能引起的影响

**作者:** Tian-Zuo Wang, Tian Qin, Zhi-Hua Zhou

**Abstract:** Causal effect identification is a fundamental task in artificial intelligence. A most ideal scenario for causal effect identification is that there is a directed acyclic graph as a prior causal graph encoding the causal relations of all relevant variables. In real tasks, however, the prior causal graph is usually not available, and some relevant variables may be latent as well. With observational data, we can only learn a partial ancestral graph (PAG), which contains some indeterminate causal relations. Since many causal graphs can correspond to one PAG, they are possibly associated with different causal effects. The aim of this paper is to estimate these possible causal effects via covariate adjustment given a PAG. This task is challenging because the number of causal graphs corresponding to a PAG grows super-exponentially with the number of variables. We propose a new graphical characterization for possible adjustment sets, and based on this, we develop the first method to determine the set of possible causal effects that are consistent with the given PAG without enumerating any causal graphs. Our method can output the same set as the enumeration method with super-exponentially less complexity. Experiments validate the effectiveness and tremendous efficiency improvement of the proposed method.

**摘要:** 因果效应识别是人工知能的一个基本任务。因果效应识别最理想场景是存在一个针对所有相关变量的因果关系编码的预先因果图的非循环图。然而在实际任务中,预先因果图通常不可用,一些相关变量也可能隐藏。我们只能学习部分祖先图(PAG),其中包含一些不确定的因果关系。由于许多因果图可以与一个 PAG 相符,它们可能与不同的因果关系相关。本论文的目的是通过对一个 PAG 进行共变量调整来估计这些可能的因果效应。提出了一种新的调整集的图形特征,在此基础上,我们开发了第一个确定与该PAG相符的可能因果效应的集合的方法,而不列举任何因果图。该方法可以输出与列举方法相同的集,具有超指数性较少的复杂性。实验验证了该方法的有效性和巨大的效率改善。

**[Paper URL](https://proceedings.mlr.press/v202/wang23ag.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23ag/wang23ag.pdf)** 

# InfoDiffusion: Representation Learning Using Information Maximizing Diffusion Models
**题目:** InfoDiffusion:使用信息最大化扩散模型学习

**作者:** Yingheng Wang, Yair Schiff, Aaron Gokaslan, Weishen Pan, Fei Wang, Christopher De Sa, Volodymyr Kuleshov

**Abstract:** While diffusion models excel at generating high-quality samples, their latent variables typically lack semantic meaning and are not suitable for representation learning. Here, we propose InfoDiffusion, an algorithm that augments diffusion models with low-dimensional latent variables that capture high-level factors of variation in the data. InfoDiffusion relies on a learning objective regularized with the mutual information between observed and hidden variables, which improves latent space quality and prevents the latents from being ignored by expressive diffusion-based decoders. Empirically, we find that InfoDiffusion learns disentangled and human-interpretable latent representations that are competitive with state-of-the-art generative and contrastive methods, while retaining the high sample quality of diffusion models. Our method enables manipulating the attributes of generated images and has the potential to assist tasks that require exploring a learned latent space to generate quality samples, e.g., generative design.

**摘要:** 虽然扩散模型 excel at generating high-quality samples, their latent variables typically lack semantic meaning and are not suitable for representation learning. Here, we propose InfoDiffusion, a algorithm that augments diffusion models with low-dimensional latent variables that capture high-level factors of variation in the data. InfoDiffusion relies on a learning objective regularized with the mutual information between observed and hidden variables, which improves latent space quality and prevents the latents from being ignored by expressive diffusion-based decoders. Empirically, we find that InfoDiffusion learns disentangled and human-interpretable latent representations that are competitive with state-of-the-art generative and contrastive methods, while retaining the high sample quality of diffusion models.我们的方法可以操纵生成图像的属性,并有能力协助需要探索学习的潜在空间来生成质量样品的任务,例如生成设计。

**[Paper URL](https://proceedings.mlr.press/v202/wang23ah.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23ah/wang23ah.pdf)** 

# A Robust Test for the Stationarity Assumption in Sequential Decision Making
**题目:** 连续决策中定性假设的稳健测试

**作者:** Jitao Wang, Chengchun Shi, Zhenke Wu

**Abstract:** Reinforcement learning (RL) is a powerful technique that allows an autonomous agent to learn an optimal policy to maximize the expected return. The optimality of various RL algorithms relies on the stationarity assumption, which requires time-invariant state transition and reward functions. However, deviations from stationarity over extended periods often occur in real-world applications like robotics control, health care and digital marketing, resulting in suboptimal policies learned under stationary assumptions. In this paper, we propose a model-based doubly robust procedure for testing the stationarity assumption and detecting change points in offline RL settings with certain degree of homogeneity. Our proposed testing procedure is robust to model misspecifications and can effectively control type-I error while achieving high statistical power, especially in high-dimensional settings. Extensive comparative simulations and a real-world interventional mobile health example illustrate the advantages of our method in detecting change points and optimizing long-term rewards in high-dimensional, non-stationary environments.

**摘要:** 强化学习(英语:Reinforcement learning,简称RL)是一种强大的技术,允许自主代理人学习最优策略,以最大化预期回报。不同的RL算法的优化依赖于静态假设,需要时间不变状态转换和奖励函数。然而,长期的静态偏差经常发生在机器人控制、医疗和数字营销等现实应用中,导致在静态假设下学习的次优策略。广泛的比较模拟和实时干预移动健康实例说明了我们方法在高维非静态环境中检测变化点和优化长期回报的优点。

**[Paper URL](https://proceedings.mlr.press/v202/wang23ai.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23ai/wang23ai.pdf)** 

# GEAR: A GPU-Centric Experience Replay System for Large Reinforcement Learning Models
**题目:** GEAR:大型增强学习模型的GPU中心体验重演系统

**作者:** Hanjing Wang, Man-Kit Sit, Congjie He, Ying Wen, Weinan Zhang, Jun Wang, Yaodong Yang, Luo Mai

**Abstract:** This paper introduces a distributed, GPU-centric experience replay system, GEAR, designed to perform scalable reinforcement learning (RL) with large sequence models (such as transformers). With such models, existing systems such as Reverb face considerable bottlenecks in memory, computation, and communication. GEAR, however, optimizes memory efficiency by enabling the memory resources on GPU servers (including host memory and device memory) to manage trajectory data. Furthermore, it facilitates decentralized GPU devices to expedite various trajectory selection strategies, circumventing computational bottlenecks. GEAR is equipped with GPU kernels capable of collecting trajectories using zero-copy access to host memory, along with remote-directed-memory access over InfiniBand, improving communication efficiency. Cluster experiments have shown that GEAR can achieve performance levels up to 6× greater than Reverb when training state-of-the-art large RL models. GEAR is open-sourced at https:// github.com/bigrl-team/gear.

**摘要:** 本文介绍了一种分布式、GPU中心的体验重演系统,GEAR,其设计是用大型序列模型(如变换器)进行可扩展增强学习(RL) 。 与这种模型相比,Reverb等现有系统在内存、计算和通信中面临着相当大的瓶颈。 GEAR通过允许GPU服务器上的内存资源(包括主机内存和设备内存)管理轨迹数据来优化内存效率。GEAR可以在 https:// github.com/bigrl-team/gear 开源。

**[Paper URL](https://proceedings.mlr.press/v202/wang23aj.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23aj/wang23aj.pdf)** 

# Effective and Efficient Structural Inference with Reservoir Computing
**题目:** 高效的水库计算结构干涉

**作者:** Aoran Wang, Tsz Pan Tong, Jun Pang

**Abstract:** In this paper, we present an effective and efficient structural inference approach by integrating a Reservoir Computing (RC) network into a Variational Auto-encoder-based (VAE-based) structural inference framework. With the help of Bi-level Optimization, the backbone VAE-based method follows the Information Bottleneck principle and infers a general adjacency matrix in its latent space; the RC net substitutes the partial role of the decoder and encourages the whole approach to perform further steps of gradient descent based on limited available data. The experimental results on various datasets including biological networks, simulated fMRI data, and physical simulations show the effectiveness and efficiency of our proposed method for structural inference, either with much fewer trajectories or with much shorter trajectories compared with previous works.

**摘要:** 本文通过将 Reservoir Computing(RC)网络集成到 Variational Auto-encoder-based(VAE-based)结构推导框架中,提出一种有效的结构推导方法。采用双级优化,基于VAE的骨干方法遵循信息网格原理,推导其潜在空间中的一般邻接矩阵;RC网取代了解码器的部分作用,鼓励整个方法在有限的可用数据的基础上进行梯度下降的进一步步骤。

**[Paper URL](https://proceedings.mlr.press/v202/wang23ak.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23ak/wang23ak.pdf)** 

# Optimal Goal-Reaching Reinforcement Learning via Quasimetric Learning
**题目:** 四维学习实现目标的优化强化学习

**作者:** Tongzhou Wang, Antonio Torralba, Phillip Isola, Amy Zhang

**Abstract:** In goal-reaching reinforcement learning (RL), the optimal value function has a particular geometry, called quasimetrics structure. This paper introduces Quasimetric Reinforcement Learning (QRL), a new RL method that utilizes quasimetric models to learn optimal value functions. Distinct from prior approaches, the QRL objective is specifically designed for quasimetrics, and provides strong theoretical recovery guarantees. Empirically, we conduct thorough analyses on a discretized MountainCar environment, identifying properties of QRL and its advantages over alternatives. On offline and online goal-reaching benchmarks, QRL also demonstrates improved sample efficiency and performance, across both state-based and image-based observations.

**摘要:** 在目标实现强化学习中,最佳值函数具有特殊的几何,称为准metrics结构。本文介绍准metric Reinforcement Learning(QRL),一种利用准metric模型学习最佳值函数的新RL方法。不同于以往的方法,QRL目标是专门用于准metrics,并提供强有力的理论恢复保证。

**[Paper URL](https://proceedings.mlr.press/v202/wang23al.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23al/wang23al.pdf)** 

# Model-Free Robust Average-Reward Reinforcement Learning
**题目:** 无模型的鲁棒平均奖金增强学习

**作者:** Yue Wang, Alvaro Velasquez, George K. Atia, Ashley Prater-Bennette, Shaofeng Zou

**Abstract:** Robust Markov decision processes (MDPs) address the challenge of model uncertainty by optimizing the worst-case performance over an uncertainty set of MDPs. In this paper, we focus on the robust average-reward MDPs under the model-free setting. We first theoretically characterize the structure of solutions to the robust average-reward Bellman equation, which is essential for our later convergence analysis. We then design two model-free algorithms, robust relative value iteration (RVI) TD and robust RVI Q-learning, and theoretically prove their convergence to the optimal solution. We provide several widely used uncertainty sets as examples, including those defined by the contamination model, total variation, Chi-squared divergence, Kullback-Leibler (KL) divergence, and Wasserstein distance.

**摘要:** 鲁棒马可夫决策过程(MDPs)通过对MDP的不确定性集优化最坏情况来解决模型不确定性的挑战。本文重点讨论了在模型自由设置下的鲁棒平均收益MDP。首先从理论上描述了鲁棒平均收益贝尔曼方程的解决方案的结构,这是我们以后的收敛分析中必不可少的。然后设计了两个模型自由算法,鲁棒相对值迭代(RVI) TD和鲁棒RVI Q-learning,并从理论上证明它们的收敛为最佳解决方案。

**[Paper URL](https://proceedings.mlr.press/v202/wang23am.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23am/wang23am.pdf)** 

# Live in the Moment: Learning Dynamics Model Adapted to Evolving Policy
**题目:** 实时生活:适应政策发展的学习动力学模型

**作者:** Xiyao Wang, Wichayaporn Wongkamjan, Ruonan Jia, Furong Huang

**Abstract:** Model-based reinforcement learning (RL) often achieves higher sample efficiency in practice than model-free RL by learning a dynamics model to generate samples for policy learning. Previous works learn a dynamics model that fits under the empirical state-action visitation distribution for all historical policies, i.e., the sample replay buffer. However, in this paper, we observe that fitting the dynamics model under the distribution for all historical policies does not necessarily benefit model prediction for the current policy since the policy in use is constantly evolving over time. The evolving policy during training will cause state-action visitation distribution shifts. We theoretically analyze how this distribution shift over historical policies affects the model learning and model rollouts. We then propose a novel dynamics model learning method, named Policy-adapted Dynamics Model Learning (PDML). PDML dynamically adjusts the historical policy mixture distribution to ensure the learned model can continually adapt to the state-action visitation distribution of the evolving policy. Experiments on a range of continuous control environments in MuJoCo show that PDML achieves significant improvement in sample efficiency and higher asymptotic performance combined with the state-of-the-art model-based RL methods.

**摘要:** 基于模型的强化学习(RL)通过学习动态模型来生成政策学习的样本,往往在实践中达到比无模型RL更高的样本效率。以前的工作学习了适用于所有历史政策的实证状态行动访问分布的动态模型,即样本重演缓冲。然而,本文观察到,在所有历史政策的分布下调整动态模型不一定有利于当前政策的模型预测,因为使用的政策在时间上不断演变。在训练期间的政策演变会导致状态行动访问分布的转变。PDML动态调整历史政策混合分布,以确保学习模型能持续适应不断变化的政策状态行动访问分布。在MuJoCo中对一系列连续控制环境的实验表明,PDML能够显著提高样品效率和较高的渐近性能,并结合最先进的基于模型的RL方法。

**[Paper URL](https://proceedings.mlr.press/v202/wang23an.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23an/wang23an.pdf)** 

# Learning to Bid in Repeated First-Price Auctions with Budgets
**题目:** 学习以预算为基础的一次性首价拍卖

**作者:** Qian Wang, Zongjun Yang, Xiaotie Deng, Yuqing Kong

**Abstract:** Budget management strategies in repeated auctions have received growing attention in online advertising markets. However, previous work on budget management in online bidding mainly focused on second-price auctions. The rapid shift from second-price auctions to first-price auctions for online ads in recent years has motivated the challenging question of how to bid in repeated first-price auctions while controlling budgets. In this work, we study the problem of learning in repeated first-price auctions with budgets. We design a dual-based algorithm that can achieve a near-optimal $\widetilde{O}(\sqrt{T})$ regret with full information feedback where the maximum competing bid is always revealed after each auction. We further consider the setting with one-sided information feedback where only the winning bid is revealed after each auction. We show that our modified algorithm can still achieve an $\widetilde{O}(\sqrt{T})$ regret with mild assumptions on the bidder’s value distribution. Finally, we complement the theoretical results with numerical experiments to confirm the effectiveness of our budget management policy.

**摘要:** 重复拍卖的预算管理策略在在线广告市场得到了越来越广泛的关注。然而,在网上竞标中的预算管理工作主要集中在第二价拍卖上。近年来,从第二价拍卖到第一价拍卖的快速转变为在线广告,激发了如何在控制预算的同时在重复一级拍卖中竞标的挑战性问题。在这个工作中,我们研究了与预算的重复一级拍卖中学习的问题。我们设计了一个双重算法,可以实现 near-optimal $\widetilde{O}(\sqrt{T})$ regret with full information feedback where the maximum competing bid is always revealed after each auction。我们进一步考虑了与单边信息反馈的设置,其中只有获胜的竞标在每次拍卖后被揭示。我们证明,我们修改的算法仍然能够实现$\widetilde{O}(\sqrt{T})$ regret with mild assumptions最后,我们通过数值实验补充了理论结果,证实了我国预算管理政策的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/wang23ao.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23ao/wang23ao.pdf)** 

# Network Effects in Performative Prediction Games
**题目:** 性能预测游戏中的网络效应

**作者:** Xiaolu Wang, Chung-Yiu Yau, Hoi To Wai

**Abstract:** This paper studies the multi-agent performative prediction (Multi-PP) games over multiplex networks. We consider a distributed learning setting where agents partially cooperate on an agent network, while during learning, the data samples drawn depend on the prediction models of the agent itself and neighboring agents on a population network. The dynamics of Multi-PP games is hence affected by the interplay between both networks. This paper concentrates on this Multi-PP game with the following contributions. Firstly, we analyze sufficient conditions for the existence of the performative stable equilibrium (PSE) and Nash equilibrium (NE) of the Multi-PP games. Secondly, we analyze the changes to the equilibrium induced by perturbed data distributions, and derive the closed-form solutions where the network topologies are explicit. Our results connect the existence of PSE/NE with strengths of agents’ cooperation, and the changes of equilibrium solutions across agents with their node centrality, etc. Lastly, we show that a stochastic gradient descent (SGD) based distributed learning procedure finds the PSE under the said sufficient condition. Numerical illustrations on the network effects in Multi-PP games corroborate our findings.

**摘要:** 本文研究了多代理性能预测(Multi-PP)游戏在多元网络上。我们考虑了代理在代理网络上部分协作的分布式学习环境,同时在学习过程中,抽取的数据样本取决于代理本身和邻近代理在人口网络上的预测模型。因此,多代理游戏的动力学受到两个网络之间的相互作用的影响。本文以下列贡献集中研究多代理性能预测(Multi-PP)游戏:首先,我们分析了多代理游戏的性能稳定均衡(PSE)和纳什均衡(NE)的存在条件;其次,我们分析了受干扰的数据分布所引起的均衡的变化,并得出闭式解决方案,其中网络拓扑是明确的。最后,我们证明基于分布式学习过程的随机梯度下降(SGD)能够在上述条件下找到PSE。多PP游戏网络效应的数值说明证实了我们的发现。

**[Paper URL](https://proceedings.mlr.press/v202/wang23ap.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23ap/wang23ap.pdf)** 

# Robustly Learning a Single Neuron via Sharpness
**题目:** 通过 Sharpness快速学习单个神经元

**作者:** Puqian Wang, Nikos Zarifis, Ilias Diakonikolas, Jelena Diakonikolas

**Abstract:** We study the problem of learning a single neuron with respect to the $L_2^2$-loss in the presence of adversarial label noise. We give an efficient algorithm that, for a broad family of activations including ReLUs, approximates the optimal $L_2^2$-error within a constant factor. Notably, our algorithm succeeds under much milder distributional assumptions compared to prior work. The key ingredient enabling our results is a novel connection to local error bounds from optimization theory.

**摘要:** 我们研究了在敌方标签噪声的情况下学习单神经元$L_2^2$-损失的问题,给出了一个有效的算法,用于包括ReLU在内的广泛的活动群,在一定因素内近似了最佳$L_2^2$-误差。

**[Paper URL](https://proceedings.mlr.press/v202/wang23aq.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23aq/wang23aq.pdf)** 

# DualHSIC: HSIC-Bottleneck and Alignment for Continual Learning
**题目:** DualHSIC:HSIC-Bottleneck and Alignment for Continual Learning

**作者:** Zifeng Wang, Zheng Zhan, Yifan Gong, Yucai Shao, Stratis Ioannidis, Yanzhi Wang, Jennifer Dy

**Abstract:** Rehearsal-based approaches are a mainstay of continual learning (CL). They mitigate the catastrophic forgetting problem by maintaining a small fixed-size buffer with a subset of data from past tasks. While most rehearsal-based approaches exploit the knowledge from buffered past data, little attention is paid to inter-task relationships and to critical task-specific and task-invariant knowledge. By appropriately leveraging inter-task relationships, we propose a novel CL method, named DualHSIC, to boost the performance of existing rehearsal-based methods in a simple yet effective way. DualHSIC consists of two complementary components that stem from the so-called Hilbert Schmidt independence criterion (HSIC): HSIC-Bottleneck for Rehearsal (HBR) lessens the inter-task interference and HSIC Alignment (HA) promotes task-invariant knowledge sharing. Extensive experiments show that DualHSIC can be seamlessly plugged into existing rehearsal-based methods for consistent performance improvements, outperforming recent state-of-the-art regularization-enhanced rehearsal methods.

**摘要:** 基于练习的方法是持续学习(CL)的支柱。它们通过保持一个较小的固定大小缓冲器和从过去的任务中的数据子集来缓解灾难性遗忘问题。虽然大多数基于练习的方法利用缓冲器的过去数据的知识,但很少关注任务间关系和关键任务特定和任务不变知识。通过适当地利用任务间关系,我们提出了一种新的CL方法,叫做DualHSIC,以一种简单而有效的方法提高现有基于练习的方法的性能。广泛的实验表明,DualHSIC可以无缝地连接到现有的试用方法,以持续提高性能,超过了最近最先进的校正增强试用方法。

**[Paper URL](https://proceedings.mlr.press/v202/wang23ar.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23ar/wang23ar.pdf)** 

# Enforcing Hard Constraints with Soft Barriers: Safe Reinforcement Learning in Unknown Stochastic Environments
**题目:** 强有力的约束与软障碍:在未知的随机环境中安全强化学习

**作者:** Yixuan Wang, Simon Sinong Zhan, Ruochen Jiao, Zhilu Wang, Wanxin Jin, Zhuoran Yang, Zhaoran Wang, Chao Huang, Qi Zhu

**Abstract:** It is quite challenging to ensure the safety of reinforcement learning (RL) agents in an unknown and stochastic environment under hard constraints that require the system state not to reach certain specified unsafe regions. Many popular safe RL methods such as those based on the Constrained Markov Decision Process (CMDP) paradigm formulate safety violations in a cost function and try to constrain the expectation of cumulative cost under a threshold. However, it is often difficult to effectively capture and enforce hard reachability-based safety constraints indirectly with such constraints on safety violation cost. In this work, we leverage the notion of barrier function to explicitly encode the hard safety chance constraints, and given that the environment is unknown, relax them to our design of generative-model-based soft barrier functions. Based on such soft barriers, we propose a novel safe RL approach with bi-level optimization that can jointly learn the unknown environment and optimize the control policy, while effectively avoiding the unsafe region with safety probability optimization. Experiments on a set of examples demonstrate that our approach can effectively enforce hard safety chance constraints and significantly outperform CMDP-based baseline methods in system safe rates measured via simulations.

**摘要:** 在一个未知和随机环境下,需要系统状态不到达特定不安全的 Hard constraints下,保证增强学习(RL)代理的安全性是相当困难的。许多流行的安全RL方法,例如基于约束马可夫决策过程(CMDP)范式,在成本函数中制订了安全违反,并试图限制在阈值下累积成本的期望。然而,往往很难有效地捕捉和强制性安全违反成本的 Hard reachability-based safety constraints 间接地使用这些约束。基于这些软屏障,我们提出了一种具有双级优化的新型安全RL方法,可以共同学习未知环境,优化控制政策,同时有效地避免不安全的区域,并优化安全概率。

**[Paper URL](https://proceedings.mlr.press/v202/wang23as.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23as/wang23as.pdf)** 

# LinSATNet: The Positive Linear Satisfiability Neural Networks
**题目:** LinSATNet:积极的线性满意度神经网络

**作者:** Runzhong Wang, Yunhao Zhang, Ziao Guo, Tianyi Chen, Xiaokang Yang, Junchi Yan

**Abstract:** Encoding constraints into neural networks is attractive. This paper studies how to introduce the popular positive linear satisfiability to neural networks. We propose the first differentiable satisfiability layer based on an extension of the classic Sinkhorn algorithm for jointly encoding multiple sets of marginal distributions. We further theoretically characterize the convergence property of the Sinkhorn algorithm for multiple marginals, and the underlying formulation is also derived. In contrast to the sequential decision e.g. reinforcement learning-based solvers, we showcase our technique in solving constrained (specifically satisfiability) problems by one-shot neural networks, including i) a neural routing solver learned without supervision of optimal solutions; ii) a partial graph matching network handling graphs with unmatchable outliers on both sides; iii) a predictive network for financial portfolios with continuous constraints. To our knowledge, there exists no one-shot neural solver for these scenarios when they are formulated as satisfiability problems. Source code is available at https://github.com/Thinklab-SJTU/LinSATNet.

**摘要:** 本文研究了如何在神经网络中引入普遍的正线性满足性。我们提出了基于经典辛克宏算法的扩展的第一个可微分满足性层,用于联合编码多组边缘分布。我们进一步从理论上描述了辛克宏算法对多边的收敛特性,并导出了其基本公式。与基于增强学习的求解方法相比,我们展示了通过一击神经网络解决约束性(具体满足性)问题的方法,包括:(i)无优化解决方案监督的神经路由求解器;(ii)部分图与网络处理图相匹配;(iii)连续约束的金融组合预测网络。据我们所知,当这些场景被编写为满足性问题时,不存在一击神经解决器。源代码可于 https://github.com/Thinklab-SJTU/LinSATNet。

**[Paper URL](https://proceedings.mlr.press/v202/wang23at.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23at/wang23at.pdf)** 

# Offline Meta Reinforcement Learning with In-Distribution Online Adaptation
**题目:** 基于分布式在线适应的非线性元数据增强学习

**作者:** Jianhao Wang, Jin Zhang, Haozhe Jiang, Junyu Zhang, Liwei Wang, Chongjie Zhang

**Abstract:** Recent offline meta-reinforcement learning (meta-RL) methods typically utilize task-dependent behavior policies (e.g., training RL agents on each individual task) to collect a multi-task dataset. However, these methods always require extra information for fast adaptation, such as offline context for testing tasks. To address this problem, we first formally characterize a unique challenge in offline meta-RL: transition-reward distribution shift between offline datasets and online adaptation. Our theory finds that out-of-distribution adaptation episodes may lead to unreliable policy evaluation and that online adaptation with in-distribution episodes can ensure adaptation performance guarantee. Based on these theoretical insights, we propose a novel adaptation framework, called In-Distribution online Adaptation with uncertainty Quantification (IDAQ), which generates in-distribution context using a given uncertainty quantification and performs effective task belief inference to address new tasks. We find a return-based uncertainty quantification for IDAQ that performs effectively. Experiments show that IDAQ achieves state-of-the-art performance on the Meta-World ML1 benchmark compared to baselines with/without offline adaptation.

**摘要:** 最近的非线性元增强学习(meta-RL)方法通常使用任务依赖行为政策(例如,在每个单独任务上训练RL代理人)来收集多任务数据集。然而,这些方法总是需要快速适应的额外信息,例如测试任务的非线性上下文。基于这些理论洞察,我们提出了一种名为In-Distribution Online Adaptation with Uncertainty Quantification(IDAQ)的新适应框架,该框架利用给定的不确定性量化生成在分布范围内的上下文,并执行有效的任务信条推导来处理新的任务。

**[Paper URL](https://proceedings.mlr.press/v202/wang23au.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23au/wang23au.pdf)** 

# Reachability-Aware Laplacian Representation in Reinforcement Learning
**题目:** 增强学习中的可达性意识的拉普拉西亚代表

**作者:** Kaixin Wang, Kuangqi Zhou, Jiashi Feng, Bryan Hooi, Xinchao Wang

**Abstract:** In Reinforcement Learning (RL), Laplacian Representation (LapRep) is a task-agnostic state representation that encodes the geometry of the environment. A desirable property of LapRep stated in prior works is that the Euclidean distance in the LapRep space roughly reflects the reachability between states, which motivates the usage of this distance for reward shaping. However, we find that LapRep does not necessarily have this property in general: two states having a small distance under LapRep can actually be far away in the environment. Such a mismatch would impede the learning process in reward shaping. To fix this issue, we introduce a Reachability-Aware Laplacian Representation (RA-LapRep), by properly scaling each dimension of LapRep. Despite the simplicity, we demonstrate that RA-LapRep can better capture the inter-state reachability as compared to LapRep, through both theoretical explanations and experimental results. Additionally, we show that this improvement yields a significant boost in reward shaping performance and benefits bottleneck state discovery.

**摘要:** 在强化学习(RL)中,拉普拉斯代表(LapRep)是一个具有环境几何特征的任务- agnostic状态表示。在先前的工作中指出的拉普拉斯的理想属性是拉普拉斯空间的欧几里德距离大致反映了状态间的可达性,从而促使使用这个距离来塑造奖励。然而,我们发现拉普拉斯不一定具有这个属性:两个状态在拉普拉斯下有小距离,实际上可以在环境中很远。此外,我们证明,这种改进能显著提高奖励塑造性能,并有利于瓶颈状态的发现。

**[Paper URL](https://proceedings.mlr.press/v202/wang23av.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23av/wang23av.pdf)** 

# PPG Reloaded: An Empirical Study on What Matters in Phasic Policy Gradient
**题目:** 重载PPG:中期政策评级中重要事项的实证研究

**作者:** Kaixin Wang, Daquan Zhou, Jiashi Feng, Shie Mannor

**Abstract:** In model-free reinforcement learning, recent methods based on a phasic policy gradient (PPG) framework have shown impressive improvements in sample efficiency and zero-shot generalization on the challenging Procgen benchmark. In PPG, two design choices are believed to be the key contributing factors to its superior performance over PPO: the high level of value sample reuse and the low frequency of feature distillation. However, through an extensive empirical study, we unveil that policy regularization and data diversity are what actually matters. In particular, we can achieve the same level of performance with low value sample reuse and frequent feature distillation, as long as the policy regularization strength and data diversity are preserved. In addition, we can maintain the high performance of PPG while reducing the computational cost to a similar level as PPO. Our comprehensive study covers all 16 Procgen games in both sample efficiency and generalization setups. We hope it can advance the understanding of PPG and provide insights for future works.

**摘要:** 在无模型强化学习中,基于渐进政策梯度(PPG)框架的近来方法显示了在具有挑战性Procgen基准的样品效率和零击一般化方面的令人印象深刻的改进。在PPG中,两个设计选择被认为是其比PPO高性能的关键贡献因素:高值样品重用和特征蒸馏的低频率。然而,通过广泛的实证研究,我们揭示了政策规范化和数据多样化才是真正重要的。我们希望它能够促进PPG的理解,并为今后的工作提供洞察力。

**[Paper URL](https://proceedings.mlr.press/v202/wang23aw.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wang23aw/wang23aw.pdf)** 

# On Heterogeneous Treatment Effects in Heterogeneous Causal Graphs
**题目:** 异性致病图中的异性治疗效果

**作者:** Richard A Watson, Hengrui Cai, Xinming An, Samuel Mclean, Rui Song

**Abstract:** Heterogeneity and comorbidity are two interwoven challenges associated with various healthcare problems that greatly hampered research on developing effective treatment and understanding of the underlying neurobiological mechanism. Very few studies have been conducted to investigate heterogeneous causal effects (HCEs) in graphical contexts due to the lack of statistical methods. To characterize this heterogeneity, we first conceptualize heterogeneous causal graphs (HCGs) by generalizing the causal graphical model with confounder-based interactions and multiple mediators. Such confounders with an interaction with the treatment are known as moderators. This allows us to flexibly produce HCGs given different moderators and explicitly characterize HCEs from the treatment or potential mediators on the outcome. We establish the theoretical forms of HCEs and derive their properties at the individual level in both linear and nonlinear models. An interactive structural learning is developed to estimate the complex HCGs and HCEs with confidence intervals provided. Our method is empirically justified by extensive simulations and its practical usefulness is illustrated by exploring causality among psychiatric disorders for trauma survivors. Code implementing the proposed algorithm is open-source and publicly available at: https://github.com/richard-watson/ISL.

**摘要:** 异质性与异质性是与各种医疗问题有关的两个相互关联的挑战,严重阻碍了研究开发有效的治疗和理解神经生物学机制。由于缺乏统计方法,在图形环境中研究异质性因果效应(HCEs)的研究已经进行了很少。为了对这种异质性进行特征,我们首先通过对异质性因果图(HCGs)的一般化,将因果图模型与异质性因果相互作用和多种调解者相结合来概念化异质性因果图。与治疗相互作用的异质性因果者被称为调解者。开发了一个交互式结构性学习方法,以评估复杂的HCG和HCEs,并提供信任间隔。我们的方法通过广泛的仿真实证,并通过探讨创伤幸存者精神病的因果关系来说明其实用价值。

**[Paper URL](https://proceedings.mlr.press/v202/watson23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/watson23a/watson23a.pdf)** 

# Nonparametric Extensions of Randomized Response for Private Confidence Sets
**题目:** 私人保密集随机响应非参数扩展

**作者:** Ian Waudby-Smith, Steven Wu, Aaditya Ramdas

**Abstract:** This work derives methods for performing nonparametric, nonasymptotic statistical inference for population means under the constraint of local differential privacy (LDP). Given bounded observations $(X_1, …, X_n)$ with mean $\mu^\star$ that are privatized into $(Z_1, …, Z_n)$, we present confidence intervals (CI) and time-uniform confidence sequences (CS) for $\mu^\star$ when only given access to the privatized data. To achieve this, we introduce a nonparametric and sequentially interactive generalization of Warner’s famous “randomized response” mechanism, satisfying LDP for arbitrary bounded random variables, and then provide CIs and CSs for their means given access to the resulting privatized observations. For example, our results yield private analogues of Hoeffding’s inequality in both fixed-time and time-uniform regimes. We extend these Hoeffding-type CSs to capture time-varying (non-stationary) means, and conclude by illustrating how these methods can be used to conduct private online A/B tests.

**摘要:** 该研究导出了在局部微分私隐约束下对人口手段进行非参数、非渐近统计推导的方法。 考虑$(X_1,..., X_n)$与平均$\mu^\star$被私有化为$(Z_1,..., Z_n)$,我们给出$\mu^\star$的信任间隔(CI)和时间均匀信任序列(CS),当只提供访问私有化数据时。我们将这些霍夫丁式CS扩展到捕捉时间变化的(非静态)手段,并以说明这些方法如何进行私人在线A/B测试为结论。

**[Paper URL](https://proceedings.mlr.press/v202/waudby-smith23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/waudby-smith23a/waudby-smith23a.pdf)** 

# Global optimality for Euclidean CCCP under Riemannian convexity
**题目:** 黎曼凸度下的欧几里达CCCP的全球优化

**作者:** Melanie Weber, Suvrit Sra

**Abstract:** We study geodesically convex (g-convex) problems that can be written as a difference of Euclidean convex functions. This structure arises in key applications such as matrix scaling, M- estimators of scatter matrices, and Brascamp-Lieb inequalities. In particular, we exploit this structure to make use of the Convex-Concave Procedure (CCCP), which helps us bypass potentially expensive Riemannian operations and leads to very competitive solvers. Importantly, unlike existing theory for CCCP that ensures convergence to stationary points, we exploit the overall g-convexity structure and provide iteration complexity results for global optimality. We illustrate our results by specializing them to a few concrete optimization problems that have been previously studied in the machine learning literature. We hope our work spurs the study of mixed Euclidean-Riemannian optimization algorithms.

**摘要:** 我们研究了几何凸(g-凸)问题,可以作为欧氏凸函数的差异写成。这种结构在诸如矩阵尺度、散布矩阵的M-估计器和Brascamp-Lieb不平等等关键应用中产生。特别是,我们利用这个结构利用凸凸过程(CCCP),帮助我们绕过潜在昂贵的黎曼操作并导致非常竞争的求解者。

**[Paper URL](https://proceedings.mlr.press/v202/weber23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/weber23a/weber23a.pdf)** 

# A Universal Unbiased Method for Classification from Aggregate Observations
**题目:** 综合观测分类的普遍公正方法

**作者:** Zixi Wei, Lei Feng, Bo Han, Tongliang Liu, Gang Niu, Xiaofeng Zhu, Heng Tao Shen

**Abstract:** In conventional supervised classification, true labels are required for individual instances. However, it could be prohibitive to collect the true labels for individual instances, due to privacy concerns or unaffordable annotation costs. This motivates the study on classification from aggregate observations (CFAO), where the supervision is provided to groups of instances, instead of individual instances. CFAO is a generalized learning framework that contains various learning problems, such as multiple-instance learning and learning from label proportions. The goal of this paper is to present a novel universal method of CFAO, which holds an unbiased estimator of the classification risk for arbitrary losses—previous research failed to achieve this goal. Practically, our method works by weighing the importance of each instance and each label in the group, which provides purified supervision for the classifier to learn. Theoretically, our proposed method not only guarantees the risk consistency due to the unbiased risk estimator but also can be compatible with arbitrary losses. Extensive experiments on various problems of CFAO demonstrate the superiority of our proposed method.

**摘要:** 在传统的监督分类中,对个别实例需要真正的标签,然而,由于隐私问题或无法负担的注释成本,收集个别实例的真正的标签可能是违法的。这促使从综合观察(CFAO)进行分类研究,其中监督是针对个别实例的组别提供,而不是个别实例。CFAO是一个综合学习框架,包含各种学习问题,例如多实例学习和从标签比例学习。本论文的目的是提出一种新的CFAO通用方法,该方法为任意损失的分类风险进行公正的估计 — — 此前的研究未能达到这一目标。从理论上看,我们提出的方法不仅保证了不偏不倚风险估计器所带来的风险一致性,而且可以与任意损失相适应。

**[Paper URL](https://proceedings.mlr.press/v202/wei23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wei23a/wei23a.pdf)** 

# NTK-approximating MLP Fusion for Efficient Language Model Fine-tuning
**题目:** NTK近似MLP融合为高效语言模型微调

**作者:** Tianxin Wei, Zeming Guo, Yifan Chen, Jingrui He

**Abstract:** Fine-tuning a pre-trained language model (PLM) emerges as the predominant strategy in many natural language processing applications. However, even fine-tuning the PLMs and doing inference are expensive, especially on edge devices with low computing power. Some general approaches (e.g. quantization and distillation) have been widely studied to reduce the compute/memory of PLM fine-tuning, while very few one-shot compression techniques are explored. In this paper, we investigate the neural tangent kernel (NTK)–which reveals the gradient descent dynamics of neural networks–of the multilayer perceptrons (MLP) modules in a PLM and propose to coin a lightweight PLM through NTK-approximating MLP fusion. To achieve this, we reconsider the MLP as a bundle of sub-MLPs, and cluster them into a given number of centroids, which can then be restored as a compressed MLP and surprisingly shown to well approximate the NTK of the original PLM. Extensive experiments of PLM fine-tuning on both natural language understanding (NLU) and generation (NLG) tasks are provided to verify the effectiveness of the proposed method MLP fusion. Our code is available at https://github.com/weitianxin/MLP_Fusion.

**摘要:** 预训练语言模型(PLM)的精细调制作为许多自然语言处理应用的主导策略。然而,即使精细调制的PLM和推导都是昂贵的,特别是在低计算能力的边缘设备上。一些一般方法(例如量化和蒸馏)已被广泛研究,以减少PLM精细调制的计算/记忆,而很少的单击压缩技术被研究。对自然语言理解(NLU)和生成(NLG)任务的PLM微调进行了广泛的实验,以验证拟议的MLP融合方法的有效性。我们的代码可于 https://github.com/weitianxin/MLP_Fusion。

**[Paper URL](https://proceedings.mlr.press/v202/wei23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wei23b/wei23b.pdf)** 

# Boosting Graph Contrastive Learning via Graph Contrastive Saliency
**题目:** 增强图形对比学习通过图形对比嗅觉

**作者:** Chunyu Wei, Yu Wang, Bing Bai, Kai Ni, David Brady, Lu Fang

**Abstract:** Graph augmentation plays a crucial role in achieving good generalization for contrastive graph self-supervised learning. However, mainstream Graph Contrastive Learning (GCL) often favors random graph augmentations, by relying on random node dropout or edge perturbation on graphs. Random augmentations may inevitably lead to semantic information corruption during the training, and force the network to mistakenly focus on semantically irrelevant environmental background structures. To address these limitations and to improve generalization, we propose a novel self-supervised learning framework for GCL, which can adaptively screen the semantic-related substructure in graphs by capitalizing on the proposed gradient-based Graph Contrastive Saliency (GCS). The goal is to identify the most semantically discriminative structures of a graph via contrastive learning, such that we can generate semantically meaningful augmentations by leveraging on saliency. Empirical evidence on 16 benchmark datasets demonstrates the exclusive merits of the GCS-based framework. We also provide rigorous theoretical justification for GCS’s robustness properties. Code is available at https://github.com/GCS2023/GCS .

**摘要:**  Graph augmentation 在实现对比图自我监督学习的良好一般化中起着关键作用。然而,主流的对比图学习(GCL)经常倾向于随机的对比图增强,依靠随机节点退出或边缘扰动在图上。随机增强可能不可避免地导致训练期间的语义信息腐败,并迫使网络错误地集中于语义无关环境背景结构。为了解决这些限制和改进一般化,我们建议GCL的新自我监督学习框架,该框架可以通过利用提议的梯度基础对比图(GCS)来适应性筛选图中的语义相关部分结构。16个基准数据集的实证证明了基于GCS的框架的独一无二的优点。我们还为GCS的鲁棒性特性提供严格的理论理由。代码可于 https://github.com/GCS2023/GCS 。

**[Paper URL](https://proceedings.mlr.press/v202/wei23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wei23c/wei23c.pdf)** 

# Set-membership Belief State-based Reinforcement Learning for POMDPs
**题目:** 强积金计划署的国别强化学习计划

**作者:** Wei Wei, Lijun Zhang, Lin Li, Huizhong Song, Jiye Liang

**Abstract:** Reinforcement learning (RL) has made significant progress in areas such as Atari games and robotic control, where the agents have perfect sensing capabilities. However, in many real-world sequential decision-making tasks, the observation data could be noisy or incomplete due to the intrinsic low quality of the sensors or unexpected malfunctions; that is, the agent’s perceptions are rarely perfect. The current POMDP RL methods, such as particle-based and Gaussian-based, can only provide a probability estimate of hidden states rather than certain belief regions, which may lead to inefficient and even wrong decision-making. This paper proposes a novel algorithm called Set-membership Belief state-based Reinforcement Learning (SBRL), which consists of two parts: a Set-membership Belief state learning Model (SBM) for learning bounded belief state sets and an RL controller for making decisions based on SBM. We prove that our belief estimation method can provide a series of belief state sets that always contain the true states under the unknown-but-bounded (UBB) noise. The effectiveness of the proposed method is verified on a collection of benchmark tasks, and the results show that our method outperforms the state-of-the-art methods.

**摘要:** 强化学习(RL)在Atari游戏和机器人控制等领域取得了显著的进展,其中代理人具有完美的感知能力。然而,在许多实世界连续决策任务中,观察数据可能由于传感器的内在低质量或意外故障引起噪声或不完整,即代理人的感知很少完美。目前的POMDP RL方法,例如基于粒子和高斯的,只能提供隐藏状态的概率估计,而不是某些信念区域,这可能导致不效率甚至错误决策。我们证明,我们的信念估计方法能够提供一系列的信念状态集,它们总是包含未知但约束的(UBB)噪声下的真实状态。我们通过对基准任务的集合验证了该方法的有效性,结果表明该方法优于最先进的方法。

**[Paper URL](https://proceedings.mlr.press/v202/wei23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wei23d/wei23d.pdf)** 

# Mitigating Memorization of Noisy Labels by Clipping the Model Prediction
**题目:** 通过剪切模型预测来减轻噪声标签的记忆

**作者:** Hongxin Wei, Huiping Zhuang, Renchunzi Xie, Lei Feng, Gang Niu, Bo An, Yixuan Li

**Abstract:** In the presence of noisy labels, designing robust loss functions is critical for securing the generalization performance of deep neural networks. Cross Entropy (CE) loss has been shown to be not robust to noisy labels due to its unboundedness. To alleviate this issue, existing works typically design specialized robust losses with the symmetric condition, which usually lead to the underfitting issue. In this paper, our key idea is to induce a loss bound at the logit level, thus universally enhancing the noise robustness of existing losses. Specifically, we propose logit clipping (LogitClip), which clamps the norm of the logit vector to ensure that it is upper bounded by a constant. In this manner, CE loss equipped with our LogitClip method is effectively bounded, mitigating the overfitting to examples with noisy labels. Moreover, we present theoretical analyses to certify the noise-tolerant ability of LogitClip. Extensive experiments show that LogitClip not only significantly improves the noise robustness of CE loss, but also broadly enhances the generalization performance of popular robust losses.

**摘要:** 在噪声标签的存在下,设计鲁棒损伤函数是保证深层神经网络的通用性能的关键。由于其无界性,交叉熵损伤已经证明对噪声标签不具有鲁棒性。为了缓解这一问题,现有的工作通常设计具有对称条件的鲁棒损伤,通常导致低性能问题。本论文的重点是诱导在 logit级的损伤界限,从而普遍提高现有损伤的噪声鲁棒性。具体,我们提出了 logit clipping(LogitClip),它将 logit向量规范锁定以确保其以恒定为上限。广泛的实验表明,LogitClip不仅显著提高了CE损耗的噪声鲁棒性,而且广泛提高了流行的鲁棒损耗的一般化性能。

**[Paper URL](https://proceedings.mlr.press/v202/wei23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wei23e/wei23e.pdf)** 

# Graphically Structured Diffusion Models
**题目:** 图形结构扩散模型

**作者:** Christian Dietrich Weilbach, William Harvey, Frank Wood

**Abstract:** We introduce a framework for automatically defining and learning deep generative models with problem-specific structure. We tackle problem domains that are more traditionally solved by algorithms such as sorting, constraint satisfaction for Sudoku, and matrix factorization. Concretely, we train diffusion models with an architecture tailored to the problem specification. This problem specification should contain a graphical model describing relationships between variables, and often benefits from explicit representation of subcomputations. Permutation invariances can also be exploited. Across a diverse set of experiments we improve the scaling relationship between problem dimension and our model’s performance, in terms of both training time and final accuracy. Our code can be found at https://github.com/plai-group/gsdm.

**摘要:** 我们引入了自动定义和学习具有问题特有结构的深层生成模型的框架。我们处理由类别、约束满足、矩阵因子化等算法传统上解决的问题领域。具体地说,我们训练了针对问题特有结构的扩散模型。该问题特有应该包含描述变量之间的关系的图形模型,并经常从分数的显式表示中获益。变量变量也可以利用。在各种实验中,我们改进了问题维度和模型的性能之间的比例关系,包括训练时间和最终的准确性。我们的代码可以在 https://github.com/plai-group/gsdm 上找到。

**[Paper URL](https://proceedings.mlr.press/v202/weilbach23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/weilbach23a/weilbach23a.pdf)** 

# Expectation-Complete Graph Representations with Homomorphisms
**题目:** 期望-完全图表表示与同态

**作者:** Pascal Welke, Maximilian Thiessen, Fabian Jogl, Thomas Gärtner

**Abstract:** We investigate novel random graph embeddings that can be computed in expected polynomial time and that are able to distinguish all non-isomorphic graphs in expectation. Previous graph embeddings have limited expressiveness and either cannot distinguish all graphs or cannot be computed efficiently for every graph. To be able to approximate arbitrary functions on graphs, we are interested in efficient alternatives that become arbitrarily expressive with increasing resources. Our approach is based on Lovász’ characterisation of graph isomorphism through an infinite dimensional vector of homomorphism counts. Our empirical evaluation shows competitive results on several benchmark graph learning tasks.

**摘要:** 我们研究新的随机图嵌入式,能够在预期多项式时间中计算,并且能够在预期中区分所有非同型图。以前的图嵌入式具有有限的表达性,要么不能区分所有图,要么不能对每个图进行有效的计算。为了能够对图中任意函数的近似,我们对增加资源的任意表达式具有兴趣。

**[Paper URL](https://proceedings.mlr.press/v202/welke23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/welke23a/welke23a.pdf)** 

# A Conditional Normalizing Flow for Accelerated Multi-Coil MR Imaging
**题目:** 一种加速多圈MR成像条件下正常化流

**作者:** Jeffrey Wen, Rizwan Ahmad, Philip Schniter

**Abstract:** Accelerated magnetic resonance (MR) imaging attempts to reduce acquisition time by collecting data below the Nyquist rate. As an ill-posed inverse problem, many plausible solutions exist, yet the majority of deep learning approaches generate only a single solution. We instead focus on sampling from the posterior distribution, which provides more comprehensive information for downstream inference tasks. To do this, we design a novel conditional normalizing flow (CNF) that infers the signal component in the measurement operator’s nullspace, which is later combined with measured data to form complete images. Using fastMRI brain and knee data, we demonstrate fast inference and accuracy that surpasses recent posterior sampling techniques for MRI. Code is available at https://github.com/jwen307/mri_cnf

**摘要:** 加速磁共振(MR)成像试图通过在尼奎斯特率下收集数据来减少采集时间。作为一种不良的逆问题,有许多可行的解决方案存在,但大多数深层学习方法只产生一个解决方案。我们相反地集中于后方分布的采样,为下游推理任务提供更全面的信息。为此,我们设计了一种新的条件正常化流(CNF)来推导测量操作员的零空间中的信号组成部分,后来与测量数据结合形成完整的图像。

**[Paper URL](https://proceedings.mlr.press/v202/wen23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wen23a/wen23a.pdf)** 

# Optimizing Mode Connectivity for Class Incremental Learning
**题目:** 优化模式连通性,提高班级学习水平

**作者:** Haitao Wen, Haoyang Cheng, Heqian Qiu, Lanxiao Wang, Lili Pan, Hongliang Li

**Abstract:** Class incremental learning (CIL) is one of the most challenging scenarios in continual learning. Existing work mainly focuses on strategies like memory replay, regularization, or dynamic architecture but ignores a crucial aspect: mode connectivity. Recent studies have shown that different minima can be connected by a low-loss valley, and ensembling over the valley shows improved performance and robustness. Motivated by this, we try to investigate the connectivity in CIL and find that the high-loss ridge exists along the linear connection between two adjacent continual minima. To dodge the ridge, we propose parameter-saving OPtimizing Connectivity (OPC) based on Fourier series and gradient projection for finding the low-loss path between minima. The optimized path provides infinite low-loss solutions. We further propose EOPC to ensemble points within a local bent cylinder to improve performance on learned tasks. Our scheme can serve as a plug-in unit, extensive experiments on CIFAR-100, ImageNet-100, and ImageNet-1K show consistent improvements when adapting EOPC to existing representative CIL methods. Our code is available at https://github.com/HaitaoWen/EOPC.

**摘要:** 类增益学习(CIL)是持续学习中最具有挑战性的场景之一。现有的工作主要集中在存储重演、校正、动态架构等策略上,但忽略了一个关键方面:模式连接。最近的研究表明,不同的 minima可以通过低损失谷连接,并且在谷上堆积显示改进的性能和鲁棒性。为此,我们试图研究CIL中的连接,并发现高损失脊在两个相邻的连续 minima之间的线性连接中存在。为了避开脊,我们提出了基于傅立叶系列和梯度投影的参数节约优化连接(Optimizing Connectivity,OPC)。我们的方案可以作为一个插件,在CIFAR-100、ImageNet-100和ImageNet-1K上进行的广泛实验显示,在将EOPC适应现有的代表性CIL方法时,有持续的改进。我们的代码可浏览 https://github.com/HaitaoWen/EOPC。

**[Paper URL](https://proceedings.mlr.press/v202/wen23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wen23b/wen23b.pdf)** 

# Towards Learning Geometric Eigen-Lengths Crucial for Fitting Tasks
**题目:** 学习地理特征-长度是适应任务的关键

**作者:** Yijia Weng, Kaichun Mo, Ruoxi Shi, Yanchao Yang, Leonidas Guibas

**Abstract:** Some extremely low-dimensional yet crucial geometric eigen-lengths often determine the success of some geometric tasks. For example, the height of an object is important to measure to check if it can fit between the shelves of a cabinet, while the width of a couch is crucial when trying to move it through a doorway. Humans have materialized such crucial geometric eigen-lengths in common sense since they are very useful in serving as succinct yet effective, highly interpretable, and universal object representations. However, it remains obscure and underexplored if learning systems can be equipped with similar capabilities of automatically discovering such key geometric quantities from doing tasks. In this work, we therefore for the first time formulate and propose a novel learning problem on this question and set up a benchmark suite including tasks, data, and evaluation metrics for studying the problem. We focus on a family of common fitting tasks as the testbed for the proposed learning problem. We explore potential solutions and demonstrate the feasibility of learning eigen-lengths from simply observing successful and failed fitting trials. We also attempt geometric grounding for more accurate eigen-length measurement and study the reusability of the learned geometric eigen-lengths across multiple tasks. Our work marks the first exploratory step toward learning crucial geometric eigen-lengths and we hope it can inspire future research in tackling this important yet underexplored problem.

**摘要:** 一些极低维度但关键的几何特征长度往往决定了某些几何任务的成功。例如,一个对象的高度是重要的测量,以确定它是否能够在柜子的架子之间匹配,而一张沙发的宽度是关键的,当试图通过门廊移动它时。人类已经在一般意义上实现这些关键的几何特征长度,因为它们在作为简洁而有效的、高度可解释和普遍对象的表示中非常有用。本文主要着重于一组共同的适应任务,作为拟议的学习问题测试平台。我们探索潜在的解决方法,并通过观察成功和失败的适应试验来证明学习特征长度的可行性。我们还尝试建立更准确的特征长度测量的几何基础,并研究学习的几何特征长度在多个任务中再利用性。

**[Paper URL](https://proceedings.mlr.press/v202/weng23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/weng23a/weng23a.pdf)** 

# Open-VCLIP: Transforming CLIP to an Open-vocabulary Video Model via Interpolated Weight Optimization
**题目:** Open-VCLIP:通过插值重量优化将CLIP转换为一个开放口语视频模型

**作者:** Zejia Weng, Xitong Yang, Ang Li, Zuxuan Wu, Yu-Gang Jiang

**Abstract:** Contrastive Language-Image Pretraining (CLIP) has demonstrated impressive zero-shot learning abilities for image understanding, yet limited effort has been made to investigate CLIP for zero-shot video recognition. We introduce Open-VCLIP, a simple yet effective approach that transforms CLIP into a strong zero-shot video classifier that can recognize unseen actions and events at test time. Our framework extends CLIP with minimal modifications to model spatial-temporal relationships in videos, making it a specialized video classifier, while striving for generalization. We formally show that training an Open-VCLIP is equivalent to continual learning with zero historical data. To address this problem, we propose Interpolated Weight Optimization, which utilizes the benefit of weight interpolation in both training and test time. We evaluate our method on three popular and challenging action recognition datasets following various zero-shot evaluation protocols and we demonstrate our approach outperforms state-of-the-art methods by clear margins. In particular, we achieve 87.9%, 58.3%, 81.1% zero-shot accuracy on UCF, HMDB and Kinetics-600 respectively, outperforming state-of-the-art methods by 8.3%, 7.8% and 12.2%. Code is released at https://github.com/wengzejia1/Open-VCLIP.

**摘要:** 对比语言-图像预训练(CLIP)为图像理解提供了令人印象深刻的零射击学习能力,但对零射击视频识别的CLIP进行了有限的努力。我们介绍了Open-VCLIP,一种简单而有效的方法,将CLIP转变为一个强大的零射击视频分类器,能够在测试时识别未见的动作和事件。我们的框架以最小修改的方式扩展CLIP,使视频中的空间-时空关系模型成为专门的视频分类器,同时努力推广。我们根据不同的零射击评估协议,对三个流行和挑战性的行动识别数据集进行评估,并通过清晰的边界证明我们的方法超过了最先进的方法。我们分别在UCF、HMDB和Kinetics-600中达到87.9%、58.3%、81.1%的零射击精度,超过了最先进的方法8.3%、7.8 %和12.2%。

**[Paper URL](https://proceedings.mlr.press/v202/weng23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/weng23b/weng23b.pdf)** 

# Fully-Adaptive Composition in Differential Privacy
**题目:** 分离性隐私的全面适应性构成

**作者:** Justin Whitehouse, Aaditya Ramdas, Ryan Rogers, Steven Wu

**Abstract:** Composition is a key feature of differential privacy. Well-known advanced composition theorems allow one to query a private database quadratically more times than basic privacy composition would permit. However, these results require that the privacy parameters of all algorithms be fixed before interacting with the data. To address this, Rogers et al. introduced fully adaptive composition, wherein both algorithms and their privacy parameters can be selected adaptively. They defined two probabilistic objects to measure privacy in adaptive composition: privacy filters, which provide differential privacy guarantees for composed interactions, and privacy odometers, time-uniform bounds on privacy loss. There are substantial gaps between advanced composition and existing filters and odometers. First, existing filters place stronger assumptions on the algorithms being composed. Second, these odometers and filters suffer from large constants, making them impractical. We construct filters that match the rates of advanced composition, including constants, despite allowing for adaptively chosen privacy parameters. En route we also derive a privacy filter for approximate zCDP. We also construct several general families of odometers. These odometers match the tightness of advanced composition at an arbitrary, preselected point in time, or at all points in time simultaneously, up to a doubly-logarithmic factor. We obtain our results by leveraging advances in martingale concentration. In sum, we show that fully adaptive privacy is obtainable at almost no loss.

**摘要:** 组合是微分隐私的一个关键特征。众所周知的高级组合定理允许一个查询一个私人数据库的二次性时间比基本隐私组合允许的多。然而,这些结果要求所有算法的隐私参数在与数据相互作用之前固定。为了解决这个问题,罗杰斯等人引入了完全适应性组合,其中 both algorithms and their privacy parameters can be selected adaptively。我们构建了匹配高级组合率的滤波器,包括常数,尽管允许采用自适应选择的隐私参数。在路径上,我们还导出了近似zCDP的隐私滤波器。我们还构建了几种一般类别的计量器。这些计量器在任意、预选的时点或在所有时点同时匹配高级组合的紧迫性,最大达到双重数值系数。

**[Paper URL](https://proceedings.mlr.press/v202/whitehouse23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/whitehouse23a/whitehouse23a.pdf)** 

# Scalable Set Encoding with Universal Mini-Batch Consistency and Unbiased Full Set Gradient Approximation
**题目:** 具有通用小批量一致性和不偏不倚的全套梯度近似的可 skalable set encoding

**作者:** Jeffrey Willette, Seanie Lee, Bruno Andreis, Kenji Kawaguchi, Juho Lee, Sung Ju Hwang

**Abstract:** Recent work on mini-batch consistency (MBC) for set functions has brought attention to the need for sequentially processing and aggregating chunks of a partitioned set while guaranteeing the same output for all partitions. However, existing constraints on MBC architectures lead to models with limited expressive power. Additionally, prior work has not addressed how to deal with large sets during training when the full set gradient is required. To address these issues, we propose a Universally MBC (UMBC) class of set functions which can be used in conjunction with arbitrary non-MBC components while still satisfying MBC, enabling a wider range of function classes to be used in MBC settings. Furthermore, we propose an efficient MBC training algorithm which gives an unbiased approximation of the full set gradient and has a constant memory overhead for any set size for both train- and test-time. We conduct extensive experiments including image completion, text classification, unsupervised clustering, and cancer detection on high-resolution images to verify the efficiency and efficacy of our scalable set encoding framework. Our code is available at github.com/jeffwillette/umbc

**摘要:** 最近对集合函数的小型批量一致性(MBC)工作引起了注意,需要对分区集合的批量进行序列处理和聚集,同时保证所有分区的输出相同。然而,MBC架构的现有限制导致了有限的表达能力的模型。此外,以前的工作还未解决如何处理在训练时需要完全集合梯度时处理大的集合。为了解决这些问题,我们提出了一个通用MBC(UMBC)类集合函数,可以与任意的非MBC组件结合,同时满足MBC,使MBC设置中使用更广泛的函数类别。我们对高分辨率图像进行广泛的实验,包括图像完成、文本分类、无监督聚类和癌症检测,以验证我们可扩展的集编码框架的效率和有效性。我们的代码可于 github.com/jeffwillette/umbc

**[Paper URL](https://proceedings.mlr.press/v202/willette23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/willette23a/willette23a.pdf)** 

# Flexible Phase Dynamics for Bio-Plausible Contrastive Learning
**题目:** 生物弹性对比学习的弹性阶段动力学

**作者:** Ezekiel Williams, Colin Bredenberg, Guillaume Lajoie

**Abstract:** Many learning algorithms used as normative models in neuroscience or as candidate approaches for learning on neuromorphic chips learn by contrasting one set of network states with another. These Contrastive Learning (CL) algorithms are traditionally implemented with rigid, temporally non-local, and periodic learning dynamics, that could limit the range of physical systems capable of harnessing CL. In this study, we build on recent work exploring how CL might be implemented by biological or neurmorphic systems and show that this form of learning can be made temporally local, and can still function even if many of the dynamical requirements of standard training procedures are relaxed. Thanks to a set of general theorems corroborated by numerical experiments across several CL models, our results provide theoretical foundations for the study and development of CL methods for biological and neuromorphic neural networks.

**摘要:** 许多学习算法作为神经科学的规范模型或作为神经形态芯片学习的候选方法,通过与网络状态的对比来学习。这些反向学习(CL)算法传统上采用刚性、时间非局部和周期学习动力学来实现,可以限制利用CL的物理系统范围。本研究中,我们基于最近的研究,探索如何由生物或神经形态系统实现CL,并表明这种学习形式可以实现时间局部,并且即使许多标准训练程序的动态要求被放松,仍能发挥作用。

**[Paper URL](https://proceedings.mlr.press/v202/williams23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/williams23a/williams23a.pdf)** 

# Approximate Stein Classes for Truncated Density Estimation
**题目:** 截面密度估计的大约石类

**作者:** Daniel James Williams, Song Liu

**Abstract:** Estimating truncated density models is difficult, as these models have intractable normalising constants and hard to satisfy boundary conditions. Score matching can be adapted to solve the truncated density estimation problem, but requires a continuous weighting function which takes zero at the boundary and is positive elsewhere. Evaluation of such a weighting function (and its gradient) often requires a closed-form expression of the truncation boundary and finding a solution to a complicated optimisation problem. In this paper, we propose approximate Stein classes, which in turn leads to a relaxed Stein identity for truncated density estimation. We develop a novel discrepancy measure, truncated kernelised Stein discrepancy (TKSD), which does not require fixing a weighting function in advance, and can be evaluated using only samples on the boundary. We estimate a truncated density model by minimising the Lagrangian dual of TKSD. Finally, experiments show the accuracy of our method to be an improvement over previous works even without the explicit functional form of the boundary.

**摘要:** 对截面密度模型的估计是困难的,因为这些模型具有难以解决的定常和难以满足边界条件。分数匹配可以用于解决截面密度估计问题,但需要一个连续的权重函数,它在边界上占零,并且在其他地方是正值。对这种权重函数(及其梯度)的评价通常需要截面边界闭式表达式,并寻找一个复杂优化问题的解决方法。本文提出了近似施泰因类,从而导致截面密度估计的松弛施泰因特征。我们开发了一种新颖的差异度量,截面核化施泰因差异度(TKSD),它不需要事先确定权重函数,并且可以用边界上的样品来评估。最后,实验表明,即使没有明确的函数形式的边界,我们方法的准确性也比以往的工作有所提高。

**[Paper URL](https://proceedings.mlr.press/v202/williams23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/williams23b/williams23b.pdf)** 

# Theoretical Behavior of XAI Methods in the Presence of Suppressor Variables
**题目:** 抑制变量的XAI方法理论行为

**作者:** Rick Wilming, Leo Kieslich, Benedict Clark, Stefan Haufe

**Abstract:** In recent years, the community of ’explainable artificial intelligence’ (XAI) has created a vast body of methods to bridge a perceived gap between model ’complexity’ and ’interpretability’. However, a concrete problem to be solved by XAI methods has not yet been formally stated. As a result, XAI methods are lacking theoretical and empirical evidence for the ’correctness’ of their explanations, limiting their potential use for quality-control and transparency purposes. At the same time, Haufe et al. (2014) showed, using simple toy examples, that even standard interpretations of linear models can be highly misleading. Specifically, high importance may be attributed to so-called suppressor variables lacking any statistical relation to the prediction target. This behavior has been confirmed empirically for a large array of XAI methods in Wilming et al. (2022). Here, we go one step further by deriving analytical expressions for the behavior of a variety of popular XAI methods on a simple two-dimensional binary classification problem involving Gaussian class-conditional distributions. We show that the majority of the studied approaches will attribute non-zero importance to a non-class-related suppressor feature in the presence of correlated noise. This poses important limitations on the interpretations and conclusions that the outputs of these XAI methods can afford.

**摘要:** 近年来,“解释性人工知能”(XAI)的社区创造了大量方法,以弥补模型“复杂性”和“解释性”之间的 perceived gap。然而,XAI方法所解决的具体问题尚未得到正式声明。因此,XAI方法缺乏“正确性”的理论和经验证据,限制了它们在质量控制和透明度目的中潜在的使用。在此,我们进一步推导了一系列流行的XAI方法在涉及高斯类-条件分布的简单二维分类问题上的行为的分析表达式。我们表明,大多数研究的方法将在与类相关噪声存在时归纳非零重要性的非类相关抑制特性。这对这些XAI方法的输出能提供的重要解释和结论有限制。

**[Paper URL](https://proceedings.mlr.press/v202/wilming23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wilming23a/wilming23a.pdf)** 

# Marginalization is not Marginal: No Bad VAE Local Minima when Learning Optimal Sparse Representations
**题目:**  Marginalization is not Marginal: No Bad VAE Local Minima when Learning Optimal Sparse Representations

**作者:** David Wipf

**Abstract:** Although the variational autoencoder (VAE) represents a widely-used deep generative model, the underlying energy function when applied to continuous data remains poorly understood. In fact, most prior theoretical analysis has assumed a simplified affine decoder such that the model collapses to probabilistic PCA, a restricted regime whereby existing classical algorithms can also be trivially applied to guarantee globally optimal solutions. To push our understanding into more complex, practically-relevant settings, this paper instead adopts a deceptively sophisticated single-layer decoder that nonetheless allows the VAE to address the fundamental challenge of learning optimally sparse representations of continuous data originating from popular multiple-response regression models. In doing so, we can then examine VAE properties within the non-trivial context of solving difficult, NP-hard inverse problems. More specifically, we prove rigorous conditions which guarantee that any minimum of the VAE energy (local or global) will produce the optimally sparse latent representation, meaning zero reconstruction error using a minimal number of active latent dimensions. This is ultimately possible because VAE marginalization over the latent posterior selectively smooths away bad local minima as has been conjectured but not actually proven in prior work. We then discuss how equivalent-capacity deterministic autoencoders, even with appropriate sparsity-promoting regularization of the latent space, maintain bad local minima that do not correspond with such parsimonious representations. Overall, these results serve to elucidate key properties of the VAE loss surface relative to finding low-dimensional structure in data.

**摘要:** 尽管变量自动编码器(VAE)是一种广泛应用的深层生成模型,但当应用于连续数据时,其基本能量函数仍未得到充分理解。事实上,大多数理论分析都假设了一种简化的微分编码器,使得模型倒塌为概率性PCA,一种限制的制度,现有的经典算法也可以被微不足道地应用,以保证全球最佳解决方案。为了将我们的理解推向更复杂的实际相关环境,本文采用了一种欺骗性复杂的单层编码器,尽管如此,它允许VAE解决从流行的多响应回归模型中产生的连续数据最小表示的基本挑战。具体地说,我们证明了严格的条件,保证任何VAE能量(局部或全球)的最小值都会产生最优稀疏的延迟表示,这意味着使用最小数量的活性延迟维度的零重建误差。这最终是可能的,因为延迟后端的VAE边缘化选择性地平滑了被推测但实际上在以前的工作中没有证明的坏局部微量。

**[Paper URL](https://proceedings.mlr.press/v202/wipf23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wipf23a/wipf23a.pdf)** 

# Uncertainty Estimation for Molecules: Desiderata and Methods
**题目:** 分子不确定度估计:测定和方法

**作者:** Tom Wollschläger, Nicholas Gao, Bertrand Charpentier, Mohamed Amine Ketata, Stephan Günnemann

**Abstract:** Graph Neural Networks (GNNs) are promising surrogates for quantum mechanical calculations as they establish unprecedented low errors on collections of molecular dynamics (MD) trajectories. Thanks to their fast inference times they promise to accelerate computational chemistry applications. Unfortunately, despite low in-distribution (ID) errors, such GNNs might be horribly wrong for out-of-distribution (OOD) samples. Uncertainty estimation (UE) may aid in such situations by communicating the model’s certainty about its prediction. Here, we take a closer look at the problem and identify six key desiderata for UE in molecular force fields, three ’physics-informed’ and three ’application-focused’ ones. To overview the field, we survey existing methods from the field of UE and analyze how they fit to the set desiderata. By our analysis, we conclude that none of the previous works satisfies all criteria. To fill this gap, we propose Localized Neural Kernel (LNK) a Gaussian Process (GP)-based extension to existing GNNs satisfying the desiderata. In our extensive experimental evaluation, we test four different UE with three different backbones across two datasets. In out-of-equilibrium detection, we find LNK yielding up to 2.5 and 2.1 times lower errors in terms of AUC-ROC score than dropout or evidential regression-based methods while maintaining high predictive performance.

**摘要:** 图神经网络(GNNs)是量子力学计算的代用品,因为它们在分子动力学(MD)轨迹的集合上建立了前所未有的低误差。由于它们的快速推导时间,它们承诺加速计算化学应用。不幸的是,尽管存在低的分布(ID)误差,这些GNNs可能对非分布(OOD)样品造成可怕的误差。不确定估计(UE)可能通过对模型的预测的确定来帮助这种情况。为了填补这一缺口,我们提出了基于高斯过程(GP)的本地神经核(LNK)扩展,以满足现有GNN的要求。在我们的广泛的实验评估中,我们测试了四个不同的UE和两个数据集的三个不同的后骨bone。在非平衡检测中,我们发现LNK在AUC-ROC分数方面产生2.5和2.1倍低的误差,而不是放弃或基于证据回归的方法,同时保持高预测性能。

**[Paper URL](https://proceedings.mlr.press/v202/wollschlager23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wollschlager23a/wollschlager23a.pdf)** 

# The Blessing of Heterogeneity in Federated Q-Learning: Linear Speedup and Beyond
**题目:** 联邦Q-学习中的异质性祝福:线性加速及 Beyond

**作者:** Jiin Woo, Gauri Joshi, Yuejie Chi

**Abstract:** In this paper, we consider federated Q-learning, which aims to learn an optimal Q-function by periodically aggregating local Q-estimates trained on local data alone. Focusing on infinite-horizon tabular Markov decision processes, we provide sample complexity guarantees for both the synchronous and asynchronous variants of federated Q-learning. In both cases, our bounds exhibit a linear speedup with respect to the number of agents and sharper dependencies on other salient problem parameters. Moreover, existing approaches to federated Q-learning adopt an equally-weighted averaging of local Q-estimates, which can be highly sub-optimal in the asynchronous setting since the local trajectories can be highly heterogeneous due to different local behavior policies. Existing sample complexity scales inverse proportionally to the minimum entry of the stationary state-action occupancy distributions over all agents, requiring that every agent covers the entire state-action space. Instead, we propose a novel importance averaging algorithm, giving larger weights to more frequently visited state-action pairs. The improved sample complexity scales inverse proportionally to the minimum entry of the average stationary state-action occupancy distribution of all agents, thus only requiring the agents collectively cover the entire state-action space, unveiling the blessing of heterogeneity.

**摘要:** 本文研究了基于本地数据的局部Q-估计数的周期性聚合学习最佳Q-函数的联邦Q-学习,重点在于无穷水平的马可夫决策过程,为联邦Q-学习的同步和非同步变异提供样本复杂度保证。在这两个情况下,我们的边界显示了对代理数的线性加速和对其他突出问题参数的更尖锐的依赖性。此外,现有的联邦Q-学习方法采用同样权重的平均值的局部Q-估计数,因为局部轨迹可能因不同的局部行为政策而高度异质,因此在非同步环境中具有极低最佳性。相反,我们提出了一种新颖的平均值算法,给予较频繁访问的状态-行动对的较大权重。改进的样品复杂度尺度与所有代理的平均静态状态-行动占用率分布的最低输入相逆,因此只要求代理集体覆盖整个状态-行动空间,揭示了异质性的祝福。

**[Paper URL](https://proceedings.mlr.press/v202/woo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/woo23a/woo23a.pdf)** 

# Learning Deep Time-index Models for Time Series Forecasting
**题目:** 学习时间序列预测的深度时间指数模型

**作者:** Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, Steven Hoi

**Abstract:** Deep learning has been actively applied to time series forecasting, leading to a deluge of new methods, belonging to the class of historical-value models. Yet, despite the attractive properties of time-index models, such as being able to model the continuous nature of underlying time series dynamics, little attention has been given to them. Indeed, while naive deep time-index models are far more expressive than the manually predefined function representations of classical time-index models, they are inadequate for forecasting, being unable to generalize to unseen time steps due to the lack of inductive bias. In this paper, we propose DeepTime, a meta-optimization framework to learn deep time-index models which overcome these limitations, yielding an efficient and accurate forecasting model. Extensive experiments on real world datasets in the long sequence time-series forecasting setting demonstrate that our approach achieves competitive results with state-of-the-art methods, and is highly efficient. Code is available at https://github.com/salesforce/DeepTime.

**摘要:** 深入学习已经积极应用于时间序列预测,导致属于历史价值模型类的新方法的涌现。然而,尽管时间序列模型具有吸引力,例如能够模拟潜在时间序列动力学的连续性,但对它们却很少给予重视。事实上, while naive deep time-index models are far more expressive than the manually predefined function representations of classical time-index models, they are inadequate for forecasting, being unable to generalize to unseen time steps due to the lack of inductive bias。在长期序列时间序列预测设置中对真实世界数据集进行了广泛的实验,证明我们的方法能够与最先进的方法取得竞争性的结果,并且具有很高的效率。

**[Paper URL](https://proceedings.mlr.press/v202/woo23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/woo23b/woo23b.pdf)** 

# Sharper Bounds for $\ell_p$ Sensitivity Sampling
**题目:** $\ell_p$敏感度样本的更清晰的边界

**作者:** David Woodruff, Taisuke Yasuda

**Abstract:** In large scale machine learning, random sampling is a popular way to approximate datasets by a small representative subset of examples. In particular, sensitivity sampling is an intensely studied technique which provides provable guarantees on the quality of approximation, while reducing the number of examples to the product of the VC dimension $d$ and the total sensitivity $\mathfrak{S}$ in remarkably general settings. However, guarantees going beyond this general bound of $\mathfrak{S} d$ are known in perhaps only one setting, for $\ell_2$ subspace embeddings, despite intense study of sensitivity sampling in prior work. In this work, we show the first bounds for sensitivity sampling for $\ell_p$ subspace embeddings for $p\neq 2$ that improve over the general $\mathfrak{S} d$ bound, achieving a bound of roughly $\mathfrak{S}^{2/p}$ for $1\leq p<2$ and $\mathfrak{S}^{2-2/p}$ for $2root leverage score sampling algorithm achieves a bound of roughly $d$ for $1\leq p<2$, and that a combination of leverage score and sensitivity sampling achieves an improved bound of roughly $d^{2/p}\mathfrak{S}^{2-4/p}$ for $2
Cite this Paper



    BibTeX
  



@InProceedings{pmlr-v202-woodruff23a,
  title = 	 {Sharper Bounds for $\ell_p$ Sensitivity Sampling},
  author =       {Woodruff, David and Yasuda, Taisuke},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {37238--37272},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/woodruff23a/woodruff23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/woodruff23a.html},
  abstract = 	 {In large scale machine learning, random sampling is a popular way to approximate datasets by a small representative subset of examples. In particular, sensitivity sampling is an intensely studied technique which provides provable guarantees on the quality of approximation, while reducing the number of examples to the product of the VC dimension $d$ and the total sensitivity $\mathfrak{S}$ in remarkably general settings. However, guarantees going beyond this general bound of $\mathfrak{S} d$ are known in perhaps only one setting, for $\ell_2$ subspace embeddings, despite intense study of sensitivity sampling in prior work. In this work, we show the first bounds for sensitivity sampling for $\ell_p$ subspace embeddings for $p\neq 2$ that improve over the general $\mathfrak{S} d$ bound, achieving a bound of roughly $\mathfrak{S}^{2/p}$ for $1\leq p<2$ and $\mathfrak{S}^{2-2/p}$ for $2root leverage score sampling algorithm achieves a bound of roughly $d$ for $1\leq p<2$, and that a combination of leverage score and sensitivity sampling achieves an improved bound of roughly $d^{2/p}\mathfrak{S}^{2-4/p}$ for $2

Copy to Clipboard
Download




    Endnote
  


%0 Conference Paper
%T Sharper Bounds for $\ell_p$ Sensitivity Sampling
%A David Woodruff
%A Taisuke Yasuda
%B Proceedings of the 40th International Conference on Machine Learning
%C Proceedings of Machine Learning Research
%D 2023
%E Andreas Krause
%E Emma Brunskill
%E Kyunghyun Cho
%E Barbara Engelhardt
%E Sivan Sabato
%E Jonathan Scarlett	
%F pmlr-v202-woodruff23a
%I PMLR
%P 37238--37272
%U https://proceedings.mlr.press/v202/woodruff23a.html
%V 202
%X In large scale machine learning, random sampling is a popular way to approximate datasets by a small representative subset of examples. In particular, sensitivity sampling is an intensely studied technique which provides provable guarantees on the quality of approximation, while reducing the number of examples to the product of the VC dimension $d$ and the total sensitivity $\mathfrak{S}$ in remarkably general settings. However, guarantees going beyond this general bound of $\mathfrak{S} d$ are known in perhaps only one setting, for $\ell_2$ subspace embeddings, despite intense study of sensitivity sampling in prior work. In this work, we show the first bounds for sensitivity sampling for $\ell_p$ subspace embeddings for $p\neq 2$ that improve over the general $\mathfrak{S} d$ bound, achieving a bound of roughly $\mathfrak{S}^{2/p}$ for $1\leq p<2$ and $\mathfrak{S}^{2-2/p}$ for $2root leverage score sampling algorithm achieves a bound of roughly $d$ for $1\leq p<2$, and that a combination of leverage score and sensitivity sampling achieves an improved bound of roughly $d^{2/p}\mathfrak{S}^{2-4/p}$ for $2

Copy to Clipboard
Download




    APA
  



Woodruff, D. & Yasuda, T.. (2023). Sharper Bounds for $\ell_p$ Sensitivity Sampling. Proceedings of the 40th International Conference on Machine Learning, in Proceedings of Machine Learning Research 202:37238-37272 Available from https://proceedings.mlr.press/v202/woodruff23a.html.



Copy to Clipboard
Download



Related Material


Download PDF
OpenReview

**摘要:** 在大型机器学习中,随机采样是通过小代表的实例子集对数据集进行近似的一种常见方法。特别是,灵敏采样是一种经过深入研究的技术,它提供了近似质量的可证明的保证,同时减少了实例的数量,使得VC维度$d$和总灵敏度$\mathfrak{S}$在显而易见的一般设置中产生。本文给出了对$p\neq 2$ 的 $\ell_p$ 子空间嵌入件的灵敏度采样的第一个界限,与一般 $\mathfrak{S} d$ 界限相比,达到大约 $\mathfrak{S}^{2/p}$ 的界限,$1\leq p<2$ 和 $\mathfrak{S}^{2-2/p}$ 的界限,$2root 杠杆分数采样算法达到大约 $d$ 的界限,$1\leq p<2$ 的界限,和杠杆分数和灵敏度采样的结合达到大约 $d^{2/p}\mathfrak{S}^{2-4/p}$ 的界限。 参考本论文 BibTeX @InProceedings{pml{机器学习研究过程},月={23--29日},出版者={PMLR},pdf={https://proceedings.mlr.press/v202/woodruff23a/woodruff23a.pdf},url={https://proceedings.mlr.press/v202/woodruff23a.html},抽象={在大规模机器学习中,随机抽样是通过小代表的副集实例近似数据集的一种常见方法。在此研究中,我们显示了$p\neq 2$的$\ell_p$子空间嵌入件的灵敏度采样的第一个边界,超过一般$\mathfrak{S} d$边界,达到大约$\mathfrak{S}^{2/p}$的$1\leq p<2$和$\mathfrak{S}^{2-2/p}$的$2root杠杆分数采样算法达到大约$d$的$1\leq p<2$的边界,以及杠杆分数和灵敏度采样的结合达到大约$d^{2/p}\mathfrak{S}^{2-4/p}$的$2的边界 Copy to Clipboard Download Endnote %0 Conference Paper %T Sharper Bounds for $\ell_p$ Sensitivity Sampling202 %X 在大型机器学习中,随机采样是通过小代表的实例子集近似数据集的一种流行方法。 特别是,灵敏采样是一种被深入研究的技术,它提供了近似质量的可证明的保证,同时减少了实例的数量到VC维度$d$和总灵敏度$\mathfrak{S}$的产物,在显著的一般设置中。在此研究中,我们展示了$p\neq 2$的$\ell_p$子空间嵌入器的灵敏度采样的第一个界限,比一般$\mathfrak{S} d$界限有所改善,达到大约$\mathfrak{S}^{2/p}$的界限$1\leq p<2$和$\mathfrak{S}^{2-2/p}$的界限$2root杠杆分数采样算法达到大约$d$的界限$1\leq p<2$,以及杠杆分数和灵敏度采样的组合达到大约$d^{2/p}\mathfrak{S}^{2-4/p}$的改善界限$2 复制到剪贴板下载 APA Woodruff, D. & Yasuda, T.. (2023). Sharper

**[Paper URL](https://proceedings.mlr.press/v202/woodruff23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/woodruff23a/woodruff23a.pdf)** 

# Two Losses Are Better Than One: Faster Optimization Using a Cheaper Proxy
**题目:** 两个损失比一个好:使用更便宜的代理进行更快的优化

**作者:** Blake Woodworth, Konstantin Mishchenko, Francis Bach

**Abstract:** We present an algorithm for minimizing an objective with hard-to-compute gradients by using a related, easier-to-access function as a proxy. Our algorithm is based on approximate proximal-point iterations on the proxy combined with relatively few stochastic gradients from the objective. When the difference between the objective and the proxy is $\delta$-smooth, our algorithm guarantees convergence at a rate matching stochastic gradient descent on a $\delta$-smooth objective, which can lead to substantially better sample efficiency. Our algorithm has many potential applications in machine learning, and provides a principled means of leveraging synthetic data, physics simulators, mixed public and private data, and more.

**摘要:** 本文提出了一种基于近似近点迭代的代理函数来最小化目标的计算梯度的算法,并结合目标的相对较少的随机梯度。当目标与代理之间的差额为$\delta$-smooth时,我们的算法保证在$\delta$-smooth目标上的随机梯度下降速度一致的收敛性,从而大大提高样品效率。我们的算法在机器学习中具有许多潜在的应用,并提供一种利用合成数据、物理模拟器、混合公共和私人数据等原则手段。

**[Paper URL](https://proceedings.mlr.press/v202/woodworth23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/woodworth23a/woodworth23a.pdf)** 

# SEGA: Structural Entropy Guided Anchor View for Graph Contrastive Learning
**题目:** SEGA: Graph Contrastive Learning的结构熵导引锚视图

**作者:** Junran Wu, Xueyuan Chen, Bowen Shi, Shangzhe Li, Ke Xu

**Abstract:** In contrastive learning, the choice of "view" controls the information that the representation captures and influences the performance of the model. However, leading graph contrastive learning methods generally produce views via random corruption or learning, which could lead to the loss of essential information and alteration of semantic information. An anchor view that maintains the essential information of input graphs for contrastive learning has been hardly investigated. In this paper, based on the theory of graph information bottleneck, we deduce the definition of this anchor view; put differently, the anchor view with essential information of input graph is supposed to have the minimal structural uncertainty. Furthermore, guided by structural entropy, we implement the anchor view, termed SEGA, for graph contrastive learning. We extensively validate the proposed anchor view on various benchmarks regarding graph classification under unsupervised, semi-supervised, and transfer learning and achieve significant performance boosts compared to the state-of-the-art methods.

**摘要:** 在对比性学习中,“视图”的选择控制了表示所捕捉和影响模型性能的信息。然而,导引图对比性学习方法通常通过随机破坏或学习产生视图,从而导致基本信息的丢失和语义信息的改变。对于对比性学习的输入图的基本信息保持的锚角视图几乎没有研究。本文基于图信息瓶颈理论,推导了这个锚角视图的定义;换句话说,输入图的基本信息的锚角视图应具有最低结构不确定性。本文详细验证了基于非监督、半监督和转移学习的图类别指标的锚点视角,与最新方法相比,取得了显著的性能提升。

**[Paper URL](https://proceedings.mlr.press/v202/wu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23a/wu23a.pdf)** 

# Causal Proxy Models for Concept-based Model Explanations
**题目:** 基于概念的模型解释的动因代理模型

**作者:** Zhengxuan Wu, Karel D’Oosterlinck, Atticus Geiger, Amir Zur, Christopher Potts

**Abstract:** Explainability methods for NLP systems encounter a version of the fundamental problem of causal inference: for a given ground-truth input text, we never truly observe the counterfactual texts necessary for isolating the causal effects of model representations on outputs. In response, many explainability methods make no use of counterfactual texts, assuming they will be unavailable. In this paper, we show that robust causal explainability methods can be created using approximate counterfactuals, which can be written by humans to approximate a specific counterfactual or simply sampled using metadata-guided heuristics. The core of our proposal is the Causal Proxy Model (CPM). A CPM explains a black-box model $\mathcal{N}$ because it is trained to have the same actual input/output behavior as $\mathcal{N}$ while creating neural representations that can be intervened upon to simulate the counterfactual input/output behavior of $\mathcal{N}$. Furthermore, we show that the best CPM for $\mathcal{N}$ performs comparably to $\mathcal{N}$ in making factual predictions, which means that the CPM can simply replace $\mathcal{N}$, leading to more explainable deployed models.

**摘要:** NLP系统解释性方法遇到了因果推理的基本问题:对于给定的实地输入文本,我们从不真正观察对因果文本的必要性,以孤立模型表示结果的因果效应。作为回应,许多解释性方法不使用对因果文本,假设它们将不可用。在这个论文中,我们展示了通过近似对因果的方法来创建可靠的因果解释性方法,这些方法可以由人类写成,以近似特定对因果或简单地通过元数据指导的实验样本。我们的建议的核心是 Causal Proxy Model(CPM)。CPM解释了黑盒模型$\mathcal{N}$,因为它被训练有与$\mathcal{N}$相同的实际输入/输出行为,同时创建神经模型,可以干预模拟$\mathcal{N}$的对因果输入/输出行为。此外,我们证明,最佳的CPM对$\mathcal{N}$在实际预测方面表现得与$\mathcal{N}$相比,这意味着CPM可以简单地取代$\mathcal{N}$,从而使部署模型更加解释性。

**[Paper URL](https://proceedings.mlr.press/v202/wu23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23b/wu23b.pdf)** 

# Effective Neural Topic Modeling with Embedding Clustering Regularization
**题目:** 嵌入集群调节的有效神经主题建模

**作者:** Xiaobao Wu, Xinshuai Dong, Thong Thanh Nguyen, Anh Tuan Luu

**Abstract:** Topic models have been prevalent for decades with various applications. However, existing topic models commonly suffer from the notorious topic collapsing: discovered topics semantically collapse towards each other, leading to highly repetitive topics, insufficient topic discovery, and damaged model interpretability. In this paper, we propose a new neural topic model, Embedding Clustering Regularization Topic Model (ECRTM). Besides the existing reconstruction error, we propose a novel Embedding Clustering Regularization (ECR), which forces each topic embedding to be the center of a separately aggregated word embedding cluster in the semantic space. This enables each produced topic to contain distinct word semantics, which alleviates topic collapsing. Regularized by ECR, our ECRTM generates diverse and coherent topics together with high-quality topic distributions of documents. Extensive experiments on benchmark datasets demonstrate that ECRTM effectively addresses the topic collapsing issue and consistently surpasses state-of-the-art baselines in terms of topic quality, topic distributions of documents, and downstream classification tasks.

**摘要:** 本文提出了一种新的神经主题模型,嵌入聚类规范化主题模型(ECRTM)。除了现有的重建误差外,我们提出了一种新的嵌入聚类规范化(ECR),它要求每个嵌入的主题成为语义空间中单独聚集的词汇嵌入聚类中心。这使得每个生成的主题包含不同的词汇语义,从而缓解了主题的崩溃。对基准数据集的广泛实验表明,ECRTM有效解决了主题崩溃问题,在主题质量、文件主题分配和下游分类任务方面始终超越了最先进的基准。

**[Paper URL](https://proceedings.mlr.press/v202/wu23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23c/wu23c.pdf)** 

# Adaptive Compositional Continual Meta-Learning
**题目:** 适应性复合持续的元学习

**作者:** Bin Wu, Jinyuan Fang, Xiangxiang Zeng, Shangsong Liang, Qiang Zhang

**Abstract:** This paper focuses on continual meta-learning, where few-shot tasks are heterogeneous and sequentially available. Recent works use a mixture model for meta-knowledge to deal with the heterogeneity. However, these methods suffer from parameter inefficiency caused by two reasons: (1) the underlying assumption of mutual exclusiveness among mixture components hinders sharing meta-knowledge across heterogeneous tasks. (2) they only allow increasing mixture components and cannot adaptively filter out redundant components. In this paper, we propose an Adaptive Compositional Continual Meta-Learning (ACML) algorithm, which employs a compositional premise to associate a task with a subset of mixture components, allowing meta-knowledge sharing among heterogeneous tasks. Moreover, to adaptively adjust the number of mixture components, we propose a component sparsification method based on evidential theory to filter out redundant components. Experimental results show ACML outperforms strong baselines, showing the effectiveness of our compositional meta-knowledge, and confirming that ACML can adaptively learn meta-knowledge.

**摘要:** 本文着重于连续的元学习,即少 shot任务是异构的,并可排序地进行。最近的研究使用混合模型来处理元知识的异构性。然而,这些方法由于两个原因导致参数效率低下:(一)混合组件间相互排斥的假设阻碍了在异构任务中共享元知识;(二)它们只允许增加混合组件,不能适应性地筛选冗余组件;(三)本文提出了一种适应性复合持续元学习(ACML)算法,采用组合前提将任务与混合组件的子集结合起来,让异构任务间共享元知识。实验结果表明,ACML具有较强的基准性能,证明了我们合成的元知识的有效性,并证实了ACML能够适应性地学习元知识。

**[Paper URL](https://proceedings.mlr.press/v202/wu23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23d/wu23d.pdf)** 

# Anchor Sampling for Federated Learning with Partial Client Participation
**题目:** 部分客户参与的联合学习锚样本

**作者:** Feijie Wu, Song Guo, Zhihao Qu, Shiqi He, Ziming Liu, Jing Gao

**Abstract:** Compared with full client participation, partial client participation is a more practical scenario in federated learning, but it may amplify some challenges in federated learning, such as data heterogeneity. The lack of inactive clients’ updates in partial client participation makes it more likely for the model aggregation to deviate from the aggregation based on full client participation. Training with large batches on individual clients is proposed to address data heterogeneity in general, but their effectiveness under partial client participation is not clear. Motivated by these challenges, we propose to develop a novel federated learning framework, referred to as FedAMD, for partial client participation. The core idea is anchor sampling, which separates partial participants into anchor and miner groups. Each client in the anchor group aims at the local bullseye with the gradient computation using a large batch. Guided by the bullseyes, clients in the miner group steer multiple near-optimal local updates using small batches and update the global model. By integrating the results of the two groups, FedAMD is able to accelerate the training process and improve the model performance. Measured by $\epsilon$-approximation and compared to the state-of-the-art methods, FedAMD achieves the convergence by up to $O(1/\epsilon)$ fewer communication rounds under non-convex objectives. Empirical studies on real-world datasets validate the effectiveness of FedAMD and demonstrate the superiority of the proposed algorithm: Not only does it considerably save computation and communication costs, but also the test accuracy significantly improves.

**摘要:** 与完全客户参与相比,部分客户参与在联邦学习中是一个更实用的场景,但它可能加剧联邦学习中的某些挑战,例如数据异质性。部分客户参与的非主动客户更新的缺失使得模型集群更有可能以完全客户参与为基础的集群偏离。针对个别客户进行大规模批量培训,提出解决数据异质性的问题,但其在部分客户参与下的效果并不明确。通过将两个组的结果整合起来,FedAMD能够加速培训过程并提高模型性能。由$\epsilon$-approximation测量和与最先进的方法比较,FedAMD在非凸目标下实现最大$O(1/\epsilon)$少量通信回合的收敛性。实世界数据集的实证研究验证了FedAMD的有效性,并证明了提议算法的优越性:它不仅大幅节省计算和通信费用,而且提高了测试精度。

**[Paper URL](https://proceedings.mlr.press/v202/wu23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23e/wu23e.pdf)** 

# Solving High-Dimensional PDEs with Latent Spectral Models
**题目:** 利用潜在光谱模型解决高维PDEs问题

**作者:** Haixu Wu, Tengge Hu, Huakun Luo, Jianmin Wang, Mingsheng Long

**Abstract:** Deep models have achieved impressive progress in solving partial differential equations (PDEs). A burgeoning paradigm is learning neural operators to approximate the input-output mappings of PDEs. While previous deep models have explored the multiscale architectures and various operator designs, they are limited to learning the operators as a whole in the coordinate space. In real physical science problems, PDEs are complex coupled equations with numerical solvers relying on discretization into high-dimensional coordinate space, which cannot be precisely approximated by a single operator nor efficiently learned due to the curse of dimensionality. We present Latent Spectral Models (LSM) toward an efficient and precise solver for high-dimensional PDEs. Going beyond the coordinate space, LSM enables an attention-based hierarchical projection network to reduce the high-dimensional data into a compact latent space in linear time. Inspired by classical spectral methods in numerical analysis, we design a neural spectral block to solve PDEs in the latent space that approximates complex input-output mappings via learning multiple basis operators, enjoying nice theoretical guarantees for convergence and approximation. Experimentally, LSM achieves consistent state-of-the-art and yields a relative gain of 11.5% averaged on seven benchmarks covering both solid and fluid physics. Code is available at https://github.com/thuml/Latent-Spectral-Models.

**摘要:** 深层模型在解决局部微分方程(PDEs)方面取得了令人印象深刻的进展。一个新兴的范式是学习神经元操作员来近似PDEs的输入输出映射。虽然以前的深层模型已经探索了多尺度架构和各种操作员的设计,但它们只限于在坐标空间中学习整个操作员。在实际物理学问题中,PDEs是复杂的耦合方程,数值解数依赖于离散化,不能由单个操作员准确近似,也不能因次数的诅咒而有效地学习。灵感于数值分析中的经典光谱方法,我们设计了一个神经光谱块,以解决潜空间的PDEs,通过学习多个基本操作器来近似复杂输入输出映射,享受收敛和近似的良好理论保证。

**[Paper URL](https://proceedings.mlr.press/v202/wu23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23f/wu23f.pdf)** 

# A Law of Robustness beyond Isoperimetry
**题目:** 超离子测量的鲁棒性规律

**作者:** Yihan Wu, Heng Huang, Hongyang Zhang

**Abstract:** We study the robust interpolation problem of arbitrary data distributions supported on a bounded space and propose a two-fold law of robustness. Robust interpolation refers to the problem of interpolating $n$ noisy training data points in $R^d$ by a Lipschitz function. Although this problem has been well understood when the samples are drawn from an isoperimetry distribution, much remains unknown concerning its performance under generic or even the worst-case distributions. We prove a Lipschitzness lower bound $\Omega(\sqrt{n/p})$ of the interpolating neural network with $p$ parameters on arbitrary data distributions. With this result, we validate the law of robustness conjecture in prior work by Bubeck, Li and Nagaraj on two-layer neural networks with polynomial weights. We then extend our result to arbitrary interpolating approximators and prove a Lipschitzness lower bound $\Omega(n^{1/d})$ for robust interpolation. Our results demonstrate a two-fold law of robustness: a) we show the potential benefit of overparametrization for smooth data interpolation when $n=poly(d)$, and b) we disprove the potential existence of an $O(1)$-Lipschitz robust interpolating function when $n=\exp(\omega(d))$.

**摘要:** 我们研究了基于边界空间的任意数据分布的鲁棒插值问题,并提出了鲁棒的双重法则。鲁棒插值是指由利普希茨函数在$R^d$中插值$n$噪声训练数据点的问题。虽然当样本从异构分布中提取时,这个问题已得到很好的理解,但对于其在通用或甚至最坏情况下的分布下的性能仍未知晓。我们证明了在任意数据分布上用$p$参数插值神经网络的利普希茨度下界$\Omega(\sqrt{n/p})$。结果证明了鲁棒性的双重定律:a)我们证明了在$n=poly(d)$时对数据平滑插值的过参数化的潜在利益,b)我们驳斥了在$n=\exp(\omega(d))$时存在一个$O(1)$-Lipschitz鲁棒插值函数的潜在存在。

**[Paper URL](https://proceedings.mlr.press/v202/wu23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23g/wu23g.pdf)** 

# Uncovering Adversarial Risks of Test-Time Adaptation
**题目:** 检测测试时间适应的敌对风险

**作者:** Tong Wu, Feiran Jia, Xiangyu Qi, Jiachen T. Wang, Vikash Sehwag, Saeed Mahloujifar, Prateek Mittal

**Abstract:** Recently, test-time adaptation (TTA) has been proposed as a promising solution for addressing distribution shifts. It allows a base model to adapt to an unforeseen distribution during inference by leveraging the information from the batch of (unlabeled) test data. However, we uncover a novel security vulnerability of TTA based on the insight that predictions on benign samples can be impacted by malicious samples in the same batch. To exploit this vulnerability, we propose Distribution Invading Attack (DIA), which injects a small fraction of malicious data into the test batch. DIA causes models using TTA to misclassify benign and unperturbed test data, providing an entirely new capability for adversaries that is infeasible in canonical machine learning pipelines. Through comprehensive evaluations, we demonstrate the high effectiveness of our attack on multiple benchmarks across six TTA methods. In response, we investigate two countermeasures to robustify the existing insecure TTA implementations, following the principle of security by design. Together, we hope our findings can make the community aware of the utility-security tradeoffs in deploying TTA and provide valuable insights for developing robust TTA approaches.

**摘要:** 最近,测试时间适应(TTA)被提议为解决分配转移的有前途解决方案。它允许一个基建模型通过从(未标记)测试数据批量中提取信息,在推断过程中适应不预见的分布。然而,我们发现TTA的新安全漏洞,基于洞察力,即 benign样品的预测可以被同一批量中的 malicious样品所影响。为了利用这一漏洞,我们提议分配入侵攻击(DIA),它将 malicious数据注入测试批量中的一个小部分。DIA使TTA使用模型误区 benign和不扰动测试数据,为敌方提供一种完全新的能力,这是不能实现的 canonical machine learning pipelines。为此,我们根据设计安全原则,研究了两种对策,以加强现有不安全的TTA实现。我们希望,我们共同的发现能使社会认识到在部署TTA时实用性和安全性的权衡,并为发展可靠的TTA方法提供宝贵的洞察。

**[Paper URL](https://proceedings.mlr.press/v202/wu23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23h/wu23h.pdf)** 

# Stable Estimation of Heterogeneous Treatment Effects
**题目:**  heterogeneous治疗效果的稳定估计

**作者:** Anpeng Wu, Kun Kuang, Ruoxuan Xiong, Bo Li, Fei Wu

**Abstract:** Estimating heterogeneous treatment effects (HTE) is crucial for identifying the variation of treatment effects across individuals or subgroups. Most existing methods estimate HTE by removing the confounding bias from imbalanced treatment assignments. However, these methods may produce unreliable estimates of treatment effects and potentially allocate suboptimal treatment arms for underrepresented populations. To improve the estimation accuracy of HTE for underrepresented populations, we propose a novel Stable CounterFactual Regression (StableCFR) to smooth the population distribution and upsample the underrepresented subpopulations, while balancing confounders between treatment and control groups. Specifically, StableCFR upsamples the underrepresented data using uniform sampling, where each disjoint subpopulation is weighted proportional to the Lebesgue measure of its support. Moreover, StableCFR balances covariates by using an epsilon-greedy matching approach. Empirical results on both synthetic and real-world datasets demonstrate the superior performance of our StableCFR on estimating HTE for underrepresented populations.

**摘要:** 估计异性治疗效应(HTE)对于识别不同个体或分组治疗效应的差异至关重要。大多数现有方法通过从不平衡的治疗分配中消除混淆性偏见来估计HTE。然而,这些方法可能产生不可靠的治疗效应的估计和潜在分配低代表性群体的亚最佳治疗 arms。为了提高低代表性群体的HTE估计精度,我们提出了一种新型的稳定反事实回归(StableCFR)来平滑人口分布,并提取低代表性的分组群,同时平衡治疗与控制群之间的混淆性偏见。对合成数据和实物数据集的实证结果表明,我们的StableCFR在低代表人口的HTE估计上具有较高的性能。

**[Paper URL](https://proceedings.mlr.press/v202/wu23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23i/wu23i.pdf)** 

# Rethinking Explaining Graph Neural Networks via Non-parametric Subgraph Matching
**题目:** 通过非参数子图匹配重新思考解释图神经网络

**作者:** Fang Wu, Siyuan Li, Xurui Jin, Yinghui Jiang, Dragomir Radev, Zhangming Niu, Stan Z. Li

**Abstract:** The success of graph neural networks (GNNs) provokes the question about explainability: “Which fraction of the input graph is the most determinant of the prediction?” Particularly, parametric explainers prevail in existing approaches because of their more robust capability to decipher the black-box (i.e., target GNNs). In this paper, based on the observation that graphs typically share some common motif patterns, we propose a novel non-parametric subgraph matching framework, dubbed MatchExplainer, to explore explanatory subgraphs. It couples the target graph with other counterpart instances and identifies the most crucial joint substructure by minimizing the node corresponding-based distance. Moreover, we note that present graph sampling or node-dropping methods usually suffer from the false positive sampling problem. To alleviate this issue, we design a new augmentation paradigm named MatchDrop. It takes advantage of MatchExplainer to fix the most informative portion of the graph and merely operates graph augmentations on the rest less informative part. Extensive experiments on synthetic and real-world datasets show the effectiveness of our MatchExplainer by outperforming all state-of-the-art parametric baselines with significant margins. Results also demonstrate that MatchDrop is a general scheme to be equipped with GNNs for enhanced performance. The code is available at https://github.com/smiles724/MatchExplainer.

**摘要:** graph neural networks(GNNs)的成功引发了解释性问题: “输入图中的哪个部分是预测的最决定性因素?” 特别是,参数解释者在现有方法中占主导地位,因为它们具有较强的解密黑箱的能力(即目标GNNs)。在这个论文中,基于观察图通常共享一些共同的主题模式,我们提出了一种新的非参数子图匹配框架,称为MatchExplainer,以探索解释子图。它将目标图与其他同类实例结合起来,并通过最小化相应的节点距离来识别最关键的联合子结构。它利用MatchExplainer来修正图中最重要的信息部分,并仅在其他较少信息部分操作图的增加。在合成和真实世界数据集上进行的广泛实验显示了我们的MatchExplainer的有效性,通过超越所有最先进的参数基线,具有显著的边际。

**[Paper URL](https://proceedings.mlr.press/v202/wu23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23j/wu23j.pdf)** 

# Understanding Int4 Quantization for Language Models: Latency Speedup, Composability, and Failure Cases
**题目:** 理解语言模型的Int4量化:延迟加速、兼容性和失败案例

**作者:** Xiaoxia Wu, Cheng Li, Reza Yazdani Aminabadi, Zhewei Yao, Yuxiong He

**Abstract:** Improving the deployment efficiency of transformer-based language models has been challenging given their high computation and memory cost. While INT8 quantization has recently been shown to be effective in reducing both the memory cost and latency while preserving model accuracy, it remains unclear whether we can leverage INT4 (which doubles peak hardware throughput) to achieve further latency improvement. In this study, we explore the feasibility of employing INT4 weight and activation (W4A4) quantization for language models. Our findings indicate that W4A4 quantization introduces no to negligible accuracy degradation for encoder-only and encoder-decoder models, but causes a significant accuracy drop for decoder-only models. To materialize the performance gain using W4A4, we develop a highly-optimized end-to-end W4A4 encoder inference pipeline supporting different quantization strategies. Our INT4 pipeline is $8.5\times$ faster for latency-oriented scenarios and up to $3\times$ for throughput-oriented scenarios compared to the inference of FP16, and improves the SOTA BERT INT8 performance from FasterTransformer by up to $1.7\times$. We provide insights into the failure cases when applying W4A4 to decoder-only models, and further explore the compatibility of INT4 quantization with other compression methods, like pruning and layer reduction.

**摘要:** 改进基于变换器的语言模型的部署效率是由于它们的高计算和存储成本而引起的挑战。虽然INT8定量化最近被证明在保持模型精度的同时降低存储成本和延迟效率,但仍不清楚我们是否能利用INT4(将硬件吞吐倍增)来实现进一步延迟改善。在这个研究中,我们探讨了使用INT4重量和激活(W4A4)定量化语言模型的可行性。我们的INT4管道比FP16的推导快8.5美元,对基于延迟的场景更快,对基于吞吐量的场景更快3美元,并从 FasterTransformer的SOTA BERT INT8性能提高到1.7美元。我们提供在将W4A4应用于仅解码器模型时的故障案例的洞察,并进一步探讨INT4量化与其他压缩方法,如剪切和层减少的兼容性。

**[Paper URL](https://proceedings.mlr.press/v202/wu23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23k/wu23k.pdf)** 

# Towards Understanding Generalization of Macro-AUC in Multi-label Learning
**题目:** 面向多标签学习中宏观AUC的一般化理解

**作者:** Guoqiang Wu, Chongxuan Li, Yilong Yin

**Abstract:** Macro-AUC is the arithmetic mean of the class-wise AUCs in multi-label learning and is commonly used in practice. However, its theoretical understanding is far lacking. Toward solving it, we characterize the generalization properties of various learning algorithms based on the corresponding surrogate losses w.r.t. Macro-AUC. We theoretically identify a critical factor of the dataset affecting the generalization bounds: the label-wise class imbalance. Our results on the imbalance-aware error bounds show that the widely-used univariate loss-based algorithm is more sensitive to the label-wise class imbalance than the proposed pairwise and reweighted loss-based ones, which probably implies its worse performance. Moreover, empirical results on various datasets corroborate our theory findings. To establish it, technically, we propose a new (and more general) McDiarmid-type concentration inequality, which may be of independent interest.

**摘要:** Macro-AUC是多标签学习中的类wise AUC的算术平均值,常用于实践中。然而,它的理论理解还远远不足。为了解决这个问题,我们根据相应的代用损失来描述各种学习算法的一般化特性 Macro-AUC。我们从理论上确定影响一般化边界的数据集的一个关键因素:类wise class imbalance。

**[Paper URL](https://proceedings.mlr.press/v202/wu23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23l/wu23l.pdf)** 

# Quantifying the Knowledge in GNNs for Reliable Distillation into MLPs
**题目:** 可靠蒸馏到MPP的GNN知识的量化

**作者:** Lirong Wu, Haitao Lin, Yufei Huang, Stan Z. Li

**Abstract:** To bridge the gaps between topology-aware Graph Neural Networks (GNNs) and inference-efficient Multi-Layer Perceptron (MLPs), GLNN proposes to distill knowledge from a well-trained teacher GNN into a student MLP. Despite their great progress, comparatively little work has been done to explore the reliability of different knowledge points (nodes) in GNNs, especially their roles played during distillation. In this paper, we first quantify the knowledge reliability in GNN by measuring the invariance of their information entropy to noise perturbations, from which we observe that different knowledge points (1) show different distillation speeds (temporally); (2) are differentially distributed in the graph (spatially). To achieve reliable distillation, we propose an effective approach, namely Knowledge-inspired Reliable Distillation (KRD), that models the probability of each node being an informative and reliable knowledge point, based on which we sample a set of additional reliable knowledge points as supervision for training student MLPs. Extensive experiments show that KRD improves over the vanilla MLPs by 12.62% and outperforms its corresponding teacher GNNs by 2.16% averaged over 7 datasets and 3 GNN architectures. Codes are publicly available at: https://github.com/LirongWu/RKD.

**摘要:** 为了解决拓扑认知图形神经网络(GNN)与推导效率高的多层感知器(MLP)之间的差距,GLNN提出了将一个经过良好训练的GNN教师的知识分离为学生MLP。尽管它们取得了很大的进展,但对GNN中不同知识点(节点)的可靠性进行了较少的研究,特别是它们在分离过程中所起的作用。为了实现可靠的蒸馏,我们提出了一种有效的方法,即知识启发的可靠蒸馏(KRD),它将模型每个节点的概率为信息和可靠的知识点,在此基础上,我们采样了一套额外可靠的知识点作为培训学生MLP的监督。

**[Paper URL](https://proceedings.mlr.press/v202/wu23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23m/wu23m.pdf)** 

# Delay-agnostic Asynchronous Coordinate Update Algorithm
**题目:** 延迟性非同步坐标更新算法

**作者:** Xuyang Wu, Changxin Liu, Sindri Magnússon, Mikael Johansson

**Abstract:** We propose a delay-agnostic asynchronous coordinate update algorithm (DEGAS) for computing operator fixed points, with applications to asynchronous optimization. DEGAS includes novel asynchronous variants of ADMM and block-coordinate descent as special cases. We prove that DEGAS converges with both bounded and unbounded delays under delay-free parameter conditions. We also validate by theory and experiments that DEGAS adapts well to the actual delays. The effectiveness of DEGAS is demonstrated by numerical experiments on classification problems.

**摘要:** 提出了一种用于非同步优化的调用算子固定点的延迟-渐进非同步坐标更新算法(DEGAS)。DEGAS包括新的ADMM和块坐标下降的非同步变量作为特殊案例。我们证明,DEGAS在无延迟参数条件下与边界和无边界延迟结合起来。我们还通过理论和实验验证了DEGAS对实际延迟的适应性。DEGAS的有效性由分类问题的数值实验证明。

**[Paper URL](https://proceedings.mlr.press/v202/wu23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23n/wu23n.pdf)** 

# Masked Trajectory Models for Prediction, Representation, and Control
**题目:** 预测、表示和控制的隐形推测模型

**作者:** Philipp Wu, Arjun Majumdar, Kevin Stone, Yixin Lin, Igor Mordatch, Pieter Abbeel, Aravind Rajeswaran

**Abstract:** We introduce Masked Trajectory Models (MTM) as a generic abstraction for sequential decision making. MTM takes a trajectory, such as a state-action sequence, and aims to reconstruct the trajectory conditioned on random subsets of the same trajectory. By training with a highly randomized masking pattern, MTM learns versatile networks that can take on different roles or capabilities, by simply choosing appropriate masks at inference time. For example, the same MTM network can be used as a forward dynamics model, inverse dynamics model, or even an offline RL agent. Through extensive experiments in several continuous control tasks, we show that the same MTM network – i.e. same weights – can match or outperform specialized networks trained for the aforementioned capabilities. Additionally, we find that state representations learned by MTM can significantly accelerate the learning speed of traditional RL algorithms. Finally, in offline RL benchmarks, we find that MTM is competitive with specialized offline RL algorithms, despite MTM being a generic self-supervised learning method without any explicit RL components. Code is available at https://github.com/facebookresearch/mtm.

**摘要:** 我们引入 Masked Trajectory Models(MTM)作为序列决策的通用抽象。MTM采用一个路径,例如状态-行动序列,并旨在重建由相同路径的随机子集组成的路径。通过使用高度随机化掩护模式的训练,MTM学习可接受不同的角色或能力的多功能网络,通过在推断时简单选择适当的掩护。例如,相同的MTM网络可以作为前行动力学模型、逆动力学模型、甚至一个非线性RL代理使用。通过在多个连续控制任务中进行广泛的实验,我们证明,相同的MTM网络-即相同的重量-可以匹配或超过为上述能力训练的专门网络。最后,在非线性RL基准中,我们发现MTM与专门的非线性RL算法具有竞争性,尽管MTM是无明确RL组件的通用自我监督学习方法。

**[Paper URL](https://proceedings.mlr.press/v202/wu23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23o/wu23o.pdf)** 

# Disentangled Multi-Fidelity Deep Bayesian Active Learning
**题目:** 分散的多真性深海式主动学习

**作者:** Dongxia Wu, Ruijia Niu, Matteo Chinazzi, Yian Ma, Rose Yu

**Abstract:** To balance quality and cost, various domain areas of science and engineering run simulations at multiple levels of sophistication. Multi-fidelity active learning aims to learn a direct mapping from input parameters to simulation outputs at the highest fidelity by actively acquiring data from multiple fidelity levels. However, existing approaches based on Gaussian processes are hardly scalable to high-dimensional data. Deep learning-based methods often impose a hierarchical structure in hidden representations, which only supports passing information from low-fidelity to high-fidelity. These approaches can lead to the undesirable propagation of errors from low-fidelity representations to high-fidelity ones. We propose a novel framework called Disentangled Multi-fidelity Deep Bayesian Active Learning (D-MFDAL), which learns the surrogate models conditioned on the distribution of functions at multiple fidelities. On benchmark tasks of learning deep surrogates of partial differential equations including heat equation, Poisson’s equation and fluid simulations, our approach significantly outperforms state-of-the-art in prediction accuracy and sample efficiency.

**摘要:** 为了平衡质量和成本,科学和工程的各个领域在多个层次进行仿真。多真性主动学习的目标是通过积极获取多真性层次的数据,从输入参数直接映射到最高真性模拟输出。然而,基于高斯过程的现有方法很难将高维数据扩展到高维数据。基于深层学习的方法经常在隐藏的表示中强加层次结构,只支持从低真性传递到高真性的信息。这些方法可以导致从低真性表示到高真性表示错误的不良传播。在学习热方程、波森方程和流体仿真等部分微分方程的深度替代物的基准任务上,我们的方法在预测精度和样品效率方面远远超过了最先进的方法。

**[Paper URL](https://proceedings.mlr.press/v202/wu23p.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23p/wu23p.pdf)** 

# Tight Data Access Bounds for Private Top-$k$ Selection
**题目:** 密接的数据访问边界用于私人$k$选择

**作者:** Hao Wu, Olga Ohrimenko, Anthony Wirth

**Abstract:** We study the top-$k$ selection problem under the differential privacy model: $m$ items are rated according to votes of a set of clients. We consider a setting in which algorithms can retrieve data via a sequence of accesses, each either a random access or a sorted access; the goal is to minimize the total number of data accesses. Our algorithm requires only $O(\sqrt{mk})$ expected accesses: to our knowledge, this is the first sublinear data-access upper bound for this problem. Our analysis also shows that the well-known exponential mechanism requires only $O(\sqrt{m})$ expected accesses. Accompanying this, we develop the first lower bounds for the problem, in three settings: only random accesses; only sorted accesses; a sequence of accesses of either kind. We show that, to avoid $\Omega(m)$ access cost, supporting both kinds of access is necessary, and that in this case our algorithm’s access cost is optimal.

**摘要:** 我们研究了不同隐私模型下的顶部$k$选择问题:$m$项按客户集的投票分级。我们考虑了一个设置,其中算法可以通过访问序列检索数据,每个是随机访问或排序访问;目标是尽量减少数据访问的总数。我们的算法只要求$O(\sqrt{mk})$预期访问:我们知道,这是该问题的第一个次线性数据访问上限。我们的分析还表明,众所周知的指数机制只要求$O(\sqrt{m})$预期访问。

**[Paper URL](https://proceedings.mlr.press/v202/wu23q.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23q/wu23q.pdf)** 

# The Implicit Regularization of Dynamical Stability in Stochastic Gradient Descent
**题目:** 随机梯度下降动态稳定性的隐性调节

**作者:** Lei Wu, Weijie J Su

**Abstract:** In this paper, we study the implicit regularization of stochastic gradient descent (SGD) through the lens of dynamical stability (Wu et al., 2018). We start by revising existing stability analyses of SGD, showing how the Frobenius norm and trace of Hessian relate to different notions of stability. Notably, if a global minimum is linearly stable for SGD, then the trace of Hessian must be less than or equal to $2/\eta$, where $\eta$ denotes the learning rate. By contrast, for gradient descent (GD), the stability imposes a similar constraint but only on the largest eigenvalue of Hessian. We then turn to analyze the generalization properties of these stable minima, focusing specifically on two-layer ReLU networks and diagonal linear networks. Notably, we establish the equivalence between these metrics of sharpness and certain parameter norms for the two models, which allows us to show that the stable minima of SGD provably generalize well. By contrast, the stability-induced regularization of GD is provably too weak to ensure satisfactory generalization. This discrepancy provides an explanation of why SGD often generalizes better than GD. Note that the learning rate (LR) plays a pivotal role in the strength of stability-induced regularization. As the LR increases, the regularization effect becomes more pronounced, elucidating why SGD with a larger LR consistently demonstrates superior generalization capabilities. Additionally, numerical experiments are provided to support our theoretical findings.

**摘要:** 本文通过动态稳定性的透镜研究了随机梯度下降(SGD)的隐性定律化(Wu et al., 2018)。我们首先回顾了SGD的现有稳定性分析,说明了弗罗贝尼乌斯定律和希斯sian的痕跡如何与稳定的不同概念有关。特别是,如果全球最低值为SGD的线性稳定,那么希斯sian的痕跡必须低于或等于 $2/\eta$,$\eta$表示学习率。相比之下,GD的稳定性诱导的规则化明显太弱以确保满意的一般化。这一差异提供了为什么GD通常比GD更普遍的原因的解释。注意,学习率(LR)在稳定性诱导的规则化强度中起着关键作用。随着LR的增加,规则化效应变得更加明显,说明为什么一个较大的LR的GD始终表现出优越的一般化能力。此外,为支持我们的理论发现提供了数值实验。

**[Paper URL](https://proceedings.mlr.press/v202/wu23r.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23r/wu23r.pdf)** 

# Distributional Offline Policy Evaluation with Predictive Error Guarantees
**题目:** 基于预测误差保证的分布式离线政策评估

**作者:** Runzhe Wu, Masatoshi Uehara, Wen Sun

**Abstract:** We study the problem of estimating the distribution of the return of a policy using an offline dataset that is not generated from the policy, i.e., distributional offline policy evaluation (OPE). We propose an algorithm called Fitted Likelihood Estimation (FLE), which conducts a sequence of Maximum Likelihood Estimation (MLE) and has the flexibility of integrating any state-of-the-art probabilistic generative models as long as it can be trained via MLE. FLE can be used for both finite-horizon and infinite-horizon discounted settings where rewards can be multi-dimensional vectors. Our theoretical results show that for both finite-horizon and infinite-horizon discounted settings, FLE can learn distributions that are close to the ground truth under total variation distance and Wasserstein distance, respectively. Our theoretical results hold under the conditions that the offline data covers the test policy’s traces and that the supervised learning MLE procedures succeed. Experimentally, we demonstrate the performance of FLE with two generative models, Gaussian mixture models and diffusion models. For the multi-dimensional reward setting, FLE with diffusion models is capable of estimating the complicated distribution of the return of a test policy.

**摘要:** 我们研究了利用非线性数据集来估计政策返回的分布问题,即分布非线性政策评价(OPE)。我们提出了一种叫做“拟合概率估计”(FLE)的算法,该算法导出了最大概率估计(MLE)的序列,并具有通过MLE进行训练的灵活性,可以集成最先进的概率生成模型。FLE可以用于有限水平和无限水平降价设置, rewards可以是多维向量。我们的理论结果表明,对于有限水平和无限水平降价设置,FLE可以学习在 total variation distance 和 Wasserstein distance 下接近地面的分布。通过实验,用两种生成模型,高斯混合模型和扩散模型,验证了FLE的性能。在多维奖励设置中,扩散模型的FLE能够估计测试策略 return的复杂分布。

**[Paper URL](https://proceedings.mlr.press/v202/wu23s.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23s/wu23s.pdf)** 

# $\pi$-Tuning: Transferring Multimodal Foundation Models with Optimal Multi-task Interpolation
**题目:** $\pi$-调制:使用最佳多任务插值转移多模态基础模型

**作者:** Chengyue Wu, Teng Wang, Yixiao Ge, Zeyu Lu, Ruisong Zhou, Ying Shan, Ping Luo

**Abstract:** Foundation models have achieved great advances in multi-task learning with a unified interface of unimodal and multimodal tasks. However, the potential of such multi-task learners has not been exploited during transfer learning. In this work, we present a universal parameter-efficient transfer learning method, termed Predict-Interpolate Tuning ($\pi$-Tuning), for vision, language, and vision-language tasks. It aggregates the parameters of lightweight task-specific experts learned from similar tasks to aid the target downstream task. The task similarities are predicted in a unified modality-independent space, yielding a scalable graph to demonstrate task relationships. $\pi$-Tuning has several appealing benefits. First, it flexibly explores both intra- and inter-modal transferability between similar tasks to improve the accuracy and robustness of transfer learning, especially in data-scarce scenarios. Second, it offers a systematical solution for transfer learning with multi-task prediction-and-then-interpolation, compatible with diverse types of parameter-efficient experts, such as prompt and adapter. Third, an extensive study of task-level mutual benefits on 14 unimodal and 6 multimodal datasets shows that $\pi$-Tuning surpasses fine-tuning and other parameter-efficient transfer learning methods both in full-shot and low-shot regimes. The task graph also enables an in-depth interpretable analysis of task transferability across modalities. The code will be available at https://github.com/TencentARC/pi-Tuning.

**摘要:** 基础模型在单模和多模任务的统一接口下,在多任务学习中取得了巨大的进步。然而,这种多任务学习者在学习过程中的潜力没有被利用。在这项工作中,我们提出了一种通用参数高效的传输学习方法,称为预见-间polate Tuning($\pi$-Tuning),用于视觉、语言和视觉语言任务。它汇集了从类似任务中学习的轻量任务特定专家参数,以帮助下游目标任务。其次,它提供了一个具有多任务预测和插值的系统解决方案,兼容各种参数效率专家,如快速和适配器。 第三,对14个单调和6个多模数据集的任务级别互利的广泛研究表明,$\pi$-Tuning超越了精调和其他参数效率的传输学习方法,在全射和低射两种模式中。

**[Paper URL](https://proceedings.mlr.press/v202/wu23t.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23t/wu23t.pdf)** 

# Learning Functional Distributions with Private Labels
**题目:** 使用私人标签学习功能分布

**作者:** Changlong Wu, Yifan Wang, Ananth Grama, Wojciech Szpankowski

**Abstract:** We study the problem of learning functional distributions in the presence of noise. A functional is a map from the space of features to distributions over a set of labels, and is often assumed to belong to a known class of hypotheses $\mathcal{F}$. Features are generated by a general random process and labels are sampled independently from feature-dependent distributions. In privacy sensitive applications, labels are passed through a noisy kernel. We consider online learning, where at each time step, a predictor attempts to predict the actual (label) distribution given only the features and noisy labels in prior steps. The performance of the predictor is measured by the expected KL-risk that compares the predicted distributions to the underlying truth. We show that the minimax expected KL-risk is of order $\tilde{\Theta}(\sqrt{T\log|\mathcal{F}|})$ for finite hypothesis class $\mathcal{F}$ and any non-trivial noise level. We then extend this result to general infinite classes via the concept of stochastic sequential covering and provide matching lower and upper bounds for a wide range of natural classes.

**摘要:** 我们研究在噪声的情况下学习函数分布的问题。函数是特征空间映射到标签集上的分布,并经常被认为属于已知类假设$\mathcal{F}$。特征由一般随机过程生成,标签由特征依赖分布独立抽样。在隐私敏感应用中,标签通过噪声内核传递。我们考虑在线学习,在每次步骤中,预测器试图预测实际(标签)分布,仅给出特征和噪声标签在前面步骤中。预测器的性能由预期的KL-风险来衡量,它将预测的分布与基本事实相比较。我们证明,最小期望的KL-风险是 $\tilde{\Theta}(\sqrt{T\log|\mathcal{F}|})$ 对有限假设类$\mathcal{F}$和任何非平凡的噪声水平。通过随机序列覆盖的概念,我们将这个结果扩展到一般无穷类,并为广泛的自然类提供匹配的下边界和上边界。

**[Paper URL](https://proceedings.mlr.press/v202/wu23u.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23u/wu23u.pdf)** 

# QuantumDARTS: Differentiable Quantum Architecture Search for Variational Quantum Algorithms
**题目:** QuantumDARTS:变量量算法的可变量架构搜索

**作者:** Wenjie Wu, Ge Yan, Xudong Lu, Kaisen Pan, Junchi Yan

**Abstract:** With the arrival of the Noisy Intermediate-Scale Quantum (NISQ) era and the fast development of machine learning, variational quantum algorithms (VQA) including Variational Quantum Eigensolver (VQE) and quantum neural network (QNN) have received increasing attention with wide potential applications in foreseeable near future. We study the problem of quantum architecture search (QAS) for VQA to automatically design parameterized quantum circuits (PQC). We devise a differentiable searching algorithm based on Gumbel-Softmax in contrast to peer methods that often require numerous circuit sampling and evaluation. Two versions of our algorithm are provided, namely macro search and micro search, where macro search directly searches for the whole circuit like other literature while the innovative micro search is able to infer the sub-circuit structure from a small-scale and then transfer that to a large-scale problem. We conduct intensive experiments on unweighted Max-Cut, ground state energy estimation, and image classification. The superior performance shows the efficiency and capability of macro search, which requires little prior knowledge. Moreover, the experiments on micro search show the potential of our algorithm for large-scale QAS problems.

**摘要:** 随着噪声中级量子(NISQ)时代的到来和机器学习的迅速发展,变量量量子算法(VQA)包括变量量量子自解器(VQE)和量子神经网络(QNN)在可预见的不久的将来得到越来越多的关注,具有广泛的应用潜力。我们对VQA的量子架构搜索(QAS)问题进行了研究,以自动设计参数化量子电路(PQC)。我们对无权限的Max-Cut、地面状态能量估算和图像分类进行了深入的实验,其优越性能显示了宏观搜索的效率和能力,这需要较少的事先知识。此外,对微型搜索的实验显示了我们算法在大规模的QAS问题上具有潜力。

**[Paper URL](https://proceedings.mlr.press/v202/wu23v.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23v/wu23v.pdf)** 

# Discover and Cure: Concept-aware Mitigation of Spurious Correlation
**题目:** 发现和治愈:概念意识的痕量相关性减轻

**作者:** Shirley Wu, Mert Yuksekgonul, Linjun Zhang, James Zou

**Abstract:** Deep neural networks often rely on spurious correlations to make predictions, which hinders generalization beyond training environments. For instance, models that associate cats with bed backgrounds can fail to predict the existence of cats in other environments without beds. Mitigating spurious correlations is crucial in building trustworthy models. However, the existing works lack transparency to offer insights into the mitigation process. In this work, we propose an interpretable framework, Discover and Cure (DISC), to tackle the issue. With human-interpretable concepts, DISC iteratively 1) discovers unstable concepts across different environments as spurious attributes, then 2) intervenes on the training data using the discovered concepts to reduce spurious correlation. Across systematic experiments, DISC provides superior generalization ability and interpretability than the existing approaches. Specifically, it outperforms the state-of-the-art methods on an object recognition task and a skin-lesion classification task by 7.5% and 9.6%, respectively. Additionally, we offer theoretical analysis and guarantees to understand the benefits of models trained by DISC. Code and data are available at https://github.com/Wuyxin/DISC.

**摘要:** 深度神经网络经常依靠虚构关联来预测,这阻碍了训练环境以外的泛化。例如,与床背景关联的模型无法预测没有床的其他环境中的猫的存在。对虚构关联的缓解是构建可靠模型的关键。然而,现有的工作缺乏透明度,无法提供对缓解过程的洞察。在这个工作中,我们提出了一种可解释框架,“发现和治愈”(Discover and Cure,DISC)来解决这个问题。此外,我们提供理论分析和保证了解DISC训练的模型的好处。代码和数据可浏览 https://github.com/Wuyxin/DISC。

**[Paper URL](https://proceedings.mlr.press/v202/wu23w.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23w/wu23w.pdf)** 

# On the Training Instability of Shuffling SGD with Batch Normalization
**题目:** 批量标准化的SGD缓冲训练不稳定问题

**作者:** David Xing Wu, Chulhee Yun, Suvrit Sra

**Abstract:** We uncover how SGD interacts with batch normalization and can exhibit undesirable training dynamics such as divergence. More precisely, we study how Single Shuffle (SS) and Random Reshuffle (RR)—two widely used variants of SGD—interact surprisingly differently in the presence of batch normalization: RR leads to much more stable evolution of training loss than SS. As a concrete example, for regression using a linear network with batch normalized inputs, we prove that SS and RR converge to distinct global optima that are “distorted” away from gradient descent. Thereafter, for classification we characterize conditions under which training divergence for SS and RR can, and cannot occur. We present explicit constructions to show how SS leads to distorted optima in regression and divergence for classification, whereas RR avoids both distortion and divergence. We validate our results empirically in realistic settings, and conclude that the separation between SS and RR used with batch normalization is relevant in practice.

**摘要:** 我们揭示了SGD如何与批量规范化相互作用,并能表现出不受欢迎的训练动态,如偏差。更确切地说,我们研究了SGD的两个广泛使用的变量——单一缓冲(SS)和随机缓冲(RR)如何在批量规范化的存在下相互作用惊人的不同:RR导致训练损失的演化比SS更稳定。在实际环境下,我们通过实证验证了我们的结果,并得出在批量标准化中使用SS和RR的分离在实践中具有重要的意义。

**[Paper URL](https://proceedings.mlr.press/v202/wu23x.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23x/wu23x.pdf)** 

# dugMatting: Decomposed-Uncertainty-Guided Matting
**题目:** dugMatting:Decomposed-Uncertainty-Guided Matting

**作者:** Jiawei Wu, Changqing Zhang, Zuoyong Li, Huazhu Fu, Xi Peng, Joey Tianyi Zhou

**Abstract:** Cutting out an object and estimating its opacity mask, known as image matting, is a key task in image and video editing. Due to the highly ill-posed issue, additional inputs, typically user-defined trimaps or scribbles, are usually needed to reduce the uncertainty. Although effective, it is either time consuming or only suitable for experienced users who know where to place the strokes. In this work, we propose a decomposed-uncertainty-guided matting (dugMatting) algorithm, which explores the explicitly decomposed uncertainties to efficiently and effectively improve the results. Basing on the characteristic of these uncertainties, the epistemic uncertainty is reduced in the process of guiding interaction (which introduces prior knowledge), while the aleatoric uncertainty is reduced in modeling data distribution (which introduces statistics for both data and possible noise). The proposed matting framework relieves the requirement for users to determine the interaction areas by using simple and efficient labeling. Extensively quantitative and qualitative results validate that the proposed method significantly improves the original matting algorithms in terms of both efficiency and efficacy.

**摘要:** 在图像和视频编辑中,切断对象和估计其隐形面具,称为图像映射,是关键任务。由于高度不确定的问题,通常需要额外的输入,通常是用户定义的三图或划线,以减少不确定性。虽然有效,它既耗费时间,也只适合有经验的用户知道如何配置划线。在这个工作中,我们提出了一种解散不确定导引映射(dugMatting)算法,它探索明确解散不确定,以有效提高结果。拟议的映射框架减少了用户使用简单高效的标签来确定相互作用区域的需要,广泛的定量和质量结果验证了拟议方法在效率和效率方面大大改进了原来的映射算法。

**[Paper URL](https://proceedings.mlr.press/v202/wu23y.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23y/wu23y.pdf)** 

# Personalized Federated Learning under Mixture of Distributions
**题目:** 混合分布下的个性化联合学习

**作者:** Yue Wu, Shuaicheng Zhang, Wenchao Yu, Yanchi Liu, Quanquan Gu, Dawei Zhou, Haifeng Chen, Wei Cheng

**Abstract:** The recent trend towards Personalized Federated Learning (PFL) has garnered significant attention as it allows for the training of models that are tailored to each client while maintaining data privacy. However, current PFL techniques primarily focus on modeling the conditional distribution heterogeneity (i.e. concept shift), which can result in suboptimal performance when the distribution of input data across clients diverges (i.e. covariate shift). Additionally, these techniques often lack the ability to adapt to unseen data, further limiting their effectiveness in real-world scenarios. To address these limitations, we propose a novel approach, FedGMM, which utilizes Gaussian mixture models (GMM) to effectively fit the input data distributions across diverse clients. The model parameters are estimated by maximum likelihood estimation utilizing a federated Expectation-Maximization algorithm, which is solved in closed form and does not assume gradient similarity. Furthermore, FedGMM possesses an additional advantage of adapting to new clients with minimal overhead, and it also enables uncertainty quantification. Empirical evaluations on synthetic and benchmark datasets demonstrate the superior performance of our method in both PFL classification and novel sample detection.

**摘要:** 近年来,面向个人化联邦学习(PFL)的趋势引起了大量关注,因为它允许为每个客户定制的模型进行培训,同时保持数据隐私。然而,目前的PFL技术主要集中在模拟条件分布异质性(即概念变换),当客户间的输入数据分布偏离(即共变换)时,可能产生亚最佳性能。此外,这些技术往往缺乏适应未知数据的能力,进一步限制了它们在现实世界中的有效性。同时,FedGMM具有适应新客户并减少开支的额外优势,也可进行不确定性的定量化。对合成数据和基准数据集的实证评价表明,该方法在PFL分类和新样品检测方面具有较高的性能。

**[Paper URL](https://proceedings.mlr.press/v202/wu23z.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23z/wu23z.pdf)** 

# Differentially Private Episodic Reinforcement Learning with Heavy-tailed Rewards
**题目:** 具有重尾奖赏的差异性私人续集强化学习

**作者:** Yulian Wu, Xingyu Zhou, Sayak Ray Chowdhury, Di Wang

**Abstract:** In this paper we study the problem of (finite horizon tabular) Markov decision processes (MDPs) with heavy-tailed rewards under the constraint of differential privacy (DP). Compared with the previous studies for private reinforcement learning that typically assume rewards are sampled from some bounded or sub-Gaussian distributions to ensure DP, we consider the setting where reward distributions have only finite $(1+v)$-th moments with some $v \in (0,1]$. By resorting to robust mean estimators for rewards, we first propose two frameworks for heavy-tailed MDPs, i.e., one is for value iteration and another is for policy optimization. Under each framework, we consider both joint differential privacy (JDP) and local differential privacy (LDP) models. Based on our frameworks, we provide regret upper bounds for both JDP and LDP cases, and show that the moment of distributions and privacy budget have significant impact on regrets. Finally, we establish a lower bound of regret minimization for heavy-tailed MDPs in JDP model by reducing it to the instance-independent lower bound of heavy-tailed multi-armed bandits in DP model. We also show the lower bound for the problem in LDP by adopting some private minimax methods. Our results reveal that there are fundamental differences between the problem of private RL with sub-Gaussian and that with heavy-tailed rewards.

**摘要:** 本文研究了马可夫决策过程(MDP)与微分隐私约束下的重尾奖赏问题。与以往的私人强化学习研究相比,我们通常假设奖赏是从一些有限或亚加斯分布中抽取的,以确保微分隐私,我们考虑了奖赏分布只有有限$(1+v)$-th moments的设置,其中一些$v\in (0,1]$。通过对奖赏的可靠平均估算,我们首先提出重尾MDP的两个框架,即一个为价值迭代和另一个为政策优化。最后,在JDP模型中,通过降低重尾多武器 bandit的实例独立下界限,建立了重尾MDP的遗憾最小化下界限,并采用一些私人最小化方法显示了LDP问题下界限。

**[Paper URL](https://proceedings.mlr.press/v202/wu23aa.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23aa/wu23aa.pdf)** 

# Finite-Sample Analysis of Learning High-Dimensional Single ReLU Neuron
**题目:** 高维单个ReLU神经元学习实例分析

**作者:** Jingfeng Wu, Difan Zou, Zixiang Chen, Vladimir Braverman, Quanquan Gu, Sham M. Kakade

**Abstract:** This paper considers the problem of learning single ReLU neuron with squared loss (a.k.a., ReLU regression) in the overparameterized regime, where the input dimension can exceed the number of samples. We analyze a Perceptron-type algorithm called GLM-tron [Kakade et al. 2011], and provide its dimension-free risk upper bounds for high-dimensional ReLU regression in both well-specified and misspecified settings. Our risk bounds recover several existing results as special cases. Moreover, in the well-specified setting, we also provide an instance-wise matching risk lower bound for GLM-tron. Our upper and lower risk bounds provide a sharp characterization of the high-dimensional ReLU regression problems that can be learned via GLM-tron. On the other hand, we provide some negative results for stochastic gradient descent (SGD) for ReLU regression with symmetric Bernoulli data: if the model is well-specified, the excess risk of SGD is provably no better than that of GLM-tron ignoring constant factors, for each problem instance; and in the noiseless case, GLM-tron can achieve a small risk while SGD unavoidably suffers from a constant risk in expectation. These results together suggest that GLM-tron might be more preferable than SGD for high-dimensional ReLU regression.

**摘要:** 本文讨论了在超参数化模式下,输入维度可以超过样品数量的单个ReLU神经元 learning problem(即ReLU回归) 。 分析了一种名为GLM-tron的 Perceptron-type算法(Kakade et al. 2011),并为高维ReLU回归在既定的、既定的、既定的设置中提供无维风险上限。另一方面,我们通过对立伯努利数据对ReLU回归的随机梯度降落(SGD)提供了一些负结果:如果模型是明确的,SGD的过剩风险在每个问题实例中都不能比GLM-tron忽略常量因素的风险更好;在无噪情况下,GLM-tron可以达到小风险,而SGD不可避免地遭受了预期中的常量风险;这些结果共同表明,GLM-tron对于高维ReLU回归可能比SGD更有利。

**[Paper URL](https://proceedings.mlr.press/v202/wu23ab.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/wu23ab/wu23ab.pdf)** 

# Understanding Backdoor Attacks through the Adaptability Hypothesis
**题目:** 通过适应性假设来理解后门攻击

**作者:** Xun Xian, Ganghua Wang, Jayanth Srinivasa, Ashish Kundu, Xuan Bi, Mingyi Hong, Jie Ding

**Abstract:** A poisoning backdoor attack is a rising security concern for deep learning. This type of attack can result in the backdoored model functioning normally most of the time but exhibiting abnormal behavior when presented with inputs containing the backdoor trigger, making it difficult to detect and prevent. In this work, we propose the adaptability hypothesis to understand when and why a backdoor attack works for general learning models, including deep neural networks, based on the theoretical investigation of classical kernel-based learning models. The adaptability hypothesis postulates that for an effective attack, the effect of incorporating a new dataset on the predictions of the original data points will be small, provided that the original data points are distant from the new dataset. Experiments on benchmark image datasets and state-of-the-art backdoor attacks for deep neural networks are conducted to corroborate the hypothesis. Our finding provides insight into the factors that affect the attack’s effectiveness and has implications for the design of future attacks and defenses.

**摘要:** 毒性后门攻击是深层学习的日益增加的安全问题。这种类型的攻击可能导致后门模型正常运行,但在包含后门触发器的输入时表现出异常行为,使得检测和预防变得困难。本研究中,我们提出了一种适应性假设,以理解后门攻击在一般学习模型中的作用,包括深层神经网络,基于经典内核学习模型的理论研究。适应性假设假设假设认为,对于有效的攻击,对原始数据点的预测采用新数据集的影响将很小,前提是原始数据点远离新数据集。我们的发现提供了对影响攻击效率的因素的洞察,并对未来攻击和防御的设计产生影响。

**[Paper URL](https://proceedings.mlr.press/v202/xian23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xian23a/xian23a.pdf)** 

# Fair and Optimal Classification via Post-Processing
**题目:** 通过后处理的公平和最佳分类

**作者:** Ruicheng Xian, Lang Yin, Han Zhao

**Abstract:** To mitigate the bias exhibited by machine learning models, fairness criteria can be integrated into the training process to ensure fair treatment across all demographics, but it often comes at the expense of model performance. Understanding such tradeoffs, therefore, underlies the design of fair algorithms. To this end, this paper provides a complete characterization of the inherent tradeoff of demographic parity on classification problems, under the most general multi-group, multi-class, and noisy setting. Specifically, we show that the minimum error rate achievable by randomized and attribute-aware fair classifiers is given by the optimal value of a Wasserstein-barycenter problem. On the practical side, our findings lead to a simple post-processing algorithm that derives fair classifiers from score functions, which yields the optimal fair classifier when the score is Bayes optimal. We provide suboptimality analysis and sample complexity for our algorithm, and demonstrate its effectiveness on benchmark datasets.

**摘要:** 为了减轻机器学习模型所表现出的偏见,公平性标准可纳入培训过程,以确保公平处理,但往往以模型性能为代价。因此,理解这种折衷是公平算法设计的基础。为此目的,本文提供了在分类问题下,在最一般的多组、多类和噪声设置下,人口平等的内在折衷的完整描述。具体地说,我们表明通过随机化和属性意识的公平分类器实现的最低误差率是由水星-巴里中心问题的最佳值给出的。我们为我们的算法提供亚优性分析和样品复杂性,并证明其在基准数据集上的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/xian23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xian23b/xian23b.pdf)** 

# UMD: Unsupervised Model Detection for X2X Backdoor Attacks
**题目:** UMD:X2X后门攻击的无监督模式检测

**作者:** Zhen Xiang, Zidi Xiong, Bo Li

**Abstract:** Backdoor (Trojan) attack is a common threat to deep neural networks, where samples from one or more source classes embedded with a backdoor trigger will be misclassified to adversarial target classes. Existing methods for detecting whether a classifier is backdoor attacked are mostly designed for attacks with a single adversarial target (e.g., all-to-one attack). To the best of our knowledge, without supervision, no existing methods can effectively address the more general X2X attack with an arbitrary number of source classes, each paired with an arbitrary target class. In this paper, we propose UMD, the first Unsupervised Model Detection method that effectively detects X2X backdoor attacks via a joint inference of the adversarial (source, target) class pairs. In particular, we first define a novel transferability statistic to measure and select a subset of putative backdoor class pairs based on a proposed clustering approach. Then, these selected class pairs are jointly assessed based on an aggregation of their reverse-engineered trigger size for detection inference, using a robust and unsupervised anomaly detector we proposed. We conduct comprehensive evaluations on CIFAR-10, GTSRB, and Imagenette dataset, and show that our unsupervised UMD outperforms SOTA detectors (even with supervision) by 17%, 4%, and 8%, respectively, in terms of the detection accuracy against diverse X2X attacks. We also show the strong detection performance of UMD against several strong adaptive attacks.

**摘要:** 背door(Trojan)攻击是对深层神经网络的常见威胁,其中一个或多个源类被嵌入背door触发器的样品将被误分类为敌对目标类。现有检测分类器是否被背door攻击的方法大多是针对与单个敌对目标(例如,全向一攻击)的攻击设计。然后,这些选定的类别对分别根据它们的反向调试触发大小进行综合评估,用我们提议的鲁棒和无监视异常检测器进行检测推导。我们对CIFAR-10、GTSRB和Imagenette数据集进行了全面评估,并显示,我们无监视的UMD比SOTA检测器(即使在监督下)的检测精度分别是17 % 、 4 % 和 8 %, 对各种X2X攻击而言,我们还显示了UMD对几种强适应攻击的强检测性能。

**[Paper URL](https://proceedings.mlr.press/v202/xiang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xiang23a/xiang23a.pdf)** 

# Random Shuffle Transformer for Image Restoration
**题目:** 用于图像恢复的随机缓冲变换器

**作者:** Jie Xiao, Xueyang Fu, Man Zhou, Hongjian Liu, Zheng-Jun Zha

**Abstract:** Non-local interactions play a vital role in boosting performance for image restoration. However, local window Transformer has been preferred due to its efficiency for processing high-resolution images. The superiority in efficiency comes at the cost of sacrificing the ability to model non-local interactions. In this paper, we present that local window Transformer can also function as modeling non-local interactions. The counterintuitive function is based on the permutation-equivariance of self-attention. The basic principle is quite simple: by randomly shuffling the input, local self-attention also has the potential to model non-local interactions without introducing extra parameters. Our random shuffle strategy enjoys elegant theoretical guarantees in extending the local scope. The resulting Transformer dubbed ShuffleFormer is capable of processing high-resolution images efficiently while modeling non-local interactions. Extensive experiments demonstrate the effectiveness of ShuffleFormer across a variety of image restoration tasks, including image denoising, deraining, and deblurring. Code is available at https://github.com/jiexiaou/ShuffleFormer.

**摘要:** 非本地交互在提高图像恢复性能方面起着至关重要的作用。然而,本地窗口变换器由于其处理高分辨率图像的效率而被推崇。效率的优越性来自牺牲模型非本地交互的能力的成本。本论文中,我们提出本地窗口变换器也可以作为建模非本地交互的函数。反直觉函数是基于自注意的变换均衡。基本原理很简单:通过随机切换输入,本地自注意也可以在引入额外参数的情况下建模非本地交互。我们的随机切换策略在扩展本地范围中享有优雅的理论保证。广泛的实验证明了 ShuffleFormer在各种图像恢复任务中具有有效性,包括image denoising、deraining和 deblurring。代码可于 https://github.com/jiexiaou/ShuffleFormer。

**[Paper URL](https://proceedings.mlr.press/v202/xiao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xiao23a/xiao23a.pdf)** 

# Communication-Efficient Federated Hypergradient Computation via Aggregated Iterative Differentiation
**题目:** 综合迭代分化实现通信效率的联邦高梯度计算

**作者:** Peiyao Xiao, Kaiyi Ji

**Abstract:** Federated bilevel optimization has attracted increasing attention due to emerging machine learning and communication applications. The biggest challenge lies in computing the gradient of the upper-level objective function (i.e., hypergradient) in the federated setting due to the nonlinear and distributed construction of a series of global Hessian matrices. In this paper, we propose a novel communication-efficient federated hypergradient estimator via aggregated iterative differentiation (AggITD). AggITD is simple to implement and significantly reduces the communication cost by conducting the federated hypergradient estimation and the lower-level optimization simultaneously. We show that the proposed AggITD-based algorithm achieves the same sample complexity as existing approximate implicit differentiation (AID)-based approaches with much fewer communication rounds in the presence of data heterogeneity. Our results also shed light on the great advantage of ITD over AID in the federated/distributed hypergradient estimation. This differs from the comparison in the non-distributed bilevel optimization, where ITD is less efficient than AID. Our extensive experiments demonstrate the great effectiveness and communication efficiency of the proposed method.

**摘要:** 联邦双层优化是由于新兴的机器学习和通信应用而引起越来越多的关注,最大的挑战在于由于一系列全球黑森矩阵的非线性和分布式构造,在联邦环境中计算上层目标函数(即高阶函数)的梯度。本文提出了一种新的通信效率的联邦高阶函数估计器,通过综合迭代差分(AggITD)实现。AggITD实现简单,同时进行联邦高阶函数估计和低阶优化,大大降低了通信成本。结果还揭示了ITD比AID在联合/分布式超梯度估计中的优势,与非分布式双层优化相比,ITD比AID效率较低。我们广泛的实验证明了该方法的有效性和通信效率。

**[Paper URL](https://proceedings.mlr.press/v202/xiao23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xiao23b/xiao23b.pdf)** 

# SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models
**题目:** SmoothQuant:大型语言模型的准确和高效后训练量化

**作者:** Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, Song Han

**Abstract:** Large language models (LLMs) show excellent performance but are compute- and memory-intensive. Quantization can reduce memory and accelerate inference. However, existing methods cannot maintain accuracy and hardware efficiency at the same time. We propose SmoothQuant, a training-free, accuracy-preserving, and general-purpose post-training quantization (PTQ) solution to enable 8-bit weight, 8-bit activation (W8A8) quantization for LLMs. Based on the fact that weights are easy to quantize while activations are not, SmoothQuant smooths the activation outliers by offline migrating the quantization difficulty from activations to weights with a mathematically equivalent transformation. SmoothQuant enables an INT8 quantization of both weights and activations for all the matrix multiplications in LLMs, including OPT, BLOOM, GLM, MT-NLG, and LLaMA family. We demonstrate up to 1.56$\times$ speedup and 2$\times$ memory reduction for LLMs with negligible loss in accuracy. SmoothQuant enables serving 530B LLM within a single node. Our work offers a turn-key solution that reduces hardware costs and democratizes LLMs.

**摘要:** 大型语言模型(LLMs)显示出良好的性能,但具有计算和内存密集性。量化可以减少内存和加速推理。然而,现有的方法不能同时保持精度和硬件效率。我们建议SmoothQuant,一个训练自由、准确保存、以及一般用途的训练量化(PTQ)解决方案,以使8位重量、8位激活(W8A8)量化LLMs。基于在激活不时量化权重的事实,SmoothQuant通过将量化困难从激活转移到具有数学等价变换的权重,平滑了激活异常。SmoothQuant允许在LLMs的所有矩阵乘法中,包括OPT、BLOOM、GLM、MT-NLG和LLaMA家族的INT8量化。SmoothQuant允许在单一节点内提供 530B LLM服务。我们的工作提供了一个简便的解决方案,降低硬件成本和民主化LLM。

**[Paper URL](https://proceedings.mlr.press/v202/xiao23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xiao23c/xiao23c.pdf)** 

# On the Forward Invariance of Neural ODEs
**题目:** 神经元ODEs前向不变性研究

**作者:** Wei Xiao, Tsun-Hsuan Wang, Ramin Hasani, Mathias Lechner, Yutong Ban, Chuang Gan, Daniela Rus

**Abstract:** We propose a new method to ensure neural ordinary differential equations (ODEs) satisfy output specifications by using invariance set propagation. Our approach uses a class of control barrier functions to transform output specifications into constraints on the parameters and inputs of the learning system. This setup allows us to achieve output specification guarantees simply by changing the constrained parameters/inputs both during training and inference. Moreover, we demonstrate that our invariance set propagation through data-controlled neural ODEs not only maintains generalization performance but also creates an additional degree of robustness by enabling causal manipulation of the system’s parameters/inputs. We test our method on a series of representation learning tasks, including modeling physical dynamics and convexity portraits, as well as safe collision avoidance for autonomous vehicles.

**摘要:** 我们提出了一种新的方法,以确保神经常微分方程(ODEs)通过变量集传播满足输出规格。我们的方法采用控制屏障函数来将输出规格转化为学习系统参数和输入的约束。该设置允许我们通过在训练和推导期间,简单地改变约束参数/输入来实现输出规格。此外,我们证明通过数据控制神经ODEs的变量集传播不仅保持了一般化性能,而且通过使系统参数/输入的因果操作创造了一个额外的鲁棒度。

**[Paper URL](https://proceedings.mlr.press/v202/xiao23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xiao23d/xiao23d.pdf)** 

# COMCAT: Towards Efficient Compression and Customization of Attention-Based Vision Models
**题目:** COMCAT:基于注意力的视觉模型的有效压缩和定制

**作者:** Jinqi Xiao, Miao Yin, Yu Gong, Xiao Zang, Jian Ren, Bo Yuan

**Abstract:** Attention-based vision models, such as Vision Transformer (ViT) and its variants, have shown promising performance in various computer vision tasks. However, these emerging architectures suffer from large model sizes and high computational costs, calling for efficient model compression solutions. To date, pruning ViTs has been well studied, while other compression strategies that have been widely applied in CNN compression, e.g., model factorization, is little explored in the context of ViT compression. This paper explores an efficient method for compressing vision transformers to enrich the toolset for obtaining compact attention-based vision models. Based on the new insight on the multi-head attention layer, we develop a highly efficient ViT compression solution, which outperforms the state-of-the-art pruning methods. For compressing DeiT-small and DeiT-base models on ImageNet, our proposed approach can achieve $0.45%$ and $0.76%$ higher top-1 accuracy even with fewer parameters. Our finding can also be applied to improve the customization efficiency of text-to-image diffusion models, with much faster training (up to $2.6\times$ speedup) and lower extra storage cost (up to $1927.5\times$ reduction) than the existing works.

**摘要:** 基于注意力的视觉模型,如视觉变换器(ViT)及其变种,在各种计算机视觉任务中表现出有前途的性能。然而,这些新兴的架构承受着巨大的模型大小和高计算成本,要求有效的模型压缩解决方案。到目前为止,剪切ViTs已经得到很好的研究,而在CNN压缩中广泛应用的其他压缩策略,例如模型因子化,在ViT压缩中很少被研究。本论文探讨了压缩视觉变换器的有效方法,以丰富获取小型基于注意力的视觉模型的工具集。基于多头注意力层的新洞察,我们开发了一个高效的ViT压缩解决方案,超越了最先进的剪切方法。我们的发现也可以应用,以提高文本-图像扩散模型的定制效率,通过比现有的工作更快的培训(最大$2.6\times$加速)和更低的额外存储成本(最大$927.5\times$减少)。

**[Paper URL](https://proceedings.mlr.press/v202/xiao23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xiao23e/xiao23e.pdf)** 

# Improving Bi-level Optimization Based Methods with Inspiration from Humans’ Classroom Study Techniques
**题目:** 利用人类课堂学习技术,改进基于二级优化的方法

**作者:** Pengtao Xie

**Abstract:** In humans’ classroom learning, many effective study techniques (e.g., the Feynman technique, peer questioning, etc.) have been developed to improve learning outcomes. We are interested in investigating whether these techniques can inspire the development of ML training strategies to improve bi-level optimization (BLO) based methods. Towards this goal, we develop a general framework, Skillearn, which consists of basic elements such as learners, interaction functions, learning stages, etc. These elements can be flexibly configured to create various training strategies, each emulating a study technique of humans. In case studies, we apply Skillearn to create new training strategies, by emulating the Feynman technique and peer questioning, which are two broadly adopted techniques in humans’ classroom learning. These training strategies are used for improving two BLO based applications including neural architecture search and data weighting. Experiments on various datasets demonstrate the effectiveness of our methods.

**摘要:** 在人类课堂学习中,许多有效的学习技术(例如费恩曼技术、同行问卷等)已经被开发,以提高学习成果。我们想知道这些技术是否能激发ML培训策略的发展,以改善基于二级优化(BLO)的方法。为了达到这一目标,我们开发了一个通用框架, Skillearn,该框架包括学习者、交互功能、学习阶段等基本元素。这些元素可以灵活配置,以创建各种培训策略,每个模拟人类的学习技术。对各种数据集的实验证明了我们的方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/xie23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xie23a/xie23a.pdf)** 

# Future-conditioned Unsupervised Pretraining for Decision Transformer
**题目:** 基于未来条件的未经监督决策变换者预备培训

**作者:** Zhihui Xie, Zichuan Lin, Deheng Ye, Qiang Fu, Yang Wei, Shuai Li

**Abstract:** Recent research in offline reinforcement learning (RL) has demonstrated that return-conditioned supervised learning is a powerful paradigm for decision-making problems. While promising, return conditioning is limited to training data labeled with rewards and therefore faces challenges in learning from unsupervised data. In this work, we aim to utilize generalized future conditioning to enable efficient unsupervised pretraining from reward-free and sub-optimal offline data. We propose Pretrained Decision Transformer (PDT), a conceptually simple approach for unsupervised RL pretraining. PDT leverages future trajectory information as a privileged context to predict actions during training. The ability to make decisions based on both present and future factors enhances PDT’s capability for generalization. Besides, this feature can be easily incorporated into a return-conditioned framework for online finetuning, by assigning return values to possible futures and sampling future embeddings based on their respective values. Empirically, PDT outperforms or performs on par with its supervised pretraining counterpart, especially when dealing with sub-optimal data. Further analysis reveals that PDT can extract diverse behaviors from offline data and controllably sample high-return behaviors by online finetuning. Code is available at here.

**摘要:** 网络增强学习(英语:Offline reinforcement learning,简称RL)的研究表明,基于反馈条件的监控学习是决策问题的一个有力的范例。虽然有希望,但反馈条件只限于训练数据以奖励标记,因此在从无监督数据中学习方面面临挑战。本课题中,我们的目标是利用广义的未来条件化,使从无奖励和亚最佳的网络数据中进行有效的无监督预训练。我们建议采用预处理决策变换器(PDT)作为无监督RL预训练的一个概念简单方法。PDT利用未来轨迹信息作为一种特权的背景来预测训练过程中的行动。此外,该功能可以通过将返回值分配给可能的未来并根据其相关值采样未来嵌入物,轻易地纳入在线微调的返回条件框架中。在实证上,PDT能够与其监管的预训练对手相比,特别是在处理亚最佳数据时。进一步分析表明PDT能够从非在线数据中提取各种行为,并通过在线微调可控制地采样高回报行为。

**[Paper URL](https://proceedings.mlr.press/v202/xie23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xie23b/xie23b.pdf)** 

# DeSRA: Detect and Delete the Artifacts of GAN-based Real-World Super-Resolution Models
**题目:** DeSRA:检测和删除GAN基于真实世界超分辨率模型的人工物

**作者:** Liangbin Xie, Xintao Wang, Xiangyu Chen, Gen Li, Ying Shan, Jiantao Zhou, Chao Dong

**Abstract:** Image super-resolution (SR) with generative adversarial networks (GAN) has achieved great success in restoring realistic details. However, it is notorious that GAN-based SR models will inevitably produce unpleasant and undesirable artifacts, especially in practical scenarios. Previous works typically suppress artifacts with an extra loss penalty in the training phase. They only work for in-distribution artifact types generated during training. When applied in real-world scenarios, we observe that those improved methods still generate obviously annoying artifacts during inference. In this paper, we analyze the cause and characteristics of the GAN artifacts produced in unseen test data without ground-truths. We then develop a novel method, namely, DeSRA, to Detect and then “Delete” those SR Artifacts in practice. Specifically, we propose to measure a relative local variance distance from MSE-SR results and GAN-SR results, and locate the problematic areas based on the above distance and semantic-aware thresholds. After detecting the artifact regions, we develop a finetune procedure to improve GAN-based SR models with a few samples, so that they can deal with similar types of artifacts in more unseen real data. Equipped with our DeSRA, we can successfully eliminate artifacts from inference and improve the ability of SR models to be applied in real-world scenarios. The code will be available at https://github.com/TencentARC/DeSRA.

**摘要:** 图像超分辨率(SR)与生成敌对网络(GAN)在恢复现实细节方面取得了巨大的成功。然而,GAN-based SR模型将不可避免地产生令人不愉快和不受欢迎的物件,特别是在实际场景中。以前的工作通常是抑制在训练阶段的额外损失处罚的物件。它们只用于在训练过程中生成的分布式物件类型。当应用于现实场景时,我们观察这些改进的方法在推断过程中仍然产生明显令人讨厌的物件。具体而言,我们建议从MSE-SR结果和GAN-SR结果中测量相对的局部变异距离,并根据上述距离和语义意识阈值定位问题区域。在检测变异区域后,我们开发了改进GAN-based SR模型的微调程序,以少数样品,以便它们能够处理在更不可见的实物数据中类似的变异类型。

**[Paper URL](https://proceedings.mlr.press/v202/xie23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xie23c/xie23c.pdf)** 

# Semiparametrically Efficient Off-Policy Evaluation in Linear Markov Decision Processes
**题目:** 线性马可夫决策过程非政策评价的半等效性

**作者:** Chuhan Xie, Wenhao Yang, Zhihua Zhang

**Abstract:** We study semiparametrically efficient estimation in off-policy evaluation (OPE) where the underlying Markov decision process (MDP) is linear with a known feature map. We characterize the variance lower bound for regular estimators in the linear MDP setting and propose an efficient estimator whose variance achieves that lower bound. Consistency and asymptotic normality of our estimator are established under mild conditions, which merely requires the only infinite-dimensional nuisance parameter to be estimated at a $n^{-1/4}$ convergence rate. We also construct an asymptotically valid confidence interval for statistical inference and conduct simulation studies to validate our results. To our knowledge, this is the first work that concerns efficient estimation in the presence of a known structure of MDPs in the OPE literature.

**摘要:** 我们研究了非政策评价(OPE)中的半参数有效估计,其中基准马可夫决策过程(MDP)是线性,具有已知特征图。我们对线性MDP设置中的正规估计者的变量较低界限进行了描述,并提出了一种有效的估计者 whose variance achieves that lower bound。我们的估计者的一致性和渐近正常性是在温和条件下建立的,仅需要在$n^{-1/4}$收敛率下估计的唯一无穷维扰动参数。我们还构造了一个渐近有效的统计推断信 interval,并进行仿真研究验证我们的结果。

**[Paper URL](https://proceedings.mlr.press/v202/xie23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xie23d/xie23d.pdf)** 

# A Critical View of Vision-Based Long-Term Dynamics Prediction Under Environment Misalignment
**题目:** 环境偏差下基于视觉的长期动力学预测的临界视角

**作者:** Hanchen Xie, Jiageng Zhu, Mahyar Khayatkhoei, Jiazhi Li, Mohamed E. Hussein, Wael Abdalmageed

**Abstract:** Dynamics prediction, which is the problem of predicting future states of scene objects based on current and prior states, is drawing increasing attention as an instance of learning physics. To solve this problem, Region Proposal Convolutional Interaction Network (RPCIN), a vision-based model, was proposed and achieved state-of-the-art performance in long-term prediction. RPCIN only takes raw images and simple object descriptions, such as the bounding box and segmentation mask of each object, as input. However, despite its success, the model’s capability can be compromised under conditions of environment misalignment. In this paper, we investigate two challenging conditions for environment misalignment: Cross-Domain and Cross-Context by proposing four datasets that are designed for these challenges: SimB-Border, SimB-Split, BlenB-Border, and BlenB-Split. The datasets cover two domains and two contexts. Using RPCIN as a probe, experiments conducted on the combinations of the proposed datasets reveal potential weaknesses of the vision-based long-term dynamics prediction model. Furthermore, we propose a promising direction to mitigate the Cross-Domain challenge and provide concrete evidence supporting such a direction, which provides dramatic alleviation of the challenge on the proposed datasets.

**摘要:** 动态预测是基于当前和先前状态的场景对象未来状态预测问题,在学习物理学的实例中日益引起人们的关注。为了解决这一问题,提出了一种基于视觉的区域建议变形交互网络(Region Proposal Convolutional Interaction Network,RPCIN)模型,并实现了最先进的长期预测性能。RPCIN仅以原始图像和简单的对象描述,如各对象的 bounding box和 segmentation mask,作为输入。利用RPCIN作为探测器,对拟议数据集的组合进行了实验,揭示了基于视觉的长期动力学预测模型的潜在弱点。此外,我们提出了解决跨域挑战的良好方向,并提供了支持这一方向的具体证据,从而大大缓解了拟议数据集的挑战。

**[Paper URL](https://proceedings.mlr.press/v202/xie23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xie23e/xie23e.pdf)** 

# Controlling Type Confounding in Ad Hoc Teamwork with Instance-wise Teammate Feedback Rectification
**题目:** 特设团队工作与实例团队mates反馈的控制类型混淆 Rectification

**作者:** Dong Xing, Pengjie Gu, Qian Zheng, Xinrun Wang, Shanqi Liu, Longtao Zheng, Bo An, Gang Pan

**Abstract:** Ad hoc teamwork requires an agent to cooperate with unknown teammates without prior coordination. Many works propose to abstract teammate instances into high-level representation of types and then pre-train the best response for each type. However, most of them do not consider the distribution of teammate instances within a type. This could expose the agent to the hidden risk of type confounding. In the worst case, the best response for an abstract teammate type could be the worst response for all specific instances of that type. This work addresses the issue from the lens of causal inference. We first theoretically demonstrate that this phenomenon is due to the spurious correlation brought by uncontrolled teammate distribution. Then, we propose our solution, CTCAT, which disentangles such correlation through an instance-wise teammate feedback rectification. This operation reweights the interaction of teammate instances within a shared type to reduce the influence of type confounding. The effect of CTCAT is evaluated in multiple domains, including classic ad hoc teamwork tasks and real-world scenarios. Results show that CTCAT is robust to the influence of type confounding, a practical issue that directly hazards the robustness of our trained agents but was unnoticed in previous works.

**摘要:** 特设团队工作需要一个代理人与未知团队成员进行合作,而不需事先进行协调。许多工作建议将抽象团队成员的实例转化为类型的高层次表现,然后预先训练每个类型的最佳响应。然而,其中大多数不考虑在类型内分配团队成员的实例。这可能使代理人暴露于隐藏的类型混淆的风险。最坏的情况是,抽象团队成员的实例的最佳响应可能是该类型的所有特定实例的最坏响应。CTCAT在多个领域,包括经典的特设团队工作任务和现实世界中的场景中得到评价,结果表明CTCAT对类型混淆的影响是强有力的,这是一个直接危害训练人员鲁棒性的实际问题,但在以前的工作中却没有引起注意。

**[Paper URL](https://proceedings.mlr.press/v202/xing23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xing23a/xing23a.pdf)** 

# Universal Morphology Control via Contextual Modulation
**题目:** 通过上下文调制的通用形态学控制

**作者:** Zheng Xiong, Jacob Beck, Shimon Whiteson

**Abstract:** Learning a universal policy across different robot morphologies can significantly improve learning efficiency and generalization in continuous control. However, it poses a challenging multi-task reinforcement learning problem, as the optimal policy may be quite different across robots and critically depend on the morphology. Existing methods utilize graph neural networks or transformers to handle heterogeneous state and action spaces across different morphologies, but pay little attention to the dependency of a robot’s control policy on its morphology context. In this paper, we propose a hierarchical architecture to better model this dependency via contextual modulation, which includes two key submodules: (1) Instead of enforcing hard parameter sharing across robots, we use hypernetworks to generate morphology-dependent control parameters; (2) We propose a fixed attention mechanism that solely depends on the morphology to modulate the interactions between different limbs in a robot. Experimental results show that our method not only improves learning performance on a diverse set of training robots, but also generalizes better to unseen morphologies in a zero-shot fashion. The code is publicly available at https://github.com/MasterXiong/ModuMorph.

**摘要:** 利用图形神经网络或变换器处理不同形态的异态状态和动作空间,但很少注意机器人控制政策对其形态环境的依赖性。本文提出了一种层次结构,以通过上下文调制更好地建模这种依赖性,包括两个关键子模块: (一)在机器人间强制性参数共享的基础上,我们使用超网络生成形态依赖性控制参数; (二)提出了一种只依赖于形态的固定注意机制,以调制机器人不同肢体之间的相互作用。实验结果表明,我们的方法不仅改善了各种训练机器人的学习性能,而且在零射击模式下更全面地推广了未见的形态。

**[Paper URL](https://proceedings.mlr.press/v202/xiong23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xiong23a/xiong23a.pdf)** 

# Relevant Walk Search for Explaining Graph Neural Networks
**题目:** 图神经网络解释的相关步行搜索

**作者:** Ping Xiong, Thomas Schnake, Michael Gastegger, Grégoire Montavon, Klaus Robert Muller, Shinichi Nakajima

**Abstract:** Graph Neural Networks (GNNs) have become important machine learning tools for graph analysis, and its explainability is crucial for safety, fairness, and robustness. Layer-wise relevance propagation for GNNs (GNN-LRP) evaluates the relevance of walks to reveal important information flows in the network, and provides higher-order explanations, which have been shown to be superior to the lower-order, i.e., node-/edge-level, explanations. However, identifying relevant walks by GNN-LRP requires exponential computational complexity with respect to the network depth, which we will remedy in this paper. Specifically, we propose polynomial-time algorithms for finding top-$K$ relevant walks, which drastically reduces the computation and thus increases the applicability of GNN-LRP to large-scale problems. Our proposed algorithms are based on the max-product algorithm—a common tool for finding the maximum likelihood configurations in probabilistic graphical models—and can find the most relevant walks exactly at the neuron level and approximately at the node level. Our experiments demonstrate the performance of our algorithms at scale and their utility across application domains, i.e., on epidemiology, molecular, and natural language benchmarks. We provide our codes under github.com/xiong-ping/rel_walk_gnnlrp.

**摘要:** 图神经网络(GNNs)已成为图分析的重要机器学习工具,其解释性对于安全、公平和鲁棒性至关重要。GNNs的层级关联传播(英语:Layer-wise relevance propagation for GNNs)(GNN-LRP)评估路径相关性,以揭示网络中的重要信息流,并提供较高级的解释,证明其优于较低级的解释,即节点/边缘层次的解释。我们提出的算法是基于最大产值算法的,这是在概率图形模型中找到最大概率配置的通用工具,并且能够在神经元和大约在节点层面找到最相关的行走。我们的实验证明了我们的算法在各个应用领域,即流行病学、分子和自然语言的基准上的表现及其实用性。

**[Paper URL](https://proceedings.mlr.press/v202/xiong23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xiong23b/xiong23b.pdf)** 

# Why do Nearest Neighbor Language Models Work?
**题目:** 为什么最近邻语言模型工作?

**作者:** Frank F. Xu, Uri Alon, Graham Neubig

**Abstract:** Language models (LMs) compute the probability of a text by sequentially computing a representation of an already-seen context and using this representation to predict the next word. Currently, most LMs calculate these representations through a neural network consuming the immediate previous context. However recently, retrieval-augmented LMs have shown to improve over standard neural LMs, by accessing information retrieved from a large datastore, in addition to their standard, parametric, next-word prediction. In this paper, we set out to understand why retrieval-augmented language models, and specifically why k-nearest neighbor language models (kNN-LMs) perform better than standard parametric LMs, even when the k-nearest neighbor component retrieves examples from the same training set that the LM was originally trained on. To this end, we perform analysis of various dimensions over which kNN-LM diverges from standard LMs, and investigate these dimensions one by one. Empirically, we identify three main reasons why kNN-LM performs better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution. Further, we incorporate some insights into the standard parametric LM, improving performance without the need for an explicit retrieval component. The code is available at https://github.com/frankxu2004/knnlm-why.

**摘要:** 语言模型(英语:Language models,简称:LMs)是通过连续计算已见语境的表示来计算文本的概率,并利用此表示来预测下一个词。目前,大多数LMs通过神经网络来计算这些表示,同时消耗了前面的语境。然而最近,检索增强的LMs已经显示,通过从大型数据存储中检索的信息,除了其标准的参数化下一个词的预测之外,还可以改进标准的神经LMs。 Empirically, we identify three main reasons why kNN-LM performs better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution. Further, we incorporate some insights into the standard parametric LM, improving performance without the need for an explicit retrieval component. The code is available at https://github.com/frankxu2004/knnlm-why.

**[Paper URL](https://proceedings.mlr.press/v202/xu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23a/xu23a.pdf)** 

# MixFlows: principled variational inference via mixed flows
**题目:** 混合流:通过混合流的原理变量推导

**作者:** Zuheng Xu, Naitong Chen, Trevor Campbell

**Abstract:** This work presents mixed variational flows (MixFlows), a new variational family that consists of a mixture of repeated applications of a map to an initial reference distribution. First, we provide efficient algorithms for i.i.d. sampling, density evaluation, and unbiased ELBO estimation. We then show that MixFlows have MCMC-like convergence guarantees when the flow map is ergodic and measure-preserving, and provide bounds on the accumulation of error for practical implementations where the flow map is approximated. Finally, we develop an implementation of MixFlows based on uncorrected discretized Hamiltonian dynamics combined with deterministic momentum refreshment. Simulated and real data experiments show that MixFlows can provide more reliable posterior approximations than several black-box normalizing flows, as well as samples of comparable quality to those obtained from state-of-the-art MCMC methods.

**摘要:** 本文介绍了混合变量流(MixFlows),一种新的变量家族,由映射对初始参考分布的重复应用混合而成。首先,我们为诸如采样、密度评估和无偏见ELBO估计提供有效的算法。然后,我们证明,MixFlows在流动映射是 ergodic和计量保存时具有MCMCMC相似的收敛性保证,并为实际实现在流动映射近似时的误差累积提供界限。最后,我们开发了基于未纠正的离散哈密顿动力学和确定动力刷新相结合的MixFlows的实现。

**[Paper URL](https://proceedings.mlr.press/v202/xu23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23b/xu23b.pdf)** 

# Bit Allocation using Optimization
**题目:** 使用优化的位分配

**作者:** Tongda Xu, Han Gao, Chenjian Gao, Yuanyuan Wang, Dailan He, Jinyong Pi, Jixiang Luo, Ziyu Zhu, Mao Ye, Hongwei Qin, Yan Wang, Jingjing Liu, Ya-Qin Zhang

**Abstract:** In this paper, we consider the problem of bit allocation in Neural Video Compression (NVC). First, we reveal a fundamental relationship between bit allocation in NVC and Semi-Amortized Variational Inference (SAVI). Specifically, we show that SAVI with GoP (Group-of-Picture)-level likelihood is equivalent to pixel-level bit allocation with precise rate & quality dependency model. Based on this equivalence, we establish a new paradigm of bit allocation using SAVI. Different from previous bit allocation methods, our approach requires no empirical model and is thus optimal. Moreover, as the original SAVI using gradient ascent only applies to single-level latent, we extend the SAVI to multi-level such as NVC by recursively applying back-propagating through gradient ascent. Finally, we propose a tractable approximation for practical implementation. Our method can be applied to scenarios where performance outweights encoding speed, and serves as an empirical bound on the R-D performance of bit allocation. Experimental results show that current state-of-the-art bit allocation algorithms still have a room of $\approx 0.5$ dB PSNR to improve compared with ours. Code is available at https://github.com/tongdaxu/Bit-Allocation-Using-Optimization.

**摘要:** 本文研究了神经视频压缩(NVC)中的位数分配问题,首先揭示了神经视频压缩(NVC)中的位数分配与半修正变量ference(SAVI)之间的基本关系,具体说明了GoP(Group-of-Picture)级的SAVI与像素级的位数分配具有精确的速度和质量依赖模型等价,基于此等价,建立了SAVI的位数分配的新范式,与以往的位数分配方法不同,我们不需要经验模型,因此是最佳的。我们的方法可以应用于性能超过编码速度的场景,并作为比特分配的研发性能的实证约束。实验结果表明,目前最先进的比特分配算法仍然有$\约0.5$dB的PSNR空间,以改善与我们相比。代码可于 https://github.com/tongdaxu/Bit-Allocation-Using-Optimization。

**[Paper URL](https://proceedings.mlr.press/v202/xu23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23c/xu23c.pdf)** 

# Regret Bounds for Markov Decision Processes with Recursive Optimized Certainty Equivalents
**题目:** 递归优化确定值的马可夫决策过程的遗憾约束

**作者:** Wenhao Xu, Xuefeng Gao, Xuedong He

**Abstract:** The optimized certainty equivalent (OCE) is a family of risk measures that cover important examples such as entropic risk, conditional value-at-risk and mean-variance models. In this paper, we propose a new episodic risk-sensitive reinforcement learning formulation based on tabular Markov decision processes with recursive OCEs. We design an efficient learning algorithm for this problem based on value iteration and upper confidence bound. We derive an upper bound on the regret of the proposed algorithm, and also establish a minimax lower bound. Our bounds show that the regret rate achieved by our proposed algorithm has optimal dependence on the number of episodes and the number of actions.

**摘要:** 优化确定性等值(英语:Optimized certainty equivalent,缩写为OCE)是一种包含熵风险、风险条件值和平均变量模型等重要例子的风险措施的家族。本文提出了一种基于表式马可夫决策过程的基于递归OCE的 episodic risk-sensitive reinforcement learning formulation。

**[Paper URL](https://proceedings.mlr.press/v202/xu23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23d/xu23d.pdf)** 

# Probabilistic Categorical Adversarial Attack and Adversarial Training
**题目:** 概率类别敌对攻击与敌对训练

**作者:** Han Xu, Pengfei He, Jie Ren, Yuxuan Wan, Zitao Liu, Hui Liu, Jiliang Tang

**Abstract:** The studies on adversarial attacks and defenses have greatly improved the robustness of Deep Neural Networks (DNNs). Most advanced approaches have been overwhelmingly designed for continuous data such as images. However, these achievements are still hard to be generalized to categorical data. To bridge this gap, we propose a novel framework, Probabilistic Categorical Adversarial Attack (or PCAA). It transfers the discrete optimization problem of finding categorical adversarial examples to a continuous problem that can be solved via gradient-based methods. We analyze the optimality (attack success rate) and time complexity of PCAA to demonstrate its significant advantage over current search-based attacks. More importantly, through extensive empirical studies, we demonstrate that the well-established defenses for continuous data, such as adversarial training and TRADES, can be easily accommodated to defend DNNs for categorical data.

**摘要:** 对敌对攻击和防御的研究大大提高了深度神经网络(DNNs)的鲁棒性。最先进的方法被大量设计为连续数据,例如图像。然而,这些成就仍然很难将它们推广到分类数据。为了弥补这一差距,我们提出了一种新框架,概率分类敌对攻击(或PCAA)。它将分类敌对的发现实例的离散优化问题转移到可通过梯度基础的方法解决的连续问题。我们分析了PCAA的优越性(攻击成功率)和时间复杂性,以证明其在当前基于搜索的攻击中具有重大优势。

**[Paper URL](https://proceedings.mlr.press/v202/xu23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23e/xu23e.pdf)** 

# Hierarchical Neural Coding for Controllable CAD Model Generation
**题目:** 可控CAD模型生成的层次神经编码

**作者:** Xiang Xu, Pradeep Kumar Jayaraman, Joseph George Lambourne, Karl D.D. Willis, Yasutaka Furukawa

**Abstract:** This paper presents a novel generative model for Computer Aided Design (CAD) that 1) represents high-level design concepts of a CAD model as a three-level hierarchical tree of neural codes, from global part arrangement down to local curve geometry; and 2) controls the generation or completion of CAD models by specifying the target design using a code tree. Concretely, a novel variant of a vector quantized VAE with "masked skip connection" extracts design variations as neural codebooks at three levels. Two-stage cascaded auto-regressive transformers learn to generate code trees from incomplete CAD models and then complete CAD models following the intended design. Extensive experiments demonstrate superior performance on conventional tasks such as unconditional generation while enabling novel interaction capabilities on conditional generation tasks. The code is available at https://github.com/samxuxiang/hnc-cad.

**摘要:** 本文对计算机辅助设计(CAD)提出了一种新型的生成模型,该模型(一)代表了CAD模型的高层次设计概念,即神经代码的三个层次层次层次树,从全球部件配置到局部曲线几何;(二)通过使用代码树指定目标设计来控制CAD模型的生成或完成。具体而言,一种具有“ masked skip connection”的向量化VAE的新型变量提取了三个层次的神经代码本的设计变量。

**[Paper URL](https://proceedings.mlr.press/v202/xu23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23f/xu23f.pdf)** 

# Efficient Sequence Transduction by Jointly Predicting Tokens and Durations
**题目:** 联合预测トークン和期限的高效序列转换

**作者:** Hainan Xu, Fei Jia, Somshubra Majumdar, He Huang, Shinji Watanabe, Boris Ginsburg

**Abstract:** This paper introduces a novel Token-and-Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conventional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently normalized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted duration output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better accuracy and up to 2.82X faster inference than conventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with conventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent accuracy by up to over 1% (absolute) over conventional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https://github.com/NVIDIA/NeMo) toolkit.

**摘要:** 本文介绍了一种新的序列到序列任务的符号和时间转换器(TDT)架构。TDT通过联合预测一个符号及其时间,即被发射的符号覆盖的输入帧的数目,扩展了传统的RNN-转换器架构。这通过使用两个输出的联合网络实现,可以独立规范生成在符号和时间上的分布。在推导过程中,TDT模型可以跳过由预测时间输出导入的输入帧,从而使它们比传统的转换器大大更快,因为它们通过帧处理编码器输出帧。TDT模型在不同序列转换任务上获得比传统的转换器更好的精度和更快的推导。TDT语言识别模型获得比传统的转换器更快的精度和更快的推导。TDT语言翻译模型在MUST-C测试中达到超过1 BLEU的绝对收益,与传统的变换器相比,其推导速度更快2.27X。在语言意图分类和 Slot 填充任务中,TDT模型提高了传统变换器的意图准确度超过1%(绝对),同时运行速度更快1.28X。TDT模型的实现将使用NeMo(https://github.com/NVIDIA/NeMo)工具包。

**[Paper URL](https://proceedings.mlr.press/v202/xu23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23g/xu23g.pdf)** 

# Constrained Efficient Global Optimization of Expensive Black-box Functions
**题目:** 有限有效的全球优化昂贵的黑箱功能

**作者:** Wenjie Xu, Yuning Jiang, Bratislav Svetozarevic, Colin Jones

**Abstract:** We study the problem of constrained efficient global optimization, where both the objective and constraints are expensive black-box functions that can be learned with Gaussian processes. We propose CONFIG (CONstrained efFIcient Global Optimization), a simple and effective algorithm to solve it. Under certain regularity assumptions, we show that our algorithm enjoys the same cumulative regret bound as that in the unconstrained case and similar cumulative constraint violation upper bounds. For commonly used Matern and Squared Exponential kernels, our bounds are sublinear and allow us to derive a convergence rate to the optimal solution of the original constrained problem. In addition, our method naturally provides a scheme to declare infeasibility when the original black-box optimization problem is infeasible. Numerical experiments on sampled instances from the Gaussian process, artificial numerical problems, and a black-box building controller tuning problem all demonstrate the competitive performance of our algorithm. Compared to the other state-of-the-art methods, our algorithm significantly improves the theoretical guarantees while achieving competitive empirical performance.

**摘要:** 我们研究了约束有效的全球优化问题,其中目标和约束都是高昂的黑箱函数,可与高斯过程学习。我们提出了约束有效的全球优化(CONFIG),一种简单的有效的算法来解决它。在某些规则假设下,我们表明,我们的算法享有相同的累积遗憾边界,如在无约束的情况下和类似累积约束违反上限边界。对于常用的母核和平方指数核,我们的边界是次线性,允许我们推导到原始约束问题的最优解决率。高斯过程样本实例的数值实验、人工数值问题和黑箱建筑控制器调制问题都表明了我们的算法的竞争性性能。与其他最先进的方法相比,我们的算法在实现竞争性经验性能的同时,大大提高了理论保证。

**[Paper URL](https://proceedings.mlr.press/v202/xu23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23h/xu23h.pdf)** 

# Pareto Regret Analyses in Multi-objective Multi-armed Bandit
**题目:** 多目标多武装强盗的 Pareto遗憾分析

**作者:** Mengfan Xu, Diego Klabjan

**Abstract:** We study Pareto optimality in multi-objective multi-armed bandit by providing a formulation of adversarial multi-objective multi-armed bandit and defining its Pareto regrets that can be applied to both stochastic and adversarial settings. The regrets do not rely on any scalarization functions and reflect Pareto optimality compared to scalarized regrets. We also present new algorithms assuming both with and without prior information of the multi-objective multi-armed bandit setting. The algorithms are shown optimal in adversarial settings and nearly optimal up to a logarithmic factor in stochastic settings simultaneously by our established upper bounds and lower bounds on Pareto regrets. Moreover, the lower bound analyses show that the new regrets are consistent with the existing Pareto regret for stochastic settings and extend an adversarial attack mechanism from bandit to the multi-objective one.

**摘要:** 我们通过对敌对多目标多武器 bandit的公式,研究了多目标多武器 bandit的帕雷托优越性,并定义了其对随机和敌对设置的帕雷托遗憾,这些遗憾不依赖任何 scalarization函数,并反映了对随机设置的帕雷托优越性。我们还给出了从多目标多武器 bandit设置的预先信息和预先信息两个假设的新算法。

**[Paper URL](https://proceedings.mlr.press/v202/xu23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23i/xu23i.pdf)** 

# Diverse and Faithful Knowledge-Grounded Dialogue Generation via Sequential Posterior Inference
**题目:** 通过序列后向ference产生多样和忠实的基于知识的对话

**作者:** Yan Xu, Deqian Kong, Dehong Xu, Ziwei Ji, Bo Pang, Pascale Fung, Ying Nian Wu

**Abstract:** The capability to generate responses with diversity and faithfulness using factual knowledge is paramount for creating a human-like, trustworthy dialogue system. Common strategies either adopt a two-step paradigm, which optimizes knowledge selection and response generation separately, and may overlook the inherent correlation between these two tasks, or leverage conditional variational method to jointly optimize knowledge selection and response generation by employing an inference network. In this paper, we present an end-to-end learning framework, termed Sequential Posterior Inference (SPI), capable of selecting knowledge and generating dialogues by approximately sampling from the posterior distribution. Unlike other methods, SPI does not require the inference network or assume a simple geometry of the posterior distribution. This straightforward and intuitive inference procedure of SPI directly queries the response generation model, allowing for accurate knowledge selection and generation of faithful responses. In addition to modeling contributions, our experimental results on two common dialogue datasets (Wizard of Wikipedia and Holl-E) demonstrate that SPI outperforms previous strong baselines according to both automatic and human evaluation metrics.

**摘要:** 利用实情知识,具有多样性和可靠的响应能力,是建立具有人性和可信的对话系统的关键。一般策略要么采用两步模式,分别优化知识选择和响应生成,或者利用条件变异法利用推理网络共同优化知识选择和响应生成。本文提出了一种从后方分布抽样选择知识和生成对话的终到终学习框架,称为次序后方ference(SPI)。与其他方法不同,SPI不需要推理网络或假设后方分布的简单几何。SPI的直接和直观推理程序直接查询响应生成模型,允许准确的知识选择和产生忠实的响应。除了建模贡献之外,我们对两个共同对话数据集(维基百科和霍尔-E)的实验结果表明,SPI在自动和人类评价指标的基础上比以前的强基线表现得更好。

**[Paper URL](https://proceedings.mlr.press/v202/xu23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23j/xu23j.pdf)** 

# Quantifying the Variability Collapse of Neural Networks
**题目:** 神经网络变量崩溃的定量化

**作者:** Jing Xu, Haoxiong Liu

**Abstract:** Recent studies empirically demonstrate the positive relationship between the transferability of neural networks and the in-class variation of the last layer features. The recently discovered Neural Collapse (NC) phenomenon provides a new perspective of understanding such last layer geometry of neural networks. In this paper, we propose a novel metric, named Variability Collapse Index (VCI), to quantify the variability collapse phenomenon in the NC paradigm. The VCI metric is well-motivated and intrinsically related to the linear probing loss on the last layer features. Moreover, it enjoys desired theoretical and empirical properties, including invariance under invertible linear transformations and numerical stability, that distinguishes it from previous metrics. Our experiments verify that VCI is indicative of the variability collapse and the transferability of pretrained neural networks.

**摘要:** 近年来的实验研究表明,神经网络的可转移性与末层特征的类别变异之间存在着积极的关系。最近发现的神经网络的末层几何现象提供了一种新的理解神经网络的末层几何的视角。本文提出了一种新的计量方法,称为变异性折叠指数(VCI),以量化NC范式中变异性折叠现象。VCI计量方法具有良好的动机,与末层特征的线性探测损失有内在关系。此外,它具有预期的理论和经验性质,包括可逆线性变换和数值稳定性下的变异性,使它与以前的计量方法有所区别。

**[Paper URL](https://proceedings.mlr.press/v202/xu23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23k/xu23k.pdf)** 

# Progressive Purification for Instance-Dependent Partial Label Learning
**题目:** 实例依赖部分标签学习的进化纯化

**作者:** Ning Xu, Biao Liu, Jiaqi Lv, Congyu Qiao, Xin Geng

**Abstract:** Partial label learning (PLL) aims to train multiclass classifiers from the examples each annotated with a set of candidate labels where a fixed but unknown candidate label is correct. In the last few years, the instance-independent generation process of candidate labels has been extensively studied, on the basis of which many theoretical advances have been made in PLL. Nevertheless, the candidate labels are always instance-dependent in practice and there is no theoretical guarantee that the model trained on the instance-dependent PLL examples can converge to an ideal one. In this paper, a theoretically grounded and practically effective approach named POP, i.e. PrOgressive Purification for instance-dependent partial label learning, is proposed. Specifically, POP updates the learning model and purifies each candidate label set progressively in every epoch. Theoretically, we prove that POP enlarges the region appropriately fast where the model is reliable, and eventually approximates the Bayes optimal classifier with mild assumptions. Technically, POP is flexible with arbitrary PLL losses and could improve the performance of the previous PLL losses in the instance-dependent case. Experiments on the benchmark datasets and the real-world datasets validate the effectiveness of the proposed method.

**摘要:** 部分标签学习(英语:Partial label learning,缩写为PLL)旨在训练各类类类别分类器,从每个类别分类器的实例中注释出一个集合的候选标签,其中一个固定但未知的候选标签是正确的。在过去几年中,对候选标签的实例独立生成过程进行了广泛研究,在此基础上,在PLL中取得了许多理论上的进展。然而,候选标签在实践中都是实例依赖的,没有理论保证,由实例依赖的PLL实例训练的模型能够达到理想的模型。从理论上看,我们证明了POP能够在模型可靠的地方快速扩大区域,并最终以轻微假设逼近贝伊斯最佳分类器。从技术上看,POP具有随机的PLL损失的灵活性,可以在实例依赖的案例中提高以前的PLL损失的性能。

**[Paper URL](https://proceedings.mlr.press/v202/xu23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23l/xu23l.pdf)** 

# PFGM++: Unlocking the Potential of Physics-Inspired Generative Models
**题目:** PFGM++:解开物理启发的生成模型的潜力

**作者:** Yilun Xu, Ziming Liu, Yonglong Tian, Shangyuan Tong, Max Tegmark, Tommi Jaakkola

**Abstract:** We introduce a new family of physics-inspired generative models termed PFGM++ that unifies diffusion models and Poisson Flow Generative Models (PFGM). These models realize generative trajectories for N dimensional data by embedding paths in N+D dimensional space while still controlling the progression with a simple scalar norm of the D additional variables. The new models reduce to PFGM when D=1 and to diffusion models when D$\to\infty$. The flexibility of choosing D allows us to trade off robustness against rigidity as increasing D results in more concentrated coupling between the data and the additional variable norms. We dispense with the biased large batch field targets used in PFGM and instead provide an unbiased perturbation-based objective similar to diffusion models. To explore different choices of D, we provide a direct alignment method for transferring well-tuned hyperparameters from diffusion models (D$\to\infty$) to any finite D values. Our experiments show that models with finite D can be superior to previous state-of-the-art diffusion models on CIFAR-10/FFHQ 64$\times$64 datasets/LSUN Churches 256$\times$256, with median Ds. In class-conditional setting, D=2048 yields current state-of-the-art FID of 1.74 on CIFAR-10 without additional training. Furthermore, we demonstrate that models with smaller $D$ exhibit improved robustness against modeling errors. Code is available at https://github.com/Newbeeer/pfgmpp

**摘要:** 我们介绍了一种由物理学启发的新型生成模型,称为PFGM++,它将扩散模型和波森流生成模型(PFGM)统一起来。这些模型通过在N+D维空间内嵌入路径实现N维数据的生成轨迹,同时仍控制D额外变量的一个简单的 scalar规范的进度。新的模型减少到PFGM时D=1和扩散模型时D$\to\infty$。选择D的灵活性使我们能够抵消增加D的结果与增加D的刚度的鲁棒性,从而使数据和额外变量规范更加集中耦合。我们不再使用PFGM中偏向的大型批量场目标,而是提供与扩散模型类似的偏向扰动目标。我们的实验表明,有限D的模型可以比以前在CIFAR-10/FFHQ64$\times$64数据集/LSUN教堂256$\times$256上的最先进的扩散模型优于中等D的模型。在类条件设置中,D=2048在CIFAR-10上提供1.44的最先进的FID,无需额外训练。

**[Paper URL](https://proceedings.mlr.press/v202/xu23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23m/xu23m.pdf)** 

# Geometric Latent Diffusion Models for 3D Molecule Generation
**题目:** 3D分子生成的几何随机扩散模型

**作者:** Minkai Xu, Alexander S Powers, Ron O. Dror, Stefano Ermon, Jure Leskovec

**Abstract:** Generative models, especially diffusion models (DMs), have achieved promising results for generating feature-rich geometries and advancing foundational science problems such as molecule design. Inspired by the recent huge success of Stable (latent) Diffusion models, we propose a novel and principled method for 3D molecule generation named Geometric Latent Diffusion Models (GeoLDM). GeoLDM is the first latent DM model for the molecular geometry domain, composed of autoencoders encoding structures into continuous latent codes and DMs operating in the latent space. Our key innovation is that for modeling the 3D molecular geometries, we capture its critical roto-translational equivariance constraints by building a point-structured latent space with both invariant scalars and equivariant tensors. Extensive experiments demonstrate that GeoLDM can consistently achieve better performance on multiple molecule generation benchmarks, with up to 7% improvement for the valid percentage of large biomolecules. Results also demonstrate GeoLDM’s higher capacity for controllable generation thanks to the latent modeling. Code is provided at https://github.com/MinkaiXu/GeoLDM.

**摘要:** 生成模型,特别是扩散模型(DMs),为生成具有特征的几何和推进分子设计等基础科学问题取得了令人期待的成果。我们以稳定(潜在)扩散模型的巨大成功为灵感,提出了一种新颖和原则化的3D分子生成方法,称Geometric Latent Diffusion Models(GeoLDM)。GeoLDM是分子几何领域第一个潜在DM模型,由自动编码器编码结构 into continuous latent codes and DMs operating in the latent space组成。广泛的实验表明,GeoLDM能够在多个分子生成基准上持续取得更好的性能,为大分子的有效百分比提高到7%。结果还表明,GeoLDM的可控生成能力是由于潜在的建模而提高的。

**[Paper URL](https://proceedings.mlr.press/v202/xu23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23n/xu23n.pdf)** 

# The Power of Preconditioning in Overparameterized Low-Rank Matrix Sensing
**题目:** 超参数低级矩阵感知预冷的优越性

**作者:** Xingyu Xu, Yandi Shen, Yuejie Chi, Cong Ma

**Abstract:** We propose $\textsf{ScaledGD($\lambda$)}$, a preconditioned gradient descent method to tackle the low-rank matrix sensing problem when the true rank is unknown, and when the matrix is possibly ill-conditioned. Using overparametrized factor representations, $\textsf{ScaledGD($\lambda$)}$ starts from a small random initialization, and proceeds by gradient descent with a specific form of preconditioning with a fixed damping term to combat overparameterization. At the expense of light computational overhead incurred by preconditioners, $\textsf{ScaledGD($\lambda$)}$ is remarkably robust to ill-conditioning compared to vanilla gradient descent ($\mathsf{GD}$). Specifically, we show that, under the Gaussian design, $\textsf{ScaledGD($\lambda$)}$ converges to the true low-rank matrix at a constant linear rate that is independent of the condition number (apart from a short nearly dimension-free burdening period), with near-optimal sample complexity. This significantly improves upon the convergence rate of vanilla $\mathsf{GD}$ which suffers from a polynomial dependency with the condition number. Our work provides evidence on the power of preconditioning in accelerating the convergence without hurting generalization in overparameterized learning.

**摘要:** 我们提出了一个预先条件下的梯度下降方法来解决低级矩阵感知问题,当真级未知时和矩阵可能有不良条件时。使用过参数化因子表示,$\textsf{ScaledGD($\lambda$)}$从小随机初始化开始,并通过梯度下降以固定阻尼条件的特定形式进行预conditioning,以对抗过参数化。这大大提高了瓦尼拉$\mathsf{GD}$的收敛率,因为瓦尼拉$\mathsf{GD}$与条件数具有多项式依赖性,我们的工作证明了预条件化在加速收敛而不影响过度参数化学习中的一般化能力。

**[Paper URL](https://proceedings.mlr.press/v202/xu23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23o/xu23o.pdf)** 

# Fascinating Supervisory Signals and Where to Find Them: Deep Anomaly Detection with Scale Learning
**题目:** 惊人的监视信号及寻找它们的途径:基于尺度学习的深度异常检测

**作者:** Hongzuo Xu, Yijie Wang, Juhui Wei, Songlei Jian, Yizhou Li, Ning Liu

**Abstract:** Due to the unsupervised nature of anomaly detection, the key to fueling deep models is finding supervisory signals. Different from current reconstruction-guided generative models and transformation-based contrastive models, we devise novel data-driven supervision for tabular data by introducing a characteristic – scale – as data labels. By representing varied sub-vectors of data instances, we define scale as the relationship between the dimensionality of original sub-vectors and that of representations. Scales serve as labels attached to transformed representations, thus offering ample labeled data for neural network training. This paper further proposes a scale learning-based anomaly detection method. Supervised by the learning objective of scale distribution alignment, our approach learns the ranking of representations converted from varied subspaces of each data instance. Through this proxy task, our approach models inherent regularities and patterns within data, which well describes data "normality". Abnormal degrees of testing instances are obtained by measuring whether they fit these learned patterns. Extensive experiments show that our approach leads to significant improvement over state-of-the-art generative/contrastive anomaly detection methods.

**摘要:** 由于异常检测的无监督性质,对深度模型的动力关键是寻找监控信号。与当前的重建导向的生成模型和基于变换的对比模型不同,我们通过引入特征—尺度—作为数据标签来设计新的数据驱动的表数据监控。通过对数据实例的变异子向量表示,我们定义尺度为原子向量与表示的维度之间的关系。尺度作为被变换表示的标签,从而为神经网络培训提供充足的标签数据。通过这个代理任务,我们的方法模型了数据内部的固有规律和模式,这很好地描述了数据的“正常性”。通过测量它们是否符合这些学习模式来获得测试实例的异常程度。广泛的实验表明,我们的方法能够大大改善最先进的生成/对比异常检测方法。

**[Paper URL](https://proceedings.mlr.press/v202/xu23p.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23p/xu23p.pdf)** 

# Competing for Shareable Arms in Multi-Player Multi-Armed Bandits
**题目:** 多玩家多武装匪徒争夺可共享武器

**作者:** Renzhe Xu, Haotian Wang, Xingxuan Zhang, Bo Li, Peng Cui

**Abstract:** Competitions for shareable and limited resources have long been studied with strategic agents. In reality, agents often have to learn and maximize the rewards of the resources at the same time. To design an individualized competing policy, we model the competition between agents in a novel multi-player multi-armed bandit (MPMAB) setting where players are selfish and aim to maximize their own rewards. In addition, when several players pull the same arm, we assume that these players averagely share the arms’ rewards by expectation. Under this setting, we first analyze the Nash equilibrium when arms’ rewards are known. Subsequently, we propose a novel Selfish MPMAB with Averaging Allocation (SMAA) approach based on the equilibrium. We theoretically demonstrate that SMAA could achieve a good regret guarantee for each player when all players follow the algorithm. Additionally, we establish that no single selfish player can significantly increase their rewards through deviation, nor can they detrimentally affect other players’ rewards without incurring substantial losses for themselves. We finally validate the effectiveness of the method in extensive synthetic experiments.

**摘要:** 对可共享和有限资源的竞争已经长期与战略代理人进行研究。在现实中,代理人往往必须同时学习和最大化资源的奖励。为设计个性化的竞争政策,我们在新型的 multiplayer multiplayer bandit(MPMAB)设置中模拟代理人之间的竞争,玩家是自私的,他们的目标是最大化自己的奖励。此外,当多个玩家牵引相同的手臂时,我们假设这些玩家平均通过期望共享武器的奖励。在这一设置下,我们首先分析了武器的奖励时的纳什均衡。随后,我们提出了基于平衡的新型自私 MPMAB(Averaging Allocation)方法。此外,我们证明,任何单一的自私玩家都不能通过偏差大幅增加其奖金,也不能对其他玩家的奖金造成损害,而不会对自身造成重大损失。我们最后在广泛的合成实验中验证了该方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/xu23q.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23q/xu23q.pdf)** 

# Sequential Predictive Conformal Inference for Time Series
**题目:** 时间序列序列预测兼容性ference

**作者:** Chen Xu, Yao Xie

**Abstract:** We present a new distribution-free conformal prediction algorithm for sequential data (e.g., time series), called the sequential predictive conformal inference (SPCI). We specifically account for the nature that time series data are non-exchangeable, and thus many existing conformal prediction algorithms are not applicable. The main idea is to adaptively re-estimate the conditional quantile of non-conformity scores (e.g., prediction residuals), upon exploiting the temporal dependence among them. More precisely, we cast the problem of conformal prediction interval as predicting the quantile of a future residual, given a user-specified point prediction algorithm. Theoretically, we establish asymptotic valid conditional coverage upon extending consistency analyses in quantile regression. Using simulation and real-data experiments, we demonstrate a significant reduction in interval width of SPCI compared to other existing methods under the desired empirical coverage.

**摘要:** 本文提出了一种无分布的序列数据(例如时间序列)的一致预测算法,称为序列预测一致推断(SPCI)。我们特别考虑到时间序列数据是不可交换的性质,因此许多现有的一致预测算法是不适用的。主意是通过利用它们之间的时间依赖性,适应性地重新估算不一致分数(例如预测残余)的条件量度。更准确地说,我们用用户指定的点预测算法,将一致预测间隔问题当作预测未来残余的量度问题。理论上,我们通过在量度回归中进行一致分析来建立渐近有效条件覆盖。

**[Paper URL](https://proceedings.mlr.press/v202/xu23r.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23r/xu23r.pdf)** 

# mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image and Video
**题目:** mPLUG-2:文本、图像和视频的模块化多模态基础模型

**作者:** Haiyang Xu, Qinghao Ye, Ming Yan, Yaya Shi, Jiabo Ye, Yuanhong Xu, Chenliang Li, Bin Bi, Qi Qian, Wei Wang, Guohai Xu, Ji Zhang, Songfang Huang, Fei Huang, Jingren Zhou

**Abstract:** Recent years have witnessed a big convergence of language, vision, and multi-modal pretraining. In this work, we present mPLUG-2, a new unified paradigm with modularized design for multi-modal pretraining, which can benefit from modality collaboration while addressing the problem of modality entanglement. In contrast to predominant paradigms of solely relying on sequence-to-sequence generation or encoder-based instance discrimination, mPLUG-2 introduces a multi-module composition network by sharing common universal modules for modality collaboration and disentangling different modality modules to deal with modality entanglement. It is flexible to select different modules for different understanding and generation tasks across all modalities including text, image, and video. Empirical study shows that mPLUG-2 achieves state-of-the-art or competitive results on a broad range of over 30 downstream tasks, spanning multi-modal tasks of image-text and video-text understanding and generation, and uni-modal tasks of text-only, image-only, and video-only understanding. Notably, mPLUG-2 shows new state-of-the-art results of 48.0 top-1 accuracy and 80.3 CIDEr on the challenging MSRVTT video QA and video caption tasks with a far smaller model size and data scale. It also demonstrates strong zero-shot transferability on vision-language and video-language tasks. Code and models will be released in https://github.com/X-PLUG/mPLUG-2.

**摘要:** 近年来,语言、视觉和多模态预训练的融合已经十分明显。本文介绍了一种新的多模态预训练模块化设计的统一范式mPLUG-2,该模块可以从多模态协作中获益,同时解决多模态包围问题。与基于编码器的序列生成或实例歧视的主流范式相比,mPLUG-2通过共享多模态协作的通用模块和分离不同模态模块来处理多模态包围问题,引入了多模态组合网络。实验研究表明,mPLUG-2在30多个下游任务的广泛范围内实现了最先进的或竞争性的结果,包括图像文本和视频文本理解和生成的多模任务,以及单模文本、图像和视频理解的单模任务。 mPLUG-2特别显示了48.0高精度和80.3CIDEr的新最先进的结果,这使得MSRVTT视频QA和视频字幕任务具有较小的模型大小和数据尺度。

**[Paper URL](https://proceedings.mlr.press/v202/xu23s.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23s/xu23s.pdf)** 

# ProtST: Multi-Modality Learning of Protein Sequences and Biomedical Texts
**题目:** ProtST:多模态学习蛋白质序列和生物医学文本

**作者:** Minghao Xu, Xinyu Yuan, Santiago Miret, Jian Tang

**Abstract:** Current protein language models (PLMs) learn protein representations mainly based on their sequences, thereby well capturing co-evolutionary information, but they are unable to explicitly acquire protein functions, which is the end goal of protein representation learning. Fortunately, for many proteins, their textual property descriptions are available, where their various functions are also described. Motivated by this fact, we first build the ProtDescribe dataset to augment protein sequences with text descriptions of their functions and other important properties. Based on this dataset, we propose the ProtST framework to enhance Protein Sequence pre-training and understanding by biomedical Texts. During pre-training, we design three types of tasks, i.e., unimodal mask prediction, multimodal representation alignment and multimodal mask prediction, to enhance a PLM with protein property information with different granularities and, at the same time, preserve the PLM’s original representation power. On downstream tasks, ProtST enables both supervised learning and zero-shot prediction. We verify the superiority of ProtST-induced PLMs over previous ones on diverse representation learning benchmarks. Under the zero-shot setting, we show the effectiveness of ProtST on zero-shot protein classification, and ProtST also enables functional protein retrieval from a large-scale database without any function annotation.

**摘要:** 当前的蛋白质语言模型(PLMs)主要基于蛋白质序列学习蛋白质表现,从而很好地捕捉共进性信息,但它们无法明确地获取蛋白质功能,这是蛋白质表现学习的最终目标。幸运的是,对于许多蛋白质,它们的文本特性描述是可用的,其中它们的多种功能也被描述。在预训练期间,我们设计了三个类型的任务,即单模面罩预测、多模面罩调整和多模面罩预测,以增强具有不同粒度的蛋白质属性信息的PLM,同时保持PLM的原始表现能力。在下游任务中,ProtST可进行监督学习和零射击预测。我们验证了ProtST诱导的PLM在不同表现学习基准上优越于以前的PLM。在零射击设置下,我们显示了ProtST在零射击蛋白质分类上的有效性,而ProtST还可从大规模数据库中进行功能蛋白质检索,而无需任何功能注释。

**[Paper URL](https://proceedings.mlr.press/v202/xu23t.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23t/xu23t.pdf)** 

# Bayesian Design Principles for Frequentist Sequential Learning
**题目:** 贝叶斯设计原理用于频率序列学习

**作者:** Yunbei Xu, Assaf Zeevi

**Abstract:** We develop a general theory to optimize the frequentist regret for sequential learning problems, where efficient bandit and reinforcement learning algorithms can be derived from unified Bayesian principles. We propose a novel optimization approach to create "algorithmic beliefs" at each round, and use Bayesian posteriors to make decisions. This is the first approach to make Bayesian-type algorithms prior-free and applicable to adversarial settings, in a generic and optimal manner. Moreover, the algorithms are simple and often efficient to implement. As a major application, we present a novel algorithm for multi-armed bandits that achieves the "best-of-all-worlds" empirical performance in the stochastic, adversarial, and non-stationary environments. And we illustrate how these principles can be used in linear bandits, convex bandits, and reinforcement learning.

**摘要:** 本文提出了一种基于统一贝叶斯原理的优化方法,利用贝叶斯后方来创建各轮的“算法信条”,是实现贝叶斯类型算法的初始自由和适用于敌对环境的最优和最普遍的方法。此外,这些算法的实现是简单且经常有效的。作为主要应用,我们提出了一种实现“最佳世界”经验性能的多武器贝叶斯算法,用于随机、敌对和非静态环境。

**[Paper URL](https://proceedings.mlr.press/v202/xu23u.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23u/xu23u.pdf)** 

# SLAMB: Accelerated Large Batch Training with Sparse Communication
**题目:** SLAMB:用备用通讯加速大型批量培训

**作者:** Hang Xu, Wenxuan Zhang, Jiawei Fei, Yuzhe Wu, Tingwen Xie, Jun Huang, Yuchen Xie, Mohamed Elhoseiny, Panos Kalnis

**Abstract:** Distributed training of large deep neural networks requires frequent exchange of massive data between machines, thus communication efficiency is a major concern. Existing compressed communication methods are either not compatible with large batch optimization algorithms, or do not provide sufficient speedup in large scale. In this paper, we combine sparsification-based gradient compression with the layer-wise adaptive moments optimizer for large batch training (LAMB). We propose SLAMB, a novel communication-efficient optimizer that supports large batch sizes and scales to thousands of GPUs. SLAMB employs momentum masking, local error compensation, and element-wise adaptive rescaling to achieve accurate layer-wise weight updates, which translates to fast convergence for very large batches. Our empirical results show that, compared to the state-of-the-art, SLAMB transmits half the amount of data in large-batch BERT pre-training, without sacrificing accuracy. Moreover, SLAMB achieves excellent scalability in large computing infrastructures. For instance, SLAMB with 128 GPUs reduces the training time of Swin Transformer pre-training on ImageNet to 5.35 hours, which is 2 hours faster than the state-of-the-art. At the extreme, we trained BERT-XL (2.8B parameters) on 1,024 NVIDIA A100 GPUs, where SLAMB achieved 90% scaling efficiency.

**摘要:** 大型深度神经网络的分布式训练需要机器间频繁交换大量数据,因此通信效率是一个主要问题。现有的压缩通信方法要么与大型批量优化算法不兼容,要么在大规模范围内不能提供充分的加速。本文结合了基于散化的梯度压缩与大型批量训练的层级自适应矩阵优化器(LAMB)。我们提出了SLAMB,一种支持大型批量大小和数千台 GPU的新型通信效率优化器。此外,SLAMB在大型计算基础设施中具有卓越的可扩展性。例如,SLAMB的128位GPU将Swin Transformer预训练时间降低到5.35小时,比最新技术快2小时。在极端情况下,我们在1,024位 NVIDIA A100 GPU上训练了BERT-XL(2.8B参数),其中SLAMB达到了90%的可扩展效率。

**[Paper URL](https://proceedings.mlr.press/v202/xu23v.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23v/xu23v.pdf)** 

# Do Not Train It: A Linear Neural Architecture Search of Graph Neural Networks
**题目:** 不要训练它:图形神经网络的线性神经结构研究

**作者:** Peng Xu, Lin Zhang, Xuanzhou Liu, Jiaqi Sun, Yue Zhao, Haiqin Yang, Bei Yu

**Abstract:** Neural architecture search (NAS) for Graph neural networks (GNNs), called NAS-GNNs, has achieved significant performance over manually designed GNN architectures. However, these methods inherit issues from the conventional NAS methods, such as high computational cost and optimization difficulty. More importantly, previous NAS methods have ignored the uniqueness of GNNs, where GNNs possess expressive power without training. With the randomly-initialized weights, we can then seek the optimal architecture parameters via the sparse coding objective and derive a novel NAS-GNNs method, namely neural architecture coding (NAC). Consequently, our NAC holds a no-update scheme on GNNs and can efficiently compute in linear time. Empirical evaluations on multiple GNN benchmark datasets demonstrate that our approach leads to state-of-the-art performance, which is up to $200\times$ faster and $18.8%$ more accurate than the strong baselines.

**摘要:** 图形神经网络(GNNs)的神经架构搜索(NAS),称为NAS-GNNs,在手动设计的GNN架构上取得了显著的性能。然而,这些方法继承了传统的NAS方法的问题,例如高计算成本和优化困难。更重要的是,以前的NAS方法忽略了GNNs的独特性,GNNs在没有训练的情况下具有表达能力。

**[Paper URL](https://proceedings.mlr.press/v202/xu23w.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23w/xu23w.pdf)** 

# An Instrumental Variable Approach to Confounded Off-Policy Evaluation
**题目:** 基于仪器的变量方法对非政策的复杂评价

**作者:** Yang Xu, Jin Zhu, Chengchun Shi, Shikai Luo, Rui Song

**Abstract:** Off-policy evaluation (OPE) aims to estimate the return of a target policy using some pre-collected observational data generated by a potentially different behavior policy. In many cases, there exist unmeasured variables that confound the action-reward or action-next-state relationships, rendering many existing OPE approaches ineffective. This paper develops an instrumental variable (IV)-based method for consistent OPE in confounded sequential decision making. Similar to single-stage decision making, we show that IV enables us to correctly identify the target policy’s value in infinite horizon settings as well. Furthermore, we propose a number of policy value estimators and illustrate their effectiveness through extensive simulations and real data analysis from a world-leading short-video platform.

**摘要:** 非政策评价(Off-policy evaluation,OPE)旨在利用潜在不同的行为政策产生的一些预收集的观察数据来估计目标政策的回报。在许多情况下,存在无法测量的变量,使行动回报或行动次国关系模糊,使得许多现有的OPE方法无效。本文开发了一个基于IV的工具变量方法,用于混乱的顺序决策中一致的OPE。类似于单阶段决策,我们表明IV可以正确地识别目标政策的价值在无限水平设置中。

**[Paper URL](https://proceedings.mlr.press/v202/xu23x.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xu23x/xu23x.pdf)** 

# Near-Optimal Quantum Coreset Construction Algorithms for Clustering
**题目:**  clustering的近视量子核心集建构算法

**作者:** Yecheng Xue, Xiaoyu Chen, Tongyang Li, Shaofeng H.-C. Jiang

**Abstract:** $k$-Clustering in $\mathbb{R}^d$ (e.g., $k$-median and $k$-means) is a fundamental machine learning problem. While near-linear time approximation algorithms were known in the classical setting for a dataset with cardinality $n$, it remains open to find sublinear-time quantum algorithms. We give quantum algorithms that find coresets for $k$-clustering in $\mathbb{R}^d$ with $\tilde{O}(\sqrt{nk}d^{3/2})$ query complexity. Our coreset reduces the input size from $n$ to $\mathrm{poly}(k\epsilon^{-1}d)$, so that existing $\alpha$-approximation algorithms for clustering can run on top of it and yield $(1 + \epsilon)\alpha$-approximation. This eventually yields a quadratic speedup for various $k$-clustering approximation algorithms. We complement our algorithm with a nearly matching lower bound, that any quantum algorithm must make $\Omega(\sqrt{nk})$ queries in order to achieve even $O(1)$-approximation for $k$-clustering.

**摘要:** $k$-Clustering in $\mathbb{R}^d$ (e.g., $k$-median and $k$-means) 是一个基本的机器学习问题。虽然近线性时间近似算法在经典设置中为一个数据集具有基数$n$而知,但仍然可以找到次线性时间量子算法。我们给出了用于$k$-clustering的量子算法,其中$\tilde{O}(\sqrt{nk}d^{3/2})$查询复杂性。我们的量子算法从$n$减少输入大小到$\mathrm{poly}(k\epsilon^{-1}d)$,使得现有的$\alpha$-approximation algorithms可以运行在其顶部并产生$(1 + \epsilon)\alpha$

**[Paper URL](https://proceedings.mlr.press/v202/xue23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xue23a/xue23a.pdf)** 

# A Study on Transformer Configuration and Training Objective
**题目:** 变换器配置与培训目标的研究

**作者:** Fuzhao Xue, Jianghai Chen, Aixin Sun, Xiaozhe Ren, Zangwei Zheng, Xiaoxin He, Yongming Chen, Xin Jiang, Yang You

**Abstract:** Transformer-based models have delivered impressive results on many tasks, particularly vision and language tasks. In many model training situations, conventional configurations are often adopted. For example, we usually set the base model with hidden size (i.e. model width) to be 768 and the number of transformer layers (i.e. model depth) to be 12. In this paper, we revisit these conventional configurations by studying the the relationship between transformer configuration and training objective. We show that the optimal transformer configuration is closely related to the training objective. Specifically, compared with the simple classification objective, the masked autoencoder is effective in alleviating the over-smoothing issue in deep transformer training. Based on this finding, we propose “Bamboo”, a notion of using deeper and narrower transformer configurations, for masked autoencoder training. On ImageNet, with such a simple change in configuration, the re-designed Base-level transformer achieves 84.2% top-1 accuracy and outperforms SoTA models like MAE by $0.9%$. On language tasks, re-designed model outperforms BERT with the default setting by 1.1 points on average, on GLUE benchmark with 8 datasets.

**摘要:** 基于变换器的模型在许多任务,特别是视觉和语言任务中取得了令人印象深刻的结果。在许多模型训练中,传统的配置经常被采用。例如,我们通常将隐藏大小(即模型宽度)的基模型设置为768,变换器层数(即模型深度)为12。在本文中,我们通过研究变换器配置与训练目标之间的关系,重视这些传统的配置。我们表明,最佳变换器配置与训练目标密切相关。在ImageNet上,经过如此简单的配置更改,重新设计的Base-level变换器达到了84.2%的顶端-1精度,并且比MAE等SoTA模型高0.9%。

**[Paper URL](https://proceedings.mlr.press/v202/xue23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xue23b/xue23b.pdf)** 

# LazyGNN: Large-Scale Graph Neural Networks via Lazy Propagation
**题目:** LazyGNN:通过懒散传播的大规模图形神经网络

**作者:** Rui Xue, Haoyu Han, Mohamadali Torkamani, Jian Pei, Xiaorui Liu

**Abstract:** Recent works have demonstrated the benefits of capturing long-distance dependency in graphs by deeper graph neural networks (GNNs). But deeper GNNs suffer from the long-lasting scalability challenge due to the neighborhood explosion problem in large-scale graphs. In this work, we propose to capture long-distance dependency in graphs by shallower models instead of deeper models, which leads to a much more efficient model, LazyGNN, for graph representation learning. Moreover, we demonstrate that LazyGNN is compatible with existing scalable approaches (such as sampling methods) for further accelerations through the development of mini-batch LazyGNN. Comprehensive experiments demonstrate its superior prediction performance and scalability on large-scale benchmarks. The implementation of LazyGNN is available at https: //github.com/RXPHD/Lazy_GNN.

**摘要:** 最近的工作已经证明了通过更深的图神经网络(GNN)在图中捕捉长距离依赖的好处。但更深的GNN由于大型图中的邻近爆炸问题而遭受了长期的可扩展性挑战。在这个工作中,我们建议通过较浅的模型而不是更深的模型在图中捕捉长距离依赖,从而导致一个更高效的模型,LazyGNN,用于图表表示学习。

**[Paper URL](https://proceedings.mlr.press/v202/xue23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xue23c/xue23c.pdf)** 

# Which Features are Learnt by Contrastive Learning? On the Role of Simplicity Bias in Class Collapse and Feature Suppression
**题目:** 对单调偏见在课堂崩溃和特征抑制中的作用

**作者:** Yihao Xue, Siddharth Joshi, Eric Gan, Pin-Yu Chen, Baharan Mirzasoleiman

**Abstract:** Contrastive learning (CL) has emerged as a powerful technique for representation learning, with or without label supervision. However, supervised CL is prone to collapsing representations of subclasses within a class by not capturing all their features, and unsupervised CL may suppress harder class-relevant features by focusing on learning easy class-irrelevant features; both significantly compromise representation quality. Yet, there is no theoretical understanding of class collapse or feature suppression at test time. We provide the first unified theoretically rigorous framework to determine which features are learnt by CL. Our analysis indicate that, perhaps surprisingly, bias of (stochastic) gradient descent towards finding simpler solutions is a key factor in collapsing subclass representations and suppressing harder class-relevant features. Moreover, we present increasing embedding dimensionality and improving the quality of data augmentations as two theoretically motivated solutions to feature suppression. We also provide the first theoretical explanation for why employing supervised and unsupervised CL together yields higher-quality representations, even when using commonly-used stochastic gradient methods.

**摘要:** 反向学习(英语:Contrastive learning,缩写为CL)是表示学习的一种强大的技术,具有标签监督或无标签监督。然而,受监督的CL倾向于在类内包含所有特征的子类的倒闭表示,而不受监督的CL可能通过集中学习易于 class-irrelevant特征而抑制较强的 class-relevant特征,两者都严重损害了表示质量。然而,在测试时没有关于类倒闭或特征抑制的理论理解。我们提供了第一个统一的理论上严格的框架来确定哪些特征是由CL学习的。此外,我们提出了增强嵌入维度和提高数据增强质量的两个理论动机的特征抑制解决方案,并给出了为什么联合使用监督和非监督的CLC可以产生高质量的表示,即使使用常用的随机梯度方法。

**[Paper URL](https://proceedings.mlr.press/v202/xue23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xue23d/xue23d.pdf)** 

# Adaptive Computation with Elastic Input Sequence
**题目:** 弹性输入序列的适应性计算

**作者:** Fuzhao Xue, Valerii Likhosherstov, Anurag Arnab, Neil Houlsby, Mostafa Dehghani, Yang You

**Abstract:** Humans have the ability to adapt the type of information they use, the procedure they employ, and the amount of time they spend when solving problems. However, most standard neural networks have a fixed function type and computation budget regardless of the sample’s nature or difficulty. Adaptivity is a powerful paradigm as it not only imbues practitioners with flexibility pertaining to the downstream usage of these models but can also serve as a powerful inductive bias for solving certain challenging classes of problems. In this work, we introduce a new approach called AdaTape, which allows for dynamic computation in neural networks through adaptive tape tokens. AdaTape utilizes an elastic input sequence by equipping an architecture with a dynamic read-and-write tape. Specifically, we adaptively generate input sequences using tape tokens obtained from a tape bank which can be either trainable or derived from input data. We examine the challenges and requirements to obtain dynamic sequence content and length, and propose the Adaptive Tape Reading (ATR) algorithm to achieve both goals. Through extensive experiments on image recognition tasks, we show that AdaTape can achieve better performance while maintaining the computational cost. To facilitate further research, we have released code at https://github.com/google-research/scenic/tree/main/scenic/projects/adatape.

**摘要:** 适应性是一种强大的范式,它不仅能使实践者具有与这些模型的下游使用有关的灵活性,而且可以作为解决某些挑战性类问题的有力诱导性偏见服务。在这个工作中,我们引入了一种名为AdaTape的新方法,它允许通过适应性带牌进行神经网络动态计算。AdaTape利用带牌的弹性输入序列,装配一个结构结构的动态读写带牌。具体地说,我们通过从带牌银行获得的带牌序列来适应性生成输入序列。我们研究了获得动态序列内容和长度的挑战和要求,并提出了适应带读取(ATR)算法来实现这两个目标。通过对图像识别任务的广泛实验,我们证明AdaTape可以在维持计算成本的同时取得更好的性能。

**[Paper URL](https://proceedings.mlr.press/v202/xue23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/xue23e/xue23e.pdf)** 

# Q-learning Decision Transformer: Leveraging Dynamic Programming for Conditional Sequence Modelling in Offline RL
**题目:** Q-learning决策变换器:利用动态编程在非线性RL条件序列建模中的应用

**作者:** Taku Yamagata, Ahmed Khalil, Raul Santos-Rodriguez

**Abstract:** Recent works have shown that tackling offline reinforcement learning (RL) with a conditional policy produces promising results. The Decision Transformer (DT) combines the conditional policy approach and a transformer architecture, showing competitive performance against several benchmarks. However, DT lacks stitching ability – one of the critical abilities for offline RL to learn the optimal policy from sub-optimal trajectories. This issue becomes particularly significant when the offline dataset only contains sub-optimal trajectories. On the other hand, the conventional RL approaches based on Dynamic Programming (such as Q-learning) do not have the same limitation; however, they suffer from unstable learning behaviours, especially when they rely on function approximation in an off-policy learning setting. In this paper, we propose the Q-learning Decision Transformer (QDT) to address the shortcomings of DT by leveraging the benefits of Dynamic Programming (Q-learning). It utilises the Dynamic Programming results to relabel the return-to-go in the training data to then train the DT with the relabelled data. Our approach efficiently exploits the benefits of these two approaches and compensates for each other’s shortcomings to achieve better performance.

**摘要:** 近来的研究表明,利用条件性策略来解决非线性强化学习(RL)产生有前途的结果。决策变换器(DT)结合条件性策略方法和变换器架构,显示了与多个基准相比的竞争性能。然而,DT缺乏缝纫能力—— offline RL学习最优策略的关键能力之一,在非线性数据集只包含最优路径时,这一问题尤为突出。它利用动态编程结果将训练数据中的返回数据重新编码,然后用重新编码的数据训练DT。我们的方法有效地利用这两个方法的好处,补偿彼此的不足以达到更好的性能。

**[Paper URL](https://proceedings.mlr.press/v202/yamagata23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yamagata23a/yamagata23a.pdf)** 

# Quantum Ridgelet Transform: Winning Lottery Ticket of Neural Networks with Quantum Computation
**题目:** 量子 Ridgelet变换:用量子计算实现神经网络的赢家奖券

**作者:** Hayata Yamasaki, Sathyawageeswar Subramanian, Satoshi Hayakawa, Sho Sonoda

**Abstract:** A significant challenge in the field of quantum machine learning (QML) is to establish applications of quantum computation to accelerate common tasks in machine learning such as those for neural networks. Ridgelet transform has been a fundamental mathematical tool in the theoretical studies of neural networks, but the practical applicability of ridgelet transform to conducting learning tasks was limited since its numerical implementation by conventional classical computation requires an exponential runtime $\exp(O(D))$ as data dimension $D$ increases. To address this problem, we develop a quantum ridgelet transform (QRT), which implements the ridgelet transform of a quantum state within a linear runtime $O(D)$ of quantum computation. As an application, we also show that one can use QRT as a fundamental subroutine for QML to efficiently find a sparse trainable subnetwork of large shallow wide neural networks without conducting large-scale optimization of the original network. This application discovers an efficient way in this regime to demonstrate the lottery ticket hypothesis on finding such a sparse trainable neural network. These results open an avenue of QML for accelerating learning tasks with commonly used classical neural networks.

**摘要:** 量子机器学习(QML)领域的一个重要挑战是建立量子计算的应用,以加速机器学习中常见的任务,例如神经网络。雷格雷特变换在神经网络理论研究中是一个基本的数学工具,但雷格雷特变换在执行学习任务时的实际适用性是有限的,因为传统经典计算的数值实现需要指数运行时间$\exp(O(D))$,因为数据维度$D$增加。该应用发现一种有效的方法,以证明这种稀疏的训练性神经网络的抽奖券假设。这些结果开辟了QML的途径,以加速与常用的经典神经网络进行学习任务。

**[Paper URL](https://proceedings.mlr.press/v202/yamasaki23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yamasaki23a/yamasaki23a.pdf)** 

# Compressed Decentralized Proximal Stochastic Gradient Method for Nonconvex Composite Problems with Heterogeneous Data
**题目:** 非凸复合问题与异构数据的压缩分散近似随机梯度方法

**作者:** Yonggui Yan, Jie Chen, Pin-Yu Chen, Xiaodong Cui, Songtao Lu, Yangyang Xu

**Abstract:** We first propose a decentralized proximal stochastic gradient tracking method (DProxSGT) for nonconvex stochastic composite problems, with data heterogeneously distributed on multiple workers in a decentralized connected network. To save communication cost, we then extend DProxSGT to a compressed method by compressing the communicated information. Both methods need only $\mathcal{O}(1)$ samples per worker for each proximal update, which is important to achieve good generalization performance on training deep neural networks. With a smoothness condition on the expected loss function (but not on each sample function), the proposed methods can achieve an optimal sample complexity result to produce a near-stationary point. Numerical experiments on training neural networks demonstrate the significantly better generalization performance of our methods over large-batch training methods and momentum variance-reduction methods and also, the ability of handling heterogeneous data by the gradient tracking scheme.

**摘要:** 首先,我们提出了一种非凸随机复合问题的分散近距离随机梯度跟踪方法(DProxSGT),在分散连接网络中对多个工人分布异质数据,以节省通信成本。然后,我们将DProxSGT扩展到压缩方法,通过压缩通信信息。训练神经网络的数值实验证明了我们方法在大规模训练方法和运动变异减速方法上具有显著的推广性能,并通过梯度跟踪方案处理异质数据的能力。

**[Paper URL](https://proceedings.mlr.press/v202/yan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yan23a/yan23a.pdf)** 

# Temporally Consistent Transformers for Video Generation
**题目:** 为视频生成提供临时一致的变换器

**作者:** Wilson Yan, Danijar Hafner, Stephen James, Pieter Abbeel

**Abstract:** To generate accurate videos, algorithms have to understand the spatial and temporal dependencies in the world. Current algorithms enable accurate predictions over short horizons but tend to suffer from temporal inconsistencies. When generated content goes out of view and is later revisited, the model invents different content instead. Despite this severe limitation, no established benchmarks exist for video generation with long temporal dependencies. In this paper, we curate 3 challenging video datasets with long-range dependencies by rendering walks through 3D scenes of procedural mazes, Minecraft worlds, and indoor scans. We perform a comprehensive evaluation of current models and observe their limitations in temporal consistency. Moreover, we introduce the Temporally Consistent Transformer (TECO), a generative model that substantially improves long-term consistency while also reducing sampling time. By compressing its input sequence into fewer embeddings, applying a temporal transformer, and expanding back using a spatial MaskGit, TECO outperforms existing models across many metrics. Videos are available on the website: https://wilson1yan.github.io/teco

**摘要:** 为了生成准确的视频,算法必须了解世界上的空间和时间依赖性。当前的算法能够在短时间内准确预测,但往往会发生时间不一致。当生成的视频内容被删除并被重新检视时,该模型则发明了不同的内容。尽管存在这种严重限制,但没有建立的标准为视频生成具有长期的依赖性。通过压缩其输入序列到较少的嵌入件,应用时空变换器,并使用空间 MaskGit重新扩展,TECO在许多 metrics上超过现有模型。视频可于网站: https://wilson1yan.github.io/teco

**[Paper URL](https://proceedings.mlr.press/v202/yan23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yan23b/yan23b.pdf)** 

# Distortion and Uncertainty Aware Loss for Panoramic Depth Completion
**题目:** 扭曲和不确定性意识的损失对泛观深度的完成

**作者:** Zhiqiang Yan, Xiang Li, Kun Wang, Shuo Chen, Jun Li, Jian Yang

**Abstract:** Standard MSE or MAE loss function is commonly used in limited field-of-vision depth completion, treating each pixel equally under a basic assumption that all pixels have same contribution during optimization. Recently, with the rapid rise of panoramic photography, panoramic depth completion (PDC) has raised increasing attention in 3D computer vision. However, the assumption is inapplicable to panoramic data due to its latitude-wise distortion and high uncertainty nearby textures and edges. To handle these challenges, we propose distortion and uncertainty aware loss (DUL) that consists of a distortion-aware loss and an uncertainty-aware loss. The distortion-aware loss is designed to tackle the panoramic distortion caused by equirectangular projection, whose coordinate transformation relation is used to adaptively calculate the weight of the latitude-wise distortion, distributing uneven importance instead of the equal treatment for each pixel. The uncertainty-aware loss is presented to handle the inaccuracy in non-smooth regions. Specifically, we characterize uncertainty into PDC solutions under Bayesian deep learning framework, where a novel consistent uncertainty estimation constraint is designed to learn the consistency between multiple uncertainty maps of a single panorama. This consistency constraint allows model to produce more precise uncertainty estimation that is robust to feature deformation. Extensive experiments show the superiority of our method over standard loss functions, reaching the state of the art.

**摘要:** 标准MSE或MAE损失函数通常用于有限视域深度完成,处理每个像素均匀,根据基本假设,所有像素在优化过程中都有相同的贡献。最近,随着光景摄影的迅速发展,光景深度完成(PDC)在3D计算机视觉中引起了越来越多的关注。然而,这个假设不适用于光景数据,因为它的纬度偏差和附近的纹理和边缘高度不确定。为了处理这些挑战,我们提出了变形和不确定意识损失(DUL),它由变形意识损失和不确定意识损失组成。本文以不确定意识损伤为对象,以处理非均匀区域的不准确性。具体而言,我们在贝叶斯深入学习框架下对不确定性进行了描述,设计了一种新的一致不确定估计约束,以学习单一视图的多个不确定地图之间的一致性。这种一致性约束使模型能够产生更准确的不确定估计,具有较强的特征变形特性。

**[Paper URL](https://proceedings.mlr.press/v202/yan23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yan23c/yan23c.pdf)** 

# Self-Interpretable Time Series Prediction with Counterfactual Explanations
**题目:** 自导时间序列预测与反事实解释

**作者:** Jingquan Yan, Hao Wang

**Abstract:** Interpretable time series prediction is crucial for safety-critical areas such as healthcare and autonomous driving. Most existing methods focus on interpreting predictions by assigning important scores to segments of time series. In this paper, we take a different and more challenging route and aim at developing a self-interpretable model, dubbed Counterfactual Time Series (CounTS), which generates counterfactual and actionable explanations for time series predictions. Specifically, we formalize the problem of time series counterfactual explanations, establish associated evaluation protocols, and propose a variational Bayesian deep learning model equipped with counterfactual inference capability of time series abduction, action, and prediction. Compared with state-of-the-art baselines, our self-interpretable model can generate better counterfactual explanations while maintaining comparable prediction accuracy.

**摘要:** 解释性时间序列预测对于安全关键领域,如医疗和自主驾驶,是至关重要的。目前的大多数方法集中于对时间序列部分分配重要分数来解释预测。本文采用不同的、更具有挑战性的路径,旨在开发一种自解释性模型,称为反事实时间序列(CounTS),它为时间序列预测生成反事实和可采取行动的解释。具体而言,我们对时间序列反事实解释问题进行了形式化,建立了相关评价协议,并提出了一种具有反事实推导能力、反行为和预测的变性贝叶斯深层学习模型。

**[Paper URL](https://proceedings.mlr.press/v202/yan23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yan23d/yan23d.pdf)** 

# Quantum 3D Graph Learning with Applications to Molecule Embedding
**题目:** 分子嵌入的量子3D图形学习

**作者:** Ge Yan, Huaijin Wu, Junchi Yan

**Abstract:** Learning 3D graph with spatial position as well as node attributes has been recently actively studied, for its utility in different applications e.g. 3D molecules. Quantum computing is known a promising direction for its potential theoretical supremacy for large-scale graph and combinatorial problem as well as the increasing evidence for the availability to physical quantum devices in the near term. In this paper, for the first time to our best knowledge, we propose a quantum 3D embedding ansatz that learns the latent representation of 3D structures from the Hilbert space composed of the Bloch sphere of each qubit. Specifically, the 3D Cartesian coordinates of nodes are converted into rotation and torsion angles and then encode them into the form of qubits. Moreover, Parameterized Quantum Circuit (PQC) is applied to serve as the trainable layers and the output of the PQC is adopted as the final node embedding. Experimental results on two downstream tasks, molecular property prediction and 3D molecular geometries generation, demonstrate the effectiveness of our model. We show the capacity and capability of our model with the evaluation on the QM9 dataset (134k molecules) with very few parameters, and its potential to be executed on a real quantum device.

**摘要:** 研究了具有空间位置和节点属性的3D图形,并对其在不同应用中的应用进行了积极研究,例如3D分子。量子计算在大规模图形和组合问题中具有潜在的理论优势,同时也在短期内对物理量子设备的可用性有日益增加的证据。本文首次提出一种量子3D嵌入法,它从各量子球体的布洛克球体组成的希尔伯特空间中学习三维结构的隐形表示。具体而言,节点的3D Cartesian坐标转换为旋转和扭转角,然后将其编码成量子球体。两项下游任务,分子性质预测和3D分子几何生成的实验结果,证明了模型的有效性。我们通过对极少数参数的QM9数据集(134k分子)的评价,证明了模型的能力和在实际量子器件上执行的潜力。

**[Paper URL](https://proceedings.mlr.press/v202/yan23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yan23e/yan23e.pdf)** 

# Fast Rates in Time-Varying Strongly Monotone Games
**题目:** 快速时间变化强的单调游戏

**作者:** Yu-Hu Yan, Peng Zhao, Zhi-Hua Zhou

**Abstract:** Multi-player online games depict the interaction of multiple players with each other over time. Strongly monotone games are of particular interest since they have benign properties and also relate to many classic games that have applications in real life. Existing works mainly focus on the time-invariant case with provable guarantees established. However, the research of the more general time-varying games in changing environments is underexplored and the best-known result cannot match the guarantees in the time-invariant case. In this work, we present a new decentralized online algorithm for time-varying strongly monotone games, which greatly improves existing results and obtains fast rates, matching the best time-invariant guarantee without knowing the environmental non-stationarity. Furthermore, to achieve faster rates, we generalize the RVU property with smoothness and establish a series of problem-dependent bounds that also match the best time-invariant one. To realize all those results, we make a comprehensive use of the techniques in non-stationary and universal online learning.

**摘要:** 单调游戏具有良好的特性,也与许多经典游戏有实际应用。现有的工作主要集中在具有可证明的保证的 Time-invariant 案例上。然而,在变化环境中对更普遍的 Time-invariant 游戏的研究还未得到深入研究,而最著名的结果不能与 Time-invariant 案例的保证相符。在这个工作中,我们提出了一种新的分散式在线算法,用于 Time-varying strongly monotone 游戏,大大改善现有的结果,并获得快速的速度,同时不了解环境非静态性,从而达到最佳 Time-invariant 保证。为了实现所有这些结果,我们全面利用非静态和通用的在线学习技术。

**[Paper URL](https://proceedings.mlr.press/v202/yan23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yan23f/yan23f.pdf)** 

# Proper Scoring Rules for Survival Analysis
**题目:** 生存分析的正确评分规则

**作者:** Hiroki Yanagisawa

**Abstract:** Survival analysis is the problem of estimating probability distributions for future event times, which can be seen as a problem in uncertainty quantification. Although there are fundamental theories on strictly proper scoring rules for uncertainty quantification, little is known about those for survival analysis. In this paper, we investigate extensions of four major strictly proper scoring rules for survival analysis and we prove that these extensions are proper under certain conditions, which arise from the discretization of the estimation of probability distributions. We also compare the estimation performances of these extended scoring rules by using real datasets, and the extensions of the logarithmic score and the Brier score performed the best.

**摘要:** 生存分析是预测未来事件时间的概率分布问题,它可以被视为不确定性定量问题。虽然存在严格正确的评分规则的基本理论,但是对于生存分析的理论却很少,本文研究了四个主要严格正确的评分规则的扩展,并证明这些扩展在某些条件下是正确的,这些扩展是由于估计概率分布的离散而产生的。

**[Paper URL](https://proceedings.mlr.press/v202/yanagisawa23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yanagisawa23a/yanagisawa23a.pdf)** 

# Behavior Contrastive Learning for Unsupervised Skill Discovery
**题目:** 非监督技能发现行为对比学习

**作者:** Rushuai Yang, Chenjia Bai, Hongyi Guo, Siyuan Li, Bin Zhao, Zhen Wang, Peng Liu, Xuelong Li

**Abstract:** In reinforcement learning, unsupervised skill discovery aims to learn diverse skills without extrinsic rewards. Previous methods discover skills by maximizing the mutual information (MI) between states and skills. However, such an MI objective tends to learn simple and static skills and may hinder exploration. In this paper, we propose a novel unsupervised skill discovery method through contrastive learning among behaviors, which makes the agent produce similar behaviors for the same skill and diverse behaviors for different skills. Under mild assumptions, our objective maximizes the MI between different behaviors based on the same skill, which serves as an upper bound of the previous MI objective. Meanwhile, our method implicitly increases the state entropy to obtain better state coverage. We evaluate our method on challenging mazes and continuous control tasks. The results show that our method generates diverse and far-reaching skills, and also obtains competitive performance in downstream tasks compared to the state-of-the-art methods.

**摘要:** 在强化学习中,无监督技能发现的目标是学习不同技能,而无外部奖励。以前的方法通过最大化状态和技能之间的相互信息来发现技能。然而,这种 MI目标倾向于学习简单和静态技能,并可能阻碍探索。本文提出了一种新的无监督技能发现方法,通过行为间的对比学习,使代理人为相同的技能产生类似行为和不同的技能产生不同的行为。结果表明,我们的方法能产生多种多样的、深远的技能,同时在下游任务中获得较先进的方法的竞争性表现。

**[Paper URL](https://proceedings.mlr.press/v202/yang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23a/yang23a.pdf)** 

# Nested Elimination: A Simple Algorithm for Best-Item Identification From Choice-Based Feedback
**题目:** 嵌入式消除:基于选择反馈的最佳对象识别的简单算法

**作者:** Junwen Yang, Yifan Feng

**Abstract:** We study the problem of best-item identification from choice-based feedback. In this problem, a company sequentially and adaptively shows display sets to a population of customers and collects their choices. The objective is to identify the most preferred item with the least number of samples and at a high confidence level. We propose an elimination-based algorithm, namely Nested Elimination (NE), which is inspired by the nested structure implied by the information-theoretic lower bound. NE is simple in structure, easy to implement, and has a strong theoretical guarantee for sample complexity. Specifically, NE utilizes an innovative elimination criterion and circumvents the need to solve any complex combinatorial optimization problem. We provide an instance-specific and non-asymptotic bound on the expected sample complexity of NE. We also show NE achieves high-order worst-case asymptotic optimality. Finally, numerical experiments from both synthetic and real data corroborate our theoretical findings.

**摘要:** 我们研究了基于选择反馈的最优项目识别问题。在这个问题中,一个公司连续地和适应性地向客户群显示设置,并收集他们的选择。目标是以最少的样品和高信任水平识别最优先项目。我们提出了基于消除的算法,即嵌入消除(NE),该算法由信息理论下界所暗示的嵌入结构所灵感。NE结构简单,易于实现,具有强有力的样品复杂性理论保证。具体而言,NE利用创新的消除标准,避免解决任何复杂组合优化问题的必要性。最后,从合成数据和实际数据的数值实验证实了我们的理论发现。

**[Paper URL](https://proceedings.mlr.press/v202/yang23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23b/yang23b.pdf)** 

# Towards Better Graph Representation Learning with Parameterized Decomposition & Filtering
**题目:** 基于参数化分解和滤波的更好的图表表示学习

**作者:** Mingqi Yang, Wenjie Feng, Yanming Shen, Bryan Hooi

**Abstract:** Proposing an effective and flexible matrix to represent a graph is a fundamental challenge that has been explored from multiple perspectives, e.g., filtering in Graph Fourier Transforms. In this work, we develop a novel and general framework which unifies many existing GNN models from the view of parameterized decomposition and filtering, and show how it helps to enhance the flexibility of GNNs while alleviating the smoothness and amplification issues of existing models. Essentially, we show that the extensively studied spectral graph convolutions with learnable polynomial filters are constrained variants of this formulation, and releasing these constraints enables our model to express the desired decomposition and filtering simultaneously. Based on this generalized framework, we develop models that are simple in implementation but achieve significant improvements and computational efficiency on a variety of graph learning tasks. Code is available at https://github.com/qslim/PDF.

**摘要:** 提出一种有效的和灵活的矩阵来代表图形是一个从多个角度研究的根本挑战,例如,在图形傅立叶变换中进行滤波。在这个工作中,我们开发了一个新颖的通用框架,从参数化分解和滤波的视角统一了许多现有的GNN模型,并展示它如何帮助提高GNN的灵活性,同时减轻现有模型的平滑性和放大问题。

**[Paper URL](https://proceedings.mlr.press/v202/yang23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23c/yang23c.pdf)** 

# Weighted Flow Diffusion for Local Graph Clustering with Node Attributes: an Algorithm and Statistical Guarantees
**题目:** 基于节点属性的局部图集权重流扩散:算法和统计保证

**作者:** Shenghao Yang, Kimon Fountoulakis

**Abstract:** Local graph clustering methods aim to detect small clusters in very large graphs without the need to process the whole graph. They are fundamental and scalable tools for a wide range of tasks such as local community detection, node ranking and node embedding. While prior work on local graph clustering mainly focuses on graphs without node attributes, modern real-world graph datasets typically come with node attributes that provide valuable additional information. We present a simple local graph clustering algorithm for graphs with node attributes, based on the idea of diffusing mass locally in the graph while accounting for both structural and attribute proximities. Using high-dimensional concentration results, we provide statistical guarantees on the performance of the algorithm for the recovery of a target cluster with a single seed node. We give conditions under which a target cluster generated from a fairly general contextual random graph model, which includes both the stochastic block model and the planted cluster model as special cases, can be fully recovered with bounded false positives. Empirically, we validate all theoretical claims using synthetic data, and we show that incorporating node attributes leads to superior local clustering performances using real-world graph datasets.

**摘要:** 本地图集的方法旨在在非常大的图中检测小类群,而不需要处理整个图。它们是用于广泛的任务,例如本地社区检测、节点排名和节点嵌入的基本和可扩展工具。在本地图集的工作主要集中在没有节点属性的图中,现代现实世界图数据集通常带有节点属性,提供有价值的额外信息。我们提出了一个简单的基于节点属性的图的本地图集算法,基于在图中局部扩散质量的想法,同时考虑到结构和属性的近距离。我们给出了从一个相对一般的上下文随机图模型中生成的目标群,包括随机块模型和种群模型作为特殊案例,可以完全用有限的错误正值恢复的条件。

**[Paper URL](https://proceedings.mlr.press/v202/yang23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23d/yang23d.pdf)** 

# Chemically Transferable Generative Backmapping of Coarse-Grained Proteins
**题目:** 粗粒蛋白的化学转移性生成后置映射

**作者:** Soojung Yang, Rafael Gomez-Bombarelli

**Abstract:** Coarse-graining (CG) accelerates molecular simulations of protein dynamics by simulating sets of atoms as singular beads. Backmapping is the opposite operation of bringing lost atomistic details back from the CG representation. While machine learning (ML) has produced accurate and efficient CG simulations of proteins, fast and reliable backmapping remains a challenge. Rule-based methods produce poor all-atom geometries, needing computationally costly refinement through additional simulations. Recently proposed ML approaches outperform traditional baselines but are not transferable between proteins and sometimes generate unphysical atom placements with steric clashes and implausible torsion angles. This work addresses both issues to build a fast, transferable, and reliable generative backmapping tool for CG protein representations. We achieve generalization and reliability through a combined set of innovations: representation based on internal coordinates; an equivariant encoder/prior; a custom loss function that helps ensure local structure, global structure, and physical constraints; and expert curation of high-quality out-of-equilibrium protein data for training. Our results pave the way for out-of-the-box backmapping of coarse-grained simulations for arbitrary proteins.

**摘要:** 粗粒化(英语:Coarse-graining)(CG)通过模拟原子集作为单一珠子来加速蛋白质动力学的分子模拟。后置映射是从CG表示中带回丢失的原子细节的相反操作。虽然机器学习(英语:Machine Learning)(ML)已经产生精确和高效的蛋白质CG模拟,快速和可靠的后置映射仍然是一个挑战。基于规则的方法产生不良的全原子几何,需要通过额外的仿真进行计算成本昂贵的精细。我们通过一种综合的创新,实现了广义化和可靠性:基于内部坐标的表示;一个等效编码器/前端;帮助确保局部结构、全球结构和物理约束的定制损失函数;以及训练用高质量的非平衡蛋白质数据的专家编译。

**[Paper URL](https://proceedings.mlr.press/v202/yang23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23e/yang23e.pdf)** 

# Data Poisoning Attacks Against Multimodal Encoders
**题目:** 对多模编码器的数据中毒攻击

**作者:** Ziqing Yang, Xinlei He, Zheng Li, Michael Backes, Mathias Humbert, Pascal Berrang, Yang Zhang

**Abstract:** Recently, the newly emerged multimodal models, which leverage both visual and linguistic modalities to train powerful encoders, have gained increasing attention. However, learning from a large-scale unlabeled dataset also exposes the model to the risk of potential poisoning attacks, whereby the adversary aims to perturb the model’s training data to trigger malicious behaviors in it. In contrast to previous work, only poisoning visual modality, in this work, we take the first step to studying poisoning attacks against multimodal models in both visual and linguistic modalities. Specially, we focus on answering two questions: (1) Is the linguistic modality also vulnerable to poisoning attacks? and (2) Which modality is most vulnerable? To answer the two questions, we propose three types of poisoning attacks against multimodal models. Extensive evaluations on different datasets and model architectures show that all three attacks can achieve significant attack performance while maintaining model utility in both visual and linguistic modalities. Furthermore, we observe that the poisoning effect differs between different modalities. To mitigate the attacks, we propose both pre-training and post-training defenses. We empirically show that both defenses can significantly reduce the attack performance while preserving the model’s utility. Our code is available at https://github.com/zqypku/mm_poison/.

**摘要:** 近年来,利用视觉和语言模式来训练强大的编码器的新型多模态模型得到了越来越多的关注,然而,从大规模无标签的数据集中学习也暴露了模型在潜在的毒害攻击的危险中,从而使对手的目标是扰乱模型的训练数据,从而引发恶意行为。与以前的工作相比,只有毒害视觉模式,在这个工作中,我们采取了研究在视觉和语言模式中对多模态模型的毒害攻击的第一步。对不同数据集和模型架构的广泛评价表明,所有三个攻击都能在视觉和语言模式中保持模型实用性的同时达到显著的攻击性能。此外,我们观察到毒性效应在不同的模式中有所不同。

**[Paper URL](https://proceedings.mlr.press/v202/yang23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23f/yang23f.pdf)** 

# Towards Sustainable Learning: Coresets for Data-efficient Deep Learning
**题目:** 走向可持续发展:基于数据的深度学习核心

**作者:** Yu Yang, Hao Kang, Baharan Mirzasoleiman

**Abstract:** To improve the efficiency and sustainability of learning deep models, we propose CREST, the first scalable framework with rigorous theoretical guarantees to identify the most valuable examples for training non-convex models, particularly deep networks. To guarantee convergence to a stationary point of a non-convex function, CREST models the non-convex loss as a series of quadratic functions and extracts a coreset for each quadratic sub-region. In addition, to ensure faster convergence of stochastic gradient methods such as (mini-batch) SGD, CREST iteratively extracts multiple mini-batch coresets from larger random subsets of training data, to ensure nearly-unbiased gradients with small variances. Finally, to further improve scalability and efficiency, CREST identifies and excludes the examples that are learned from the coreset selection pipeline. Our extensive experiments on several deep networks trained on vision and NLP datasets, including CIFAR-10, CIFAR-100, TinyImageNet, and SNLI, confirm that CREST speeds up training deep networks on very large datasets, by 1.7x to 2.5x with minimum loss in the performance. By analyzing the learning difficulty of the subsets selected by CREST, we show that deep models benefit the most by learning from subsets of increasing difficulty levels.

**摘要:** 为了提高学习深层模型的效率和持续性,我们提出了第一个具有严格理论保障的可扩展框架CREST,以识别非凸模型,特别是深层网络的最有价值的实例。为了保证对非凸函数的静止点的收敛性,CREST模型将非凸损失作为一系列的二次函数,并提取每个二次子区域的核子集。此外,为了确保(小批量)SGD等随机梯度方法的更快收敛性,CREST迭代提取多个小批量核子集从较大的随机训练数据子集中,以确保几乎不偏向的梯度和小变量。最后,为了进一步提高可扩展性和效率,CREST识别并排除从核子集选择管道中学习的实例。我们对包括CIFAR-10、CIFAR-100、TinyImageNet和SNLI在内的视觉和NLP数据集训练的多个深层网络进行了广泛的实验,证实CREST能够在非常大的数据集上加速训练深层网络,达到1.7至2.5倍,减少性能损失。

**[Paper URL](https://proceedings.mlr.press/v202/yang23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23g/yang23g.pdf)** 

# Improving Adversarial Robustness by Putting More Regularizations on Less Robust Samples
**题目:** 通过对较少可靠的样品进行更多监管,提高敌方的鲁棒性

**作者:** Dongyoon Yang, Insung Kong, Yongdai Kim

**Abstract:** Adversarial training, which is to enhance robustness against adversarial attacks, has received much attention because it is easy to generate human-imperceptible perturbations of data to deceive a given deep neural network. In this paper, we propose a new adversarial training algorithm that is theoretically well motivated and empirically superior to other existing algorithms. A novel feature of the proposed algorithm is to apply more regularization to data vulnerable to adversarial attacks than other existing regularization algorithms do. Theoretically, we show that our algorithm can be understood as an algorithm of minimizing a newly derived upper bound of the robust risk. Numerical experiments illustrate that our proposed algorithm improves the generalization (accuracy on examples) and robustness (accuracy on adversarial attacks) simultaneously to achieve the state-of-the-art performance.

**摘要:** 针对敌对攻击的鲁棒性增强的敌对训练得到了广泛的关注,因为它很容易产生无法人察觉的数据扰动来欺骗给定的深层神经网络。本文提出了一种新的敌对训练算法,其理论上具有良好的动机和经验上优于其他现有的算法。

**[Paper URL](https://proceedings.mlr.press/v202/yang23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23h/yang23h.pdf)** 

# Improving Adversarial Robustness of Deep Equilibrium Models with Explicit Regulations Along the Neural Dynamics
**题目:** 神经动力学中 Deep Equilibrium模型的敌对鲁棒性提高

**作者:** Zonghan Yang, Peng Li, Tianyu Pang, Yang Liu

**Abstract:** Deep equilibrium (DEQ) models replace the multiple-layer stacking of conventional deep networks with a fixed-point iteration of a single-layer transformation. Having been demonstrated to be competitive in a variety of real-world scenarios, the adversarial robustness of general DEQs becomes increasingly crucial for their reliable deployment. Existing works improve the robustness of general DEQ models with the widely-used adversarial training (AT) framework, but they fail to exploit the structural uniquenesses of DEQ models. To this end, we interpret DEQs through the lens of neural dynamics and find that AT under-regulates intermediate states. Besides, the intermediate states typically provide predictions with a high prediction entropy. Informed by the correlation between the entropy of dynamical systems and their stability properties, we propose reducing prediction entropy by progressively updating inputs along the neural dynamics. During AT, we also utilize random intermediate states to compute the loss function. Our methods regulate the neural dynamics of DEQ models in this manner. Extensive experiments demonstrate that our methods substantially increase the robustness of DEQ models and even outperform the strong deep network baselines.

**摘要:** 深度均衡(DEQ)模型以单层变换的固定点迭代取代传统的深层网络的多层堆栈。由于在各种现实场景中被证明具有竞争性,一般DEQ的敌对鲁棒性对于它们的可靠部署变得越来越关键。现有的工作通过广泛使用的敌对训练(AT)框架改进一般DEQ模型的鲁棒性,但它们无法利用DEQ模型的结构特异性。为此目的,我们通过神经动力学的透镜解释DEQ,发现AT不足调节中间状态。此外,中间状态通常提供高预测熵的预测。在AT中,我们还利用随机中间状态来计算损失函数。我们的方法以这种方式调节DEQ模型的神经动力学。广泛的实验表明,我们的方法大大提高了DEQ模型的鲁棒性,甚至超过了强的深网基线。

**[Paper URL](https://proceedings.mlr.press/v202/yang23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23i/yang23i.pdf)** 

# Mitigating Spurious Correlations in Multi-modal Models during Fine-tuning
**题目:** 微调过程中多模模型的痕量相关性减轻

**作者:** Yu Yang, Besmira Nushi, Hamid Palangi, Baharan Mirzasoleiman

**Abstract:** Spurious correlations that degrade model generalization or lead the model to be right for the wrong reasons are one of the main robustness concerns for real-world deployments. However, mitigating these correlations during pre-training for large-scale models can be costly and impractical, particularly for those without access to high-performance computing resources. This paper proposes a novel approach to address spurious correlations during fine-tuning for a given domain of interest. With a focus on multi-modal models (e.g., CLIP), the proposed method leverages different modalities in these models to detect and explicitly set apart spurious attributes from the affected class, achieved through a multi-modal contrastive loss function that expresses spurious relationships through language. Our experimental results and in-depth visualizations on CLIP show that such an intervention can effectively i) improve the model’s accuracy when spurious attributes are not present, and ii) directs the model’s activation maps towards the actual class rather than the spurious attribute when present. In particular, on the Waterbirds dataset, our algorithm achieved a worst-group accuracy 23% higher than ERM on CLIP with a ResNet-50 backbone, and 32% higher on CLIP with a ViT backbone, while maintaining the same average accuracy as ERM.

**摘要:** 影响模型一般化或导致模型正确的原因的误差相关性是现实部署的主要鲁棒性问题之一。然而,在大规模模型的预训练中减轻这些相关性,尤其对于那些没有获得高性能计算资源的模型来说,是昂贵和不实用的。本文提出了一种新的解决误差相关性的方法,在给定的兴趣领域进行微调时。我们的实验结果和对CLIP进行深入的可视化表明,这种干预可以有效地(i)提高模型在没有假属性时的准确性,以及(ii)将模型的激活映射指向实际类而不是在存在时的假属性。

**[Paper URL](https://proceedings.mlr.press/v202/yang23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23j/yang23j.pdf)** 

# A theory of representation learning gives a deep generalisation of kernel methods
**题目:** 表示学习理论对核方法进行了深入的一般化

**作者:** Adam X. Yang, Maxime Robeyns, Edward Milsom, Ben Anson, Nandi Schoots, Laurence Aitchison

**Abstract:** The successes of modern deep machine learning methods are founded on their ability to transform inputs across multiple layers to build good high-level representations. It is therefore critical to understand this process of representation learning. However, standard theoretical approaches (formally NNGPs) involving infinite width limits eliminate representation learning. We therefore develop a new infinite width limit, the Bayesian representation learning limit, that exhibits representation learning mirroring that in finite-width models, yet at the same time, retains some of the simplicity of standard infinite-width limits. In particular, we show that Deep Gaussian processes (DGPs) in the Bayesian representation learning limit have exactly multivariate Gaussian posteriors, and the posterior covariances can be obtained by optimizing an interpretable objective combining a log-likelihood to improve performance with a series of KL-divergences which keep the posteriors close to the prior. We confirm these results experimentally in wide but finite DGPs. Next, we introduce the possibility of using this limit and objective as a flexible, deep generalisation of kernel methods, that we call deep kernel machines (DKMs). Like most naive kernel methods, DKMs scale cubically in the number of datapoints. We therefore use methods from the Gaussian process inducing point literature to develop a sparse DKM that scales linearly in the number of datapoints. Finally, we extend these approaches to NNs (which have non-Gaussian posteriors) in the Appendices.

**摘要:** 现代深层机器学习方法的成功建立在其在多个层间转换输入的能力上,以构建高层次的良好表现。因此,理解这种表现学习的过程至关重要。然而,涉及无限宽限的标准理论方法(正式的NNGP)消除了表现学习。因此,我们开发了一个新的无限宽限,贝叶斯表现学习限制,展示了在有限宽限模型中表现学习的镜像,但同时保留了标准无限宽限的某些简单性。我们通过实验验证了这些结果在宽但有限的DGP中。接下来,我们引入了使用这个限度和目标的可能,作为一种灵活的、深入的核方法的一般化,我们称之为深核机器(DKMs)。

**[Paper URL](https://proceedings.mlr.press/v202/yang23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23k/yang23k.pdf)** 

# Efficient Algorithms for Exact Graph Matching on Correlated Stochastic Block Models with Constant Correlation
**题目:** 定相关随机块模型的精确图匹配的有效算法

**作者:** Joonhyuk Yang, Dongpil Shin, Hye Won Chung

**Abstract:** We consider the problem of graph matching, or learning vertex correspondence, between two correlated stochastic block models (SBMs). The graph matching problem arises in various fields, including computer vision, natural language processing and bioinformatics, and in particular, matching graphs with inherent community structure has significance related to de-anonymization of correlated social networks. Compared to the correlated Erdos-Renyi (ER) model, where various efficient algorithms have been developed, among which a few algorithms have been proven to achieve the exact matching with constant edge correlation, no low-order polynomial algorithm has been known to achieve exact matching for the correlated SBMs with constant correlation. In this work, we propose an efficient algorithm for matching graphs with community structure, based on the comparison between partition trees rooted from each vertex, by extending the idea of Mao et al. (2021) to graphs with communities. The partition tree divides the large neighborhoods of each vertex into disjoint subsets using their edge statistics to different communities. Our algorithm is the first low-order polynomial-time algorithm achieving exact matching between two correlated SBMs with high probability in dense graphs.

**摘要:** 本文对两个相关随机块模型(SBM)之间的图形匹配问题进行了研究,包括计算机视觉、自然语言处理和生物信息学等各个领域出现的图形匹配问题,特别是与相关社会网络的非匿名化有关的关联社区结构的匹配问题。分区树将每个顶点的大型邻域分成不同的社区的边缘统计。我们的算法是第一个低阶多项式时间算法,实现了两个相连的SBM在密集图中具有很高的概率的精确匹配。

**[Paper URL](https://proceedings.mlr.press/v202/yang23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23l/yang23l.pdf)** 

# Are Neurons Actually Collapsed? On the Fine-Grained Structure in Neural Representations
**题目:** 神经元是否真的崩溃?神经元表现的细微结构

**作者:** Yongyi Yang, Jacob Steinhardt, Wei Hu

**Abstract:** Recent work has observed an intriguing "Neural Collapse” phenomenon in well-trained neural networks, where the last-layer representations of training samples with the same label collapse into each other. This appears to suggest that the last-layer representations are completely determined by the labels, and do not depend on the intrinsic structure of input distribution. We provide evidence that this is not a complete description, and that the apparent collapse hides important fine-grained structure in the representations. Specifically, even when representations apparently collapse, the small amount of remaining variation can still faithfully and accurately captures the intrinsic structure of input distribution. As an example, if we train on CIFAR-10 using only 5 coarse-grained labels (by combining two classes into one super-class) until convergence, we can reconstruct the original 10-class labels from the learned representations via unsupervised clustering. The reconstructed labels achieve 93% accuracy on the CIFAR-10 test set, nearly matching the normal CIFAR-10 accuracy for the same architecture. We also provide an initial theoretical result showing the fine-grained representation structure in a simplified synthetic setting. Our results show concretely how the structure of input data can play a significant role in determining the fine-grained structure of neural representations, going beyond what Neural Collapse predicts.

**摘要:** 近期的研究发现,在训练良好的神经网络中,具有相同的标签的训练样品的最后层表示会相互折叠,这表明最后层表示完全由标签决定,并不依赖输入分布的内在结构。我们提供了证据表明,这不是完全的描述,而且明显的折叠在表示中隐藏着重要的细粒结构。具体地说,即使表示明显折叠,仍然可以忠实准确地捕捉输入分布的内在结构。重建的标签在CIFAR-10测试集中达到了93%的精度,几乎与同一架构的正常CIFAR-10精度相匹配。我们还提供了一个简化合成设置中显示细粒度表示结构的初始理论结果。我们的结果具体显示了输入数据的结构在确定神经表示细粒度结构方面能发挥重要作用,超越神经崩溃预测的范围。

**[Paper URL](https://proceedings.mlr.press/v202/yang23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23m/yang23m.pdf)** 

# Generative Adversarial Symmetry Discovery
**题目:**  Generative Adversarial Symmetry Discovery

**作者:** Jianke Yang, Robin Walters, Nima Dehmamy, Rose Yu

**Abstract:** Despite the success of equivariant neural networks in scientific applications, they require knowing the symmetry group a priori. However, it may be difficult to know which symmetry to use as an inductive bias in practice. Enforcing the wrong symmetry could even hurt the performance. In this paper, we propose a framework, LieGAN, to automatically discover equivariances from a dataset using a paradigm akin to generative adversarial training. Specifically, a generator learns a group of transformations applied to the data, which preserve the original distribution and fool the discriminator. LieGAN represents symmetry as interpretable Lie algebra basis and can discover various symmetries such as the rotation group $\mathrm{SO}(n)$, restricted Lorentz group $\mathrm{SO}(1,3)^+$ in trajectory prediction and top-quark tagging tasks. The learned symmetry can also be readily used in several existing equivariant neural networks to improve accuracy and generalization in prediction.

**摘要:** 尽管在科学应用中均匀性神经网络取得了成功,但它们需要先知对称群。然而,很难知道在实践中使用哪种对称作为诱导偏差。执行错误的对称甚至会损害性能。我们提出了一个框架,LieGAN,自动从数据集中发现均匀性,使用类似于生成敌对训练的范式。具体地说,一个发电机学习了对数据应用的变换群,这些变换保存了原始分布并欺骗了鉴别器。

**[Paper URL](https://proceedings.mlr.press/v202/yang23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23n/yang23n.pdf)** 

# Boosting Offline Reinforcement Learning with Action Preference Query
**题目:** 利用行动优先查询促进 offline增强学习

**作者:** Qisen Yang, Shenzhi Wang, Matthieu Gaetan Lin, Shiji Song, Gao Huang

**Abstract:** Training practical agents usually involve offline and online reinforcement learning (RL) to balance the policy’s performance and interaction costs. In particular, online fine-tuning has become a commonly used method to correct the erroneous estimates of out-of-distribution data learned in the offline training phase. However, even limited online interactions can be inaccessible or catastrophic for high-stake scenarios like healthcare and autonomous driving. In this work, we introduce an interaction-free training scheme dubbed Offline-with-Action-Preferences (OAP). The main insight is that, compared to online fine-tuning, querying the preferences between pre-collected and learned actions can be equally or even more helpful to the erroneous estimate problem. By adaptively encouraging or suppressing policy constraint according to action preferences, OAP could distinguish overestimation from beneficial policy improvement and thus attains a more accurate evaluation of unseen data. Theoretically, we prove a lower bound of the behavior policy’s performance improvement brought by OAP. Moreover, comprehensive experiments on the D4RL benchmark and state-of-the-art algorithms demonstrate that OAP yields higher (29% on average) scores, especially on challenging AntMaze tasks (98% higher).

**摘要:** 培训的实际代理人通常涉及在线和在线强化学习(RL)以平衡政策的性能和交互成本。特别是,在线微调已成为在在线培训阶段学习的外发数据误差估计的常用方法。然而,甚至有限的在线交互也可能是无法访问或致命的,如医疗和自主驾驶等高风险场景。在这个工作中,我们引入了无交互培训计划,称为Offline-with-Action-Preferences(OAP)。理论上,我们证明了OAP带来的行为政策性能改善的较低边界。 此外,D4RL基准和最先进的算法的综合实验表明,OAP的得分较高(平均29%),特别是在挑战AntMaze任务(98%)上。

**[Paper URL](https://proceedings.mlr.press/v202/yang23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23o/yang23o.pdf)** 

# Towards Controlled Data Augmentations for Active Learning
**题目:** 面向主动学习的控制数据增强

**作者:** Jianan Yang, Haobo Wang, Sai Wu, Gang Chen, Junbo Zhao

**Abstract:** The mission of active learning is to identify the most valuable data samples, thus attaining decent performance with much fewer samples. The data augmentation techniques seem straightforward yet promising to enhance active learning by extending the exploration of the input space, which helps locate more valuable samples. In this work, we thoroughly study the coupling of data augmentation and active learning, thereby proposing Controllable Augmentation ManiPulator for Active Learning. In contrast to the few prior works that touched on this line, CAMPAL emphasizes a purposeful, tighten, and better-controlled integration of data augmentation into active learning in three folds: (i)-carefully designed augmentation policies applied separately on labeled and unlabeled data pools; (ii)-controlled and quantifiably optimizable augmentation strengths; (iii)-full and flexible coverage for most (if not all) active learning schemes. Theories are proposed and associated with the development of key components in CAMPAL. Through extensive empirical experiments, we bring the performance of active learning methods to a new level: an absolute performance boost of 16.99% on CIFAR-10 and 12.25 on SVHN with 1,000 annotated samples. Codes are available at https://github.com/jnzju/CAMPAL.

**摘要:** 主动学习的任务是识别最有价值的数据样品,从而获得较少的样品的良好性能。数据增强技术看起来简单,但有望通过扩大输入空间的探索来增强主动学习,从而帮助找到更有价值的样品。在这项工作中,我们深入研究数据增强和主动学习的耦合,从而提议对主动学习的可控增强管理器。与在此线上涉及的少数以前的工作相比, CAMPAL强调在三个方面将数据增强纳入主动学习的有目的、紧缩和更好的控制集成: (i)仔细设计的增强政策分别应用于标记和未标记的数据池; (ii)控制和量化可优化的增强力量; (iii)对大多数(如果不是所有)主动学习计划的全面和灵活覆盖。通过广泛的实证实验,我们将主动学习方法的性能提升到一个新的水平:在CIFAR-10和SVHN中,绝对的性能提升为16.99%,并在1000个注释样本中提升为12.25。

**[Paper URL](https://proceedings.mlr.press/v202/yang23p.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23p/yang23p.pdf)** 

# What is Essential for Unseen Goal Generalization of Offline Goal-conditioned RL?
**题目:** 非线性目标条件RL的隐形目标推广是何必的?

**作者:** Rui Yang, Lin Yong, Xiaoteng Ma, Hao Hu, Chongjie Zhang, Tong Zhang

**Abstract:** Offline goal-conditioned RL (GCRL) offers a way to train general-purpose agents from fully offline datasets. In addition to being conservative within the dataset, the generalization ability to achieve unseen goals is another fundamental challenge for offline GCRL. However, to the best of our knowledge, this problem has not been well studied yet. In this paper, we study out-of-distribution (OOD) generalization of offline GCRL both theoretically and empirically to identify factors that are important. In a number of experiments, we observe that weighted imitation learning enjoys better generalization than pessimism-based offline RL method. Based on this insight, we derive a theory for OOD generalization, which characterizes several important design choices. We then propose a new offline GCRL method, Generalizable Offline goAl-condiTioned RL (GOAT), by combining the findings from our theoretical and empirical studies. On a new benchmark containing 9 independent identically distributed (IID) tasks and 17 OOD tasks, GOAT outperforms current state-of-the-art methods by a large margin.

**摘要:** 非线性目标条件化RL(GCRL)提供了从完全非线性数据集中训练一般目标代理的途径。除了在数据集内保持保守,实现非线性目标的一般化能力是非线性GCRL的另一个基本挑战。然而,对于我们的知识,这个问题还没有得到很好的研究。在新的基准中,包含了9个独立分布式(IID)任务和17个OOD任务,GOAT大大超过了当前最先进的方法。

**[Paper URL](https://proceedings.mlr.press/v202/yang23q.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23q/yang23q.pdf)** 

# Neural Prediction Errors enable Analogical Visual Reasoning in Human Standard Intelligence Tests
**题目:** 神经预测误差在人类标准智力测试中实现可视逻辑推理

**作者:** Lingxiao Yang, Hongzhi You, Zonglei Zhen, Dahui Wang, Xiaohong Wan, Xiaohua Xie, Ru-Yuan Zhang

**Abstract:** Deep neural networks have long been criticized for lacking the ability to perform analogical visual reasoning. Here, we propose a neural network model to solve Raven’s Progressive Matrices (RPM) - one of the standard intelligence tests in human psychology. Specifically, we design a reasoning block based on the well-known concept of prediction error (PE) in neuroscience. Our reasoning block uses convolution to extract abstract rules from high-level visual features of the 8 context images and generates the features of a predicted answer. PEs are then calculated between the predicted features and those of the 8 candidate answers, and are then passed to the next stage. We further integrate our novel reasoning blocks into a residual network and build a new Predictive Reasoning Network (PredRNet). Extensive experiments show that our proposed PredRNet achieves state-of-the-art average performance on several important RPM benchmarks. PredRNet also shows good generalization abilities in a variety of out-of-distribution scenarios and other visual reasoning tasks. Most importantly, our PredRNet forms low-dimensional representations of abstract rules and minimizes hierarchical prediction errors during model training, supporting the critical role of PE minimization in visual reasoning. Our work highlights the potential of using neuroscience theories to solve abstract visual reasoning problems in artificial intelligence. The code is available at https://github.com/ZjjConan/AVR-PredRNet.

**摘要:** 深层神经网络长期以来因缺乏模拟视觉推理的能力而受到批评。这里,我们提出了一种神经网络模型来解决 Raven’s Progressive Matrices(RPM)——人类心理学中的标准智力测试之一。具体地说,我们设计了一个基于神经科学中的预测误差(PE)的概念的推理块。我们的推理块使用卷曲来从8个上下文图像的高层次视觉特征中提取抽象规则,并生成预测结果的特征。然后,PE在预测结果和8个候选结果之间进行计算,然后再通过下一阶段。我们进一步将新颖的推理块整合到剩余网络,并构建新的预测推理网络(PredRNet)。PredRNet还显示出在不同外分布场景和其它视觉推理任务中良好的一般化能力。最重要的是,我们的PredRNet形式是抽象规则的低维表示,并在模型训练中最小化层次推理错误,支持在视觉推理中PE最小化的关键作用。我们的工作突出了使用神经科学理论来解决人工智能中的抽象视觉推理问题的可能性。

**[Paper URL](https://proceedings.mlr.press/v202/yang23r.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23r/yang23r.pdf)** 

# Change is Hard: A Closer Look at Subpopulation Shift
**题目:** 改变是困难的:对次人口 Shift 进行更深入的观察

**作者:** Yuzhe Yang, Haoran Zhang, Dina Katabi, Marzyeh Ghassemi

**Abstract:** Machine learning models often perform poorly on subgroups that are underrepresented in the training data. Yet, little is understood on the variation in mechanisms that cause subpopulation shifts, and how algorithms generalize across such diverse shifts at scale. In this work, we provide a fine-grained analysis of subpopulation shift. We first propose a unified framework that dissects and explains common shifts in subgroups. We then establish a comprehensive benchmark of 20 state-of-the-art algorithms evaluated on 12 real-world datasets in vision, language, and healthcare domains. With results obtained from training over 10,000 models, we reveal intriguing observations for future progress in this space. First, existing algorithms only improve subgroup robustness over certain types of shifts but not others. Moreover, while current algorithms rely on group-annotated validation data for model selection, we find that a simple selection criterion based on worst-class accuracy is surprisingly effective even without any group information. Finally, unlike existing works that solely aim to improve worst-group accuracy (WGA), we demonstrate the fundamental tradeoff between WGA and other important metrics, highlighting the need to carefully choose testing metrics. Code and data are available at: https://github.com/YyzHarry/SubpopBench.

**摘要:** 机器学习模型往往在训练数据中不足表现的分组中表现不佳。然而,对于造成分组迁移的机制的变异和算法如何在规模上推广这些不同的迁移的理解甚少。在这项工作中,我们提供分组迁移的细微分析。我们首先提出一种统一的框架,它剖析和解释分组中常见的迁移。然后,我们建立了20个最先进的算法的综合基准,评估了视觉、语言和医疗领域中的12个真实世界数据集。此外,尽管当前的算法依赖于群注释验证数据来选择模型,但我们发现基于最差类精度的简单选择标准即使没有群信息,也具有惊人的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/yang23s.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23s/yang23s.pdf)** 

# Continual Task Allocation in Meta-Policy Network via Sparse Prompting
**题目:** 基于节余提示的Meta-Policy网络持续任务分配

**作者:** Yijun Yang, Tianyi Zhou, Jing Jiang, Guodong Long, Yuhui Shi

**Abstract:** How to train a generalizable meta-policy by continually learning a sequence of tasks? It is a natural human skill yet challenging to achieve by current reinforcement learning: the agent is expected to quickly adapt to new tasks (plasticity) meanwhile retaining the common knowledge from previous tasks (stability). We address it by "Continual Task Allocation via Sparse Prompting (CoTASP)", which learns over-complete dictionaries to produce sparse masks as prompts extracting a sub-network for each task from a meta-policy network. CoTASP trains a policy for each task by optimizing the prompts and the sub-network weights alternatively. The dictionary is then updated to align the optimized prompts with tasks’ embedding, thereby capturing tasks’ semantic correlations. Hence, relevant tasks share more neurons in the meta-policy network due to similar prompts while cross-task interference causing forgetting is effectively restrained. Given a meta-policy and dictionaries trained on previous tasks, new task adaptation reduces to highly efficient sparse prompting and sub-network finetuning. In experiments, CoTASP achieves a promising plasticity-stability trade-off without storing or replaying any past tasks’ experiences. It outperforms existing continual and multi-task RL methods on all seen tasks, forgetting reduction, and generalization to unseen tasks.

**摘要:** 如何通过不断学习任务序列来训练一个可推广的元策略? 这是一个自然的人类技能,但目前的强化学习仍难以实现:预期代理人会迅速适应新的任务(弹性),同时保持以前任务的共同知识(稳定性)。我们通过“通过节点提示的持续任务分配”(CoTASP)”来解决这个问题,它学习了从元策略网络中提取每个任务的子网络的提示,从而产生节点面 mask。CoTASP通过优化提示和子网络权重来训练每个任务的策略。通过对过去的任务进行训练的元策略和词典,新的任务适应性降低到高效的稀疏促动和分网络微调。在实验中,CoTASP在没有存储或重演任何过去的任务经验的情况下,实现了可塑性-稳定性的良好交换。它在所有已见任务中超越现有的连续和多任务RL方法,忘记减少和将未知任务推广到一般化。

**[Paper URL](https://proceedings.mlr.press/v202/yang23t.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23t/yang23t.pdf)** 

# Hyperbolic Representation Learning: Revisiting and Advancing
**题目:** 高分子表现学习:回顾和推进

**作者:** Menglin Yang, Min Zhou, Rex Ying, Yankai Chen, Irwin King

**Abstract:** The non-Euclidean geometry of hyperbolic spaces has recently garnered considerable attention in the realm of representation learning. Current endeavors in hyperbolic representation largely presuppose that the underlying hierarchies can be automatically inferred and preserved through the adaptive optimization process. This assumption, however, is questionable and requires further validation. In this work, we first introduce a position-tracking mechanism to scrutinize existing prevalent hyperbolic models, revealing that the learned representations are sub-optimal and unsatisfactory. To address this, we propose a simple yet effective method, hyperbolic informed embedding (HIE), by incorporating cost-free hierarchical information deduced from the hyperbolic distance of the node to the origin (i.e., induced hyperbolic norm) to advance existing hyperbolic models. The proposed method HIE is both task-agnostic and model-agnostic, enabling its seamless integration with a broad spectrum of models and tasks. Extensive experiments across various models and different tasks demonstrate the versatility and adaptability of the proposed method. Remarkably, our method achieves a remarkable improvement of up to 21.4% compared to the competing baselines.

**摘要:** 超线性空间的非欧几何学最近在表示学习领域引起了相当大的关注。目前的超线性表示的尝试大多假设下层层次可以通过适应优化过程自动推导和保存。然而,这一假设是值得怀疑的,需要进一步验证。在这个工作中,我们首先引入了一个位置追踪机制来对现有普遍的超线性模型进行检查,揭示了学习的表示是次优和不令人满意。所提议的方法是 task-agnostic 和 model-agnostic, 使它能够与广泛的模型和任务进行无缝的集成. 对各种模型和不同的任务进行广泛的实验证明了所提议的方法的多用途性和适应性. 值得注意的是,我们的方法在与竞争的基线相比,达到了最大21.4%的显著改进。

**[Paper URL](https://proceedings.mlr.press/v202/yang23u.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yang23u/yang23u.pdf)** 

# Which is Better for Learning with Noisy Labels: The Semi-supervised Method or Modeling Label Noise?
**题目:** 什么是用噪音标签学习的最好方法:半监督方法还是模板标签噪声?

**作者:** Yu Yao, Mingming Gong, Yuxuan Du, Jun Yu, Bo Han, Kun Zhang, Tongliang Liu

**Abstract:** In real life, accurately annotating large-scale datasets is sometimes difficult. Datasets used for training deep learning models are likely to contain label noise. To make use of the dataset containing label noise, two typical methods have been proposed. One is to employ the semi-supervised method by exploiting labeled confident examples and unlabeled unconfident examples. The other one is to model label noise and design statistically consistent classifiers. A natural question remains unsolved: which one should be used for a specific real-world application? In this paper, we answer the question from the perspective of causal data generative process. Specifically, the performance of the semi-supervised based method depends heavily on the data generative process while the method modeling label-noise is not influenced by the generation process. For example, for a given dataset, if it has a causal generative structure that the features cause the label, the semi-supervised based method would not be helpful. When the causal structure is unknown, we provide an intuitive method to discover the causal structure for a given dataset containing label noise.

**摘要:** 在现实生活中,准确注释大规模数据集有时是困难的。用于训练深层学习模型的数据集可能包含标签噪声。为了利用包含标签噪声的数据集,提出了两种典型的方法。一种是利用带有标签的自信实例和带有标签的不自信实例使用半监督方法。另一种是模拟标签噪声并设计统计上一致的分类器。一个自然问题仍未解决:该方法应用于具体的现实应用?本论文从因果数据生成过程的角度回答这个问题。例如,对于某一数据集,如果它具有因果生成结构,使得特征引起标签,半监督的基于方法并不会有帮助。当因果结构未知时,我们提供一种直观的方法来发现包含标签噪声的某一数据集的因果结构。

**[Paper URL](https://proceedings.mlr.press/v202/yao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yao23a/yao23a.pdf)** 

# How Bad is Top-$K$ Recommendation under Competing Content Creators?
**题目:** 在竞争性内容创造者下 Top-$K$ 的建议有多糟糕?

**作者:** Fan Yao, Chuanhao Li, Denis Nekipelov, Hongning Wang, Haifeng Xu

**Abstract:** This study explores the impact of content creators’ competition on user welfare in recommendation platforms, as well as the long-term dynamics of relevance-driven recommendations. We establish a model of creator competition, under the setting where the platform uses a top-$K$ recommendation policy, user decisions are guided by the Random Utility model, and creators, in absence of explicit utility functions, employ arbitrary no-regret learning algorithms for strategy updates. We study the user welfare guarantee through the lens of Price of Anarchy and show that the fraction of user welfare loss due to creator competition is always upper bounded by a small constant depending on $K$ and randomness in user decisions; we also prove the tightness of this bound. Our result discloses an intrinsic merit of the relevance-driven recommendation policy, as long as users’ decisions involve randomness and the platform provides reasonably many alternatives to its users.

**摘要:** 本研究探讨了内容创造者竞争对推荐平台的用户福利的影响,以及相关性驱动建议的长期动态。我们建立了创建者竞争的模型,在平台使用顶部$K$推荐政策的设置下,用户决策由随机实用模型指导,而创造者在没有明确实用功能的情况下,使用随机无悔学习算法进行策略更新。我们通过 Anarchy Price的视角研究了用户福利保障,并证明由于创造者竞争造成的用户福利损失的比重总是由$K$和用户决策中的随机性 پورې اړه的小常数限制;我们还证明了这一约束的紧迫性。

**[Paper URL](https://proceedings.mlr.press/v202/yao23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yao23b/yao23b.pdf)** 

# MultiAdam: Parameter-wise Scale-invariant Optimizer for Multiscale Training of Physics-informed Neural Networks
**题目:** 多亚当:基于参数的多尺度神经网络多尺度训练的尺度不变优化器

**作者:** Jiachen Yao, Chang Su, Zhongkai Hao, Songming Liu, Hang Su, Jun Zhu

**Abstract:** Physics-informed Neural Networks (PINNs) have recently achieved remarkable progress in solving Partial Differential Equations (PDEs) in various fields by minimizing a weighted sum of PDE loss and boundary loss. However, there are several critical challenges in the training of PINNs, including the lack of theoretical frameworks and the imbalance between PDE loss and boundary loss. In this paper, we present an analysis of second-order non-homogeneous PDEs, which are classified into three categories and applicable to various common problems. We also characterize the connections between the training loss and actual error, guaranteeing convergence under mild conditions. The theoretical analysis inspires us to further propose MultiAdam, a scale-invariant optimizer that leverages gradient momentum to parameter-wisely balance the loss terms. Extensive experiment results on multiple problems from different physical domains demonstrate that our MultiAdam solver can improve the predictive accuracy by 1-2 orders of magnitude compared with strong baselines.

**摘要:** 物理信息神经网络(PINNs)最近通过最小化PDE损失和边界损失的权重总数,在解决部分差分方程(PDEs)方面取得了显著的进展。然而,在PINNs的训练中存在 several critical challenges, including the lack of theoretical frameworks and the imbalance between PDE loss and boundary loss。 本论文对二阶非均匀PDEs进行了分析,分为三类,适用于各种常见问题。对不同物理领域多个问题的广泛实验结果表明,我们的MultiAdam求解器能够比强的基线提高1-2级的预测精度。

**[Paper URL](https://proceedings.mlr.press/v202/yao23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yao23c/yao23c.pdf)** 

# Policy Mirror Ascent for Efficient and Independent Learning in Mean Field Games
**题目:** 政策镜子提升中场运动会有效独立学习

**作者:** Batuhan Yardim, Semih Cayci, Matthieu Geist, Niao He

**Abstract:** Mean-field games have been used as a theoretical tool to obtain an approximate Nash equilibrium for symmetric and anonymous $N$-player games. However, limiting applicability, existing theoretical results assume variations of a “population generative model”, which allows arbitrary modifications of the population distribution by the learning algorithm. Moreover, learning algorithms typically work on abstract simulators with population instead of the $N$-player game. Instead, we show that $N$ agents running policy mirror ascent converge to the Nash equilibrium of the regularized game within $\widetilde{\mathcal{O}}(\varepsilon^{-2})$ samples from a single sample trajectory without a population generative model, up to a standard $\mathcal{O}(\frac{1}{\sqrt{N}})$ error due to the mean field. Taking a divergent approach from the literature, instead of working with the best-response map we first show that a policy mirror ascent map can be used to construct a contractive operator having the Nash equilibrium as its fixed point. We analyze single-path TD learning for $N$-agent games, proving sample complexity guarantees by only using a sample path from the $N$-agent simulator without a population generative model. Furthermore, we demonstrate that our methodology allows for independent learning by $N$ agents with finite sample guarantees.

**摘要:** 中场游戏是获得对称和匿名$N$玩家游戏的近似纳什均衡的理论工具。然而,限制适用性,现有的理论结果假设“人口生成模型”的变异,允许学习算法任意修改人口分布。此外,学习算法通常在抽象模拟器上使用人口而不是$N$玩家游戏。通过从文献中采取不同的方法,首先证明一种政策镜像上升图可以用于构造一个具有纳什均衡为固定点的契约运算符,以代替使用最佳响应图。我们对$N$-代理游戏的单路径TD学习进行了分析,通过只使用$N$-代理模拟器的样品路径而证明样品复杂性保证,并无人口生成模型。

**[Paper URL](https://proceedings.mlr.press/v202/yardim23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yardim23a/yardim23a.pdf)** 

# Retrieval-Augmented Multimodal Language Modeling
**题目:** 检索增强多模态语言建模

**作者:** Michihiro Yasunaga, Armen Aghajanyan, Weijia Shi, Richard James, Jure Leskovec, Percy Liang, Mike Lewis, Luke Zettlemoyer, Wen-Tau Yih

**Abstract:** Recent multimodal models such as DALL-E and CM3 have achieved remarkable progress in text-to-image and image-to-text generation. However, these models store all their knowledge (e.g., the appearance of the Eiffel Tower) in the model parameters, requiring increasingly larger models and training data to capture more knowledge. To integrate knowledge in a more scalable and modular way, we propose a retrieval-augmented multimodal model, which enables a base multimodal model (generator) to refer to relevant text and images fetched by a retriever from external memory (e.g., documents on the web). Specifically, for the retriever, we use a pretrained CLIP, and for the generator, we train a CM3 Transformer on the LAION dataset. Our resulting model, named Retrieval-Augmented CM3 (RA-CM3), is the first multimodal model that can retrieve and generate both text and images. We show that RA-CM3 significantly outperforms baseline multimodal models such as DALL-E and CM3 on both image and caption generation tasks (12 FID and 17 CIDEr improvements on MS-COCO), while requiring much less compute for training ($<$30% of DALL-E). Moreover, we show that RA-CM3 exhibits novel capabilities such as faithful image generation and multimodal in-context learning (e.g., image generation from demonstrations).

**摘要:** 最近的多模模型如DALL-E和CM3在文本到图像和图像到文本生成方面取得了显著的进步。然而,这些模型在模型参数中存储了所有它们的知识(例如埃菲尔塔的外观),需要越来越大的模型和训练数据来捕捉更多的知识。为了在更可扩展和模块化的方式集成知识,我们提出了一种检索增强多模模型,它使一个基本多模模型(生成器)可从外部存储器(例如在网络上的文件)检索相关的文本和图像。我们表明,RA-CM3在图像和字幕生成任务中明显超过了DALL-E和CM3等基本多模模型(12FID和MS-COCO上的17CIDEr改进),同时需要较少的计算量(DALL-E的30%)。此外,我们显示RA-CM3显示出新的功能,如忠实的图像生成和多模上下文学习(例如,从演示中生成图像)。

**[Paper URL](https://proceedings.mlr.press/v202/yasunaga23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yasunaga23a/yasunaga23a.pdf)** 

# On the Power of Pre-training for Generalization in RL: Provable Benefits and Hardness
**题目:** 区域推广预培训的有效性:可提供效益和难度

**作者:** Haotian Ye, Xiaoyu Chen, Liwei Wang, Simon Shaolei Du

**Abstract:** Generalization in Reinforcement Learning (RL) aims to train an agent during training that generalizes to the target environment. In this work, we first point out that RL generalization is fundamentally different from the generalization in supervised learning, and fine-tuning on the target environment is necessary for good test performance. Therefore, we seek to answer the following question: how much can we expect pre-training over training environments to be helpful for efficient and effective fine-tuning? On one hand, we give a surprising result showing that asymptotically, the improvement from pre-training is at most a constant factor. On the other hand, we show that pre-training can be indeed helpful in the non-asymptotic regime by designing a policy collection-elimination (PCE) algorithm and proving a distribution-dependent regret bound that is independent of the state-action space. We hope our theoretical results can provide insight towards understanding pre-training and generalization in RL.

**摘要:** 强化学习的一般化(英语:Generalization in Reinforcement Learning,简称RL)旨在在训练过程中训练一个向目标环境推广的代理人。在这个工作中,我们首先指出RL的一般化与监督学习的一般化基本不同,对目标环境的微调对于良好测试性能是必要的。因此,我们试图回答以下问题:在训练环境上,我们能期望预训练对有效和有效的微调有何帮助?我们希望,我们的理论结果能为了解预训练和一般化RL提供洞察力。

**[Paper URL](https://proceedings.mlr.press/v202/ye23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ye23a/ye23a.pdf)** 

# Personalized Federated Learning with Inferred Collaboration Graphs
**题目:** 基于隐形协作图的个性化联邦学习

**作者:** Rui Ye, Zhenyang Ni, Fangzhao Wu, Siheng Chen, Yanfeng Wang

**Abstract:** Personalized federated learning (FL) aims to collaboratively train a personalized model for each client. Previous methods do not adaptively determine who to collaborate at a fine-grained level, making them difficult to handle diverse data heterogeneity levels and those cases where malicious clients exist. To address this issue, our core idea is to learn a collaboration graph, which models the benefits from each pairwise collaboration and allocates appropriate collaboration strengths. Based on this, we propose a novel personalized FL algorithm, pFedGraph, which consists of two key modules: (1) inferring the collaboration graph based on pairwise model similarity and dataset size at server to promote fine-grained collaboration and (2) optimizing local model with the assistance of aggregated model at client to promote personalization. The advantage of pFedGraph is flexibly adaptive to diverse data heterogeneity levels and model poisoning attacks, as the proposed collaboration graph always pushes each client to collaborate more with similar and beneficial clients. Extensive experiments show that pFedGraph consistently outperforms the other $14$ baseline methods across various heterogeneity levels and multiple cases where malicious clients exist. Code will be available at https://github.com/MediaBrain-SJTU/pFedGraph.

**摘要:** 个性化联合学习(英语:Personalized federated learning,缩写为FL)旨在共同训练每个客户端的个性化模型。以前的方法并不以适应性的方式决定在精细层次上谁进行协作,使得它们难以处理各种数据异质性水平和有恶意客户端的案例。为了解决这个问题,我们的核心思想是学习一个协作图,该图模拟每个双向协作的收益并分配适当的协作力量。基于此,我们提出了一种新颖的个性化FL算法,pFedGraph,它由两个关键模块组成:(一)基于服务器上的双向模型相似性和数据集大小推导的协作图,以促进精细层次的协作,(二)利用客户群模型协助优化本地模型,促进个性化。pFedGraph的优点是灵活地适应不同的数据异质性水平和模型中毒攻击,因为提议的协作图总是促使每个客户与相似和有益的客户进行更多的合作。

**[Paper URL](https://proceedings.mlr.press/v202/ye23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ye23b/ye23b.pdf)** 

# Compositional Exemplars for In-context Learning
**题目:** 构造学习实例

**作者:** Jiacheng Ye, Zhiyong Wu, Jiangtao Feng, Tao Yu, Lingpeng Kong

**Abstract:** Large pretrained language models (LMs) have shown impressive In-Context Learning (ICL) ability, where the model learns to do an unseen task simply by conditioning on a prompt consisting of input-output examples as demonstration, without any parameter updates. The performance of ICL is highly dominated by the quality of the selected in-context examples. However, previous selection methods are mostly based on simple heuristics, leading to sub-optimal performance. In this work, we systematically formulate in-context example selection as a subset selection problem, and optimize it in an end-to-end fashion. We propose CEIL (Compositional Exemplars for In-context Learning), which is instantiated by Determinantal Point Processes (DPPs) to model the interaction between the given input and in-context examples, and optimized through carefully-designed contrastive learning to obtain preference from LMs. We validate CEIL on 12 classification and generation datasets from 7 distinct NLP tasks, including sentiment analysis, phraphrase detection, natural language inference, commonsense reasoning, open-domain question answering, code generation and semantic parsing. Extensive experiments demonstrate the effectiveness, transferability, compositionality of CEIL, shedding new lights on in-context leaning. Our code is released at https://github.com/HKUNLP/icl-ceil.

**摘要:** 大型预制语言模型(LMs)显示出令人印象深刻的In-Context Learning(ICL)能力,该模型通过在参数更新的情况下,以输入输出实例为实例的提示为条件,以完成无视任务。ICL的性能受到选取的In-Context实例的质量的高度支配。然而,以前的选择方法大多基于简单的启发式,导致亚最佳性能。在这个工作中,我们系统地制订了In-Context实例选择作为子集选择问题,并以最终的方式优化它。我们提议CEIL(Compositional Exemplars for In-Context Learning),以确定点过程(DPPs)为实例,以模拟给定的输入与In-Context实例之间的相互作用,并通过精心设计的对比性学习来优化LMs的优越性。我们对12个不同NLP任务中的分类和生成数据集验证了CEIL,包括情绪分析、语句检测、自然语言推理、常识推理、开放域问题回答、代码生成和语义分析。广泛的实验证明CEIL的有效性、可转让性、组成性、在上下文 leaning上放出新的光线。我们的代码在 https://github.com/HKUNLP/icl-ceil 上发布。

**[Paper URL](https://proceedings.mlr.press/v202/ye23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ye23c/ye23c.pdf)** 

# Corruption-Robust Algorithms with Uncertainty Weighting for Nonlinear Contextual Bandits and Markov Decision Processes
**题目:** 非线性背景曲线和马可夫决策过程不确定权重的腐败-腐蚀算法

**作者:** Chenlu Ye, Wei Xiong, Quanquan Gu, Tong Zhang

**Abstract:** Despite the significant interest and progress in reinforcement learning (RL) problems with adversarial corruption, current works are either confined to the linear setting or lead to an undesired $\tilde{\mathcal O}(\sqrt{T}\zeta)$ regret bound, where $T$ is the number of rounds and $\zeta$ is the total amount of corruption. In this paper, we consider contextual bandits with general function approximation and propose a computationally efficient algorithm to achieve a regret of $\tilde{\mathcal O}(\sqrt{T}+\zeta)$. The proposed algorithm relies on the recently developed uncertainty-weighted least-squares regression from linear contextual bandits (He et al., 2022) and a new weighted estimator of uncertainty for the general function class. In contrast to the existing analysis for the sum of uncertainty that is heavily based on the linear structure, we develop a novel technique to control the sum of weighted uncertainty, thus establishing the final regret bound. We then generalize our algorithm to the episodic MDP and first achieve an additive dependence on the corruption level $\zeta$ in the scenario of general function approximation. Notably, our algorithms achieve regret bounds that either nearly match the lower bound or improve the performance of existing methods for all the corruption levels in both known and unknown $\zeta$ cases.

**摘要:** 尽管对对抗腐蚀的强化学习(RL)问题具有重大的兴趣和进展,但目前的工作要么局限于线性设置,要么导致不希望的$\tilde{\mathcal O}(\sqrt{T}\zeta)$遗憾约束,其中$T$是轮数和$\zeta$是腐蚀的总数。本文,我们考虑了与一般函数近似的上下文带子,并提出了实现$\tilde{\mathcal O}(\sqrt{T}+\zeta)$遗憾的计算效率高的算法。然后,我们将算法归纳为 episodic MDP,并在一般函数近似的场景中首先实现对腐蚀级别$\zeta$的增量依赖。

**[Paper URL](https://proceedings.mlr.press/v202/ye23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ye23d/ye23d.pdf)** 

# GNN&GBDT-Guided Fast Optimizing Framework for Large-scale Integer Programming
**题目:** 基于GNN&GBDT的大规模整数编程快速优化框架

**作者:** Huigen Ye, Hua Xu, Hongyan Wang, Chengming Wang, Yu Jiang

**Abstract:** The latest two-stage optimization framework based on graph neural network (GNN) and large neighborhood search (LNS) is the most popular framework in solving large-scale integer programs (IPs). However, the framework can not effectively use the embedding spatial information in GNN and still highly relies on large-scale solvers in LNS, resulting in the scale of IP being limited by the ability of the current solver and performance bottlenecks. To handle these issues, this paper presents a GNN&GBDT-guided fast optimizing framework for large-scale IPs that only uses a small-scale optimizer to solve large-scale IPs efficiently. Specifically, the proposed framework can be divided into three stages: Multi-task GNN Embedding to generate the embedding space, GBDT Prediction to effectively use the embedding spatial information, and Neighborhood Optimization to solve large-scale problems fast using the small-scale optimizer. Extensive experiments show that the proposed framework can solve IPs with millions of scales and surpass SCIP and Gurobi in the specified wall-clock time using only a small-scale optimizer with 30% of the problem size. It also shows that the proposed framework can save 99% of running time in achieving the same solution quality as SCIP, which verifies the effectiveness and efficiency of the proposed framework in solving large-scale IPs.

**摘要:** 基于图神经网络(GNN)和大型邻域搜索(LNS)的最新两阶段优化框架是解决大规模整数程序(IPs)最受欢迎的框架。然而,该框架不能有效地使用GNN内嵌入空间信息,并且仍高度依赖LNS内嵌入空间的解决方案,导致当前的解决方案和性能瓶颈限制了IP的规模。为了处理这些问题,本文提出了一种基于GNN&GBDT的大规模IP快速优化框架,仅使用小型优化器来有效解决大规模IP。具体而言,该框架可以分为三个阶段:多任务GNN内嵌入生成嵌入空间,GBDT预测有效使用嵌入空间信息,以及邻域优化以快速解决大规模问题。广泛的实验表明,该构架能够解决数百万尺度的IP问题,并且在指定的墙时钟时间上超越了SCIP和Gurobi,仅使用小规模优化器解决了30%的问题的大小。该构架能节省99%的运行时间,实现与SCIP相同的解决方案质量,从而验证了该构架在解决大规模IP问题上的作用和效率。

**[Paper URL](https://proceedings.mlr.press/v202/ye23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ye23e/ye23e.pdf)** 

# FedDisco: Federated Learning with Discrepancy-Aware Collaboration
**题目:** FedDisco:与差异意识协作的联合学习

**作者:** Rui Ye, Mingkai Xu, Jianyu Wang, Chenxin Xu, Siheng Chen, Yanfeng Wang

**Abstract:** This work considers the category distribution heterogeneity in federated learning. This issue is due to biased labeling preferences at multiple clients and is a typical setting of data heterogeneity. To alleviate this issue, most previous works consider either regularizing local models or fine-tuning the global model, while they ignore the adjustment of aggregation weights and simply assign weights based on the dataset size. However, based on our empirical observations and theoretical analysis, we find that the dataset size is not optimal and the discrepancy between local and global category distributions could be a beneficial and complementary indicator for determining aggregation weights. We thus propose a novel aggregation method, Federated Learning with Discrepancy-Aware Collaboration (FedDisco), whose aggregation weights not only involve both the dataset size and the discrepancy value, but also contribute to a tighter theoretical upper bound of the optimization error. FedDisco can promote utility and modularity in a communication- and computation-efficient way. Extensive experiments show that our FedDisco outperforms several state-of-the-art methods and can be easily incorporated with many existing methods to further enhance the performance. Our code will be available at https://github.com/MediaBrain-SJTU/FedDisco.

**摘要:** 本文研究了联合学习中的类别分布异质性问题。该问题是由于多个客户偏向的标签偏好,是一个典型的数据异质性设置问题。为了缓解这一问题,大多数以前的研究都考虑了局部模型的规范化或全球模型的微调化,同时忽略了集权的调整,并简单地根据集权的大小分配了集权。然而,基于我们的实证观察和理论分析,我们发现集权的大小不是最佳的,当地和全球类别分布之间的异质性可能是确定集权的一个有益的补充指标。FedDisco可以以通信和计算效率的方式促进实用性和模块化性。广泛的实验表明,我们的FedDisco超过了几种最先进的方法,并且可以轻易地结合许多现有的方法进一步提高性能。我们的代码将在 https://github.com/MediaBrain-SJTU/FedDisco上提供。

**[Paper URL](https://proceedings.mlr.press/v202/ye23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ye23f/ye23f.pdf)** 

# Towards Quantum Machine Learning for Constrained Combinatorial Optimization: a Quantum QAP Solver
**题目:** 面向约束组合优化的量子机器学习:量子QAP求解器

**作者:** Xinyu Ye, Ge Yan, Junchi Yan

**Abstract:** Combinatorial optimization (CO) on the graph is a crucial but challenging research topic. Recent quantum algorithms provide a new perspective for solving CO problems and have the potential to demonstrate quantum advantage. Quantum Approximate Optimization Algorithm (QAOA) is a well-known quantum heuristic for CO constructed by a parametric quantum circuit. However, QAOA is originally designed for unconstrained problems and the circuit parameters and solutions are jointly solved with time-consuming iterations. In this paper, we propose a novel quantum neural network (QNN) for learning CO problems in a supervised manner to achieve better and faster results. We focus on the Quadratic Assignment Problem (QAP) with matching constraints and the node permutation invariance property. To this end, a quantum neural network called QAP-QNN is devised to translate the QAP into a constrained vertex classification task. Moreover, we study two QAP tasks: Graph Matching and Traveling Salesman Problem on TorchQauntum simulators, and empirically show the effectiveness of our approach.

**摘要:** 量子近似优化算法(英语:Quantum Approximate Optimization Algorithm,缩写:QOA)是一种由参数量子电路构造的可知量子启发算法,它最初是为无约束问题设计的,而电路参数和解则与耗时迭代一起解决。本文提出了一种新的量子神经网络(英语:Quantum Neural Network,缩写:QNN)来指导学习可知量子问题,以取得更好的更快的结果。此外,我们研究了两个QAP任务:图标匹配和旅行推销员问题在TorchQauntum模拟器上,并实验证明了我们的方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/ye23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ye23g/ye23g.pdf)** 

# Temporal Label Smoothing for Early Event Prediction
**题目:** 早期事件预测的临时标签 Smoothing

**作者:** Hugo Yèche, Alizée Pace, Gunnar Ratsch, Rita Kuznetsova

**Abstract:** Models that can predict the occurrence of events ahead of time with low false-alarm rates are critical to the acceptance of decision support systems in the medical community. This challenging task is typically treated as a simple binary classification, ignoring temporal dependencies between samples, whereas we propose to exploit this structure. We first introduce a common theoretical framework unifying dynamic survival analysis and early event prediction. Following an analysis of objectives from both fields, we propose Temporal Label Smoothing (TLS), a simpler, yet best-performing method that preserves prediction monotonicity over time. By focusing the objective on areas with a stronger predictive signal, TLS improves performance over all baselines on two large-scale benchmark tasks. Gains are particularly notable along clinically relevant measures, such as event recall at low false-alarm rates. TLS reduces the number of missed events by up to a factor of two over previously used approaches in early event prediction.

**摘要:** 具有低误报率的预测事件的模型对医疗界决策支持系统接受至关重要。这一挑战性任务通常被处理为简单的二进制分类,忽略样品之间的时间依赖性,而我们建议利用这一结构。我们首先引入一个统一的理论框架,统一动态生存分析和早期事件预测。TLS可以比先前在早期事件预测中使用的方法减少错过事件的数目最大两倍。

**[Paper URL](https://proceedings.mlr.press/v202/yeche23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yeche23a/yeche23a.pdf)** 

# From Temporal to Contemporaneous Iterative Causal Discovery in the Presence of Latent Confounders
**题目:** 从暂时性到当代的反常性因果发现在潜在的破坏者面前

**作者:** Raanan Yehezkel Rohekar, Shami Nisimov, Yaniv Gurwicz, Gal Novik

**Abstract:** We present a constraint-based algorithm for learning causal structures from observational time-series data, in the presence of latent confounders. We assume a discrete-time, stationary structural vector autoregressive process, with both temporal and contemporaneous causal relations. One may ask if temporal and contemporaneous relations should be treated differently. The presented algorithm gradually refines a causal graph by learning long-term temporal relations before short-term ones, where contemporaneous relations are learned last. This ordering of causal relations to be learnt leads to a reduction in the required number of statistical tests. We validate this reduction empirically and demonstrate that it leads to higher accuracy for synthetic data and more plausible causal graphs for real-world data compared to state-of-the-art algorithms.

**摘要:** 我们提出了一种基于约束的基于观察时间序列数据学习因果结构的算法,在潜在的混淆者的存在下,我们假设一个离散时间的静态结构向量自回归过程,同时具有时间和同时的因果关系。我们可以问一下,时间和同时的关系应该如何处理。

**[Paper URL](https://proceedings.mlr.press/v202/yehezkel-rohekar23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yehezkel-rohekar23a/yehezkel-rohekar23a.pdf)** 

# Doubly Adversarial Federated Bandits
**题目:** 雙敵聯邦匪徒

**作者:** Jialin Yi, Milan Vojnovic

**Abstract:** We study a new non-stochastic federated multiarmed bandit problem with multiple agents collaborating via a communication network. The losses of the arms are assigned by an oblivious adversary that specifies the loss of each arm not only for each time step but also for each agent, which we call doubly adversarial. In this setting, different agents may choose the same arm in the same time step but observe different feedback. The goal of each agent is to find a globally best arm in hindsight that has the lowest cumulative loss averaged over all agents, which necessities the communication among agents. We provide regret lower bounds for any federated bandit algorithm under different settings, when agents have access to full-information feedback, or the bandit feedback. For the bandit feedback setting, we propose a near-optimal federated bandit algorithm called FEDEXP3. Our algorithm gives a positive answer to an open question proposed in (Cesa-Bianchi et al., 2016): FEDEXP3 can guarantee a sub-linear regret without exchanging sequences of selected arm identities or loss sequences among agents. We also provide numerical evaluations of our algorithm to validate our theoretical results and demonstrate its effectiveness on synthetic and real-world datasets.

**摘要:** 我们研究了一种新的非随机联合多武器盗版问题,由多个代理人通过通信网络合作。武器的损失由一个无意识的对手分配,它不仅指定了每个武器的损失,而且指定了每个代理人的损失,我们称之为双重敌对。在这个设置中,不同的代理人可以在同一时间步骤中选择相同的手臂,但观察不同的反馈。每个代理人的目标是在后视中找到一个具有在所有代理人之间通信的平均最低累积损失的全球最佳手臂,我们为任何联合盗版算法在不同的设置下提供更低的限制,当代理人获得完整的信息反馈或盗版反馈时。我们的算法对(Cesa-Bianchi et al., 2016)提出的一个开放问题给出了积极的答案: FEDEXP3可以保证在代理人之间不交换选定的手臂身份序列或损失序列的情况下实现次线性遗憾。

**[Paper URL](https://proceedings.mlr.press/v202/yi23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yi23a/yi23a.pdf)** 

# Online Prototype Alignment for Few-shot Policy Transfer
**题目:** 少 shot政策转移的在线原型整合

**作者:** Qi Yi, Rui Zhang, Shaohui Peng, Jiaming Guo, Yunkai Gao, Kaizhao Yuan, Ruizhi Chen, Siming Lan, Xing Hu, Zidong Du, Xishan Zhang, Qi Guo, Yunji Chen

**Abstract:** Domain adaptation in RL mainly deals with the changes of observation when transferring the policy to a new environment. Many traditional approaches of domain adaptation in RL manage to learn a mapping function between the source and target domain in explicit or implicit ways. However, they typically require access to abundant data from the target domain. Besides, they often rely on visual clues to learn the mapping function and may fail when the source domain looks quite different from the target domain. To address these problems, in this paper, we propose a novel framework Online Prototype Alignment (OPA) to learn the mapping function based on the functional similarity of elements and is able to achieve few-shot policy transfer within only several episodes. The key insight of OPA is to introduce an exploration mechanism that can interact with the unseen elements of the target domain in an efficient and purposeful manner, and then connect them with the seen elements in the source domain according to their functionalities (instead of visual clues). Experimental results show that when the target domain looks visually different from the source domain, OPA can achieve better transfer performance even with much fewer samples from the target domain, outperforming prior methods.

**摘要:** RL域适应主要处理在将策略转移到一个新的环境时的观察变化。RL域适应的许多传统方法以明确或隐含的方式学习源域和目标域之间的映射函数。然而,它们通常需要从目标域获得大量数据。此外,它们经常依赖视觉线索来学习映射函数,并且在源域看起来与目标域非常不同时可能失败。OPA的关键洞察是引入一种能够有效和有目的地与目标域的无形元素相互作用的探索机制,然后根据它们的功能(而不是视觉线索)与源域的无形元素连接起来。实验结果表明,当目标域看起来与源域有视觉差异时,OPA可以在目标域的样品少得多的情况下实现更好的传输性能,超过了以往的方法。

**[Paper URL](https://proceedings.mlr.press/v202/yi23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yi23b/yi23b.pdf)** 

# MonoFlow: Rethinking Divergence GANs via the Perspective of Wasserstein Gradient Flows
**题目:** 单流:从水星梯度流的视角重新思考差异GAN

**作者:** Mingxuan Yi, Zhanxing Zhu, Song Liu

**Abstract:** The conventional understanding of adversarial training in generative adversarial networks (GANs) is that the discriminator is trained to estimate a divergence, and the generator learns to minimize this divergence. We argue that despite the fact that many variants of GANs were developed following this paradigm, the current theoretical understanding of GANs and their practical algorithms are inconsistent. In this paper, we leverage Wasserstein gradient flows which characterize the evolution of particles in the sample space, to gain theoretical insights and algorithmic inspiration of GANs. We introduce a unified generative modeling framework – MonoFlow: the particle evolution is rescaled via a monotonically increasing mapping of the log density ratio. Under our framework, adversarial training can be viewed as a procedure first obtaining MonoFlow’s vector field via training the discriminator and the generator learns to draw the particle flow defined by the corresponding vector field. We also reveal the fundamental difference between variational divergence minimization and adversarial training. This analysis helps us to identify what types of generator loss functions can lead to the successful training of GANs and suggest that GANs may have more loss designs beyond the literature (e.g., non-saturated loss), as long as they realize MonoFlow. Consistent empirical studies are included to validate the effectiveness of our framework.

**摘要:** 在生成敌对网络中的敌对训练的传统理解是,分离器被训练以估计偏差,而生成器则学会尽量减少这种偏差。我们认为,尽管在这一模式下开发了许多变异的GAN,但目前的GAN理论理解及其实际算法是不一致的。我们还揭示了变异偏差最小化与敌对训练之间的根本差异。分析有助于我们确定产生损伤函数的类型可以导致GAN的训练成功,并建议GAN可能具有超过文献的损伤设计(例如不饱和损伤),只要它们实现单流。

**[Paper URL](https://proceedings.mlr.press/v202/yi23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yi23c/yi23c.pdf)** 

# SE(3) diffusion model with application to protein backbone generation
**题目:** SE(3)扩散模型应用于蛋白质后骨生成

**作者:** Jason Yim, Brian L. Trippe, Valentin De Bortoli, Emile Mathieu, Arnaud Doucet, Regina Barzilay, Tommi Jaakkola

**Abstract:** The design of novel protein structures remains a challenge in protein engineering for applications across biomedicine and chemistry. In this line of work, a diffusion model over rigid bodies in 3D (referred to as frames) has shown success in generating novel, functional protein backbones that have not been observed in nature. However, there exists no principled methodological framework for diffusion on SE(3), the space of orientation preserving rigid motions in R3, that operates on frames and confers the group invariance. We address these shortcomings by developing theoretical foundations of SE(3) invariant diffusion models on multiple frames followed by a novel framework, FrameDiff, for estimating the SE(3) equivariant score over multiple frames. We apply FrameDiff on monomer backbone generation and find it can generate designable monomers up to 500 amino acids without relying on a pretrained protein structure prediction network that has been integral to previous methods. We find our samples are capable of generalizing beyond any known protein structure.

**摘要:** 在生物医学和化学领域应用中,新型蛋白质结构的设计仍然是蛋白质工程中的一个挑战。在这一领域,在3D的固体扩散模型(称为框架)中,已成功地产生新功能性蛋白质骨骼,但尚未被自然界观察到。然而,在SE(3)上的扩散,即在R3中保持固体运动的定位空间,在框架上运行并赋予群不变性,目前尚无原则的方法框架。我们解决这些问题,开发了基于多个框架的SE(3)不变扩散模型的理论基础,并用新框架 FrameDiff来估计多个框架上的SE(3)等变性分数。我们发现我们的样品能够超越任何已知的蛋白质结构.

**[Paper URL](https://proceedings.mlr.press/v202/yim23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yim23a/yim23a.pdf)** 

# CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive Graph Classification
**题目:** CoCo:非监管域适应图分类的耦合约束框架

**作者:** Nan Yin, Li Shen, Mengzhu Wang, Long Lan, Zeyu Ma, Chong Chen, Xian-Sheng Hua, Xiao Luo

**Abstract:** Although graph neural networks (GNNs) have achieved impressive achievements in graph classification, they often need abundant task-specific labels, which could be extensively costly to acquire. A credible solution is to explore additional labeled graphs to enhance unsupervised learning on the target domain. However, how to apply GNNs to domain adaptation remains unsolved owing to the insufficient exploration of graph topology and the significant domain discrepancy. In this paper, we propose Coupled Contrastive Graph Representation Learning (CoCo), which extracts the topological information from coupled learning branches and reduces the domain discrepancy with coupled contrastive learning. CoCo contains a graph convolutional network branch and a hierarchical graph kernel network branch, which explore graph topology in implicit and explicit manners. Besides, we incorporate coupled branches into a holistic multi-view contrastive learning framework, which not only incorporates graph representations learned from complementary views for enhanced understanding, but also encourages the similarity between cross-domain example pairs with the same semantics for domain alignment. Extensive experiments on popular datasets show that our CoCo outperforms these competing baselines in different settings generally.

**摘要:** 尽管图神经网络在图分类中取得了令人印象深刻的成就,但它们经常需要大量的任务特有标签,而这些标签的获取可能非常昂贵。一个可信的解决办法是探索附加标签的图,以增强目标域的无监督学习。然而,如何应用GNN对域的适应性仍然无法解决,因为图拓扑的探索不足,以及重要的域差异。此外,我们将耦合分支纳入一个整体的多视角对比学习框架,它不仅包括从互补视角学习的图形表示,以提高理解,而且鼓励跨域的实例对与相同语义的域匹配之间的相似性。

**[Paper URL](https://proceedings.mlr.press/v202/yin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yin23a/yin23a.pdf)** 

# Adaptive Estimation of Graphical Models under Total Positivity
**题目:** 图形模型总体正值下的适应性估计

**作者:** Jiaxi Ying, José Vinı́cius De Miranda Cardoso, Daniel P. Palomar

**Abstract:** We consider the problem of estimating (diagonally dominant) M-matrices as precision matrices in Gaussian graphical models. Such models have shown interesting properties, e.g., the maximum likelihood estimator exists with as little as two observations in the case of M-matrices, and exists even with one observation in the case of diagonally dominant M-matrices. We propose an adaptive multiple-stage estimation method, which refines the estimate by solving a weighted $\ell_1$-regularized problem in each stage. We further design a unified framework based on gradient projection method to solve the regularized problem, equipped with different projections to handle the constraints of M-matrices and diagonally dominant M-matrices. Theoretical analysis of the estimation error is established. The proposed method outperforms state-of-the-art methods in estimating precision matrices and identifying graph edges, as evidenced by synthetic and financial time-series data sets.

**摘要:** 我们把估计(斜向主导)M-矩阵问题当作高斯图形模型的精度矩阵问题。这些模型显示出有趣的特性,例如,最大概率估计器存在于M-矩阵中只有两个观察,并且存在于斜向主导M-矩阵中甚至只有一个观察。我们提出了一种适应性多阶段估计方法,通过在每个阶段解决一个权重 $\ell_1$-调节问题的改进估计。我们进一步设计了基于梯度投影法的统一框架,以解决调节问题,并装有不同的投影来处理M-矩阵和斜向主导M-矩阵的约束。

**[Paper URL](https://proceedings.mlr.press/v202/ying23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ying23a/ying23a.pdf)** 

# Improving Visual Prompt Tuning for Self-supervised Vision Transformers
**题目:** 改善自监督视觉变换器的视觉快速调制

**作者:** Seungryong Yoo, Eunji Kim, Dahuin Jung, Jungbeom Lee, Sungroh Yoon

**Abstract:** Visual Prompt Tuning (VPT) is an effective tuning method for adapting pretrained Vision Transformers (ViTs) to downstream tasks. It leverages extra learnable tokens, known as prompts, which steer the frozen pretrained ViTs. Although VPT has demonstrated its applicability with supervised vision transformers, it often underperforms with self-supervised ones. Through empirical observations, we deduce that the effectiveness of VPT hinges largely on the ViT blocks with which the prompt tokens interact. Specifically, VPT shows improved performance on image classification tasks for MAE and MoCo v3 when the prompt tokens are inserted into later blocks rather than the first block. These observations suggest that there exists an optimal location of blocks for the insertion of prompt tokens. Unfortunately, identifying the optimal blocks for prompts within each self-supervised ViT for diverse future scenarios is a costly process. To mitigate this problem, we propose a simple yet effective method that learns a gate for each ViT block to adjust its intervention into the prompt tokens. With our method, prompt tokens are selectively influenced by blocks that require steering for task adaptation. Our method outperforms VPT variants in FGVC and VTAB image classification and ADE20K semantic segmentation. The code is available at https://github.com/ryongithub/GatedPromptTuning.

**摘要:** Visual Prompt Tuning(VPT)是针对下游任务调整预制视图变换器(ViTs)的有效调制方法。它利用预制视图变换器(ViTs)所知的额外可学习的符号来指导预制视图变换器。虽然VPT已经证明了其可应用性,但它经常与自监督视图变换器相比表现不佳。通过实证观察,我们推导了VPT的有效性主要取决于提示符号相互作用的ViT块。具体地说,VPT显示了提示符号被插入后块而不是第一个块时,MAE和MoCov3的图像分类任务的性能有所提高。这些观察表明,存在着提示符号插入的最佳块位置。不幸的是,在每个自监督视图变换器内确定提示符号的最佳块是一个昂贵的过程。为了缓解这一问题,我们提出了一种简单而有效的方法,它为每个ViT块学习一个门,以调整其干预到提示符号中。我们的方法,提示符号被需要调制任务适应的块选择性影响。我们的方法比FGVC和VTAB图像分类和ADE20K语义分割的VPT变异更出色。

**[Paper URL](https://proceedings.mlr.press/v202/yoo23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yoo23a/yoo23a.pdf)** 

# End-to-End Multi-Object Detection with a Regularized Mixture Model
**题目:** 基于规范混合模型的多目标检测

**作者:** Jaeyoung Yoo, Hojun Lee, Seunghyeon Seo, Inseop Chung, Nojun Kwak

**Abstract:** Recent end-to-end multi-object detectors simplify the inference pipeline by removing hand-crafted processes such as non-maximum suppression (NMS). However, during training, they still heavily rely on heuristics and hand-crafted processes which deteriorate the reliability of the predicted confidence score. In this paper, we propose a novel framework to train an end-to-end multi-object detector consisting of only two terms: negative log-likelihood (NLL) and a regularization term. In doing so, the multi-object detection problem is treated as density estimation of the ground truth bounding boxes utilizing a regularized mixture density model. The proposed end-to-end multi-object Detection with a Regularized Mixture Model (D-RMM) is trained by minimizing the NLL with the proposed regularization term, maximum component maximization (MCM) loss, preventing duplicate predictions. Our method reduces the heuristics of the training process and improves the reliability of the predicted confidence score. Moreover, our D-RMM outperforms the previous end-to-end detectors on MS COCO dataset. Code is available at https://github.com/lhj815/D-RMM.

**摘要:** 当前的端到端多物体探测器通过除去非最大抑制(NMS)等手工处理过程,简化了推导管道。然而,在训练过程中,它们仍严重依赖于模拟和手工处理过程,从而降低了预测的信任分数的可靠性。本文提出了一种新框架,以训练由两个单词组成的端到端多物体探测器:负逻辑概率(NLL)和定律术语。在这样做时,多物体探测问题被处理为使用定律混合物密度模型的地真 bounding boxes的密度估计。我们的方法降低了训练过程的灵敏度,提高了预测的信心分数的可靠性。此外,我们的D-RMM在MSCOCO数据集上比以前的端到端检测器高。代码可于 https://github.com/lhj815/D-RMM。

**[Paper URL](https://proceedings.mlr.press/v202/yoo23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yoo23b/yoo23b.pdf)** 

# EM-Network: Oracle Guided Self-distillation for Sequence Learning
**题目:** EM-Network:Oracle引导的序列学习自提法

**作者:** Ji Won Yoon, Sunghwan Ahn, Hyeonseung Lee, Minchan Kim, Seok Min Kim, Nam Soo Kim

**Abstract:** We introduce EM-Network, a novel self-distillation approach that effectively leverages target information for supervised sequence-to-sequence (seq2seq) learning. In contrast to conventional methods, it is trained with oracle guidance, which is derived from the target sequence. Since the oracle guidance compactly represents the target-side context that can assist the sequence model in solving the task, the EM-Network achieves a better prediction compared to using only the source input. To allow the sequence model to inherit the promising capability of the EM-Network, we propose a new self-distillation strategy, where the original sequence model can benefit from the knowledge of the EM-Network in a one-stage manner. We conduct comprehensive experiments on two types of seq2seq models: connectionist temporal classification (CTC) for speech recognition and attention-based encoder-decoder (AED) for machine translation. Experimental results demonstrate that the EM-Network significantly advances the current state-of-the-art approaches, improving over the best prior work on speech recognition and establishing state-of-the-art performance on WMT’14 and IWSLT’14.

**摘要:** 本文介绍了一种新型的自蒸馏方法,它有效地利用目标信息进行监控的序列-到序列(seq2seq)学习。与传统的方法相比,该方法采用了从目标序列导引来训练的自蒸馏方法。由于自蒸馏方法简洁地代表了目标侧的上下文,可以帮助序列模型解决任务,因此,自蒸馏方法比只使用源输入更具有更好的预测能力。为了使序列模型继承自蒸馏的潜力,我们提出了一种新的自蒸馏策略,其中原有的序列模型可以在一阶段从自蒸馏模型的知识中获益。实验结果表明,EM-Network大大提升了当前最先进的方法,改善了对语音识别的最好工作,并建立了WMT’14和IWSLT’14的最先进的性能。

**[Paper URL](https://proceedings.mlr.press/v202/yoon23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yoon23a/yoon23a.pdf)** 

# Continual Learners are Incremental Model Generalizers
**题目:** 持续学习者是不断建模的一般化者

**作者:** Jaehong Yoon, Sung Ju Hwang, Yue Cao

**Abstract:** Motivated by the efficiency and rapid convergence of pre-trained models for solving downstream tasks, this paper extensively studies the impact of Continual Learning (CL) models as pre-trainers. We find that, in both supervised and unsupervised CL, the transfer quality of representations does not show a noticeable degradation of fine-tuning performance but rather increases gradually. This is because CL models can learn improved task-general features when easily forgetting task-specific knowledge. Based on this observation, we suggest a new unsupervised CL framework with masked modeling, which aims to capture fluent task-generic representation during training. Furthermore, we propose a new fine-tuning scheme, GLobal Attention Discretization (GLAD), that preserves rich task-generic representation during solving downstream tasks. The model fine-tuned with GLAD achieves competitive performance and can also be used as a good pre-trained model itself. We believe this paper breaks the barriers between pre-training and fine-tuning steps and leads to a sustainable learning framework in which the continual learner incrementally improves model generalization, yielding better transfer to unseen tasks.

**摘要:** 本文主要研究了持续学习(CL)模型作为预训练者在解决下游任务的效率和快速收敛性方面的影响,发现在监管和非监管的CL中,表现的传递质量并不表现出微调性能的显著下降,而是逐渐增加,这是因为CL模型在容易忘记特定任务知识时可以学习改进的任务一般特征。基于这一观察,我们提出了一种新的非监管的CL框架,即隐形模型,旨在在训练中捕捉流畅的任务generic表现。我们认为,本论文打破了预培训和微调阶段之间的障碍,并导致了持续学习框架,即持续学习者逐步改进模型的一般化,从而更好地转移到未知任务。

**[Paper URL](https://proceedings.mlr.press/v202/yoon23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yoon23b/yoon23b.pdf)** 

# An Investigation into Pre-Training Object-Centric Representations for Reinforcement Learning
**题目:** 强化学习前训练对象中心表现的调查

**作者:** Jaesik Yoon, Yi-Fu Wu, Heechul Bae, Sungjin Ahn

**Abstract:** Unsupervised object-centric representation (OCR) learning has recently drawn attention as a new paradigm of visual representation. This is because of its potential of being an effective pre-training technique for various downstream tasks in terms of sample efficiency, systematic generalization, and reasoning. Although image-based reinforcement learning (RL) is one of the most important and thus frequently mentioned such downstream tasks, the benefit in RL has surprisingly not been investigated systematically thus far. Instead, most of the evaluations have focused on rather indirect metrics such as segmentation quality and object property prediction accuracy. In this paper, we investigate the effectiveness of OCR pre-training for image-based reinforcement learning via empirical experiments. For systematic evaluation, we introduce a simple object-centric visual RL benchmark and conduct experiments to answer questions such as "Does OCR pre-training improve performance on object-centric tasks?" and "Can OCR pre-training help with out-of-distribution generalization?". Our results provide empirical evidence for valuable insights into the effectiveness of OCR pre-training for RL and the potential limitations of its use in certain scenarios. Additionally, this study also examines the critical aspects of incorporating OCR pre-training in RL, including performance in a visually complex environment and the appropriate pooling layer to aggregate the object representations.

**摘要:** 基于图像的增强学习(英语:Image-based reinforcement learning,缩写为OCR)是最重要,因此经常提到的下游任务之一,但迄今为止尚未有系统地研究RL的效益。相反,大部分评价都集中在像分割质量和对象属性预测精度等间接指标上。为系统性评价,我们引入了简单的面向对象的视觉RL基准,并进行了实验,以回答诸如“OCR预训练能改善面向对象任务的性能吗?”和“OCR预训练能帮助 out-of-distribution一般化吗?”等问题。我们的结果为对RL的OCR预训练的有效性以及在某些场景中使用OCR预训练的潜在限制提供了实证证据。此外,本研究还研究了将OCR预训练纳入RL中的关键方面,包括在视觉上复杂的环境中的表现以及适当的聚合层来聚集对象表示。

**[Paper URL](https://proceedings.mlr.press/v202/yoon23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yoon23c/yoon23c.pdf)** 

# Graph Generative Model for Benchmarking Graph Neural Networks
**题目:** 图神经网络 Benchmarking 图生成模型

**作者:** Minji Yoon, Yue Wu, John Palowitch, Bryan Perozzi, Russ Salakhutdinov

**Abstract:** As the field of Graph Neural Networks (GNN) continues to grow, it experiences a corresponding increase in the need for large, real-world datasets to train and test new GNN models on challenging, realistic problems. Unfortunately, such graph datasets are often generated from online, highly privacy-restricted ecosystems, which makes research and development on these datasets hard, if not impossible. This greatly reduces the amount of benchmark graphs available to researchers, causing the field to rely only on a handful of publicly-available datasets. To address this problem, we introduce a novel graph generative model, Computation Graph Transformer (CGT) that learns and reproduces the distribution of real-world graphs in a privacy-controlled way. More specifically, CGT (1) generates effective benchmark graphs on which GNNs show similar task performance as on the source graphs, (2) scales to process large-scale graphs, (3) incorporates off-the-shelf privacy modules to guarantee end-user privacy of the generated graph. Extensive experiments across a vast body of graph generative models show that only our model can successfully generate privacy-controlled, synthetic substitutes of large-scale real-world graphs that can be effectively used to benchmark GNN models.

**摘要:** 由于 Graph Neural Networks(GNN)的领域继续增长,它对训练和测试新的GNN模型在挑战性、现实问题上需要大型、现实数据集的相应增加。不幸的是,这些图数据集经常来自在线、高度受私隐限制的生态系统,这使得这些数据集的研究和开发变得困难,如果不是不可能的话。这大大减少了研究者可用的基准图的数量,导致该领域只能依靠少数公开的数据集。更具体地说,CGT(一)生成有效的基准图,GNN的任务性能与源图相似,(二)用于处理大型图的尺度,(三)包含在市场上的隐私模块,以确保生成图的最终用户隐私。

**[Paper URL](https://proceedings.mlr.press/v202/yoon23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yoon23d/yoon23d.pdf)** 

# Analyzing Convergence in Quantum Neural Networks: Deviations from Neural Tangent Kernels
**题目:** 量子神经网络的收敛性分析:神经 Tangent Kernels的偏差

**作者:** Xuchen You, Shouvanik Chakrabarti, Boyang Chen, Xiaodi Wu

**Abstract:** A quantum neural network (QNN) is a parameterized mapping efficiently implementable on near-term Noisy Intermediate-Scale Quantum (NISQ) computers. It can be used for supervised learning when combined with classical gradient-based optimizers. Despite the existing empirical and theoretical investigations, the convergence of QNN training is not fully understood. Inspired by the success of the neural tangent kernels (NTKs) in probing into the dynamics of classical neural networks, a recent line of works proposes to study over-parameterized QNNs by examining a quantum version of tangent kernels. In this work, we study the dynamics of QNNs and show that contrary to popular belief it is qualitatively different from that of any kernel regression: due to the unitarity of quantum operations, there is a non-negligible deviation from the tangent kernel regression derived at the random initialization. As a result of the deviation, we prove the at-most sublinear convergence for QNNs with Pauli measurements, which is beyond the explanatory power of any kernel regression dynamics. We then present the actual dynamics of QNNs in the limit of over-parameterization. The new dynamics capture the change of convergence rate during training and implies that the range of measurements is crucial to the fast QNN convergence.

**摘要:** 量子神经网络(英语:Quantum neural network,缩写:QNN)是 near-term Noisy Intermediate-Scale Quantum (NISQ) 计算机上可有效地实现参数化映射的参数化映射。它可以在与经典梯度基础优化器结合时用于监督学习。尽管存在经验和理论研究,QNN训练的收敛性并不完全理解。结果表明,波利测度对QNN的近线性收敛性几乎超出任何核回归动力学的解释力。然后,在超参数化限度下,我们给出了QNN的实际动力学。新的动力学记录了训练期间收敛率的变化,并暗示了测量范围对于快速QNN收敛性至关重要。

**[Paper URL](https://proceedings.mlr.press/v202/you23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/you23a/you23a.pdf)** 

# Entropy-driven Unsupervised Keypoint Representation Learning in Videos
**题目:** 基于熵的无监督关键点表示学习视频

**作者:** Ali Younes, Simone Schaub-Meyer, Georgia Chalvatzaki

**Abstract:** Extracting informative representations from videos is fundamental for effectively learning various downstream tasks. We present a novel approach for unsupervised learning of meaningful representations from videos, leveraging the concept of image spatial entropy (ISE) that quantifies the per-pixel information in an image. We argue that local entropy of pixel neighborhoods and their temporal evolution create valuable intrinsic supervisory signals for learning prominent features. Building on this idea, we abstract visual features into a concise representation of keypoints that act as dynamic information transmitters, and design a deep learning model that learns, purely unsupervised, spatially and temporally consistent representations directly from video frames. Two original information-theoretic losses, computed from local entropy, guide our model to discover consistent keypoint representations; a loss that maximizes the spatial information covered by the keypoints and a loss that optimizes the keypoints’ information transportation over time. We compare our keypoint representation to strong baselines for various downstream tasks, e.g., learning object dynamics. Our empirical results show superior performance for our information-driven keypoints that resolve challenges like attendance to static and dynamic objects or objects abruptly entering and leaving the scene.

**摘要:** 从视频中提取信息性表现是有效学习各种下游任务的基础。我们提出了一种新方法,即利用图像空间熵(ISE)的概念,对图像中的每个像素信息进行量化。我们认为像素邻域的局部熵及其时间演化为学习突出特征创造有价值的内在监督信号。基于局部熵计算的两个原始信息理论损失,指导了我们的模型发现一致的基点表示;一种使基点覆盖的空间信息最大化的损失,以及一种使基点信息在时间上运转最优化的损失。我们比较了我们的基点表示与各种下游任务(例如学习对象动力学)的强基线。我们的实证结果显示了我们以信息驱动的基点表现的优越表现,解决了如对静态和动态对象或突然进入和离开场景的对象的参与等挑战。

**[Paper URL](https://proceedings.mlr.press/v202/younes23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/younes23a/younes23a.pdf)** 

# The Benefits of Model-Based Generalization in Reinforcement Learning
**题目:** 基于模型的推广在强化学习中的价值

**作者:** Kenny John Young, Aditya Ramesh, Louis Kirsch, Jürgen Schmidhuber

**Abstract:** Model-Based Reinforcement Learning (RL) is widely believed to have the potential to improve sample efficiency by allowing an agent to synthesize large amounts of imagined experience. Experience Replay (ER) can be considered a simple kind of model, which has proved effective at improving the stability and efficiency of deep RL. In principle, a learned parametric model could improve on ER by generalizing from real experience to augment the dataset with additional plausible experience. However, given that learned value functions can also generalize, it is not immediately obvious why model generalization should be better. Here, we provide theoretical and empirical insight into when, and how, we can expect data generated by a learned model to be useful. First, we provide a simple theorem motivating how learning a model as an intermediate step can narrow down the set of possible value functions more than learning a value function directly from data using the Bellman equation. Second, we provide an illustrative example showing empirically how a similar effect occurs in a more concrete setting with neural network function approximation. Finally, we provide extensive experiments showing the benefit of model-based learning for online RL in environments with combinatorial complexity, but factored structure that allows a learned model to generalize. In these experiments, we take care to control for other factors in order to isolate, insofar as possible, the benefit of using experience generated by a learned model relative to ER alone.

**摘要:** 基于模型强化学习(英语:Model-Based Reinforcement Learning,缩写为RL)是广泛认为通过允许代理人合成大量想象经验来提高样品效率的潜力。经验重演(英语:Experience Replay,缩写为ER)可被视为一种简单的模型,已经证明在提高深层RL的稳定性和效率方面有效。在原则上,一个学习参数模型可以通过从实际经验中推广提高ER,以增加数据集的可信经验。然而,鉴于学习值函数也可以推广,因此模型推广应该更好并不明显。其次,我们提供了一个实例,说明在更具体的环境中,神经网络函数近似下,如何产生类似效应。最后,我们提供广泛的实验,说明在复合复杂环境中,基于模型的在线RL学习的好处,但允许学习模型推广的因子结构。

**[Paper URL](https://proceedings.mlr.press/v202/young23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/young23a/young23a.pdf)** 

# COLA: Orchestrating Error Coding and Learning for Robust Neural Network Inference Against Hardware Defects
**题目:** COLA:组织错误编码和学习对硬件缺陷的鲁棒神经网络入侵

**作者:** Anlan Yu, Ning Lyu, Jieming Yin, Zhiyuan Yan, Wujie Wen

**Abstract:** Error correcting output codes (ECOCs) have been proposed to improve the robustness of deep neural networks (DNNs) against hardware defects of DNN hardware accelerators. Unfortunately, existing efforts suffer from drawbacks that would greatly impact their practicality: 1) robust accuracy (with defects) improvement at the cost of degraded clean accuracy (without defects); 2) no guarantee on better robust or clean accuracy using stronger ECOCs. In this paper, we first shed light on the connection between these drawbacks and error correlation, and then propose a novel comprehensive error decorrelation framework, namely COLA. Specifically, we propose to reduce inner layer feature error correlation by 1) adopting a separated architecture, where the last portions of the paths to all output nodes are separated, and 2) orthogonalizing weights in common DNN layers so that the intermediate features are orthogonal with each other. We also propose a regularization technique based on total correlation to mitigate overall error correlation at the outputs. The effectiveness of COLA is first analyzed theoretically, and then evaluated experimentally, e.g. up to 6.7% clean accuracy improvement compared with the original DNNs and up to 40% robust accuracy improvement compared to the state-of-the-art ECOC-enhanced DNNs.

**摘要:** 错误纠正输出代码(ECOCs)旨在提高深度神经网络(DNNs)的鲁棒性,防止DNN硬件加速器硬件缺陷。不幸的是,现有的努力遭受了严重影响的缺点: 1)鲁棒的准确性(有缺陷)在降低的清洁准确性(没有缺陷)的成本上提高; 2)使用更强的ECOCs没有保证更好的鲁棒或清洁的准确性。我们还提出了一种基于总相关性的校正技术,以减轻输出的总误差相关性。COLA的有效性首先从理论上分析,然后通过实验评价,例如,与原型DNN相比,最大6.7 % 的清洁精度提高,和最先进的ECOC增强DNN相比,最大40%的鲁棒精度提高。

**[Paper URL](https://proceedings.mlr.press/v202/yu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yu23a/yu23a.pdf)** 

# Delving into Noisy Label Detection with Clean Data
**题目:** 使用清洁数据进行噪声标签检测

**作者:** Chenglin Yu, Xinsong Ma, Weiwei Liu

**Abstract:** A critical element of learning with noisy labels is noisy label detection. Notably, numerous previous works assume that no source of labels can be clean in a noisy label detection context. In this work, we relax this assumption and assume that a small subset of the training data is clean, which enables substantial noisy label detection performance gains. Specifically, we propose a novel framework that leverages clean data by framing the problem of noisy label detection with clean data as a multiple hypothesis testing problem. Moreover, we propose BHN, a simple yet effective approach for noisy label detection that integrates the Benjamini-Hochberg (BH) procedure into deep neural networks. BHN achieves $\textit{state-of-the-art}$ performance and outperforms baselines by $\textbf{28.48}$% in terms of false discovery rate (FDR) and by $\textbf{18.99}$% in terms of F1 on CIFAR-10. Extensive ablation studies further demonstrate the superiority of BHN. Our code is available at https://github.com/ChenglinYu/BHN.

**摘要:** 噪声标签检测是学习噪声标签的一个关键要素。在噪声标签检测中,许多先前的工作假设在噪声标签检测上下文中没有源代码可以清洁。在这个工作中,我们放松了这个假设并假设训练数据的一个小部分是清洁的,这使得噪声标签检测性能得到显著的提高。具体而言,我们提出了一种新框架,通过将噪声标签检测问题与清洁数据结合起来作为多个假设测试问题来利用清洁数据来提取新的框架。此外,我们提出了BHN,一种简便而有效的噪声标签检测方法,它将Benjamini-Hochberg(BH)程序集成到深层神经网络中。我们的代码在 https://github.com/ChenglinYu/BHN.

**[Paper URL](https://proceedings.mlr.press/v202/yu23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yu23b/yu23b.pdf)** 

# Bag of Tricks for Training Data Extraction from Language Models
**题目:** 从语言模型中抽取训练数据的秘诀

**作者:** Weichen Yu, Tianyu Pang, Qian Liu, Chao Du, Bingyi Kang, Yan Huang, Min Lin, Shuicheng Yan

**Abstract:** With the advance of language models, privacy protection is receiving more attention. Training data extraction is therefore of great importance, as it can serve as a potential tool to assess privacy leakage. However, due to the difficulty of this task, most of the existing methods are proof-of-concept and still not effective enough. In this paper, we investigate and benchmark tricks for improving training data extraction using a publicly available dataset. Because most existing extraction methods use a pipeline of generating-then-ranking, i.e., generating text candidates as potential training data and then ranking them based on specific criteria, our research focuses on the tricks for both text generation (e.g., sampling strategy) and text ranking (e.g., token-level criteria). The experimental results show that several previously overlooked tricks can be crucial to the success of training data extraction. Based on the GPT-Neo 1.3B evaluation results, our proposed tricks outperform the baseline by a large margin in most cases, providing a much stronger baseline for future research. The code is available at https://github.com/weichen-yu/LM-Extraction.

**摘要:** 随着语言模型的发展,隐私保护正受到越来越多的关注。因此,培训数据提取是十分重要的,因为它可以作为评估隐私泄露的潜在工具。然而,由于这项任务的难度,大多数现有的方法都是概念的证明,而且仍不够有效。本论文中,我们研究并用公开的数据集来改进培训数据提取的基准技巧。基于GPT-Neo1.3B评价结果,我们建议的技巧在大多数情况下比基线高出很大幅度,为未来研究提供更强的基线。

**[Paper URL](https://proceedings.mlr.press/v202/yu23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yu23c/yu23c.pdf)** 

# Discover-Then-Rank Unlabeled Support Vectors in the Dual Space for Multi-Class Active Learning
**题目:** 多类主动学习双层空间中的无标签支持向量发现后排名

**作者:** Dayou Yu, Weishi Shi, Qi Yu

**Abstract:** We propose to approach active learning (AL) from a novel perspective of discovering and then ranking potential support vectors by leveraging the key properties of the dual space of a sparse kernel max-margin predictor. We theoretically analyze the change of a hinge loss in the dual form and provide both the upper and lower bounds that are deeply connected to the key geometric properties induced by the dual space, which then help us identify various types of important data samples for AL. These bounds inform the design of a novel sampling strategy that leverages class-wise evidence as a key vehicle, formed through an affine combination of dual variables and kernel evaluation. We construct two distinct types of sampling functions, including discovery and ranking. The former focuses on samples with low total evidence from all classes, which signifies their potential to support exploration; the latter exploits the current decision boundary to identify the most conflicting regions for sampling, aiming to further refine the decision boundary. These two functions, which are complementary to each other, are automatically arranged into a two-phase active sampling process that starts with the discovery and then transitions to the ranking of data points to most effectively balance exploration and exploitation. Experiments on various real-world data demonstrate the state-of-the-art AL performance achieved by our model.

**摘要:** 通过利用稀疏核最大边际预测器的双空间关键特性,从新的角度对主动学习(AL)进行研究,并将其定位为潜在支持向量。我们从理论上分析了双空间的铰链损伤的变化,并提供与双空间所诱导的关键几何特性紧密关联的上界和下界,从而帮助我们识别AL的各类重要数据样本。这些边界有助于设计一种新型的采样策略,利用类别证据作为关键工具,通过双变量和核评估的精细组合形成。前者集中于所有类别的低总证据样本,这表明它们有支持勘探的潜力;后者利用当前的决策界限来识别最冲突的采样区域,以进一步完善决策界限。这两个互补的功能,自动安排成两个阶段的主动采样过程,从发现开始,然后转移到数据点的排名,以最有效地平衡勘探和开发。

**[Paper URL](https://proceedings.mlr.press/v202/yu23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yu23d/yu23d.pdf)** 

# Long-Term Rhythmic Video Soundtracker
**题目:** 长期节奏视频追踪器

**作者:** Jiashuo Yu, Yaohui Wang, Xinyuan Chen, Xiao Sun, Yu Qiao

**Abstract:** We consider the problem of generating musical soundtracks in sync with rhythmic visual cues. Most existing works rely on pre-defined music representations, leading to the incompetence of generative flexibility and complexity. Other methods directly generating video-conditioned waveforms suffer from limited scenarios, short lengths, and unstable generation quality. To this end, we present Long-Term Rhythmic Video Soundtracker (LORIS), a novel framework to synthesize long-term conditional waveforms. Specifically, our framework consists of a latent conditional diffusion probabilistic model to perform waveform synthesis. Furthermore, a series of context-aware conditioning encoders are proposed to take temporal information into consideration for a long-term generation. Notably, we extend our model’s applicability from dances to multiple sports scenarios such as floor exercise and figure skating. To perform comprehensive evaluations, we establish a benchmark for rhythmic video soundtracks including the pre-processed dataset, improved evaluation metrics, and robust generative baselines. Extensive experiments show that our model generates long-term soundtracks with state-of-the-art musical quality and rhythmic correspondence. Codes are available at https://github.com/OpenGVLab/LORIS.

**摘要:** 我们考虑产生与节奏视觉符号同步的音乐声带的问题。大多数现有作品依赖于预定义的音乐表现,导致产生灵活性和复杂性的能力不足。直接生成视频条件波形的其他方法受到有限的场景、短长度和不稳定的生成质量的影响。为此目的,我们提出了长期节奏视频声带追踪器(LORIS),一种合成长期条件波形的新框架。具体而言,我们的框架由潜在的条件扩散概率模型组成,用于进行波形合成。此外,提出了一系列具有上下文意识的条件编码器,以考虑长期生成的时空信息。为了进行全面评估,我们建立了一个基于节奏的视频声带的基准,包括预处理的数据集、改进的评价指标和强有力的生成基准。广泛的实验表明,我们的模型能产生具有最先进的音乐质量和节奏的对应的长期声带。代码可浏览 https://github.com/OpenGVLab/LORIS。

**[Paper URL](https://proceedings.mlr.press/v202/yu23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yu23e/yu23e.pdf)** 

# Adversarial Parameter Attack on Deep Neural Networks
**题目:** 对深度神经网络的敌对参数攻击

**作者:** Lijia Yu, Yihan Wang, Xiao-Shan Gao

**Abstract:** The parameter perturbation attack is a safety threat to deep learning, where small parameter perturbations are made such that the attacked network gives wrong or desired labels of the adversary to specified inputs. However, such attacks could be detected by the user, because the accuracy of the attacked network will reduce and the network cannot work normally. To make the attack more stealthy, in this paper, the adversarial parameter attack is proposed, in which small perturbations to the parameters of the network are made such that the accuracy of the attacked network does not decrease much, but its robustness against adversarial example attacks becomes much lower. As a consequence, the attacked network performs normally on standard samples, but is much more vulnerable to adversarial attacks. The existence of nearly perfect adversarial parameters under $L_\infty$ norm and $L_0$ norm is proved under reasonable conditions. Algorithms are given which can be used to produce high quality adversarial parameters for the commonly used networks trained with various robust training methods, in that the robustness of the attacked networks decreases significantly when they are evaluated using various adversarial attack methods.

**摘要:** 参数扰乱攻击是对深度学习的一种安全威胁,其中小参数扰乱使得攻击的网络对指定输入给出错误或预期的敌方标签。然而,这种攻击可以由用户检测,因为攻击的网络的准确度会降低,而网络不能正常工作。为了使攻击更加隐形,本文提出了敌方参数攻击,其中对网络参数的小扰乱使得攻击的网络的准确度不会大幅降低,但其对敌方实例攻击的鲁棒性会大大降低。给出了用各种鲁棒训练方法训练的常用的网络产生高质量的敌对参数的算法,在采用各种敌对攻击方法评价网络时,攻击网络的鲁棒性大大降低。

**[Paper URL](https://proceedings.mlr.press/v202/yu23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yu23f/yu23f.pdf)** 

# CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models
**题目:** CodeIPPrompt:代码语言模型的知识产权侵权评估

**作者:** Zhiyuan Yu, Yuhao Wu, Ning Zhang, Chenguang Wang, Yevgeniy Vorobeychik, Chaowei Xiao

**Abstract:** Recent advances in large language models (LMs) have facilitated their ability to synthesize programming code. However, they have also raised concerns about intellectual property (IP) rights violations. Despite the significance of this issue, it has been relatively less explored. In this paper, we aim to bridge the gap by presenting CodeIPPrompt, a platform for automatic evaluation of the extent to which code language models may reproduce licensed programs. It comprises two key components: prompts constructed from a licensed code database to elicit LMs to generate IP-violating code, and a measurement tool to evaluate the extent of IP violation of code LMs. We conducted an extensive evaluation of existing open-source code LMs and commercial products and revealed the prevalence of IP violations in all these models. We further identified that the root cause is the substantial proportion of training corpus subject to restrictive licenses, resulting from both intentional inclusion and inconsistent license practice in the real world. To address this issue, we also explored potential mitigation strategies, including fine-tuning and dynamic token filtering. Our study provides a testbed for evaluating the IP violation issues of the existing code generation platforms and stresses the need for a better mitigation strategy.

**摘要:** 大型语言模型(LMs)的近期发展使得它们能够合成编程代码。然而,它们也引发了对知识产权侵犯的关注。尽管这一问题具有重要意义,但其研究程度相对较少。本论文的目的是通过介绍CodeIPPrompt,一种用于自动评估代码语言模型是否能够复制授权程序的平台,它包含两个关键组成部分:从授权代码数据库中生成LMs来生成侵犯知识产权的代码的提示,以及评估代码LMs的知识产权侵犯程度的测量工具。我们进一步指出,根本原因是受限制许可证约束的培训文体的大量比例,这是由于在现实世界中的意图包含和不一致的许可证做法造成的。为了解决这个问题,我们还探讨了潜在的缓解策略,包括微调和动态トークン筛选。

**[Paper URL](https://proceedings.mlr.press/v202/yu23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yu23g/yu23g.pdf)** 

# SeedGNN: Graph Neural Network for Supervised Seeded Graph Matching
**题目:** SeedGNN: Graph Neural Network for Supervised Seeded Graph Matching

**作者:** Liren Yu, Jiaming Xu, Xiaojun Lin

**Abstract:** There is a growing interest in designing Graph Neural Networks (GNNs) for seeded graph matching, which aims to match two unlabeled graphs using only topological information and a small set of seed nodes. However, most previous GNNs for this task use a semi-supervised approach, which requires a large number of seeds and cannot learn knowledge that is transferable to unseen graphs. In contrast, this paper proposes a new supervised approach that can learn from a training set how to match unseen graphs with only a few seeds. Our SeedGNN architecture incorporates several novel designs, inspired by theoretical studies of seeded graph matching: 1) it can learn to compute and use witness-like information from different hops, in a way that can be generalized to graphs of different sizes; 2) it can use easily-matched node-pairs as new seeds to improve the matching in subsequent layers. We evaluate SeedGNN on synthetic and real-world graphs and demonstrate significant performance improvements over both non-learning and learning algorithms in the existing literature. Furthermore, our experiments confirm that the knowledge learned by SeedGNN from training graphs can be generalized to test graphs of different sizes and categories.

**摘要:**  Graph Neural Networks (GNNs) 为播种图匹配设计有日益增长的兴趣,其目标是只使用拓扑信息和少数种子节点匹配两个未标记图。然而,大多数以前的GNNs 使用半监督方法,要求大量种子,不能学习可移植到未见图的知识。我们对SeedGNN的合成和实世界图进行评价,并证明在现有文献中对非学习和学习算法的性能有显著的改进。此外,我们的实验证实了SeedGNN从训练图中获得的知识可以推广到测试不同大小和类别的图。

**[Paper URL](https://proceedings.mlr.press/v202/yu23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yu23h/yu23h.pdf)** 

# Efficient and Equivariant Graph Networks for Predicting Quantum Hamiltonian
**题目:** 量子汉密尔顿定量预测的高效和等变图网络

**作者:** Haiyang Yu, Zhao Xu, Xiaofeng Qian, Xiaoning Qian, Shuiwang Ji

**Abstract:** We consider the prediction of the Hamiltonian matrix, which finds use in quantum chemistry and condensed matter physics. Efficiency and equivariance are two important, but conflicting factors. In this work, we propose a SE(3)-equivariant network, named QHNet, that achieves efficiency and equivariance. Our key advance lies at the innovative design of QHNet architecture, which not only obeys the underlying symmetries, but also enables the reduction of number of tensor products by 92%. In addition, QHNet prevents the exponential growth of channel dimension when more atom types are involved. We perform experiments on MD17 datasets, including four molecular systems. Experimental results show that our QHNet can achieve comparable performance to the state of the art methods at a significantly faster speed. Besides, our QHNet consumes 50% less memory due to its streamlined architecture. Our code is publicly available as part of the AIRS library (https://github.com/divelab/AIRS).

**摘要:** 我们考虑了汉密尔顿矩阵的预测,该矩阵在量子化学和压缩物质物理中的应用。效率和等价是两个重要,但相互冲突的因素。在这个工作中,我们提出了一个 SE(3)等价网络,名为QHNet,它实现效率和等价。我们的关键进展在于QHNet架构的创新设计,它不仅遵循基本的对称,而且能减少92%的 Tensor产品数量。此外,QHNet防止了更多的原子类型参与时的通道维度指数增长。我们对MD17数据集进行了实验,包括四个分子系统。实验结果表明,QHNet能够在更快速的速度达到与艺术方法相等的性能。此外,QHNet架构的合理化也减少了50%的内存。我们的代码是AIRS库的一部分(https://github.com/divelab/AIRS)。

**[Paper URL](https://proceedings.mlr.press/v202/yu23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yu23i/yu23i.pdf)** 

# On the Global Convergence of Risk-Averse Policy Gradient Methods with Expected Conditional Risk Measures
**题目:** 风险厌恶政策梯度方法与预期条件风险措施的全球融合

**作者:** Xian Yu, Lei Ying

**Abstract:** Risk-sensitive reinforcement learning (RL) has become a popular tool to control the risk of uncertain outcomes and ensure reliable performance in various sequential decision-making problems. While policy gradient methods have been developed for risk-sensitive RL, it remains unclear if these methods enjoy the same global convergence guarantees as in the risk-neutral case. In this paper, we consider a class of dynamic time-consistent risk measures, called Expected Conditional Risk Measures (ECRMs), and derive policy gradient updates for ECRM-based objective functions. Under both constrained direct parameterization and unconstrained softmax parameterization, we provide global convergence and iteration complexities of the corresponding risk-averse policy gradient algorithms. We further test risk-averse variants of REINFORCE and actor-critic algorithms to demonstrate the efficacy of our method and the importance of risk control.

**摘要:** 风险敏感强化学习(英语:Risk-sensitive reinforcement learning,简称RL)已成为控制不确定结果风险和确保各种连续决策问题的可靠性能的流行工具。虽然对风险敏感RL进行了政策梯度方法的开发,但仍不清楚这些方法是否具有与风险中立情况下相同的全球收敛性保证。本文考虑了一种动态时间一致风险措施,即预期条件风险措施(ECRMs),并为基于ECRM的客观函数导出政策梯度更新。在约束直接参数化和无约束软最大参数化两种情况下,我们提供了相应的风险厌恶政策梯度算法的全球收敛性和迭代复杂性。

**[Paper URL](https://proceedings.mlr.press/v202/yu23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yu23j/yu23j.pdf)** 

# Actor-Critic Alignment for Offline-to-Online Reinforcement Learning
**题目:** 非在线增强学习的演员-批判性整合

**作者:** Zishun Yu, Xinhua Zhang

**Abstract:** Deep offline reinforcement learning has recently demonstrated considerable promises in leveraging offline datasets, providing high-quality models that significantly reduce the online interactions required for fine-tuning. However, such a benefit is often diminished due to the marked state-action distribution shift, which causes significant bootstrap error and wipes out the good initial policy. Existing solutions resort to constraining the policy shift or balancing the sample replay based on their online-ness. However, they require online estimation of distribution divergence or density ratio. To avoid such complications, we propose deviating from existing actor-critic approaches that directly transfer the state-action value functions. Instead, we post-process them by aligning with the offline learned policy, so that the $Q$-values for actions outside the offline policy are also tamed. As a result, the online fine-tuning can be simply performed as in the standard actor-critic algorithms. We show empirically that the proposed method improves the performance of the fine-tuned robotic agents on various simulated tasks.

**摘要:** 深层非线性强化学习最近在利用非线性数据集中显示出重大的承诺,提供了高质量模型,大大降低了需要精细调制的在线交互。然而,这种利益往往由于显著的状态行动分布转变而减少,导致重大的启动陷阱误差和消灭良好的初始政策。现有的解决方案依靠约束政策转变或平衡样品重演,以其在线性为基础。然而,它们需要在线估计分布差异或密度比。结果,在线精确校正可以像标准的演员关键算法那样简单完成,实验表明,该方法能提高精确校正机器人在各种模拟任务中的表现。

**[Paper URL](https://proceedings.mlr.press/v202/yu23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yu23k/yu23k.pdf)** 

# Master-ASR: Achieving Multilingual Scalability and Low-Resource Adaptation in ASR with Modular Learning
**题目:**  master-ASR:实现模块化学习的多语言可扩展性和低资源适应性

**作者:** Zhongzhi Yu, Yang Zhang, Kaizhi Qian, Cheng Wan, Yonggan Fu, Yongan Zhang, Yingyan Celine Lin

**Abstract:** Despite the impressive performance recently achieved by automatic speech recognition (ASR), we observe two primary challenges that hinder its broader applications: (1) The difficulty of introducing scalability into the model to support more languages with limited training, inference, and storage overhead; (2) The low-resource adaptation ability that enables effective low-resource adaptation while avoiding over fitting and catastrophic forgetting issues. Inspired by recent findings, we hypothesize that we can address the above challenges with modules widely shared across languages. To this end, we propose an ASR framework, dubbed Master-ASR, that, for the first time, simultaneously achieves strong multilingual scalability and low-resource adaptation ability thanks to its modularize-then-assemble strategy. Specifically, Master-ASR learns a small set of generalizable sub-modules and adaptively assembles them for different languages to reduce the multilingual overhead and enable effective knowledge transfer for low-resource adaptation. Extensive experiments and visualizations demonstrate that Master-ASR can effectively discover language similarity and improve multilingual and low-resource ASR performance over state-of-the-art (SOTA) methods, e.g., under multilingual-ASR, our framework achieves a 0.13∼2.41 lower character error rate (CER) with 30% smaller inference overhead over SOTA solutions on multilingual ASR and a comparable CER with nearly 100 times fewer trainable parameters over SOTA solutions on low-resource tuning, respectively.

**摘要:** 尽管自动语音识别(ASR)最近取得了令人印象深刻的性能,但我们观察到两个主要挑战阻碍其广泛应用:(一)在模型中引入可扩展性以支持更多语言的难点,包括有限的训练、推理和存储费用;(二)通过低资源的适应能力实现有效的低资源的适应,同时避免过度适应和灾难性的遗忘问题。具体而言,Master-ASR学习了少量可推广的子模块,并以适应性的方式组装它们用于不同的语言,以减少多语言的开支,并为低资源的适应提供有效的知识转移。广泛的实验和可视化表明,Master-ASR能够有效地发现语言相似性并改善多语言和低资源的ASR性能,比最先进的(SOTA)方法,例如,在多语言-ASR下,我们的框架达到0.13~2.41低字符误差率(CER)和30%小推导开支比多语言ASR的SOTA解决方案,以及比低资源调制的SOTA解决方案的几乎100倍小训练参数的可比CER。

**[Paper URL](https://proceedings.mlr.press/v202/yu23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yu23l/yu23l.pdf)** 

# Coordinate Descent Methods for Fractional Minimization
**题目:** 分离微化坐标起始方法

**作者:** Ganzhao Yuan

**Abstract:** We consider a class of structured fractional minimization problems, in which the numerator part of the objective is the sum of a differentiable convex function and a convex non-smooth function, while the denominator part is a convex or concave function. This problem is difficult to solve since it is non-convex. By exploiting the structure of the problem, we propose two Coordinate Descent (CD) methods for solving this problem. The proposed methods iteratively solve a one-dimensional subproblem globally, and they are guaranteed to converge to coordinate-wise stationary points. In the case of a convex denominator, under a weak locally bounded non-convexity condition, we prove that the optimality of coordinate-wise stationary point is stronger than that of the standard critical point and directional point. Under additional suitable conditions, CD methods converge Q-linearly to coordinate-wise stationary points. In the case of a concave denominator, we show that any critical point is a global minimum, and CD methods converge to the global minimum with a sublinear convergence rate. We demonstrate the applicability of the proposed methods to some machine learning and signal processing models. Our experiments on real-world data have shown that our method significantly and consistently outperforms existing methods in terms of accuracy.

**摘要:** 我们考虑了一种结构化微分化问题的类别,其中目标的数值部分是可微分凸函数和凸非凹函数的总数,而变量部分是凸或凹函数。这个问题很难解决,因为它是非凸。通过利用问题的结构,我们提出了两个坐标起始(CD)方法来解决这个问题。对凸变量进行分析,表明任何临界点是全球最小点,CD方法以次线性收敛速度收敛到全球最小点。我们证明了该方法对某些机器学习和信号处理模型的适用性。我们对实物数据的实验表明,该方法在准确性方面大大和连续地超过现有方法。

**[Paper URL](https://proceedings.mlr.press/v202/yuan23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yuan23a/yuan23a.pdf)** 

# On the Power of Foundation Models
**题目:** 基础模型的力量

**作者:** Yang Yuan

**Abstract:** With infinitely many high-quality data points, infinite computational power, an infinitely large foundation model with a perfect training algorithm and guaranteed zero generalization error on the pretext task, can the model be used for everything? This question cannot be answered by the existing theory of representation, optimization or generalization, because the issues they mainly investigate are assumed to be nonexistent here. In this paper, we show that category theory provides powerful machinery to answer this question. We have proved three results. The first one limits the power of prompt-based learning, saying that the model can solve a downstream task with prompts if and only if the task is representable. The second one says fine tuning does not have this limit, as a foundation model with the minimum required power (up to symmetry) can theoretically solve downstream tasks for the category defined by pretext task, with fine tuning and enough resources. Our final result can be seen as a new type of generalization theorem, showing that the foundation model can generate unseen objects from the target category (e.g., images) using the structural information from the source category (e.g., texts). Along the way, we provide a categorical framework for supervised and self-supervised learning, which might be of independent interest.

**摘要:** 由于它们主要研究的问题被认为是不存在的,因此,不能由现有的表示、优化或推广理论来回答这个问题。在本文中,我们展示了类别理论为回答这个问题提供了强大的机器。我们已经证明了三个结果。第一项限制了基于提示的学习的权力,说该模型可以用提示解决下游任务,如果且仅当该任务可表示。第二项说微调没有这个限制,因为一个具有最小要求功率(至对称)的类别模型可以理论上解决下游任务,用微调和足够的资源。最后的结果可以被视为一种新的一般化定理,表明基础模型可以利用源类(例如文本)的结构信息,从目标类(例如图像)生成未知对象。

**[Paper URL](https://proceedings.mlr.press/v202/yuan23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yuan23b/yuan23b.pdf)** 

# Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement Learning
**题目:** 深入强化学习中自动内在奖励的开发

**作者:** Mingqi Yuan, Bo Li, Xin Jin, Wenjun Zeng

**Abstract:** We present AIRS: Automatic Intrinsic Reward Shaping that intelligently and adaptively provides high-quality intrinsic rewards to enhance exploration in reinforcement learning (RL). More specifically, AIRS selects shaping function from a predefined set based on the estimated task return in real-time, providing reliable exploration incentives and alleviating the biased objective problem. Moreover, we develop an intrinsic reward toolkit to provide efficient and reliable implementations of diverse intrinsic reward approaches. We test AIRS on various tasks of MiniGrid, Procgen, and DeepMind Control Suite. Extensive simulation demonstrates that AIRS can outperform the benchmarking schemes and achieve superior performance with simple architecture.

**摘要:** 我们介绍AIRS:自动内在奖励形状,智能和适应性地提供高质量内在奖励以增强增强学习(RL)的探索功能。更具体地说,AIRS从预定义的集合中选择基于估计任务回报的形状功能,提供可靠的探索激励和减轻偏见的客观问题。此外,我们开发了一个内在奖励工具包,以提供有效的和可靠的实现各种内在奖励方法。我们测试AIRS在MiniGrid、Procgen和DeepMind控制套件的各个任务上。

**[Paper URL](https://proceedings.mlr.press/v202/yuan23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yuan23c/yuan23c.pdf)** 

# Traversing Between Modes in Function Space for Fast Ensembling
**题目:** 快速仿真功能空间中的模式间的跟踪

**作者:** Eunggu Yun, Hyungi Lee, Giung Nam, Juho Lee

**Abstract:** Deep ensemble is a simple yet powerful way to improve the performance of deep neural networks. Under this motivation, recent works on mode connectivity have shown that parameters of ensembles are connected by low-loss subspaces, and one can efficiently collect ensemble parameters in those subspaces. While this provides a way to efficiently train ensembles, for inference, multiple forward passes should still be executed using all the ensemble parameters, which often becomes a serious bottleneck for real-world deployment. In this work, we propose a novel framework to reduce such costs. Given a low-loss subspace connecting two modes of a neural network, we build an additional neural network that predicts the output of the original neural network evaluated at a certain point in the low-loss subspace. The additional neural network, which we call a “bridge”, is a lightweight network that takes minimal features from the original network and predicts outputs for the low-loss subspace without forward passes through the original network. We empirically demonstrate that we can indeed train such bridge networks and significantly reduce inference costs with the help of bridge networks.

**摘要:** 深度集群是提高深度神经网络性能的一种简单而有力的途径。在这一动机下,最近的模式连接性研究表明,集群的参数是由低损子空间连接起来,并且在这些子空间中可以有效地收集集群参数。虽然这提供了有效的训练集群的方法,但对于推断而言,多个向前通行仍应使用所有集群参数执行,经常成为现实部署的严重瓶颈。额外的神经网络,我们称之为“桥梁”,是一种轻型网络,它从原始网络中获取最小特征,并且在没有前行通过原始网络的情况下预测低损次空间的输出。我们实验证明,通过桥梁网络,我们确实能够训练这些桥梁网络,大大降低推导成本。

**[Paper URL](https://proceedings.mlr.press/v202/yun23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/yun23a/yun23a.pdf)** 

# Conformal Prediction with Missing Values
**题目:** 与缺失值的一致预测

**作者:** Margaux Zaffran, Aymeric Dieuleveut, Julie Josse, Yaniv Romano

**Abstract:** Conformal prediction is a theoretically grounded framework for constructing predictive intervals. We study conformal prediction with missing values in the covariates – a setting that brings new challenges to uncertainty quantification. We first show that the marginal coverage guarantee of conformal prediction holds on imputed data for any missingness distribution and almost all imputation functions. However, we emphasize that the average coverage varies depending on the pattern of missing values: conformal methods tend to construct prediction intervals that under-cover the response conditionally to some missing patterns. This motivates our novel generalized conformalized quantile regression framework, missing data augmentation, which yields prediction intervals that are valid conditionally to the patterns of missing values, despite their exponential number. We then show that a universally consistent quantile regression algorithm trained on the imputed data is Bayes optimal for the pinball risk, thus achieving valid coverage conditionally to any given data point. Moreover, we examine the case of a linear model, which demonstrates the importance of our proposal in overcoming the heteroskedasticity induced by missing values. Using synthetic and data from critical care, we corroborate our theory and report improved performance of our methods.

**摘要:** 对应预测是建立预测间隔的理论基础框架。我们研究了对应预测在共变量中缺失值的对应预测 — — 这是一种对不确定性定量化带来新挑战的设置。首先,我们证明了对应预测的边界覆盖保证在任何缺失分布和几乎所有归因函数的推算数据上。然而,我们强调,平均覆盖范围取决于缺失值的模式:对应方法倾向于构造对某些缺失值的响应条件下覆盖的预测间隔。然后证明,在计算数据上训练的普遍一致的量子回归算法是贝伊斯最佳的 pinball风险,从而达到任何数据点的有效覆盖条件。此外,我们研究了线性模型的案例,证明了我们提出的克服缺失值引起的异构性的重要性。

**[Paper URL](https://proceedings.mlr.press/v202/zaffran23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zaffran23a/zaffran23a.pdf)** 

# KDEformer: Accelerating Transformers via Kernel Density Estimation
**题目:** KDEformer:通过核密度估计加速变换器

**作者:** Amir Zandieh, Insu Han, Majid Daliri, Amin Karbasi

**Abstract:** Dot-product attention mechanism plays a crucial role in modern deep architectures (e.g., Transformer) for sequence modeling, however, naïve exact computation of this model incurs quadratic time and memory complexities in sequence length, hindering the training of long-sequence models. Critical bottlenecks are due to the computation of partition functions in the denominator of softmax function as well as the multiplication of the softmax matrix with the matrix of values. Our key observation is that the former can be reduced to a variant of the kernel density estimation (KDE) problem, and an efficient KDE solver can be further utilized to accelerate the latter via subsampling-based fast matrix products. Our proposed KDEformer can approximate the attention in sub-quadratic time with provable spectral norm bounds, while all prior results merely provide entry-wise error bounds. Empirically, we verify that KDEformer outperforms other attention approximations in terms of accuracy, memory, and arithmetic operations on various pre-trained models. For instance, on BigGAN image generation we achieve better generative scores than the exact computation with over 4× speedup. For ImageNet classification with T2T-ViT, KDEformer shows over 18× speedup while the accuracy drop is less than 0.5%.

**摘要:** 点产物注意机制在现代深层架构(例如变换器)中对序列建模起关键作用,然而,对该模型的 naiv 准确计算导致序列长度的二次时间和内存复杂性,阻碍了长序列模型的训练。关键性瓶颈是由于软max函数的名词中的分区函数的计算以及软max矩阵与值矩阵的乘法。我们的关键观察是,前者可以被降低到核密度估计(KDE)问题的一个变量,并且一个高效的KDE求解器可以进一步利用以通过分样基础的快速矩阵产品加速后者。通过实验,我们验证了KDEformer在不同预训练模型的精度、内存和算术操作上的表现优于其他注意近似。例如,在BigGAN图像生成中,我们比4×加速度的精确计算取得更好的生成分数。

**[Paper URL](https://proceedings.mlr.press/v202/zandieh23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zandieh23a/zandieh23a.pdf)** 

# Bayesian Estimation of Differential Privacy
**题目:** 贝叶斯估算微分隐私

**作者:** Santiago Zanella-Beguelin, Lukas Wutschitz, Shruti Tople, Ahmed Salem, Victor Rühle, Andrew Paverd, Mohammad Naseri, Boris Köpf, Daniel Jones

**Abstract:** Algorithms such as Differentially Private SGD enable training machine learning models with formal privacy guarantees. However, because these guarantees hold with respect to unrealistic adversaries, the protection afforded against practical attacks is typically much better. An emerging strand of work empirically estimates the protection afforded by differentially private training as a confidence interval for the privacy budget $\hat{\varepsilon}$ spent with respect to specific threat models. Existing approaches derive confidence intervals for $\hat{\varepsilon}$ from confidence intervals for false positive and false negative rates of membership inference attacks, which requires training an impractically large number of models to get intervals that can be acted upon. We propose a novel, more efficient Bayesian approach that brings privacy estimates within the reach of practitioners. Our approach reduces sample size by computing a posterior for $\hat{\varepsilon}$ (not just a confidence interval) from the joint posterior of the false positive and false negative rates of membership inference attacks. We implement an end-to-end system for privacy estimation that integrates our approach and state-of-the-art membership inference attacks, and evaluate it on text and vision classification tasks. For the same number of samples, we see a reduction in interval width of up to 40% compared to prior work.

**摘要:** 不同的私人SGD等算法使培训机器学习模型具有正式的隐私保证。然而,由于这些保证对于不现实的对手保持,对实际攻击提供的保护通常比实际攻击要好得多。一个新兴的工作领域 empirically估计了由不同的私人培训提供的保护,作为隐私预算 $\hat{\varepsilon}$用于具体威胁模型的信任间隔。现有的方法从假正和假负成员推理攻击的信任间隔中导出$\hat{\varepsilon}$的信任间隔,这要求训练不实际的大量模型,以获得可以采取的间隔。我们的方法通过计算 membership inference 攻击的错误正负率的联合后端后端 $\hat{\varepsilon}$ 的 $\hat{\varepsilon}$ 的后端(不仅仅是信任间隔)来减少样品的大小。我们实施了集成了我们的方法和最先进的 membership inference 攻击的end-to-end系统,并对其文本和视觉分类任务进行评估。

**[Paper URL](https://proceedings.mlr.press/v202/zanella-beguelin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zanella-beguelin23a/zanella-beguelin23a.pdf)** 

# When is Realizability Sufficient for Off-Policy Reinforcement Learning?
**题目:** 何时可为非政策强化学习提供可行性?

**作者:** Andrea Zanette

**Abstract:** Understanding when reinforcement learning algorithms can make successful off-policy predictions—and when the may fail to do so–remains an open problem. Typically, model-free algorithms for reinforcement learning are analyzed under a condition called Bellman completeness when they operate off-policy with function approximation, unless additional conditions are met. However, Bellman completeness is a requirement that is much stronger than realizability and that is deemed to be too strong to hold in practice. In this work, we relax this structural assumption and analyze the statistical complexity of off-policy reinforcement learning when only realizability holds for the prescribed function class. We establish finite-sample guarantees for off-policy reinforcement learning that are free of the approximation error term known as inherent Bellman error, and that depend on the interplay of three factors. The first two are well known: they are the metric entropy of the function class and the concentrability coefficient that represents the cost of learning off-policy. The third factor is new, and it measures the violation of Bellman completeness, namely the mis-alignment between the chosen function class and its image through the Bellman operator. Our analysis directly applies to the solution found by temporal difference algorithms when they converge.

**摘要:** 理解增强学习算法能够做出成功 off-policy 预测时-以及当它们可能失败时-仍然是一个开放问题。 通常,增强学习的模型自由算法在执行 off-policy 的函数近似时,在 Bellman 完全性条件下进行分析,除非满足额外条件。 然而, Bellman 完全性要求比实现性要强得多,并且认为在实践中是太强,因此我们放松了这一结构假设,并分析了 Off-policy 增强学习的统计复杂性,只有实现性为指定函数类有效。第一个两个是众所周知的:它们是函数类的度量熵和反映非政策学习成本的集中性系数。第三个因素是新的,它测量了贝尔曼完全性的侵犯,即通过贝尔曼操作器对选定函数类及其图像的误配。

**[Paper URL](https://proceedings.mlr.press/v202/zanette23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zanette23a/zanette23a.pdf)** 

# On Distribution Dependent Sub-Logarithmic Query Time of Learned Indexing
**题目:** 学习索引的分布依赖子逻辑查询时间

**作者:** Sepanta Zeighami, Cyrus Shahabi

**Abstract:** A fundamental problem in data management is to find the elements in an array that match a query. Recently, learned indexes are being extensively used to solve this problem, where they learn a model to predict the location of the items in the array. They are empirically shown to outperform non-learned methods (e.g., B-trees or binary search that answer queries in $O(\log n)$ time) by orders of magnitude. However, success of learned indexes has not been theoretically justified. Only existing attempt shows the same query time of $O(\log n)$, but with a constant factor improvement in space complexity over non-learned methods, under some assumptions on data distribution. In this paper, we significantly strengthen this result, showing that under mild assumptions on data distribution, and the same space complexity as non-learned methods, learned indexes can answer queries in $O(\log\log n)$ expected query time. We also show that allowing for slightly larger but still near-linear space overhead, a learned index can achieve $O(1)$ expected query time. Our results theoretically prove learned indexes are orders of magnitude faster than non-learned methods, theoretically grounding their empirical success.

**摘要:** 在数据管理中,一个基本问题是找到匹配查询的元素。最近,学习索引被广泛用于解决这一问题,它们学习模型来预测索引中的项的位置。它们在实证上被显示超过非学习方法(例如B树或二进制搜索以满足$O(\log n)$时间的查询)以大小顺序。然而,学习索引的成功从理论上没有得到证明。只有现有的尝试显示$O(\log n)$的相同查询时间,但与非学习方法相比空间复杂度的恒常因子改进,在数据分布的一些假设下。我们还证明,允许略大但仍接近线性空间的顶部,学习指数可以达到预期查询时间$O(1)$。我们的结果从理论上证明,学习指数比非学习方法的速度大很多,理论上证明了它们的实证成功。

**[Paper URL](https://proceedings.mlr.press/v202/zeighami23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zeighami23a/zeighami23a.pdf)** 

# Sequential Counterfactual Risk Minimization
**题目:** 序列反事实风险减小

**作者:** Houssam Zenati, Eustache Diemert, Matthieu Martin, Julien Mairal, Pierre Gaillard

**Abstract:** Counterfactual Risk Minimization (CRM) is a framework for dealing with the logged bandit feedback problem, where the goal is to improve a logging policy using offline data. In this paper, we explore the case where it is possible to deploy learned policies multiple times and acquire new data. We extend the CRM principle and its theory to this scenario, which we call "Sequential Counterfactual Risk Minimization (SCRM)." We introduce a novel counterfactual estimator and identify conditions that can improve the performance of CRM in terms of excess risk and regret rates, by using an analysis similar to restart strategies in accelerated optimization methods. We also provide an empirical evaluation of our method in both discrete and continuous action settings, and demonstrate the benefits of multiple deployments of CRM.

**摘要:** 反事实风险微化(英语:Contrafactual Risk Minimization,缩写为CRM)是处理记录带子反馈问题的一个框架,其目标是利用非线性数据改进记录政策。本文探讨了在可部署学问政策多次并获取新数据的情况下,我们将CRM原则及其理论扩展到这个场景,我们称之为“连续反事实风险微化”(英语:Sequential Counterfactual Risk Minimization,缩写为SCRM)。我们介绍了一种新颖的反事实估计器,并通过一种类似加速优化方法重新启动策略的分析,确定能够提高CRM在风险和遗憾率方面的性能的条件。

**[Paper URL](https://proceedings.mlr.press/v202/zenati23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zenati23a/zenati23a.pdf)** 

# LookupFFN: Making Transformers Compute-lite for CPU inference
**题目:** LookupFFN:为CPU推理制作变换器计算-lite

**作者:** Zhanpeng Zeng, Michael Davies, Pranav Pulijala, Karthikeyan Sankaralingam, Vikas Singh

**Abstract:** While GPU clusters are the de facto choice for training large deep neural network (DNN) models today, several reasons including ease of workflow, security and cost have led to efforts investigating whether CPUs may be viable for inference in routine use in many sectors of the industry. But the imbalance between the compute capabilities of GPUs and CPUs is huge. Motivated by these considerations, we study a module which is a workhorse within modern DNN architectures, GEMM based Feed Forward Networks (FFNs), and assess the extent to which it can be made compute- (or FLOP-) lite. Specifically, we propose an alternative formulation (we call it LookupFFN) to GEMM based FFNs inspired by the recent studies of using Locality Sensitive Hashing (LSH) to approximate FFNs. Our formulation recasts most essential operations as a memory look-up, leveraging the trade-off between the two resources on any platform: compute and memory (since CPUs offer it in abundance). For RoBERTa language model pretraining, our formulation achieves similar performance compared to GEMM based FFNs, while dramatically reducing the required FLOP. Our development is complemented with a detailed hardware profiling of strategies that will maximize efficiency – not just on contemporary hardware but on products that will be offered in the near/medium term future. Code is avaiable at https://github.com/mlpen/LookupFFN.

**摘要:** 尽管GPU集群是训练大型深度神经网络(DNN)模型的实际选择,但一些原因包括工作流程、安全和成本的简便,导致研究CPU是否能够在工业的许多部门进行常规使用中推导。但GPU和CPU的计算能力之间的不平衡是巨大的。针对RoBERTa语言模型预训练,我们的公式与GEMM基于FFN相比具有相似的性能,同时大幅减少所需的FLOP。我们开发的详细的硬件配置策略将最大化效率--不仅在当代硬件上,而且在 near/medium term 未来将提供的产品上。

**[Paper URL](https://proceedings.mlr.press/v202/zeng23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zeng23a/zeng23a.pdf)** 

# Attribute-Efficient PAC Learning of Low-Degree Polynomial Threshold Functions with Nasty Noise
**题目:** 不良噪声低级多项式阈值函数属性高效的PAC学习

**作者:** Shiwei Zeng, Jie Shen

**Abstract:** The concept class of low-degree polynomial threshold functions (PTFs) plays a fundamental role in machine learning. In this paper, we study PAC learning of $K$-sparse degree-$d$ PTFs on $\mathbb{R}^n$, where any such concept depends only on $K$ out of $n$ attributes of the input. Our main contribution is a new algorithm that runs in time $({nd}/{\epsilon})^{O(d)}$ and under the Gaussian marginal distribution, PAC learns the class up to error rate $\epsilon$ with $O(\frac{K^{4d}}{\epsilon^{2d}} \cdot \log^{5d} n)$ samples even when an $\eta \leq O(\epsilon^d)$ fraction of them are corrupted by the nasty noise of Bshouty et al. (2002), possibly the strongest corruption model. Prior to this work, attribute-efficient robust algorithms are established only for the special case of sparse homogeneous halfspaces. Our key ingredients are: 1) a structural result that translates the attribute sparsity to a sparsity pattern of the Chow vector under the basis of Hermite polynomials, and 2) a novel attribute-efficient robust Chow vector estimation algorithm which uses exclusively a restricted Frobenius norm to either certify a good approximation or to validate a sparsity-induced degree-$2d$ polynomial as a filter to detect corrupted samples.

**摘要:** 低级多项式阈值函数的概念类(PTFs)在机器学习中起着根本作用。本文研究了$K$-sparse degree-$d$ PTFs的PAC学习在$\mathbb{R}^n$上,其中任何概念只依赖于输入的$n$属性中$K$。我们的主要贡献是运行时间$({nd}/{\epsilon})^{O(d)}$和高斯边界分布下,PAC学习到误差率$\epsilon$的类,即使其中$\eta \leq O(\epsilon^d)$部分被Bshouty等人(2002年)的恶臭噪声破坏,这可能是最强的破坏模型。我们的关键成分是: 1)一个基于赫米特多项式的结构结果,将属性稀疏转化为肖向量稀疏模式,以及2)一种新的属性效率强的肖向量估计算法,该算法只使用有限的弗罗贝尼乌斯规范,以证明良好近似,或作为滤波器 validate a sparsity-induced degree-$2d$ polynomial to detect corrupted samples。

**[Paper URL](https://proceedings.mlr.press/v202/zeng23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zeng23b/zeng23b.pdf)** 

# Generative Graph Dictionary Learning
**题目:** 生成图辞典学习

**作者:** Zhichen Zeng, Ruike Zhu, Yinglong Xia, Hanqing Zeng, Hanghang Tong

**Abstract:** Dictionary learning, which approximates data samples by a set of shared atoms, is a fundamental task in representation learning. However, dictionary learning over graphs, namely graph dictionary learning (GDL), is much more challenging than vectorial data as graphs lie in disparate metric spaces. The sparse literature on GDL formulates the problem from the reconstructive view and often learns linear graph embeddings with a high computational cost. In this paper, we propose a Fused Gromov-Wasserstein (FGW) Mixture Model named FraMe to address the GDL problem from the generative view. Equipped with the graph generation function based on the radial basis function kernel and FGW distance, FraMe generates nonlinear embedding spaces, which, as we theoretically proved, provide a good approximation of the original graph spaces. A fast solution is further proposed on top of the expectation-maximization algorithm with guaranteed convergence. Extensive experiments demonstrate the effectiveness of the obtained node and graph embeddings, and our algorithm achieves significant improvements over the state-of-the-art methods.

**摘要:** 字典学习是表示学习的一个基本任务,它通过一个集合的共享原子来近似数据样本。然而,对图表的字典学习,即图表字典学习(GDL)比向量数据更困难,因为图表存在在不同度量空间中。GDL的稀疏文献从建构视角来拟定问题,并经常学习高计算成本的线性图形嵌入。本文提出了一种FusedGromov-Wasserstein(FGW)混合模型,名为FraMe,以从生成视角解决GDL问题。广泛的实验证明了得到的节点和图形嵌入的有效性,我们的算法在最先进的方法上取得了显著的改进。

**[Paper URL](https://proceedings.mlr.press/v202/zeng23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zeng23c/zeng23c.pdf)** 

# Stabilizing Transformer Training by Preventing Attention Entropy Collapse
**题目:** 防止注意力熵崩溃稳定变换器训练

**作者:** Shuangfei Zhai, Tatiana Likhomanenko, Etai Littwin, Dan Busbridge, Jason Ramapuram, Yizhe Zhang, Jiatao Gu, Joshua M. Susskind

**Abstract:** Training stability is of great importance to Transformers. In this work, we investigate the training dynamics of Transformers by examining the evolution of the attention layers. In particular, we track the attention entropy for each attention head during the course of training, which is a proxy for model sharpness. We identify a common pattern across different architectures and tasks, where low attention entropy is accompanied by high training instability, which can take the form of oscillating loss or divergence. We denote the pathologically low attention entropy, corresponding to highly concentrated attention scores, as $\textit{entropy collapse}$. As a remedy, we propose $\sigma$Reparam, a simple and efficient solution where we reparametrize all linear layers with spectral normalization and an additional learned scalar. We demonstrate that $\sigma$Reparam successfully prevents entropy collapse in the attention layers, promoting more stable training. Additionally, we prove a tight lower bound of the attention entropy, which decreases exponentially fast with the spectral norm of the attention logits, providing additional motivation for our approach. We conduct experiments with $\sigma$Reparam on image classification, image self-supervised learning, machine translation, speech recognition, and language modeling tasks. We show that $\sigma$Reparam provides stability and robustness with respect to the choice of hyperparameters, going so far as enabling training (a) a Vision Transformer to competitive performance without warmup, weight decay, layer normalization or adaptive optimizers; (b) deep architectures in machine translation and (c) speech recognition to competitive performance without warmup and adaptive optimizers. Code is available at https://github.com/apple/ml-sigma-reparam.

**摘要:** 训练稳定性对变换器具有重要意义。在这项工作中,我们通过研究注意力层的演化来研究变换器的训练动力学。特别是,在训练过程中,我们跟踪每个注意力头的注意力熵,这是模型敏锐的代理。我们识别在不同的架构和任务中常见的模式,其中低注意力熵伴随高训练不稳定性,这可以形成振荡损失或偏差。我们指出病理低注意力熵,与高度集中注意力分数相符,如$\textit{entropy collapse}$。此外,我们证明了注意力熵的较低极限,以注意力逻辑的光谱规范快速降低,为我们的方法提供了额外的动力。我们对图像分类、图像自我监督学习、机器翻译、语音识别和语言建模任务进行了实验。我们显示,$\sigma$Reparam提供了对超参数的选择的稳定性和鲁棒性,使训练能够(a)使一个视觉变换器能够在没有加热、重量衰变、层正常化或适应性优化的情况下进行竞争性性能的训练;(b)在机器翻译中进行深层架构和(c)使语音识别能够在没有加热和适应性优化的情况下进行竞争性性能的训练。

**[Paper URL](https://proceedings.mlr.press/v202/zhai23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhai23a/zhai23a.pdf)** 

# Offline Learning in Markov Games with General Function Approximation
**题目:** 与一般函数近似的马可夫游戏的在线学习

**作者:** Yuheng Zhang, Yu Bai, Nan Jiang

**Abstract:** We study offline multi-agent reinforcement learning (RL) in Markov games, where the goal is to learn an approximate equilibrium—such as Nash equilibrium and (Coarse) Correlated Equilibrium—from an offline dataset pre-collected from the game. Existing works consider relatively restricted tabular or linear models and handle each equilibria separately. In this work, we provide the first framework for sample-efficient offline learning in Markov games under general function approximation, handling all 3 equilibria in a unified manner. By using Bellman-consistent pessimism, we obtain interval estimation for policies’ returns, and use both the upper and the lower bounds to obtain a relaxation on the gap of a candidate policy, which becomes our optimization objective. Our results generalize prior works and provide several additional insights. Importantly, we require a data coverage condition that improves over the recently proposed “unilateral concentrability”. Our condition allows selective coverage of deviation policies that optimally trade-off between their greediness (as approximate best responses) and coverage, and we show scenarios where this leads to significantly better guarantees. As a new connection, we also show how our algorithmic framework can subsume seemingly different solution concepts designed for the special case of two-player zero-sum games.

**摘要:** 我们研究了马可夫游戏中的多代理强化学习(RL),目标是从从游戏上预先收集的在线数据集中学习近似平衡(如纳什平衡和(粗)相关平衡)。现有的工作考虑相对有限的表格或线性模型,并分别处理每个平衡。在这个工作中,我们为马可夫游戏的样本有效在线学习提供第一个框架,在一般函数近似下处理所有3个平衡,以统一的方式。我们的条件允许选择性覆盖偏差策略,将它们的贪婪(作为近似最佳响应)和覆盖之间进行最佳的交换,并且我们展示了可能导致显著更好的保证的场景。作为一种新的连接,我们还展示了我们的算法框架能够将看似不同的解决方案概念纳入双人零总游戏的特殊情况。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23a/zhang23a.pdf)** 

# Learning useful representations for shifting tasks and distributions
**题目:** 学习用于转移任务和分配的有用的表示

**作者:** Jianyu Zhang, Leon Bottou

**Abstract:** Does the dominant approach to learn representations (as a side effect of optimizing an expected cost for a single training distribution) remain a good approach when we are dealing with multiple distributions? Our thesis is that such scenarios are better served by representations that are richer than those obtained with a single optimization episode. We support this thesis with simple theoretical arguments and with experiments utilizing an apparently näive ensembling technique: concatenating the representations obtained from multiple training episodes using the same data, model, algorithm, and hyper-parameters, but different random seeds. These independently trained networks perform similarly. Yet, in a number of scenarios involving new distributions, the concatenated representation performs substantially better than an equivalently sized network trained with a single training run. This proves that the representations constructed by multiple training episodes are in fact different. Although their concatenation carries little additional information about the training task under the training distribution, it becomes substantially more informative when tasks or distributions change. Meanwhile, a single training episode is unlikely to yield such a redundant representation because the optimization process has no reason to accumulate features that do not incrementally improve the training performance.

**摘要:** 当处理多个分布时,学习表达式的主导方法(作为优化一个单个训练分布的预期成本的副作用)是否仍然是一个良好的方法?我们的论文是这样的场景比与单个优化事件取得的更丰富的表达式更好。我们支持这一论文的简单理论论据和利用一个明显的仿真技术进行实验:用相同的数据、模型、算法和超参数,但不同的随机种子,将从多个训练事件中获得的表达式合并。这些独立训练的网络性能类似。然而,在涉及新的分布的场景中,合并的表达式比一个与单个训练运行相等大小的网络表现得更好。尽管它们的结合在训练分布下对训练任务的额外信息很少,但当任务或分配发生变化时,它会变得更加有意义。同时,一个训练 epizod不太可能产生这样的冗余的表示,因为优化过程没有理由积累那些不会逐渐提高训练性能的特征。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23b/zhang23b.pdf)** 

# Nonparametric Iterative Machine Teaching
**题目:** 非参数迭代机器教学

**作者:** Chen Zhang, Xiaofeng Cao, Weiyang Liu, Ivor Tsang, James Kwok

**Abstract:** In this paper, we consider the problem of Iterative Machine Teaching (IMT), where the teacher provides examples to the learner iteratively such that the learner can achieve fast convergence to a target model. However, existing IMT algorithms are solely based on parameterized families of target models. They mainly focus on convergence in the parameter space, resulting in difficulty when the target models are defined to be functions without dependency on parameters. To address such a limitation, we study a more general task – Nonparametric Iterative Machine Teaching (NIMT), which aims to teach nonparametric target models to learners in an iterative fashion. Unlike parametric IMT that merely operates in the parameter space, we cast NIMT as a functional optimization problem in the function space. To solve it, we propose both random and greedy functional teaching algorithms. We obtain the iterative teaching dimension (ITD) of the random teaching algorithm under proper assumptions, which serves as a uniform upper bound of ITD in NIMT. Further, the greedy teaching algorithm has a significantly lower ITD, which reaches a tighter upper bound of ITD in NIMT. Finally, we verify the correctness of our theoretical findings with extensive experiments in nonparametric scenarios.

**摘要:** 本文研究了Iterative Machine Teaching(IMT)问题,即教师以迭代的方式向学习者提供实例,使学习者能够快速地接近目标模型。然而,现有的IMT算法只基于目标模型的参数化家族。它们主要集中在参数空间中的收敛,导致目标模型被定义为无参数函数时的困难。为了解决这一局限性,我们研究了一种更一般的任务——非参数迭代机器教学(NIMT),其目的是以迭代方式向学习者教导非参数目标模型。在适当假设下,得到了随机教学算法迭代教学维度(ITD),作为NIMT中ITD的统一上限。 此外,贪婪教学算法具有显著较低的ITD,达到NIMT中ITD的更紧的上限。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23c/zhang23c.pdf)** 

# Matrix Estimation for Individual Fairness
**题目:** 个人公平的矩阵估计

**作者:** Cindy Zhang, Sarah Huiyi Cen, Devavrat Shah

**Abstract:** In recent years, multiple notions of algorithmic fairness have arisen. One such notion is individual fairness (IF), which requires that individuals who are similar receive similar treatment. In parallel, matrix estimation (ME) has emerged as a natural paradigm for handling noisy data with missing values. In this work, we connect the two concepts. We show that pre-processing data using ME can improve an algorithm’s IF without sacrificing performance. Specifically, we show that using a popular ME method known as singular value thresholding (SVT) to pre-process the data provides a strong IF guarantee under appropriate conditions. We then show that, under analogous conditions, SVT pre-processing also yields estimates that are consistent and approximately minimax optimal. As such, the ME pre-processing step does not, under the stated conditions, increase the prediction error of the base algorithm, i.e., does not impose a fairness-performance trade-off. We verify these results on synthetic and real data.

**摘要:** 同时,矩阵估计(ME) emerged as a natural paradigm for handling noisy data with missing values. In this work, we connect the two concepts. We show that pre-processing data using ME can improve an algorithm’s IF without sacrificing performance. Specifically, we show that using a popular ME method known as singular value thresholding (SVT) to pre-process the data provides a strong IF guarantee under appropriate conditions. We then show that, under analogous conditions, SVT pre-processing also yields estimates that are consistent and approximately minimax optimal. As such, the ME pre-processing step does not, under the stated conditions, increase the prediction error of the base algorithm, i.e., does not impose a fairness-performance trade-off.我们通过合成和实物数据验证了这些结果.

**[Paper URL](https://proceedings.mlr.press/v202/zhang23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23d/zhang23d.pdf)** 

# Graph Contrastive Backdoor Attacks
**题目:** 图反向后门攻击

**作者:** Hangfan Zhang, Jinghui Chen, Lu Lin, Jinyuan Jia, Dinghao Wu

**Abstract:** Graph Contrastive Learning (GCL) has attracted considerable interest due to its impressive node representation learning capability. Despite the wide application of GCL techniques, little attention has been paid to the security of GCL. In this paper, we systematically study the vulnerability of GCL in the presence of malicious backdoor adversaries. In particular, we propose GCBA, the first backdoor attack for graph contrastive learning. GCBA incorporates three attacks: poisoning, crafting, and natural backdoor, each targeting one stage of the GCL pipeline. We formulate our attacks as optimization problems and solve them with a novel discrete optimization technique to overcome the discrete nature of graph-structured data. By extensively evaluating GCBA on multiple datasets and GCL methods, we show that our attack can achieve high attack success rates while preserving stealthiness. We further consider potential countermeasures to our attack and conclude that existing defenses are insufficient to mitigate GCBA. We show that as a complex paradigm involving data and model republishing, GCL is vulnerable to backdoor attacks, and specifically designed defenses are needed to mitigate the backdoor attacks on GCL.

**摘要:**  Graph Contrastive Learning(GCL)由于其令人印象深刻的节点表示学习能力,引起了相当大的兴趣。尽管GCL技术广泛应用,对GCL的安全性却很少给予重视。本论文系统地研究了恶意后门敌对GCL的脆弱性。我们特别提议GCBA,为图形对比学习的第一个后门攻击。GCBA包含三个攻击:毒害、制造和自然后门,每个攻击目标是GCL管道的一个阶段。我们将我们的攻击定义为优化问题,并用新颖的离散优化技术解决它们来克服图形结构数据的离散性质。我们进一步考虑了对攻击的潜在对策,并得出现有的防御措施不足以缓解GCBA。我们表明,作为涉及数据和模型重新出版的复杂范式,GCL易受后门攻击,需要专门设计的防御措施来缓解GCL的后门攻击。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23e/zhang23e.pdf)** 

# Effective Minkowski Dimension of Deep Nonparametric Regression: Function Approximation and Statistical Theories
**题目:** 深非参数回归的有效Minkowski维度:函数近似和统计理论

**作者:** Zixuan Zhang, Minshuo Chen, Mengdi Wang, Wenjing Liao, Tuo Zhao

**Abstract:** Existing theories on deep nonparametric regression have shown that when the input data lie on a low-dimensional manifold, deep neural networks can adapt to the intrinsic data structures. In real world applications, such an assumption of data lying exactly on a low dimensional manifold is stringent. This paper introduces a relaxed assumption that the input data are concentrated around a subset of $\mathbb{R}^d$ denoted by $\mathcal{S}$, and the intrinsic dimension of $\mathcal{S}$ can be characterized by a new complexity notation – effective Minkowski dimension. We prove that, the sample complexity of deep nonparametric regression only depends on the effective Minkowski dimension of $\mathcal{S}$ denoted by $p$. We further illustrate our theoretical findings by considering nonparametric regression with an anisotropic Gaussian random design $N(0,\Sigma)$, where $\Sigma$ is full rank. When the eigenvalues of $\Sigma$ have an exponential or polynomial decay, the effective Minkowski dimension of such an Gaussian random design is $p=\mathcal{O}(\sqrt{\log n})$ or $p=\mathcal{O}(n^\gamma)$, respectively, where $n$ is the sample size and $\gamma\in(0,1)$ is a small constant depending on the polynomial decay rate. Our theory shows that, when the manifold assumption does not hold, deep neural networks can still adapt to the effective Minkowski dimension of the data, and circumvent the curse of the ambient dimensionality for moderate sample sizes.

**摘要:** 现有关于深非参数回归理论表明,当输入数据 lie on a low-dimensional manifold, deep neural networks can adapt to the intrinsic data structures. In real world applications, such an assumption of data lying exactly on a low dimensional manifold is stringent. This paper introduces a relaxed assumption that the input data are concentrated around a subset of $\mathbb{R}^d$ denoted by $\mathcal{S}$, and the intrinsic dimension of $\mathcal{S}$ can be characterized by a new complexity notation – effective Minkowski dimension. We prove that, the sample complexity of deep nonparametric regression only depends on the effective Minkowski dimension of $\mathcal{S}$ denoted by $p$. We further illustrate our theoretical findings by considering nonparametric re当$\Sigma$的特征值具有指数或多项式衰变时,这种高斯随机设计的有效Minkowski维度分别是$p=\mathcal{O}(\sqrt{\log n})$或$p=\mathcal{O}(n^\gamma)$,其中$n$是样品大小,$\gamma\in(0,1)$是一个小常数,取决于多项式衰变率。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23f/zhang23f.pdf)** 

# Tractable Control for Autoregressive Language Generation
**题目:** 自动进化语言生成的传动控制

**作者:** Honghua Zhang, Meihua Dang, Nanyun Peng, Guy Van Den Broeck

**Abstract:** Despite the success of autoregressive large language models in text generation, it remains a major challenge to generate text that satisfies complex constraints: sampling from the conditional distribution ${\Pr}(\text{text} | \alpha)$ is intractable for even the simplest lexical constraints $\alpha$. To overcome this challenge, we propose to use tractable probabilistic models (TPMs) to impose lexical constraints in autoregressive text generation models, which we refer to as GeLaTo (Generating Language with Tractable Constraints). To demonstrate the effectiveness of this framework, we use distilled hidden Markov models, where we can efficiently compute ${\Pr}(\text{text} | \alpha)$, to guide autoregressive generation from GPT2. GeLaTo achieves state-of-the-art performance on challenging benchmarks for constrained text generation (e.g., CommonGen), beating various strong baselines by a large margin. Our work not only opens up new avenues for controlling large language models but also motivates the development of more expressive TPMs.

**摘要:** 尽管在文本生成中自动回归的大型语言模型取得了成功,但满足复杂约束的文本生成仍然是一个重大挑战:从条件分布${\Pr}(\text{text} | \alpha)$抽取的样本对于最简单的词汇约束$\alpha$是不可解的。为了克服这一挑战,我们建议使用可处理概率模型(TPM)来在自动回归的文本生成模型中施加词汇约束,我们称之为GeLaTo(Generating Language with Tractable Constraints)。我们的工作不仅为控制大型语言模型开辟了新的途径,而且激励了更表达式的TPM的开发。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23g/zhang23g.pdf)** 

# CataBEEM: Integrating Latent Interaction Categories in Node-wise Community Detection Models for Network Data
**题目:** CataBEEM:基于节点的网络数据社区检测模型中的潜在交互类别集成

**作者:** Yuhua Zhang, Walter H. Dempsey

**Abstract:** Community detection is a fundamental task in network analysis. Learning underlying network structures has brought deep insights into the understanding of complex systems. While many methods have focused on clustering nodes into blocks, few accounts for the fact that interactions may exhibit edge-level clustering, which we call categories. Real network data often arise via a series of interactions. Interactions in complex systems can often be clustered into different categories and node-level community structures that depend on the category. In this paper, we introduce a category-and-block edge exchangeable model (CataBEEM) to study interaction networks with joint latent interaction-level category and node-level community structures. In particular, the proposed method models the network from the interaction process perspective and allows the incorporation of prior knowledge from auxiliary interaction-wise information. We derive an efficient variational inference algorithm that can be applied to networks consisting of millions of interactions and provide the theoretical bound of the misspecification rate. We demonstrate the effectiveness of our method in various simulation settings and apply the method to TalkLife data, a large-scale online peer-to-peer support network. We show CataBEEM detects more temporally consistent community structures and has better predictions than other methods.

**摘要:** 社区检测是网络分析中的一个基本任务。学习网络结构的根本原因,对复杂系统的认识产生了深刻的洞察。虽然许多方法都集中在将节点聚类成块上,但很少有证据表明相互作用可能表现为边缘级聚类,我们称之为类别。真正的网络数据往往通过一系列相互作用产生。复杂系统中的相互作用往往可以聚类成不同的类别和依赖类别的节点级社区结构。本文介绍了一种基于类别和块边缘交换模型(CataBEEM)来研究与潜在相互作用级类别和节点级社区结构的相互作用网络。我们导出了一种有效的变量推导算法,可以应用于数百万相互作用的网络,并提供误标率的理论界限。我们在各种仿真设置中证明了我们的方法的有效性,并将该方法应用于TalkLife数据,这是一个大规模的在线 peer-to-peer支持网络。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23h/zhang23h.pdf)** 

# Rethink DARTS Search Space and Renovate a New Benchmark
**题目:** 重新思考DARTS搜索空间和重新创新新的基准

**作者:** Jiuling Zhang, Zhiming Ding

**Abstract:** DARTS search space (DSS) has become a canonical benchmark for NAS whereas some emerging works pointed out the issue of narrow accuracy range and claimed it would hurt the method ranking. We observe some recent studies already suffer from this issue that overshadows the meaning of scores. In this work, we first propose and orchestrate a suite of improvements to frame a larger and harder DSS, termed LHD, while retaining high efficiency in search. We step forward to renovate a LHD-based new benchmark, taking care of both discernibility and accessibility. Specifically, we re-implement twelve baselines and evaluate them across twelve conditions by combining two underexpolored influential factors: transductive robustness and discretization policy, to reasonably construct a benchmark upon multi-condition evaluation. Considering that the tabular benchmarks are always insufficient to adequately evaluate the methods of neural architecture search (NAS), our work can serve as a crucial basis for the future progress of NAS.

**摘要:** DARTS搜索空间(DSS)已成为NAS的标准基准,而一些新兴作品指出了狭窄精度范围的问题,并声称会损害方法排名。我们观察到一些最近的研究已经受到这一问题的影响,它掩盖了分数的意义。在这项工作中,我们首先提议和组织一系列改进,以构造一个更大的和更硬的DSS,称为LHD,同时保持在搜索中的高效率。我们向前迈进以LHD为基础的新基准,同时照顾到可辨识性和可访问性。鉴于表格的基准总是不足以充分评价神经结构搜索(NAS)的方法,我们的工作可以作为NAS的未来进步的一个关键基础。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23i/zhang23i.pdf)** 

# Team Belief DAG: Generalizing the Sequence Form to Team Games for Fast Computation of Correlated Team Max-Min Equilibria via Regret Minimization
**题目:** 团队信念DAG:通过减少遗憾来将序列形式推广到团队游戏,快速计算相关团队最大-最小均衡

**作者:** Brian Hu Zhang, Gabriele Farina, Tuomas Sandholm

**Abstract:** A classic result in the theory of extensive-form games asserts that the set of strategies available to any perfect-recall player is strategically equivalent to a low-dimensional convex polytope, called the sequence-form polytope. Online convex optimization tools operating on this polytope are the current state-of-the-art for computing several notions of equilibria in games, and have been crucial in landmark applications of computational game theory. However, when optimizing over the joint strategy space of a team of players, one cannot use the sequence form to obtain a strategically-equivalent convex description of the strategy set of the team. In this paper, we provide new complexity results on the computation of optimal strategies for teams, and propose a new representation, coined team belief DAG (TB-DAG), that describes team strategies as a convex set. The TB-DAG enjoys state-of-the-art parameterized complexity bounds, while at the same time enjoying the advantages of efficient regret minimization techniques. We show that TB-DAG can be exponentially smaller and can be computed exponentially faster than all other known representations, and that the converse is never true. Experimentally, we show that the TB-DAG, when paired with learning techniques, yields state of the art on a wide variety of benchmark team games.

**摘要:** 广泛形式游戏理论中的一个经典结果表明,任何完全召唤玩家可使用的策略集具有战略等价的低维凸聚体,称为序列形式聚体。在该聚体上运行的在线凸优化工具是计算游戏中平衡的几种概念的最新技术,在计算游戏理论的标志性应用中是至关重要的。然而,在对团队的联合战略空间进行优化时,不能使用序列形式来获得团队战略集的具有战略等价凸描述。TB-DAG具有最先进的参数化复杂度边界,同时享受了高效的遗憾最小化技术的优势。我们证明 TB-DAG可以指数级地小,可以指数级地快速计算,并且反向性永远是正确的。实验表明,当与学习技术相配时,TB-DAG在广泛的基准团队游戏中具有最先进的性能。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23j/zhang23j.pdf)** 

# A Complete Expressiveness Hierarchy for Subgraph GNNs via Subgraph Weisfeiler-Lehman Tests
**题目:** 基于Weisfeiler-Lehman测试的子图GNN的完整表达层次结构

**作者:** Bohang Zhang, Guhao Feng, Yiheng Du, Di He, Liwei Wang

**Abstract:** Recently, subgraph GNNs have emerged as an important direction for developing expressive graph neural networks (GNNs). While numerous architectures have been proposed, so far there is still a limited understanding of how various design paradigms differ in terms of expressive power, nor is it clear what design principle achieves maximal expressiveness with minimal architectural complexity. To address these fundamental questions, this paper conducts a systematic study of general node-based subgraph GNNs through the lens of Subgraph Weisfeiler-Lehman Tests (SWL). Our central result is to build a complete hierarchy of SWL with strictly growing expressivity. Concretely, we prove that any node-based subgraph GNN falls into one of the six SWL equivalence classes, among which $\mathsf{SSWL}$ achieves the maximal expressive power. We also study how these equivalence classes differ in terms of their practical expressiveness such as encoding graph distance and biconnectivity. In addition, we give a tight expressivity upper bound of all SWL algorithms by establishing a close relation with localized versions of WL and Folklore WL (FWL) tests. Overall, our results provide insights into the power of existing subgraph GNNs, guide the design of new architectures, and point out their limitations by revealing an inherent gap with the 2-FWL test. Finally, experiments demonstrate that $\mathsf{SSWL}$-inspired subgraph GNNs can significantly outperform prior architectures on multiple benchmarks despite great simplicity.

**摘要:** 近来,子图GNN作为发展表达式图神经网络的重要方向出现。虽然已经提出了众多的结构,但目前仍缺乏关于不同设计模式在表达能力方面有差异的有限理解,也没有明确设计原理在最小的结构复杂性下达到最大表达能力。为了解决这些基本问题,本文通过子图Weisfeiler-Lehman测试(SWL)的镜头对一般基于节点的子图GNN进行了系统研究。我们的中心结果是建立一个严格增长的表达能力的SWL完整的层次结构。具体地说,我们证明任何基于节点的子图GNN fall into one of the six SWL equivalence classes, among which $\mathsf{SSWL}$ achieves the maximal expressive power。此外,我们通过建立与WL和民俗WL(FWL)测试的本地化版本的密切关系,给出了所有SWL算法的严格表达性上限。总体而言,我们的结果提供了对现有分行GNN的能量的洞察,指导了新架构的设计,并指出了它们的局限性,通过揭示与2-FWL测试的内在差距。最后,实验证明$\mathsf{SSWL}$-inspired分行GNN可以在多个基准上大幅超过前架构,尽管非常简单。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23k/zhang23k.pdf)** 

# Crafting Training Degradation Distribution for the Accuracy-Generalization Trade-off in Real-World Super-Resolution
**题目:** 真实世界超分辨率精确-一般化交易的培训降级分配

**作者:** Ruofan Zhang, Jinjin Gu, Haoyu Chen, Chao Dong, Yulun Zhang, Wenming Yang

**Abstract:** Super-resolution (SR) techniques designed for real-world applications commonly encounter two primary challenges: generalization performance and restoration accuracy. We demonstrate that when methods are trained using complex, large-range degradations to enhance generalization, a decline in accuracy is inevitable. However, since the degradation in a certain real-world applications typically exhibits a limited variation range, it becomes feasible to strike a trade-off between generalization performance and testing accuracy within this scope. In this work, we introduce a novel approach to craft training degradation distributions using a small set of reference images. Our strategy is founded upon the binned representation of the degradation space and the Frechet distance between degradation distributions. Our results indicate that the proposed technique significantly improves the performance of test images while preserving generalization capabilities in real-world applications.

**摘要:** 针对现实应用设计的超分辨率技术通常面临两个主要挑战:一般化性能和恢复精度。我们证明,当使用复杂、大范围的降解来提高一般化训练时,精度的下降是不可避免的。然而,由于某些现实应用中的降解通常表现出有限的变异范围,因此在这一范围内,在一般化性能和测试精度之间达成交易是可行的。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23l/zhang23l.pdf)** 

# Prompting Large Language Model for Machine Translation: A Case Study
**题目:** 机器翻译的大型语言模型:个案研究

**作者:** Biao Zhang, Barry Haddow, Alexandra Birch

**Abstract:** Research on prompting has shown excellent performance with little or even no supervised training across many tasks. However, prompting for machine translation is still under-explored in the literature. We fill this gap by offering a systematic study on prompting strategies for translation, examining various factors for prompt template and demonstration example selection. We further explore the use of monolingual data and the feasibility of cross-lingual, cross-domain, and sentence-to-document transfer learning in prompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the testbed show that 1) the number and the quality of prompt examples matter, where using suboptimal examples degenerates translation; 2) several features of prompt examples, such as semantic similarity, show significant Spearman correlation with their prompting performance; yet, none of the correlations are strong enough; 3) using pseudo parallel prompt examples constructed from monolingual data via zero-shot prompting could improve translation; and 4) improved performance is achievable by transferring knowledge from prompt examples selected in other settings. We finally provide an analysis on the model outputs and discuss several problems that prompting still suffers from.

**摘要:** 促销研究显示,在许多任务中,对机器翻译的促销仍未得到充分的了解,甚至没有经过监督的培训。我们通过对促销翻译策略的系统研究,对促销模板和示例选择的各个因素进行了研究,并进一步探讨了单语数据的使用以及促销中跨语言、跨域和句子到文档转移学习的可行性。对GLM-130B(Zeng et al., 2022)作为测试床的广泛实验表明: 1) 提示例的数量和质量是重要的,使用次优的提示例会降低翻译质量; 2) 提示例的若干特征,例如语义相似性,与提示例性能有显著的斯佩尔曼相关性;然而,没有一个相关性足够强; 3) 通过零射击提示从单语言数据中构建的伪平行提示例可以改进翻译; 4) 通过从其他设置中选定的提示例转移知识来提高翻译性能。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23m/zhang23m.pdf)** 

# On the Interplay Between Misspecification and Sub-optimality Gap in Linear Contextual Bandits
**题目:** 线性背景带子误区与次优差之间的相互作用

**作者:** Weitong Zhang, Jiafan He, Zhiyuan Fan, Quanquan Gu

**Abstract:** We study linear contextual bandits in the misspecified setting, where the expected reward function can be approximated by a linear function class up to a bounded misspecification level $\zeta>0$. We propose an algorithm based on a novel data selection scheme, which only selects the contextual vectors with large uncertainty for online regression. We show that, when the misspecification level $\zeta$ is dominated by $\tilde O(\Delta / \sqrt{d})$ with $\Delta$ being the minimal sub-optimality gap and $d$ being the dimension of the contextual vectors, our algorithm enjoys the same gap-dependent regret bound $\tilde O ({d^2} /{\Delta})$ as in the well-specified setting up to logarithmic factors. Given this result, we show that the existing SupLinUCB algorithm (Chu et al., 2011) can also achieve a gap-dependent constant regret bound without the knowledge of sub-optimality gap $\Delta$. Together with a lower bound adapted from Lattimore et al. (2020), our result suggests an interplay between the misspecification level and the sub-optimality gap: (1) the linear contextual bandit model is efficiently learnable when $\zeta \leq \tilde O({\Delta} / \sqrt{d})$; and (2) it is not efficiently learnable when $\zeta \geq \tilde \Omega({\Delta} / {\sqrt{d}})$. Experiments on both synthetic and real-world datasets corroborate our theoretical results.

**摘要:** 我们研究了误标设置中的线性上下文带子,其中预期的奖励函数可以通过线性函数类近似到界限误标级别$\zeta>0$。我们提出了一种基于新的数据选择方案的算法,该算法只选择在在线回归中具有较大不确定性的上下文向量。我们证明,当误标级别$\zeta$由$\tilde O(\Delta / \sqrt{d})$主导时,$\Delta$是最小次优差和$d$是上下文向量的维度,我们的算法享受到在对数值因子配置中相同的差依赖性遗憾约束$\tilde O({d^2} /{\Delta})$。(2020年),我们的结果表明误区和次优差之间的相互作用: (1) 线性文 contextual bandit 模型在 $\zeta \leq \tilde O({\Delta} / \sqrt{d})$ 时可有效学习; (2) 它在 $\zeta \geq \tilde \Omega({\Delta} / {\sqrt{d}})$ 时不能有效学习。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23n/zhang23n.pdf)** 

# When Sparsity Meets Contrastive Models: Less Graph Data Can Bring Better Class-Balanced Representations
**题目:** 当节俭与相反的模型相符时:减少图形数据可以带来更好的类别平衡表现

**作者:** Chunhui Zhang, Chao Huang, Yijun Tian, Qianlong Wen, Zhongyu Ouyang, Youhuan Li, Yanfang Ye, Chuxu Zhang

**Abstract:** Graph Neural Networks (GNNs) are powerful models for non-Euclidean data, but their training is often accentuated by massive unnecessary computation: on the one hand, training on non-Euclidean data has relatively high computational cost due to its irregular density properties; on the other hand, the class imbalance property often associated with non-Euclidean data cannot be alleviated by the massiveness of the data, thus hindering the generalisation of the models. To address the above issues, theoretically, we start with a hypothesis about the effectiveness of using a subset of training data for GNNs, which is guaranteed by the gradient distance between the subset and the full set. Empirically, we also observe that a subset of the data can provide informative gradients for model optimization and which changes over time dynamically. We name this phenomenon dynamic data sparsity. Additionally, we find that pruned sparse contrastive models may miss valuable information, leading to a large loss value on the informative subset. Motivated by the above findings, we develop a unified data model dynamic sparsity framework called Data Decantation (DataDec) to address the above challenges. The key idea of DataDec is to identify the informative subset dynamically during the training process by applying sparse graph contrastive learning. The effectiveness of DataDec is comprehensively evaluated on graph benchmark datasets and we also verify its generalizability on image data.

**摘要:**  Graph Neural Networks (GNNs)是非欧几里德数据的强型模型,但它们的训练往往被大量不必要的计算所加重:一方面,非欧几里德数据的训练由于其不规则密度特性而具有相对较高的计算成本;另一方面,与非欧几里德数据经常相关的类不平衡特性不能通过数据的庞大程度来缓解,从而妨碍模型的推广。此外,我们发现剪切的稀疏对比模型可能会丢失有价值的信息,从而导致信息子集的损失值大。基于上述发现,我们开发了一个统一的数据模型动态稀疏框架,称为Data Decantation(DataDec),以解决上述挑战。DataDec的核心思想是通过应用稀疏对比图学习,在训练过程中动态地识别信息子集。DataDec的有效性在图标基准数据集中得到全面评价,并验证其在图像数据上可推广性。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23o/zhang23o.pdf)** 

# Spatial-Temporal Graph Learning with Adversarial Contrastive Adaptation
**题目:** 逆向反向适应的空间-温度图学习

**作者:** Qianru Zhang, Chao Huang, Lianghao Xia, Zheng Wang, Siu Ming Yiu, Ruihua Han

**Abstract:** Spatial-temporal graph learning has emerged as the state-of-the-art solution for modeling structured spatial-temporal data in learning region representations for various urban sensing tasks (e.g., crime forecasting, traffic flow prediction). However, most existing models are vulnerable to the quality of the generated region graph due to the inartistic graph-structured information aggregation schema. The ubiquitous spatial-temporal data noise and incompleteness in real-life scenarios bring difficulties to generate high-quality region representations. In this paper, we propose a Spatial-Temporal Adversarial Graph contrastive learning model (STAG) to tackle this challenge for adaptive self-supervised graph augmentation. Specifically, we propose a learnable contrastive learning function that enables the automated distillation of important multi-view self-supervised signals for adaptive spatial-temporal graph augmentation. To enhance the representation discrimination ability and robustness, the designed adversarial contrastive learning mechanism empowers STAG to adaptively identify hard samples for better self-supervision. Finally, a cross-view contrastive learning paradigm is introduced to model the inter-dependencies across view-specific region representations and preserve the underlying relation heterogeneity. We verify the superiority of our STAG method in various spatial-temporal prediction tasks on several benchmark datasets.

**摘要:**  spatial-temporal graph learning 是基于城市感知任务(例如犯罪预测、交通流量预测)的学习区域表示中的结构性空间-temporal数据建模的最先进的解决方案,但由于非艺术图结构性信息聚合模式,大多数现有的模型对生成区域图的质量有脆弱性。在现实场景中,普遍存在的空间-temporal数据噪声和不完整性使得生成高质量区域表示困难。本文提出了一种空间-Temporal Adversarial Graph 对比学习模型(STAG)来解决适应性自监督图增强的挑战。为了提高表示区分能力和鲁棒性,设计的敌对对比学习机制使STAG能够适应性地识别硬样品,以便更好地自我监督。最后,引入了交叉视角对比学习范式,以建模视角特异区域的相互依存关系,并保持相关性异质性。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23p.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23p/zhang23p.pdf)** 

# Towards Coherent Image Inpainting Using Denoising Diffusion Implicit Models
**题目:** 使用无声扩散隐形模型来绘制连贯图像

**作者:** Guanhua Zhang, Jiabao Ji, Yang Zhang, Mo Yu, Tommi Jaakkola, Shiyu Chang

**Abstract:** Image inpainting refers to the task of generating a complete, natural image based on a partially revealed reference image. Recently, many research interests have been focused on addressing this problem using fixed diffusion models. These approaches typically directly replace the revealed region of the intermediate or final generated images with that of the reference image or its variants. However, since the unrevealed regions are not directly modified to match the context, it results in incoherence between revealed and unrevealed regions. To address the incoherence problem, a small number of methods introduce a rigorous Bayesian framework, but they tend to introduce mismatches between the generated and the reference images due to the approximation errors in computing the posterior distributions. In this paper, we propose CoPaint, which can coherently inpaint the whole image without introducing mismatches. CoPaint also uses the Bayesian framework to jointly modify both revealed and unrevealed regions but approximates the posterior distribution in a way that allows the errors to gradually drop to zero throughout the denoising steps, thus strongly penalizing any mismatches with the reference image. Our experiments verify that CoPaint can outperform the existing diffusion-based methods under both objective and subjective metrics.

**摘要:** 图像绘制是指基于部分显示的参考图像生成完整的自然图像的任务。最近,许多研究兴趣都集中在使用固定扩散模型来解决这一问题。这些方法通常直接替换中继或最终生成图像的显示区域与参考图像或其变异区域。然而,由于未显示区域没有直接修改以匹配上下文,导致显示和未显示区域之间的不一致。为了解决不一致问题,少数方法引入了严格的贝叶斯框架,但它们往往由于计算后继分布的近似误差而导致生成和参考图像之间的不一致。CoPaint还利用贝叶斯框架共同修改显现和未显现的区域,但近似后方分布,使误差在描述步骤中逐渐下降到零,从而严重惩罚与参考图像的任何不一致。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23q.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23q/zhang23q.pdf)** 

# CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling
**题目:** CAB:对长序建模的综合关注评判

**作者:** Jun Zhang, Shuyang Jiang, Jiangtao Feng, Lin Zheng, Lingpeng Kong

**Abstract:** Transformer has achieved remarkable success in language, image, and speech processing. Recently, various efficient attention architectures have been proposed to improve transformer’s efficiency while largely preserving its efficacy, especially in modeling long sequences. A widely-used benchmark to test these efficient methods’ capability on long-range modeling is Long Range Arena (LRA). However, LRA only focuses on the standard bidirectional (or noncausal) self attention, and completely ignores cross attentions and unidirectional (or causal) attentions, which are equally important to downstream applications. In this paper, we propose Comprehensive Attention Benchmark (CAB) under a fine-grained attention taxonomy with four distinguishable attention patterns, namely, noncausal self, causal self, noncausal cross, and causal cross attentions. CAB collects seven real-world tasks from different research areas to evaluate efficient attentions under the four attention patterns. Among these tasks, CAB validates efficient attentions in eight backbone networks to show their generalization across neural architectures. We conduct exhaustive experiments to benchmark the performances of nine widely-used efficient attention architectures designed with different philosophies on CAB. Extensive experimental results also shed light on the fundamental problems of efficient attentions, such as efficiency length against vanilla attention, performance consistency across attention patterns, the benefit of attention mechanisms, and interpolation/extrapolation on long-context language modeling.

**摘要:** 变换器在语言、图像和语音处理方面取得了显著的成功。最近,为了提高变换器的效率,提出了各种有效的注意力架构,同时在很大程度上保持其有效性,特别是在建模长序列中。为测试这些有效的方法在长程建模上的能力,广泛使用的基准是长程竞技场(LRA)。然而,LRA只关注标准双向(或非因果)自我注意力,完全忽略交叉注意力和单向(或因果)注意力,这对下游应用同样重要。在这些任务中,CAB验证了八个骨干网络中的有效注意力,以显示它们在神经架构中具有普遍性。我们进行了全面的实验,以测试九种广泛使用的有效注意力架构的性能,设计了不同的CAB哲学。广泛的实验结果也揭示了有效注意力的基本问题,如效率长度与瓦尼拉注意力,注意力模式之间的性能一致性,注意力机制的好处,以及长期语境语言建模的插值/插值。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23r.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23r/zhang23r.pdf)** 

# Adaptive Barrier Smoothing for First-Order Policy Gradient with Contact Dynamics
**题目:** 基于接触动力学的首订单政策梯度适应性屏障缓冲

**作者:** Shenao Zhang, Wanxin Jin, Zhaoran Wang

**Abstract:** Differentiable physics-based simulators have witnessed remarkable success in robot learning involving contact dynamics, benefiting from their improved accuracy and efficiency in solving the underlying complementarity problem. However, when utilizing the First-Order Policy Gradient (FOPG) method, our theory indicates that the complementarity-based systems suffer from stiffness, leading to an explosion in the gradient variance of FOPG. As a result, optimization becomes challenging due to chaotic and non-smooth loss landscapes. To tackle this issue, we propose a novel approach called Adaptive Barrier Smoothing (ABS), which introduces a class of softened complementarity systems that correspond to barrier-smoothed objectives. With a contact-aware adaptive central-path parameter, ABS reduces the FOPG gradient variance while controlling the gradient bias. We justify the adaptive design by analyzing the roots of the system’s stiffness. Additionally, we establish the convergence of FOPG and show that ABS achieves a reasonable trade-off between the gradient variance and bias by providing their upper bounds. Moreover, we present a variant of FOPG based on complementarity modeling that efficiently fits the contact dynamics by learning the physical parameters. Experimental results on various robotic tasks are provided to support our theory and method.

**摘要:** 基于物理的可变模拟器在接触动力学的机器人学习中取得了显著的成功,并从其改善的准确性和效率中获益,解决了基本的互补性问题。然而,当使用第一阶策略梯度(FOPG)方法时,我们的理论表明,基于互补性系统的系统受到僵化,导致FOPG梯度变异的爆炸。因此,由于混沌和非僵化损失景观,优化变得困难。为了解决这一问题,我们提出了一种名为适应性障碍阻尼(ABS)的新方法,该方法引入了符合障碍阻尼目标的软化互补性系统。此外,我们建立了FOPG的收敛性,并证明了ABS通过提供其上限实现梯度变量与偏差之间的合理交换。此外,我们提出了基于互补模型的FOPG变量,通过学习物理参数,有效地适应接触动力学。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23s.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23s/zhang23s.pdf)** 

# One-Step Estimator for Permuted Sparse Recovery
**题目:** 转折备件回收的单步估计器

**作者:** Hang Zhang, Ping Li

**Abstract:** This paper considers the unlabeled sparse recovery under multiple measurements, i.e., ${\mathbf{Y}} = {\mathbf{\Pi}}^{\natural} {\mathbf{X}} {\mathbf{B}}^{\natural} + {\mathbf{W}}$, where ${\mathbf{Y}} \in \mathbb{R}^{n\times m}, {\mathbf{\Pi}}^{\natural}\in \mathbb{R}^{n\times n}, {\mathbf{X}} \in \mathbb{R}^{n\times p}, {\mathbf{B}} ^{\natural}\in \mathbb{R}^{p\times m}, {\mathbf{W}}\in \mathbb{R}^{n\times m}$ represents the observations, missing (or incomplete) correspondence information, sensing matrix, sparse signals, and additive sensing noise, respectively. Different from the previous works on multiple measurements ($m > 1$) which all focus on the sufficient samples regime, namely, $n > p$, we consider a sparse matrix $\mathbf{B}^{\natural}$ and investigate the insufficient samples regime (i.e., $n \ll p$) for the first time. To begin with, we establish the lower bound on the sample number and signal-to-noise ratio ($ {\mathsf{SNR}}$) for the correct permutation recovery. Moreover, we present a simple yet effective estimator. Under mild conditions, we show that our estimator can restore the correct correspondence information with high probability. Numerical experiments are presented to corroborate our theoretical claims.

**摘要:** 本文考虑在多个测量下未标记的稀疏恢复,即${\mathbf{Y}} = {\mathbf{\Pi}}^{\natural} {\mathbf{X}} {\mathbf{B}}^{\natural} + {\mathbf{W}}$,其中${\mathbf{Y}} \in \mathbb{R}^{n\times m}, {\mathbf{\Pi}}^{\natural}\in \mathbb{R}^{n\times n}, {\mathbf{X}} \in \mathbb{R}^{n\times p}, {\mathbf{B}} ^{\natural}\in \mathbb{R}^{p\times m}, {\mathbf{W}}\in \mathbb{R}^{n此外,我们提出了一种简单而有效的估计器,在温和的条件下,我们证明了我们的估计器能够恢复高概率的正确相关信息,并给出了数值实验来证实我们的理论主张。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23t.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23t/zhang23t.pdf)** 

# Quantum Lower Bounds for Finding Stationary Points of Nonconvex Functions
**题目:** 非凸函数的静止点的量子下限

**作者:** Chenyi Zhang, Tongyang Li

**Abstract:** Quantum computing is an emerging technology that has been rapidly advancing in the past decades. In this paper, we conduct a systematic study of quantum lower bounds on finding $\epsilon$-approximate stationary points of nonconvex functions, and we consider the following two important settings: 1) having access to $p$-th order derivatives; or 2) having access to stochastic gradients. The classical query lower bounds are $\Omega\big(\epsilon^{-\frac{1+p}{p}}\big)$ regarding the first setting and $\Omega(\epsilon^{-4})$ regarding the second setting (or $\Omega(\epsilon^{-3})$ if the stochastic gradient function is mean-squared smooth). In this paper, we extend all these classical lower bounds to the quantum setting. They match the classical algorithmic results respectively, demonstrating that there is no quantum speedup for finding $\epsilon$-stationary points of nonconvex functions with $p$-th order derivative inputs or stochastic gradient inputs, whether with or without the mean-squared smoothness assumption. Technically, we prove our quantum lower bounds by showing that the sequential nature of classical hard instances in all these settings also applies to quantum queries, preventing any quantum speedup other than revealing information of the stationary points sequentially.

**摘要:** 量子计算是一种新兴技术,在过去几十年中迅速发展起来。本文对量子下边界进行系统研究,研究非凸函数的近定点$epsilon$,并考虑以下两个重要设置: 1) 访问$p$-th阶导数;或 2) 访问随机梯度。经典查询下边界是$\Omega\big(\epsilon^{-\frac{1+p}{p}}\big)$关于第一个设置和$\Omega(\epsilon^{-4})$关于第二个设置(或$\Omega(\epsilon^{-3})$如果随机梯度函数是平均方程平滑)。它们分别与经典算法的结果相匹配,证明没有对非凸函数$p$-th阶导数输入或随机梯度输入的$\epsilon$-静点进行量子加速,不论是使用或不使用平均方程平滑假设。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23u.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23u/zhang23u.pdf)** 

# Improving Medical Predictions by Irregular Multimodal Electronic Health Records Modeling
**题目:** 不规则多模式电子健康记录建模改进医学预测

**作者:** Xinlu Zhang, Shiyang Li, Zhiyu Chen, Xifeng Yan, Linda Ruth Petzold

**Abstract:** Health conditions among patients in intensive care units (ICUs) are monitored via electronic health records (EHRs), composed of numerical time series and lengthy clinical note sequences, both taken at $\textit{irregular}$ time intervals. Dealing with such irregularity in every modality, and integrating irregularity into multimodal representations to improve medical predictions, is a challenging problem. Our method first addresses irregularity in each single modality by (1) modeling irregular time series by dynamically incorporating hand-crafted imputation embeddings into learned interpolation embeddings via a gating mechanism, and (2) casting a series of clinical note representations as multivariate irregular time series and tackling irregularity via a time attention mechanism. We further integrate irregularity in multimodal fusion with an interleaved attention mechanism across temporal steps. To the best of our knowledge, this is the first work to thoroughly model irregularity in multimodalities for improving medical predictions. Our proposed methods for two medical prediction tasks consistently outperforms state-of-the-art (SOTA) baselines in each single modality and multimodal fusion scenarios. Specifically, we observe relative improvements of 6.5%, 3.6%, and 4.3% in F1 for time series, clinical notes, and multimodal fusion, respectively. These results demonstrate the effectiveness of our methods and the importance of considering irregularity in multimodal EHRs.

**摘要:** 集中病房病人的健康状况由电子健康记录(EHR)监测,由数值时间序列和长长的临床注释序列组成,两者都以$\textit{irregular}$时间间隔进行。处理每种模式中这种不规则现象,并将不规则现象纳入多模态表示,以改善医疗预测,是一项挑战性问题。我们的方法首先解决了每种模式中不规则现象,首先通过(一)动态地将手工编写的归纳嵌入法纳入学习插值嵌入法的模式化时间序列,(二)将一系列临床注释表示作为多变量不规则时间序列,并通过时间注意机制来解决不规则现象。我们进一步将多模态融合中的不规则现象与间导注意力机制相结合,并通过时间步骤解决不规则问题。为了提高医学预测,本文首先对多模态中不规则性进行了深入的建模。我们提出的两项医学预测任务的方法,在单模态和多模态融合场景中,一致超过了最新技术(SOTA)的基线。具体而言,我们观察到时间序列、临床注释和多模态融合的F1中分别有6.5 % 、 3.6% 、 4.3% 的相对改善,这些结果表明了我们的方法的有效性和考虑多模态HR中不规则性的重要性。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23v.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23v/zhang23v.pdf)** 

# FedCR: Personalized Federated Learning Based on Across-Client Common Representation with Conditional Mutual Information Regularization
**题目:** FedCR:基于全客户共同代表的个性化联邦学习与条件相互信息监管

**作者:** Hao Zhang, Chenglin Li, Wenrui Dai, Junni Zou, Hongkai Xiong

**Abstract:** In personalized federated learning (PFL), multiple clients train customized models to fulfill their personal objectives, which, however, are prone to overfitting to local data due to the heterogeneity and scarcity of local data. To address this, we propose from the information-theoretic perspective a personalized federated learning framework based on the common representation learned across clients, named FedCR. Specifically, we introduce to the local client update a regularizer that aims at minimizing the discrepancy between local and global conditional mutual information (CMI), such that clients are encouraged to learn and exploit the common representation. Upon this, each client learns individually a customized predictor (head), while the extractor (body) remains to be aggregated by the server. Our CMI regularizer leads to a theoretically sound alignment between the local and global stochastic feature distributions in terms of their Kullback-Leibler (KL) divergence. More importantly, by modeling the global joint feature distribution as a product of multiple local feature distributions, clients can efficiently extract diverse information from the global data but without need of the raw data from other clients. We further show that noise injection via feature alignment and ensemble of local predictors in FedCR would help enhance its generalization capability. Experiments on benchmark datasets demonstrate a consistent performance gain and better generalization behavior of FedCR.

**摘要:** 在个性化联合学习(PFL)中,多个客户训练定制模型来实现个人目标,但由于本地数据的异质性和稀缺,这些模型易于对本地数据进行过滤。为了解决这个问题,我们从信息理论角度提出了基于客户间共同表现的个性化联合学习框架,称为FedCR。具体而言,我们向本地客户介绍更新一个规范化程序,目的是尽量减少本地和全球条件相互信息(CMI)之间的差异,从而鼓励客户学习和利用共同表现。在此基础上,每个客户单独学习一个定制预测器(头部),而提取器(身体)则由服务器聚集。更重要的是,通过将全球联合特征分布模型作为多个本地特征分布的产物,客户可以有效地从全球数据中提取各种信息,但不需要从其他客户中提取原始数据。我们进一步表明,通过特征整合和本地预测器组合的噪声注入在FedCR中有助于提高其推广能力。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23w.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23w/zhang23w.pdf)** 

# On the Optimality of Misspecified Kernel Ridge Regression
**题目:** 误区核 Ridge回归的优化问题

**作者:** Haobo Zhang, Yicheng Li, Weihao Lu, Qian Lin

**Abstract:** In the misspecified kernel ridge regression problem, researchers usually assume the underground true function $f_{\rho}^{\star} \in [\mathcal{H}]^{s}$, a less-smooth interpolation space of a reproducing kernel Hilbert space (RKHS) $\mathcal{H}$ for some $s\in (0,1)$. The existing minimax optimal results require $\left\Vert f_{\rho}^{\star} \right \Vert_{L^{\infty}} < \infty$ which implicitly requires $s > \alpha_{0}$ where $\alpha_{0} \in (0,1) $ is the embedding index, a constant depending on $\mathcal{H}$. Whether the KRR is optimal for all $s\in (0,1)$ is an outstanding problem lasting for years. In this paper, we show that KRR is minimax optimal for any $s\in (0,1)$ when the $\mathcal{H}$ is a Sobolev RKHS.

**摘要:** 在错误指定的内核脊回归问题中,研究者通常假定下层真函数$f_{\rho}^{\star} \in [\mathcal{H}]^{s}$,是复制内核希尔伯特空间(RKHS)$\mathcal{H}$的较不 Smooth 的插值空间$s\in (0,1)$。现有的最小值优化结果要求$\left\Vert f_{\rho}^{\star} \right \Vert_{L^{\infty}} < \infty$, implicitly要求$s > \alpha_{0}$,其中$\alpha_{0} \in (0,1)$是嵌入指数,一个常数取决于$\mathcal{H}$。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23x.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23x/zhang23x.pdf)** 

# Fed-CBS: A Heterogeneity-Aware Client Sampling Mechanism for Federated Learning via Class-Imbalance Reduction
**题目:** Fed-CBS:通过减少类别失衡实现联邦学习的异性认知客户端采样机制

**作者:** Jianyi Zhang, Ang Li, Minxue Tang, Jingwei Sun, Xiang Chen, Fan Zhang, Changyou Chen, Yiran Chen, Hai Li

**Abstract:** Due to the often limited communication bandwidth of edge devices, most existing federated learning (FL) methods randomly select only a subset of devices to participate in training at each communication round. Compared with engaging all the available clients, such a random-selection mechanism could lead to significant performance degradation on non-IID (independent and identically distributed) data. In this paper, we present our key observation that the essential reason resulting in such performance degradation is the class-imbalance of the grouped data from randomly selected clients. Based on this observation, we design an efficient heterogeneity-aware client sampling mechanism, namely, Federated Class-balanced Sampling (Fed-CBS), which can effectively reduce class-imbalance of the grouped dataset from the intentionally selected clients. We first propose a measure of class-imbalance which can be derived in a privacy-preserving way. Based on this measure, we design a computation-efficient client sampling strategy such that the actively selected clients will generate a more class-balanced grouped dataset with theoretical guarantees. Experimental results show that Fed-CBS outperforms the status quo approaches in terms of test accuracy and the rate of convergence while achieving comparable or even better performance than the ideal setting where all the available clients participate in the FL training.

**摘要:** 由于边缘设备的通信带宽经常有限,大多数现有的联合学习(FL)方法只随机选择一个设备的子集,以参与每个通信回合的训练。与参与所有可用的客户端相比,这种随机选择机制可能导致非IID(独立和均匀分布的)数据的性能显著下降。本论文提出了我们的主要观察,导致这种性能下降的根本原因是随机选定的客户端集群数据的类别失衡。基于这一观察,我们设计了一个具有异质性意识的客户端采样机制,即联合集群数据的类别失衡(Fed-CBS),该机制可以有效地减少意图选定的客户端集群数据的类别失衡。在此基础上,我们设计了一种计算效率高的客户采样策略,使积极选择的客户能够生成具有理论保证的更平衡的类群数据集。实验结果表明,Fed-CBS在测试准确度和收敛率方面比现有客户参加FL培训的理想环境表现得更好,甚至比理想环境表现得更佳。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23y.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23y/zhang23y.pdf)** 

# Learning Subpocket Prototypes for Generalizable Structure-based Drug Design
**题目:** 基于通用结构的药物设计模板学习

**作者:** Zaixi Zhang, Qi Liu

**Abstract:** Generating molecules with high binding affinities to target proteins (a.k.a. structure-based drug design) is a fundamental and challenging task in drug discovery. Recently, deep generative models have achieved remarkable success in generating 3D molecules conditioned on the protein pocket. However, most existing methods consider molecular generation for protein pockets independently while neglecting the underlying connections such as subpocket-level similarities. Subpockets are the local protein environments of ligand fragments and pockets with similar subpockets may bind the same molecular fragment (motif) even though their overall structures are different. Therefore, the trained models can hardly generalize to unseen protein pockets in real-world applications. In this paper, we propose a novel method DrugGPS for generalizable structure-based drug design. With the biochemical priors, we propose to learn subpocket prototypes and construct a global interaction graph to model the interactions between subpocket prototypes and molecular motifs. Moreover, a hierarchical graph transformer encoder and motif-based 3D molecule generation scheme are used to improve the model’s performance. The experimental results show that our model consistently outperforms baselines in generating realistic drug candidates with high affinities in challenging out-of-distribution settings.

**摘要:** 针对靶向蛋白质(即基于结构的药物设计)具有较高的结合性分子的生成是药物发现的根本和挑战性任务。最近,基于蛋白质口袋的深层生成模型在生成3D分子方面取得了显著的成功。然而,大多数现有的方法都将蛋白质口袋的分子生成视为独立的,同时忽略了潜在的联系,例如子口袋的相似性。子口袋是配体碎片的局部蛋白质环境,和同类子口袋的口袋可能结合相同的分子碎片(动因),尽管它们的整体结构不同。通过生物化学预先研究,我们提出学习子袋原型,并构建一个全球相互作用图,以建模子袋原型与分子原型之间的相互作用。此外,采用层次式图变换器编码器和基于原型的3D分子生成方案来提高模型的性能。实验结果表明,我们的模型在 challenging out-of-distribution settings中始终超过了基准,在生成高亲和的现实药物候选者时。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23z.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23z/zhang23z.pdf)** 

# No One Idles: Efficient Heterogeneous Federated Learning with Parallel Edge and Server Computation
**题目:** No One Idles: 基于平行边缘和服务器计算的高效异构联邦学习

**作者:** Feilong Zhang, Xianming Liu, Shiyi Lin, Gang Wu, Xiong Zhou, Junjun Jiang, Xiangyang Ji

**Abstract:** Federated learning suffers from a latency bottleneck induced by network stragglers, which hampers the training efficiency significantly. In addition, due to the heterogeneous data distribution and security requirements, simple and fast averaging aggregation is not feasible anymore. Instead, complicated aggregation operations, such as knowledge distillation, are required. The time cost for complicated aggregation becomes a new bottleneck that limits the computational efficiency of FL. In this work, we claim that the root cause of training latency actually lies in the aggregation-then-broadcasting workflow of the server. By swapping the computational order of aggregation and broadcasting, we propose a novel and efficient parallel federated learning (PFL) framework that unlocks the edge nodes during global computation and the central server during local computation. This fully asynchronous and parallel pipeline enables handling complex aggregation and network stragglers, allowing flexible device participation as well as achieving scalability in computation. We theoretically prove that synchronous and asynchronous PFL can achieve a similar convergence rate as vanilla FL. Extensive experiments empirically show that our framework brings up to $5.56\times$ speedup compared with traditional FL. Code is available at: https://github.com/Hypervoyager/PFL.

**摘要:** 联合学习受网络阻挠者所诱导的延迟瓶颈影响,严重阻碍了培训效率。此外,由于数据分布和安全要求不均匀,简单的和快速的平均聚合不再可行。相反,需要复杂的聚合操作,如知识蒸馏。复杂聚合的时间成本成为限制FL的计算效率的新瓶颈。在这个工作中,我们宣称培训延迟的根本原因实际上在于服务器的聚合-然后-广播工作流程。这个完全异步和平行管道可处理复杂集群和网络阻尼器,允许灵活的设备参与以及在计算中实现可扩展性。我们理论上证明,同步和异步PFL可以达到类似的聚合率,如瓦尼拉FL。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23aa.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23aa/zhang23aa.pdf)** 

# The Wisdom of Hindsight Makes Language Models Better Instruction Followers
**题目:** 反思的智慧使语言模型更适合教学

**作者:** Tianjun Zhang, Fangchen Liu, Justin Wong, Pieter Abbeel, Joseph E. Gonzalez

**Abstract:** Reinforcement learning has seen wide success in finetuning large language models to better align with instructions via human feedback. The so-called algorithm, Reinforcement Learning with Human Feedback (RLHF) demonstrates impressive performance on the GPT series models. However, the underlying reinforcement learning algorithm is complex and requires additional training for reward and value networks. In this paper, we consider an alternative approach: converting feedback to instruction by relabeling the original one and training the model for better alignment in a supervised manner. Such an algorithm doesn’t require any additional parameters except for the original language model and maximally reuses the pretraining pipeline. To achieve this, we formulate instruction alignment problem for language models as a goal-reaching problem in decision making. We propose Hindsight Instruction Relabeling (HIR), a novel algorithm for aligning language models with instructions. The resulting two-stage algorithm shed light to a family of reward-free approaches that utilize the hindsightly relabeled instructions based on feedback. We evaluate the performance of HIR extensively on 12 challenging BigBench reasoning tasks and show that HIR outperforms the baseline algorithms and is comparable to or even surpasses supervised fine-tuning. The implementation of HIR is available at https://github.com/tianjunz/HIR.

**摘要:** 增强学习在微调大型语言模型以通过人反馈来更好地配合指令方面取得了巨大的成功。所谓的增强学习与人反馈(RLHF)算法在GPT系列模型中显示出令人印象深刻的性能。然而,基本的增强学习算法是复杂的,需要额外训练奖励和价值网络。本论文考虑了一种替代方法:将反馈转换为指令,通过重新编译原型并以监督的方式培训模型以更好地配合指令。这种算法不需要任何额外参数,除了原型语言模型之外,并且最大地重用预训练管道。我们对HIR在12个挑战性的BigBench推理任务中的表现进行了广泛的评估,并显示HIR比基线算法高,甚至比监督的微调高。HIR的实现可于 https://github.com/tianjunz/HIR。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ab.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ab/zhang23ab.pdf)** 

# Detecting Adversarial Data by Probing Multiple Perturbations Using Expected Perturbation Score
**题目:** 利用预期扰动分数检测多个扰动来检测敌对数据

**作者:** Shuhai Zhang, Feng Liu, Jiahao Yang, Yifan Yang, Changsheng Li, Bo Han, Mingkui Tan

**Abstract:** Adversarial detection aims to determine whether a given sample is an adversarial one based on the discrepancy between natural and adversarial distributions. Unfortunately, estimating or comparing two data distributions is extremely difficult, especially in high-dimension spaces. Recently, the gradient of log probability density (a.k.a., score) w.r.t. the sample is used as an alternative statistic to compute. However, we find that the score is sensitive in identifying adversarial samples due to insufficient information with one sample only. In this paper, we propose a new statistic called expected perturbation score (EPS), which is essentially the expected score of a sample after various perturbations. Specifically, to obtain adequate information regarding one sample, we perturb it by adding various noises to capture its multi-view observations. We theoretically prove that EPS is a proper statistic to compute the discrepancy between two samples under mild conditions. In practice, we can use a pre-trained diffusion model to estimate EPS for each sample. Last, we pro- pose an EPS-based adversarial detection (EPS- AD) method, in which we develop EPS-based maximum mean discrepancy (MMD) as a metric to measure the discrepancy between the test sample and natural samples. We also prove that the EPS-based MMD between natural and adversarial samples is larger than that among natural samples. Extensive experiments show the superior adversarial detection performance of our EPS-AD.

**摘要:** 敌对检测的目的是根据自然和敌对分布的差异来确定某样品是否是敌对样品。不幸的是,估计或比较两个数据分布是非常困难的,特别是在高维空间中。最近,逻辑概率密度的梯度(即分数)被用作计算的替代统计。然而,我们发现分数在识别敌对样品时是敏感的,因为只有一个样品信息不足。最后,我们提出了基于EPS的敌对检测(EPS-AD)方法,用EPS的平均最大差异(MMD)作为测量测试样本与自然样本之间的差异的度量。我们还证明,基于EPS的自然样本与敌对样本之间的MMD比自然样本大。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ac.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ac/zhang23ac.pdf)** 

# On Enhancing Expressive Power via Compositions of Single Fixed-Size ReLU Network
**题目:** 基于单个固定大小的RELU网络构件增强表达能力

**作者:** Shijun Zhang, Jianfeng Lu, Hongkai Zhao

**Abstract:** This paper explores the expressive power of deep neural networks through the framework of function compositions. We demonstrate that the repeated compositions of a single fixed-size ReLU network exhibit surprising expressive power, despite the limited expressive capabilities of the individual network itself. Specifically, we prove by construction that $\mathcal{L}_2\circ \boldsymbol{g}^{\circ r}\circ \boldsymbol{\mathcal{L}}_1$ can approximate $1$-Lipschitz continuous functions on $[0,1]^d$ with an error $\mathcal{O}(r^{-1/d})$, where $\boldsymbol{g}$ is realized by a fixed-size ReLU network, $\boldsymbol{\mathcal{L}}_1$ and $\mathcal{L}_2$ are two affine linear maps matching the dimensions, and $\boldsymbol{g}^{\circ r}$ denotes the $r$-times composition of $\boldsymbol{g}$. Furthermore, we extend such a result to generic continuous functions on $[0,1]^d$ with the approximation error characterized by the modulus of continuity. Our results reveal that a continuous-depth network generated via a dynamical system has immense approximation power even if its dynamics function is time-independent and realized by a fixed-size ReLU network.

**摘要:** 本文通过函数组合框架探讨了深度神经网络的表达能力。我们证明,单个固定大小的ReLU网络的重复组合显示出惊人的表达能力,尽管单个网络本身的表达能力有限。具体地说,我们通过构造证明,$\mathcal{L}_2\circ \boldsymbol{g}^{\circ r}\circ \boldsymbol{\mathcal{L}}_1$可以近似$1$-Lipschitz连续函数$[0,1]^d$的误差$\mathcal{O}(r^{-1/d})$,其中$\boldsymbol{g}$由固定大小的ReLU网络实现,$\boldsymbol{\mathcal{L}}_1$和$\mathcal{L}_2$是两个相匹配的细线性地图,$\boldsymbol{g}^{结果表明,通过动态系统生成的连续深度网络具有巨大的近似能力,即使其动态功能是时间独立的,并且由固定大小的ReLU网络实现。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ad.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ad/zhang23ad.pdf)** 

# Bi-directional Masks for Efficient N:M Sparse Training
**题目:** 高效N:M备件训练双向面罩

**作者:** Yuxin Zhang, Yiting Luo, Mingbao Lin, Yunshan Zhong, Jingjing Xie, Fei Chao, Rongrong Ji

**Abstract:** We focus on addressing the dense backward propagation issue for training efficiency of N:M fine-grained sparsity that preserves at most N out of M consecutive weights and achieves practical speedups supported by the N:M sparse tensor core. Therefore, we present a novel method of Bi-directional Masks (Bi-Mask) with its two central innovations in: 1) Separate sparse masks in the two directions of forward and backward propagation to obtain training acceleration. It disentangles the forward and backward weight sparsity and overcomes the very dense gradient computation. 2) An efficient weight row permutation method to maintain performance. It picks up the permutation candidate with the most eligible N:M weight blocks in the backward to minimize the gradient gap between traditional unidirectional masks and our bi-directional masks. Compared with existing uni-directional scenario that applies a transposable mask and enables backward acceleration, our Bi-Mask is experimentally demonstrated to be more superior in performance. Also, our Bi-Mask performs on par with or even better than methods that fail to achieve backward acceleration. Project of this paper is available at https://github.com/zyxxmu/Bi-Mask.

**摘要:** 本文主要研究了N:M微粒稀疏度的训练效率问题,以保持M连续重量中最大N值,并实现N:M稀疏张量核心支持的实际增速。因此,提出了一种新的双向面具(双面具)方法,其两个核心创新是: 1)在前向和后向的两方向分离稀疏面具,以获得训练加速;它将前向和后向的重量稀疏度分离,并克服非常密集的梯度计算;2)保持性能的有效重量行变换方法;在后向的最有资格的N:M重量块中选取变换候选者,以减少传统单向面具和双向面具之间的梯度差距。与现有的单指向场景相比,我们的Bi-Mask在实验中被证明在性能上更优越。此外,我们的Bi-Mask的性能与或甚至比未能实现逆向加速的方法相等。本论文的计划可浏览 https://github.com/zyxxmu/Bi-Mask。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ae.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ae/zhang23ae.pdf)** 

# Towards Unbiased Training in Federated Open-world Semi-supervised Learning
**题目:** 面向联邦开放世界半监督学习的公正培训

**作者:** Jie Zhang, Xiaosong Ma, Song Guo, Wenchao Xu

**Abstract:** Federated Semi-supervised Learning (FedSSL) has emerged as a new paradigm for allowing distributed clients to collaboratively train a machine learning model over scarce labeled data and abundant unlabeled data. However, existing works for FedSSL rely on a closed-world assumption that all local training data and global testing data are from seen classes observed in the labeled dataset. It is crucial to go one step further: adapting FL models to an open-world setting, where unseen classes exist in the unlabeled data. In this paper, we propose a novel Federatedopen-world Semi-Supervised Learning (FedoSSL) framework, which can solve the key challenge in distributed and open-world settings, i.e., the biased training process for heterogeneously distributed unseen classes. Specifically, since the advent of a certain unseen class depends on a client basis, the locally unseen classes (exist in multiple clients) are likely to receive differentiated superior aggregation effects than the globally unseen classes (exist only in one client). We adopt an uncertainty-aware suppressed loss to alleviate the biased training between locally unseen and globally unseen classes. Besides, we enable a calibration module supplementary to the global aggregation to avoid potential conflicting knowledge transfer caused by inconsistent data distribution among different clients. The proposed FedoSSL can be easily adapted to state-of-the-art FL methods, which is also validated via extensive experiments on benchmarks and real-world datasets (CIFAR-10, CIFAR-100 and CINIC-10).

**摘要:** Federated Semi-supervised Learning(FedSSL)是允许分布式客户协同培训机器学习模型的新型范式,其应用于稀缺的标签数据和丰富的无标签数据。然而,FedSSL的现有工作依赖于一个封闭世界假设,即所有本地培训数据和全球测试数据来自在标签数据集中观察到的类别。具体地说,由于某一隐形类的出现取决于一个客户端,局部隐形类(存在于多个客户端)可能比全球隐形类(仅存在于一个客户端)获得不同的优越集群效应。我们采用不确定意识的抑制损失来缓解局部隐形类和全球隐形类之间的偏见训练。此外,我们允许全球集群的校正模块,以避免因不同客户端之间数据分布不一致而导致的潜在冲突的知识转移。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23af.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23af/zhang23af.pdf)** 

# Interactive Object Placement with Reinforcement Learning
**题目:** 互动对象配置与强化学习

**作者:** Shengping Zhang, Quanling Meng, Qinglin Liu, Liqiang Nie, Bineng Zhong, Xiaopeng Fan, Rongrong Ji

**Abstract:** Object placement aims to insert a foreground object into a background image with a suitable location and size to create a natural composition. To predict a diverse distribution of placements, existing methods usually establish a one-to-one mapping from random vectors to the placements. However, these random vectors are not interpretable, which prevents users from interacting with the object placement process. To address this problem, we propose an Interactive Object Placement method with Reinforcement Learning, dubbed IOPRE, to make sequential decisions for producing a reasonable placement given an initial location and size of the foreground. We first design a novel action space to flexibly and stably adjust the location and size of the foreground while preserving its aspect ratio. Then, we propose a multi-factor state representation learning method, which integrates composition image features and sinusoidal positional embeddings of the foreground to make decisions for selecting actions. Finally, we design a hybrid reward function that combines placement assessment and the number of steps to ensure that the agent learns to place objects in the most visually pleasing and semantically appropriate location. Experimental results on the OPA dataset demonstrate that the proposed method achieves state-of-the-art performance in terms of plausibility and diversity.

**摘要:** 对象配置的目标是将一个前景对象插入背景图像中,具有适当的位置和大小,以创建自然成分。为了预测配置的多样性分布,现有的方法通常建立一个对一个的映射从随机向量到配置。然而,这些随机向量是不能解释的,这使得用户无法与对象配置过程进行交互。为了解决这个问题,我们提出了一种基于增强学习的交互对象配置方法,称为IOPRE,以根据前景的初始位置和大小来作出合理的配置的顺序决策。然后,我们提出了一种多因素状态表示学习方法,该方法将复合图像特征和前场的 sinusoidal位置嵌入结合起来,为选择行动作出决定。最后,我们设计了一种混合奖励函数,将配置评估和步骤数结合起来,以确保代理人学会将对象放置在最视觉上令人愉快和语义上适当的位置。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ag.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ag/zhang23ag.pdf)** 

# Optimal Shrinkage for Distributed Second-Order Optimization
**题目:** 分布式第二批优化优化优化的优化设计

**作者:** Fangzhao Zhang, Mert Pilanci

**Abstract:** In this work, we address the problem of Hessian inversion bias in distributed second-order optimization algorithms. We introduce a novel shrinkage-based estimator for the resolvent of gram matrices which is asymptotically unbiased, and characterize its non-asymptotic convergence rate in the isotropic case. We apply this estimator to bias correction of Newton steps in distributed second-order optimization algorithms, as well as randomized sketching based methods. We examine the bias present in the naive averaging-based distributed Newton’s method using analytical expressions and contrast it with our proposed biasfree approach. Our approach leads to significant improvements in convergence rate compared to standard baselines and recent proposals, as shown through experiments on both real and synthetic datasets.

**摘要:** 本文对分布式二阶优化算法中的希斯反向偏差问题进行了研究,介绍了一种基于缩减的新方法对具有渐近性非偏差的 gram 矩阵溶剂的估计数,并对其在同向性情况下的非渐近性收敛率进行了特征化,应用于分布式二阶优化算法中牛顿步骤的偏差修正,以及基于随机草图的方法。我们利用分析表达式对基于平均的分布式牛顿方法中存在的偏差进行了研究,并与我们提出的偏差自由方法进行了对比。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ah.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ah/zhang23ah.pdf)** 

# "Why did the Model Fail?": Attributing Model Performance Changes to Distribution Shifts
**题目:** “为什么模型失败?”:将模型性能变化归功于分配 Shifts

**作者:** Haoran Zhang, Harvineet Singh, Marzyeh Ghassemi, Shalmali Joshi

**Abstract:** Machine learning models frequently experience performance drops under distribution shifts. The underlying cause of such shifts may be multiple simultaneous factors such as changes in data quality, differences in specific covariate distributions, or changes in the relationship between label and features. When a model does fail during deployment, attributing performance change to these factors is critical for the model developer to identify the root cause and take mitigating actions. In this work, we introduce the problem of attributing performance differences between environments to distribution shifts in the underlying data generating mechanisms. We formulate the problem as a cooperative game where the players are distributions. We define the value of a set of distributions to be the change in model performance when only this set of distributions has changed between environments, and derive an importance weighting method for computing the value of an arbitrary set of distributions. The contribution of each distribution to the total performance change is then quantified as its Shapley value. We demonstrate the correctness and utility of our method on synthetic, semi-synthetic, and real-world case studies, showing its effectiveness in attributing performance changes to a wide range of distribution shifts.

**摘要:** 机器学习模型经常经历性能下降的分布变迁。这种变迁的根本原因可能是数据质量的变化、特定共变分布的差异、标签与特征之间的关系的变化等多个同时因素。当模型在部署过程中失败时,将性能变化归因于这些因素对于模型开发者来说至关重要,以确定根源原因并采取缓解行动。在这个工作中,我们引入了归因环境间的性能差异归因于数据生成机制中的分布变迁的问题。然后将每个分布对整个性能变化的贡献定量化为其Shapley值。我们证明了本方法在合成、半合成和实世界案例研究中正确性和实用性,证明了该方法在归因性能变化到广泛的分布变化时的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ai.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ai/zhang23ai.pdf)** 

# Learning Regions of Interest for Bayesian Optimization with Adaptive Level-Set Estimation
**题目:** 基于适应性水平定量估计的贝叶斯优化研究领域

**作者:** Fengxue Zhang, Jialin Song, James C Bowden, Alexander Ladd, Yisong Yue, Thomas Desautels, Yuxin Chen

**Abstract:** We study Bayesian optimization (BO) in high-dimensional and non-stationary scenarios. Existing algorithms for such scenarios typically require extensive hyperparameter tuning, which limits their practical effectiveness. We propose a framework, called BALLET, which adaptively filters for a high-confidence region of interest (ROI) as a superlevel-set of a nonparametric probabilistic model such as a Gaussian process (GP). Our approach is easy to tune, and is able to focus on local region of the optimization space that can be tackled by existing BO methods. The key idea is to use two probabilistic models: a coarse GP to identify the ROI, and a localized GP for optimization within the ROI. We show theoretically that BALLET can efficiently shrink the search space, and can exhibit a tighter regret bound than standard BO without ROI filtering. We demonstrate empirically the effectiveness of BALLET on both synthetic and real-world optimization tasks.

**摘要:** 我们研究高维和非静态场景中的贝叶斯优化(BO)。对于这些场景的现有算法通常需要广泛的超参数调制,这限制了它们的实际有效性。我们提出了一种框架,叫做BALLET,它以高信任区域的兴趣(ROI)作为高级的非参数概率模型,例如高斯过程(GP)的超级集合进行自适应滤波。我们的方法很容易调制,并且能够集中于现有的BO方法来处理的优化空间的局部区域。关键概念是使用两个概率模型:粗糙GP来识别ROI,和局部GP来优化ROI。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23aj.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23aj/zhang23aj.pdf)** 

# A Category-theoretical Meta-analysis of Definitions of Disentanglement
**题目:** 混淆定义的分类理论 Meta-分析

**作者:** Yivan Zhang, Masashi Sugiyama

**Abstract:** Disentangling the factors of variation in data is a fundamental concept in machine learning and has been studied in various ways by different researchers, leading to a multitude of definitions. Despite the numerous empirical studies, more theoretical research is needed to fully understand the defining properties of disentanglement and how different definitions relate to each other. This paper presents a meta-analysis of existing definitions of disentanglement, using category theory as a unifying and rigorous framework. We propose that the concepts of the cartesian and monoidal products should serve as the core of disentanglement. With these core concepts, we show the similarities and crucial differences in dealing with (i) functions, (ii) equivariant maps, (iii) relations, and (iv) stochastic maps. Overall, our meta-analysis deepens our understanding of disentanglement and its various formulations and can help researchers navigate different definitions and choose the most appropriate one for their specific context.

**摘要:** 数据变异因素的解构是机器学习的一个基本概念,由不同的研究者以各种方式研究,导致了多种定义。尽管进行了大量的实证研究,但为了全面理解解构的定义性质以及不同的定义如何相互关联,需要更多的理论研究。本论文以类别理论为统一和严格的框架,对现有解构定义的元分析。我们提议, cartesian和 monoidal产品的概念应作为解构的核心。通过这些核心概念,我们展示了处理(i)函数、(ii)等效映射、(iii)关系和(iv)随机映射的相似性和关键差异。总的来说,我们的元分析深入了我们对分离及其各种公式的理解,并可以帮助研究者导航不同的定义并选择最适合他们的具体环境的定义。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ak.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ak/zhang23ak.pdf)** 

# On the Convergence of SARSA with Linear Function Approximation
**题目:** SARSA与线性函数近似的融合

**作者:** Shangtong Zhang, Remi Tachet Des Combes, Romain Laroche

**Abstract:** SARSA, a classical on-policy control algorithm for reinforcement learning, is known to chatter when combined with linear function approximation: SARSA does not diverge but oscillates in a bounded region. However, little is known about how fast SARSA converges to that region and how large the region is. In this paper, we make progress towards this open problem by showing the convergence rate of projected SARSA to a bounded region. Importantly, the region is much smaller than the region that we project into, provided that the the magnitude of the reward is not too large. Existing works regarding the convergence of linear SARSA to a fixed point all require the Lipschitz constant of SARSA’s policy improvement operator to be sufficiently small; our analysis instead applies to arbitrary Lipschitz constants and thus characterizes the behavior of linear SARSA for a new regime.

**摘要:** SARSA是一种经典的增强学习策略控制算法,它与线性函数近似结合时便知其易于交谈: SARSA不分离,而是在有限区域振荡;然而,人们对该区域和该区域的收敛速度以及区域的大小几乎无所知。本文通过显示投影 SARSA对有限区域的收敛率来实现这一开放问题。重要的是,该区域比我们投影的区域小得多,只要奖励的大小不太大。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23al.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23al/zhang23al.pdf)** 

# AdaNPC: Exploring Non-Parametric Classifier for Test-Time Adaptation
**题目:** AdaNPC:测试时间适应的非参数分类器研究

**作者:** Yifan Zhang, Xue Wang, Kexin Jin, Kun Yuan, Zhang Zhang, Liang Wang, Rong Jin, Tieniu Tan

**Abstract:** Many recent machine learning tasks focus to develop models that can generalize to unseen distributions. Domain generalization (DG) has become one of the key topics in various fields. Several literatures show that DG can be arbitrarily hard without exploiting target domain information. To address this issue, test-time adaptive (TTA) methods are proposed. Existing TTA methods require offline target data or extra sophisticated optimization procedures during the inference stage. In this work, we adopt Non-Parametric Classifier to perform the test-time Adaptation (AdaNPC). In particular, we construct a memory that contains the feature and label pairs from training domains. During inference, given a test instance, AdaNPC first recalls $k$ closed samples from the memory to vote for the prediction, and then the test feature and predicted label are added to the memory. In this way, the sample distribution in the memory can be gradually changed from the training distribution towards the test distribution with very little extra computation cost. We theoretically justify the rationality behind the proposed method. Besides, we test our model on extensive numerical experiments. AdaNPC significantly outperforms competitive baselines on various DG benchmarks. In particular, when the adaptation target is a series of domains, the adaptation accuracy of AdaNPC is $50$% higher than advanced TTA methods.

**摘要:** 许多最近的机器学习任务集中开发模型,可以将它们推广到未见的分布。域一般化(DG)已成为各个领域的关键主题之一。一些文献表明,DG可以在不利用目标域信息的情况下任意困难。为了解决这个问题,提出了测试时间适应性(TTA)方法。现有TTA方法需要在推理阶段的离线目标数据或额外复杂的优化程序。在这个工作中,我们采用非参数分类器来执行测试时间适应性(AdaNPC)。在理论上,我们证明了该方法背后的合理性。此外,我们在广泛的数值实验中测试了我们的模型。AdaNPC在不同DG基准上的竞争性基准水平明显高于AdaNPC。特别是当适应目标是一系列领域时,AdaNPC的适应精度比先进的TTA方法高50$%。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23am.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23am/zhang23am.pdf)** 

# On the Generalization of Multi-modal Contrastive Learning
**题目:** 多模反向学习的一般化

**作者:** Qi Zhang, Yifei Wang, Yisen Wang

**Abstract:** Multi-modal contrastive learning (MMCL) has recently garnered considerable interest due to its superior performance in visual tasks, achieved by embedding multi-modal data, such as visual-language pairs. However, there still lack theoretical understandings of how MMCL extracts useful visual representation from multi-modal pairs, and particularly, how MMCL outperforms previous approaches like self-supervised contrastive learning (SSCL). In this paper, by drawing an intrinsic connection between MMCL and asymmetric matrix factorization, we establish the first generalization guarantees of MMCL for visual downstream tasks. Based on this framework, we further unify MMCL and SSCL by showing that MMCL implicitly performs SSCL with (pseudo) positive pairs induced by text pairs. Through this unified perspective, we characterize the advantage of MMCL by showing that text pairs induce more semantically consistent and diverse positive pairs, which, according to our analysis, provably benefit downstream generalization. Inspired by this finding, we propose several methods to significantly improve the downstream performance of SSCL on ImageNet by leveraging multi-modal information. Code is available at https://github.com/PKU-ML/CLIP-Help-SimCLR.

**摘要:** 多模对比性学习(MMCL)由于多模数据的嵌入,例如视觉语言对,在视觉任务中具有较高的性能,因此最近引起了广泛的兴趣。然而,仍缺乏对MMCL如何从多模对中提取有用的视觉表示方法的理论理解,特别是MMCL如何超越以往的自我监督对比性学习(SSCL)方法。本文通过对MMCL和非对称矩阵因子化之间的内在联系,建立了MMCL对视觉下游任务的第一个一般化保证。通过这一统一的视角,我们通过显示文本对诱导更具有语义一致和多样性的正对来描述MMCL的优点,根据我们的分析,可以证明其有利于下游的一般化。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23an.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23an/zhang23an.pdf)** 

# ConCerNet: A Contrastive Learning Based Framework for Automated Conservation Law Discovery and Trustworthy Dynamical System Prediction
**题目:** ConCerNet:一种基于对比学习的自动保护法发现和可靠动态系统预测框架

**作者:** Wang Zhang, Tsui-Wei Weng, Subhro Das, Alexandre Megretski, Luca Daniel, Lam M. Nguyen

**Abstract:** Deep neural networks (DNN) have shown great capacity of modeling a dynamical system; nevertheless, they usually do not obey physics constraints such as conservation laws. This paper proposes a new learning framework named $\textbf{ConCerNet}$ to improve the trustworthiness of the DNN based dynamics modeling to endow the invariant properties. $\textbf{ConCerNet}$ consists of two steps: (i) a contrastive learning method to automatically capture the system invariants (i.e. conservation properties) along the trajectory observations; (ii) a neural projection layer to guarantee that the learned dynamics models preserve the learned invariants. We theoretically prove the functional relationship between the learned latent representation and the unknown system invariant function. Experiments show that our method consistently outperforms the baseline neural networks in both coordinate error and conservation metrics by a large margin. With neural network based parameterization and no dependence on prior knowledge, our method can be extended to complex and large-scale dynamics by leveraging an autoencoder.

**摘要:** 深度神经网络(DNN)具有建模动态系统的能力;然而,它们通常不遵循物理约束,如保护法。本文提出了一种名为$\textbf{ConCerNet}$的新学习框架,以提高基于DNN的动态建模的可信性,以赋予不变性特性。$\textbf{ConCerNet}$由两个步骤组成: (i)一种对比学习方法,以自动捕捉系统不变性(即保护特性)沿着轨迹观测; (ii)一种神经投影层,以保证学习动态模型保存学习不变性。基于神经网络的参数化,不依赖于先前的知识,利用自动编码器可以扩展到复杂的大规模动态中。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ao.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ao/zhang23ao.pdf)** 

# Towards Trustworthy Explanation: On Causal Rationalization
**题目:** 走向可信的解释:基于原因的理性化

**作者:** Wenbo Zhang, Tong Wu, Yunlong Wang, Yong Cai, Hengrui Cai

**Abstract:** With recent advances in natural language processing, rationalization becomes an essential self-explaining diagram to disentangle the black box by selecting a subset of input texts to account for the major variation in prediction. Yet, existing association-based approaches on rationalization cannot identify true rationales when two or more snippets are highly inter-correlated and thus provide a similar contribution to prediction accuracy, so-called spuriousness. To address this limitation, we novelly leverage two causal desiderata, non-spuriousness and efficiency, into rationalization from the causal inference perspective. We formally define a series of probabilities of causation based on a newly proposed structural causal model of rationalization, with its theoretical identification established as the main component of learning necessary and sufficient rationales. The superior performance of the proposed causal rationalization is demonstrated on real-world review and medical datasets with extensive experiments compared to state-of-the-art methods.

**摘要:** 随着自然语言处理的最新进展,合理化成为一种重要的自我解释图,通过选择输入文本的子集来分开黑框,以解释预测中的巨大变化。然而,现有基于关联的合理化方法无法在两个或多个片段高度相互关联时识别真正的合理性,从而为预测准确性提供类似的贡献,称为虚伪性。为了解决这一限制,我们从因果推理角度引入两个因果愿望,即非虚伪性和效率。通过广泛的实验,在实时审查和医学数据集中,与最先进的方法相比,证明了拟议的因果合理化的优越性。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ap.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ap/zhang23ap.pdf)** 

# Demystifying Uneven Vulnerability of Link Stealing Attacks against Graph Neural Networks
**题目:** 对图形神经网络的链路盗窃攻击的不均匀脆弱性的解明

**作者:** He Zhang, Bang Wu, Shuo Wang, Xiangwen Yang, Minhui Xue, Shirui Pan, Xingliang Yuan

**Abstract:** While graph neural networks (GNNs) dominate the state-of-the-art for exploring graphs in real-world applications, they have been shown to be vulnerable to a growing number of privacy attacks. For instance, link stealing is a well-known membership inference attack (MIA) on edges that infers the presence of an edge in a GNN’s training graph. Recent studies on independent and identically distributed data (e.g., images) have empirically demonstrated that individuals from different groups suffer from different levels of privacy risks to MIAs, i.e., uneven vulnerability. However, theoretical evidence of such uneven vulnerability is missing. In this paper, we first present theoretical evidence of the uneven vulnerability of GNNs to link stealing attacks, which lays the foundation for demystifying such uneven risks among different groups of edges. We further demonstrate a group-based attack paradigm to expose the practical privacy harm to GNN users derived from the uneven vulnerability of edges. Finally, we empirically validate the existence of obvious uneven vulnerability on nine real-world datasets (e.g., about 25% AUC difference between different groups in the Credit graph). Compared with existing methods, the outperformance of our group-based attack paradigm confirms that customising different strategies for different groups results in more effective privacy attacks.

**摘要:** graph neural networks(GNNs)在探索真实世界应用中的图形方面占主导地位,但它们已经被证明易受越来越多的私隐攻击。例如,链路盗窃是在边上的一个众所周知的成员推断攻击(MIA),它推断了GNN训练图中的边的存在。最近对独立和同等分布的数据(例如图像)的研究表明,来自不同群体的个人对MIA有不同程度的私隐风险,即不均匀脆弱性。然而,这种不均匀脆弱性缺乏理论证据。最后,我们以实例验证了九个实物数据集存在明显的不均性脆弱性(例如,信用图中不同组间的AUC差约25%)。与现有方法相比,我们基于群的攻击模式的优越性证实了对不同组的不同策略的定制导致了更有效的隐私攻击。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23aq.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23aq/zhang23aq.pdf)** 

# Provable Dynamic Fusion for Low-Quality Multimodal Data
**题目:** 提供低质量多模数据动态融合

**作者:** Qingyang Zhang, Haitao Wu, Changqing Zhang, Qinghua Hu, Huazhu Fu, Joey Tianyi Zhou, Xi Peng

**Abstract:** The inherent challenge of multimodal fusion is to precisely capture the cross-modal correlation and flexibly conduct cross-modal interaction. To fully release the value of each modality and mitigate the influence of low-quality multimodal data, dynamic multimodal fusion emerges as a promising learning paradigm. Despite its widespread use, theoretical justifications in this field are still notably lacking. Can we design a provably robust multimodal fusion method? This paper provides theoretical understandings to answer this question under a most popular multimodal fusion framework from the generalization perspective. We proceed to reveal that several uncertainty estimation solutions are naturally available to achieve robust multimodal fusion. Then a novel multimodal fusion framework termed Quality-aware Multimodal Fusion (QMF) is proposed, which can improve the performance in terms of classification accuracy and model robustness. Extensive experimental results on multiple benchmarks can support our findings.

**摘要:** 多模融合的本质挑战是准确地捕捉多模相关性并灵活地进行多模相互作用。为了充分释放每个模态的价值并减轻低质量多模数据的影响,动态多模融合成为一种有前途的学习范式。尽管其广泛应用,在这一领域仍缺乏理论依据。我们能设计一个可证明的强多模融合方法吗?本文提供了从一般化角度对最受欢迎的多模融合框架下对这个问题的理论理解。对多个基准的广泛实验结果可以支持我们的发现。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ar.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ar/zhang23ar.pdf)** 

# ReDi: Efficient Learning-Free Diffusion Inference via Trajectory Retrieval
**题目:** ReDi:基于推理检索的高效学习自由扩散ference

**作者:** Kexun Zhang, Xianjun Yang, William Yang Wang, Lei Li

**Abstract:** Diffusion models show promising generation capability for a variety of data. Despite their high generation quality, the inference for diffusion models is still time-consuming due to the numerous sampling iterations required. To accelerate the inference, we propose ReDi, a simple yet learning-free Retrieval-based Diffusion sampling framework. From a precomputed knowledge base, ReDi retrieves a trajectory similar to the partially generated trajectory at an early stage of generation, skips a large portion of intermediate steps, and continues sampling from a later step in the retrieved trajectory. We theoretically prove that the generation performance of ReDi is guaranteed. Our experiments demonstrate that ReDi improves the model inference efficiency by 2$\times$ speedup. Furthermore, ReDi is able to generalize well in zero-shot cross-domain image generation such as image stylization. The code and demo for ReDi is available at https://github.com/zkx06111/ReDiffusion.

**摘要:** 扩散模型显示了各种数据的具有潜力的生成能力。尽管其高生成质量,扩散模型的推导仍然耗费时间,因为需要的大量采样迭代。为了加速推导,我们提出了ReDi,一个简单的,但无学习的,基于检索的扩散采样框架。从预估知识库中,ReDi在早期的生成阶段检索类似部分生成的轨迹,跳过中间步骤的大部分,并继续从检索的轨迹中采样。我们理论上证明,ReDi的生成性能是保证的。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23as.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23as/zhang23as.pdf)** 

# Nearly Optimal Competitive Ratio for Online Allocation Problems with Two-sided Resource Constraints and Finite Requests
**题目:** 两边资源限制和最终请求的在线分配问题近乎最佳竞争率

**作者:** Qixin Zhang, Wenbing Ye, Zaiyi Chen, Haoyuan Hu, Enhong Chen, Yu Yang

**Abstract:** In this paper, we investigate the online allocation problem of maximizing the overall revenue subject to both lower and upper bound constraints. Compared to the extensively studied online problems with only resource upper bounds, the two-sided constraints affect the prospects of resource consumption more severely. As a result, only limited violations of constraints or pessimistic competitive bounds could be guaranteed. To tackle the challenge, we define a measure of feasibility $\xi^*$ to evaluate the hardness of this problem, and estimate this measurement by an optimization routine with theoretical guarantees. We propose an online algorithm adopting a constructive framework, where we initialize a threshold price vector using the estimation, then dynamically update the price vector and use it for decision-making at each step. It can be shown that the proposed algorithm is $\big(1-O(\frac{\varepsilon}{\xi^*-\varepsilon})\big)$ or $\big(1-O(\frac{\varepsilon}{\xi^*-\sqrt{\varepsilon}})\big)$ competitive with high probability for $\xi^*$ known or unknown respectively. To the best of our knowledge, this is the first result establishing a nearly optimal competitive algorithm for solving two-sided constrained online allocation problems with a high probability of feasibility.

**摘要:** 本文研究了基于上下界限约束的总体收入最大化网络分配问题,与基于资源上限约束的广泛研究的网络问题相比,双边约束更严重地影响资源消费前景。结果,只有有限的约束或悲观的竞争界限的侵犯才能得到保证。为了解决这一问题,我们定义了可行的度量 $\xi^*$来评估这一问题的硬度,并通过理论保证的优化程序估计这个度量。可以证明,提议的算法是$\big(1-O(\frac{\varepsilon}{\xi^*-\varepsilon})\big)$或$\big(1-O(\frac{\varepsilon}{\xi^*-\sqrt{\varepsilon}})\big)$对$\xi^*$具有较高的概率的竞争算法,分别是已知或未知。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23at.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23at/zhang23at.pdf)** 

# Do You Remember? Overcoming Catastrophic Forgetting for Fake Audio Detection
**题目:** 你还记得吗?克服错声检测的灾难性遗忘

**作者:** Xiaohui Zhang, Jiangyan Yi, Jianhua Tao, Chenglong Wang, Chu Yuan Zhang

**Abstract:** Current fake audio detection algorithms have achieved promising performances on most datasets. However, their performance may be significantly degraded when dealing with audio of a different dataset. The orthogonal weight modification to overcome catastrophic forgetting does not consider the similarity of genuine audio across different datasets. To overcome this limitation, we propose a continual learning algorithm for fake audio detection to overcome catastrophic forgetting, called Regularized Adaptive Weight Modification (RAWM). When fine-tuning a detection network, our approach adaptively computes the direction of weight modification according to the ratio of genuine utterances and fake utterances. The adaptive modification direction ensures the network can effectively detect fake audio on the new dataset while preserving its knowledge of old model, thus mitigating catastrophic forgetting. In addition, genuine audio collected from quite different acoustic conditions may skew their feature distribution, so we introduce a regularization constraint to force the network to remember the old distribution in this regard. Our method can easily be generalized to related fields, like speech emotion recognition. We also evaluate our approach across multiple datasets and obtain a significant performance improvement on cross-dataset experiments.

**摘要:** 当前的伪音频检测算法在大多数数据集中取得了令人期待的性能。然而,当处理不同数据集的音频时,它们的性能可能会大幅下降。克服灾难性遗忘的正交重量修改并不考虑在不同数据集中真实音频的相似性。为了克服这一限制,我们提出了一种持续学习算法,用于克服灾难性遗忘的伪音频检测,称为“规范化适应性重量修改”(RAWM)。在精细调制检测网络时,我们的方法以适应性计算重量修改的方向,根据真实语句和伪语句的比率。适应性修改方向确保网络能够有效地检测新数据集的伪音频,同时保持其对旧模型的知识,从而减轻灾难性遗忘。此外,从不同的音频条件收集的真音频可能扭曲其特征分布,因此我们引入了规则化约束来强迫网络在此方面记住旧的分布。我们的方法可以轻易地推广到相关领域,如语音情感识别。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23au.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23au/zhang23au.pdf)** 

# Coder Reviewer Reranking for Code Generation
**题目:** 编码审查员重新排序代码生成

**作者:** Tianyi Zhang, Tao Yu, Tatsunori Hashimoto, Mike Lewis, Wen-Tau Yih, Daniel Fried, Sida Wang

**Abstract:** Sampling diverse programs from a code language model and reranking with model likelihood is a popular method for code generation but it is prone to preferring degenerate solutions. Inspired by collaborative programming, we propose Coder-Reviewer reranking. We augment Coder language models from past work, which generate programs given language instructions, with Reviewer models, which evaluate the likelihood of the instruction given the generated programs. We perform an extensive study across six datasets with eight models from three model families. Experimental results show that Coder-Reviewer reranking leads to consistent and significant improvement (up to 17% absolute accuracy gain) over reranking with the Coder model only. When combined with executability filtering, Coder-Reviewer reranking can often outperform the minimum Bayes risk method. Coder-Reviewer reranking is easy to implement by prompting, can generalize to different programming languages, and works well with off-the-shelf hyperparameters.

**摘要:** 从代码语言模型中提取不同的程序和重新排序与模型概率是代码生成的一个流行方法,但它倾向于偏好退化解决方案。 受协作编程的启发,我们提出了Coder-Reviewer重新排序。 我们从过去的工作中增加Coder语言模型,生成给语言指令的程序,与Reviewer模型,评估给生成程序的指令的可能性。Coder-Reviewer重排是通过提示实现的简单,可以将重排推广到不同的编程语言,并且在市场上的超参数上也很好。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23av.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23av/zhang23av.pdf)** 

# DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for Large-Scale Bayesian Inference
**题目:** DP-Fast MH:私人、快速、准确的大型贝伊西亚环流系统

**作者:** Wanrong Zhang, Ruqi Zhang

**Abstract:** Bayesian inference provides a principled framework for learning from complex data and reasoning under uncertainty. It has been widely applied in machine learning tasks such as medical diagnosis, drug design, and policymaking. In these common applications, data can be highly sensitive. Differential privacy (DP) offers data analysis tools with powerful worst-case privacy guarantees and has been developed as the leading approach in privacy-preserving data analysis. In this paper, we study Metropolis-Hastings (MH), one of the most fundamental MCMC methods, for large-scale Bayesian inference under differential privacy. While most existing private MCMC algorithms sacrifice accuracy and efficiency to obtain privacy, we provide the first exact and fast DP MH algorithm, using only a minibatch of data in most iterations. We further reveal, for the first time, a three-way trade-off among privacy, scalability (i.e. the batch size), and efficiency (i.e. the convergence rate), theoretically characterizing how privacy affects the utility and computational cost in Bayesian inference. We empirically demonstrate the effectiveness and efficiency of our algorithm in various experiments.

**摘要:** 贝叶斯推理提供了从复杂数据和不确定下推理学习的原理框架。它广泛应用于机器学习任务,如医疗诊断、药物设计和决策。在这些共同应用中,数据可以高度敏感。差分隐私(DP)提供数据分析工具,具有最强的最坏情况隐私保证,并作为隐私保护数据分析的领先方法开发。本论文中,我们研究了Metropolis-Hastings(MH),一个最基本的MCMC方法,用于大规模贝叶斯推理在差分隐私下。),从理论上描述了隐私如何影响贝叶斯推理的实用性和计算成本。我们在各种实验中实证了我们的算法的有效性和效率。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23aw.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23aw/zhang23aw.pdf)** 

# Nearly-tight Bounds for Deep Kernel Learning
**题目:** 深核学习的近距离约束

**作者:** Yifan Zhang, Min-Ling Zhang

**Abstract:** The generalization analysis of deep kernel learning (DKL) is a crucial and open problem of kernel methods for deep learning. The implicit nonlinear mapping in DKL makes existing methods of capacity-based generalization analysis for deep learning invalid. In an attempt to overcome this challenge and make up for the gap in the generalization theory of DKL, we develop an analysis method based on the composite relationship of function classes and derive capacity-based bounds with mild dependence on the depth, which generalizes learning theory bounds to deep kernels and serves as theoretical guarantees for the generalization of DKL. In this paper, we prove novel and nearly-tight generalization bounds based on the uniform covering number and the Rademacher chaos complexity for deep (multiple) kernel machines. In addition, for some common classes, we estimate their uniform covering numbers and Rademacher chaos complexities by bounding their pseudo-dimensions and kernel pseudo-dimensions, respectively. The mild bounds without strong assumptions partially explain the good generalization ability of deep learning combined with kernel methods.

**摘要:** 深层核学习的广义化分析是深层核方法的一个关键和开放问题。深层核学习的隐含非线性映射使得现有的基于能力的广义化分析方法无效。为了克服这一挑战和弥补DKL广义化理论中的差距,我们开发了一个基于函数类的复合关系的分析方法,并以深度的轻度依赖性导出基于能力的边界,将学习理论的边界推广到深层核,并作为DKL广义化理论的理论保证。此外,对于一些普通类,我们通过对它们的伪次元和核伪次元分别旋转来估计它们的均匀覆盖数和拉德马切尔混沌复杂性。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ax.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ax/zhang23ax.pdf)** 

# OpenFE: Automated Feature Generation with Expert-level Performance
**题目:** OpenFE:专家级性能的自动化功能生成

**作者:** Tianping Zhang, Zheyu Aqa Zhang, Zhiyuan Fan, Haoyan Luo, Fengyuan Liu, Qian Liu, Wei Cao, Li Jian

**Abstract:** The goal of automated feature generation is to liberate machine learning experts from the laborious task of manual feature generation, which is crucial for improving the learning performance of tabular data. The major challenge in automated feature generation is to efficiently and accurately identify effective features from a vast pool of candidate features. In this paper, we present OpenFE, an automated feature generation tool that provides competitive results against machine learning experts. OpenFE achieves high efficiency and accuracy with two components: 1) a novel feature boosting method for accurately evaluating the incremental performance of candidate features and 2) a two-stage pruning algorithm that performs feature pruning in a coarse-to-fine manner. Extensive experiments on ten benchmark datasets show that OpenFE outperforms existing baseline methods by a large margin. We further evaluate OpenFE in two Kaggle competitions with thousands of data science teams participating. In the two competitions, features generated by OpenFE with a simple baseline model can beat 99.3% and 99.6% data science teams respectively. In addition to the empirical results, we provide a theoretical perspective to show that feature generation can be beneficial in a simple yet representative setting.

**摘要:** 自动特征生成的目的是使机器学习专家免于手工特征生成的繁琐任务,这对于提高表数据学习性能至关重要。自动特征生成的主要挑战是从大量候选特征中有效地和准确地识别有效的特征。本论文介绍OpenFE,一种针对机器学习专家提供竞争性结果的自动特征生成工具。OpenFE具有两个组成部分的高效率和准确性:(一)为准确评价候选特征的增量性能提供一种新颖的特征增强方法,(二)为粗糙到精细的方式进行特征剪切的两个阶段剪切算法。在两项比赛中,OpenFE的基于简单的基线模型的特征可以分别胜出99.3%和99.6%的数据科学团队。除了实验结果外,我们提供了一个理论的视角,以证明在简单但具有代表性的环境中,特征生成是有益的。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ay.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ay/zhang23ay.pdf)** 

# Optimal Horizon-Free Reward-Free Exploration for Linear Mixture MDPs
**题目:** 线性混合物MDP最佳水平自由奖励自由探索

**作者:** Junkai Zhang, Weitong Zhang, Quanquan Gu

**Abstract:** We study reward-free reinforcement learning (RL) with linear function approximation, where the agent works in two phases: (1) in the exploration phase, the agent interacts with the environment but cannot access the reward; and (2) in the planning phase, the agent is given a reward function and is expected to find a near-optimal policy based on samples collected in the exploration phase. The sample complexities of existing reward-free algorithms have a polynomial dependence on the planning horizon, which makes them intractable for long planning horizon RL problems. In this paper, we propose a new reward-free algorithm for learning linear mixture Markov decision processes (MDPs), where the transition probability can be parameterized as a linear combination of known feature mappings. At the core of our algorithm is uncertainty-weighted value-targeted regression with exploration-driven pseudo-reward and a high-order moment estimator for the aleatoric and epistemic uncertainties. When the total reward is bounded by $1$, we show that our algorithm only needs to explore $\tilde O\left( d^2\varepsilon^{-2}\right)$ episodes to find an $\varepsilon$-optimal policy, where $d$ is the dimension of the feature mapping. The sample complexity of our algorithm only has a polylogarithmic dependence on the planning horizon and therefore is "horizon-free”. In addition, we provide an $\Omega\left(d^2\varepsilon^{-2}\right)$ sample complexity lower bound, which matches the sample complexity of our algorithm up to logarithmic factors, suggesting that our algorithm is optimal.

**摘要:** 我们研究了基于线性函数近似的 reward-free reinforcement learning(RL),其中代理在两个阶段工作: (1)在探索阶段,代理与环境相互作用,但无法访问奖励; (2)在规划阶段,代理得到奖励函数,并期望在探索阶段收集的样品的基础上找到 near-optimal政策。现有的 reward-free算法的样品复杂性依赖于规划地平线,使得它们无法解决长期规划地平线RL问题。当总奖金被限制为$1时,我们证明我们的算法只需要探索$\tilde O\left(d^2\varepsilon^{-2}\right)$片段才能找到$\varepsilon$-optimal策略,其中$d$是特征映射的维度。我们的算法的样品复杂性只依赖于规划地平线,因此是“地平线自由”。此外,我们提供了$\Omega\left(d^2\varepsilon^{-2}\right)$样品复杂性较低的界限,这匹配了我们的算法的样品复杂性到数值因素,暗示我们的算法是最佳的。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23az.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23az/zhang23az.pdf)** 

# Unlocking Slot Attention by Changing Optimal Transport Costs
**题目:** 通过改变最佳运输成本来解锁 Slot注意

**作者:** Yan Zhang, David W. Zhang, Simon Lacoste-Julien, Gertjan J. Burghouts, Cees G. M. Snoek

**Abstract:** Slot attention is a powerful method for object-centric modeling in images and videos. However, its set-equivariance limits its ability to handle videos with a dynamic number of objects because it cannot break ties. To overcome this limitation, we first establish a connection between slot attention and optimal transport. Based on this new perspective we propose MESH (Minimize Entropy of Sinkhorn): a cross-attention module that combines the tiebreaking properties of unregularized optimal transport with the speed of regularized optimal transport. We evaluate slot attention using MESH on multiple object-centric learning benchmarks and find significant improvements over slot attention in every setting.

**摘要:** 网格注意力是图像和视频中面向对象建模的强有力方法,但其设置等效性限制了它能够处理视频的动态对象数目,因为它不能打破链路。为了克服这一限制,我们首先建立网格注意力和最佳运输之间的联系。基于这一新视角,我们提出了MESH(Minimize Entropy of Sinkhorn):一个交叉注意模块,它将非调节的最佳运输的链路分割特性与调节的最佳运输的速度结合起来。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23ba.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23ba/zhang23ba.pdf)** 

# Towards a Persistence Diagram that is Robust to Noise and Varied Densities
**题目:** 对噪声和不同密度的持久度图

**作者:** Hang Zhang, Kaifeng Zhang, Kai Ming Ting, Ye Zhu

**Abstract:** Recent works have identified that existing methods, which construct persistence diagrams in Topological Data Analysis (TDA), are not robust to noise and varied densities in a point cloud. We analyze the necessary properties of an approach that can address these two issues, and propose a new filter function for TDA based on a new data-dependent kernel which possesses these properties. Our empirical evaluation reveals that the proposed filter function provides a better means for t-SNE visualization and SVM classification than three existing methods of TDA.

**摘要:** 最近的研究发现,在拓扑数据分析(TDA)中构造持久度图的现有方法对点云中噪声和不同密度不强。我们分析了解决这两个问题的方法所需的特性,并提出了一种基于这些特性的新数据依赖核的TDA新的滤波函数。我们的实证评价表明,提议的滤波函数为TDA的三种现有方法提供了更好的 t-SNE 视觉和 SVM 分类手段。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23bb.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23bb/zhang23bb.pdf)** 

# Robust Situational Reinforcement Learning in Face of Context Disturbances
**题目:** 面对环境动荡的鲁棒形势强化学习

**作者:** Jinpeng Zhang, Yufeng Zheng, Chuheng Zhang, Li Zhao, Lei Song, Yuan Zhou, Jiang Bian

**Abstract:** In many real-world tasks, some parts of state features, called contexts, are independent of action signals, e.g., customer demand in inventory control, speed of lead car in autonomous driving, etc. One of the challenges of reinforcement learning in these applications is that the true context transitions can be easily exposed some unknown source of contamination, leading to a shift of context transitions between source domains and target domains, which could cause performance degradation for RL algorithms. However, existing methods on robust RL aim at learning robust policies against the deviations of the entire system dynamics. To tackle this problem, this paper proposes the framework of robust situational Markov decision process (RS-MDP) which captures the possible deviations of context transitions explicitly. To scale to large context space, we introduce the softmin smoothed robust Bellman operator to learn the robust Q-value approximately, and apply our RS-MDP framework to existing RL algorithm SAC to learn the desired robust policies. We conduct experiments on several robot control tasks with dynamic contexts and inventory control tasks to demonstrate that our algorithm can generalize better and more robust against deviations of context transitions, and outperform existing robust RL algorithms.

**摘要:** 在许多现实任务中,一些状态特征,即语境,是独立于动作信号的,例如在库存控制中客户需求、在自主驾驶中铅车的速度等。在这些应用中,强化学习的一个挑战是,真正的语境过渡很容易暴露一些未知污染源,导致源域和目标域之间语境过渡的转变,从而导致RL算法的性能下降。为了扩展到大范围的上下文空间,我们引入软敏平滑的鲁棒贝尔曼操作器来学习鲁棒Q值,并应用RS-MDP框架到现有的RL算法SAC来学习所需的鲁棒策略。我们对几个具有动态上下文的机器人控制任务和库存控制任务进行了实验,证明我们的算法能够对上下文转换的偏差进行更强的通用化,并且超过现有的鲁棒RL算法。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23bc.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23bc/zhang23bc.pdf)** 

# Patch-level Contrastive Learning via Positional Query for Visual Pre-training
**题目:** 基于位置查询的多层对比学习,用于视觉预训练

**作者:** Shaofeng Zhang, Qiang Zhou, Zhibin Wang, Fan Wang, Junchi Yan

**Abstract:** Dense contrastive learning (DCL) has been recently explored for learning localized information for dense prediction tasks (e.g., detection and segmentation). It still suffers the difficulty of mining pixels/patches correspondence between two views. A simple way is inputting the same view twice and aligning the pixel/patch representation. However, it would reduce the variance of inputs, and hurts the performance. We propose a plug-in method PQCL (Positional Query for patch-level Contrastive Learning), which allows performing patch-level contrasts between two views with exact patch correspondence. Besides, by using positional queries, PQCL increases the variance of inputs, to enhance training. We apply PQCL to popular transformer-based CL frameworks (DINO and iBOT, and evaluate them on classification, detection and segmentation tasks, where our method obtains stable improvements, especially for dense tasks. It achieves new state-of-the-art in most settings. Code is available at https://github.com/Sherrylone/Query_Contrastive.

**摘要:** 密度对比学习(英语:Dense contrastive learning,缩写为DCL)是用于学习密度预测任务(例如检测和分割)的本地化信息的,它仍承受着两个视图之间挖掘像素/批量对照的困难。一种简单的方法是输入相同的视图两次,并排列像素/批量对照。然而,它会减少输入的差异,并损害性能。我们提出了一种插件方法PQCL(Positional Query for patch-level Contrastive Learning,缩写为PQCL),它允许在两个视图之间进行准确的批量对照的批量对照。此外,通过使用位置查询,PQCL增加了输入的差异,增强训练。代码可以在 https://github.com/Sherrylone/Query_Contrative上找到。

**[Paper URL](https://proceedings.mlr.press/v202/zhang23bd.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhang23bd/zhang23bd.pdf)** 

# Men Also Do Laundry: Multi-Attribute Bias Amplification
**题目:** 男士也做洗衣:多属性偏差放大

**作者:** Dora Zhao, Jerone Andrews, Alice Xiang

**Abstract:** The phenomenon of $\textit{bias amplification}$ occurs when models amplify training set biases at test time. Existing metrics measure bias amplification with respect to single annotated attributes (e.g., $\texttt{computer}$). However, large-scale datasets typically consist of instances with multiple attribute annotations (e.g., $\{\texttt{computer}, \texttt{keyboard}\}$). We demonstrate models can learn to exploit correlations with respect to multiple attributes, which are not accounted for by current metrics. Moreover, we show that current metrics can give the erroneous impression that little to no bias amplification has occurred as they aggregate positive and negative bias scores. Further, these metrics lack an ideal value, making them difficult to interpret. To address these shortcomings, we propose a new metric: $\textit{Multi-Attribute Bias Amplification}$. We validate our metric’s utility through a bias amplification analysis on the COCO, imSitu, and CelebA datasets. Finally, we benchmark bias mitigation methods using our proposed metric, suggesting possible avenues for future bias mitigation efforts.

**摘要:** $\textit{bias amplification}$现象发生在模型在测试时放大训练集合偏差时。现有的度量测量单个注释属性的偏差放大(例如$\texttt{computer}$)。然而,大规模数据集通常由多个属性注释的实例组成(例如$\texttt{computer}, \texttt{keyboard}\}$)。我们证明模型可以学习利用多个属性的关联,而这些属性不是当前度量所考虑的。此外,我们显示当前度量可以给错误的印象,因为它们聚集了积极和负偏差分数,因此难以解释。为了解决这些缺陷,我们提出了一个新的度量:$\textit{Multi-Attribute Bias Amplification}$。我们通过对COCO、imSitu和CelebA数据集的偏差放大分析验证了度量的功能。最后,我们利用我们提议的计量方法对偏见减低方法进行比较,提出今后偏见减低努力的可能途径。

**[Paper URL](https://proceedings.mlr.press/v202/zhao23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23a/zhao23a.pdf)** 

# Rockmate: an Efficient, Fast, Automatic and Generic Tool for Re-materialization in PyTorch
**题目:** Rockmate:一个高效、快速、自动和通用的PyTorch重塑工具

**作者:** Xunyi Zhao, Théotime Le Hellard, Lionel Eyraud-Dubois, Julia Gusak, Olivier Beaumont

**Abstract:** We propose Rockmate to control the memory requirements when training PyTorch DNN models. Rockmate is an automatic tool that starts from the model code and generates an equivalent model, using a predefined amount of memory for activations, at the cost of a few re-computations. Rockmate automatically detects the structure of computational and data dependencies and rewrites the initial model as a sequence of complex blocks. We show that such a structure is widespread and can be found in many models in the literature (Transformer based models, ResNet, RegNets,...). This structure allows us to solve the problem in a fast and efficient way, using an adaptation of Checkmate (too slow on the whole model but general) at the level of individual blocks and an adaptation of Rotor (fast but limited to sequential models) at the level of the sequence itself. We show through experiments on many models that Rockmate is as fast as Rotor and as efficient as Checkmate, and that it allows in many cases to obtain a significantly lower memory consumption for activations (by a factor of 2 to 5) for a rather negligible overhead (of the order of 10% to 20%). Rockmate is open source and available at https://github.com/topal-team/rockmate.

**摘要:** 我们建议Rockmate在训练PyTorchDNN模型时控制内存需求。Rockmate是一个自动工具,它从模型代码开始并生成一个等价模型,使用预定义的启动内存量,以数个重新计算的成本。Rockmate自动检测计算和数据依赖的结构,并重新编写初始模型为复杂块的序列。我们通过对许多模型的实验表明,Rockmate是像Rotor一样快速和像Checkmate一样高效,并且它在许多情况下能够获得相当低的内存消耗(以2至5的因子)以获得相当微不足道的开销(从10%到20%的顺序)。

**[Paper URL](https://proceedings.mlr.press/v202/zhao23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23b/zhao23b.pdf)** 

# Revisiting Structured Variational Autoencoders
**题目:** 重覆结构变量自动编码器

**作者:** Yixiu Zhao, Scott Linderman

**Abstract:** Structured variational autoencoders (SVAEs) combine probabilistic graphical model priors on latent variables, deep neural networks to link latent variables to observed data, and structure-exploiting algorithms for approximate posterior inference. These models are particularly appealing for sequential data, where the prior can capture temporal dependencies. However, despite their conceptual elegance, SVAEs have proven difficult to implement, and more general approaches have been favored in practice. Here, we revisit SVAEs using modern machine learning tools and demonstrate their advantages over more general alternatives in terms of both accuracy and efficiency. First, we develop a modern implementation for hardware acceleration, parallelization, and automatic differentiation of the message passing algorithms at the core of the SVAE. Second, we show that by exploiting structure in the prior, the SVAE learns more accurate models and posterior distributions, which translate into improved performance on prediction tasks. Third, we show how the SVAE can naturally handle missing data, and we leverage this ability to develop a novel, self-supervised training approach. Altogether, these results show that the time is ripe to revisit structured variational autoencoders.

**摘要:** 结构变量自动编码器(英语:Structured variational autoencoders,简称SVAE)结合了潜在变量上的概率图形模型预先,深度神经网络将潜在变量连接到观测数据,并利用结构推导算法进行近似后推导。这些模型尤其适用于序列数据,其中预先可以捕捉时间依赖性。然而,尽管它们具有概念优雅,SVAE已经证明难以实现,而且更普遍的方法在实践中得到了支持。其次,通过利用前者的结构,SVAE学习了更准确的模型和后方分布,从而提高了预测任务的性能。第三,我们展示了SVAE如何自然地处理丢失的数据,并利用这一能力开发一种新颖、自我监督的训练方法。

**[Paper URL](https://proceedings.mlr.press/v202/zhao23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23c/zhao23c.pdf)** 

# On Pitfalls of Test-Time Adaptation
**题目:** 测试时间适应的困境

**作者:** Hao Zhao, Yuejiang Liu, Alexandre Alahi, Tao Lin

**Abstract:** Test-Time Adaptation (TTA) has recently gained significant attention as a new paradigm for tackling distribution shifts. Despite the sheer number of existing methods, the inconsistent experimental conditions and lack of standardization in prior literature make it difficult to measure their actual efficacies and progress. To address this issue, we present a large-scale open-sourced Test-Time Adaptation Benchmark, dubbed TTAB, which includes nine state-of-the-art algorithms, a diverse array of distribution shifts, and two comprehensive evaluation protocols. Through extensive experiments, we identify three common pitfalls in prior efforts: (i) choosing appropriate hyper-parameter, especially for model selection, is exceedingly difficult due to online batch dependency; (ii) the effectiveness of TTA varies greatly depending on the quality of the model being adapted; (iii) even under optimal algorithmic conditions, existing methods still systematically struggle with certain types of distribution shifts. Our findings suggest that future research in the field should be more transparent about their experimental conditions, ensure rigorous evaluations on a broader set of models and shifts, and re-examine the assumptions underlying the potential success of TTA for practical applications.

**摘要:** 测试时间适应技术(英语:Test-Time Adaptation,TTAB)是解决分布变迁的新范式,在最近得到了大量关注。尽管现有方法数目非常多,但实验条件不一致和文献中缺乏标准化使得测量其实际效果和进展困难。通过广泛的实验,我们确定了前面的努力中的三个共同漏洞: (i)由于在线批量依赖性,选择适当的超参数,特别是模型选择,非常困难; (ii)TTA的有效性取决于被调整的模型的质量; (iii)即使在最佳的算法条件下,现有的方法仍系统地与某些类型的分布变换作斗争。

**[Paper URL](https://proceedings.mlr.press/v202/zhao23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23d/zhao23d.pdf)** 

# Addressing Budget Allocation and Revenue Allocation in Data Market Environments Using an Adaptive Sampling Algorithm
**题目:** 利用适应性采样算法解决数据市场环境中的预算分配和收入分配问题

**作者:** Boxin Zhao, Boxiang Lyu, Raul Castro Fernandez, Mladen Kolar

**Abstract:** High-quality machine learning models are dependent on access to high-quality training data. When the data are not already available, it is tedious and costly to obtain them. Data markets help with identifying valuable training data: model consumers pay to train a model, the market uses that budget to identify data and train the model (the budget allocation problem), and finally the market compensates data providers according to their data contribution (revenue allocation problem). For example, a bank could pay the data market to access data from other financial institutions to train a fraud detection model. Compensating data contributors requires understanding data’s contribution to the model; recent efforts to solve this revenue allocation problem based on the Shapley value are inefficient to lead to practical data markets. In this paper, we introduce a new algorithm to solve budget allocation and revenue allocation problems simultaneously in linear time. The new algorithm employs an adaptive sampling process that selects data from those providers who are contributing the most to the model. Better data means that the algorithm accesses those providers more often, and more frequent accesses corresponds to higher compensation. Furthermore, the algorithm can be deployed in both centralized and federated scenarios, boosting its applicability. We provide theoretical guarantees for the algorithm that show the budget is used efficiently and the properties of revenue allocation are similar to Shapley’s. Finally, we conduct an empirical evaluation to show the performance of the algorithm in practical scenarios and when compared to other baselines. Overall, we believe that the new algorithm paves the way for the implementation of practical data markets.

**摘要:** 高质量的机器学习模型依赖于高质量的培训数据的访问。当数据尚未可用时,获取数据是繁琐和昂贵的。数据市场有助于识别有价值的培训数据:模型消费者支付培训模型,市场利用预算来识别数据和培训模型(预算分配问题),最后市场根据数据贡献(收入分配问题)补偿数据提供者。新算法采用一种适应性抽样过程,从提供者中选取数据,这些提供者对模型的贡献最大。更好的数据意味着该算法更频繁地访问这些提供者,而更频繁的访问则符合较高的补偿。此外,该算法可以在集中和联合的场景中部署,增强其适用性。我们为该算法提供理论保证,表明预算有效使用,收入分配的性质与Shapley’s相似。最后,我们进行了实证评价,以显示该算法在实际场景中的表现和与其他基线相比。

**[Paper URL](https://proceedings.mlr.press/v202/zhao23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23e/zhao23e.pdf)** 

# X-Paste: Revisiting Scalable Copy-Paste for Instance Segmentation using CLIP and StableDiffusion
**题目:** X-Paste:使用CLIP和StableDiffusion进行实例分割的可 skalable Copy-Paste重置

**作者:** Hanqing Zhao, Dianmo Sheng, Jianmin Bao, Dongdong Chen, Dong Chen, Fang Wen, Lu Yuan, Ce Liu, Wenbo Zhou, Qi Chu, Weiming Zhang, Nenghai Yu

**Abstract:** Copy-Paste is a simple and effective data augmentation strategy for instance segmentation. By randomly pasting object instances onto new background images, it creates new training data for free and significantly boosts the segmentation performance, especially for rare object categories. Although diverse, high-quality object instances used in Copy-Paste result in more performance gain, previous works utilize object instances either from human-annotated instance segmentation datasets or rendered from 3D object models, and both approaches are too expensive to scale up to obtain good diversity. In this paper, we revisit Copy-Paste at scale with the power of newly emerged zero-shot recognition models (e.g., CLIP) and text2image models (e.g., StableDiffusion). We demonstrate for the first time that using a text2image model to generate images or zero-shot recognition model to filter noisily crawled images for different object categories is a feasible way to make Copy-Paste truly scalable. To make such success happen, we design a data acquisition and processing framework, dubbed “X-Paste", upon which a systematic study is conducted. On the LVIS dataset, X-Paste provides impressive improvements over the strong baseline CenterNet2 with Swin-L as the backbone. Specifically, it archives +2.6 box AP and +2.1 mask AP gains on all classes and even more significant gains with +6.8 box AP +6.5 mask AP on long-tail classes.

**摘要:** Copy-Paste是实例分割的简单有效的数据增强策略。通过随机贴入新背景图像的对象实例,它为免费创建新的训练数据,并显著提高分割性能,特别是对于稀有对象类别。虽然在 Copy-Paste中使用的各种、高质量的对象实例导致了更多的性能提升,但以前的工作则利用人类注释的实例分割数据集或从3D对象模型中渲染的对象实例,而这两个方法都太昂贵,以获得良好的多样性。为了实现这一成功,我们设计了一个数据采集和处理框架,称为“X-Paste”,在此基础上进行系统研究。在LVIS数据集上,X-Paste提供了强大的基线 CenterNet2的显著改进,其中Swin-L作为后台。具体而言,它 archives +2.6 box AP and +2.1 mask AP gains on all classes and even more significant gains with +6.8 box AP +6.5 mask AP on long-tail classes。

**[Paper URL](https://proceedings.mlr.press/v202/zhao23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23f/zhao23f.pdf)** 

# Revisiting Simple Regret: Fast Rates for Returning a Good Arm
**题目:** 重新回顾简单的遗憾:回赠一个好的武器的快速利率

**作者:** Yao Zhao, Connor Stephens, Csaba Szepesvari, Kwang-Sung Jun

**Abstract:** Simple regret is a natural and parameter-free performance criterion for pure exploration in multi-armed bandits yet is less popular than the probability of missing the best arm or an $\epsilon$-good arm, perhaps due to lack of easy ways to characterize it. In this paper, we make a significant progress on minimizing simple regret in both data-rich ($T\ge n$) and data-poor regime ($T \le n$) where $n$ is the number of arms and $T$ is the number of samples. At its heart is our improved instance-dependent analysis of the well-known Sequential Halving (SH) algorithm where we bound the probability of returning an arm whose mean reward is not within $\epsilon$ from the best (i.e., not $\epsilon$-good) for any choice of $\epsilon>0$, although $\epsilon$ is not an input to SH. Our bound not only leads to an optimal worst-case simple regret bound of $\sqrt{n/T}$ up to logarithmic factors but also essentially matches the instance-dependent lower bound for returning an $\epsilon$-good arm reported by Katz-Samuels and Jamieson (2020). For the more challenging data-poor regime, we propose Bracketing SH (BSH) that enjoys the same improvement even without sampling each arm at least once. Our empirical study shows that BSH outperforms existing methods on real-world tasks.

**摘要:** 简单的遗憾是多武器 bandit 的纯探索的自然、无参数性能标准,但与缺少最佳手臂或良好手臂的概率相比更少,可能是因为缺乏简单的特征方法。本文在数据丰富($T\ge n$)和数据贫乏($T \le n$)两方面,在最小化简单的遗憾方面取得了重大进展,其中$n$是手臂的数量和$T$是样品的数量。我们的约束不仅导致$sqrt{n/T}$的最优最坏情况下简单的遗憾约束到数值因素,而且基本符合由Katz-Samuels和Jamieson(2020)报告的$epsilon$-good arm返回的实例依赖下限。

**[Paper URL](https://proceedings.mlr.press/v202/zhao23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23g/zhao23g.pdf)** 

# Transformed Distribution Matching for Missing Value Imputation
**题目:** 变形分布匹配缺失值推定

**作者:** He Zhao, Ke Sun, Amir Dezfouli, Edwin V. Bonilla

**Abstract:** We study the problem of imputing missing values in a dataset, which has important applications in many domains. The key to missing value imputation is to capture the data distribution with incomplete samples and impute the missing values accordingly. In this paper, by leveraging the fact that any two batches of data with missing values come from the same data distribution, we propose to impute the missing values of two batches of samples by transforming them into a latent space through deep invertible functions and matching them distributionally. To learn the transformations and impute the missing values simultaneously, a simple and well-motivated algorithm is proposed. Our algorithm has fewer hyperparameters to fine-tune and generates high-quality imputations regardless of how missing values are generated. Extensive experiments over a large number of datasets and competing benchmark algorithms show that our method achieves state-of-the-art performance.

**摘要:** 本文研究了数据集中缺失值的归纳问题,该问题在许多领域具有重要的应用价值。缺失值归纳的关键是用不完整的样品捕捉数据分布,并相应归纳缺失值。本文通过利用任何两个数据批量与缺失值来自相同的数据分布的事实,提出将两个样品批量中的缺失值归纳为潜在空间,通过深度可逆函数和分布式匹配来归纳缺失值。

**[Paper URL](https://proceedings.mlr.press/v202/zhao23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23h/zhao23h.pdf)** 

# Protecting Language Generation Models via Invisible Watermarking
**题目:** 通过隐形水印保护语言生成模型

**作者:** Xuandong Zhao, Yu-Xiang Wang, Lei Li

**Abstract:** Language generation models have been an increasingly powerful enabler to many applications. Many such models offer free or affordable API access which makes them potentially vulnerable to model extraction attacks through distillation. To protect intellectual property (IP) and make fair use of these models, various techniques such as lexical watermarking and synonym replacement have been proposed. However, these methods can be nullified by obvious countermeasures such as “synonym randomization”. To address this issue, we propose GINSW, a novel method to protect text generation models from being stolen through distillation. The key idea of our method is to inject secret signals into the probability vector of the decoding steps for each target token. We can then detect the secret message by probing a suspect model to tell if it is distilled from the protected one. Experimental results show that GINSW can effectively identify instances of IP infringement with minimal impact on the generation quality of protected APIs. Our method demonstrates an absolute improvement of 19 to 29 points on mean average precision (mAP) in detecting suspects compared to previous methods against watermark removal attacks.

**摘要:** 语言生成模型对于许多应用程序具有越来越强大的功能。许多这样的模型提供免费或廉价的API访问,使得它们可能易于通过蒸馏对模型提取攻击。为了保护知识产权(IP)和公平使用这些模型,提出了各种技术,例如词汇水印和同义词替换。然而,这些方法可以通过明显的反措施如“同义词随机化”取消。为了解决这个问题,我们提出了GINSW,一种保护文本生成模型从蒸馏中被盗窃的新方法。我们的方法的关键思想是将秘密信号注入每个目标トークン的解码步骤的概率向量中。实验结果表明,GINSW能够有效地识别侵犯知识产权的案例,对保护API的生成质量产生最小影响。我们的方法在检测嫌疑人时,在检测水印除去攻击时,在平均精度(mAP)上显示了19至29点的绝对改进。

**[Paper URL](https://proceedings.mlr.press/v202/zhao23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23i/zhao23i.pdf)** 

# Local Optimization Achieves Global Optimality in Multi-Agent Reinforcement Learning
**题目:** 本地优化实现多代理强化学习的全球优化

**作者:** Yulai Zhao, Zhuoran Yang, Zhaoran Wang, Jason D. Lee

**Abstract:** Policy optimization methods with function approximation are widely used in multi-agent reinforcement learning. However, it remains elusive how to design such algorithms with statistical guarantees. Leveraging a multi-agent performance difference lemma that characterizes the landscape of multi-agent policy optimization, we find that the localized action value function serves as an ideal descent direction for each local policy. Motivated by the observation, we present a multi-agent PPO algorithm in which the local policy of each agent is updated similarly to vanilla PPO. We prove that with standard regularity conditions on the Markov game and problem-dependent quantities, our algorithm converges to the globally optimal policy at a sublinear rate. We extend our algorithm to the off-policy setting and introduce pessimism to policy evaluation, which aligns with experiments. To our knowledge, this is the first provably convergent multi-agent PPO algorithm in cooperative Markov games.

**摘要:** 基于函数近似的策略优化方法在多agent增强学习中广泛应用,但如何设计这些算法与统计保证仍然是难以理解的。利用多agent性能差异引数来描述多agent策略优化的景观,我们发现本地化行动值函数为每个本地政策提供理想的下降方向。基于观察的动机,我们提出了一个多agentPPO算法,其中每个代理的本地政策类似于瓦尼拉PPO的更新。我们证明,在马可夫游戏的标准规则条件和问题依赖量下,我们的算法会以次线性速度趋向到全球最佳政策。

**[Paper URL](https://proceedings.mlr.press/v202/zhao23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23j/zhao23j.pdf)** 

# Simplified Temporal Consistency Reinforcement Learning
**题目:** 简化临时一致性增强学习

**作者:** Yi Zhao, Wenshuai Zhao, Rinu Boney, Juho Kannala, Joni Pajarinen

**Abstract:** Reinforcement learning (RL) is able to solve complex sequential decision-making tasks but is currently limited by sample efficiency and required computation. To improve sample efficiency, recent work focuses on model-based RL which interleaves model learning with planning. Recent methods further utilize policy learning, value estimation, and, self-supervised learning as auxiliary objectives. In this paper we show that, surprisingly, a simple representation learning approach relying only on a latent dynamics model trained by latent temporal consistency is sufficient for high-performance RL. This applies when using pure planning with a dynamics model conditioned on the representation, but, also when utilizing the representation as policy and value function features in model-free RL. In experiments, our approach learns an accurate dynamics model to solve challenging high-dimensional locomotion tasks with online planners while being 4.1$\times$ faster to train compared to ensemble-based methods. With model-free RL without planning, especially on high-dimensional tasks, such as the Deepmind Control Suite Humanoid and Dog tasks, our approach outperforms model-free methods by a large margin and matches model-based methods’ sample efficiency while training 2.4$\times$ faster.

**摘要:** 强化学习能够解决复杂的顺序决策任务,但目前受样本效率和需要的计算限制。为了提高样本效率,最近的工作重点是基于模型的RL,将模型学习与规划相结合。最近的方法进一步利用政策学习、价值估计和自我监督学习作为辅助目标。在实验中,我们的方法学习了一个准确的动力学模型,以解决在线规划者挑战的高维运动任务,同时在训练时更快 4.1$\times$ compared to ensemble-based methods. With model-free RL without planning, especially on high-dimensional tasks, such as the Deepmind Control Suite Humanoid and Dog tasks, our approach outperforms model-free methods by a large margin and matches model-based methods’ sample efficiency while training 2.4$\times$ faster.

**[Paper URL](https://proceedings.mlr.press/v202/zhao23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23k/zhao23k.pdf)** 

# RLEG: Vision-Language Representation Learning with Diffusion-based Embedding Generation
**题目:** RLEG:基于扩散的嵌入式生成的视觉语言表达学习

**作者:** Liming Zhao, Kecheng Zheng, Yun Zheng, Deli Zhao, Jingren Zhou

**Abstract:** Vision-language representation learning models (e.g., CLIP) have achieved state-of-the-art performance on various downstream tasks, which usually need large-scale training data to learn discriminative representation. Recent progress on generative diffusion models (e.g., DALL-E 2) has demonstrated that diverse high-quality samples can be synthesized by randomly sampling from generative distribution. By virtue of generative capability in this paper, we propose a novel vision-language Representation Learning method with diffusion-based Embedding Generation (RLEG), which exploits diffusion models to generate feature embedding online for learning effective vision-language representation. Specifically, we first adopt image and text encoders to extract the corresponding embeddings. Secondly, pretrained diffusion-based embedding generators are harnessed to transfer the embedding modality online between vision and language domains. The embeddings generated from the generators are then served as augmented embedding-level samples, which are applied to contrastive learning with the variant of the CLIP framework. Experimental results show that the proposed method could learn effective representation and achieve state-of-the-art performance on various tasks including image classification, image-text retrieval, object detection, semantic segmentation, and text-conditional image generation.

**摘要:** 视觉语言表示学习模型(例如CLIP)在不同下游任务中取得了最先进的性能,通常需要大规模训练数据来学习鉴别性表示。在生成式扩散模型(例如DALL-E2)中最近的进展表明,通过随机抽取生成分布的样品,可以合成多种高质量样品。基于本论文的生成能力,我们提出了一种基于扩散的嵌入生成(RLEG)的新视觉语言表示学习方法,利用扩散模型生成特征嵌入在线学习有效的视觉语言表示。实验结果表明,该方法可以学习有效的表示,在图像分类、图像文本检索、对象检测、语义分割和文本条件图像生成等各个任务中达到最先进的性能。

**[Paper URL](https://proceedings.mlr.press/v202/zhao23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23l/zhao23l.pdf)** 

# Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits
**题目:** 随机噪声的优化在线通用线性回归及其应用于异速带

**作者:** Heyang Zhao, Dongruo Zhou, Jiafan He, Quanquan Gu

**Abstract:** We study the problem of online generalized linear regression in the stochastic setting, where the label is generated from a generalized linear model with possibly unbounded additive noise. We provide a sharp analysis of the classical follow-the-regularized-leader (FTRL) algorithm to cope with the label noise. More specifically, for $\sigma$-sub-Gaussian label noise, our analysis provides a regret upper bound of $O(\sigma^2 d \log T) + o(\log T)$, where $d$ is the dimension of the input vector, $T$ is the total number of rounds. We also prove an $\Omega(\sigma^2d\log(T/d))$ lower bound for stochastic online linear regression, which indicates that our upper bound is nearly optimal. In addition, we extend our analysis to a more refined Bernstein noise condition. As an application, we study generalized linear bandits with heterogeneous noise and propose an algorithm based on FTRL to achieve the first variance-aware regret bound.

**摘要:** 我们研究了随机设置中的在线一般化线性回归问题,其中标签是基于可能无约束的附加噪声的一般化线性模型生成的。我们提供经典跟踪-调节-领导(FTRL)算法的尖锐分析来处理标签噪声。更具体地说,对于$\sigma$-sub-Gaussian标签噪声,我们的分析提供了$O(\sigma^2d \log T)+o(\log T)$ regret upper bound,其中$d$是输入向量尺寸,$T$是圆的总数。我们还证明了$\Omega(\sigma^2d\log(T/d))$ lower bound for stochastic online linear regression, which indicates that our upper bound is nearly optimal。此外,我们扩展了我们的分析到更精细的伯恩斯坦噪声条件。作为

**[Paper URL](https://proceedings.mlr.press/v202/zhao23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23m/zhao23m.pdf)** 

# Does Continual Learning Equally Forget All Parameters?
**题目:** 持续学习是否同样忘记所有参数?

**作者:** Haiyan Zhao, Tianyi Zhou, Guodong Long, Jing Jiang, Chengqi Zhang

**Abstract:** Distribution shift (e.g., task or domain shift) in continual learning (CL) usually results in catastrophic forgetting of previously learned knowledge. Although it can be alleviated by repeatedly replaying buffered data, the every-step replay is time-consuming. In this paper, we study which modules in neural networks are more prone to forgetting by investigating their training dynamics during CL. Our proposed metrics show that only a few modules are more task-specific and sensitive to task change, while others can be shared across tasks as common knowledge. Hence, we attribute forgetting mainly to the former and find that finetuning them only on a small buffer at the end of any CL method can bring non-trivial improvement. Due to the small number of finetuned parameters, such ”Forgetting Prioritized Finetuning (FPF)” is efficient in computation. We further propose a more efficient and simpler method that entirely removes the every-step replay and replaces them by only $k$-times of FPF periodically triggered during CL. Surprisingly, this ”$k$-FPF” performs comparably to FPF and outperforms the SOTA CL methods but significantly reduces their computational overhead and cost. In experiments on several benchmarks of class- and domain-incremental CL, FPF consistently improves existing CL methods by a large margin, and $k$-FPF further excels in efficiency without degrading the accuracy. We also empirically studied the impact of buffer size, epochs per task, and finetuning modules on the cost and accuracy of our methods.

**摘要:** 在持续学习中,分配转移(例如任务或域转移)通常导致先前学习的知识的灾难性遗忘。虽然通过反复重演缓冲数据可以减轻这种遗忘,但每次重演都耗费时间。本文研究了神经网络中哪些模块更倾向于遗忘,通过对其训练动态进行研究。我们进一步提议一种更高效、更简单的方法,完全消除每个步骤的重演,并仅用CLC期间周期性触发的FPF$k$时间替换它们。令人惊奇的是,这个“$k$-FPF”与FPF相比性能优于SOTA CL方法,但大大降低了它们的计算费用和成本。

**[Paper URL](https://proceedings.mlr.press/v202/zhao23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23n/zhao23n.pdf)** 

# Online Learning in Stackelberg Games with an Omniscient Follower
**题目:** 全面追随者在线学习Stackelberg游戏

**作者:** Geng Zhao, Banghua Zhu, Jiantao Jiao, Michael Jordan

**Abstract:** We study the problem of online learning in a two-player decentralized cooperative Stackelberg game. In each round, the leader first takes an action, followed by the follower who takes their action after observing the leader’s move. The goal of the leader is to learn to minimize the cumulative regret based on the history of interactions. Differing from the traditional formulation of repeated Stackelberg games, we assume the follower is omniscient, with full knowledge of the true reward, and that they always best-respond to the leader’s actions. We analyze the sample complexity of regret minimization in this repeated Stackelberg game. We show that depending on the reward structure, the existence of the omniscient follower may change the sample complexity drastically, from constant to exponential, even for linear cooperative Stackelberg games. This poses unique challenges for the learning process of the leader and the subsequent regret analysis.

**摘要:** 我们研究了两个玩家分散合作的Stackelberg游戏中的在线学习问题。在每一轮中,领导者首先采取行动,然后由追随者在观察领导者的移动后采取行动。领导者的目标是根据交互历史减少累积的遗憾。不同于重复的Stackelberg游戏的传统形式,我们假设追随者是全能的,完全了解真正的奖励,并且他们总是对领导者的行动作出最好的回应。我们分析了重复的Stackelberg游戏中的遗憾的最小化样本复杂度。我们表明,依赖于奖励结构,全能追随者的存在可以极大地改变样本复杂度,从常数到指数,甚至在线性合作Stackelberg游戏中。这为领导的学习过程和后续的遗憾分析带来了独特的挑战。

**[Paper URL](https://proceedings.mlr.press/v202/zhao23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhao23o/zhao23o.pdf)** 

# Structure-informed Language Models Are Protein Designers
**题目:** 结构信息型语言模型是蛋白质设计者

**作者:** Zaixiang Zheng, Yifan Deng, Dongyu Xue, Yi Zhou, Fei Ye, Quanquan Gu

**Abstract:** This paper demonstrates that language models are strong structure-based protein designers. We present LM-Design, a generic approach to reprogramming sequence-based protein language models (pLMs), that have learned massive sequential evolutionary knowledge from the universe of natural protein sequences, to acquire an immediate capability to design preferable protein sequences for given folds. We conduct a structural surgery on pLMs, where a lightweight structural adapter is implanted into pLMs and endows it with structural awareness. During inference, iterative refinement is performed to effectively optimize the generated protein sequences. Experiments show that LM-Design improves the state-of-the-art results by a large margin, leading to 4% to 12% accuracy gains in sequence recovery (e.g., 55.65%/56.63% on CATH 4.2/4.3 single-chain benchmarks, and $>$60% when designing protein complexes). We provide extensive and in-depth analyses, which verify that LM-Design can (1) indeed leverage both structural and sequential knowledge to accurately handle structurally non-deterministic regions, (2) benefit from scaling data and model size, and (3) generalize to other proteins (e.g., antibodies and de novo proteins).

**摘要:** 本文表明,语言模型是基于结构的强型蛋白质设计者。我们介绍了基于序列的蛋白质语言模型(pLMs)重新编程的通用方法LM-Design,它从自然蛋白质序列的宇宙中学习了大量序列进化知识,以便在给定的折叠中获得设计优先的蛋白质序列的立即能力。我们对pLMs进行了结构手术,其中一个轻型结构适配器被植入pLMs,并赋予它结构意识。在推导过程中,迭代精细以有效优化生成的蛋白质序列。实验表明,LM-Design大大提高了序列恢复的精度,达到4%至 12%(例如在CATH 4.2/4.3单链基准中55.65%/56.63%,在设计蛋白质复合物时>60%)。我们提供广泛和深入的分析,验证LM-Design能够(一)确实利用结构和序列知识来准确处理结构上非确定性区域,(二)从数据和模型大小的规模化中获益,(三)推广到其他蛋白质(例如抗体和新蛋白质)。

**[Paper URL](https://proceedings.mlr.press/v202/zheng23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zheng23a/zheng23a.pdf)** 

# Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories
**题目:** 半监督的在线强化学习与无行动牵引器

**作者:** Qinqing Zheng, Mikael Henaff, Brandon Amos, Aditya Grover

**Abstract:** Natural agents can effectively learn from multiple data sources that differ in size, quality, and types of measurements. We study this heterogeneity in the context of offline reinforcement learning (RL) by introducing a new, practically motivated semi-supervised setting. Here, an agent has access to two sets of trajectories: labelled trajectories containing state, action and reward triplets at every timestep, along with unlabelled trajectories that contain only state and reward information. For this setting, we develop and study a simple meta-algorithmic pipeline that learns an inverse dynamics model on the labelled data to obtain proxy-labels for the unlabelled data, followed by the use of any offline RL algorithm on the true and proxy-labelled trajectories. Empirically, we find this simple pipeline to be highly successful — on several D4RL benchmarks (Fu et al., 2020), certain offline RL algorithms can match the performance of variants trained on a fully labelled dataset even when we label only 10% of trajectories which are highly suboptimal. To strengthen our understanding, we perform a large-scale controlled empirical study investigating the interplay of data-centric properties of the labelled and unlabelled datasets, with algorithmic design choices (e.g., choice of inverse dynamics, offline RL algorithm) to identify general trends and best practices for training RL agents on semi-supervised offline datasets.

**摘要:** 自然代理可以有效地从不同大小、质量和测量类型的多个数据源学习。我们通过引入一种新的、实际动机的半监督设置,研究了在非在线增强学习(RL)中这种异质性。这里,代理可以访问两组路径:包含状态、行动和奖励的标签路径,每个时间段都有三重 triplets,以及包含只有状态和奖励信息的非标签路径。从经验上看,我们发现这个简单的管道非常成功 — — 在若干D4RL基准(Fu et al., 2020)上,某些非线性RL算法能够与在完全标记数据集上训练的变量性能相匹配,即使我们仅标记10%的极低最佳轨迹。

**[Paper URL](https://proceedings.mlr.press/v202/zheng23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zheng23b/zheng23b.pdf)** 

# Improved Techniques for Maximum Likelihood Estimation for Diffusion ODEs
**题目:** 扩散药物最有可能估计的改进技术

**作者:** Kaiwen Zheng, Cheng Lu, Jianfei Chen, Jun Zhu

**Abstract:** Diffusion models have exhibited excellent performance in various domains. The probability flow ordinary differential equation (ODE) of diffusion models (i.e., diffusion ODEs) is a particular case of continuous normalizing flows (CNFs), which enables deterministic inference and exact likelihood evaluation. However, the likelihood estimation results by diffusion ODEs are still far from those of the state-of-the-art likelihood-based generative models. In this work, we propose several improved techniques for maximum likelihood estimation for diffusion ODEs, including both training and evaluation perspectives. For training, we propose velocity parameterization and explore variance reduction techniques for faster convergence. We also derive an error-bounded high-order flow matching objective for finetuning, which improves the ODE likelihood and smooths its trajectory. For evaluation, we propose a novel training-free truncated-normal dequantization to fill the training-evaluation gap commonly existing in diffusion ODEs. Building upon these techniques, we achieve state-of-the-art likelihood estimation results on image datasets (2.56 on CIFAR-10, 3.43/3.69 on ImageNet-32) without variational dequantization or data augmentation.

**摘要:** 扩散模型在各个领域表现得非常出色。扩散模型的概率流常微分方程(ODE)是连续标准化流(CNFs)的特殊案例,可进行确定性推理和准确的概率评价。然而,扩散ODE的概率估计结果仍远于最先进的基于概率的生成模型。在本研究中,我们提出了扩散ODE的最大概率估计的几个改进技术,包括训练和评价视角。为了评价,我们提出了一种新的无训练的切断-正常定量化方法,以填补扩散药物药物治疗中普遍存在的训练-评价缺口。我们利用这些方法,在图像数据集(CIFAR-10的2.56,ImageNet-32的3.33/3.69)上取得最先进的概率估计结果,而无需变量定量化或数据增加。

**[Paper URL](https://proceedings.mlr.press/v202/zheng23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zheng23c/zheng23c.pdf)** 

# Fast Sampling of Diffusion Models via Operator Learning
**题目:** 通过操作员学习快速采样扩散模型

**作者:** Hongkai Zheng, Weili Nie, Arash Vahdat, Kamyar Azizzadenesheli, Anima Anandkumar

**Abstract:** Diffusion models have found widespread adoption in various areas. However, their sampling process is slow because it requires hundreds to thousands of network evaluations to emulate a continuous process defined by differential equations. In this work, we use neural operators, an efficient method to solve the probability flow differential equations, to accelerate the sampling process of diffusion models. Compared to other fast sampling methods that have a sequential nature, we are the first to propose a parallel decoding method that generates images with only one model forward pass. We propose diffusion model sampling with neural operator (DSNO) that maps the initial condition, i.e., Gaussian distribution, to the continuous-time solution trajectory of the reverse diffusion process. To model the temporal correlations along the trajectory, we introduce temporal convolution layers that are parameterized in the Fourier space into the given diffusion model backbone. We show our method achieves state-of-the-art FID of 3.78 for CIFAR-10 and 7.83 for ImageNet-64 in the one-model-evaluation setting.

**摘要:** 扩散模型在各个领域得到了广泛的应用,但其采样过程很慢,因为需要数以千计的网络评价以模拟由微分方程定义的连续过程。本研究中,我们使用神经运算器,一种有效的方法来解决概率流动微分方程,加速扩散模型的采样过程。与具有序列性质的其他快速采样方法相比,我们是第一个提议产生只有一个模型向前通行的图像的平行解码方法的提案者。我们提议与神经运算器(DSNO)进行扩散模型采样,以映射逆扩散过程的初始条件,即高斯分布的连续时间解决轨迹。我们展示了我们的方法在单模型评价设置中达到了CIFAR-10的最先端FID3.78和ImageNet-64的7.83。

**[Paper URL](https://proceedings.mlr.press/v202/zheng23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zheng23d/zheng23d.pdf)** 

# Outline, Then Details: Syntactically Guided Coarse-To-Fine Code Generation
**题目:** 概述,然后详细说明:综合引导的粗到精码生成

**作者:** Wenqing Zheng, S P Sharan, Ajay Kumar Jaiswal, Kevin Wang, Yihan Xi, Dejia Xu, Zhangyang Wang

**Abstract:** For a complicated algorithm, its implementation by a human programmer usually starts with outlining a rough control flow followed by iterative enrichments, eventually yielding carefully generated syntactic structures and variables in a hierarchy. However, state-of-the-art large language models generate codes in a single pass, without intermediate warm-ups to reflect the structured thought process of "outline-then-detail". Inspired by the recent success of chain-of-thought prompting, we propose ChainCoder, a program synthesis language model that generates Python code progressively, i.e. from coarse to fine in multiple passes. We first decompose source code into layout frame components and accessory components via abstract syntax tree parsing to construct a hierarchical representation. We then reform our prediction target into a multi-pass objective, each pass generates a subsequence, which is concatenated in the hierarchy. Finally, a tailored transformer architecture is leveraged to jointly encode the natural language descriptions and syntactically aligned I/O data samples. Extensive evaluations show that ChainCoder outperforms state-of-the-arts, demonstrating that our progressive generation eases the reasoning procedure and guides the language model to generate higher-quality solutions. Our codes are available at: https://github.com/VITA-Group/ChainCoder.

**摘要:** 对于复杂算法,其由程序员实现通常以概述粗糙的控制流程,然后再进行迭代的丰富,最终在层次结构中产生精心生成的语法结构和变量。然而,最先进的大型语言模型在单个传递中生成代码,没有中间的加热,以反映“outline-then-detail”的结构思维过程。最后,一个定制的变换器架构被利用,共同编码自然语言描述和协同排列的I/O数据样本。广泛的评估表明,ChainCoder超越了最先进的技术,证明了我们的进步生成简化了推理过程,并指导语言模型生成高质量解决方案。

**[Paper URL](https://proceedings.mlr.press/v202/zheng23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zheng23e/zheng23e.pdf)** 

# Revisiting Discriminative vs. Generative Classifiers: Theory and Implications
**题目:** 重视歧视性与生成性分类器:理论与影响

**作者:** Chenyu Zheng, Guoqiang Wu, Fan Bao, Yue Cao, Chongxuan Li, Jun Zhu

**Abstract:** A large-scale deep model pre-trained on massive labeled or unlabeled data transfers well to downstream tasks. Linear evaluation freezes parameters in the pre-trained model and trains a linear classifier separately, which is efficient and attractive for transfer. However, little work has investigated the classifier in linear evaluation except for the default logistic regression. Inspired by the statistical efficiency of naive Bayes, the paper revisits the classical topic on discriminative vs. generative classifiers. Theoretically, the paper considers the surrogate loss instead of the zero-one loss in analyses and generalizes the classical results from binary cases to multiclass ones. We show that, under mild assumptions, multiclass naive Bayes requires $O(\log n)$ samples to approach its asymptotic error while the corresponding multiclass logistic regression requires $O(n)$ samples, where $n$ is the feature dimension. To establish it, we present a multiclass $\mathcal{H}$-consistency bound framework and an explicit bound for logistic loss, which are of independent interests. Simulation results on a mixture of Gaussian validate our theoretical findings. Experiments on various pre-trained deep vision models show that naive Bayes consistently converges faster as the number of data increases. Besides, naive Bayes shows promise in few-shot cases and we observe the "two regimes” phenomenon in pre-trained supervised models. Our code is available at https://github.com/ML-GSAI/Revisiting-Dis-vs-Gen-Classifiers.

**摘要:** 在大规模标记或未标记的数据传输上,一个大规模深层模型预先训练可以很好地完成下游任务。线性评价在预训练模型中冻结参数,并单独训练一个线性分类器,这对于传输具有效率和吸引力。然而,很少的工作对线性评价中的分类器进行了研究,除了默认的后勤回归以外。为了建立它,我们提出了多类$\mathcal{H}$-一致性约束框架和逻辑损失的明确约束,这些是独立利益的。在高斯的混合物上的仿真结果验证了我们的理论发现。在各种预训练的深度视觉模型的实验显示, naive Bayes随着数据数目增加而趋于一致。此外, naive Bayes在少数事件中显示了前景,我们观察了预训练的监管模型中的“两个制度”现象。我们的代码在 https://github.com/ML-GSAI/Revisiting-Dis-vs-Gen-Classifiers上。

**[Paper URL](https://proceedings.mlr.press/v202/zheng23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zheng23f/zheng23f.pdf)** 

# Evidential Interactive Learning for Medical Image Captioning
**题目:** 医学图像捕捉的显而易见交互学习

**作者:** Ervine Zheng, Qi Yu

**Abstract:** Medical image captioning alleviates the burden of physicians and possibly reduces medical errors by automatically generating text descriptions to describe image contents and convey findings. It is more challenging than conventional image captioning due to the complexity of medical images and the difficulty of aligning image regions with medical terms. In this paper, we propose an evidential interactive learning framework that leverages evidence-based uncertainty estimation and interactive machine learning to improve image captioning with limited labeled data. The interactive learning process involves three stages: keyword prediction, caption generation, and model retraining. First, the model predicts a list of keywords with evidence-based uncertainty and selects the most informative keywords to seek user feedback. Second, user-approved keywords are used as model input to guide the model to generate satisfactory captions. Third, the model is updated based on user-approved keywords and captions, where evidence-based uncertainty is used to allocate different weights to different data instances. Experiments on two medical image datasets illustrate that the proposed framework can effectively learn from human feedback and improve the model’s performance in the future.

**摘要:** 医学图像加 captioning可以减轻医生的负担,并可能通过自动生成文本描述来减少医学错误,以描述图像内容和传达结果。由于医学图像的复杂性和图像区域与医学术语的匹配的困难,它比传统的图像加 captioning更加困难。本文提出了一种基于证据的不确定性估计和基于有限标记的数据的交互式机器学习框架,以提高图像加 captioning。交互式学习过程包括三个阶段:关键字预测、加 caption生成和模型再培训。第三,该模型基于用户认可的关键词和标题更新,在此基础上,基于证据的不确定性将不同的权重分配给不同的数据实例。

**[Paper URL](https://proceedings.mlr.press/v202/zheng23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zheng23g/zheng23g.pdf)** 

# Finding the Missing-half: Graph Complementary Learning for Homophily-prone and Heterophily-prone Graphs
**题目:** 寻找缺失的一半:同性恋倾向和异性恋倾向图形的图形辅助学习

**作者:** Yizhen Zheng, He Zhang, Vincent Lee, Yu Zheng, Xiao Wang, Shirui Pan

**Abstract:** Real-world graphs generally have only one kind of tendency in their connections. These connections are either homophilic-prone or heterophily-prone. While graphs with homophily-prone edges tend to connect nodes with the same class (i.e., intra-class nodes), heterophily-prone edges tend to build relationships between nodes with different classes (i.e., inter-class nodes). Existing GNNs only take the original graph as input during training. The problem with this approach is that it forgets to take into consideration the ”missing-half” structural information, that is, heterophily-prone topology for homophily-prone graphs and homophily-prone topology for heterophily-prone graphs. In our paper, we introduce Graph cOmplementAry Learning, namely GOAL, which consists of two components: graph complementation and complemented graph convolution. The first component finds the missing-half structural information for a given graph to complement it. The complemented graph has two sets of graphs including both homophily- and heterophily-prone topology. In the latter component, to handle complemented graphs, we design a new graph convolution from the perspective of optimisation. The experiment results show that GOAL consistently outperforms all baselines in eight real-world datasets.

**摘要:** 实世界图通常只有一种倾向性。这些关联是同性恋倾向或同性恋倾向。同性恋倾向边缘图则倾向于与同类的节点连接(即类内节点),同性恋倾向的边缘图则倾向于与不同类的节点之间建立关系(即类间节点)。现有的GNN只在训练期间以原始图为输入。这一方法的问题在于它忘记考虑“缺失一半”结构信息,即对同性恋倾向图的同性恋倾向拓扑和对同性恋倾向图的同性恋倾向拓扑。该辅助图具有两个组图,包括同性恋和异性恋倾向的拓扑。在后者组件中,为了处理辅助图,我们从优化的角度设计了新的图卷。实验结果表明,GOAL在8个实物数据集中始终超过了所有基线。

**[Paper URL](https://proceedings.mlr.press/v202/zheng23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zheng23h/zheng23h.pdf)** 

# Multi-agent Online Scheduling: MMS Allocations for Indivisible Items
**题目:** 多代理网上计划:不可分割项目MS拨款

**作者:** Shengwei Zhou, Rufan Bai, Xiaowei Wu

**Abstract:** We consider the problem of fairly allocating a sequence of indivisible items that arrive online in an arbitrary order to a group of $n$ agents with additive normalized valuation functions, we consider the allocation of goods and chores separately and propose algorithms for approximating maximin share (MMS) allocations for both settings. When agents have identical valuation functions the problem coincides with the semi-online machine covering problem (when items are goods) and load balancing problem (when items are chores), for both of which optimal competitive ratios have been achieved. In this paper we consider the case when agents have general additive valuation functions. For the allocation of goods we show that no competitive algorithm exists even when there are only three agents and propose an optimal $0.5$-competitive algorithm for the case of two agents. For the allocation of chores we propose a $(2-1/n)$-competitive algorithm for $n\geq 3$ agents and a $\sqrt{2}\approx 1.414$-competitive algorithm for two agents. Additionally, we show that no algorithm can do better than $15/11\approx 1.364$-competitive for two agents.

**摘要:** 本文对一种具有增量规范化估价函数的$n$代理人组在任意顺序到达在线的不可分割物品序列的合理分配问题进行了分析,分别对货物和作业的分配问题进行了分析,并提出了近似两组设置的最大分摊分配算法。当代理人具有相同的估价函数时,问题与半在线机器覆盖问题(当物品是货物)和负荷平衡问题(当物品是作业)相一致,两者均达到最佳竞争比率。本论文对代理人具有一般增量估价函数的案例进行了分析。为了分配任务,我们提出了$n\geq 3$代理的$(2-1/n)$竞争算法和$sqrt{2}的$1.414$两个代理的$1.364$竞争算法。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23a/zhou23a.pdf)** 

# Eliminating Adversarial Noise via Information Discard and Robust Representation Restoration
**题目:** 通过信息丢弃和稳固的代表恢复消除敌对噪音

**作者:** Dawei Zhou, Yukun Chen, Nannan Wang, Decheng Liu, Xinbo Gao, Tongliang Liu

**Abstract:** Deep neural networks (DNNs) are vulnerable to adversarial noise. Denoising model-based defense is a major protection strategy. However, denoising models may fail and induce negative effects in fully white-box scenarios. In this work, we start from the latent inherent properties of adversarial samples to break the limitations. Unlike solely learning a mapping from adversarial samples to natural samples, we aim to achieve denoising by destroying the spatial characteristics of adversarial noise and preserving the robust features of natural information. Motivated by this, we propose a defense based on information discard and robust representation restoration. Our method utilize complementary masks to disrupt adversarial noise and guided denoising models to restore robust-predictive representations from masked samples. Experimental results show that our method has competitive performance against white-box attacks and effectively reverses the negative effect of denoising models.

**摘要:** 深度神经网络(DNN)易受敌对噪声影响。基于模型的防护是一项主要的防护策略。然而,防护模型可能失败并产生完全白箱场景中的负面影响。在这个工作中,我们从敌对样品潜在的固有特性出发,打破局限性。与仅仅学习从敌对样品到自然样品的映射不同,我们的目标是通过破坏敌对噪声的空间特性和保存自然信息的鲁棒特征来实现防护。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23b/zhou23b.pdf)** 

# Brainformers: Trading Simplicity for Efficiency
**题目:** Brainformers:贸易简化为效率

**作者:** Yanqi Zhou, Nan Du, Yanping Huang, Daiyi Peng, Chang Lan, Da Huang, Siamak Shakeri, David So, Andrew M. Dai, Yifeng Lu, Zhifeng Chen, Quoc V Le, Claire Cui, James Laudon, Jeff Dean

**Abstract:** Transformers are central to recent successes in natural language processing and computer vision. Transformers have a mostly uniform backbone where layers alternate between feed-forward and self-attention in order to build a deep network. Here we investigate this design choice and find that more complex blocks that have different permutations of layer primitives can be more efficient. Using this insight, we develop a complex block, named Brainformer, that consists of a diverse sets of layers such as sparsely gated feed-forward layers, dense feed-forward layers, attention layers, and various forms of layer normalization and activation functions. Brainformer consistently outperforms the state-of-the-art dense and sparse Transformers, in terms of both quality and efficiency. A Brainformer model with 8 billion activated parameters per token demonstrates 2x faster training convergence and 5x faster step time compared to its GLaM counterpart. In downstream task evaluation, Brainformer also demonstrates a 3% higher SuperGLUE score with fine-tuning compared to GLaM with a similar number of activated parameters. Finally, Brainformer largely outperforms a Primer dense model derived with NAS with similar computation per token on fewshot evaluations.

**摘要:** 变形器是自然语言处理和计算机视觉中最近取得的成就的核心。变形器具有一个基本均匀的后骨,其中各层在向导和自我关注之间进行交互,以建立深层网络。我们研究了这一设计选择,发现具有不同变形的复杂块可以更高效。使用这一洞察,我们开发了一个复杂块,名为Brainformer,它由各种不同层组组成,如稀疏的向导层、密集的向导层、注意力层和各种形式的层规范化和激活功能。Brainformer始终能超越最先进的密度和稀疏变形器,在质量和效率方面。在下游任务评估中,Brainformer还显示了比GLaM具有类似数量的激活参数的SuperGLUE得分3%的精细调度。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23c/zhou23c.pdf)** 

# Implicit Regularization Leads to Benign Overfitting for Sparse Linear Regression
**题目:** 隐性调节导致备用线性回归的优越性

**作者:** Mo Zhou, Rong Ge

**Abstract:** In deep learning, often the training process finds an interpolator (a solution with 0 training loss), but the test loss is still low. This phenomenon, known as benign overfitting, is a major mystery that received a lot of recent attention. One common mechanism for benign overfitting is implicit regularization, where the training process leads to additional properties for the interpolator, often characterized by minimizing certain norms. However, even for a simple sparse linear regression problem $y = \beta^{\ast\top} x +\xi$ with sparse $\beta^{\ast}$, neither minimum $\ell_1$ or $\ell_2$ norm interpolator gives the optimal test loss. In this work, we give a different parametrization of the model which leads to a new implicit regularization effect that combines the benefit of $\ell_1$ and $\ell_2$ interpolators. We show that training our new model via gradient descent leads to an interpolator with near-optimal test loss. Our result is based on careful analysis of the training dynamics and provides another example of implicit regularization effect that goes beyond norm minimization.

**摘要:** 在深层学习中,训练过程经常会发现一个插值器(有0训练损失的解决方案),但测试损失仍然很低。这个现象,被称为良性插值器,是最近得到大量关注的一个重大谜题。良性插值器的一个常见机制是隐式校正,训练过程会导致插值器的额外特性,通常通过最小化某些规范来表现。然而,即使是简单的稀疏线性回归问题, $y = \beta^{\ast\top} x +\xi$ 与稀疏 $\beta^{\ast}$ 之间,最低 $\ell_1$ 或 $\ell_2$ 规范插值器都没有提供最佳测试损失。在这个工作中,我们给出了模型的不同的参数化,导致新的隐式校正效应,结合了 $\ell_1$ 和 $\ell_2$ 插值器的好处。通过对训练动力学的仔细分析,给出了一个超越规范最小化 implicit regularization 效应的例子。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23d/zhou23d.pdf)** 

# ODS: Test-Time Adaptation in the Presence of Open-World Data Shift
**题目:** ODS:开放世界数据移位的测试时间适应

**作者:** Zhi Zhou, Lan-Zhe Guo, Lin-Han Jia, Dingchu Zhang, Yu-Feng Li

**Abstract:** Test-time adaptation (TTA) adapts a source model to the distribution shift in testing data without using any source data. There have been plenty of algorithms concentrated on covariate shift in the last decade, i.e., $\mathcal{D}_t(X)$, the distribution of the test data is different from the source data. Nonetheless, in real application scenarios, it is necessary to consider the influence of label distribution shift, i.e., both $\mathcal{D}_t(X)$ and $\mathcal{D}_t(Y)$ are shifted, which has not been sufficiently explored yet. To remedy this, we study a new problem setup, namely, TTA with Open-world Data Shift (AODS). The goal of AODS is simultaneously adapting a model to covariate and label distribution shifts in the test phase. In this paper, we first analyze the relationship between classification error and distribution shifts. Motivated by this, we hence propose a new framework, namely ODS, which decouples the mixed distribution shift and then addresses covariate and label distribution shifts accordingly. We conduct experiments on multiple benchmarks with different types of shifts, and the results demonstrate the superior performance of our method against the state of the arts. Moreover, ODS is suitable for many TTA algorithms.

**摘要:** 测试时间适应(TTA)在测试数据中,不使用任何源数据的情况下,将源模型适应于分布移。在过去十年中,已有大量的算法集中于共变移,即$\mathcal{D}_t(X)$,测试数据的分布与源数据不同。尽管如此,在实际应用场景中,有必要考虑标签分布移的影响,即$\mathcal{D}_t(X)$和$\mathcal{D}_t(Y)$均被移,尚未充分研究。基于此,我们提出了一种新的框架,即ODS,该框架将混合分布变换分离,然后针对不同类型的变换和标签分布变换。我们对不同类型的变换的多个基准进行了实验,结果证明了该方法在技术上的表现优越。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23e/zhou23e.pdf)** 

# Fourmer: An Efficient Global Modeling Paradigm for Image Restoration
**题目:** 傅立叶:图像恢复的高效全球建模范式

**作者:** Man Zhou, Jie Huang, Chun-Le Guo, Chongyi Li

**Abstract:** Global modeling-based image restoration frameworks have become popular. However, they often require a high memory footprint and do not consider task-specific degradation. Our work presents an alternative approach to global modeling that is more efficient for image restoration. The key insights which motivate our study are two-fold: 1) Fourier transform is capable of disentangling image degradation and content component to a certain extent, serving as the image degradation prior, and 2) Fourier domain innately embraces global properties, where each pixel in the Fourier space is involved with all spatial pixels. While adhering to the “spatial interaction + channel evolution” rule of previous studies, we customize the core designs with Fourier spatial interaction modeling and Fourier channel evolution. Our paradigm, Fourmer, achieves competitive performance on common image restoration tasks such as image de-raining, image enhancement, image dehazing, and guided image super-resolution, while requiring fewer computational resources. The code for Fourmer will be made publicly available.

**摘要:** 基于全球建模的图像恢复框架已经变得非常流行。然而,它们往往需要很高的内存脚印,并不考虑特定任务的降解。我们的工作提出了一种更有效的全球建模方法。我们研究的动力是两个方面:(1)傅立叶变换能够在某种程度上划分图像降解和内容成分,作为图像降解的先例,以及(2)傅立叶域自然地包含全球属性,其中每个傅立叶空间中的像素都与所有空间像素有关。我们的范式,Fourmer,在像素除影、像素增强、像素丢失和引导像素超分辨等常见的像素恢复任务中具有竞争性性能,同时需要较少的计算资源。Fourmer代码将公开。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23f/zhou23f.pdf)** 

# Controlled Text Generation with Natural Language Instructions
**题目:** 自然语言教学控制文本生成

**作者:** Wangchunshu Zhou, Yuchen Eleanor Jiang, Ethan Wilcox, Ryan Cotterell, Mrinmaya Sachan

**Abstract:** Large language models can be prompted to pro- duce fluent output for a wide range of tasks without being specifically trained to do so. Nevertheless, it is notoriously difficult to control their generation in such a way that it satisfies user-specified constraints. In this paper, we present InstructCTG, a simple controlled text generation framework that incorporates different constraints by verbalizing them as natural language instructions. We annotate natural texts through a combination of off-the-shelf NLP tools and simple heuristics with the linguistic and extra-linguistic constraints they satisfy. Then, we verbalize the constraints into natural language instructions to form weakly supervised training data, i.e., we prepend the natural language verbalizations of the constraints in front of their corresponding natural language sentences. Next, we fine-tune a pre-trained language model on the augmented corpus. Compared to existing methods, InstructCTG is more flexible in terms of the types of constraints it allows the practitioner to use. It also does not require any modification of the decoding procedure. Finally, InstructCTG allows the model to adapt to new constraints without re-training through the use of in-context learning.

**摘要:** 大型语言模型可以在不经过专门训练的情况下,为广泛任务提供流畅的输出。然而,控制它们的生成非常困难,以满足用户指定的约束。本论文介绍InstructCTG,一种简单控制的文本生成框架,它通过将它们语法化为自然语言指令,结合不同的约束。我们通过结合现有的NLP工具和简单的语法和外语约束来注释自然文本,然后将约束语法化为自然语言指令,以形成受弱监督的训练数据,即在相应的自然语言句子前面预备自然语言语法化。与现有方法相比,InstructCTG具有更灵活的约束类型,允许实践者使用。它也不需要任何修改解码程序。最后,InstructCTG允许模型通过使用内在环境学习来适应新的约束,而不需要再培训。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23g/zhou23g.pdf)** 

# NNSplitter: An Active Defense Solution for DNN Model via Automated Weight Obfuscation
**题目:** NNSplitter:通过自动重量模糊实现DNN模型的主动防御解决方案

**作者:** Tong Zhou, Yukui Luo, Shaolei Ren, Xiaolin Xu

**Abstract:** As a type of valuable intellectual property (IP), deep neural network (DNN) models have been protected by techniques like watermarking. However, such passive model protection cannot fully prevent model abuse. In this work, we propose an active model IP protection scheme, namely NNSplitter, which actively protects the model by splitting it into two parts: the obfuscated model that performs poorly due to weight obfuscation, and the model secrets consisting of the indexes and original values of the obfuscated weights, which can only be accessed by authorized users with the support of the trusted execution environment. Experimental results demonstrate the effectiveness of NNSplitter, e.g., by only modifying 275 out of over 11 million (i.e., 0.002%) weights, the accuracy of the obfuscated ResNet-18 model on CIFAR-10 can drop to 10%. Moreover, NNSplitter is stealthy and resilient against norm clipping and fine-tuning attacks, making it an appealing solution for DNN model protection. The code is available at: https://github.com/Tongzhou0101/NNSplitter.

**摘要:** 作为一种有价值的知识产权(IP),深度神经网络(DNN)模型被诸如水印技术保护。然而,这种被动模型保护不能完全防止模型滥用。在这项工作中,我们提出了一种有效的模型IP保护方案,即NNSplitter,它通过将模型分成两个部分来积极保护:由于重量模糊 performs poorly due to weight obfuscation, and the model secrets consisting of the indexes and original values of the obfuscated weights, which can only be accessed by authorized users with the support of the trusted execution environment。代码可于: https://github.com/Tongzhou0101/NNSplitter。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23h/zhou23h.pdf)** 

# Deep Latent State Space Models for Time-Series Generation
**题目:** 时间序列生成的深层潜在状态空间模型

**作者:** Linqi Zhou, Michael Poli, Winnie Xu, Stefano Massaroli, Stefano Ermon

**Abstract:** Methods based on ordinary differential equations (ODEs) are widely used to build generative models of time-series. In addition to high computational overhead due to explicitly computing hidden states recurrence, existing ODE-based models fall short in learning sequence data with sharp transitions - common in many real-world systems - due to numerical challenges during optimization. In this work, we propose LS4, a generative model for sequences with latent variables evolving according to a state space ODE to increase modeling capacity. Inspired by recent deep state space models (S4), we achieve speedups by leveraging a convolutional representation of LS4 which bypasses the explicit evaluation of hidden states. We show that LS4 significantly outperforms previous continuous-time generative models in terms of marginal distribution, classification, and prediction scores on real-world datasets in the Monash Forecasting Repository, and is capable of modeling highly stochastic data with sharp temporal transitions. LS4 sets state-of-the-art for continuous-time latent generative models, with significant improvement of mean squared error and tighter variational lower bounds on irregularly-sampled datasets, while also being x100 faster than other baselines on long sequences.

**摘要:** 基于普通微分方程(ODEs)的方法广泛用于建立时间序列的生成模型。除了由于显而易见地计算隐藏状态的重演的高计算费用外,现有基于ODE的模型由于优化过程中的数值挑战,在学习序列数据时缺乏尖锐的过渡,这在许多实世界系统中常见。本文提出了LS4,一种基于状态空间ODE的潜在变量演变的序列生成模型,以提高建模能力。结果表明,LS4在蒙纳什预测库的实世界数据集的边缘分布、分类和预测分数方面明显优于以往的连续时间生成模型,并且能够以敏锐的时空过渡模式模拟高随机数据。LS4为连续时间 latent生成模型提供了最先进的设置,在不规则采样数据集中,平均平方误差和更严格的变量较低边界得到显著改善,同时在长序列的其他基线中,它的速度也比其他基线快100倍。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23i/zhou23i.pdf)** 

# SlotGAT: Slot-based Message Passing for Heterogeneous Graphs
**题目:** SlotGAT:基于槽的异构图消息传递

**作者:** Ziang Zhou, Jieming Shi, Renchi Yang, Yuanhang Zou, Qing Li

**Abstract:** Heterogeneous graphs are ubiquitous to model complex data. There are urgent needs on powerful heterogeneous graph neural networks to effectively support important applications. We identify a potential semantic mixing issue in existing message passing processes, where the representations of the neighbors of a node v are forced to be transformed to the feature space of v for aggregation, though the neighbors are in different types. That is, the semantics in different node types are entangled together into node v’s representation. To address the issue, we propose SlotGAT with separate message passing processes in slots, one for each node type, to maintain the representations in their own node-type feature spaces. Moreover, in a slot-based message passing layer, we design an attention mechanism for effective slot-wise message aggregation. Further, we develop a slot attention technique after the last layer of SlotGAT, to learn the importance of different slots in downstream tasks. Our analysis indicates that the slots in SlotGAT can preserve different semantics in various feature spaces. The superiority of SlotGAT is evaluated against 13 baselines on 6 datasets for node classification and link prediction. Our code is at https://github.com/scottjiao/SlotGAT_ICML23/.

**摘要:** 对复杂数据的建模,异构图是无处不在的,具有强大的异构图神经网络的迫切需要,以有效支持重要的应用。我们在现有消息传递过程中识别了一个潜在的语义混合问题,其中邻域v的表示被强制转换为v的特征空间,虽然邻域是不同的类型。也就是说,不同节点类型的语义被卷入节点v的表示中。为了解决这个问题,我们建议SlotGAT在各节点中进行单独的消息传递过程,一个用于每个节点类型,以保持其自己的节点类型的特征空间的表示。此外,在基于节点的信息传递层中,我们设计了有效的节点wise消息聚集的注意机制。我们的分析表明,SlotGAT的插槽可以在不同功能空间中保持不同的语义。SlotGAT的优越性是根据6个数据集的13个基线来评估节点分类和链接预测。我们的代码是 https://github.com/scottjiao/SlotGAT_ICML23/。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23j/zhou23j.pdf)** 

# Fast Online Node Labeling for Very Large Graphs
**题目:** 快速在线节点标签用于非常大的图形

**作者:** Baojian Zhou, Yifan Sun, Reza Babanezhad Harikandeh

**Abstract:** This paper studies the online node classification problem under a transductive learning setting. Current methods either invert a graph kernel matrix with $\mathcal{O}(n^3)$ runtime and $\mathcal{O}(n^2)$ space complexity or sample a large volume of random spanning trees, thus are difficult to scale to large graphs. In this work, we propose an improvement based on the online relaxation technique introduced by a series of works (Rakhlin et al., 2012; Rakhlin & Sridharan, 2015; 2017). We first prove an effective regret $\mathcal{O}(\sqrt{n^{1+\gamma}})$ when suitable parameterized graph kernels are chosen, then propose an approximate algorithm FastONL enjoying $\mathcal{O}(k\sqrt{n^{1+\gamma}})$ regret based on this relaxation. The key of FastONL is a generalized local push method that effectively approximates inverse matrix columns and applies to a series of popular kernels. Furthermore, the per-prediction cost is $\mathcal{O}(\operatorname{vol}{\mathcal{S}}\log 1/\epsilon)$ locally dependent on the graph with linear memory cost. Experiments show that our scalable method enjoys a better tradeoff between local and global consistency.

**摘要:** 本文研究了在转换学习设置下在线节点分类问题。当前的方法要么以$\mathcal{O}(n^3)$运行时间和$\mathcal{O}(n^2)$空间复杂度反向图形内核矩阵,要么以随机 spanning树的大量样本,从而很难 scale到大型图形。在这个工作中,我们提出了基于一系列作品(Rakhlin et al., 2012; Rakhlin & Sridharan, 2015; 2017)引入的在线放松技术改进。此外,每预测成本是$\mathcal{O}(\operatorname{vol}{\mathcal{S}}\log 1/\epsilon)$,局部依赖于线性内存成本的图表。实验表明,我们的可扩展方法具有较好的局部和全球一致性。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23k/zhou23k.pdf)** 

# Horizon-Free and Variance-Dependent Reinforcement Learning for Latent Markov Decision Processes
**题目:** 水平自由和变异依赖的增强学习对潜在马可夫决策过程

**作者:** Runlong Zhou, Ruosong Wang, Simon Shaolei Du

**Abstract:** We study regret minimization for reinforcement learning (RL) in Latent Markov Decision Processes (LMDPs) with context in hindsight. We design a novel model-based algorithmic framework which can be instantiated with both a model-optimistic and a value-optimistic solver. We prove an $\tilde{O}(\sqrt{\mathsf{Var}^\star M \Gamma S A K})$ regret bound where $\tilde{O}$ hides logarithm factors, $M$ is the number of contexts, $S$ is the number of states, $A$ is the number of actions, $K$ is the number of episodes, $\Gamma \le S$ is the maximum transition degree of any state-action pair, and $\mathsf{Var}^\star$ is a variance quantity describing the determinism of the LMDP. The regret bound only scales logarithmically with the planning horizon, thus yielding the first (nearly) horizon-free regret bound for LMDP. This is also the first problem-dependent regret bound for LMDP. Key in our proof is an analysis of the total variance of alpha vectors (a generalization of value functions), which is handled with a truncation method. We complement our positive result with a novel $\Omega(\sqrt{\mathsf{Var}^\star M S A K})$ regret lower bound with $\Gamma = 2$, which shows our upper bound minimax optimal when $\Gamma$ is a constant for the class of variance-bounded LMDPs. Our lower bound relies on new constructions of hard instances and an argument inspired by the symmetrization technique from theoretical computer science, both of which are technically different from existing lower bound proof for MDPs, and thus can be of independent interest.

**摘要:** 在Latent Markov决策过程(LMDPs)中,我们研究了增强学习的遗憾最小化。我们设计了一个基于新模型的算法框架,可以与模型优化和价值优化的求解者进行实时化。我们证明$\tilde{O}(\sqrt{\mathsf{Var}^\star M \Gamma S A K}) regret bound where $\tilde{O}$ hides logarithm factors, $M$ is the number of contexts, $S$ is the number of states, $A$ is the number of actions, $K$ is the number of episodes, $\Gamma \le S$ is the maximum transition degree of any state-action pair, and $\mathsf{Var}^\star$ is a variance quantity describing the determinism of the LMDP。 regret 我们的证明的关键是对α向量总变量(值函数的一般化)进行分析,并用切换方法处理。我们补充了新的$\Omega(\sqrt{\mathsf{Var}^\star M S A K})$ regret lower bound 与$\Gamma = 2$,这表明当$\Gamma$为变量约束LMDP类的常数时,我们的上界最小值是最佳的。我们的下界依赖于硬实例的新构造和由理论计算机科学的对称技术所启发的论点,两者都与现有的MDP下界证明技术不同,因此可以独立感兴趣。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23l/zhou23l.pdf)** 

# Phase-aware Adversarial Defense for Improving Adversarial Robustness
**题目:** 提高敌对鲁棒性的阶段意识敌对防御

**作者:** Dawei Zhou, Nannan Wang, Heng Yang, Xinbo Gao, Tongliang Liu

**Abstract:** Deep neural networks have been found to be vulnerable to adversarial noise. Recent works show that exploring the impact of adversarial noise on intrinsic components of data can help improve adversarial robustness. However, the pattern closely related to human perception has not been deeply studied. In this paper, inspired by the cognitive science, we investigate the interference of adversarial noise from the perspective of image phase, and find ordinarily-trained models lack enough robustness against phase-level perturbations. Motivated by this, we propose a joint adversarial defense method: a phase-level adversarial training mechanism to enhance the adversarial robustness on the phase pattern; an amplitude-based pre-processing operation to mitigate the adversarial perturbation in the amplitude pattern. Experimental results show that the proposed method can significantly improve the robust accuracy against multiple attacks and even adaptive attacks. In addition, ablation studies demonstrate the effectiveness of our defense strategy.

**摘要:** 深层神经网络被发现易受敌对噪声影响,研究敌对噪声对数据的内在成分的影响有助于提高敌对鲁棒性。然而,与人类感知密切相关的模式尚未深入研究。本文以认知科学为灵感,从图像阶段的角度对敌对噪声的干扰进行了研究,并发现通常训练的模型对相位扰动缺乏足够的鲁棒性。此外, 解冻研究表明了我们的防御策略的有效性.

**[Paper URL](https://proceedings.mlr.press/v202/zhou23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23m/zhou23m.pdf)** 

# From Relational Pooling to Subgraph GNNs: A Universal Framework for More Expressive Graph Neural Networks
**题目:** 从关系聚合到子图GNN:一种更表达式图神经网络的通用框架

**作者:** Cai Zhou, Xiyuan Wang, Muhan Zhang

**Abstract:** Relational pooling is a framework for building more expressive and permutation-invariant graph neural networks. However, there is limited understanding of the exact enhancement in the expressivity of RP and its connection with the Weisfeiler-Lehman hierarchy. Starting from RP, we propose to explicitly assign labels to nodes as additional features to improve graph isomorphism distinguishing power of message passing neural networks. The method is then extended to higher-dimensional WL, leading to a novel $k,l$-WL algorithm, a more general framework than $k$-WL. We further introduce the subgraph concept into our hierarchy and propose a localized $k,l$-WL framework, incorporating a wide range of existing work, including many subgraph GNNs. Theoretically, we analyze the expressivity of $k,l$-WL w.r.t. $k$ and $l$ and compare it with the traditional $k$-WL. Complexity reduction methods are also systematically discussed to build powerful and practical $k,l$-GNN instances. We theoretically and experimentally prove that our method is universally compatible and capable of improving the expressivity of any base GNN model. Our $k,l$-GNNs achieve superior performance on many synthetic and real-world datasets, which verifies the effectiveness of our framework.

**摘要:** 关系聚合是建立更具表达性和变换不变的图神经网络的框架。然而,我们对RP的表达性和与Weisfeiler-Lehman层次结构的联系的精确提高的理解有限。从RP开始,我们提议明确分配标签给节点,以改善传递神经网络的信息的图同构性区分能力。该方法随后扩展到高维WL,导致一种新颖的$k,l$-WL算法,比$k,l$-WL更通用的框架。我们进一步引入分行概念到我们的层次结构中,并提议一个本地化的$k,l$-WL框架,包括许多分行GNN。我们从理论上和实验上证明,我们的方法是普遍兼容的,能够提高任何基础GNN模型的表达性。我们的$k,l$-GNN在许多合成和实世界数据集上取得了优越的性能,这验证了我们的框架的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23n/zhou23n.pdf)** 

# Towards Omni-generalizable Neural Methods for Vehicle Routing Problems
**题目:** 对车辆路由问题的全面通用神经方法

**作者:** Jianan Zhou, Yaoxin Wu, Wen Song, Zhiguang Cao, Jie Zhang

**Abstract:** Learning heuristics for vehicle routing problems (VRPs) has gained much attention due to the less reliance on hand-crafted rules. However, existing methods are typically trained and tested on the same task with a fixed size and distribution (of nodes), and hence suffer from limited generalization performance. This paper studies a challenging yet realistic setting, which considers generalization across both size and distribution in VRPs. We propose a generic meta-learning framework, which enables effective training of an initialized model with the capability of fast adaptation to new tasks during inference. We further develop a simple yet efficient approximation method to reduce the training overhead. Extensive experiments on both synthetic and benchmark instances of the traveling salesman problem (TSP) and capacitated vehicle routing problem (CVRP) demonstrate the effectiveness of our method. The code is available at: https://github.com/RoyalSkye/Omni-VRP.

**摘要:** 研究车辆路由问题(VRPs)的启发式学习,由于对手工制订的规则的依赖性较少,引起了广泛的关注。然而,现有的方法通常是与固定大小和分布(节点)相同的任务进行训练和测试,因此受到有限的一般化性能的影响。本论文研究了一个挑战性但现实的设置,它考虑在VRPs的大小和分布中进行一般化。我们提出了一种通用的元学习框架,它允许在推断过程中快速适应新任务的能力的初始化模型的有效培训。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23o/zhou23o.pdf)** 

# A Three-regime Model of Network Pruning
**题目:** 网络 Pruning的三种模式

**作者:** Yefan Zhou, Yaoqing Yang, Arin Chang, Michael W. Mahoney

**Abstract:** Recent work has highlighted the complex influence training hyperparameters, e.g., the number of training epochs, can have on the prunability of machine learning models. Perhaps surprisingly, a systematic approach to predict precisely how adjusting a specific hyperparameter will affect prunability remains elusive. To address this gap, we introduce a phenomenological model grounded in the statistical mechanics of learning. Our approach uses temperature-like and load-like parameters to model the impact of neural network (NN) training hyperparameters on pruning performance. A key empirical result we identify is a sharp transition phenomenon: depending on the value of a load-like parameter in the pruned model, increasing the value of a temperature-like parameter in the pre-pruned model may either enhance or impair subsequent pruning performance. Based on this transition, we build a three-regime model by taxonomizing the global structure of the pruned NN loss landscape. Our model reveals that the dichotomous effect of high temperature is associated with transitions between distinct types of global structures in the post-pruned model. Based on our results, we present three case-studies: 1) determining whether to increase or decrease a hyperparameter for improved pruning; 2) selecting the best model to prune from a family of models; and 3) tuning the hyperparameter of the Sharpness Aware Minimization method for better pruning performance.

**摘要:** 最近的研究突出了训练超参数的复杂影响,例如训练时代的数目,对机器学习模型的剪切性能的影响。也许令人惊讶的是,准确预测特定超参数的调整如何影响剪切性能的系统性方法仍然难以解决。为了解决这一差距,我们引入基于学习统计力学的现象学模型。我们采用温度和负荷等参数来模拟神经网络(NN)训练超参数对剪切性能的影响。研究结果表明,高温度的双向效应与不同类型的全球结构在剪切后模型中的转变有关。基于研究结果,我们提出了三个案例研究:(1)确定提高或降低剪切的超参数;(2)从模型家族中选择剪切的最佳模型;(3)调整 Sharpness Aware Minimization法的超参数,以提高剪切性能。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23p.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23p/zhou23p.pdf)** 

# Learning to Decouple Complex Systems
**题目:** 学习解耦复杂系统

**作者:** Zihan Zhou, Tianshu Yu

**Abstract:** A complex system with cluttered observations may be a coupled mixture of multiple simple sub-systems corresponding to latent entities. Such sub-systems may hold distinct dynamics in the continuous-time domain; therein, complicated interactions between sub-systems also evolve over time. This setting is fairly common in the real world but has been less considered. In this paper, we propose a sequential learning approach under this setting by decoupling a complex system for handling irregularly sampled and cluttered sequential observations. Such decoupling brings about not only subsystems describing the dynamics of each latent entity but also a meta-system capturing the interaction between entities over time. Specifically, we argue that the meta-system evolving within a simplex is governed by projected differential equations (ProjDEs). We further analyze and provide neural-friendly projection operators in the context of Bregman divergence. Experimental results on synthetic and real-world datasets show the advantages of our approach when facing complex and cluttered sequential data compared to the state-of-the-art.

**摘要:** 复杂系统与混杂的观测可能是多个简单的子系统相符的耦合混合物,这些子系统可以在连续时间域中保持不同的动力;其中,子系统间的复杂相互作用也随着时间演变。这种设置在现实世界中相当常见,但很少被考虑。本论文在这一设置下,我们提议将处理不规则的样品和混杂的连续观测的复杂系统分开来实现序列学习方法。这种分开不仅带来描述每个混杂的实体动力的子系统,而且也带来一种将实体间相互作用捕捉的元系统。对合成数据和实世界数据集的实验结果表明,当面对复杂的和杂乱的序列数据时,我们的方法在与最新技术相比具有优势。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23q.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23q/zhou23q.pdf)** 

# ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation
**题目:** ESC:零射击对象导航的软 Commonsense约束探索

**作者:** Kaiwen Zhou, Kaizhi Zheng, Connor Pryor, Yilin Shen, Hongxia Jin, Lise Getoor, Xin Eric Wang

**Abstract:** The ability to accurately locate and navigate to a specific object is a crucial capability for embodied agents that operate in the real world and interact with objects to complete tasks. Such object navigation tasks usually require large-scale training in visual environments with labeled objects, which generalizes poorly to novel objects in unknown environments. In this work, we present a novel zero-shot object navigation method, Exploration with Soft Commonsense constraints (ESC), that transfers commonsense knowledge in pre-trained models to open-world object navigation without any navigation experience nor any other training on the visual environments. First, ESC leverages a pre-trained vision and language model for open-world prompt-based grounding and a pre-trained commonsense language model for room and object reasoning. Then ESC converts commonsense knowledge into navigation actions by modeling it as soft logic predicates for efficient exploration. Extensive experiments on MP3D, HM3D, and RoboTHOR benchmarks show that our ESC method improves significantly over baselines, and achieves new state-of-the-art results for zero-shot object navigation (e.g., 288% relative Success Rate improvement than CoW on MP3D).

**摘要:** 精确定位和导航到特定对象的能力是实现在现实世界中操作和与对象相互作用完成任务的关键能力。此类对象导航任务通常需要在具有标签的对象的视觉环境中进行大规模训练,这种训练对未知环境中的新对象的一般化较差。本文提出了一种新的零射击对象导航方法, Exploration with Soft Commonsense constraints(ESC),它将事先训练的模型中的公义知识转移到开放世界对象导航中,不需要任何导航经验或任何其他视觉环境上的训练。在MP3D、HM3D和RoboTHOR指标上进行的广泛实验表明,我们的ESC方法比基线大幅改善,并为零射击物体导航取得最新结果(例如,比MP3D的CoW提高288%的相对成功率)。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23r.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23r/zhou23r.pdf)** 

# On Strengthening and Defending Graph Reconstruction Attack with Markov Chain Approximation
**题目:** 加强和防御马可夫链近似图形重建攻击

**作者:** Zhanke Zhou, Chenyu Zhou, Xuan Li, Jiangchao Yao, Quanming Yao, Bo Han

**Abstract:** Although powerful graph neural networks (GNNs) have boosted numerous real-world applications, the potential privacy risk is still underexplored. To close this gap, we perform the first comprehensive study of graph reconstruction attack that aims to reconstruct the adjacency of nodes. We show that a range of factors in GNNs can lead to the surprising leakage of private links. Especially by taking GNNs as a Markov chain and attacking GNNs via a flexible chain approximation, we systematically explore the underneath principles of graph reconstruction attack, and propose two information theory-guided mechanisms: (1) the chain-based attack method with adaptive designs for extracting more private information; (2) the chain-based defense method that sharply reduces the attack fidelity with moderate accuracy loss. Such two objectives disclose a critical belief that to recover better in attack, you must extract more multi-aspect knowledge from the trained GNN; while to learn safer for defense, you must forget more link-sensitive information in training GNNs. Empirically, we achieve state-of-the-art results on six datasets and three common GNNs. The code is publicly available at: https://github.com/tmlr-group/MC-GRA.

**摘要:** 尽管强大的图神经网络(GNNs)已经增强了众多的现实应用,但潜在的隐私风险仍未被充分探索。为了填补这一差距,我们进行了第一个旨在重建节点邻近的图重建攻击的综合研究。我们显示,GNNs的一系列因素可以导致私人链路意外泄漏。这样的两个目标公开了一种关键信念,即为了更好地恢复攻击,你必须从训练的GNN中提取更多的多方面知识;同时,为了更安全地学习,你必须在训练GNN时忘记更多的链接敏感信息。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23s.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23s/zhou23s.pdf)** 

# Sharp Variance-Dependent Bounds in Reinforcement Learning: Best of Both Worlds in Stochastic and Deterministic Environments
**题目:** 强化学习的尖锐变量依赖边界:随机环境和确定环境中的两个最优

**作者:** Runlong Zhou, Zhang Zihan, Simon Shaolei Du

**Abstract:** We study variance-dependent regret bounds for Markov decision processes (MDPs). Algorithms with variance-dependent regret guarantees can automatically exploit environments with low variance (e.g., enjoying constant regret on deterministic MDPs). The existing algorithms are either variance-independent or suboptimal. We first propose two new environment norms to characterize the fine-grained variance properties of the environment. For model-based methods, we design a variant of the MVP algorithm (Zhang et al., 2021a). We apply new analysis techniques to demonstrate that this algorithm enjoys variance-dependent bounds with respect to the norms we propose. In particular, this bound is simultaneously minimax optimal for both stochastic and deterministic MDPs, the first result of its kind. We further initiate the study on model-free algorithms with variance-dependent regret bounds by designing a reference-function-based algorithm with a novel capped-doubling reference update schedule. Lastly, we also provide lower bounds to complement our upper bounds.

**摘要:** 我们研究了马可夫决策过程(MDP)的变量依赖性悔恨边界。具有变量依赖性悔恨保证的算法可以自动利用低变量环境(例如,在确定性MDP上享受不变悔恨)。现有的算法要么是变量独立的,要么是次优的。我们首先提出两个新的环境规范,以区分环境的微粒变量特性。对于基于模型的方法,我们设计了MVP算法的变量(张等人,2021a)。我们应用新的分析技术,证明该算法与我们提出的规范有变量依赖性边界。最后, 我们 还 提供 了 较低 的 界限 来 补充 我们 的 上界限 。

**[Paper URL](https://proceedings.mlr.press/v202/zhou23t.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhou23t/zhou23t.pdf)** 

# Learning Unforeseen Robustness from Out-of-distribution Data Using Equivariant Domain Translator
**题目:** 利用等价域翻译器学习离散数据的不可预见的鲁棒性

**作者:** Sicheng Zhu, Bang An, Furong Huang, Sanghyun Hong

**Abstract:** Current approaches for training robust models are typically tailored to scenarios where data variations are accessible in the training set. While shown effective in achieving robustness to these foreseen variations, these approaches are ineffective in learning unforeseen robustness, i.e., robustness to data variations without known characterization or training examples reflecting them. In this work, we learn unforeseen robustness by harnessing the variations in the abundant out-of-distribution data. To overcome the main challenge of using such data, the domain gap, we use a domain translator to bridge it and bound the unforeseen robustness on the target distribution. As implied by our analysis, we propose a two-step algorithm that first trains an equivariant domain translator to map out-of-distribution data to the target distribution while preserving the considered variation, and then regularizes a model’s output consistency on the domain-translated data to improve its robustness. We empirically show the effectiveness of our approach in improving unforeseen and foreseen robustness compared to existing approaches. Additionally, we show that training the equivariant domain translator serves as an effective criterion for source data selection.

**摘要:** 当前的训练鲁棒模型的方法通常针对数据变异在训练集合中可访问的场景而设计。虽然这些方法在实现这些预见变异的鲁棒性方面表现出效果,但这些方法在学习不预见鲁棒性方面却没有效果,即没有明确的特征化或训练实例反映数据变异的鲁棒性。在这个工作中,我们通过利用大量外发数据中的变异来学习不预见鲁棒性。为了克服使用这些数据的主要挑战,即域隙,我们使用域翻译器将其桥梁并绑定目标分布上的不预见鲁棒性。我们以实证的方式证明了我们方法在改善未预见和预见的鲁棒性方面与现有方法相比的有效性。此外,我们证明了训练等效域翻译器是源数据选择的有效标准。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23a/zhu23a.pdf)** 

# Markovian Gaussian Process Variational Autoencoders
**题目:** Markovian Gaussian Process Variational Autoencoders

**作者:** Harrison Zhu, Carles Balsells-Rodas, Yingzhen Li

**Abstract:** Sequential VAEs have been successfully considered for many high-dimensional time series modelling problems, with many variant models relying on discrete-time mechanisms such as recurrent neural networks (RNNs). On the other hand, continuous-time methods have recently gained attraction, especially in the context of irregularly-sampled time series, where they can better handle the data than discrete-time methods. One such class are Gaussian process variational autoencoders (GPVAEs), where the VAE prior is set as a Gaussian process (GP). However, a major limitation of GPVAEs is that it inherits the cubic computational cost as GPs, making it unattractive to practioners. In this work, we leverage the equivalent discrete state space representation of Markovian GPs to enable linear time GPVAE training via Kalman filtering and smoothing. For our model, Markovian GPVAE (MGPVAE), we show on a variety of high-dimensional temporal and spatiotemporal tasks that our method performs favourably compared to existing approaches whilst being computationally highly scalable.

**摘要:** 连续时间模型在许多高维时间序列建模问题上得到了成功考虑,许多变量模型依赖于离散时间机制,例如循环神经网络(RNNs)。另一方面,连续时间方法最近获得了吸引力,特别是在不规则采样时间序列的情况下,它们比离散时间方法处理数据更好。其中一种类别是高斯过程变量自动编码器(GPVAEs),其中VAE前列设置为高斯过程(GP)。对于我们的模型,马科维安GPVAE(MGPVAE),我们在多种高维时空和空间时空任务上表明,我们的方法在计算上具有高度可扩展性的同时,与现有方法相比 performs favourably。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23b.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23b/zhu23b.pdf)** 

# Mixture Proportion Estimation Beyond Irreducibility
**题目:** 混合物比例估算超出可微化程度

**作者:** Yilun Zhu, Aaron Fjeldsted, Darren Holland, George Landon, Azaree Lintereur, Clayton Scott

**Abstract:** The task of mixture proportion estimation (MPE) is to estimate the weight of a component distribution in a mixture, given observations from both the component and mixture. Previous work on MPE adopts the irreducibility assumption, which ensures identifiablity of the mixture proportion. In this paper, we propose a more general sufficient condition that accommodates several settings of interest where irreducibility does not hold. We further present a resampling-based meta-algorithm that takes any existing MPE algorithm designed to work under irreducibility and adapts it to work under our more general condition. Our approach empirically exhibits improved estimation performance relative to baseline methods and to a recently proposed regrouping-based algorithm.

**摘要:** 混合比例估计(MPE)的任务是根据混合物和混合物的观察,估计混合物中的组成部分分布的重量。MPE以前的工作采用了不可减量假设,保证混合物比例的识别性。本文提出了一种较通用的充分条件,可以容纳在不可减量不成立的几个兴趣环境。我们进一步提出一种基于重新采样的元算法,它将任何设计在不可减量下工作的现有MPE算法应用于我们的更通用条件下。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23c.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23c/zhu23c.pdf)** 

# Exploring Model Dynamics for Accumulative Poisoning Discovery
**题目:** 对累积中毒发现的模型动力学研究

**作者:** Jianing Zhu, Xiawei Guo, Jiangchao Yao, Chao Du, Li He, Shuo Yuan, Tongliang Liu, Liang Wang, Bo Han

**Abstract:** Adversarial poisoning attacks pose huge threats to various machine learning applications. Especially, the recent accumulative poisoning attacks show that it is possible to achieve irreparable harm on models via a sequence of imperceptible attacks followed by a trigger batch. Due to the limited data-level discrepancy in real-time data streaming, current defensive methods are indiscriminate in handling the poison and clean samples. In this paper, we dive into the perspective of model dynamics and propose a novel information measure, namely, Memorization Discrepancy, to explore the defense via the model-level information. By implicitly transferring the changes in the data manipulation to that in the model outputs, Memorization Discrepancy can discover the imperceptible poison samples based on their distinct dynamics from the clean samples. We thoroughly explore its properties and propose Discrepancy-aware Sample Correction (DSC) to defend against accumulative poisoning attacks. Extensive experiments comprehensively characterized Memorization Discrepancy and verified its effectiveness. The code is publicly available at: https://github.com/tmlr-group/Memorization-Discrepancy.

**摘要:** 敌对中毒攻击对各种机器学习应用构成巨大威胁,特别是最近的累积中毒攻击表明,通过触发批次的隐形攻击序列,可以对模型造成不可弥补的伤害。由于实时数据流中的数据水平差异有限,当前的防御方法在处理毒药和清洁样品时不分区分。本文深入研究了模型动力学的视角,提出了一种新的信息措施,即记忆差异,通过模型水平信息探索防御。广泛的实验全面描述了记忆差异,并验证了它的有效性。代码可于: https://github.com/tmlr-group/Memorization-Discrepancy公开。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23d.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23d/zhu23d.pdf)** 

# Decentralized SGD and Average-direction SAM are Asymptotically Equivalent
**题目:** 分散的SGD和平均方向SAM均匀

**作者:** Tongtian Zhu, Fengxiang He, Kaixuan Chen, Mingli Song, Dacheng Tao

**Abstract:** Decentralized stochastic gradient descent (D-SGD) allows collaborative learning on massive devices simultaneously without the control of a central server. However, existing theories claim that decentralization invariably undermines generalization. In this paper, we challenge the conventional belief and present a completely new perspective for understanding decentralized learning. We prove that D-SGD implicitly minimizes the loss function of an average-direction Sharpness-aware minimization (SAM) algorithm under general non-convex non-$\beta$-smooth settings. This surprising asymptotic equivalence reveals an intrinsic regularization-optimization trade-off and three advantages of decentralization: (1) there exists a free uncertainty evaluation mechanism in D-SGD to improve posterior estimation; (2) D-SGD exhibits a gradient smoothing effect; and (3) the sharpness regularization effect of D-SGD does not decrease as total batch size increases, which justifies the potential generalization benefit of D-SGD over centralized SGD (C-SGD) in large-batch scenarios.

**摘要:** 分散随机梯度下降(英语:Decentralized stochastic gradient descent, D-SGD)允许在集中服务器控制下同时在大规模设备上进行协作学习,但现有理论认为分散不可避免地破坏了一般化。这一令人惊奇的渐近同等性揭示了内在的调节-优化权衡和分散权衡的三个优点:(一)D-SGD有一个自由的不确定性评价机制,以改善后方估计;(二)D-SGD表现出梯度平滑效应;(三)D-SGD的锐度调节效应不会随着批量总数的增加而减少,这说明D-SGD在大型批量场景中比集中SGD(C-SGD)具有潜在的推广优势。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23e.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23e/zhu23e.pdf)** 

# Principled Reinforcement Learning with Human Feedback from Pairwise or K-wise Comparisons
**题目:** 基于人际反馈的原理强化学习从双向或K向比较

**作者:** Banghua Zhu, Michael Jordan, Jiantao Jiao

**Abstract:** We provide a theoretical framework for Reinforcement Learning with Human Feedback (RLHF). We show that when the underlying true reward is linear, under both Bradley-Terry-Luce (BTL) model (pairwise comparison) and Plackett-Luce (PL) model ($K$-wise comparison), MLE converges under certain semi-norm for the family of linear reward. On the other hand, when training a policy based on the learned reward model, we show that MLE fails while a pessimistic MLE provides policies with good performance under certain coverage assumption. We also show that under the PL model, both the true MLE and a different MLE which splits the $K$-wise comparison into pairwise comparisons converge, while the true MLE is asymptotically more efficient. Our results validate the empirical success of the existing RLHF algorithms, and provide new insights for algorithm design. Our analysis can also be applied for the problem of online RLHF and inverse reinforcement learning.

**摘要:** 我们提供了一个基于人反馈的增强学习理论框架。我们表明,当潜在的真正的奖励线性时,在Bradley-Terry-Luce(BTL)模型(双向比较)和Plackett-Luce(PL)模型($K$-wise比较)下,MLE在线性奖励家族的某些半标准下收敛。另一方面,当训练基于学习的奖励模型的政策时,我们表明MLE失败,而悲观的MLE在某些覆盖假设下提供良好表现的政策。我们还表明,在PL模型下, true MLE和不同的MLE,将$K$-wise比较分成双向比较收敛,而 true MLE的效率更高。我们的结果验证了现有RLHF算法的实证成功,为算法设计提供了新的洞察力。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23f.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23f/zhu23f.pdf)** 

# Unleashing Mask: Explore the Intrinsic Out-of-Distribution Detection Capability
**题目:** 释放面具:探索内部外散检测能力

**作者:** Jianing Zhu, Hengzhuang Li, Jiangchao Yao, Tongliang Liu, Jianliang Xu, Bo Han

**Abstract:** Out-of-distribution (OOD) detection is an indispensable aspect of secure AI when deploying machine learning models in real-world applications. Previous paradigms either explore better scoring functions or utilize the knowledge of outliers to equip the models with the ability of OOD detection. However, few of them pay attention to the intrinsic OOD detection capability of the given model. In this work, we generally discover the existence of an intermediate stage of a model trained on in-distribution (ID) data having higher OOD detection performance than that of its final stage across different settings, and further identify one critical data-level attribution to be learning with the atypical samples. Based on such insights, we propose a novel method, Unleashing Mask, which aims to restore the OOD discriminative capabilities of the well-trained model with ID data. Our method utilizes a mask to figure out the memorized atypical samples, and then finetune the model or prune it with the introduced mask to forget them. Extensive experiments and analysis demonstrate the effectiveness of our method. The code is available at: https://github.com/tmlr-group/Unleashing-Mask.

**摘要:** 在实际应用中部署机器学习模型时,非分布式(OOD)检测是安全AI的一个不可缺少的方面。以前的模式 either explore better scoring functions or utilize the knowledge of outliers to equip the models with the ability of OOD detection。然而,其中很少有人注意给定模型的内在OOD detection capability。在这个工作中,我们一般发现一种在分布式(ID)数据上训练的模型的中间阶段存在,该模型的OOD检测性能比其最终阶段高,并且进一步确定一个关键数据级别的属性,以学习非典型样本。我们的方法利用面具来找出记载的非典型样品,然后调整模型或用引入的面具削减它们。广泛的实验和分析证明了我们的方法的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23g.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23g/zhu23g.pdf)** 

# Benign Overfitting in Deep Neural Networks under Lazy Training
**题目:** 懒惰训练下的深度神经网络的优越适应

**作者:** Zhenyu Zhu, Fanghui Liu, Grigorios Chrysos, Francesco Locatello, Volkan Cevher

**Abstract:** This paper focuses on over-parameterized deep neural networks (DNNs) with ReLU activation functions and proves that when the data distribution is well-separated, DNNs can achieve Bayes-optimal test error for classification while obtaining (nearly) zero-training error under the lazy training regime. For this purpose, we unify three interrelated concepts of overparameterization, benign overfitting, and the Lipschitz constant of DNNs. Our results indicate that interpolating with smoother functions leads to better generalization. Furthermore, we investigate the special case where interpolating smooth ground-truth functions is performed by DNNs under the Neural Tangent Kernel (NTK) regime for generalization. Our result demonstrates that the generalization error converges to a constant order that only depends on label noise and initialization noise, which theoretically verifies benign overfitting. Our analysis provides a tight lower bound on the normalized margin under non-smooth activation functions, as well as the minimum eigenvalue of NTK under high-dimensional settings, which has its own interest in learning theory.

**摘要:** 本文着重研究了具有ReLU激活功能的超参数化深度神经网络(DNNs),并证明当数据分布分离良好时,DNNs可以在懒惰训练模式下获得(近乎)零训练误差时实现贝伊斯最佳分类测试误差。为此目的,我们统一了超参数化、良性过渡和DNNs的利普希茨常数三个相互关联的概念。本文给出了非滑动激活函数下的正常化边界与高维环境下NTK的最小特征值的严格较低界限,具有学习理论的特殊意义。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23h.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23h/zhu23h.pdf)** 

# Interpolation for Robust Learning: Data Augmentation on Wasserstein Geodesics
**题目:** 对鲁棒学习的插值:维多斯泰因地质学数据增强

**作者:** Jiacheng Zhu, Jielin Qiu, Aritra Guha, Zhuolin Yang, Xuanlong Nguyen, Bo Li, Ding Zhao

**Abstract:** We propose to study and promote the robustness of a model as per its performance on a continuous geodesic interpolation of subpopulations, e.g., a class of samples in a classification problem. Specifically, (1) we augment the data by finding the worst-case Wasserstein barycenter on the geodesic connecting subpopulation distributions. (2) we regularize the model for smoother performance on the continuous geodesic path connecting subpopulation distributions. (3) Additionally, we provide a theoretical guarantee of robustness improvement and investigate how the geodesic location and the sample size contribute, respectively. Experimental validations of the proposed strategy on four datasets including CIFAR-100 and ImageNet, establish the efficacy of our method, e.g., our method improves the baselines’ certifiable robustness on CIFAR10 upto 7.7%, with 16.8% on empirical robustness on CIFAR-100. Our work provides a new perspective of model robustness through the lens of Wasserstein geodesic-based interpolation with a practical off-the-shelf strategy that can be combined with existing robust training methods.

**摘要:** 我们建议研究和推广一种模型的鲁棒性,根据其在子种连续地质插值上的性能,例如在分类问题中的一个类别的样品。具体而言,(1)我们通过寻找与子种分布相连的地质插值上的最坏情况的WatersteinBarycenter来增加数据。(2)我们对联结子种分布的连续地质插值路径的鲁棒性进行更平滑的规范化。(3)此外,我们提供了鲁棒性改进的理论保证,并分别研究了地质插值的位置和样品大小如何贡献。我们的工作提供了一种新的模型鲁棒性的视角,通过施瓦茨泰因地质测定基于插值的透镜,并结合现有的鲁棒训练方法。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23i.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23i/zhu23i.pdf)** 

# LeadFL: Client Self-Defense against Model Poisoning in Federated Learning
**题目:** LeadFL:联邦学习中的客户自我防护

**作者:** Chaoyi Zhu, Stefanie Roos, Lydia Y. Chen

**Abstract:** Federated Learning is highly susceptible to backdoor and targeted attacks as participants can manipulate their data and models locally without any oversight on whether they follow the correct process. There are a number of server-side defenses that mitigate the attacks by modifying or rejecting local updates submitted by clients. However, we find that bursty adversarial patterns with a high variance in the number of malicious clients can circumvent the existing defenses. We propose a client-self defense, LeadFL, that is combined with existing server-side defenses to thwart backdoor and targeted attacks. The core idea of LeadFL is a novel regularization term in local model training such that the Hessian matrix of local gradients is nullified. We provide the convergence analysis of LeadFL and its robustness guarantee in terms of certified radius. Our empirical evaluation shows that LeadFL is able to mitigate bursty adversarial patterns for both iid and non-iid data distributions. It frequently reduces the backdoor accuracy from more than 75% for state-of-the-art defenses to less than 10% while its impact on the main task accuracy is always less than for other client-side defenses.

**摘要:** 联邦学习对后门和目标攻击具有高度敏感性,因为参与者可以在没有对他们是否遵循正确的过程进行监督的情况下,在本地操作他们的数据和模型。有多个服务器侧防御以修改或拒绝客户提交的本地更新来缓解攻击。然而,我们发现,在恶意客户数目中具有高度差异的燃烧的敌对模式可以绕过现有的防御。我们提出了一个客户自身防御,LeadFL,它与现有的服务器侧防御结合来抵制后门和目标攻击。LeadFL的核心思想是本地模型培训中一种新颖的规范化术语,例如局部梯度的希斯基矩阵被取消。它经常降低了最先进的防护的后门精度从75%以上降低到10%以下,而对主要任务的准确性的影响总是比其他客户端防护要低。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23j.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23j/zhu23j.pdf)** 

# XTab: Cross-table Pretraining for Tabular Transformers
**题目:** XTab:表格转换器交叉表格预训练

**作者:** Bingzhao Zhu, Xingjian Shi, Nick Erickson, Mu Li, George Karypis, Mahsa Shoaran

**Abstract:** The success of self-supervised learning in computer vision and natural language processing has motivated pretraining methods on tabular data. However, most existing tabular self-supervised learning models fail to leverage information across multiple data tables and cannot generalize to new tables. In this work, we introduce XTab, a framework for cross-table pretraining of tabular transformers on datasets from various domains. We address the challenge of inconsistent column types and quantities among tables by utilizing independent featurizers and using federated learning to pretrain the shared component. Tested on 84 tabular prediction tasks from the OpenML-AutoML Benchmark (AMLB), we show that (1) XTab consistently boosts the generalizability, learning speed, and performance of multiple tabular transformers, (2) by pretraining FT-Transformer via XTab, we achieve superior performance than other state-of-the-art tabular deep learning models on various tasks such as regression, binary, and multiclass classification.

**摘要:** 在计算机视觉和自然语言处理中,自监督学习的成功激发了对表数据的预训练方法。然而,大多数现有的表自监督学习模型无法在多个数据表中利用信息,无法将信息推广到新的表中。本文介绍了XTab,一种基于不同领域的数据集的表变换器交叉表预训练框架。通过对OpenML-AutoML Benchmark(AMLB)的84个表格预测任务进行测试,我们发现: (1)XTab持续提高多个表格变换器的通用性、学习速度和性能; (2)通过XTab预训练FT-Transformer,我们在回归、二进制和多类分类等各种任务上比其他最先进的表格深度学习模型取得更高的性能。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23k.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23k/zhu23k.pdf)** 

# Provable Multi-instance Deep AUC Maximization with Stochastic Pooling
**题目:** 基于随机聚合的多实例深度AUC最大化

**作者:** Dixian Zhu, Bokun Wang, Zhi Chen, Yaxing Wang, Milan Sonka, Xiaodong Wu, Tianbao Yang

**Abstract:** This paper considers a novel application of deep AUC maximization (DAM) for multi-instance learning (MIL), in which a single class label is assigned to a bag of instances (e.g., multiple 2D slices of a CT scan for a patient). We address a neglected yet non-negligible computational challenge of MIL in the context of DAM, i.e., bag size is too large to be loaded into GPU memory for backpropagation, which is required by the standard pooling methods of MIL. To tackle this challenge, we propose variance-reduced stochastic pooling methods in the spirit of stochastic optimization by formulating the loss function over the pooled prediction as a multi-level compositional function. By synthesizing techniques from stochastic compositional optimization and non-convex min-max optimization, we propose a unified and provable muli-instance DAM (MIDAM) algorithm with stochastic smoothed-max pooling or stochastic attention-based pooling, which only samples a few instances for each bag to compute a stochastic gradient estimator and to update the model parameter. We establish a similar convergence rate of the proposed MIDAM algorithm as the state-of-the-art DAM algorithms. Our extensive experiments on conventional MIL datasets and medical datasets demonstrate the superiority of our MIDAM algorithm. The method is open-sourced at https://libauc.org/.

**摘要:** 本文研究了多实例学习(MIL)中深度AUC最大化(DAM)的新应用,即将单个类标记分配给一袋实例(例如对病人进行CT扫描的多个2D切片)。本文针对DAM中忽略且不可忽略的 MIL 的计算挑战,即袋体尺寸太大,无法载入 GPU 内存,这是 MIL 的标准聚合方法所要求的。通过从随机成分优化和非凸最小最小优化的综合技术,我们提出了一种统一和可证明的Mili-instance DAM(MIDAM)算法,即随机滑度最大聚合或随机注意力聚合,该算法仅为每个袋子计算随机梯度估计器和更新模型参数的几个实例。我们建立了拟议的MIDAM算法的类似收敛率,作为最先进的DAM算法。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23l.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23l/zhu23l.pdf)** 

# Surrogate Model Extension (SME): A Fast and Accurate Weight Update Attack on Federated Learning
**题目:** 替代模型扩展:对联邦学习的快速和准确体重更新攻击

**作者:** Junyi Zhu, Ruicong Yao, Matthew B. Blaschko

**Abstract:** In Federated Learning (FL) and many other distributed training frameworks, collaborators can hold their private data locally and only share the network weights trained with the local data after multiple iterations. Gradient inversion is a family of privacy attacks that recovers data from its generated gradients. Seemingly, FL can provide a degree of protection against gradient inversion attacks on weight updates, since the gradient of a single step is concealed by the accumulation of gradients over multiple local iterations. In this work, we propose a principled way to extend gradient inversion attacks to weight updates in FL, thereby better exposing weaknesses in the presumed privacy protection inherent in FL. In particular, we propose a surrogate model method based on the characteristic of two-dimensional gradient flow and low-rank property of local updates. Our method largely boosts the ability of gradient inversion attacks on weight updates containing many iterations and achieves state-of-the-art (SOTA) performance. Additionally, our method runs up to $100\times$ faster than the SOTA baseline in the common FL scenario. Our work re-evaluates and highlights the privacy risk of sharing network weights. Our code is available at https://github.com/JunyiZhu-AI/surrogate_model_extension.

**摘要:** 在联邦学习(FL)和许多其他分布式培训框架中,协作者可以将他们的私人数据保持在本地,并仅在多个迭代后与本地数据进行训练的网络权重共享。梯度反演是一个从其生成梯度中恢复数据的隐私攻击家族。显然,FL可以提供对重量更新的梯度反演攻击的保护程度,因为单一步骤的梯度是由梯度累积在多个本地迭代上隐藏的。我们的方法极大地提升了包含许多迭代的重量更新的梯度反向攻击的能力,并实现了最先进的(SOTA)性能。此外,我们的方法在通用的FL场景中比SOTA基线快100$。我们的工作重新评估和突出分享网络权重的隐私风险。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23m.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23m/zhu23m.pdf)** 

# Weak Proxies are Sufficient and Preferable for Fairness with Missing Sensitive Attributes
**题目:** 缺乏敏感属性的弱代理是公平的充分和最优

**作者:** Zhaowei Zhu, Yuanshun Yao, Jiankai Sun, Hang Li, Yang Liu

**Abstract:** Evaluating fairness can be challenging in practice because the sensitive attributes of data are often inaccessible due to privacy constraints. The go-to approach that the industry frequently adopts is using off-the-shelf proxy models to predict the missing sensitive attributes, e.g. Meta (Alao et al., 2021) and Twitter (Belli et al., 2022). Despite its popularity, there are three important questions unanswered: (1) Is directly using proxies efficacious in measuring fairness? (2) If not, is it possible to accurately evaluate fairness using proxies only? (3) Given the ethical controversy over infer-ring user private information, is it possible to only use weak (i.e. inaccurate) proxies in order to protect privacy? Our theoretical analyses show that directly using proxy models can give a false sense of (un)fairness. Second, we develop an algorithm that is able to measure fairness (provably) accurately with only three properly identified proxies. Third, we show that our algorithm allows the use of only weak proxies (e.g. with only 68.85% accuracy on COMPAS), adding an extra layer of protection on user privacy. Experiments validate our theoretical analyses and show our algorithm can effectively measure and mitigate bias. Our results imply a set of practical guidelines for prac-titioners on how to use proxies properly. Code is available at https://github.com/UCSC-REAL/fair-eval.

**摘要:** 评估公平性在实践中是挑战性的,因为数据的敏感属性往往由于隐私约束而无法访问。行业经常采用的方法是使用现货代理模型来预测丢失的敏感属性,例如Meta(Alao et al., 2021)和Twitter(Belli et al., 2022)。尽管这种模型很受欢迎,但仍有三个重要问题未得到回答: (1)直接代理在测量公平性时是否有效? (2)如果不有效,是否能准确地评估公平性,只使用代理? (3)鉴于关于推测用户隐私信息的伦理争议,是否能只使用弱(即不准确)代理来保护隐私? 我们的理论分析表明,直接代理模型可以给(不)公平的误解。第三,我们证明,我们的算法允许使用只有弱的代理(例如只有68.85%的精度在COMPAS上),增加了用户隐私的额外保护层。实验验证了我们的理论分析,并表明我们的算法能够有效地测量和减轻偏见。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23n.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23n/zhu23n.pdf)** 

# Label Distributionally Robust Losses for Multi-class Classification: Consistency, Robustness and Adaptivity
**题目:** 多类分类的分布性鲁棒损失:一致性、鲁棒性和适应性

**作者:** Dixian Zhu, Yiming Ying, Tianbao Yang

**Abstract:** We study a family of loss functions named label-distributionally robust (LDR) losses for multi-class classification that are formulated from distributionally robust optimization (DRO) perspective, where the uncertainty in the given label information are modeled and captured by taking the worse case of distributional weights. The benefits of this perspective are several fold: (i) it provides a unified framework to explain the classical cross-entropy (CE) loss and SVM loss and their variants, (ii) it includes a special family corresponding to the temperature-scaled CE loss, which is widely adopted but poorly understood; (iii) it allows us to achieve adaptivity to the uncertainty degree of label information at an instance level. Our contributions include: (1) we study both consistency and robustness by establishing top-$k$ ($\forall k\geq 1$) consistency of LDR losses for multi-class classification, and a negative result that a top-$1$ consistent and symmetric robust loss cannot achieve top-$k$ consistency simultaneously for all $k\geq 2$; (2) we propose a new adaptive LDR loss that automatically adapts the individualized temperature parameter to the noise degree of class label of each instance; (3) we demonstrate stable and competitive performance for the proposed adaptive LDR loss on 7 benchmark datasets under 6 noisy label and 1 clean settings against 13 loss functions, and on one real-world noisy dataset. The method is open-sourced at https://github.com/Optimization-AI/ICML2023_LDR.

**摘要:** 我们研究了一种基于分布性鲁棒优化(DRO)的多类分类的标签分布性鲁棒(LDR)损失函数家族,该家族的优点是: (i)它提供了统一的框架来解释经典跨热带(CE)损失和SVM损失及其变异, (ii)它包含了一个与温度分布式CE损失相符的特殊家族,它被广泛采用,但不太了解; (iii)它使我们能够在实例一级适应标签信息的不确定性程度。我们的贡献包括: (一)通过建立多类分类的LDR损失的顶$k$($\forall k\geq 1$)一致性和鲁棒性,以及一个负结果,即一个顶$1$一致和对称鲁棒损失不能同时实现顶$k$一致性的所有$k\geq 2$; (二)我们提出了一种新的适应性LDR损失,它将自动调整个人化温度参数到每个实例的类标签的噪声度; (三)我们证明了建议的适应性LDR损失的稳定和竞争性性能,在6个噪声标签下7个基准数据集和1个对13个损失函数的清洁设置下,以及在一个真实噪声数据集上。

**[Paper URL](https://proceedings.mlr.press/v202/zhu23o.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhu23o/zhu23o.pdf)** 

# Likelihood Adjusted Semidefinite Programs for Clustering Heterogeneous Data
**题目:** 聚类异性数据的拟合半定义程序

**作者:** Yubo Zhuang, Xiaohui Chen, Yun Yang

**Abstract:** Clustering is a widely deployed unsupervised learning tool. Model-based clustering is a flexible framework to tackle data heterogeneity when the clusters have different shapes. Likelihood-based inference for mixture distributions often involves non-convex and high-dimensional objective functions, imposing difficult computational and statistical challenges. The classic expectation-maximization (EM) algorithm is a computationally thrifty iterative method that maximizes a surrogate function minorizing the log-likelihood of observed data in each iteration, which however suffers from bad local maxima even in the special case of the standard Gaussian mixture model with common isotropic covariance matrices. On the other hand, recent studies reveal that the unique global solution of a semidefinite programming (SDP) relaxed $K$-means achieves the information-theoretically sharp threshold for perfectly recovering the cluster labels under the standard Gaussian mixture model. In this paper, we extend the SDP approach to a general setting by integrating cluster labels as model parameters and propose an iterative likelihood adjusted SDP (iLA-SDP) method that directly maximizes the exact observed likelihood in the presence of data heterogeneity. By lifting the cluster assignment to group-specific membership matrices, iLA-SDP avoids centroids estimation – a key feature that allows exact recovery under well-separateness of centroids without being trapped by their adversarial configurations. Thus iLA-SDP is less sensitive than EM to initialization and more stable on high-dimensional data. Our numeric experiments demonstrate that iLA-SDP can achieve lower mis-clustering errors over several widely used clustering methods including $K$-means, SDP and EM algorithms.

**摘要:** 聚类是一个广泛部署的无监督的学习工具。基于模型的聚类是处理数据异质性时的灵活框架,聚类具有不同的形状。聚类分布的概率推理通常涉及非凸和高维目标函数,强加复杂的计算和统计挑战。经典期望最大化(EM)算法是计算上灵活的迭代方法,它最大化了一个替代函数,减少了在每个迭代中观察到的数据的逻辑概率,但即使在标准高斯混合模型的特殊情况下,它也会遭受坏局部最大值。本文通过将集群标签作为模型参数结合,将SDP方法扩展到一般设置,并提出一种迭代概率调整SDP(iLA-SDP)方法,直接在数据异质的情况下最大化观察到的准确概率。通过将集群分配到特定组别成员矩阵,iLA-SDP避免了中立体估计 — — 一个关键特征,允许在中立体的良好隔离下进行准确的恢复,而不被它们的敌对配置困住。因此,iLA-SDP比EM更敏感于初始化,并且在高维数据上更稳定。

**[Paper URL](https://proceedings.mlr.press/v202/zhuang23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zhuang23a/zhuang23a.pdf)** 

# Are Random Decompositions all we need in High Dimensional Bayesian Optimisation?
**题目:** 随机分解是高维贝叶斯优化所需要的吗?

**作者:** Juliusz Krzysztof Ziomek, Haitham Bou Ammar

**Abstract:** Learning decompositions of expensive-to-evaluate black-box functions promises to scale Bayesian optimisation (BO) to high-dimensional problems. However, the success of these techniques depends on finding proper decompositions that accurately represent the black-box. While previous works learn those decompositions based on data, we investigate data-independent decomposition sampling rules in this paper. We find that data-driven learners of decompositions can be easily misled towards local decompositions that do not hold globally across the search space. Then, we formally show that a random tree-based decomposition sampler exhibits favourable theoretical guarantees that effectively trade off maximal information gain and functional mismatch between the actual black-box and its surrogate as provided by the decomposition. Those results motivate the development of the random decomposition upper-confidence bound algorithm (RDUCB) that is straightforward to implement - (almost) plug-and-play - and, surprisingly, yields significant empirical gains compared to the previous state-of-the-art on a comprehensive set of benchmarks. We also confirm the plug-and-play nature of our modelling component by integrating our method with HEBO, showing improved practical gains in the highest dimensional tasks from Bayesmark problem suite.

**摘要:** 研究高成本评价黑箱函数的分解过程,可以将贝叶斯优化(BO)扩展到高维问题。然而,这些技术的成功取决于找到准确地代表黑箱的适当分解过程。虽然以前的工作基于数据学习这些分解过程,但本文对数据独立的分解抽样规则进行了研究。我们发现,数据驱动的分解学习者很容易被误导到全球搜索空间中不保持的局部分解过程。这些结果激励了开发一种易于实现的随机分解上信bound算法(RDUCB)--几乎是插件操作--并 surprisingly yields significant empirical gains compared to the previous state-of-the-art on a comprehensive set of benchmarks. 我们还通过将我们的方法集成到HEBO,证实了我们的建模组件的插件操作性质,显示了从Bayesmark问题套件中获得的最高维度任务中的改进的实际收益。

**[Paper URL](https://proceedings.mlr.press/v202/ziomek23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ziomek23a/ziomek23a.pdf)** 

# Revisiting Bellman Errors for Offline Model Selection
**题目:** 重新检视贝尔曼错误在非线模型选择中

**作者:** Joshua P Zitovsky, Daniel De Marchi, Rishabh Agarwal, Michael Rene Kosorok

**Abstract:** Offline model selection (OMS), that is, choosing the best policy from a set of many policies given only logged data, is crucial for applying offline RL in real-world settings. One idea that has been extensively explored is to select policies based on the mean squared Bellman error (MSBE) of the associated Q-functions. However, previous work has struggled to obtain adequate OMS performance with Bellman errors, leading many researchers to abandon the idea. To this end, we elucidate why previous work has seen pessimistic results with Bellman errors and identify conditions under which OMS algorithms based on Bellman errors will perform well. Moreover, we develop a new estimator of the MSBE that is more accurate than prior methods. Our estimator obtains impressive OMS performance on diverse discrete control tasks, including Atari games.

**摘要:** 非线性模型选择(OMS),即从多个政策中选择最佳政策,仅提供记录数据,是应用非线性RL在现实环境中的关键。一个被广泛研究的想法是根据关联Q函数的平均方程贝尔曼误差(MSBE)选择政策。然而,以前的工作已经努力获得与贝尔曼误差相适应的OMS性能,导致许多研究人员放弃这一想法。为此,我们解释了为什么以前的工作已经看到与贝尔曼误差的悲观结果,并确定了基于贝尔曼误差的OMS算法在哪些条件下将表现良好。

**[Paper URL](https://proceedings.mlr.press/v202/zitovsky23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zitovsky23a/zitovsky23a.pdf)** 

# spred: Solving L1 Penalty with SGD
**题目:** 散发:用SGD解决L1处罚

**作者:** Liu Ziyin, Zihao Wang

**Abstract:** We propose to minimize a generic differentiable objective with $L_1$ constraint using a simple reparametrization and straightforward stochastic gradient descent. Our proposal is the direct generalization of previous ideas that the $L_1$ penalty may be equivalent to a differentiable reparametrization with weight decay. We prove that the proposed method, spred, is an exact differentiable solver of $L_1$ and that the reparametrization trick is completely “benign" for a generic nonconvex function. Practically, we demonstrate the usefulness of the method in (1) training sparse neural networks to perform gene selection tasks, which involves finding relevant features in a very high dimensional space, and (2) neural network compression task, to which previous attempts at applying the $L_1$-penalty have been unsuccessful. Conceptually, our result bridges the gap between the sparsity in deep learning and conventional statistical learning.

**摘要:** 我们建议用简单的修正法和直观随机梯度下降来最小化一种通用的可微分目标,我们建议的是将先前的理论直接推广成可微分修正法与重量衰变的可微分修正法。我们证明,所提议的方法,Spread,是$L_1$的精确可微分解法,而且修正法对于通用的非凸函数是完全“妥当的”。在实践中,我们证明了该方法在(1)训练稀疏神经网络执行基因选择任务时的有效性,包括在高维空间中找到相关特征,以及(2)神经网络压缩任务时的有效性,在应用$L_1$-罚金以前的尝试失败。

**[Paper URL](https://proceedings.mlr.press/v202/ziyin23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/ziyin23a/ziyin23a.pdf)** 

# The Benefits of Mixup for Feature Learning
**题目:** 混合技术对特征学习的好处

**作者:** Difan Zou, Yuan Cao, Yuanzhi Li, Quanquan Gu

**Abstract:** Mixup, a simple data augmentation method that randomly mixes two data points via linear interpolation, has been extensively applied in various deep learning applications to gain better generalization. However, its theoretical explanation remains largely unclear. In this work, we aim to seek a fundamental understanding of the benefits of Mixup. We first show that Mixup using different linear interpolation parameters for features and labels can still achieve similar performance as standard Mixup. This indicates that the intuitive linearity explanation in Zhang et al., (2018) may not fully explain the success of Mixup. Then, we perform a theoretical study of Mixup from the feature learning perspective. We consider a feature-noise data model and show that Mixup training can effectively learn the rare features (appearing in a small fraction of data) from its mixture with the common features (appearing in a large fraction of data). In contrast, standard training can only learn the common features but fails to learn the rare features, thus suffering from bad generalization performance. Moreover, our theoretical analysis also shows that the benefits of Mixup for feature learning are mostly gained in the early training phase, based on which we propose to apply early stopping in Mixup. Experimental results verify our theoretical findings and demonstrate the effectiveness of the early-stopped Mixup training.

**摘要:** 混合,一种通过线性插值随机混合两个数据点的简单数据增强方法,广泛应用于各种深层学习应用,以获得更好的一般化。然而,其理论解释仍然十分不明确。在这个工作中,我们的目标是寻求混合的益处的根本理解。我们首先表明,使用不同线性插值参数的混合仍然可以达到标准混合的类似性能。这表明,张等人(2018年)的直观线性解释可能不能充分解释混合的成功。相比之下,标准训练只能学习普通特征,却不能学习罕见特征,因而 suffer from bad generalization performance 。 此外,我们的理论分析也表明,Mixup对特征学习的好处主要是在早期训练阶段获得,基于此,我们建议在Mixup中应用早期停止。实验结果验证了我们的理论发现,并证明了Mixup早期停止训练的有效性。

**[Paper URL](https://proceedings.mlr.press/v202/zou23a.html)** 

**[Paper PDF](https://proceedings.mlr.press/v202/zou23a/zou23a.pdf)** 

